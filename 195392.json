{"path":"contrib/miscellaneous/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","commits":[{"id":"7ae36bc5dae83f94e7da6e03d7f3b14ea175af4c","date":1166653933,"type":0,"author":"Otis Gospodnetic","isMerge":false,"pathNew":"contrib/miscellaneous/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Resets the norms for the specified field.\n   *\n   * <p>\n   * Opens a new IndexReader on the Directory given to this instance,\n   * modifies the norms (either using the Similarity given to this instance, or by using fake norms,\n   * and closes the IndexReader.\n   * </p>\n   *\n   * @param field the field whose norms should be reset\n   */\n  public void reSetNorms(String field) throws IOException {\n    String fieldName = field.intern();\n    int[] termCounts = new int[0];\n    byte[] fakeNorms = new byte[0];\n    \n    IndexReader reader = null;\n    TermEnum termEnum = null;\n    TermDocs termDocs = null;\n    try {\n      reader = IndexReader.open(dir);\n      termCounts = new int[reader.maxDoc()];\n      // if we are killing norms, get fake ones\n      if (sim == null)\n        fakeNorms = SegmentReader.createFakeNorms(reader.maxDoc());\n      try {\n        termEnum = reader.terms(new Term(field,\"\"));\n        try {\n          termDocs = reader.termDocs();\n          do {\n            Term term = termEnum.term();\n            if (term != null && term.field().equals(fieldName)) {\n              termDocs.seek(termEnum.term());\n              while (termDocs.next()) {\n                termCounts[termDocs.doc()] += termDocs.freq();\n              }\n            }\n          } while (termEnum.next());\n          \n        } finally {\n          if (null != termDocs) termDocs.close();\n        }\n      } finally {\n        if (null != termEnum) termEnum.close();\n      }\n    } finally {\n      if (null != reader) reader.close();\n    }\n    \n    try {\n      reader = IndexReader.open(dir); \n      for (int d = 0; d < termCounts.length; d++) {\n        if (! reader.isDeleted(d)) {\n          if (sim == null)\n            reader.setNorm(d, fieldName, fakeNorms[0]);\n          else\n            reader.setNorm(d, fieldName, sim.encodeNorm(sim.lengthNorm(fieldName, termCounts[d])));\n        }\n      }\n      \n    } finally {\n      if (null != reader) reader.close();\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9d73678020862536617f065bb3d28a71d8c4020c","date":1219142439,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"contrib/miscellaneous/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","pathOld":"contrib/miscellaneous/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","sourceNew":"  /**\n   * Resets the norms for the specified field.\n   *\n   * <p>\n   * Opens a new IndexReader on the Directory given to this instance,\n   * modifies the norms (either using the Similarity given to this instance, or by using fake norms,\n   * and closes the IndexReader.\n   * </p>\n   *\n   * @param field the field whose norms should be reset\n   */\n  public void reSetNorms(String field) throws IOException {\n    String fieldName = field.intern();\n    int[] termCounts = new int[0];\n    byte[] fakeNorms = new byte[0];\n    \n    IndexReader reader = null;\n    TermEnum termEnum = null;\n    TermDocs termDocs = null;\n    try {\n      reader = IndexReader.open(dir);\n      termCounts = new int[reader.maxDoc()];\n      // if we are killing norms, get fake ones\n      if (sim == null)\n        fakeNorms = SegmentReader.createFakeNorms(reader.maxDoc());\n      try {\n        termEnum = reader.terms(new Term(field));\n        try {\n          termDocs = reader.termDocs();\n          do {\n            Term term = termEnum.term();\n            if (term != null && term.field().equals(fieldName)) {\n              termDocs.seek(termEnum.term());\n              while (termDocs.next()) {\n                termCounts[termDocs.doc()] += termDocs.freq();\n              }\n            }\n          } while (termEnum.next());\n          \n        } finally {\n          if (null != termDocs) termDocs.close();\n        }\n      } finally {\n        if (null != termEnum) termEnum.close();\n      }\n    } finally {\n      if (null != reader) reader.close();\n    }\n    \n    try {\n      reader = IndexReader.open(dir); \n      for (int d = 0; d < termCounts.length; d++) {\n        if (! reader.isDeleted(d)) {\n          if (sim == null)\n            reader.setNorm(d, fieldName, fakeNorms[0]);\n          else\n            reader.setNorm(d, fieldName, sim.encodeNorm(sim.lengthNorm(fieldName, termCounts[d])));\n        }\n      }\n      \n    } finally {\n      if (null != reader) reader.close();\n    }\n  }\n\n","sourceOld":"  /**\n   * Resets the norms for the specified field.\n   *\n   * <p>\n   * Opens a new IndexReader on the Directory given to this instance,\n   * modifies the norms (either using the Similarity given to this instance, or by using fake norms,\n   * and closes the IndexReader.\n   * </p>\n   *\n   * @param field the field whose norms should be reset\n   */\n  public void reSetNorms(String field) throws IOException {\n    String fieldName = field.intern();\n    int[] termCounts = new int[0];\n    byte[] fakeNorms = new byte[0];\n    \n    IndexReader reader = null;\n    TermEnum termEnum = null;\n    TermDocs termDocs = null;\n    try {\n      reader = IndexReader.open(dir);\n      termCounts = new int[reader.maxDoc()];\n      // if we are killing norms, get fake ones\n      if (sim == null)\n        fakeNorms = SegmentReader.createFakeNorms(reader.maxDoc());\n      try {\n        termEnum = reader.terms(new Term(field,\"\"));\n        try {\n          termDocs = reader.termDocs();\n          do {\n            Term term = termEnum.term();\n            if (term != null && term.field().equals(fieldName)) {\n              termDocs.seek(termEnum.term());\n              while (termDocs.next()) {\n                termCounts[termDocs.doc()] += termDocs.freq();\n              }\n            }\n          } while (termEnum.next());\n          \n        } finally {\n          if (null != termDocs) termDocs.close();\n        }\n      } finally {\n        if (null != termEnum) termEnum.close();\n      }\n    } finally {\n      if (null != reader) reader.close();\n    }\n    \n    try {\n      reader = IndexReader.open(dir); \n      for (int d = 0; d < termCounts.length; d++) {\n        if (! reader.isDeleted(d)) {\n          if (sim == null)\n            reader.setNorm(d, fieldName, fakeNorms[0]);\n          else\n            reader.setNorm(d, fieldName, sim.encodeNorm(sim.lengthNorm(fieldName, termCounts[d])));\n        }\n      }\n      \n    } finally {\n      if (null != reader) reader.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cf93f7a278746d4746fa3ebb3d53267b22fd040f","date":1249495506,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"contrib/miscellaneous/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","pathOld":"contrib/miscellaneous/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","sourceNew":"  /**\n   * Resets the norms for the specified field.\n   *\n   * <p>\n   * Opens a new IndexReader on the Directory given to this instance,\n   * modifies the norms (either using the Similarity given to this instance, or by using fake norms,\n   * and closes the IndexReader.\n   * </p>\n   *\n   * @param field the field whose norms should be reset\n   */\n  public void reSetNorms(String field) throws IOException {\n    String fieldName = StringHelper.intern(field);\n    int[] termCounts = new int[0];\n    byte[] fakeNorms = new byte[0];\n    \n    IndexReader reader = null;\n    TermEnum termEnum = null;\n    TermDocs termDocs = null;\n    try {\n      reader = IndexReader.open(dir);\n      termCounts = new int[reader.maxDoc()];\n      // if we are killing norms, get fake ones\n      if (sim == null)\n        fakeNorms = SegmentReader.createFakeNorms(reader.maxDoc());\n      try {\n        termEnum = reader.terms(new Term(field));\n        try {\n          termDocs = reader.termDocs();\n          do {\n            Term term = termEnum.term();\n            if (term != null && term.field().equals(fieldName)) {\n              termDocs.seek(termEnum.term());\n              while (termDocs.next()) {\n                termCounts[termDocs.doc()] += termDocs.freq();\n              }\n            }\n          } while (termEnum.next());\n          \n        } finally {\n          if (null != termDocs) termDocs.close();\n        }\n      } finally {\n        if (null != termEnum) termEnum.close();\n      }\n    } finally {\n      if (null != reader) reader.close();\n    }\n    \n    try {\n      reader = IndexReader.open(dir); \n      for (int d = 0; d < termCounts.length; d++) {\n        if (! reader.isDeleted(d)) {\n          if (sim == null)\n            reader.setNorm(d, fieldName, fakeNorms[0]);\n          else\n            reader.setNorm(d, fieldName, sim.encodeNorm(sim.lengthNorm(fieldName, termCounts[d])));\n        }\n      }\n      \n    } finally {\n      if (null != reader) reader.close();\n    }\n  }\n\n","sourceOld":"  /**\n   * Resets the norms for the specified field.\n   *\n   * <p>\n   * Opens a new IndexReader on the Directory given to this instance,\n   * modifies the norms (either using the Similarity given to this instance, or by using fake norms,\n   * and closes the IndexReader.\n   * </p>\n   *\n   * @param field the field whose norms should be reset\n   */\n  public void reSetNorms(String field) throws IOException {\n    String fieldName = field.intern();\n    int[] termCounts = new int[0];\n    byte[] fakeNorms = new byte[0];\n    \n    IndexReader reader = null;\n    TermEnum termEnum = null;\n    TermDocs termDocs = null;\n    try {\n      reader = IndexReader.open(dir);\n      termCounts = new int[reader.maxDoc()];\n      // if we are killing norms, get fake ones\n      if (sim == null)\n        fakeNorms = SegmentReader.createFakeNorms(reader.maxDoc());\n      try {\n        termEnum = reader.terms(new Term(field));\n        try {\n          termDocs = reader.termDocs();\n          do {\n            Term term = termEnum.term();\n            if (term != null && term.field().equals(fieldName)) {\n              termDocs.seek(termEnum.term());\n              while (termDocs.next()) {\n                termCounts[termDocs.doc()] += termDocs.freq();\n              }\n            }\n          } while (termEnum.next());\n          \n        } finally {\n          if (null != termDocs) termDocs.close();\n        }\n      } finally {\n        if (null != termEnum) termEnum.close();\n      }\n    } finally {\n      if (null != reader) reader.close();\n    }\n    \n    try {\n      reader = IndexReader.open(dir); \n      for (int d = 0; d < termCounts.length; d++) {\n        if (! reader.isDeleted(d)) {\n          if (sim == null)\n            reader.setNorm(d, fieldName, fakeNorms[0]);\n          else\n            reader.setNorm(d, fieldName, sim.encodeNorm(sim.lengthNorm(fieldName, termCounts[d])));\n        }\n      }\n      \n    } finally {\n      if (null != reader) reader.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"48bedd31c61edafb8baaff4bcbcac19449fb7c3a","date":1251468037,"type":5,"author":"Mark Robert Miller","isMerge":false,"pathNew":"contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","pathOld":"contrib/miscellaneous/src/java/org/apache/lucene/index/FieldNormModifier#reSetNorms(String).mjava","sourceNew":"  /**\n   * Resets the norms for the specified field.\n   *\n   * <p>\n   * Opens a new IndexReader on the Directory given to this instance,\n   * modifies the norms (either using the Similarity given to this instance, or by using fake norms,\n   * and closes the IndexReader.\n   * </p>\n   *\n   * @param field the field whose norms should be reset\n   */\n  public void reSetNorms(String field) throws IOException {\n    String fieldName = StringHelper.intern(field);\n    int[] termCounts = new int[0];\n    byte[] fakeNorms = new byte[0];\n    \n    IndexReader reader = null;\n    TermEnum termEnum = null;\n    TermDocs termDocs = null;\n    try {\n      reader = IndexReader.open(dir);\n      termCounts = new int[reader.maxDoc()];\n      // if we are killing norms, get fake ones\n      if (sim == null)\n        fakeNorms = SegmentReader.createFakeNorms(reader.maxDoc());\n      try {\n        termEnum = reader.terms(new Term(field));\n        try {\n          termDocs = reader.termDocs();\n          do {\n            Term term = termEnum.term();\n            if (term != null && term.field().equals(fieldName)) {\n              termDocs.seek(termEnum.term());\n              while (termDocs.next()) {\n                termCounts[termDocs.doc()] += termDocs.freq();\n              }\n            }\n          } while (termEnum.next());\n          \n        } finally {\n          if (null != termDocs) termDocs.close();\n        }\n      } finally {\n        if (null != termEnum) termEnum.close();\n      }\n    } finally {\n      if (null != reader) reader.close();\n    }\n    \n    try {\n      reader = IndexReader.open(dir); \n      for (int d = 0; d < termCounts.length; d++) {\n        if (! reader.isDeleted(d)) {\n          if (sim == null)\n            reader.setNorm(d, fieldName, fakeNorms[0]);\n          else\n            reader.setNorm(d, fieldName, sim.encodeNorm(sim.lengthNorm(fieldName, termCounts[d])));\n        }\n      }\n      \n    } finally {\n      if (null != reader) reader.close();\n    }\n  }\n\n","sourceOld":"  /**\n   * Resets the norms for the specified field.\n   *\n   * <p>\n   * Opens a new IndexReader on the Directory given to this instance,\n   * modifies the norms (either using the Similarity given to this instance, or by using fake norms,\n   * and closes the IndexReader.\n   * </p>\n   *\n   * @param field the field whose norms should be reset\n   */\n  public void reSetNorms(String field) throws IOException {\n    String fieldName = StringHelper.intern(field);\n    int[] termCounts = new int[0];\n    byte[] fakeNorms = new byte[0];\n    \n    IndexReader reader = null;\n    TermEnum termEnum = null;\n    TermDocs termDocs = null;\n    try {\n      reader = IndexReader.open(dir);\n      termCounts = new int[reader.maxDoc()];\n      // if we are killing norms, get fake ones\n      if (sim == null)\n        fakeNorms = SegmentReader.createFakeNorms(reader.maxDoc());\n      try {\n        termEnum = reader.terms(new Term(field));\n        try {\n          termDocs = reader.termDocs();\n          do {\n            Term term = termEnum.term();\n            if (term != null && term.field().equals(fieldName)) {\n              termDocs.seek(termEnum.term());\n              while (termDocs.next()) {\n                termCounts[termDocs.doc()] += termDocs.freq();\n              }\n            }\n          } while (termEnum.next());\n          \n        } finally {\n          if (null != termDocs) termDocs.close();\n        }\n      } finally {\n        if (null != termEnum) termEnum.close();\n      }\n    } finally {\n      if (null != reader) reader.close();\n    }\n    \n    try {\n      reader = IndexReader.open(dir); \n      for (int d = 0; d < termCounts.length; d++) {\n        if (! reader.isDeleted(d)) {\n          if (sim == null)\n            reader.setNorm(d, fieldName, fakeNorms[0]);\n          else\n            reader.setNorm(d, fieldName, sim.encodeNorm(sim.lengthNorm(fieldName, termCounts[d])));\n        }\n      }\n      \n    } finally {\n      if (null != reader) reader.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"cf93f7a278746d4746fa3ebb3d53267b22fd040f":["9d73678020862536617f065bb3d28a71d8c4020c"],"7ae36bc5dae83f94e7da6e03d7f3b14ea175af4c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"48bedd31c61edafb8baaff4bcbcac19449fb7c3a":["cf93f7a278746d4746fa3ebb3d53267b22fd040f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["48bedd31c61edafb8baaff4bcbcac19449fb7c3a"],"9d73678020862536617f065bb3d28a71d8c4020c":["7ae36bc5dae83f94e7da6e03d7f3b14ea175af4c"]},"commit2Childs":{"cf93f7a278746d4746fa3ebb3d53267b22fd040f":["48bedd31c61edafb8baaff4bcbcac19449fb7c3a"],"7ae36bc5dae83f94e7da6e03d7f3b14ea175af4c":["9d73678020862536617f065bb3d28a71d8c4020c"],"48bedd31c61edafb8baaff4bcbcac19449fb7c3a":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["7ae36bc5dae83f94e7da6e03d7f3b14ea175af4c"],"9d73678020862536617f065bb3d28a71d8c4020c":["cf93f7a278746d4746fa3ebb3d53267b22fd040f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}