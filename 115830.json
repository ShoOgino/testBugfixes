{"path":"lucene/src/java/org/apache/lucene/index/codecs/standard/StandardTermsDictReader#StandardTermsDictReader(StandardTermsIndexReader,Directory,FieldInfos,String,StandardPostingsReader,int,Comparator[BytesRef],int).mjava","commits":[{"id":"955c32f886db6f6356c9fcdea6b1f1cb4effda24","date":1270581567,"type":0,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/standard/StandardTermsDictReader#StandardTermsDictReader(StandardTermsIndexReader,Directory,FieldInfos,String,StandardPostingsReader,int,Comparator[BytesRef],int).mjava","pathOld":"/dev/null","sourceNew":"  public StandardTermsDictReader(StandardTermsIndexReader indexReader, Directory dir, FieldInfos fieldInfos, String segment, StandardPostingsReader postingsReader, int readBufferSize,\n                                 Comparator<BytesRef> termComp, int termsCacheSize)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n    termsCache = new DoubleBarrelLRUCache<FieldAndTerm,TermState>(termsCacheSize);\n\n    this.termComp = termComp;\n    \n    in = dir.openInput(IndexFileNames.segmentFileName(segment, StandardCodec.TERMS_EXTENSION),\n                       readBufferSize);\n\n    boolean success = false;\n    try {\n      CodecUtil.checkHeader(in, StandardTermsDictWriter.CODEC_NAME, StandardTermsDictWriter.VERSION_CURRENT);\n\n      final long dirOffset = in.readLong();\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      in.seek(dirOffset);\n\n      final int numFields = in.readInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readInt();\n        final long numTerms = in.readLong();\n        assert numTerms >= 0;\n        final long termsStartPointer = in.readLong();\n        final StandardTermsIndexReader.FieldReader fieldIndexReader;\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        fieldIndexReader = indexReader.getField(fieldInfo);\n        if (numTerms > 0) {\n          assert !fields.containsKey(fieldInfo.name);\n          fields.put(fieldInfo.name, new FieldReader(fieldIndexReader, fieldInfo, numTerms, termsStartPointer));\n        }\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        in.close();\n      }\n    }\n\n    this.indexReader = indexReader;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fb10b6bcde550b87d8f10e5f010bd8f3021023b6","date":1274974592,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/standard/StandardTermsDictReader#StandardTermsDictReader(StandardTermsIndexReader,Directory,FieldInfos,String,StandardPostingsReader,int,Comparator[BytesRef],int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/standard/StandardTermsDictReader#StandardTermsDictReader(StandardTermsIndexReader,Directory,FieldInfos,String,StandardPostingsReader,int,Comparator[BytesRef],int).mjava","sourceNew":"  public StandardTermsDictReader(StandardTermsIndexReader indexReader, Directory dir, FieldInfos fieldInfos, String segment, StandardPostingsReader postingsReader, int readBufferSize,\n                                 Comparator<BytesRef> termComp, int termsCacheSize)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n    termsCache = new DoubleBarrelLRUCache<FieldAndTerm,TermState>(termsCacheSize);\n\n    this.termComp = termComp;\n    \n    in = dir.openInput(IndexFileNames.segmentFileName(segment, \"\", StandardCodec.TERMS_EXTENSION),\n                       readBufferSize);\n\n    boolean success = false;\n    try {\n      CodecUtil.checkHeader(in, StandardTermsDictWriter.CODEC_NAME, StandardTermsDictWriter.VERSION_CURRENT);\n\n      final long dirOffset = in.readLong();\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      in.seek(dirOffset);\n\n      final int numFields = in.readInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readInt();\n        final long numTerms = in.readLong();\n        assert numTerms >= 0;\n        final long termsStartPointer = in.readLong();\n        final StandardTermsIndexReader.FieldReader fieldIndexReader;\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        fieldIndexReader = indexReader.getField(fieldInfo);\n        if (numTerms > 0) {\n          assert !fields.containsKey(fieldInfo.name);\n          fields.put(fieldInfo.name, new FieldReader(fieldIndexReader, fieldInfo, numTerms, termsStartPointer));\n        }\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        in.close();\n      }\n    }\n\n    this.indexReader = indexReader;\n  }\n\n","sourceOld":"  public StandardTermsDictReader(StandardTermsIndexReader indexReader, Directory dir, FieldInfos fieldInfos, String segment, StandardPostingsReader postingsReader, int readBufferSize,\n                                 Comparator<BytesRef> termComp, int termsCacheSize)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n    termsCache = new DoubleBarrelLRUCache<FieldAndTerm,TermState>(termsCacheSize);\n\n    this.termComp = termComp;\n    \n    in = dir.openInput(IndexFileNames.segmentFileName(segment, StandardCodec.TERMS_EXTENSION),\n                       readBufferSize);\n\n    boolean success = false;\n    try {\n      CodecUtil.checkHeader(in, StandardTermsDictWriter.CODEC_NAME, StandardTermsDictWriter.VERSION_CURRENT);\n\n      final long dirOffset = in.readLong();\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      in.seek(dirOffset);\n\n      final int numFields = in.readInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readInt();\n        final long numTerms = in.readLong();\n        assert numTerms >= 0;\n        final long termsStartPointer = in.readLong();\n        final StandardTermsIndexReader.FieldReader fieldIndexReader;\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        fieldIndexReader = indexReader.getField(fieldInfo);\n        if (numTerms > 0) {\n          assert !fields.containsKey(fieldInfo.name);\n          fields.put(fieldInfo.name, new FieldReader(fieldIndexReader, fieldInfo, numTerms, termsStartPointer));\n        }\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        in.close();\n      }\n    }\n\n    this.indexReader = indexReader;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6066dbe072ec5334ff5824f474e9d3abd1620fb7","date":1278709584,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/standard/StandardTermsDictReader#StandardTermsDictReader(StandardTermsIndexReader,Directory,FieldInfos,String,StandardPostingsReader,int,Comparator[BytesRef],int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/standard/StandardTermsDictReader#StandardTermsDictReader(StandardTermsIndexReader,Directory,FieldInfos,String,StandardPostingsReader,int,Comparator[BytesRef],int).mjava","sourceNew":"  public StandardTermsDictReader(StandardTermsIndexReader indexReader, Directory dir, FieldInfos fieldInfos, String segment, StandardPostingsReader postingsReader, int readBufferSize,\n                                 Comparator<BytesRef> termComp, int termsCacheSize)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n    termsCache = new DoubleBarrelLRUCache<FieldAndTerm,TermState>(termsCacheSize);\n\n    this.termComp = termComp;\n    \n    in = dir.openInput(IndexFileNames.segmentFileName(segment, \"\", StandardCodec.TERMS_EXTENSION),\n                       readBufferSize);\n\n    boolean success = false;\n    try {\n      readHeader(in);\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n\n      final int numFields = in.readInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readInt();\n        final long numTerms = in.readLong();\n        assert numTerms >= 0;\n        final long termsStartPointer = in.readLong();\n        final StandardTermsIndexReader.FieldReader fieldIndexReader;\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        fieldIndexReader = indexReader.getField(fieldInfo);\n        if (numTerms > 0) {\n          assert !fields.containsKey(fieldInfo.name);\n          fields.put(fieldInfo.name, new FieldReader(fieldIndexReader, fieldInfo, numTerms, termsStartPointer));\n        }\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        in.close();\n      }\n    }\n\n    this.indexReader = indexReader;\n  }\n\n","sourceOld":"  public StandardTermsDictReader(StandardTermsIndexReader indexReader, Directory dir, FieldInfos fieldInfos, String segment, StandardPostingsReader postingsReader, int readBufferSize,\n                                 Comparator<BytesRef> termComp, int termsCacheSize)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n    termsCache = new DoubleBarrelLRUCache<FieldAndTerm,TermState>(termsCacheSize);\n\n    this.termComp = termComp;\n    \n    in = dir.openInput(IndexFileNames.segmentFileName(segment, \"\", StandardCodec.TERMS_EXTENSION),\n                       readBufferSize);\n\n    boolean success = false;\n    try {\n      CodecUtil.checkHeader(in, StandardTermsDictWriter.CODEC_NAME, StandardTermsDictWriter.VERSION_CURRENT);\n\n      final long dirOffset = in.readLong();\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      in.seek(dirOffset);\n\n      final int numFields = in.readInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readInt();\n        final long numTerms = in.readLong();\n        assert numTerms >= 0;\n        final long termsStartPointer = in.readLong();\n        final StandardTermsIndexReader.FieldReader fieldIndexReader;\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        fieldIndexReader = indexReader.getField(fieldInfo);\n        if (numTerms > 0) {\n          assert !fields.containsKey(fieldInfo.name);\n          fields.put(fieldInfo.name, new FieldReader(fieldIndexReader, fieldInfo, numTerms, termsStartPointer));\n        }\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        in.close();\n      }\n    }\n\n    this.indexReader = indexReader;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5f4e87790277826a2aea119328600dfb07761f32","date":1279827275,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/standard/StandardTermsDictReader#StandardTermsDictReader(StandardTermsIndexReader,Directory,FieldInfos,String,StandardPostingsReader,int,Comparator[BytesRef],int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/standard/StandardTermsDictReader#StandardTermsDictReader(StandardTermsIndexReader,Directory,FieldInfos,String,StandardPostingsReader,int,Comparator[BytesRef],int).mjava","sourceNew":"  public StandardTermsDictReader(StandardTermsIndexReader indexReader, Directory dir, FieldInfos fieldInfos, String segment, StandardPostingsReader postingsReader, int readBufferSize,\n                                 Comparator<BytesRef> termComp, int termsCacheSize)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n    termsCache = new DoubleBarrelLRUCache<FieldAndTerm,TermState>(termsCacheSize);\n\n    this.termComp = termComp;\n    \n    in = dir.openInput(IndexFileNames.segmentFileName(segment, \"\", StandardCodec.TERMS_EXTENSION),\n                       readBufferSize);\n\n    boolean success = false;\n    try {\n      readHeader(in);\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n\n      final int numFields = in.readInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readInt();\n        final long numTerms = in.readLong();\n        assert numTerms >= 0;\n        final long termsStartPointer = in.readLong();\n        final StandardTermsIndexReader.FieldReader fieldIndexReader;\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        fieldIndexReader = indexReader.getField(fieldInfo);\n        if (numTerms > 0) {\n          assert !fields.containsKey(fieldInfo.name);\n          fields.put(fieldInfo.name, new FieldReader(fieldIndexReader, fieldInfo, numTerms, termsStartPointer));\n        }\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        in.close();\n      }\n    }\n\n    this.indexReader = indexReader;\n  }\n\n","sourceOld":"  public StandardTermsDictReader(StandardTermsIndexReader indexReader, Directory dir, FieldInfos fieldInfos, String segment, StandardPostingsReader postingsReader, int readBufferSize,\n                                 Comparator<BytesRef> termComp, int termsCacheSize)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n    termsCache = new DoubleBarrelLRUCache<FieldAndTerm,TermState>(termsCacheSize);\n\n    this.termComp = termComp;\n    \n    in = dir.openInput(IndexFileNames.segmentFileName(segment, \"\", StandardCodec.TERMS_EXTENSION),\n                       readBufferSize);\n\n    boolean success = false;\n    try {\n      CodecUtil.checkHeader(in, StandardTermsDictWriter.CODEC_NAME, StandardTermsDictWriter.VERSION_CURRENT);\n\n      final long dirOffset = in.readLong();\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      in.seek(dirOffset);\n\n      final int numFields = in.readInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readInt();\n        final long numTerms = in.readLong();\n        assert numTerms >= 0;\n        final long termsStartPointer = in.readLong();\n        final StandardTermsIndexReader.FieldReader fieldIndexReader;\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        fieldIndexReader = indexReader.getField(fieldInfo);\n        if (numTerms > 0) {\n          assert !fields.containsKey(fieldInfo.name);\n          fields.put(fieldInfo.name, new FieldReader(fieldIndexReader, fieldInfo, numTerms, termsStartPointer));\n        }\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        in.close();\n      }\n    }\n\n    this.indexReader = indexReader;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"99cf56f3a650b908f7017a72f9d23940418f8a52","date":1284891529,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/PrefixCodedTermsReader#PrefixCodedTermsReader(TermsIndexReaderBase,Directory,FieldInfos,String,PostingsReaderBase,int,Comparator[BytesRef],int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/standard/StandardTermsDictReader#StandardTermsDictReader(StandardTermsIndexReader,Directory,FieldInfos,String,StandardPostingsReader,int,Comparator[BytesRef],int).mjava","sourceNew":"  public PrefixCodedTermsReader(TermsIndexReaderBase indexReader, Directory dir, FieldInfos fieldInfos, String segment, PostingsReaderBase postingsReader, int readBufferSize,\n                                 Comparator<BytesRef> termComp, int termsCacheSize)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n    termsCache = new DoubleBarrelLRUCache<FieldAndTerm,TermState>(termsCacheSize);\n\n    this.termComp = termComp;\n    \n    in = dir.openInput(IndexFileNames.segmentFileName(segment, \"\", PrefixCodedTermsWriter.TERMS_EXTENSION),\n                       readBufferSize);\n\n    boolean success = false;\n    try {\n      readHeader(in);\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n\n      final int numFields = in.readInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readInt();\n        final long numTerms = in.readLong();\n        assert numTerms >= 0;\n        final long termsStartPointer = in.readLong();\n        final TermsIndexReaderBase.FieldReader fieldIndexReader;\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        fieldIndexReader = indexReader.getField(fieldInfo);\n        if (numTerms > 0) {\n          assert !fields.containsKey(fieldInfo.name);\n          fields.put(fieldInfo.name, new FieldReader(fieldIndexReader, fieldInfo, numTerms, termsStartPointer));\n        }\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        in.close();\n      }\n    }\n\n    this.indexReader = indexReader;\n  }\n\n","sourceOld":"  public StandardTermsDictReader(StandardTermsIndexReader indexReader, Directory dir, FieldInfos fieldInfos, String segment, StandardPostingsReader postingsReader, int readBufferSize,\n                                 Comparator<BytesRef> termComp, int termsCacheSize)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n    termsCache = new DoubleBarrelLRUCache<FieldAndTerm,TermState>(termsCacheSize);\n\n    this.termComp = termComp;\n    \n    in = dir.openInput(IndexFileNames.segmentFileName(segment, \"\", StandardCodec.TERMS_EXTENSION),\n                       readBufferSize);\n\n    boolean success = false;\n    try {\n      readHeader(in);\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n\n      final int numFields = in.readInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readInt();\n        final long numTerms = in.readLong();\n        assert numTerms >= 0;\n        final long termsStartPointer = in.readLong();\n        final StandardTermsIndexReader.FieldReader fieldIndexReader;\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        fieldIndexReader = indexReader.getField(fieldInfo);\n        if (numTerms > 0) {\n          assert !fields.containsKey(fieldInfo.name);\n          fields.put(fieldInfo.name, new FieldReader(fieldIndexReader, fieldInfo, numTerms, termsStartPointer));\n        }\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        in.close();\n      }\n    }\n\n    this.indexReader = indexReader;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":4,"author":"Michael Busch","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/standard/StandardTermsDictReader#StandardTermsDictReader(StandardTermsIndexReader,Directory,FieldInfos,String,StandardPostingsReader,int,Comparator[BytesRef],int).mjava","sourceNew":null,"sourceOld":"  public StandardTermsDictReader(StandardTermsIndexReader indexReader, Directory dir, FieldInfos fieldInfos, String segment, StandardPostingsReader postingsReader, int readBufferSize,\n                                 Comparator<BytesRef> termComp, int termsCacheSize)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n    termsCache = new DoubleBarrelLRUCache<FieldAndTerm,TermState>(termsCacheSize);\n\n    this.termComp = termComp;\n    \n    in = dir.openInput(IndexFileNames.segmentFileName(segment, \"\", StandardCodec.TERMS_EXTENSION),\n                       readBufferSize);\n\n    boolean success = false;\n    try {\n      readHeader(in);\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n\n      final int numFields = in.readInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readInt();\n        final long numTerms = in.readLong();\n        assert numTerms >= 0;\n        final long termsStartPointer = in.readLong();\n        final StandardTermsIndexReader.FieldReader fieldIndexReader;\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        fieldIndexReader = indexReader.getField(fieldInfo);\n        if (numTerms > 0) {\n          assert !fields.containsKey(fieldInfo.name);\n          fields.put(fieldInfo.name, new FieldReader(fieldIndexReader, fieldInfo, numTerms, termsStartPointer));\n        }\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        in.close();\n      }\n    }\n\n    this.indexReader = indexReader;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"6066dbe072ec5334ff5824f474e9d3abd1620fb7":["fb10b6bcde550b87d8f10e5f010bd8f3021023b6"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"955c32f886db6f6356c9fcdea6b1f1cb4effda24":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"5f4e87790277826a2aea119328600dfb07761f32":["fb10b6bcde550b87d8f10e5f010bd8f3021023b6","6066dbe072ec5334ff5824f474e9d3abd1620fb7"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["5f4e87790277826a2aea119328600dfb07761f32","99cf56f3a650b908f7017a72f9d23940418f8a52"],"99cf56f3a650b908f7017a72f9d23940418f8a52":["6066dbe072ec5334ff5824f474e9d3abd1620fb7"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["99cf56f3a650b908f7017a72f9d23940418f8a52"],"fb10b6bcde550b87d8f10e5f010bd8f3021023b6":["955c32f886db6f6356c9fcdea6b1f1cb4effda24"]},"commit2Childs":{"6066dbe072ec5334ff5824f474e9d3abd1620fb7":["5f4e87790277826a2aea119328600dfb07761f32","99cf56f3a650b908f7017a72f9d23940418f8a52"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["955c32f886db6f6356c9fcdea6b1f1cb4effda24"],"955c32f886db6f6356c9fcdea6b1f1cb4effda24":["fb10b6bcde550b87d8f10e5f010bd8f3021023b6"],"5f4e87790277826a2aea119328600dfb07761f32":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":[],"99cf56f3a650b908f7017a72f9d23940418f8a52":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"fb10b6bcde550b87d8f10e5f010bd8f3021023b6":["6066dbe072ec5334ff5824f474e9d3abd1620fb7","5f4e87790277826a2aea119328600dfb07761f32"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}