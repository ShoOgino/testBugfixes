{"path":"src/java/org/apache/lucene/analysis/KeywordTokenizer#incrementToken().mjava","commits":[{"id":"74a5e7f20b4a444da9df3b2c0f331fa7a1f64223","date":1227051709,"type":0,"author":"Michael Busch","isMerge":false,"pathNew":"src/java/org/apache/lucene/analysis/KeywordTokenizer#incrementToken().mjava","pathOld":"/dev/null","sourceNew":"  public boolean incrementToken() throws IOException {\n    if (!done) {\n      done = true;\n      int upto = 0;\n      termAtt.clear();\n      char[] buffer = termAtt.termBuffer();\n      while (true) {\n        final int length = input.read(buffer, upto, buffer.length-upto);\n        if (length == -1) break;\n        upto += length;\n        if (upto == buffer.length)\n          buffer = termAtt.resizeTermBuffer(1+buffer.length);\n      }\n      termAtt.setTermLength(upto);\n      offsetAtt.setStartOffset(0);\n      offsetAtt.setEndOffset(upto);\n      return true;\n    }\n    return false;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"10855b393afd8884613d82de3a4fff773d4e5334","date":1240953458,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/analysis/KeywordTokenizer#incrementToken().mjava","pathOld":"src/java/org/apache/lucene/analysis/KeywordTokenizer#incrementToken().mjava","sourceNew":"  public boolean incrementToken() throws IOException {\n    if (!done) {\n      done = true;\n      int upto = 0;\n      termAtt.clear();\n      char[] buffer = termAtt.termBuffer();\n      while (true) {\n        final int length = input.read(buffer, upto, buffer.length-upto);\n        if (length == -1) break;\n        upto += length;\n        if (upto == buffer.length)\n          buffer = termAtt.resizeTermBuffer(1+buffer.length);\n      }\n      termAtt.setTermLength(upto);\n      offsetAtt.setOffset(0, upto);\n      return true;\n    }\n    return false;\n  }\n\n","sourceOld":"  public boolean incrementToken() throws IOException {\n    if (!done) {\n      done = true;\n      int upto = 0;\n      termAtt.clear();\n      char[] buffer = termAtt.termBuffer();\n      while (true) {\n        final int length = input.read(buffer, upto, buffer.length-upto);\n        if (length == -1) break;\n        upto += length;\n        if (upto == buffer.length)\n          buffer = termAtt.resizeTermBuffer(1+buffer.length);\n      }\n      termAtt.setTermLength(upto);\n      offsetAtt.setStartOffset(0);\n      offsetAtt.setEndOffset(upto);\n      return true;\n    }\n    return false;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cd27af5c226d98a7c6378c388a67a3bff7c0b3a2","date":1245784531,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/analysis/KeywordTokenizer#incrementToken().mjava","pathOld":"src/java/org/apache/lucene/analysis/KeywordTokenizer#incrementToken().mjava","sourceNew":"  public boolean incrementToken() throws IOException {\n    if (!done) {\n      done = true;\n      int upto = 0;\n      termAtt.clear();\n      char[] buffer = termAtt.termBuffer();\n      while (true) {\n        final int length = input.read(buffer, upto, buffer.length-upto);\n        if (length == -1) break;\n        upto += length;\n        if (upto == buffer.length)\n          buffer = termAtt.resizeTermBuffer(1+buffer.length);\n      }\n      termAtt.setTermLength(upto);\n      offsetAtt.setOffset(input.correctOffset(0), input.correctOffset(upto));\n      return true;\n    }\n    return false;\n  }\n\n","sourceOld":"  public boolean incrementToken() throws IOException {\n    if (!done) {\n      done = true;\n      int upto = 0;\n      termAtt.clear();\n      char[] buffer = termAtt.termBuffer();\n      while (true) {\n        final int length = input.read(buffer, upto, buffer.length-upto);\n        if (length == -1) break;\n        upto += length;\n        if (upto == buffer.length)\n          buffer = termAtt.resizeTermBuffer(1+buffer.length);\n      }\n      termAtt.setTermLength(upto);\n      offsetAtt.setOffset(0, upto);\n      return true;\n    }\n    return false;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ec8b5a20a12931b8d7e616c79c5248ae06cc5568","date":1248471948,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"src/java/org/apache/lucene/analysis/KeywordTokenizer#incrementToken().mjava","pathOld":"src/java/org/apache/lucene/analysis/KeywordTokenizer#incrementToken().mjava","sourceNew":"  public final boolean incrementToken() throws IOException {\n    if (!done) {\n      done = true;\n      int upto = 0;\n      termAtt.clear();\n      char[] buffer = termAtt.termBuffer();\n      while (true) {\n        final int length = input.read(buffer, upto, buffer.length-upto);\n        if (length == -1) break;\n        upto += length;\n        if (upto == buffer.length)\n          buffer = termAtt.resizeTermBuffer(1+buffer.length);\n      }\n      termAtt.setTermLength(upto);\n      offsetAtt.setOffset(input.correctOffset(0), input.correctOffset(upto));\n      return true;\n    }\n    return false;\n  }\n\n","sourceOld":"  public boolean incrementToken() throws IOException {\n    if (!done) {\n      done = true;\n      int upto = 0;\n      termAtt.clear();\n      char[] buffer = termAtt.termBuffer();\n      while (true) {\n        final int length = input.read(buffer, upto, buffer.length-upto);\n        if (length == -1) break;\n        upto += length;\n        if (upto == buffer.length)\n          buffer = termAtt.resizeTermBuffer(1+buffer.length);\n      }\n      termAtt.setTermLength(upto);\n      offsetAtt.setOffset(input.correctOffset(0), input.correctOffset(upto));\n      return true;\n    }\n    return false;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"457c790b0d3d5883da64fb842ea54813004bb796","date":1248495093,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"src/java/org/apache/lucene/analysis/KeywordTokenizer#incrementToken().mjava","pathOld":"src/java/org/apache/lucene/analysis/KeywordTokenizer#incrementToken().mjava","sourceNew":"  public final boolean incrementToken() throws IOException {\n    if (!done) {\n      done = true;\n      int upto = 0;\n      termAtt.clear();\n      char[] buffer = termAtt.termBuffer();\n      while (true) {\n        final int length = input.read(buffer, upto, buffer.length-upto);\n        if (length == -1) break;\n        upto += length;\n        if (upto == buffer.length)\n          buffer = termAtt.resizeTermBuffer(1+buffer.length);\n      }\n      termAtt.setTermLength(upto);\n      finalOffset = input.correctOffset(upto);\n      offsetAtt.setOffset(input.correctOffset(0), finalOffset);\n      return true;\n    }\n    return false;\n  }\n\n","sourceOld":"  public final boolean incrementToken() throws IOException {\n    if (!done) {\n      done = true;\n      int upto = 0;\n      termAtt.clear();\n      char[] buffer = termAtt.termBuffer();\n      while (true) {\n        final int length = input.read(buffer, upto, buffer.length-upto);\n        if (length == -1) break;\n        upto += length;\n        if (upto == buffer.length)\n          buffer = termAtt.resizeTermBuffer(1+buffer.length);\n      }\n      termAtt.setTermLength(upto);\n      offsetAtt.setOffset(input.correctOffset(0), input.correctOffset(upto));\n      return true;\n    }\n    return false;\n  }\n\n","bugFix":null,"bugIntro":["a82fda1447250ff156ff3b862d94a99bf0a3c23c"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0833fee1ce16a2b8e10f21cbccd2e93f3d8ccf31","date":1249940086,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/java/org/apache/lucene/analysis/KeywordTokenizer#incrementToken().mjava","pathOld":"src/java/org/apache/lucene/analysis/KeywordTokenizer#incrementToken().mjava","sourceNew":"  public final boolean incrementToken() throws IOException {\n    if (!done) {\n      done = true;\n      int upto = 0;\n      char[] buffer = termAtt.termBuffer();\n      while (true) {\n        final int length = input.read(buffer, upto, buffer.length-upto);\n        if (length == -1) break;\n        upto += length;\n        if (upto == buffer.length)\n          buffer = termAtt.resizeTermBuffer(1+buffer.length);\n      }\n      termAtt.setTermLength(upto);\n      finalOffset = input.correctOffset(upto);\n      offsetAtt.setOffset(input.correctOffset(0), finalOffset);\n      return true;\n    }\n    return false;\n  }\n\n","sourceOld":"  public final boolean incrementToken() throws IOException {\n    if (!done) {\n      done = true;\n      int upto = 0;\n      termAtt.clear();\n      char[] buffer = termAtt.termBuffer();\n      while (true) {\n        final int length = input.read(buffer, upto, buffer.length-upto);\n        if (length == -1) break;\n        upto += length;\n        if (upto == buffer.length)\n          buffer = termAtt.resizeTermBuffer(1+buffer.length);\n      }\n      termAtt.setTermLength(upto);\n      finalOffset = input.correctOffset(upto);\n      offsetAtt.setOffset(input.correctOffset(0), finalOffset);\n      return true;\n    }\n    return false;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"91d0e16ae1a83f5658ad4d16453fb88650460140","date":1250287302,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/java/org/apache/lucene/analysis/KeywordTokenizer#incrementToken().mjava","pathOld":"src/java/org/apache/lucene/analysis/KeywordTokenizer#incrementToken().mjava","sourceNew":"  public final boolean incrementToken() throws IOException {\n    if (!done) {\n      clearAttributes();\n      done = true;\n      int upto = 0;\n      char[] buffer = termAtt.termBuffer();\n      while (true) {\n        final int length = input.read(buffer, upto, buffer.length-upto);\n        if (length == -1) break;\n        upto += length;\n        if (upto == buffer.length)\n          buffer = termAtt.resizeTermBuffer(1+buffer.length);\n      }\n      termAtt.setTermLength(upto);\n      finalOffset = input.correctOffset(upto);\n      offsetAtt.setOffset(input.correctOffset(0), finalOffset);\n      return true;\n    }\n    return false;\n  }\n\n","sourceOld":"  public final boolean incrementToken() throws IOException {\n    if (!done) {\n      done = true;\n      int upto = 0;\n      char[] buffer = termAtt.termBuffer();\n      while (true) {\n        final int length = input.read(buffer, upto, buffer.length-upto);\n        if (length == -1) break;\n        upto += length;\n        if (upto == buffer.length)\n          buffer = termAtt.resizeTermBuffer(1+buffer.length);\n      }\n      termAtt.setTermLength(upto);\n      finalOffset = input.correctOffset(upto);\n      offsetAtt.setOffset(input.correctOffset(0), finalOffset);\n      return true;\n    }\n    return false;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a82fda1447250ff156ff3b862d94a99bf0a3c23c","date":1252649533,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/java/org/apache/lucene/analysis/KeywordTokenizer#incrementToken().mjava","pathOld":"src/java/org/apache/lucene/analysis/KeywordTokenizer#incrementToken().mjava","sourceNew":"  public final boolean incrementToken() throws IOException {\n    if (!done) {\n      clearAttributes();\n      done = true;\n      int upto = 0;\n      char[] buffer = termAtt.termBuffer();\n      while (true) {\n        final int length = input.read(buffer, upto, buffer.length-upto);\n        if (length == -1) break;\n        upto += length;\n        if (upto == buffer.length)\n          buffer = termAtt.resizeTermBuffer(1+buffer.length);\n      }\n      termAtt.setTermLength(upto);\n      finalOffset = correctOffset(upto);\n      offsetAtt.setOffset(correctOffset(0), finalOffset);\n      return true;\n    }\n    return false;\n  }\n\n","sourceOld":"  public final boolean incrementToken() throws IOException {\n    if (!done) {\n      clearAttributes();\n      done = true;\n      int upto = 0;\n      char[] buffer = termAtt.termBuffer();\n      while (true) {\n        final int length = input.read(buffer, upto, buffer.length-upto);\n        if (length == -1) break;\n        upto += length;\n        if (upto == buffer.length)\n          buffer = termAtt.resizeTermBuffer(1+buffer.length);\n      }\n      termAtt.setTermLength(upto);\n      finalOffset = input.correctOffset(upto);\n      offsetAtt.setOffset(input.correctOffset(0), finalOffset);\n      return true;\n    }\n    return false;\n  }\n\n","bugFix":["457c790b0d3d5883da64fb842ea54813004bb796"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8a9e385641d717e641408d8fbbc62be8fc766357","date":1256746606,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/java/org/apache/lucene/analysis/KeywordTokenizer#incrementToken().mjava","pathOld":"src/java/org/apache/lucene/analysis/KeywordTokenizer#incrementToken().mjava","sourceNew":"  @Override\n  public final boolean incrementToken() throws IOException {\n    if (!done) {\n      clearAttributes();\n      done = true;\n      int upto = 0;\n      char[] buffer = termAtt.termBuffer();\n      while (true) {\n        final int length = input.read(buffer, upto, buffer.length-upto);\n        if (length == -1) break;\n        upto += length;\n        if (upto == buffer.length)\n          buffer = termAtt.resizeTermBuffer(1+buffer.length);\n      }\n      termAtt.setTermLength(upto);\n      finalOffset = correctOffset(upto);\n      offsetAtt.setOffset(correctOffset(0), finalOffset);\n      return true;\n    }\n    return false;\n  }\n\n","sourceOld":"  public final boolean incrementToken() throws IOException {\n    if (!done) {\n      clearAttributes();\n      done = true;\n      int upto = 0;\n      char[] buffer = termAtt.termBuffer();\n      while (true) {\n        final int length = input.read(buffer, upto, buffer.length-upto);\n        if (length == -1) break;\n        upto += length;\n        if (upto == buffer.length)\n          buffer = termAtt.resizeTermBuffer(1+buffer.length);\n      }\n      termAtt.setTermLength(upto);\n      finalOffset = correctOffset(upto);\n      offsetAtt.setOffset(correctOffset(0), finalOffset);\n      return true;\n    }\n    return false;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":4,"author":"Dawid Weiss","isMerge":false,"pathNew":"/dev/null","pathOld":"src/java/org/apache/lucene/analysis/KeywordTokenizer#incrementToken().mjava","sourceNew":null,"sourceOld":"  @Override\n  public final boolean incrementToken() throws IOException {\n    if (!done) {\n      clearAttributes();\n      done = true;\n      int upto = 0;\n      char[] buffer = termAtt.termBuffer();\n      while (true) {\n        final int length = input.read(buffer, upto, buffer.length-upto);\n        if (length == -1) break;\n        upto += length;\n        if (upto == buffer.length)\n          buffer = termAtt.resizeTermBuffer(1+buffer.length);\n      }\n      termAtt.setTermLength(upto);\n      finalOffset = correctOffset(upto);\n      offsetAtt.setOffset(correctOffset(0), finalOffset);\n      return true;\n    }\n    return false;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a82fda1447250ff156ff3b862d94a99bf0a3c23c":["91d0e16ae1a83f5658ad4d16453fb88650460140"],"457c790b0d3d5883da64fb842ea54813004bb796":["ec8b5a20a12931b8d7e616c79c5248ae06cc5568"],"74a5e7f20b4a444da9df3b2c0f331fa7a1f64223":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"91d0e16ae1a83f5658ad4d16453fb88650460140":["0833fee1ce16a2b8e10f21cbccd2e93f3d8ccf31"],"8a9e385641d717e641408d8fbbc62be8fc766357":["a82fda1447250ff156ff3b862d94a99bf0a3c23c"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"10855b393afd8884613d82de3a4fff773d4e5334":["74a5e7f20b4a444da9df3b2c0f331fa7a1f64223"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["8a9e385641d717e641408d8fbbc62be8fc766357"],"0833fee1ce16a2b8e10f21cbccd2e93f3d8ccf31":["457c790b0d3d5883da64fb842ea54813004bb796"],"ec8b5a20a12931b8d7e616c79c5248ae06cc5568":["cd27af5c226d98a7c6378c388a67a3bff7c0b3a2"],"cd27af5c226d98a7c6378c388a67a3bff7c0b3a2":["10855b393afd8884613d82de3a4fff773d4e5334"]},"commit2Childs":{"a82fda1447250ff156ff3b862d94a99bf0a3c23c":["8a9e385641d717e641408d8fbbc62be8fc766357"],"457c790b0d3d5883da64fb842ea54813004bb796":["0833fee1ce16a2b8e10f21cbccd2e93f3d8ccf31"],"74a5e7f20b4a444da9df3b2c0f331fa7a1f64223":["10855b393afd8884613d82de3a4fff773d4e5334"],"91d0e16ae1a83f5658ad4d16453fb88650460140":["a82fda1447250ff156ff3b862d94a99bf0a3c23c"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["74a5e7f20b4a444da9df3b2c0f331fa7a1f64223"],"8a9e385641d717e641408d8fbbc62be8fc766357":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"10855b393afd8884613d82de3a4fff773d4e5334":["cd27af5c226d98a7c6378c388a67a3bff7c0b3a2"],"ec8b5a20a12931b8d7e616c79c5248ae06cc5568":["457c790b0d3d5883da64fb842ea54813004bb796"],"0833fee1ce16a2b8e10f21cbccd2e93f3d8ccf31":["91d0e16ae1a83f5658ad4d16453fb88650460140"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd27af5c226d98a7c6378c388a67a3bff7c0b3a2":["ec8b5a20a12931b8d7e616c79c5248ae06cc5568"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}