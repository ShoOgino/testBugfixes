{"path":"lucene/core/src/test/org/apache/lucene/index/TestPayloads#testThreadSafety().mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPayloads#testThreadSafety().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestPayloads#testThreadSafety().mjava","sourceNew":"    public void testThreadSafety() throws Exception {\n        final int numThreads = 5;\n        final int numDocs = atLeast(50);\n        final ByteArrayPool pool = new ByteArrayPool(numThreads, 5);\n        \n        Directory dir = newDirectory();\n        final IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( \n            TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n        final String field = \"test\";\n        \n        Thread[] ingesters = new Thread[numThreads];\n        for (int i = 0; i < numThreads; i++) {\n            ingesters[i] = new Thread() {\n                @Override\n                public void run() {\n                    try {\n                        for (int j = 0; j < numDocs; j++) {\n                            Document d = new Document();\n                            d.add(new TextField(field, new PoolingPayloadTokenStream(pool)));\n                            writer.addDocument(d);\n                        }\n                    } catch (Exception e) {\n                        e.printStackTrace();\n                        fail(e.toString());\n                    }\n                }\n            };\n            ingesters[i].start();\n        }\n        \n        for (int i = 0; i < numThreads; i++) {\n          ingesters[i].join();\n        }\n        writer.close();\n        IndexReader reader = IndexReader.open(dir);\n        TermsEnum terms = MultiFields.getFields(reader).terms(field).iterator(null);\n        Bits liveDocs = MultiFields.getLiveDocs(reader);\n        DocsAndPositionsEnum tp = null;\n        while (terms.next() != null) {\n          String termText = terms.term().utf8ToString();\n          tp = terms.docsAndPositions(liveDocs, tp, false);\n          while(tp.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            int freq = tp.freq();\n            for (int i = 0; i < freq; i++) {\n              tp.nextPosition();\n              final BytesRef payload = tp.getPayload();\n              assertEquals(termText, payload.utf8ToString());\n            }\n          }\n        }\n        reader.close();\n        dir.close();\n        assertEquals(pool.size(), numThreads);\n    }\n\n","sourceOld":"    public void testThreadSafety() throws Exception {\n        final int numThreads = 5;\n        final int numDocs = atLeast(50);\n        final ByteArrayPool pool = new ByteArrayPool(numThreads, 5);\n        \n        Directory dir = newDirectory();\n        final IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( \n            TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n        final String field = \"test\";\n        \n        Thread[] ingesters = new Thread[numThreads];\n        for (int i = 0; i < numThreads; i++) {\n            ingesters[i] = new Thread() {\n                @Override\n                public void run() {\n                    try {\n                        for (int j = 0; j < numDocs; j++) {\n                            Document d = new Document();\n                            d.add(new TextField(field, new PoolingPayloadTokenStream(pool)));\n                            writer.addDocument(d);\n                        }\n                    } catch (Exception e) {\n                        e.printStackTrace();\n                        fail(e.toString());\n                    }\n                }\n            };\n            ingesters[i].start();\n        }\n        \n        for (int i = 0; i < numThreads; i++) {\n          ingesters[i].join();\n        }\n        writer.close();\n        IndexReader reader = IndexReader.open(dir);\n        TermsEnum terms = MultiFields.getFields(reader).terms(field).iterator(null);\n        Bits liveDocs = MultiFields.getLiveDocs(reader);\n        DocsAndPositionsEnum tp = null;\n        while (terms.next() != null) {\n          String termText = terms.term().utf8ToString();\n          tp = terms.docsAndPositions(liveDocs, tp, false);\n          while(tp.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            int freq = tp.freq();\n            for (int i = 0; i < freq; i++) {\n              tp.nextPosition();\n              final BytesRef payload = tp.getPayload();\n              assertEquals(termText, payload.utf8ToString());\n            }\n          }\n        }\n        reader.close();\n        dir.close();\n        assertEquals(pool.size(), numThreads);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPayloads#testThreadSafety().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPayloads#testThreadSafety().mjava","sourceNew":"    public void testThreadSafety() throws Exception {\n        final int numThreads = 5;\n        final int numDocs = atLeast(50);\n        final ByteArrayPool pool = new ByteArrayPool(numThreads, 5);\n        \n        Directory dir = newDirectory();\n        final IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( \n            TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n        final String field = \"test\";\n        \n        Thread[] ingesters = new Thread[numThreads];\n        for (int i = 0; i < numThreads; i++) {\n            ingesters[i] = new Thread() {\n                @Override\n                public void run() {\n                    try {\n                        for (int j = 0; j < numDocs; j++) {\n                            Document d = new Document();\n                            d.add(new TextField(field, new PoolingPayloadTokenStream(pool)));\n                            writer.addDocument(d);\n                        }\n                    } catch (Exception e) {\n                        e.printStackTrace();\n                        fail(e.toString());\n                    }\n                }\n            };\n            ingesters[i].start();\n        }\n        \n        for (int i = 0; i < numThreads; i++) {\n          ingesters[i].join();\n        }\n        writer.close();\n        IndexReader reader = IndexReader.open(dir);\n        TermsEnum terms = MultiFields.getFields(reader).terms(field).iterator(null);\n        Bits liveDocs = MultiFields.getLiveDocs(reader);\n        DocsAndPositionsEnum tp = null;\n        while (terms.next() != null) {\n          String termText = terms.term().utf8ToString();\n          tp = terms.docsAndPositions(liveDocs, tp, false);\n          while(tp.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            int freq = tp.freq();\n            for (int i = 0; i < freq; i++) {\n              tp.nextPosition();\n              final BytesRef payload = tp.getPayload();\n              assertEquals(termText, payload.utf8ToString());\n            }\n          }\n        }\n        reader.close();\n        dir.close();\n        assertEquals(pool.size(), numThreads);\n    }\n\n","sourceOld":"    public void testThreadSafety() throws Exception {\n        final int numThreads = 5;\n        final int numDocs = atLeast(50);\n        final ByteArrayPool pool = new ByteArrayPool(numThreads, 5);\n        \n        Directory dir = newDirectory();\n        final IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( \n            TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n        final String field = \"test\";\n        \n        Thread[] ingesters = new Thread[numThreads];\n        for (int i = 0; i < numThreads; i++) {\n            ingesters[i] = new Thread() {\n                @Override\n                public void run() {\n                    try {\n                        for (int j = 0; j < numDocs; j++) {\n                            Document d = new Document();\n                            d.add(new TextField(field, new PoolingPayloadTokenStream(pool)));\n                            writer.addDocument(d);\n                        }\n                    } catch (Exception e) {\n                        e.printStackTrace();\n                        fail(e.toString());\n                    }\n                }\n            };\n            ingesters[i].start();\n        }\n        \n        for (int i = 0; i < numThreads; i++) {\n          ingesters[i].join();\n        }\n        writer.close();\n        IndexReader reader = IndexReader.open(dir);\n        TermsEnum terms = MultiFields.getFields(reader).terms(field).iterator(null);\n        Bits liveDocs = MultiFields.getLiveDocs(reader);\n        DocsAndPositionsEnum tp = null;\n        while (terms.next() != null) {\n          String termText = terms.term().utf8ToString();\n          tp = terms.docsAndPositions(liveDocs, tp, false);\n          while(tp.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            int freq = tp.freq();\n            for (int i = 0; i < freq; i++) {\n              tp.nextPosition();\n              final BytesRef payload = tp.getPayload();\n              assertEquals(termText, payload.utf8ToString());\n            }\n          }\n        }\n        reader.close();\n        dir.close();\n        assertEquals(pool.size(), numThreads);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f","date":1338430031,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPayloads#testThreadSafety().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPayloads#testThreadSafety().mjava","sourceNew":"    public void testThreadSafety() throws Exception {\n        final int numThreads = 5;\n        final int numDocs = atLeast(50);\n        final ByteArrayPool pool = new ByteArrayPool(numThreads, 5);\n        \n        Directory dir = newDirectory();\n        final IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( \n            TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n        final String field = \"test\";\n        \n        Thread[] ingesters = new Thread[numThreads];\n        for (int i = 0; i < numThreads; i++) {\n            ingesters[i] = new Thread() {\n                @Override\n                public void run() {\n                    try {\n                        for (int j = 0; j < numDocs; j++) {\n                            Document d = new Document();\n                            d.add(new TextField(field, new PoolingPayloadTokenStream(pool)));\n                            writer.addDocument(d);\n                        }\n                    } catch (Exception e) {\n                        e.printStackTrace();\n                        fail(e.toString());\n                    }\n                }\n            };\n            ingesters[i].start();\n        }\n        \n        for (int i = 0; i < numThreads; i++) {\n          ingesters[i].join();\n        }\n        writer.close();\n        IndexReader reader = DirectoryReader.open(dir);\n        TermsEnum terms = MultiFields.getFields(reader).terms(field).iterator(null);\n        Bits liveDocs = MultiFields.getLiveDocs(reader);\n        DocsAndPositionsEnum tp = null;\n        while (terms.next() != null) {\n          String termText = terms.term().utf8ToString();\n          tp = terms.docsAndPositions(liveDocs, tp, false);\n          while(tp.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            int freq = tp.freq();\n            for (int i = 0; i < freq; i++) {\n              tp.nextPosition();\n              final BytesRef payload = tp.getPayload();\n              assertEquals(termText, payload.utf8ToString());\n            }\n          }\n        }\n        reader.close();\n        dir.close();\n        assertEquals(pool.size(), numThreads);\n    }\n\n","sourceOld":"    public void testThreadSafety() throws Exception {\n        final int numThreads = 5;\n        final int numDocs = atLeast(50);\n        final ByteArrayPool pool = new ByteArrayPool(numThreads, 5);\n        \n        Directory dir = newDirectory();\n        final IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( \n            TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n        final String field = \"test\";\n        \n        Thread[] ingesters = new Thread[numThreads];\n        for (int i = 0; i < numThreads; i++) {\n            ingesters[i] = new Thread() {\n                @Override\n                public void run() {\n                    try {\n                        for (int j = 0; j < numDocs; j++) {\n                            Document d = new Document();\n                            d.add(new TextField(field, new PoolingPayloadTokenStream(pool)));\n                            writer.addDocument(d);\n                        }\n                    } catch (Exception e) {\n                        e.printStackTrace();\n                        fail(e.toString());\n                    }\n                }\n            };\n            ingesters[i].start();\n        }\n        \n        for (int i = 0; i < numThreads; i++) {\n          ingesters[i].join();\n        }\n        writer.close();\n        IndexReader reader = IndexReader.open(dir);\n        TermsEnum terms = MultiFields.getFields(reader).terms(field).iterator(null);\n        Bits liveDocs = MultiFields.getLiveDocs(reader);\n        DocsAndPositionsEnum tp = null;\n        while (terms.next() != null) {\n          String termText = terms.term().utf8ToString();\n          tp = terms.docsAndPositions(liveDocs, tp, false);\n          while(tp.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            int freq = tp.freq();\n            for (int i = 0; i < freq; i++) {\n              tp.nextPosition();\n              final BytesRef payload = tp.getPayload();\n              assertEquals(termText, payload.utf8ToString());\n            }\n          }\n        }\n        reader.close();\n        dir.close();\n        assertEquals(pool.size(), numThreads);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"322360ac5185a8446d3e0b530b2068bef67cd3d5","date":1343669494,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPayloads#testThreadSafety().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPayloads#testThreadSafety().mjava","sourceNew":"    public void testThreadSafety() throws Exception {\n        final int numThreads = 5;\n        final int numDocs = atLeast(50);\n        final ByteArrayPool pool = new ByteArrayPool(numThreads, 5);\n        \n        Directory dir = newDirectory();\n        final IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( \n            TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n        final String field = \"test\";\n        \n        Thread[] ingesters = new Thread[numThreads];\n        for (int i = 0; i < numThreads; i++) {\n            ingesters[i] = new Thread() {\n                @Override\n                public void run() {\n                    try {\n                        for (int j = 0; j < numDocs; j++) {\n                            Document d = new Document();\n                            d.add(new TextField(field, new PoolingPayloadTokenStream(pool)));\n                            writer.addDocument(d);\n                        }\n                    } catch (Exception e) {\n                        e.printStackTrace();\n                        fail(e.toString());\n                    }\n                }\n            };\n            ingesters[i].start();\n        }\n        \n        for (int i = 0; i < numThreads; i++) {\n          ingesters[i].join();\n        }\n        writer.close();\n        IndexReader reader = DirectoryReader.open(dir);\n        TermsEnum terms = MultiFields.getFields(reader).terms(field).iterator(null);\n        Bits liveDocs = MultiFields.getLiveDocs(reader);\n        DocsAndPositionsEnum tp = null;\n        while (terms.next() != null) {\n          String termText = terms.term().utf8ToString();\n          tp = terms.docsAndPositions(liveDocs, tp);\n          while(tp.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            int freq = tp.freq();\n            for (int i = 0; i < freq; i++) {\n              tp.nextPosition();\n              final BytesRef payload = tp.getPayload();\n              assertEquals(termText, payload.utf8ToString());\n            }\n          }\n        }\n        reader.close();\n        dir.close();\n        assertEquals(pool.size(), numThreads);\n    }\n\n","sourceOld":"    public void testThreadSafety() throws Exception {\n        final int numThreads = 5;\n        final int numDocs = atLeast(50);\n        final ByteArrayPool pool = new ByteArrayPool(numThreads, 5);\n        \n        Directory dir = newDirectory();\n        final IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( \n            TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n        final String field = \"test\";\n        \n        Thread[] ingesters = new Thread[numThreads];\n        for (int i = 0; i < numThreads; i++) {\n            ingesters[i] = new Thread() {\n                @Override\n                public void run() {\n                    try {\n                        for (int j = 0; j < numDocs; j++) {\n                            Document d = new Document();\n                            d.add(new TextField(field, new PoolingPayloadTokenStream(pool)));\n                            writer.addDocument(d);\n                        }\n                    } catch (Exception e) {\n                        e.printStackTrace();\n                        fail(e.toString());\n                    }\n                }\n            };\n            ingesters[i].start();\n        }\n        \n        for (int i = 0; i < numThreads; i++) {\n          ingesters[i].join();\n        }\n        writer.close();\n        IndexReader reader = DirectoryReader.open(dir);\n        TermsEnum terms = MultiFields.getFields(reader).terms(field).iterator(null);\n        Bits liveDocs = MultiFields.getLiveDocs(reader);\n        DocsAndPositionsEnum tp = null;\n        while (terms.next() != null) {\n          String termText = terms.term().utf8ToString();\n          tp = terms.docsAndPositions(liveDocs, tp, false);\n          while(tp.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            int freq = tp.freq();\n            for (int i = 0; i < freq; i++) {\n              tp.nextPosition();\n              final BytesRef payload = tp.getPayload();\n              assertEquals(termText, payload.utf8ToString());\n            }\n          }\n        }\n        reader.close();\n        dir.close();\n        assertEquals(pool.size(), numThreads);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","date":1343768312,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPayloads#testThreadSafety().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPayloads#testThreadSafety().mjava","sourceNew":"    public void testThreadSafety() throws Exception {\n        final int numThreads = 5;\n        final int numDocs = atLeast(50);\n        final ByteArrayPool pool = new ByteArrayPool(numThreads, 5);\n        \n        Directory dir = newDirectory();\n        final IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( \n            TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n        final String field = \"test\";\n        \n        Thread[] ingesters = new Thread[numThreads];\n        for (int i = 0; i < numThreads; i++) {\n            ingesters[i] = new Thread() {\n                @Override\n                public void run() {\n                    try {\n                        for (int j = 0; j < numDocs; j++) {\n                            Document d = new Document();\n                            d.add(new TextField(field, new PoolingPayloadTokenStream(pool)));\n                            writer.addDocument(d);\n                        }\n                    } catch (Exception e) {\n                        e.printStackTrace();\n                        fail(e.toString());\n                    }\n                }\n            };\n            ingesters[i].start();\n        }\n        \n        for (int i = 0; i < numThreads; i++) {\n          ingesters[i].join();\n        }\n        writer.close();\n        IndexReader reader = DirectoryReader.open(dir);\n        TermsEnum terms = MultiFields.getFields(reader).terms(field).iterator(null);\n        Bits liveDocs = MultiFields.getLiveDocs(reader);\n        DocsAndPositionsEnum tp = null;\n        while (terms.next() != null) {\n          String termText = terms.term().utf8ToString();\n          tp = terms.docsAndPositions(liveDocs, tp);\n          while(tp.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            int freq = tp.freq();\n            for (int i = 0; i < freq; i++) {\n              tp.nextPosition();\n              final BytesRef payload = tp.getPayload();\n              assertEquals(termText, payload.utf8ToString());\n            }\n          }\n        }\n        reader.close();\n        dir.close();\n        assertEquals(pool.size(), numThreads);\n    }\n\n","sourceOld":"    public void testThreadSafety() throws Exception {\n        final int numThreads = 5;\n        final int numDocs = atLeast(50);\n        final ByteArrayPool pool = new ByteArrayPool(numThreads, 5);\n        \n        Directory dir = newDirectory();\n        final IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( \n            TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n        final String field = \"test\";\n        \n        Thread[] ingesters = new Thread[numThreads];\n        for (int i = 0; i < numThreads; i++) {\n            ingesters[i] = new Thread() {\n                @Override\n                public void run() {\n                    try {\n                        for (int j = 0; j < numDocs; j++) {\n                            Document d = new Document();\n                            d.add(new TextField(field, new PoolingPayloadTokenStream(pool)));\n                            writer.addDocument(d);\n                        }\n                    } catch (Exception e) {\n                        e.printStackTrace();\n                        fail(e.toString());\n                    }\n                }\n            };\n            ingesters[i].start();\n        }\n        \n        for (int i = 0; i < numThreads; i++) {\n          ingesters[i].join();\n        }\n        writer.close();\n        IndexReader reader = DirectoryReader.open(dir);\n        TermsEnum terms = MultiFields.getFields(reader).terms(field).iterator(null);\n        Bits liveDocs = MultiFields.getLiveDocs(reader);\n        DocsAndPositionsEnum tp = null;\n        while (terms.next() != null) {\n          String termText = terms.term().utf8ToString();\n          tp = terms.docsAndPositions(liveDocs, tp, false);\n          while(tp.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            int freq = tp.freq();\n            for (int i = 0; i < freq; i++) {\n              tp.nextPosition();\n              final BytesRef payload = tp.getPayload();\n              assertEquals(termText, payload.utf8ToString());\n            }\n          }\n        }\n        reader.close();\n        dir.close();\n        assertEquals(pool.size(), numThreads);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d6f074e73200c07d54f242d3880a8da5a35ff97b","date":1344507653,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPayloads#testThreadSafety().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPayloads#testThreadSafety().mjava","sourceNew":"    public void testThreadSafety() throws Exception {\n        final int numThreads = 5;\n        final int numDocs = atLeast(50);\n        final ByteArrayPool pool = new ByteArrayPool(numThreads, 5);\n        \n        Directory dir = newDirectory();\n        final IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( \n            TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n        final String field = \"test\";\n        \n        Thread[] ingesters = new Thread[numThreads];\n        for (int i = 0; i < numThreads; i++) {\n            ingesters[i] = new Thread() {\n                @Override\n                public void run() {\n                    try {\n                        for (int j = 0; j < numDocs; j++) {\n                            Document d = new Document();\n                            d.add(new TextField(field, new PoolingPayloadTokenStream(pool)));\n                            writer.addDocument(d);\n                        }\n                    } catch (Exception e) {\n                        e.printStackTrace();\n                        fail(e.toString());\n                    }\n                }\n            };\n            ingesters[i].start();\n        }\n        \n        for (int i = 0; i < numThreads; i++) {\n          ingesters[i].join();\n        }\n        writer.close();\n        IndexReader reader = DirectoryReader.open(dir);\n        TermsEnum terms = MultiFields.getFields(reader).terms(field).iterator(null);\n        Bits liveDocs = MultiFields.getLiveDocs(reader);\n        DocsAndPositionsEnum tp = null;\n        while (terms.next() != null) {\n          String termText = terms.term().utf8ToString();\n          tp = terms.docsAndPositions(liveDocs, tp);\n          while(tp.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            int freq = tp.freq();\n            for (int i = 0; i < freq; i++) {\n              tp.nextPosition();\n              final BytesRef payload = tp.getPayload();\n              assertEquals(termText, payload.utf8ToString());\n            }\n          }\n        }\n        reader.close();\n        dir.close();\n        assertEquals(pool.size(), numThreads);\n    }\n\n","sourceOld":"    public void testThreadSafety() throws Exception {\n        final int numThreads = 5;\n        final int numDocs = atLeast(50);\n        final ByteArrayPool pool = new ByteArrayPool(numThreads, 5);\n        \n        Directory dir = newDirectory();\n        final IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( \n            TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n        final String field = \"test\";\n        \n        Thread[] ingesters = new Thread[numThreads];\n        for (int i = 0; i < numThreads; i++) {\n            ingesters[i] = new Thread() {\n                @Override\n                public void run() {\n                    try {\n                        for (int j = 0; j < numDocs; j++) {\n                            Document d = new Document();\n                            d.add(new TextField(field, new PoolingPayloadTokenStream(pool)));\n                            writer.addDocument(d);\n                        }\n                    } catch (Exception e) {\n                        e.printStackTrace();\n                        fail(e.toString());\n                    }\n                }\n            };\n            ingesters[i].start();\n        }\n        \n        for (int i = 0; i < numThreads; i++) {\n          ingesters[i].join();\n        }\n        writer.close();\n        IndexReader reader = DirectoryReader.open(dir);\n        TermsEnum terms = MultiFields.getFields(reader).terms(field).iterator(null);\n        Bits liveDocs = MultiFields.getLiveDocs(reader);\n        DocsAndPositionsEnum tp = null;\n        while (terms.next() != null) {\n          String termText = terms.term().utf8ToString();\n          tp = terms.docsAndPositions(liveDocs, tp, false);\n          while(tp.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            int freq = tp.freq();\n            for (int i = 0; i < freq; i++) {\n              tp.nextPosition();\n              final BytesRef payload = tp.getPayload();\n              assertEquals(termText, payload.utf8ToString());\n            }\n          }\n        }\n        reader.close();\n        dir.close();\n        assertEquals(pool.size(), numThreads);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPayloads#testThreadSafety().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPayloads#testThreadSafety().mjava","sourceNew":"    public void testThreadSafety() throws Exception {\n        final int numThreads = 5;\n        final int numDocs = atLeast(50);\n        final ByteArrayPool pool = new ByteArrayPool(numThreads, 5);\n        \n        Directory dir = newDirectory();\n        final IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( \n            TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n        final String field = \"test\";\n        \n        Thread[] ingesters = new Thread[numThreads];\n        for (int i = 0; i < numThreads; i++) {\n            ingesters[i] = new Thread() {\n                @Override\n                public void run() {\n                    try {\n                        for (int j = 0; j < numDocs; j++) {\n                            Document d = new Document();\n                            d.add(new TextField(field, new PoolingPayloadTokenStream(pool)));\n                            writer.addDocument(d);\n                        }\n                    } catch (Exception e) {\n                        e.printStackTrace();\n                        fail(e.toString());\n                    }\n                }\n            };\n            ingesters[i].start();\n        }\n        \n        for (int i = 0; i < numThreads; i++) {\n          ingesters[i].join();\n        }\n        writer.shutdown();\n        IndexReader reader = DirectoryReader.open(dir);\n        TermsEnum terms = MultiFields.getFields(reader).terms(field).iterator(null);\n        Bits liveDocs = MultiFields.getLiveDocs(reader);\n        DocsAndPositionsEnum tp = null;\n        while (terms.next() != null) {\n          String termText = terms.term().utf8ToString();\n          tp = terms.docsAndPositions(liveDocs, tp);\n          while(tp.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            int freq = tp.freq();\n            for (int i = 0; i < freq; i++) {\n              tp.nextPosition();\n              final BytesRef payload = tp.getPayload();\n              assertEquals(termText, payload.utf8ToString());\n            }\n          }\n        }\n        reader.close();\n        dir.close();\n        assertEquals(pool.size(), numThreads);\n    }\n\n","sourceOld":"    public void testThreadSafety() throws Exception {\n        final int numThreads = 5;\n        final int numDocs = atLeast(50);\n        final ByteArrayPool pool = new ByteArrayPool(numThreads, 5);\n        \n        Directory dir = newDirectory();\n        final IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( \n            TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n        final String field = \"test\";\n        \n        Thread[] ingesters = new Thread[numThreads];\n        for (int i = 0; i < numThreads; i++) {\n            ingesters[i] = new Thread() {\n                @Override\n                public void run() {\n                    try {\n                        for (int j = 0; j < numDocs; j++) {\n                            Document d = new Document();\n                            d.add(new TextField(field, new PoolingPayloadTokenStream(pool)));\n                            writer.addDocument(d);\n                        }\n                    } catch (Exception e) {\n                        e.printStackTrace();\n                        fail(e.toString());\n                    }\n                }\n            };\n            ingesters[i].start();\n        }\n        \n        for (int i = 0; i < numThreads; i++) {\n          ingesters[i].join();\n        }\n        writer.close();\n        IndexReader reader = DirectoryReader.open(dir);\n        TermsEnum terms = MultiFields.getFields(reader).terms(field).iterator(null);\n        Bits liveDocs = MultiFields.getLiveDocs(reader);\n        DocsAndPositionsEnum tp = null;\n        while (terms.next() != null) {\n          String termText = terms.term().utf8ToString();\n          tp = terms.docsAndPositions(liveDocs, tp);\n          while(tp.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            int freq = tp.freq();\n            for (int i = 0; i < freq; i++) {\n              tp.nextPosition();\n              final BytesRef payload = tp.getPayload();\n              assertEquals(termText, payload.utf8ToString());\n            }\n          }\n        }\n        reader.close();\n        dir.close();\n        assertEquals(pool.size(), numThreads);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPayloads#testThreadSafety().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPayloads#testThreadSafety().mjava","sourceNew":"    public void testThreadSafety() throws Exception {\n        final int numThreads = 5;\n        final int numDocs = atLeast(50);\n        final ByteArrayPool pool = new ByteArrayPool(numThreads, 5);\n        \n        Directory dir = newDirectory();\n        final IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n        final String field = \"test\";\n        \n        Thread[] ingesters = new Thread[numThreads];\n        for (int i = 0; i < numThreads; i++) {\n            ingesters[i] = new Thread() {\n                @Override\n                public void run() {\n                    try {\n                        for (int j = 0; j < numDocs; j++) {\n                            Document d = new Document();\n                            d.add(new TextField(field, new PoolingPayloadTokenStream(pool)));\n                            writer.addDocument(d);\n                        }\n                    } catch (Exception e) {\n                        e.printStackTrace();\n                        fail(e.toString());\n                    }\n                }\n            };\n            ingesters[i].start();\n        }\n        \n        for (int i = 0; i < numThreads; i++) {\n          ingesters[i].join();\n        }\n        writer.shutdown();\n        IndexReader reader = DirectoryReader.open(dir);\n        TermsEnum terms = MultiFields.getFields(reader).terms(field).iterator(null);\n        Bits liveDocs = MultiFields.getLiveDocs(reader);\n        DocsAndPositionsEnum tp = null;\n        while (terms.next() != null) {\n          String termText = terms.term().utf8ToString();\n          tp = terms.docsAndPositions(liveDocs, tp);\n          while(tp.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            int freq = tp.freq();\n            for (int i = 0; i < freq; i++) {\n              tp.nextPosition();\n              final BytesRef payload = tp.getPayload();\n              assertEquals(termText, payload.utf8ToString());\n            }\n          }\n        }\n        reader.close();\n        dir.close();\n        assertEquals(pool.size(), numThreads);\n    }\n\n","sourceOld":"    public void testThreadSafety() throws Exception {\n        final int numThreads = 5;\n        final int numDocs = atLeast(50);\n        final ByteArrayPool pool = new ByteArrayPool(numThreads, 5);\n        \n        Directory dir = newDirectory();\n        final IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( \n            TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n        final String field = \"test\";\n        \n        Thread[] ingesters = new Thread[numThreads];\n        for (int i = 0; i < numThreads; i++) {\n            ingesters[i] = new Thread() {\n                @Override\n                public void run() {\n                    try {\n                        for (int j = 0; j < numDocs; j++) {\n                            Document d = new Document();\n                            d.add(new TextField(field, new PoolingPayloadTokenStream(pool)));\n                            writer.addDocument(d);\n                        }\n                    } catch (Exception e) {\n                        e.printStackTrace();\n                        fail(e.toString());\n                    }\n                }\n            };\n            ingesters[i].start();\n        }\n        \n        for (int i = 0; i < numThreads; i++) {\n          ingesters[i].join();\n        }\n        writer.shutdown();\n        IndexReader reader = DirectoryReader.open(dir);\n        TermsEnum terms = MultiFields.getFields(reader).terms(field).iterator(null);\n        Bits liveDocs = MultiFields.getLiveDocs(reader);\n        DocsAndPositionsEnum tp = null;\n        while (terms.next() != null) {\n          String termText = terms.term().utf8ToString();\n          tp = terms.docsAndPositions(liveDocs, tp);\n          while(tp.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            int freq = tp.freq();\n            for (int i = 0; i < freq; i++) {\n              tp.nextPosition();\n              final BytesRef payload = tp.getPayload();\n              assertEquals(termText, payload.utf8ToString());\n            }\n          }\n        }\n        reader.close();\n        dir.close();\n        assertEquals(pool.size(), numThreads);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPayloads#testThreadSafety().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPayloads#testThreadSafety().mjava","sourceNew":"    public void testThreadSafety() throws Exception {\n        final int numThreads = 5;\n        final int numDocs = atLeast(50);\n        final ByteArrayPool pool = new ByteArrayPool(numThreads, 5);\n        \n        Directory dir = newDirectory();\n        final IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n        final String field = \"test\";\n        \n        Thread[] ingesters = new Thread[numThreads];\n        for (int i = 0; i < numThreads; i++) {\n            ingesters[i] = new Thread() {\n                @Override\n                public void run() {\n                    try {\n                        for (int j = 0; j < numDocs; j++) {\n                            Document d = new Document();\n                            d.add(new TextField(field, new PoolingPayloadTokenStream(pool)));\n                            writer.addDocument(d);\n                        }\n                    } catch (Exception e) {\n                        e.printStackTrace();\n                        fail(e.toString());\n                    }\n                }\n            };\n            ingesters[i].start();\n        }\n        \n        for (int i = 0; i < numThreads; i++) {\n          ingesters[i].join();\n        }\n        writer.close();\n        IndexReader reader = DirectoryReader.open(dir);\n        TermsEnum terms = MultiFields.getFields(reader).terms(field).iterator(null);\n        Bits liveDocs = MultiFields.getLiveDocs(reader);\n        DocsAndPositionsEnum tp = null;\n        while (terms.next() != null) {\n          String termText = terms.term().utf8ToString();\n          tp = terms.docsAndPositions(liveDocs, tp);\n          while(tp.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            int freq = tp.freq();\n            for (int i = 0; i < freq; i++) {\n              tp.nextPosition();\n              final BytesRef payload = tp.getPayload();\n              assertEquals(termText, payload.utf8ToString());\n            }\n          }\n        }\n        reader.close();\n        dir.close();\n        assertEquals(pool.size(), numThreads);\n    }\n\n","sourceOld":"    public void testThreadSafety() throws Exception {\n        final int numThreads = 5;\n        final int numDocs = atLeast(50);\n        final ByteArrayPool pool = new ByteArrayPool(numThreads, 5);\n        \n        Directory dir = newDirectory();\n        final IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n        final String field = \"test\";\n        \n        Thread[] ingesters = new Thread[numThreads];\n        for (int i = 0; i < numThreads; i++) {\n            ingesters[i] = new Thread() {\n                @Override\n                public void run() {\n                    try {\n                        for (int j = 0; j < numDocs; j++) {\n                            Document d = new Document();\n                            d.add(new TextField(field, new PoolingPayloadTokenStream(pool)));\n                            writer.addDocument(d);\n                        }\n                    } catch (Exception e) {\n                        e.printStackTrace();\n                        fail(e.toString());\n                    }\n                }\n            };\n            ingesters[i].start();\n        }\n        \n        for (int i = 0; i < numThreads; i++) {\n          ingesters[i].join();\n        }\n        writer.shutdown();\n        IndexReader reader = DirectoryReader.open(dir);\n        TermsEnum terms = MultiFields.getFields(reader).terms(field).iterator(null);\n        Bits liveDocs = MultiFields.getLiveDocs(reader);\n        DocsAndPositionsEnum tp = null;\n        while (terms.next() != null) {\n          String termText = terms.term().utf8ToString();\n          tp = terms.docsAndPositions(liveDocs, tp);\n          while(tp.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            int freq = tp.freq();\n            for (int i = 0; i < freq; i++) {\n              tp.nextPosition();\n              final BytesRef payload = tp.getPayload();\n              assertEquals(termText, payload.utf8ToString());\n            }\n          }\n        }\n        reader.close();\n        dir.close();\n        assertEquals(pool.size(), numThreads);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5c1c5aa8e88aa52c9e1cbfc696b611d3a56223c0","date":1422781929,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPayloads#testThreadSafety().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPayloads#testThreadSafety().mjava","sourceNew":"  public void testThreadSafety() throws Exception {\n    final int numThreads = 5;\n    final int numDocs = atLeast(50);\n    final ByteArrayPool pool = new ByteArrayPool(numThreads, 5);\n        \n    Directory dir = newDirectory();\n    final IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    final String field = \"test\";\n        \n    Thread[] ingesters = new Thread[numThreads];\n    for (int i = 0; i < numThreads; i++) {\n      ingesters[i] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              for (int j = 0; j < numDocs; j++) {\n                Document d = new Document();\n                d.add(new TextField(field, new PoolingPayloadTokenStream(pool)));\n                writer.addDocument(d);\n              }\n            } catch (Exception e) {\n              e.printStackTrace();\n              fail(e.toString());\n            }\n          }\n        };\n      ingesters[i].start();\n    }\n        \n    for (int i = 0; i < numThreads; i++) {\n      ingesters[i].join();\n    }\n    writer.close();\n    IndexReader reader = DirectoryReader.open(dir);\n    TermsEnum terms = MultiFields.getFields(reader).terms(field).iterator(null);\n    Bits liveDocs = MultiFields.getLiveDocs(reader);\n    DocsAndPositionsEnum tp = null;\n    while (terms.next() != null) {\n      String termText = terms.term().utf8ToString();\n      tp = terms.docsAndPositions(liveDocs, tp);\n      while(tp.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n        int freq = tp.freq();\n        for (int i = 0; i < freq; i++) {\n          tp.nextPosition();\n          final BytesRef payload = tp.getPayload();\n          assertEquals(termText, payload.utf8ToString());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n    assertEquals(pool.size(), numThreads);\n  }\n\n","sourceOld":"    public void testThreadSafety() throws Exception {\n        final int numThreads = 5;\n        final int numDocs = atLeast(50);\n        final ByteArrayPool pool = new ByteArrayPool(numThreads, 5);\n        \n        Directory dir = newDirectory();\n        final IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n        final String field = \"test\";\n        \n        Thread[] ingesters = new Thread[numThreads];\n        for (int i = 0; i < numThreads; i++) {\n            ingesters[i] = new Thread() {\n                @Override\n                public void run() {\n                    try {\n                        for (int j = 0; j < numDocs; j++) {\n                            Document d = new Document();\n                            d.add(new TextField(field, new PoolingPayloadTokenStream(pool)));\n                            writer.addDocument(d);\n                        }\n                    } catch (Exception e) {\n                        e.printStackTrace();\n                        fail(e.toString());\n                    }\n                }\n            };\n            ingesters[i].start();\n        }\n        \n        for (int i = 0; i < numThreads; i++) {\n          ingesters[i].join();\n        }\n        writer.close();\n        IndexReader reader = DirectoryReader.open(dir);\n        TermsEnum terms = MultiFields.getFields(reader).terms(field).iterator(null);\n        Bits liveDocs = MultiFields.getLiveDocs(reader);\n        DocsAndPositionsEnum tp = null;\n        while (terms.next() != null) {\n          String termText = terms.term().utf8ToString();\n          tp = terms.docsAndPositions(liveDocs, tp);\n          while(tp.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            int freq = tp.freq();\n            for (int i = 0; i < freq; i++) {\n              tp.nextPosition();\n              final BytesRef payload = tp.getPayload();\n              assertEquals(termText, payload.utf8ToString());\n            }\n          }\n        }\n        reader.close();\n        dir.close();\n        assertEquals(pool.size(), numThreads);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"51f5280f31484820499077f41fcdfe92d527d9dc","date":1423229122,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPayloads#testThreadSafety().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPayloads#testThreadSafety().mjava","sourceNew":"  public void testThreadSafety() throws Exception {\n    final int numThreads = 5;\n    final int numDocs = atLeast(50);\n    final ByteArrayPool pool = new ByteArrayPool(numThreads, 5);\n\n    Directory dir = newDirectory();\n    final IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    final String field = \"test\";\n        \n    Thread[] ingesters = new Thread[numThreads];\n    for (int i = 0; i < numThreads; i++) {\n      ingesters[i] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              for (int j = 0; j < numDocs; j++) {\n                Document d = new Document();\n                d.add(new TextField(field, new PoolingPayloadTokenStream(pool)));\n                writer.addDocument(d);\n              }\n            } catch (Exception e) {\n              e.printStackTrace();\n              fail(e.toString());\n            }\n          }\n        };\n      ingesters[i].start();\n    }\n        \n    for (int i = 0; i < numThreads; i++) {\n      ingesters[i].join();\n    }\n    writer.close();\n    IndexReader reader = DirectoryReader.open(dir);\n    TermsEnum terms = MultiFields.getFields(reader).terms(field).iterator(null);\n    Bits liveDocs = MultiFields.getLiveDocs(reader);\n    PostingsEnum tp = null;\n    while (terms.next() != null) {\n      String termText = terms.term().utf8ToString();\n      tp = terms.postings(liveDocs, tp, PostingsEnum.FLAG_PAYLOADS);\n      while(tp.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n        int freq = tp.freq();\n        for (int i = 0; i < freq; i++) {\n          tp.nextPosition();\n          final BytesRef payload = tp.getPayload();\n          assertEquals(termText, payload.utf8ToString());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n    assertEquals(pool.size(), numThreads);\n  }\n\n","sourceOld":"  public void testThreadSafety() throws Exception {\n    final int numThreads = 5;\n    final int numDocs = atLeast(50);\n    final ByteArrayPool pool = new ByteArrayPool(numThreads, 5);\n        \n    Directory dir = newDirectory();\n    final IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    final String field = \"test\";\n        \n    Thread[] ingesters = new Thread[numThreads];\n    for (int i = 0; i < numThreads; i++) {\n      ingesters[i] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              for (int j = 0; j < numDocs; j++) {\n                Document d = new Document();\n                d.add(new TextField(field, new PoolingPayloadTokenStream(pool)));\n                writer.addDocument(d);\n              }\n            } catch (Exception e) {\n              e.printStackTrace();\n              fail(e.toString());\n            }\n          }\n        };\n      ingesters[i].start();\n    }\n        \n    for (int i = 0; i < numThreads; i++) {\n      ingesters[i].join();\n    }\n    writer.close();\n    IndexReader reader = DirectoryReader.open(dir);\n    TermsEnum terms = MultiFields.getFields(reader).terms(field).iterator(null);\n    Bits liveDocs = MultiFields.getLiveDocs(reader);\n    DocsAndPositionsEnum tp = null;\n    while (terms.next() != null) {\n      String termText = terms.term().utf8ToString();\n      tp = terms.docsAndPositions(liveDocs, tp);\n      while(tp.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n        int freq = tp.freq();\n        for (int i = 0; i < freq; i++) {\n          tp.nextPosition();\n          final BytesRef payload = tp.getPayload();\n          assertEquals(termText, payload.utf8ToString());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n    assertEquals(pool.size(), numThreads);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e73063b92d958076ef4ae8beb5f493e8ccdcecb4","date":1424177215,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPayloads#testThreadSafety().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPayloads#testThreadSafety().mjava","sourceNew":"  public void testThreadSafety() throws Exception {\n    final int numThreads = 5;\n    final int numDocs = atLeast(50);\n    final ByteArrayPool pool = new ByteArrayPool(numThreads, 5);\n\n    Directory dir = newDirectory();\n    final IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    final String field = \"test\";\n        \n    Thread[] ingesters = new Thread[numThreads];\n    for (int i = 0; i < numThreads; i++) {\n      ingesters[i] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              for (int j = 0; j < numDocs; j++) {\n                Document d = new Document();\n                d.add(new TextField(field, new PoolingPayloadTokenStream(pool)));\n                writer.addDocument(d);\n              }\n            } catch (Exception e) {\n              e.printStackTrace();\n              fail(e.toString());\n            }\n          }\n        };\n      ingesters[i].start();\n    }\n        \n    for (int i = 0; i < numThreads; i++) {\n      ingesters[i].join();\n    }\n    writer.close();\n    IndexReader reader = DirectoryReader.open(dir);\n    TermsEnum terms = MultiFields.getFields(reader).terms(field).iterator(null);\n    Bits liveDocs = MultiFields.getLiveDocs(reader);\n    PostingsEnum tp = null;\n    while (terms.next() != null) {\n      String termText = terms.term().utf8ToString();\n      tp = terms.postings(liveDocs, tp, PostingsEnum.PAYLOADS);\n      while(tp.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n        int freq = tp.freq();\n        for (int i = 0; i < freq; i++) {\n          tp.nextPosition();\n          final BytesRef payload = tp.getPayload();\n          assertEquals(termText, payload.utf8ToString());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n    assertEquals(pool.size(), numThreads);\n  }\n\n","sourceOld":"  public void testThreadSafety() throws Exception {\n    final int numThreads = 5;\n    final int numDocs = atLeast(50);\n    final ByteArrayPool pool = new ByteArrayPool(numThreads, 5);\n\n    Directory dir = newDirectory();\n    final IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    final String field = \"test\";\n        \n    Thread[] ingesters = new Thread[numThreads];\n    for (int i = 0; i < numThreads; i++) {\n      ingesters[i] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              for (int j = 0; j < numDocs; j++) {\n                Document d = new Document();\n                d.add(new TextField(field, new PoolingPayloadTokenStream(pool)));\n                writer.addDocument(d);\n              }\n            } catch (Exception e) {\n              e.printStackTrace();\n              fail(e.toString());\n            }\n          }\n        };\n      ingesters[i].start();\n    }\n        \n    for (int i = 0; i < numThreads; i++) {\n      ingesters[i].join();\n    }\n    writer.close();\n    IndexReader reader = DirectoryReader.open(dir);\n    TermsEnum terms = MultiFields.getFields(reader).terms(field).iterator(null);\n    Bits liveDocs = MultiFields.getLiveDocs(reader);\n    PostingsEnum tp = null;\n    while (terms.next() != null) {\n      String termText = terms.term().utf8ToString();\n      tp = terms.postings(liveDocs, tp, PostingsEnum.FLAG_PAYLOADS);\n      while(tp.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n        int freq = tp.freq();\n        for (int i = 0; i < freq; i++) {\n          tp.nextPosition();\n          final BytesRef payload = tp.getPayload();\n          assertEquals(termText, payload.utf8ToString());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n    assertEquals(pool.size(), numThreads);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82","date":1428522487,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPayloads#testThreadSafety().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPayloads#testThreadSafety().mjava","sourceNew":"  public void testThreadSafety() throws Exception {\n    final int numThreads = 5;\n    final int numDocs = atLeast(50);\n    final ByteArrayPool pool = new ByteArrayPool(numThreads, 5);\n\n    Directory dir = newDirectory();\n    final IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    final String field = \"test\";\n        \n    Thread[] ingesters = new Thread[numThreads];\n    for (int i = 0; i < numThreads; i++) {\n      ingesters[i] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              for (int j = 0; j < numDocs; j++) {\n                Document d = new Document();\n                d.add(new TextField(field, new PoolingPayloadTokenStream(pool)));\n                writer.addDocument(d);\n              }\n            } catch (Exception e) {\n              e.printStackTrace();\n              fail(e.toString());\n            }\n          }\n        };\n      ingesters[i].start();\n    }\n        \n    for (int i = 0; i < numThreads; i++) {\n      ingesters[i].join();\n    }\n    writer.close();\n    IndexReader reader = DirectoryReader.open(dir);\n    TermsEnum terms = MultiFields.getFields(reader).terms(field).iterator();\n    Bits liveDocs = MultiFields.getLiveDocs(reader);\n    PostingsEnum tp = null;\n    while (terms.next() != null) {\n      String termText = terms.term().utf8ToString();\n      tp = terms.postings(liveDocs, tp, PostingsEnum.PAYLOADS);\n      while(tp.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n        int freq = tp.freq();\n        for (int i = 0; i < freq; i++) {\n          tp.nextPosition();\n          final BytesRef payload = tp.getPayload();\n          assertEquals(termText, payload.utf8ToString());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n    assertEquals(pool.size(), numThreads);\n  }\n\n","sourceOld":"  public void testThreadSafety() throws Exception {\n    final int numThreads = 5;\n    final int numDocs = atLeast(50);\n    final ByteArrayPool pool = new ByteArrayPool(numThreads, 5);\n\n    Directory dir = newDirectory();\n    final IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    final String field = \"test\";\n        \n    Thread[] ingesters = new Thread[numThreads];\n    for (int i = 0; i < numThreads; i++) {\n      ingesters[i] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              for (int j = 0; j < numDocs; j++) {\n                Document d = new Document();\n                d.add(new TextField(field, new PoolingPayloadTokenStream(pool)));\n                writer.addDocument(d);\n              }\n            } catch (Exception e) {\n              e.printStackTrace();\n              fail(e.toString());\n            }\n          }\n        };\n      ingesters[i].start();\n    }\n        \n    for (int i = 0; i < numThreads; i++) {\n      ingesters[i].join();\n    }\n    writer.close();\n    IndexReader reader = DirectoryReader.open(dir);\n    TermsEnum terms = MultiFields.getFields(reader).terms(field).iterator(null);\n    Bits liveDocs = MultiFields.getLiveDocs(reader);\n    PostingsEnum tp = null;\n    while (terms.next() != null) {\n      String termText = terms.term().utf8ToString();\n      tp = terms.postings(liveDocs, tp, PostingsEnum.PAYLOADS);\n      while(tp.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n        int freq = tp.freq();\n        for (int i = 0; i < freq; i++) {\n          tp.nextPosition();\n          final BytesRef payload = tp.getPayload();\n          assertEquals(termText, payload.utf8ToString());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n    assertEquals(pool.size(), numThreads);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0f4464508ee83288c8c4585b533f9faaa93aa314","date":1435240759,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPayloads#testThreadSafety().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPayloads#testThreadSafety().mjava","sourceNew":"  public void testThreadSafety() throws Exception {\n    final int numThreads = 5;\n    final int numDocs = atLeast(50);\n    final ByteArrayPool pool = new ByteArrayPool(numThreads, 5);\n\n    Directory dir = newDirectory();\n    final IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    final String field = \"test\";\n        \n    Thread[] ingesters = new Thread[numThreads];\n    for (int i = 0; i < numThreads; i++) {\n      ingesters[i] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              for (int j = 0; j < numDocs; j++) {\n                Document d = new Document();\n                d.add(new TextField(field, new PoolingPayloadTokenStream(pool)));\n                writer.addDocument(d);\n              }\n            } catch (Exception e) {\n              e.printStackTrace();\n              fail(e.toString());\n            }\n          }\n        };\n      ingesters[i].start();\n    }\n        \n    for (int i = 0; i < numThreads; i++) {\n      ingesters[i].join();\n    }\n    writer.close();\n    IndexReader reader = DirectoryReader.open(dir);\n    TermsEnum terms = MultiFields.getFields(reader).terms(field).iterator();\n    PostingsEnum tp = null;\n    while (terms.next() != null) {\n      String termText = terms.term().utf8ToString();\n      tp = terms.postings(tp, PostingsEnum.PAYLOADS);\n      while(tp.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n        int freq = tp.freq();\n        for (int i = 0; i < freq; i++) {\n          tp.nextPosition();\n          final BytesRef payload = tp.getPayload();\n          assertEquals(termText, payload.utf8ToString());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n    assertEquals(pool.size(), numThreads);\n  }\n\n","sourceOld":"  public void testThreadSafety() throws Exception {\n    final int numThreads = 5;\n    final int numDocs = atLeast(50);\n    final ByteArrayPool pool = new ByteArrayPool(numThreads, 5);\n\n    Directory dir = newDirectory();\n    final IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    final String field = \"test\";\n        \n    Thread[] ingesters = new Thread[numThreads];\n    for (int i = 0; i < numThreads; i++) {\n      ingesters[i] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              for (int j = 0; j < numDocs; j++) {\n                Document d = new Document();\n                d.add(new TextField(field, new PoolingPayloadTokenStream(pool)));\n                writer.addDocument(d);\n              }\n            } catch (Exception e) {\n              e.printStackTrace();\n              fail(e.toString());\n            }\n          }\n        };\n      ingesters[i].start();\n    }\n        \n    for (int i = 0; i < numThreads; i++) {\n      ingesters[i].join();\n    }\n    writer.close();\n    IndexReader reader = DirectoryReader.open(dir);\n    TermsEnum terms = MultiFields.getFields(reader).terms(field).iterator();\n    Bits liveDocs = MultiFields.getLiveDocs(reader);\n    PostingsEnum tp = null;\n    while (terms.next() != null) {\n      String termText = terms.term().utf8ToString();\n      tp = terms.postings(liveDocs, tp, PostingsEnum.PAYLOADS);\n      while(tp.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n        int freq = tp.freq();\n        for (int i = 0; i < freq; i++) {\n          tp.nextPosition();\n          final BytesRef payload = tp.getPayload();\n          assertEquals(termText, payload.utf8ToString());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n    assertEquals(pool.size(), numThreads);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e588e8c82e32e29ef3837c0b06a2ad34f3c51a2b","date":1497408244,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPayloads#testThreadSafety().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPayloads#testThreadSafety().mjava","sourceNew":"  public void testThreadSafety() throws Exception {\n    final int numThreads = 5;\n    final int numDocs = atLeast(50);\n    final ByteArrayPool pool = new ByteArrayPool(numThreads, 5);\n\n    Directory dir = newDirectory();\n    final IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    final String field = \"test\";\n        \n    Thread[] ingesters = new Thread[numThreads];\n    for (int i = 0; i < numThreads; i++) {\n      ingesters[i] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              for (int j = 0; j < numDocs; j++) {\n                Document d = new Document();\n                d.add(new TextField(field, new PoolingPayloadTokenStream(pool)));\n                writer.addDocument(d);\n              }\n            } catch (Exception e) {\n              e.printStackTrace();\n              fail(e.toString());\n            }\n          }\n        };\n      ingesters[i].start();\n    }\n        \n    for (int i = 0; i < numThreads; i++) {\n      ingesters[i].join();\n    }\n    writer.close();\n    IndexReader reader = DirectoryReader.open(dir);\n    TermsEnum terms = MultiFields.getTerms(reader, field).iterator();\n    PostingsEnum tp = null;\n    while (terms.next() != null) {\n      String termText = terms.term().utf8ToString();\n      tp = terms.postings(tp, PostingsEnum.PAYLOADS);\n      while(tp.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n        int freq = tp.freq();\n        for (int i = 0; i < freq; i++) {\n          tp.nextPosition();\n          final BytesRef payload = tp.getPayload();\n          assertEquals(termText, payload.utf8ToString());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n    assertEquals(pool.size(), numThreads);\n  }\n\n","sourceOld":"  public void testThreadSafety() throws Exception {\n    final int numThreads = 5;\n    final int numDocs = atLeast(50);\n    final ByteArrayPool pool = new ByteArrayPool(numThreads, 5);\n\n    Directory dir = newDirectory();\n    final IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    final String field = \"test\";\n        \n    Thread[] ingesters = new Thread[numThreads];\n    for (int i = 0; i < numThreads; i++) {\n      ingesters[i] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              for (int j = 0; j < numDocs; j++) {\n                Document d = new Document();\n                d.add(new TextField(field, new PoolingPayloadTokenStream(pool)));\n                writer.addDocument(d);\n              }\n            } catch (Exception e) {\n              e.printStackTrace();\n              fail(e.toString());\n            }\n          }\n        };\n      ingesters[i].start();\n    }\n        \n    for (int i = 0; i < numThreads; i++) {\n      ingesters[i].join();\n    }\n    writer.close();\n    IndexReader reader = DirectoryReader.open(dir);\n    TermsEnum terms = MultiFields.getFields(reader).terms(field).iterator();\n    PostingsEnum tp = null;\n    while (terms.next() != null) {\n      String termText = terms.term().utf8ToString();\n      tp = terms.postings(tp, PostingsEnum.PAYLOADS);\n      while(tp.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n        int freq = tp.freq();\n        for (int i = 0; i < freq; i++) {\n          tp.nextPosition();\n          final BytesRef payload = tp.getPayload();\n          assertEquals(termText, payload.utf8ToString());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n    assertEquals(pool.size(), numThreads);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9","date":1498028748,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPayloads#testThreadSafety().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPayloads#testThreadSafety().mjava","sourceNew":"  public void testThreadSafety() throws Exception {\n    final int numThreads = 5;\n    final int numDocs = atLeast(50);\n    final ByteArrayPool pool = new ByteArrayPool(numThreads, 5);\n\n    Directory dir = newDirectory();\n    final IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    final String field = \"test\";\n        \n    Thread[] ingesters = new Thread[numThreads];\n    for (int i = 0; i < numThreads; i++) {\n      ingesters[i] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              for (int j = 0; j < numDocs; j++) {\n                Document d = new Document();\n                d.add(new TextField(field, new PoolingPayloadTokenStream(pool)));\n                writer.addDocument(d);\n              }\n            } catch (Exception e) {\n              e.printStackTrace();\n              fail(e.toString());\n            }\n          }\n        };\n      ingesters[i].start();\n    }\n        \n    for (int i = 0; i < numThreads; i++) {\n      ingesters[i].join();\n    }\n    writer.close();\n    IndexReader reader = DirectoryReader.open(dir);\n    TermsEnum terms = MultiFields.getTerms(reader, field).iterator();\n    PostingsEnum tp = null;\n    while (terms.next() != null) {\n      String termText = terms.term().utf8ToString();\n      tp = terms.postings(tp, PostingsEnum.PAYLOADS);\n      while(tp.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n        int freq = tp.freq();\n        for (int i = 0; i < freq; i++) {\n          tp.nextPosition();\n          final BytesRef payload = tp.getPayload();\n          assertEquals(termText, payload.utf8ToString());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n    assertEquals(pool.size(), numThreads);\n  }\n\n","sourceOld":"  public void testThreadSafety() throws Exception {\n    final int numThreads = 5;\n    final int numDocs = atLeast(50);\n    final ByteArrayPool pool = new ByteArrayPool(numThreads, 5);\n\n    Directory dir = newDirectory();\n    final IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    final String field = \"test\";\n        \n    Thread[] ingesters = new Thread[numThreads];\n    for (int i = 0; i < numThreads; i++) {\n      ingesters[i] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              for (int j = 0; j < numDocs; j++) {\n                Document d = new Document();\n                d.add(new TextField(field, new PoolingPayloadTokenStream(pool)));\n                writer.addDocument(d);\n              }\n            } catch (Exception e) {\n              e.printStackTrace();\n              fail(e.toString());\n            }\n          }\n        };\n      ingesters[i].start();\n    }\n        \n    for (int i = 0; i < numThreads; i++) {\n      ingesters[i].join();\n    }\n    writer.close();\n    IndexReader reader = DirectoryReader.open(dir);\n    TermsEnum terms = MultiFields.getFields(reader).terms(field).iterator();\n    PostingsEnum tp = null;\n    while (terms.next() != null) {\n      String termText = terms.term().utf8ToString();\n      tp = terms.postings(tp, PostingsEnum.PAYLOADS);\n      while(tp.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n        int freq = tp.freq();\n        for (int i = 0; i < freq; i++) {\n          tp.nextPosition();\n          final BytesRef payload = tp.getPayload();\n          assertEquals(termText, payload.utf8ToString());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n    assertEquals(pool.size(), numThreads);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"28288370235ed02234a64753cdbf0c6ec096304a","date":1498726817,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPayloads#testThreadSafety().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPayloads#testThreadSafety().mjava","sourceNew":"  public void testThreadSafety() throws Exception {\n    final int numThreads = 5;\n    final int numDocs = atLeast(50);\n    final ByteArrayPool pool = new ByteArrayPool(numThreads, 5);\n\n    Directory dir = newDirectory();\n    final IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    final String field = \"test\";\n        \n    Thread[] ingesters = new Thread[numThreads];\n    for (int i = 0; i < numThreads; i++) {\n      ingesters[i] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              for (int j = 0; j < numDocs; j++) {\n                Document d = new Document();\n                d.add(new TextField(field, new PoolingPayloadTokenStream(pool)));\n                writer.addDocument(d);\n              }\n            } catch (Exception e) {\n              e.printStackTrace();\n              fail(e.toString());\n            }\n          }\n        };\n      ingesters[i].start();\n    }\n        \n    for (int i = 0; i < numThreads; i++) {\n      ingesters[i].join();\n    }\n    writer.close();\n    IndexReader reader = DirectoryReader.open(dir);\n    TermsEnum terms = MultiFields.getTerms(reader, field).iterator();\n    PostingsEnum tp = null;\n    while (terms.next() != null) {\n      String termText = terms.term().utf8ToString();\n      tp = terms.postings(tp, PostingsEnum.PAYLOADS);\n      while(tp.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n        int freq = tp.freq();\n        for (int i = 0; i < freq; i++) {\n          tp.nextPosition();\n          final BytesRef payload = tp.getPayload();\n          assertEquals(termText, payload.utf8ToString());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n    assertEquals(pool.size(), numThreads);\n  }\n\n","sourceOld":"  public void testThreadSafety() throws Exception {\n    final int numThreads = 5;\n    final int numDocs = atLeast(50);\n    final ByteArrayPool pool = new ByteArrayPool(numThreads, 5);\n\n    Directory dir = newDirectory();\n    final IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    final String field = \"test\";\n        \n    Thread[] ingesters = new Thread[numThreads];\n    for (int i = 0; i < numThreads; i++) {\n      ingesters[i] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              for (int j = 0; j < numDocs; j++) {\n                Document d = new Document();\n                d.add(new TextField(field, new PoolingPayloadTokenStream(pool)));\n                writer.addDocument(d);\n              }\n            } catch (Exception e) {\n              e.printStackTrace();\n              fail(e.toString());\n            }\n          }\n        };\n      ingesters[i].start();\n    }\n        \n    for (int i = 0; i < numThreads; i++) {\n      ingesters[i].join();\n    }\n    writer.close();\n    IndexReader reader = DirectoryReader.open(dir);\n    TermsEnum terms = MultiFields.getFields(reader).terms(field).iterator();\n    PostingsEnum tp = null;\n    while (terms.next() != null) {\n      String termText = terms.term().utf8ToString();\n      tp = terms.postings(tp, PostingsEnum.PAYLOADS);\n      while(tp.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n        int freq = tp.freq();\n        for (int i = 0; i < freq; i++) {\n          tp.nextPosition();\n          final BytesRef payload = tp.getPayload();\n          assertEquals(termText, payload.utf8ToString());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n    assertEquals(pool.size(), numThreads);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"04e775de416dd2d8067b10db1c8af975a1d5017e","date":1539906554,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPayloads#testThreadSafety().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPayloads#testThreadSafety().mjava","sourceNew":"  public void testThreadSafety() throws Exception {\n    final int numThreads = 5;\n    final int numDocs = atLeast(50);\n    final ByteArrayPool pool = new ByteArrayPool(numThreads, 5);\n\n    Directory dir = newDirectory();\n    final IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    final String field = \"test\";\n        \n    Thread[] ingesters = new Thread[numThreads];\n    for (int i = 0; i < numThreads; i++) {\n      ingesters[i] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              for (int j = 0; j < numDocs; j++) {\n                Document d = new Document();\n                d.add(new TextField(field, new PoolingPayloadTokenStream(pool)));\n                writer.addDocument(d);\n              }\n            } catch (Exception e) {\n              e.printStackTrace();\n              fail(e.toString());\n            }\n          }\n        };\n      ingesters[i].start();\n    }\n        \n    for (int i = 0; i < numThreads; i++) {\n      ingesters[i].join();\n    }\n    writer.close();\n    IndexReader reader = DirectoryReader.open(dir);\n    TermsEnum terms = MultiTerms.getTerms(reader, field).iterator();\n    PostingsEnum tp = null;\n    while (terms.next() != null) {\n      String termText = terms.term().utf8ToString();\n      tp = terms.postings(tp, PostingsEnum.PAYLOADS);\n      while(tp.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n        int freq = tp.freq();\n        for (int i = 0; i < freq; i++) {\n          tp.nextPosition();\n          final BytesRef payload = tp.getPayload();\n          assertEquals(termText, payload.utf8ToString());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n    assertEquals(pool.size(), numThreads);\n  }\n\n","sourceOld":"  public void testThreadSafety() throws Exception {\n    final int numThreads = 5;\n    final int numDocs = atLeast(50);\n    final ByteArrayPool pool = new ByteArrayPool(numThreads, 5);\n\n    Directory dir = newDirectory();\n    final IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    final String field = \"test\";\n        \n    Thread[] ingesters = new Thread[numThreads];\n    for (int i = 0; i < numThreads; i++) {\n      ingesters[i] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              for (int j = 0; j < numDocs; j++) {\n                Document d = new Document();\n                d.add(new TextField(field, new PoolingPayloadTokenStream(pool)));\n                writer.addDocument(d);\n              }\n            } catch (Exception e) {\n              e.printStackTrace();\n              fail(e.toString());\n            }\n          }\n        };\n      ingesters[i].start();\n    }\n        \n    for (int i = 0; i < numThreads; i++) {\n      ingesters[i].join();\n    }\n    writer.close();\n    IndexReader reader = DirectoryReader.open(dir);\n    TermsEnum terms = MultiFields.getTerms(reader, field).iterator();\n    PostingsEnum tp = null;\n    while (terms.next() != null) {\n      String termText = terms.term().utf8ToString();\n      tp = terms.postings(tp, PostingsEnum.PAYLOADS);\n      while(tp.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n        int freq = tp.freq();\n        for (int i = 0; i < freq; i++) {\n          tp.nextPosition();\n          final BytesRef payload = tp.getPayload();\n          assertEquals(termText, payload.utf8ToString());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n    assertEquals(pool.size(), numThreads);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82":["e73063b92d958076ef4ae8beb5f493e8ccdcecb4"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"e588e8c82e32e29ef3837c0b06a2ad34f3c51a2b":["0f4464508ee83288c8c4585b533f9faaa93aa314"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"51f5280f31484820499077f41fcdfe92d527d9dc":["5c1c5aa8e88aa52c9e1cbfc696b611d3a56223c0"],"28288370235ed02234a64753cdbf0c6ec096304a":["0f4464508ee83288c8c4585b533f9faaa93aa314","e588e8c82e32e29ef3837c0b06a2ad34f3c51a2b"],"5c1c5aa8e88aa52c9e1cbfc696b611d3a56223c0":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"0f4464508ee83288c8c4585b533f9faaa93aa314":["0a773283ef5eab2e9c7136eeb66574a4b7a2dc82"],"e73063b92d958076ef4ae8beb5f493e8ccdcecb4":["51f5280f31484820499077f41fcdfe92d527d9dc"],"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f":["e7e8d6f15900ee22ac3cb0a503f15dc952a3580f","322360ac5185a8446d3e0b530b2068bef67cd3d5"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":["e7e8d6f15900ee22ac3cb0a503f15dc952a3580f","322360ac5185a8446d3e0b530b2068bef67cd3d5"],"04e775de416dd2d8067b10db1c8af975a1d5017e":["28288370235ed02234a64753cdbf0c6ec096304a"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["322360ac5185a8446d3e0b530b2068bef67cd3d5"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"322360ac5185a8446d3e0b530b2068bef67cd3d5":["e7e8d6f15900ee22ac3cb0a503f15dc952a3580f"],"2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9":["0f4464508ee83288c8c4585b533f9faaa93aa314","e588e8c82e32e29ef3837c0b06a2ad34f3c51a2b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["04e775de416dd2d8067b10db1c8af975a1d5017e"]},"commit2Childs":{"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82":["0f4464508ee83288c8c4585b533f9faaa93aa314"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"e588e8c82e32e29ef3837c0b06a2ad34f3c51a2b":["28288370235ed02234a64753cdbf0c6ec096304a","2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"51f5280f31484820499077f41fcdfe92d527d9dc":["e73063b92d958076ef4ae8beb5f493e8ccdcecb4"],"28288370235ed02234a64753cdbf0c6ec096304a":["04e775de416dd2d8067b10db1c8af975a1d5017e"],"5c1c5aa8e88aa52c9e1cbfc696b611d3a56223c0":["51f5280f31484820499077f41fcdfe92d527d9dc"],"e73063b92d958076ef4ae8beb5f493e8ccdcecb4":["0a773283ef5eab2e9c7136eeb66574a4b7a2dc82"],"0f4464508ee83288c8c4585b533f9faaa93aa314":["e588e8c82e32e29ef3837c0b06a2ad34f3c51a2b","28288370235ed02234a64753cdbf0c6ec096304a","2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9"],"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f":["b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","d6f074e73200c07d54f242d3880a8da5a35ff97b","322360ac5185a8446d3e0b530b2068bef67cd3d5"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["5c1c5aa8e88aa52c9e1cbfc696b611d3a56223c0"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":[],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"04e775de416dd2d8067b10db1c8af975a1d5017e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["e7e8d6f15900ee22ac3cb0a503f15dc952a3580f"],"322360ac5185a8446d3e0b530b2068bef67cd3d5":["b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","d6f074e73200c07d54f242d3880a8da5a35ff97b","ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","d6f074e73200c07d54f242d3880a8da5a35ff97b","2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}