{"path":"lucene/queries/src/test/org/apache/lucene/queries/TermFilterTest#testRandom().mjava","commits":[{"id":"285b9ca1f111d4ee6cc336e5fe7db6ab94a16a70","date":1374000182,"type":0,"author":"Martijn van Groningen","isMerge":false,"pathNew":"lucene/queries/src/test/org/apache/lucene/queries/TermFilterTest#testRandom().mjava","pathOld":"/dev/null","sourceNew":"  public void testRandom() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    int num = atLeast(100);\n    List<Term> terms = new ArrayList<Term>();\n    for (int i = 0; i < num; i++) {\n      String field = \"field\" + i;\n      String string = _TestUtil.randomRealisticUnicodeString(random());\n      terms.add(new Term(field, string));\n      Document doc = new Document();\n      doc.add(newStringField(field, string, Field.Store.NO));\n      w.addDocument(doc);\n    }\n    IndexReader reader = w.getReader();\n    w.close();\n    \n    IndexSearcher searcher = newSearcher(reader);\n    \n    int numQueries = atLeast(10);\n    for (int i = 0; i < numQueries; i++) {\n      Term term = terms.get(random().nextInt(num));\n      TopDocs queryResult = searcher.search(new TermQuery(term), reader.maxDoc());\n      \n      MatchAllDocsQuery matchAll = new MatchAllDocsQuery();\n      final TermFilter filter = termFilter(term);\n      TopDocs filterResult = searcher.search(matchAll, filter, reader.maxDoc());\n      assertEquals(filterResult.totalHits, queryResult.totalHits);\n      ScoreDoc[] scoreDocs = filterResult.scoreDocs;\n      for (int j = 0; j < scoreDocs.length; j++) {\n        assertEquals(scoreDocs[j].doc, queryResult.scoreDocs[j].doc);\n      }\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","date":1376366778,"type":0,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/queries/src/test/org/apache/lucene/queries/TermFilterTest#testRandom().mjava","pathOld":"/dev/null","sourceNew":"  public void testRandom() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    int num = atLeast(100);\n    List<Term> terms = new ArrayList<Term>();\n    for (int i = 0; i < num; i++) {\n      String field = \"field\" + i;\n      String string = _TestUtil.randomRealisticUnicodeString(random());\n      terms.add(new Term(field, string));\n      Document doc = new Document();\n      doc.add(newStringField(field, string, Field.Store.NO));\n      w.addDocument(doc);\n    }\n    IndexReader reader = w.getReader();\n    w.close();\n    \n    IndexSearcher searcher = newSearcher(reader);\n    \n    int numQueries = atLeast(10);\n    for (int i = 0; i < numQueries; i++) {\n      Term term = terms.get(random().nextInt(num));\n      TopDocs queryResult = searcher.search(new TermQuery(term), reader.maxDoc());\n      \n      MatchAllDocsQuery matchAll = new MatchAllDocsQuery();\n      final TermFilter filter = termFilter(term);\n      TopDocs filterResult = searcher.search(matchAll, filter, reader.maxDoc());\n      assertEquals(filterResult.totalHits, queryResult.totalHits);\n      ScoreDoc[] scoreDocs = filterResult.scoreDocs;\n      for (int j = 0; j < scoreDocs.length; j++) {\n        assertEquals(scoreDocs[j].doc, queryResult.scoreDocs[j].doc);\n      }\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6613659748fe4411a7dcf85266e55db1f95f7315","date":1392773913,"type":3,"author":"Benson Margulies","isMerge":false,"pathNew":"lucene/queries/src/test/org/apache/lucene/queries/TermFilterTest#testRandom().mjava","pathOld":"lucene/queries/src/test/org/apache/lucene/queries/TermFilterTest#testRandom().mjava","sourceNew":"  public void testRandom() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    int num = atLeast(100);\n    List<Term> terms = new ArrayList<Term>();\n    for (int i = 0; i < num; i++) {\n      String field = \"field\" + i;\n      String string = TestUtil.randomRealisticUnicodeString(random());\n      terms.add(new Term(field, string));\n      Document doc = new Document();\n      doc.add(newStringField(field, string, Field.Store.NO));\n      w.addDocument(doc);\n    }\n    IndexReader reader = w.getReader();\n    w.close();\n    \n    IndexSearcher searcher = newSearcher(reader);\n    \n    int numQueries = atLeast(10);\n    for (int i = 0; i < numQueries; i++) {\n      Term term = terms.get(random().nextInt(num));\n      TopDocs queryResult = searcher.search(new TermQuery(term), reader.maxDoc());\n      \n      MatchAllDocsQuery matchAll = new MatchAllDocsQuery();\n      final TermFilter filter = termFilter(term);\n      TopDocs filterResult = searcher.search(matchAll, filter, reader.maxDoc());\n      assertEquals(filterResult.totalHits, queryResult.totalHits);\n      ScoreDoc[] scoreDocs = filterResult.scoreDocs;\n      for (int j = 0; j < scoreDocs.length; j++) {\n        assertEquals(scoreDocs[j].doc, queryResult.scoreDocs[j].doc);\n      }\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandom() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    int num = atLeast(100);\n    List<Term> terms = new ArrayList<Term>();\n    for (int i = 0; i < num; i++) {\n      String field = \"field\" + i;\n      String string = _TestUtil.randomRealisticUnicodeString(random());\n      terms.add(new Term(field, string));\n      Document doc = new Document();\n      doc.add(newStringField(field, string, Field.Store.NO));\n      w.addDocument(doc);\n    }\n    IndexReader reader = w.getReader();\n    w.close();\n    \n    IndexSearcher searcher = newSearcher(reader);\n    \n    int numQueries = atLeast(10);\n    for (int i = 0; i < numQueries; i++) {\n      Term term = terms.get(random().nextInt(num));\n      TopDocs queryResult = searcher.search(new TermQuery(term), reader.maxDoc());\n      \n      MatchAllDocsQuery matchAll = new MatchAllDocsQuery();\n      final TermFilter filter = termFilter(term);\n      TopDocs filterResult = searcher.search(matchAll, filter, reader.maxDoc());\n      assertEquals(filterResult.totalHits, queryResult.totalHits);\n      ScoreDoc[] scoreDocs = filterResult.scoreDocs;\n      for (int j = 0; j < scoreDocs.length; j++) {\n        assertEquals(scoreDocs[j].doc, queryResult.scoreDocs[j].doc);\n      }\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/queries/src/test/org/apache/lucene/queries/TermFilterTest#testRandom().mjava","pathOld":"lucene/queries/src/test/org/apache/lucene/queries/TermFilterTest#testRandom().mjava","sourceNew":"  public void testRandom() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    int num = atLeast(100);\n    List<Term> terms = new ArrayList<>();\n    for (int i = 0; i < num; i++) {\n      String field = \"field\" + i;\n      String string = TestUtil.randomRealisticUnicodeString(random());\n      terms.add(new Term(field, string));\n      Document doc = new Document();\n      doc.add(newStringField(field, string, Field.Store.NO));\n      w.addDocument(doc);\n    }\n    IndexReader reader = w.getReader();\n    w.close();\n    \n    IndexSearcher searcher = newSearcher(reader);\n    \n    int numQueries = atLeast(10);\n    for (int i = 0; i < numQueries; i++) {\n      Term term = terms.get(random().nextInt(num));\n      TopDocs queryResult = searcher.search(new TermQuery(term), reader.maxDoc());\n      \n      MatchAllDocsQuery matchAll = new MatchAllDocsQuery();\n      final TermFilter filter = termFilter(term);\n      TopDocs filterResult = searcher.search(matchAll, filter, reader.maxDoc());\n      assertEquals(filterResult.totalHits, queryResult.totalHits);\n      ScoreDoc[] scoreDocs = filterResult.scoreDocs;\n      for (int j = 0; j < scoreDocs.length; j++) {\n        assertEquals(scoreDocs[j].doc, queryResult.scoreDocs[j].doc);\n      }\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandom() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    int num = atLeast(100);\n    List<Term> terms = new ArrayList<Term>();\n    for (int i = 0; i < num; i++) {\n      String field = \"field\" + i;\n      String string = TestUtil.randomRealisticUnicodeString(random());\n      terms.add(new Term(field, string));\n      Document doc = new Document();\n      doc.add(newStringField(field, string, Field.Store.NO));\n      w.addDocument(doc);\n    }\n    IndexReader reader = w.getReader();\n    w.close();\n    \n    IndexSearcher searcher = newSearcher(reader);\n    \n    int numQueries = atLeast(10);\n    for (int i = 0; i < numQueries; i++) {\n      Term term = terms.get(random().nextInt(num));\n      TopDocs queryResult = searcher.search(new TermQuery(term), reader.maxDoc());\n      \n      MatchAllDocsQuery matchAll = new MatchAllDocsQuery();\n      final TermFilter filter = termFilter(term);\n      TopDocs filterResult = searcher.search(matchAll, filter, reader.maxDoc());\n      assertEquals(filterResult.totalHits, queryResult.totalHits);\n      ScoreDoc[] scoreDocs = filterResult.scoreDocs;\n      for (int j = 0; j < scoreDocs.length; j++) {\n        assertEquals(scoreDocs[j].doc, queryResult.scoreDocs[j].doc);\n      }\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/queries/src/test/org/apache/lucene/queries/TermFilterTest#testRandom().mjava","pathOld":"lucene/queries/src/test/org/apache/lucene/queries/TermFilterTest#testRandom().mjava","sourceNew":"  public void testRandom() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    int num = atLeast(100);\n    List<Term> terms = new ArrayList<>();\n    for (int i = 0; i < num; i++) {\n      String field = \"field\" + i;\n      String string = TestUtil.randomRealisticUnicodeString(random());\n      terms.add(new Term(field, string));\n      Document doc = new Document();\n      doc.add(newStringField(field, string, Field.Store.NO));\n      w.addDocument(doc);\n    }\n    IndexReader reader = w.getReader();\n    w.shutdown();\n    \n    IndexSearcher searcher = newSearcher(reader);\n    \n    int numQueries = atLeast(10);\n    for (int i = 0; i < numQueries; i++) {\n      Term term = terms.get(random().nextInt(num));\n      TopDocs queryResult = searcher.search(new TermQuery(term), reader.maxDoc());\n      \n      MatchAllDocsQuery matchAll = new MatchAllDocsQuery();\n      final TermFilter filter = termFilter(term);\n      TopDocs filterResult = searcher.search(matchAll, filter, reader.maxDoc());\n      assertEquals(filterResult.totalHits, queryResult.totalHits);\n      ScoreDoc[] scoreDocs = filterResult.scoreDocs;\n      for (int j = 0; j < scoreDocs.length; j++) {\n        assertEquals(scoreDocs[j].doc, queryResult.scoreDocs[j].doc);\n      }\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandom() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    int num = atLeast(100);\n    List<Term> terms = new ArrayList<>();\n    for (int i = 0; i < num; i++) {\n      String field = \"field\" + i;\n      String string = TestUtil.randomRealisticUnicodeString(random());\n      terms.add(new Term(field, string));\n      Document doc = new Document();\n      doc.add(newStringField(field, string, Field.Store.NO));\n      w.addDocument(doc);\n    }\n    IndexReader reader = w.getReader();\n    w.close();\n    \n    IndexSearcher searcher = newSearcher(reader);\n    \n    int numQueries = atLeast(10);\n    for (int i = 0; i < numQueries; i++) {\n      Term term = terms.get(random().nextInt(num));\n      TopDocs queryResult = searcher.search(new TermQuery(term), reader.maxDoc());\n      \n      MatchAllDocsQuery matchAll = new MatchAllDocsQuery();\n      final TermFilter filter = termFilter(term);\n      TopDocs filterResult = searcher.search(matchAll, filter, reader.maxDoc());\n      assertEquals(filterResult.totalHits, queryResult.totalHits);\n      ScoreDoc[] scoreDocs = filterResult.scoreDocs;\n      for (int j = 0; j < scoreDocs.length; j++) {\n        assertEquals(scoreDocs[j].doc, queryResult.scoreDocs[j].doc);\n      }\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/queries/src/test/org/apache/lucene/queries/TermFilterTest#testRandom().mjava","pathOld":"lucene/queries/src/test/org/apache/lucene/queries/TermFilterTest#testRandom().mjava","sourceNew":"  public void testRandom() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    int num = atLeast(100);\n    List<Term> terms = new ArrayList<>();\n    for (int i = 0; i < num; i++) {\n      String field = \"field\" + i;\n      String string = TestUtil.randomRealisticUnicodeString(random());\n      terms.add(new Term(field, string));\n      Document doc = new Document();\n      doc.add(newStringField(field, string, Field.Store.NO));\n      w.addDocument(doc);\n    }\n    IndexReader reader = w.getReader();\n    w.close();\n    \n    IndexSearcher searcher = newSearcher(reader);\n    \n    int numQueries = atLeast(10);\n    for (int i = 0; i < numQueries; i++) {\n      Term term = terms.get(random().nextInt(num));\n      TopDocs queryResult = searcher.search(new TermQuery(term), reader.maxDoc());\n      \n      MatchAllDocsQuery matchAll = new MatchAllDocsQuery();\n      final TermFilter filter = termFilter(term);\n      TopDocs filterResult = searcher.search(matchAll, filter, reader.maxDoc());\n      assertEquals(filterResult.totalHits, queryResult.totalHits);\n      ScoreDoc[] scoreDocs = filterResult.scoreDocs;\n      for (int j = 0; j < scoreDocs.length; j++) {\n        assertEquals(scoreDocs[j].doc, queryResult.scoreDocs[j].doc);\n      }\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandom() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    int num = atLeast(100);\n    List<Term> terms = new ArrayList<>();\n    for (int i = 0; i < num; i++) {\n      String field = \"field\" + i;\n      String string = TestUtil.randomRealisticUnicodeString(random());\n      terms.add(new Term(field, string));\n      Document doc = new Document();\n      doc.add(newStringField(field, string, Field.Store.NO));\n      w.addDocument(doc);\n    }\n    IndexReader reader = w.getReader();\n    w.shutdown();\n    \n    IndexSearcher searcher = newSearcher(reader);\n    \n    int numQueries = atLeast(10);\n    for (int i = 0; i < numQueries; i++) {\n      Term term = terms.get(random().nextInt(num));\n      TopDocs queryResult = searcher.search(new TermQuery(term), reader.maxDoc());\n      \n      MatchAllDocsQuery matchAll = new MatchAllDocsQuery();\n      final TermFilter filter = termFilter(term);\n      TopDocs filterResult = searcher.search(matchAll, filter, reader.maxDoc());\n      assertEquals(filterResult.totalHits, queryResult.totalHits);\n      ScoreDoc[] scoreDocs = filterResult.scoreDocs;\n      for (int j = 0; j < scoreDocs.length; j++) {\n        assertEquals(scoreDocs[j].doc, queryResult.scoreDocs[j].doc);\n      }\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"589f939c50213ffd758060ded12e334c85ef6a87","date":1423239999,"type":4,"author":"Adrien Grand","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/queries/src/test/org/apache/lucene/queries/TermFilterTest#testRandom().mjava","sourceNew":null,"sourceOld":"  public void testRandom() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    int num = atLeast(100);\n    List<Term> terms = new ArrayList<>();\n    for (int i = 0; i < num; i++) {\n      String field = \"field\" + i;\n      String string = TestUtil.randomRealisticUnicodeString(random());\n      terms.add(new Term(field, string));\n      Document doc = new Document();\n      doc.add(newStringField(field, string, Field.Store.NO));\n      w.addDocument(doc);\n    }\n    IndexReader reader = w.getReader();\n    w.close();\n    \n    IndexSearcher searcher = newSearcher(reader);\n    \n    int numQueries = atLeast(10);\n    for (int i = 0; i < numQueries; i++) {\n      Term term = terms.get(random().nextInt(num));\n      TopDocs queryResult = searcher.search(new TermQuery(term), reader.maxDoc());\n      \n      MatchAllDocsQuery matchAll = new MatchAllDocsQuery();\n      final TermFilter filter = termFilter(term);\n      TopDocs filterResult = searcher.search(matchAll, filter, reader.maxDoc());\n      assertEquals(filterResult.totalHits, queryResult.totalHits);\n      ScoreDoc[] scoreDocs = filterResult.scoreDocs;\n      for (int j = 0; j < scoreDocs.length; j++) {\n        assertEquals(scoreDocs[j].doc, queryResult.scoreDocs[j].doc);\n      }\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["6613659748fe4411a7dcf85266e55db1f95f7315"],"285b9ca1f111d4ee6cc336e5fe7db6ab94a16a70":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"6613659748fe4411a7dcf85266e55db1f95f7315":["285b9ca1f111d4ee6cc336e5fe7db6ab94a16a70"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"589f939c50213ffd758060ded12e334c85ef6a87":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["589f939c50213ffd758060ded12e334c85ef6a87"]},"commit2Childs":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"285b9ca1f111d4ee6cc336e5fe7db6ab94a16a70":["6613659748fe4411a7dcf85266e55db1f95f7315"],"6613659748fe4411a7dcf85266e55db1f95f7315":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["285b9ca1f111d4ee6cc336e5fe7db6ab94a16a70","8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["589f939c50213ffd758060ded12e334c85ef6a87"],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":[],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"589f939c50213ffd758060ded12e334c85ef6a87":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}