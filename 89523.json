{"path":"lucene/core/src/test/org/apache/lucene/analysis/TestGraphTokenizers#testMockGraphTokenFilterBeforeHolesRandom().mjava","commits":[{"id":"6795c6bc2f5a6b2a2230cb20ff4744003faf7802","date":1333839972,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/analysis/TestGraphTokenizers#testMockGraphTokenFilterBeforeHolesRandom().mjava","pathOld":"/dev/null","sourceNew":"  public void testMockGraphTokenFilterBeforeHolesRandom() throws Exception {\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n\n      // Make new analyzer each time, because MGTF has fixed\n      // seed:\n      final Analyzer a = new Analyzer() {\n          @Override\n          protected TokenStreamComponents createComponents(String fieldName, Reader reader) {\n            final Tokenizer t = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);\n            final TokenStream t1 = new MockGraphTokenFilter(random, t);\n            final TokenStream t2 = new MockHoleInjectingTokenFilter(random, t1);\n            return new TokenStreamComponents(t, t2);\n          }\n        };\n      \n      checkRandomData(random, a, 5, atLeast(1000));\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/analysis/TestGraphTokenizers#testMockGraphTokenFilterBeforeHolesRandom().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/analysis/TestGraphTokenizers#testMockGraphTokenFilterBeforeHolesRandom().mjava","sourceNew":"  public void testMockGraphTokenFilterBeforeHolesRandom() throws Exception {\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n\n      // Make new analyzer each time, because MGTF has fixed\n      // seed:\n      final Analyzer a = new Analyzer() {\n          @Override\n          protected TokenStreamComponents createComponents(String fieldName, Reader reader) {\n            final Tokenizer t = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);\n            final TokenStream t1 = new MockGraphTokenFilter(random(), t);\n            final TokenStream t2 = new MockHoleInjectingTokenFilter(random(), t1);\n            return new TokenStreamComponents(t, t2);\n          }\n        };\n      \n      Random random = random();\n      checkRandomData(random, a, 5, atLeast(1000));\n    }\n  }\n\n","sourceOld":"  public void testMockGraphTokenFilterBeforeHolesRandom() throws Exception {\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n\n      // Make new analyzer each time, because MGTF has fixed\n      // seed:\n      final Analyzer a = new Analyzer() {\n          @Override\n          protected TokenStreamComponents createComponents(String fieldName, Reader reader) {\n            final Tokenizer t = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);\n            final TokenStream t1 = new MockGraphTokenFilter(random, t);\n            final TokenStream t2 = new MockHoleInjectingTokenFilter(random, t1);\n            return new TokenStreamComponents(t, t2);\n          }\n        };\n      \n      checkRandomData(random, a, 5, atLeast(1000));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"86658da8ce1e761bc0f5a05cf8795d1f78c388e2","date":1365796110,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/analysis/TestGraphTokenizers#testMockGraphTokenFilterBeforeHolesRandom().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/analysis/TestGraphTokenizers#testMockGraphTokenFilterBeforeHolesRandom().mjava","sourceNew":"  public void testMockGraphTokenFilterBeforeHolesRandom() throws Exception {\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n\n      // Make new analyzer each time, because MGTF has fixed\n      // seed:\n      final Analyzer a = new Analyzer() {\n          @Override\n          protected TokenStreamComponents createComponents(String fieldName, Reader reader) {\n            final Tokenizer t = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);\n            final TokenStream t1 = new MockGraphTokenFilter(random(), t);\n            final TokenStream t2 = new MockHoleInjectingTokenFilter(random(), t1);\n            return new TokenStreamComponents(t, t2);\n          }\n        };\n      \n      Random random = random();\n      checkRandomData(random, a, 5, atLeast(100));\n    }\n  }\n\n","sourceOld":"  public void testMockGraphTokenFilterBeforeHolesRandom() throws Exception {\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n\n      // Make new analyzer each time, because MGTF has fixed\n      // seed:\n      final Analyzer a = new Analyzer() {\n          @Override\n          protected TokenStreamComponents createComponents(String fieldName, Reader reader) {\n            final Tokenizer t = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);\n            final TokenStream t1 = new MockGraphTokenFilter(random(), t);\n            final TokenStream t2 = new MockHoleInjectingTokenFilter(random(), t1);\n            return new TokenStreamComponents(t, t2);\n          }\n        };\n      \n      Random random = random();\n      checkRandomData(random, a, 5, atLeast(1000));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae889fd5c8a69f6b5d130d3c895bfa5b04d07338","date":1389274049,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/analysis/TestGraphTokenizers#testMockGraphTokenFilterBeforeHolesRandom().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/analysis/TestGraphTokenizers#testMockGraphTokenFilterBeforeHolesRandom().mjava","sourceNew":"  public void testMockGraphTokenFilterBeforeHolesRandom() throws Exception {\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n\n      // Make new analyzer each time, because MGTF has fixed\n      // seed:\n      final Analyzer a = new Analyzer() {\n          @Override\n          protected TokenStreamComponents createComponents(String fieldName) {\n            final Tokenizer t = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n            final TokenStream t1 = new MockGraphTokenFilter(random(), t);\n            final TokenStream t2 = new MockHoleInjectingTokenFilter(random(), t1);\n            return new TokenStreamComponents(t, t2);\n          }\n        };\n      \n      Random random = random();\n      checkRandomData(random, a, 5, atLeast(100));\n    }\n  }\n\n","sourceOld":"  public void testMockGraphTokenFilterBeforeHolesRandom() throws Exception {\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n\n      // Make new analyzer each time, because MGTF has fixed\n      // seed:\n      final Analyzer a = new Analyzer() {\n          @Override\n          protected TokenStreamComponents createComponents(String fieldName, Reader reader) {\n            final Tokenizer t = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);\n            final TokenStream t1 = new MockGraphTokenFilter(random(), t);\n            final TokenStream t2 = new MockHoleInjectingTokenFilter(random(), t1);\n            return new TokenStreamComponents(t, t2);\n          }\n        };\n      \n      Random random = random();\n      checkRandomData(random, a, 5, atLeast(100));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6e4b7ec2c9e255a912a3c37dbd8300f77ba2f046","date":1417033646,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/analysis/TestGraphTokenizers#testMockGraphTokenFilterBeforeHolesRandom().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/analysis/TestGraphTokenizers#testMockGraphTokenFilterBeforeHolesRandom().mjava","sourceNew":"  public void testMockGraphTokenFilterBeforeHolesRandom() throws Exception {\n    for(int iter=0;iter<3*RANDOM_MULTIPLIER;iter++) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n\n      // Make new analyzer each time, because MGTF has fixed\n      // seed:\n      final Analyzer a = new Analyzer() {\n          @Override\n          protected TokenStreamComponents createComponents(String fieldName) {\n            final Tokenizer t = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n            final TokenStream t1 = new MockGraphTokenFilter(random(), t);\n            final TokenStream t2 = new MockHoleInjectingTokenFilter(random(), t1);\n            return new TokenStreamComponents(t, t2);\n          }\n        };\n      \n      Random random = random();\n      checkRandomData(random, a, 5, atLeast(100));\n    }\n  }\n\n","sourceOld":"  public void testMockGraphTokenFilterBeforeHolesRandom() throws Exception {\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n\n      // Make new analyzer each time, because MGTF has fixed\n      // seed:\n      final Analyzer a = new Analyzer() {\n          @Override\n          protected TokenStreamComponents createComponents(String fieldName) {\n            final Tokenizer t = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n            final TokenStream t1 = new MockGraphTokenFilter(random(), t);\n            final TokenStream t2 = new MockHoleInjectingTokenFilter(random(), t1);\n            return new TokenStreamComponents(t, t2);\n          }\n        };\n      \n      Random random = random();\n      checkRandomData(random, a, 5, atLeast(100));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b52491e71f0d5d0f0160d6ed0d39e0dd661be68a","date":1429550638,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/test-framework/src/test/org/apache/lucene/analysis/TestGraphTokenizers#testMockGraphTokenFilterBeforeHolesRandom().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/analysis/TestGraphTokenizers#testMockGraphTokenFilterBeforeHolesRandom().mjava","sourceNew":"  public void testMockGraphTokenFilterBeforeHolesRandom() throws Exception {\n    for(int iter=0;iter<3*RANDOM_MULTIPLIER;iter++) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n\n      // Make new analyzer each time, because MGTF has fixed\n      // seed:\n      final Analyzer a = new Analyzer() {\n          @Override\n          protected TokenStreamComponents createComponents(String fieldName) {\n            final Tokenizer t = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n            final TokenStream t1 = new MockGraphTokenFilter(random(), t);\n            final TokenStream t2 = new MockHoleInjectingTokenFilter(random(), t1);\n            return new TokenStreamComponents(t, t2);\n          }\n        };\n      \n      Random random = random();\n      checkRandomData(random, a, 5, atLeast(100));\n    }\n  }\n\n","sourceOld":"  public void testMockGraphTokenFilterBeforeHolesRandom() throws Exception {\n    for(int iter=0;iter<3*RANDOM_MULTIPLIER;iter++) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n\n      // Make new analyzer each time, because MGTF has fixed\n      // seed:\n      final Analyzer a = new Analyzer() {\n          @Override\n          protected TokenStreamComponents createComponents(String fieldName) {\n            final Tokenizer t = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n            final TokenStream t1 = new MockGraphTokenFilter(random(), t);\n            final TokenStream t2 = new MockHoleInjectingTokenFilter(random(), t1);\n            return new TokenStreamComponents(t, t2);\n          }\n        };\n      \n      Random random = random();\n      checkRandomData(random, a, 5, atLeast(100));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"085e5eccb1e06e3bfb487813880adc54c888dd02","date":1483875517,"type":1,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/analysis/TestGraphTokenizers#testMockGraphTokenFilterBeforeHolesRandom().mjava","pathOld":"lucene/test-framework/src/test/org/apache/lucene/analysis/TestGraphTokenizers#testMockGraphTokenFilterBeforeHolesRandom().mjava","sourceNew":"  public void testMockGraphTokenFilterBeforeHolesRandom() throws Exception {\n    for(int iter=0;iter<3*RANDOM_MULTIPLIER;iter++) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n\n      // Make new analyzer each time, because MGTF has fixed\n      // seed:\n      final Analyzer a = new Analyzer() {\n          @Override\n          protected TokenStreamComponents createComponents(String fieldName) {\n            final Tokenizer t = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n            final TokenStream t1 = new MockGraphTokenFilter(random(), t);\n            final TokenStream t2 = new MockHoleInjectingTokenFilter(random(), t1);\n            return new TokenStreamComponents(t, t2);\n          }\n        };\n      \n      Random random = random();\n      checkRandomData(random, a, 5, atLeast(100));\n    }\n  }\n\n","sourceOld":"  public void testMockGraphTokenFilterBeforeHolesRandom() throws Exception {\n    for(int iter=0;iter<3*RANDOM_MULTIPLIER;iter++) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n\n      // Make new analyzer each time, because MGTF has fixed\n      // seed:\n      final Analyzer a = new Analyzer() {\n          @Override\n          protected TokenStreamComponents createComponents(String fieldName) {\n            final Tokenizer t = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n            final TokenStream t1 = new MockGraphTokenFilter(random(), t);\n            final TokenStream t2 = new MockHoleInjectingTokenFilter(random(), t1);\n            return new TokenStreamComponents(t, t2);\n          }\n        };\n      \n      Random random = random();\n      checkRandomData(random, a, 5, atLeast(100));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"09ab8ee44ca898536770d0106a7c0ee4be4f0eb7","date":1484239864,"type":1,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/analysis/TestGraphTokenizers#testMockGraphTokenFilterBeforeHolesRandom().mjava","pathOld":"lucene/test-framework/src/test/org/apache/lucene/analysis/TestGraphTokenizers#testMockGraphTokenFilterBeforeHolesRandom().mjava","sourceNew":"  public void testMockGraphTokenFilterBeforeHolesRandom() throws Exception {\n    for(int iter=0;iter<3*RANDOM_MULTIPLIER;iter++) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n\n      // Make new analyzer each time, because MGTF has fixed\n      // seed:\n      final Analyzer a = new Analyzer() {\n          @Override\n          protected TokenStreamComponents createComponents(String fieldName) {\n            final Tokenizer t = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n            final TokenStream t1 = new MockGraphTokenFilter(random(), t);\n            final TokenStream t2 = new MockHoleInjectingTokenFilter(random(), t1);\n            return new TokenStreamComponents(t, t2);\n          }\n        };\n      \n      Random random = random();\n      checkRandomData(random, a, 5, atLeast(100));\n    }\n  }\n\n","sourceOld":"  public void testMockGraphTokenFilterBeforeHolesRandom() throws Exception {\n    for(int iter=0;iter<3*RANDOM_MULTIPLIER;iter++) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n\n      // Make new analyzer each time, because MGTF has fixed\n      // seed:\n      final Analyzer a = new Analyzer() {\n          @Override\n          protected TokenStreamComponents createComponents(String fieldName) {\n            final Tokenizer t = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n            final TokenStream t1 = new MockGraphTokenFilter(random(), t);\n            final TokenStream t2 = new MockHoleInjectingTokenFilter(random(), t1);\n            return new TokenStreamComponents(t, t2);\n          }\n        };\n      \n      Random random = random();\n      checkRandomData(random, a, 5, atLeast(100));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"ae889fd5c8a69f6b5d130d3c895bfa5b04d07338":["86658da8ce1e761bc0f5a05cf8795d1f78c388e2"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"6e4b7ec2c9e255a912a3c37dbd8300f77ba2f046":["ae889fd5c8a69f6b5d130d3c895bfa5b04d07338"],"09ab8ee44ca898536770d0106a7c0ee4be4f0eb7":["b52491e71f0d5d0f0160d6ed0d39e0dd661be68a","085e5eccb1e06e3bfb487813880adc54c888dd02"],"b52491e71f0d5d0f0160d6ed0d39e0dd661be68a":["6e4b7ec2c9e255a912a3c37dbd8300f77ba2f046"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["6795c6bc2f5a6b2a2230cb20ff4744003faf7802"],"085e5eccb1e06e3bfb487813880adc54c888dd02":["b52491e71f0d5d0f0160d6ed0d39e0dd661be68a"],"6795c6bc2f5a6b2a2230cb20ff4744003faf7802":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["085e5eccb1e06e3bfb487813880adc54c888dd02"],"86658da8ce1e761bc0f5a05cf8795d1f78c388e2":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"]},"commit2Childs":{"ae889fd5c8a69f6b5d130d3c895bfa5b04d07338":["6e4b7ec2c9e255a912a3c37dbd8300f77ba2f046"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["6795c6bc2f5a6b2a2230cb20ff4744003faf7802"],"6e4b7ec2c9e255a912a3c37dbd8300f77ba2f046":["b52491e71f0d5d0f0160d6ed0d39e0dd661be68a"],"09ab8ee44ca898536770d0106a7c0ee4be4f0eb7":[],"b52491e71f0d5d0f0160d6ed0d39e0dd661be68a":["09ab8ee44ca898536770d0106a7c0ee4be4f0eb7","085e5eccb1e06e3bfb487813880adc54c888dd02"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["86658da8ce1e761bc0f5a05cf8795d1f78c388e2"],"085e5eccb1e06e3bfb487813880adc54c888dd02":["09ab8ee44ca898536770d0106a7c0ee4be4f0eb7","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"6795c6bc2f5a6b2a2230cb20ff4744003faf7802":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"86658da8ce1e761bc0f5a05cf8795d1f78c388e2":["ae889fd5c8a69f6b5d130d3c895bfa5b04d07338"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["09ab8ee44ca898536770d0106a7c0ee4be4f0eb7","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}