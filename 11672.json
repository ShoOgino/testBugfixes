{"path":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader#testOffsetReader().mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader#testOffsetReader().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestTermVectorsReader#testOffsetReader().mjava","sourceNew":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg, fieldInfos, newIOContext(random));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator(null);\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.getUniqueTermCount());\n    DocsAndPositionsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocsEnum.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocsEnum.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, true);\n      assertTrue(dpEnum.nextDoc() != DocsEnum.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocsEnum.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg, fieldInfos, newIOContext(random));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator(null);\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.getUniqueTermCount());\n    DocsAndPositionsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocsEnum.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocsEnum.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, true);\n      assertTrue(dpEnum.nextDoc() != DocsEnum.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocsEnum.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f08557cdb6c60ac7b88a9342c983a20cd236e74f","date":1330954480,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader#testOffsetReader().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader#testOffsetReader().mjava","sourceNew":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg, fieldInfos, newIOContext(random));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator(null);\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.getUniqueTermCount());\n    DocsAndPositionsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, true);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg, fieldInfos, newIOContext(random));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator(null);\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.getUniqueTermCount());\n    DocsAndPositionsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocsEnum.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocsEnum.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, true);\n      assertTrue(dpEnum.nextDoc() != DocsEnum.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocsEnum.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","date":1331075828,"type":3,"author":"Ryan McKinley","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader#testOffsetReader().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader#testOffsetReader().mjava","sourceNew":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg, fieldInfos, newIOContext(random));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator(null);\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.getUniqueTermCount());\n    DocsAndPositionsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, true);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg, fieldInfos, newIOContext(random));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator(null);\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.getUniqueTermCount());\n    DocsAndPositionsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocsEnum.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocsEnum.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, true);\n      assertTrue(dpEnum.nextDoc() != DocsEnum.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocsEnum.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bdb5e42b0cecd8dfb27767a02ada71899bf17917","date":1334100099,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader#testOffsetReader().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader#testOffsetReader().mjava","sourceNew":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg, fieldInfos, newIOContext(random));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator(null);\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.size());\n    DocsAndPositionsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, true);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg, fieldInfos, newIOContext(random));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator(null);\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.getUniqueTermCount());\n    DocsAndPositionsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, true);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5a238fc456663f685a9db1ed8d680e348bb45171","date":1334173266,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader#testOffsetReader().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader#testOffsetReader().mjava","sourceNew":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg, fieldInfos, newIOContext(random));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator(null);\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.size());\n    DocsAndPositionsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, true);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg, fieldInfos, newIOContext(random));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator(null);\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.getUniqueTermCount());\n    DocsAndPositionsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, true);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader#testOffsetReader().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader#testOffsetReader().mjava","sourceNew":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg, fieldInfos, newIOContext(random()));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator(null);\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.size());\n    DocsAndPositionsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, true);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg, fieldInfos, newIOContext(random));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator(null);\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.size());\n    DocsAndPositionsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, true);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9d153abcf92dc5329d98571a8c3035df9bd80648","date":1337702630,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader#testOffsetReader().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader#testOffsetReader().mjava","sourceNew":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator(null);\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.size());\n    DocsAndPositionsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, true);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg, fieldInfos, newIOContext(random()));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator(null);\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.size());\n    DocsAndPositionsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, true);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"615ddbd81799980d0fdd95e0238e1c498b6f47b0","date":1338233290,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader#testOffsetReader().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader#testOffsetReader().mjava","sourceNew":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator(null);\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.size());\n    DocsAndPositionsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, true);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg, fieldInfos, newIOContext(random()));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator(null);\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.size());\n    DocsAndPositionsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, true);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"322360ac5185a8446d3e0b530b2068bef67cd3d5","date":1343669494,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader#testOffsetReader().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader#testOffsetReader().mjava","sourceNew":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator(null);\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.size());\n    DocsAndPositionsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator(null);\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.size());\n    DocsAndPositionsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, true);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","date":1343768312,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader#testOffsetReader().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader#testOffsetReader().mjava","sourceNew":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator(null);\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.size());\n    DocsAndPositionsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator(null);\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.size());\n    DocsAndPositionsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, true);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d6f074e73200c07d54f242d3880a8da5a35ff97b","date":1344507653,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader#testOffsetReader().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader#testOffsetReader().mjava","sourceNew":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator(null);\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.size());\n    DocsAndPositionsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator(null);\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.size());\n    DocsAndPositionsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, true);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"51f5280f31484820499077f41fcdfe92d527d9dc","date":1423229122,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader#testOffsetReader().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader#testOffsetReader().mjava","sourceNew":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator(null);\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.size());\n    PostingsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.FLAG_ALL);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.FLAG_ALL);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator(null);\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.size());\n    DocsAndPositionsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e73063b92d958076ef4ae8beb5f493e8ccdcecb4","date":1424177215,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader#testOffsetReader().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader#testOffsetReader().mjava","sourceNew":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator(null);\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.size());\n    PostingsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator(null);\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.size());\n    PostingsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.FLAG_ALL);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.FLAG_ALL);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82","date":1428522487,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader#testOffsetReader().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader#testOffsetReader().mjava","sourceNew":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator();\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.size());\n    PostingsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator(null);\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.size());\n    PostingsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0f4464508ee83288c8c4585b533f9faaa93aa314","date":1435240759,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader#testOffsetReader().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader#testOffsetReader().mjava","sourceNew":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator();\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.size());\n    PostingsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator();\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.size());\n    PostingsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82":["e73063b92d958076ef4ae8beb5f493e8ccdcecb4"],"bdb5e42b0cecd8dfb27767a02ada71899bf17917":["f08557cdb6c60ac7b88a9342c983a20cd236e74f"],"5a238fc456663f685a9db1ed8d680e348bb45171":["f08557cdb6c60ac7b88a9342c983a20cd236e74f","bdb5e42b0cecd8dfb27767a02ada71899bf17917"],"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab":["3a119bbc8703c10faa329ec201c654b3a35a1e3e","f08557cdb6c60ac7b88a9342c983a20cd236e74f"],"f08557cdb6c60ac7b88a9342c983a20cd236e74f":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"9d153abcf92dc5329d98571a8c3035df9bd80648":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"51f5280f31484820499077f41fcdfe92d527d9dc":["322360ac5185a8446d3e0b530b2068bef67cd3d5"],"0f4464508ee83288c8c4585b533f9faaa93aa314":["0a773283ef5eab2e9c7136eeb66574a4b7a2dc82"],"e73063b92d958076ef4ae8beb5f493e8ccdcecb4":["51f5280f31484820499077f41fcdfe92d527d9dc"],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["629c38c4ae4e303d0617e05fbfe508140b32f0a3","9d153abcf92dc5329d98571a8c3035df9bd80648"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f":["615ddbd81799980d0fdd95e0238e1c498b6f47b0","322360ac5185a8446d3e0b530b2068bef67cd3d5"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":["615ddbd81799980d0fdd95e0238e1c498b6f47b0","322360ac5185a8446d3e0b530b2068bef67cd3d5"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["bdb5e42b0cecd8dfb27767a02ada71899bf17917"],"322360ac5185a8446d3e0b530b2068bef67cd3d5":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["0f4464508ee83288c8c4585b533f9faaa93aa314"]},"commit2Childs":{"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82":["0f4464508ee83288c8c4585b533f9faaa93aa314"],"bdb5e42b0cecd8dfb27767a02ada71899bf17917":["5a238fc456663f685a9db1ed8d680e348bb45171","629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"5a238fc456663f685a9db1ed8d680e348bb45171":[],"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab":[],"f08557cdb6c60ac7b88a9342c983a20cd236e74f":["bdb5e42b0cecd8dfb27767a02ada71899bf17917","5a238fc456663f685a9db1ed8d680e348bb45171","9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","f08557cdb6c60ac7b88a9342c983a20cd236e74f"],"9d153abcf92dc5329d98571a8c3035df9bd80648":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"51f5280f31484820499077f41fcdfe92d527d9dc":["e73063b92d958076ef4ae8beb5f493e8ccdcecb4"],"e73063b92d958076ef4ae8beb5f493e8ccdcecb4":["0a773283ef5eab2e9c7136eeb66574a4b7a2dc82"],"0f4464508ee83288c8c4585b533f9faaa93aa314":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","d6f074e73200c07d54f242d3880a8da5a35ff97b","322360ac5185a8446d3e0b530b2068bef67cd3d5"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f":[],"d6f074e73200c07d54f242d3880a8da5a35ff97b":[],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["9d153abcf92dc5329d98571a8c3035df9bd80648","615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"322360ac5185a8446d3e0b530b2068bef67cd3d5":["51f5280f31484820499077f41fcdfe92d527d9dc","b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","d6f074e73200c07d54f242d3880a8da5a35ff97b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["5a238fc456663f685a9db1ed8d680e348bb45171","9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","d6f074e73200c07d54f242d3880a8da5a35ff97b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}