{"path":"lucene/src/test/org/apache/lucene/codecs/appending/TestAppendingCodec#testCodec().mjava","commits":[{"id":"a0ae5e3ed1232483b7b8a014f175a5fe43595982","date":1324062192,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/codecs/appending/TestAppendingCodec#testCodec().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/codecs/appending/TestAppendingCodec#testCodec().mjava","sourceNew":"  public void testCodec() throws Exception {\n    Directory dir = new AppendingRAMDirectory(random, new RAMDirectory());\n    IndexWriterConfig cfg = new IndexWriterConfig(Version.LUCENE_40, new MockAnalyzer(random));\n    \n    cfg.setCodec(new AppendingCodec());\n    ((TieredMergePolicy)cfg.getMergePolicy()).setUseCompoundFile(false);\n    IndexWriter writer = new IndexWriter(dir, cfg);\n    Document doc = new Document();\n    FieldType storedTextType = new FieldType(TextField.TYPE_STORED);\n    storedTextType.setStoreTermVectors(true);\n    storedTextType.setStoreTermVectorPositions(true);\n    storedTextType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"f\", text, storedTextType));\n    writer.addDocument(doc);\n    writer.commit();\n    writer.addDocument(doc);\n    writer.forceMerge(1);\n    writer.close();\n    IndexReader reader = IndexReader.open(dir, 1);\n    assertEquals(2, reader.numDocs());\n    Document doc2 = reader.document(0);\n    assertEquals(text, doc2.get(\"f\"));\n    Fields fields = MultiFields.getFields(reader);\n    Terms terms = fields.terms(\"f\");\n    assertNotNull(terms);\n    TermsEnum te = terms.iterator(null);\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"quick\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"brown\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"fox\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"jumped\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"over\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"lazy\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"dog\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"the\")));\n    DocsEnum de = te.docs(null, null, true);\n    assertTrue(de.advance(0) != DocsEnum.NO_MORE_DOCS);\n    assertEquals(2, de.freq());\n    assertTrue(de.advance(1) != DocsEnum.NO_MORE_DOCS);\n    assertTrue(de.advance(2) == DocsEnum.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","sourceOld":"  public void testCodec() throws Exception {\n    Directory dir = new AppendingRAMDirectory(random, new RAMDirectory());\n    IndexWriterConfig cfg = new IndexWriterConfig(Version.LUCENE_40, new MockAnalyzer(random));\n    \n    cfg.setCodec(new AppendingCodec());\n    ((TieredMergePolicy)cfg.getMergePolicy()).setUseCompoundFile(false);\n    IndexWriter writer = new IndexWriter(dir, cfg);\n    Document doc = new Document();\n    FieldType storedTextType = new FieldType(TextField.TYPE_STORED);\n    storedTextType.setStoreTermVectors(true);\n    storedTextType.setStoreTermVectorPositions(true);\n    storedTextType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"f\", text, storedTextType));\n    writer.addDocument(doc);\n    writer.commit();\n    writer.addDocument(doc);\n    writer.forceMerge(1);\n    writer.close();\n    IndexReader reader = IndexReader.open(dir, 1);\n    assertEquals(2, reader.numDocs());\n    Document doc2 = reader.document(0);\n    assertEquals(text, doc2.get(\"f\"));\n    Fields fields = MultiFields.getFields(reader);\n    Terms terms = fields.terms(\"f\");\n    assertNotNull(terms);\n    TermsEnum te = terms.iterator(null);\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"quick\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"brown\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"fox\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"jumped\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"over\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"lazy\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"dog\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"the\")));\n    DocsEnum de = te.docs(null, null, true);\n    assertTrue(de.advance(0) != DocsEnum.NO_MORE_DOCS);\n    assertEquals(2, de.freq());\n    assertTrue(de.advance(1) != DocsEnum.NO_MORE_DOCS);\n    assertTrue(de.advance(2) == DocsEnum.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/appending/TestAppendingCodec#testCodec().mjava","pathOld":"lucene/src/test/org/apache/lucene/codecs/appending/TestAppendingCodec#testCodec().mjava","sourceNew":"  public void testCodec() throws Exception {\n    Directory dir = new AppendingRAMDirectory(random, new RAMDirectory());\n    IndexWriterConfig cfg = new IndexWriterConfig(Version.LUCENE_40, new MockAnalyzer(random));\n    \n    cfg.setCodec(new AppendingCodec());\n    ((TieredMergePolicy)cfg.getMergePolicy()).setUseCompoundFile(false);\n    IndexWriter writer = new IndexWriter(dir, cfg);\n    Document doc = new Document();\n    FieldType storedTextType = new FieldType(TextField.TYPE_STORED);\n    storedTextType.setStoreTermVectors(true);\n    storedTextType.setStoreTermVectorPositions(true);\n    storedTextType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"f\", text, storedTextType));\n    writer.addDocument(doc);\n    writer.commit();\n    writer.addDocument(doc);\n    writer.forceMerge(1);\n    writer.close();\n    IndexReader reader = IndexReader.open(dir, 1);\n    assertEquals(2, reader.numDocs());\n    Document doc2 = reader.document(0);\n    assertEquals(text, doc2.get(\"f\"));\n    Fields fields = MultiFields.getFields(reader);\n    Terms terms = fields.terms(\"f\");\n    assertNotNull(terms);\n    TermsEnum te = terms.iterator(null);\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"quick\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"brown\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"fox\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"jumped\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"over\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"lazy\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"dog\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"the\")));\n    DocsEnum de = te.docs(null, null, true);\n    assertTrue(de.advance(0) != DocsEnum.NO_MORE_DOCS);\n    assertEquals(2, de.freq());\n    assertTrue(de.advance(1) != DocsEnum.NO_MORE_DOCS);\n    assertTrue(de.advance(2) == DocsEnum.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","sourceOld":"  public void testCodec() throws Exception {\n    Directory dir = new AppendingRAMDirectory(random, new RAMDirectory());\n    IndexWriterConfig cfg = new IndexWriterConfig(Version.LUCENE_40, new MockAnalyzer(random));\n    \n    cfg.setCodec(new AppendingCodec());\n    ((TieredMergePolicy)cfg.getMergePolicy()).setUseCompoundFile(false);\n    IndexWriter writer = new IndexWriter(dir, cfg);\n    Document doc = new Document();\n    FieldType storedTextType = new FieldType(TextField.TYPE_STORED);\n    storedTextType.setStoreTermVectors(true);\n    storedTextType.setStoreTermVectorPositions(true);\n    storedTextType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"f\", text, storedTextType));\n    writer.addDocument(doc);\n    writer.commit();\n    writer.addDocument(doc);\n    writer.forceMerge(1);\n    writer.close();\n    IndexReader reader = IndexReader.open(dir, 1);\n    assertEquals(2, reader.numDocs());\n    Document doc2 = reader.document(0);\n    assertEquals(text, doc2.get(\"f\"));\n    Fields fields = MultiFields.getFields(reader);\n    Terms terms = fields.terms(\"f\");\n    assertNotNull(terms);\n    TermsEnum te = terms.iterator(null);\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"quick\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"brown\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"fox\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"jumped\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"over\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"lazy\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"dog\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"the\")));\n    DocsEnum de = te.docs(null, null, true);\n    assertTrue(de.advance(0) != DocsEnum.NO_MORE_DOCS);\n    assertEquals(2, de.freq());\n    assertTrue(de.advance(1) != DocsEnum.NO_MORE_DOCS);\n    assertTrue(de.advance(2) == DocsEnum.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0ae5e3ed1232483b7b8a014f175a5fe43595982"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a0ae5e3ed1232483b7b8a014f175a5fe43595982":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"]},"commit2Childs":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["a0ae5e3ed1232483b7b8a014f175a5fe43595982"],"a0ae5e3ed1232483b7b8a014f175a5fe43595982":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}