{"path":"solr/contrib/clustering/src/java/org/apache/solr/handler/clustering/ClusteringComponent#docListToSolrDocumentList(DocList,SolrIndexSearcher,Set[String],Map[SolrDocument,Integer]).mjava","commits":[{"id":"63a9344cff6a72bc4c1ef080c69e10ad0635b811","date":1490410892,"type":0,"author":"David Smiley","isMerge":false,"pathNew":"solr/contrib/clustering/src/java/org/apache/solr/handler/clustering/ClusteringComponent#docListToSolrDocumentList(DocList,SolrIndexSearcher,Set[String],Map[SolrDocument,Integer]).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Convert a DocList to a SolrDocumentList\n   *\n   * The optional param \"ids\" is populated with the lucene document id\n   * for each SolrDocument.\n   *\n   * @param docs The {@link org.apache.solr.search.DocList} to convert\n   * @param searcher The {@link org.apache.solr.search.SolrIndexSearcher} to use to load the docs from the Lucene index\n   * @param fields The names of the Fields to load\n   * @param ids A map to store the ids of the docs\n   * @return The new {@link SolrDocumentList} containing all the loaded docs\n   * @throws IOException if there was a problem loading the docs\n   * @since solr 1.4\n   */\n  public static SolrDocumentList docListToSolrDocumentList(\n      DocList docs,\n      SolrIndexSearcher searcher,\n      Set<String> fields,\n      Map<SolrDocument, Integer> ids ) throws IOException\n  {\n    IndexSchema schema = searcher.getSchema();\n\n    SolrDocumentList list = new SolrDocumentList();\n    list.setNumFound(docs.matches());\n    list.setMaxScore(docs.maxScore());\n    list.setStart(docs.offset());\n\n    DocIterator dit = docs.iterator();\n\n    while (dit.hasNext()) {\n      int docid = dit.nextDoc();\n\n      Document luceneDoc = searcher.doc(docid, fields);\n      SolrDocument doc = new SolrDocument();\n\n      for( IndexableField field : luceneDoc) {\n        if (null == fields || fields.contains(field.name())) {\n          SchemaField sf = schema.getField( field.name() );\n          doc.addField( field.name(), sf.getType().toObject( field ) );\n        }\n      }\n      if (docs.hasScores() && (null == fields || fields.contains(\"score\"))) {\n        doc.addField(\"score\", dit.score());\n      }\n\n      list.add( doc );\n\n      if( ids != null ) {\n        ids.put( doc, new Integer(docid) );\n      }\n    }\n    return list;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"de548de3ce5405595899f548152d4b93ac9eb9cc","date":1490594650,"type":0,"author":"David Smiley","isMerge":false,"pathNew":"solr/contrib/clustering/src/java/org/apache/solr/handler/clustering/ClusteringComponent#docListToSolrDocumentList(DocList,SolrIndexSearcher,Set[String],Map[SolrDocument,Integer]).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Convert a DocList to a SolrDocumentList\n   *\n   * The optional param \"ids\" is populated with the lucene document id\n   * for each SolrDocument.\n   *\n   * @param docs The {@link org.apache.solr.search.DocList} to convert\n   * @param searcher The {@link org.apache.solr.search.SolrIndexSearcher} to use to load the docs from the Lucene index\n   * @param fields The names of the Fields to load\n   * @param ids A map to store the ids of the docs\n   * @return The new {@link SolrDocumentList} containing all the loaded docs\n   * @throws IOException if there was a problem loading the docs\n   * @since solr 1.4\n   */\n  public static SolrDocumentList docListToSolrDocumentList(\n      DocList docs,\n      SolrIndexSearcher searcher,\n      Set<String> fields,\n      Map<SolrDocument, Integer> ids ) throws IOException\n  {\n    IndexSchema schema = searcher.getSchema();\n\n    SolrDocumentList list = new SolrDocumentList();\n    list.setNumFound(docs.matches());\n    list.setMaxScore(docs.maxScore());\n    list.setStart(docs.offset());\n\n    DocIterator dit = docs.iterator();\n\n    while (dit.hasNext()) {\n      int docid = dit.nextDoc();\n\n      Document luceneDoc = searcher.doc(docid, fields);\n      SolrDocument doc = new SolrDocument();\n\n      for( IndexableField field : luceneDoc) {\n        if (null == fields || fields.contains(field.name())) {\n          SchemaField sf = schema.getField( field.name() );\n          doc.addField( field.name(), sf.getType().toObject( field ) );\n        }\n      }\n      if (docs.hasScores() && (null == fields || fields.contains(\"score\"))) {\n        doc.addField(\"score\", dit.score());\n      }\n\n      list.add( doc );\n\n      if( ids != null ) {\n        ids.put( doc, new Integer(docid) );\n      }\n    }\n    return list;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b6a269c1ddba3f8c9fa9a40572ecc538eddda41a","date":1528054850,"type":3,"author":"Michael Braun","isMerge":false,"pathNew":"solr/contrib/clustering/src/java/org/apache/solr/handler/clustering/ClusteringComponent#docListToSolrDocumentList(DocList,SolrIndexSearcher,Set[String],Map[SolrDocument,Integer]).mjava","pathOld":"solr/contrib/clustering/src/java/org/apache/solr/handler/clustering/ClusteringComponent#docListToSolrDocumentList(DocList,SolrIndexSearcher,Set[String],Map[SolrDocument,Integer]).mjava","sourceNew":"  /**\n   * Convert a DocList to a SolrDocumentList\n   *\n   * The optional param \"ids\" is populated with the lucene document id\n   * for each SolrDocument.\n   *\n   * @param docs The {@link org.apache.solr.search.DocList} to convert\n   * @param searcher The {@link org.apache.solr.search.SolrIndexSearcher} to use to load the docs from the Lucene index\n   * @param fields The names of the Fields to load\n   * @param ids A map to store the ids of the docs\n   * @return The new {@link SolrDocumentList} containing all the loaded docs\n   * @throws IOException if there was a problem loading the docs\n   * @since solr 1.4\n   */\n  public static SolrDocumentList docListToSolrDocumentList(\n      DocList docs,\n      SolrIndexSearcher searcher,\n      Set<String> fields,\n      Map<SolrDocument, Integer> ids ) throws IOException\n  {\n    IndexSchema schema = searcher.getSchema();\n\n    SolrDocumentList list = new SolrDocumentList();\n    list.setNumFound(docs.matches());\n    list.setMaxScore(docs.maxScore());\n    list.setStart(docs.offset());\n\n    DocIterator dit = docs.iterator();\n\n    while (dit.hasNext()) {\n      int docid = dit.nextDoc();\n\n      Document luceneDoc = searcher.doc(docid, fields);\n      SolrDocument doc = new SolrDocument();\n\n      for( IndexableField field : luceneDoc) {\n        if (null == fields || fields.contains(field.name())) {\n          SchemaField sf = schema.getField( field.name() );\n          doc.addField( field.name(), sf.getType().toObject( field ) );\n        }\n      }\n      if (docs.hasScores() && (null == fields || fields.contains(\"score\"))) {\n        doc.addField(\"score\", dit.score());\n      }\n\n      list.add( doc );\n\n      if( ids != null ) {\n        ids.put( doc, docid );\n      }\n    }\n    return list;\n  }\n\n","sourceOld":"  /**\n   * Convert a DocList to a SolrDocumentList\n   *\n   * The optional param \"ids\" is populated with the lucene document id\n   * for each SolrDocument.\n   *\n   * @param docs The {@link org.apache.solr.search.DocList} to convert\n   * @param searcher The {@link org.apache.solr.search.SolrIndexSearcher} to use to load the docs from the Lucene index\n   * @param fields The names of the Fields to load\n   * @param ids A map to store the ids of the docs\n   * @return The new {@link SolrDocumentList} containing all the loaded docs\n   * @throws IOException if there was a problem loading the docs\n   * @since solr 1.4\n   */\n  public static SolrDocumentList docListToSolrDocumentList(\n      DocList docs,\n      SolrIndexSearcher searcher,\n      Set<String> fields,\n      Map<SolrDocument, Integer> ids ) throws IOException\n  {\n    IndexSchema schema = searcher.getSchema();\n\n    SolrDocumentList list = new SolrDocumentList();\n    list.setNumFound(docs.matches());\n    list.setMaxScore(docs.maxScore());\n    list.setStart(docs.offset());\n\n    DocIterator dit = docs.iterator();\n\n    while (dit.hasNext()) {\n      int docid = dit.nextDoc();\n\n      Document luceneDoc = searcher.doc(docid, fields);\n      SolrDocument doc = new SolrDocument();\n\n      for( IndexableField field : luceneDoc) {\n        if (null == fields || fields.contains(field.name())) {\n          SchemaField sf = schema.getField( field.name() );\n          doc.addField( field.name(), sf.getType().toObject( field ) );\n        }\n      }\n      if (docs.hasScores() && (null == fields || fields.contains(\"score\"))) {\n        doc.addField(\"score\", dit.score());\n      }\n\n      list.add( doc );\n\n      if( ids != null ) {\n        ids.put( doc, new Integer(docid) );\n      }\n    }\n    return list;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"628903f37b6c442da0d390db1c6af9a0e74d41a7","date":1531736685,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"solr/contrib/clustering/src/java/org/apache/solr/handler/clustering/ClusteringComponent#docListToSolrDocumentList(DocList,SolrIndexSearcher,Set[String],Map[SolrDocument,Integer]).mjava","pathOld":"solr/contrib/clustering/src/java/org/apache/solr/handler/clustering/ClusteringComponent#docListToSolrDocumentList(DocList,SolrIndexSearcher,Set[String],Map[SolrDocument,Integer]).mjava","sourceNew":"  /**\n   * Convert a DocList to a SolrDocumentList\n   *\n   * The optional param \"ids\" is populated with the lucene document id\n   * for each SolrDocument.\n   *\n   * @param docs The {@link org.apache.solr.search.DocList} to convert\n   * @param searcher The {@link org.apache.solr.search.SolrIndexSearcher} to use to load the docs from the Lucene index\n   * @param fields The names of the Fields to load\n   * @param ids A map to store the ids of the docs\n   * @return The new {@link SolrDocumentList} containing all the loaded docs\n   * @throws IOException if there was a problem loading the docs\n   * @since solr 1.4\n   */\n  public static SolrDocumentList docListToSolrDocumentList(\n      DocList docs,\n      SolrIndexSearcher searcher,\n      Set<String> fields,\n      Map<SolrDocument, Integer> ids ) throws IOException\n  {\n    IndexSchema schema = searcher.getSchema();\n\n    SolrDocumentList list = new SolrDocumentList();\n    list.setNumFound(docs.matches());\n    list.setMaxScore(docs.maxScore());\n    list.setStart(docs.offset());\n\n    DocIterator dit = docs.iterator();\n\n    while (dit.hasNext()) {\n      int docid = dit.nextDoc();\n\n      Document luceneDoc = searcher.doc(docid, fields);\n      SolrDocument doc = new SolrDocument();\n\n      for( IndexableField field : luceneDoc) {\n        if (null == fields || fields.contains(field.name())) {\n          SchemaField sf = schema.getField( field.name() );\n          doc.addField( field.name(), sf.getType().toObject( field ) );\n        }\n      }\n      if (docs.hasScores() && (null == fields || fields.contains(\"score\"))) {\n        doc.addField(\"score\", dit.score());\n      }\n\n      list.add( doc );\n\n      if( ids != null ) {\n        ids.put( doc, docid );\n      }\n    }\n    return list;\n  }\n\n","sourceOld":"  /**\n   * Convert a DocList to a SolrDocumentList\n   *\n   * The optional param \"ids\" is populated with the lucene document id\n   * for each SolrDocument.\n   *\n   * @param docs The {@link org.apache.solr.search.DocList} to convert\n   * @param searcher The {@link org.apache.solr.search.SolrIndexSearcher} to use to load the docs from the Lucene index\n   * @param fields The names of the Fields to load\n   * @param ids A map to store the ids of the docs\n   * @return The new {@link SolrDocumentList} containing all the loaded docs\n   * @throws IOException if there was a problem loading the docs\n   * @since solr 1.4\n   */\n  public static SolrDocumentList docListToSolrDocumentList(\n      DocList docs,\n      SolrIndexSearcher searcher,\n      Set<String> fields,\n      Map<SolrDocument, Integer> ids ) throws IOException\n  {\n    IndexSchema schema = searcher.getSchema();\n\n    SolrDocumentList list = new SolrDocumentList();\n    list.setNumFound(docs.matches());\n    list.setMaxScore(docs.maxScore());\n    list.setStart(docs.offset());\n\n    DocIterator dit = docs.iterator();\n\n    while (dit.hasNext()) {\n      int docid = dit.nextDoc();\n\n      Document luceneDoc = searcher.doc(docid, fields);\n      SolrDocument doc = new SolrDocument();\n\n      for( IndexableField field : luceneDoc) {\n        if (null == fields || fields.contains(field.name())) {\n          SchemaField sf = schema.getField( field.name() );\n          doc.addField( field.name(), sf.getType().toObject( field ) );\n        }\n      }\n      if (docs.hasScores() && (null == fields || fields.contains(\"score\"))) {\n        doc.addField(\"score\", dit.score());\n      }\n\n      list.add( doc );\n\n      if( ids != null ) {\n        ids.put( doc, new Integer(docid) );\n      }\n    }\n    return list;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","date":1531905561,"type":3,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"solr/contrib/clustering/src/java/org/apache/solr/handler/clustering/ClusteringComponent#docListToSolrDocumentList(DocList,SolrIndexSearcher,Set[String],Map[SolrDocument,Integer]).mjava","pathOld":"solr/contrib/clustering/src/java/org/apache/solr/handler/clustering/ClusteringComponent#docListToSolrDocumentList(DocList,SolrIndexSearcher,Set[String],Map[SolrDocument,Integer]).mjava","sourceNew":"  /**\n   * Convert a DocList to a SolrDocumentList\n   *\n   * The optional param \"ids\" is populated with the lucene document id\n   * for each SolrDocument.\n   *\n   * @param docs The {@link org.apache.solr.search.DocList} to convert\n   * @param searcher The {@link org.apache.solr.search.SolrIndexSearcher} to use to load the docs from the Lucene index\n   * @param fields The names of the Fields to load\n   * @param ids A map to store the ids of the docs\n   * @return The new {@link SolrDocumentList} containing all the loaded docs\n   * @throws IOException if there was a problem loading the docs\n   * @since solr 1.4\n   */\n  public static SolrDocumentList docListToSolrDocumentList(\n      DocList docs,\n      SolrIndexSearcher searcher,\n      Set<String> fields,\n      Map<SolrDocument, Integer> ids ) throws IOException\n  {\n    IndexSchema schema = searcher.getSchema();\n\n    SolrDocumentList list = new SolrDocumentList();\n    list.setNumFound(docs.matches());\n    list.setMaxScore(docs.maxScore());\n    list.setStart(docs.offset());\n\n    DocIterator dit = docs.iterator();\n\n    while (dit.hasNext()) {\n      int docid = dit.nextDoc();\n\n      Document luceneDoc = searcher.doc(docid, fields);\n      SolrDocument doc = new SolrDocument();\n\n      for( IndexableField field : luceneDoc) {\n        if (null == fields || fields.contains(field.name())) {\n          SchemaField sf = schema.getField( field.name() );\n          doc.addField( field.name(), sf.getType().toObject( field ) );\n        }\n      }\n      if (docs.hasScores() && (null == fields || fields.contains(\"score\"))) {\n        doc.addField(\"score\", dit.score());\n      }\n\n      list.add( doc );\n\n      if( ids != null ) {\n        ids.put( doc, docid );\n      }\n    }\n    return list;\n  }\n\n","sourceOld":"  /**\n   * Convert a DocList to a SolrDocumentList\n   *\n   * The optional param \"ids\" is populated with the lucene document id\n   * for each SolrDocument.\n   *\n   * @param docs The {@link org.apache.solr.search.DocList} to convert\n   * @param searcher The {@link org.apache.solr.search.SolrIndexSearcher} to use to load the docs from the Lucene index\n   * @param fields The names of the Fields to load\n   * @param ids A map to store the ids of the docs\n   * @return The new {@link SolrDocumentList} containing all the loaded docs\n   * @throws IOException if there was a problem loading the docs\n   * @since solr 1.4\n   */\n  public static SolrDocumentList docListToSolrDocumentList(\n      DocList docs,\n      SolrIndexSearcher searcher,\n      Set<String> fields,\n      Map<SolrDocument, Integer> ids ) throws IOException\n  {\n    IndexSchema schema = searcher.getSchema();\n\n    SolrDocumentList list = new SolrDocumentList();\n    list.setNumFound(docs.matches());\n    list.setMaxScore(docs.maxScore());\n    list.setStart(docs.offset());\n\n    DocIterator dit = docs.iterator();\n\n    while (dit.hasNext()) {\n      int docid = dit.nextDoc();\n\n      Document luceneDoc = searcher.doc(docid, fields);\n      SolrDocument doc = new SolrDocument();\n\n      for( IndexableField field : luceneDoc) {\n        if (null == fields || fields.contains(field.name())) {\n          SchemaField sf = schema.getField( field.name() );\n          doc.addField( field.name(), sf.getType().toObject( field ) );\n        }\n      }\n      if (docs.hasScores() && (null == fields || fields.contains(\"score\"))) {\n        doc.addField(\"score\", dit.score());\n      }\n\n      list.add( doc );\n\n      if( ids != null ) {\n        ids.put( doc, new Integer(docid) );\n      }\n    }\n    return list;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"b6a269c1ddba3f8c9fa9a40572ecc538eddda41a":["63a9344cff6a72bc4c1ef080c69e10ad0635b811"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":["63a9344cff6a72bc4c1ef080c69e10ad0635b811","628903f37b6c442da0d390db1c6af9a0e74d41a7"],"de548de3ce5405595899f548152d4b93ac9eb9cc":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"63a9344cff6a72bc4c1ef080c69e10ad0635b811":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"628903f37b6c442da0d390db1c6af9a0e74d41a7":["63a9344cff6a72bc4c1ef080c69e10ad0635b811","b6a269c1ddba3f8c9fa9a40572ecc538eddda41a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["628903f37b6c442da0d390db1c6af9a0e74d41a7"]},"commit2Childs":{"b6a269c1ddba3f8c9fa9a40572ecc538eddda41a":["628903f37b6c442da0d390db1c6af9a0e74d41a7"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":[],"de548de3ce5405595899f548152d4b93ac9eb9cc":[],"63a9344cff6a72bc4c1ef080c69e10ad0635b811":["b6a269c1ddba3f8c9fa9a40572ecc538eddda41a","0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","628903f37b6c442da0d390db1c6af9a0e74d41a7"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["de548de3ce5405595899f548152d4b93ac9eb9cc","63a9344cff6a72bc4c1ef080c69e10ad0635b811"],"628903f37b6c442da0d390db1c6af9a0e74d41a7":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","de548de3ce5405595899f548152d4b93ac9eb9cc","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}