{"path":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamDecoratorTest#testParallelIntersectStream().mjava","commits":[{"id":"8ff654a6d1fb7a79aedaa65c23cc052fdc770aaf","date":1522951207,"type":1,"author":"Joel Bernstein","isMerge":false,"pathNew":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamDecoratorTest#testParallelIntersectStream().mjava","pathOld":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelIntersectStream().mjava","sourceNew":"  @Test\n  public void testParallelIntersectStream() throws Exception {\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"setA\", \"a_i\", \"0\")\n        .add(id, \"2\", \"a_s\", \"setA\", \"a_i\", \"1\")\n        .add(id, \"3\", \"a_s\", \"setA\", \"a_i\", \"2\")\n        .add(id, \"4\", \"a_s\", \"setA\", \"a_i\", \"3\")\n\n        .add(id, \"5\", \"a_s\", \"setB\", \"a_i\", \"2\")\n        .add(id, \"6\", \"a_s\", \"setB\", \"a_i\", \"3\")\n\n        .add(id, \"7\", \"a_s\", \"setAB\", \"a_i\", \"0\")\n        .add(id, \"8\", \"a_s\", \"setAB\", \"a_i\", \"6\")\n        .commit(cluster.getSolrClient(), COLLECTIONORALIAS);\n    \n    StreamFactory streamFactory = new StreamFactory()\n      .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n      .withFunctionName(\"search\", CloudSolrStream.class)\n      .withFunctionName(\"intersect\", IntersectStream.class)\n      .withFunctionName(\"parallel\", ParallelStream.class);\n    // basic\n\n    StreamContext streamContext = new StreamContext();\n    SolrClientCache solrClientCache = new SolrClientCache();\n    streamContext.setSolrClientCache(solrClientCache);\n\n    try {\n      String zkHost = cluster.getZkServer().getZkAddress();\n      final TupleStream stream = streamFactory.constructStream(\"parallel(\"\n          + \"collection1, \"\n          + \"intersect(\"\n          + \"search(collection1, q=a_s:(setA || setAB), fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc, a_s asc\\\", partitionKeys=\\\"a_i\\\"),\"\n          + \"search(collection1, q=a_s:(setB || setAB), fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\"),\"\n          + \"on=\\\"a_i\\\"),\"\n          + \"workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"a_i asc\\\")\");\n\n      stream.setStreamContext(streamContext);\n\n      final List<Tuple> tuples = getTuples(stream);\n\n      assert (tuples.size() == 5);\n      assertOrder(tuples, 0, 7, 3, 4, 8);\n    } finally {\n      solrClientCache.close();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testParallelIntersectStream() throws Exception {\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"setA\", \"a_i\", \"0\")\n        .add(id, \"2\", \"a_s\", \"setA\", \"a_i\", \"1\")\n        .add(id, \"3\", \"a_s\", \"setA\", \"a_i\", \"2\")\n        .add(id, \"4\", \"a_s\", \"setA\", \"a_i\", \"3\")\n\n        .add(id, \"5\", \"a_s\", \"setB\", \"a_i\", \"2\")\n        .add(id, \"6\", \"a_s\", \"setB\", \"a_i\", \"3\")\n\n        .add(id, \"7\", \"a_s\", \"setAB\", \"a_i\", \"0\")\n        .add(id, \"8\", \"a_s\", \"setAB\", \"a_i\", \"6\")\n        .commit(cluster.getSolrClient(), COLLECTIONORALIAS);\n    \n    StreamFactory streamFactory = new StreamFactory()\n      .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n      .withFunctionName(\"search\", CloudSolrStream.class)\n      .withFunctionName(\"intersect\", IntersectStream.class)\n      .withFunctionName(\"parallel\", ParallelStream.class);\n    // basic\n\n    StreamContext streamContext = new StreamContext();\n    SolrClientCache solrClientCache = new SolrClientCache();\n    streamContext.setSolrClientCache(solrClientCache);\n\n    try {\n      String zkHost = cluster.getZkServer().getZkAddress();\n      final TupleStream stream = streamFactory.constructStream(\"parallel(\"\n          + \"collection1, \"\n          + \"intersect(\"\n          + \"search(collection1, q=a_s:(setA || setAB), fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc, a_s asc\\\", partitionKeys=\\\"a_i\\\"),\"\n          + \"search(collection1, q=a_s:(setB || setAB), fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\"),\"\n          + \"on=\\\"a_i\\\"),\"\n          + \"workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"a_i asc\\\")\");\n\n      stream.setStreamContext(streamContext);\n\n      final List<Tuple> tuples = getTuples(stream);\n\n      assert (tuples.size() == 5);\n      assertOrder(tuples, 0, 7, 3, 4, 8);\n    } finally {\n      solrClientCache.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b73cc5cc718a5ccdc940b7e3ecbf17e6c145d233","date":1543335722,"type":3,"author":"Joel Bernstein","isMerge":false,"pathNew":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamDecoratorTest#testParallelIntersectStream().mjava","pathOld":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamDecoratorTest#testParallelIntersectStream().mjava","sourceNew":"  @Test\n  public void testParallelIntersectStream() throws Exception {\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"setA\", \"a_i\", \"0\")\n        .add(id, \"2\", \"a_s\", \"setA\", \"a_i\", \"1\")\n        .add(id, \"3\", \"a_s\", \"setA\", \"a_i\", \"2\")\n        .add(id, \"4\", \"a_s\", \"setA\", \"a_i\", \"3\")\n\n        .add(id, \"5\", \"a_s\", \"setB\", \"a_i\", \"2\")\n        .add(id, \"6\", \"a_s\", \"setB\", \"a_i\", \"3\")\n\n        .add(id, \"7\", \"a_s\", \"setAB\", \"a_i\", \"0\")\n        .add(id, \"8\", \"a_s\", \"setAB\", \"a_i\", \"6\")\n        .commit(cluster.getSolrClient(), COLLECTIONORALIAS);\n    \n    StreamFactory streamFactory = new StreamFactory()\n      .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n      .withFunctionName(\"search\", CloudSolrStream.class)\n      .withFunctionName(\"intersect\", IntersectStream.class)\n      .withFunctionName(\"parallel\", ParallelStream.class);\n    // basic\n\n    StreamContext streamContext = new StreamContext();\n    SolrClientCache solrClientCache = new SolrClientCache();\n    streamContext.setSolrClientCache(solrClientCache);\n\n    try {\n      String zkHost = cluster.getZkServer().getZkAddress();\n      final TupleStream stream = streamFactory.constructStream(\"parallel(\"\n          + \"collection1, \"\n          + \"intersect(\"\n          + \"search(collection1, q=a_s:(setA || setAB), fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc, a_s asc\\\", partitionKeys=\\\"a_i\\\", qt=\\\"/export\\\"),\"\n          + \"search(collection1, q=a_s:(setB || setAB), fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\", qt=\\\"/export\\\"),\"\n          + \"on=\\\"a_i\\\"),\"\n          + \"workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"a_i asc\\\")\");\n\n      stream.setStreamContext(streamContext);\n\n      final List<Tuple> tuples = getTuples(stream);\n\n      assert (tuples.size() == 5);\n      assertOrder(tuples, 0, 7, 3, 4, 8);\n    } finally {\n      solrClientCache.close();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testParallelIntersectStream() throws Exception {\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"setA\", \"a_i\", \"0\")\n        .add(id, \"2\", \"a_s\", \"setA\", \"a_i\", \"1\")\n        .add(id, \"3\", \"a_s\", \"setA\", \"a_i\", \"2\")\n        .add(id, \"4\", \"a_s\", \"setA\", \"a_i\", \"3\")\n\n        .add(id, \"5\", \"a_s\", \"setB\", \"a_i\", \"2\")\n        .add(id, \"6\", \"a_s\", \"setB\", \"a_i\", \"3\")\n\n        .add(id, \"7\", \"a_s\", \"setAB\", \"a_i\", \"0\")\n        .add(id, \"8\", \"a_s\", \"setAB\", \"a_i\", \"6\")\n        .commit(cluster.getSolrClient(), COLLECTIONORALIAS);\n    \n    StreamFactory streamFactory = new StreamFactory()\n      .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n      .withFunctionName(\"search\", CloudSolrStream.class)\n      .withFunctionName(\"intersect\", IntersectStream.class)\n      .withFunctionName(\"parallel\", ParallelStream.class);\n    // basic\n\n    StreamContext streamContext = new StreamContext();\n    SolrClientCache solrClientCache = new SolrClientCache();\n    streamContext.setSolrClientCache(solrClientCache);\n\n    try {\n      String zkHost = cluster.getZkServer().getZkAddress();\n      final TupleStream stream = streamFactory.constructStream(\"parallel(\"\n          + \"collection1, \"\n          + \"intersect(\"\n          + \"search(collection1, q=a_s:(setA || setAB), fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc, a_s asc\\\", partitionKeys=\\\"a_i\\\"),\"\n          + \"search(collection1, q=a_s:(setB || setAB), fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\"),\"\n          + \"on=\\\"a_i\\\"),\"\n          + \"workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"a_i asc\\\")\");\n\n      stream.setStreamContext(streamContext);\n\n      final List<Tuple> tuples = getTuples(stream);\n\n      assert (tuples.size() == 5);\n      assertOrder(tuples, 0, 7, 3, 4, 8);\n    } finally {\n      solrClientCache.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b73cc5cc718a5ccdc940b7e3ecbf17e6c145d233"],"b73cc5cc718a5ccdc940b7e3ecbf17e6c145d233":["8ff654a6d1fb7a79aedaa65c23cc052fdc770aaf"],"8ff654a6d1fb7a79aedaa65c23cc052fdc770aaf":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["8ff654a6d1fb7a79aedaa65c23cc052fdc770aaf"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"b73cc5cc718a5ccdc940b7e3ecbf17e6c145d233":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"8ff654a6d1fb7a79aedaa65c23cc052fdc770aaf":["b73cc5cc718a5ccdc940b7e3ecbf17e6c145d233"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}