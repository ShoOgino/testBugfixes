{"path":"lucene/src/java/org/apache/lucene/index/IndexWriter#setMaxFieldLength(int).mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#setMaxFieldLength(int).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#setMaxFieldLength(int).mjava","sourceNew":"  /**\n   * The maximum number of terms that will be indexed for a single field in a\n   * document.  This limits the amount of memory required for indexing, so that\n   * collections with very large files will not crash the indexing process by\n   * running out of memory.  This setting refers to the number of running terms,\n   * not to the number of different terms.<p/>\n   * <strong>Note:</strong> this silently truncates large documents, excluding from the\n   * index all terms that occur further in the document.  If you know your source\n   * documents are large, be sure to set this value high enough to accomodate\n   * the expected size.  If you set it to Integer.MAX_VALUE, then the only limit\n   * is your memory, but you should anticipate an OutOfMemoryError.<p/>\n   * By default, no more than {@link #DEFAULT_MAX_FIELD_LENGTH} terms\n   * will be indexed for a field.\n   * @deprecated use {@link IndexWriterConfig#setMaxFieldLength(int)} instead\n   */\n  public void setMaxFieldLength(int maxFieldLength) {\n    ensureOpen();\n    this.maxFieldLength = maxFieldLength;\n    docWriter.setMaxFieldLength(maxFieldLength);\n    if (infoStream != null)\n      message(\"setMaxFieldLength \" + maxFieldLength);\n    // Required so config.getSimilarity returns the right value. But this will\n    // go away together with the method in 4.0.\n    config.setMaxFieldLength(maxFieldLength);\n  }\n\n","sourceOld":"  /**\n   * The maximum number of terms that will be indexed for a single field in a\n   * document.  This limits the amount of memory required for indexing, so that\n   * collections with very large files will not crash the indexing process by\n   * running out of memory.  This setting refers to the number of running terms,\n   * not to the number of different terms.<p/>\n   * <strong>Note:</strong> this silently truncates large documents, excluding from the\n   * index all terms that occur further in the document.  If you know your source\n   * documents are large, be sure to set this value high enough to accomodate\n   * the expected size.  If you set it to Integer.MAX_VALUE, then the only limit\n   * is your memory, but you should anticipate an OutOfMemoryError.<p/>\n   * By default, no more than {@link #DEFAULT_MAX_FIELD_LENGTH} terms\n   * will be indexed for a field.\n   * @deprecated use {@link IndexWriterConfig#setMaxFieldLength(int)} instead\n   */\n  public void setMaxFieldLength(int maxFieldLength) {\n    ensureOpen();\n    this.maxFieldLength = maxFieldLength;\n    docWriter.setMaxFieldLength(maxFieldLength);\n    if (infoStream != null)\n      message(\"setMaxFieldLength \" + maxFieldLength);\n    // Required so config.getSimilarity returns the right value. But this will\n    // go away together with the method in 4.0.\n    config.setMaxFieldLength(maxFieldLength);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7ab99e8c71442b92c320e218141dee04a9b91ce8","date":1269203801,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#setMaxFieldLength(int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#setMaxFieldLength(int).mjava","sourceNew":"  /**\n   * The maximum number of terms that will be indexed for a single field in a\n   * document.  This limits the amount of memory required for indexing, so that\n   * collections with very large files will not crash the indexing process by\n   * running out of memory.  This setting refers to the number of running terms,\n   * not to the number of different terms.<p/>\n   * <strong>Note:</strong> this silently truncates large documents, excluding from the\n   * index all terms that occur further in the document.  If you know your source\n   * documents are large, be sure to set this value high enough to accomodate\n   * the expected size.  If you set it to Integer.MAX_VALUE, then the only limit\n   * is your memory, but you should anticipate an OutOfMemoryError.<p/>\n   * By default, no more than {@link #DEFAULT_MAX_FIELD_LENGTH} terms\n   * will be indexed for a field.\n   * @deprecated use {@link IndexWriterConfig#setMaxFieldLength(int)} instead\n   */\n  public void setMaxFieldLength(int maxFieldLength) {\n    ensureOpen();\n    this.maxFieldLength = maxFieldLength;\n    docWriter.setMaxFieldLength(maxFieldLength);\n    if (infoStream != null)\n      message(\"setMaxFieldLength \" + maxFieldLength);\n    // Required so config.getMaxFieldLength returns the right value. But this\n    // will go away together with the method in 4.0.\n    config.setMaxFieldLength(maxFieldLength);\n  }\n\n","sourceOld":"  /**\n   * The maximum number of terms that will be indexed for a single field in a\n   * document.  This limits the amount of memory required for indexing, so that\n   * collections with very large files will not crash the indexing process by\n   * running out of memory.  This setting refers to the number of running terms,\n   * not to the number of different terms.<p/>\n   * <strong>Note:</strong> this silently truncates large documents, excluding from the\n   * index all terms that occur further in the document.  If you know your source\n   * documents are large, be sure to set this value high enough to accomodate\n   * the expected size.  If you set it to Integer.MAX_VALUE, then the only limit\n   * is your memory, but you should anticipate an OutOfMemoryError.<p/>\n   * By default, no more than {@link #DEFAULT_MAX_FIELD_LENGTH} terms\n   * will be indexed for a field.\n   * @deprecated use {@link IndexWriterConfig#setMaxFieldLength(int)} instead\n   */\n  public void setMaxFieldLength(int maxFieldLength) {\n    ensureOpen();\n    this.maxFieldLength = maxFieldLength;\n    docWriter.setMaxFieldLength(maxFieldLength);\n    if (infoStream != null)\n      message(\"setMaxFieldLength \" + maxFieldLength);\n    // Required so config.getSimilarity returns the right value. But this will\n    // go away together with the method in 4.0.\n    config.setMaxFieldLength(maxFieldLength);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9b832cbed6eb3d54a8bb9339296bdda8eeb53014","date":1279708040,"type":4,"author":"Michael Busch","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#setMaxFieldLength(int).mjava","sourceNew":null,"sourceOld":"  /**\n   * The maximum number of terms that will be indexed for a single field in a\n   * document.  This limits the amount of memory required for indexing, so that\n   * collections with very large files will not crash the indexing process by\n   * running out of memory.  This setting refers to the number of running terms,\n   * not to the number of different terms.<p/>\n   * <strong>Note:</strong> this silently truncates large documents, excluding from the\n   * index all terms that occur further in the document.  If you know your source\n   * documents are large, be sure to set this value high enough to accomodate\n   * the expected size.  If you set it to Integer.MAX_VALUE, then the only limit\n   * is your memory, but you should anticipate an OutOfMemoryError.<p/>\n   * By default, no more than {@link #DEFAULT_MAX_FIELD_LENGTH} terms\n   * will be indexed for a field.\n   * @deprecated use {@link IndexWriterConfig#setMaxFieldLength(int)} instead\n   */\n  public void setMaxFieldLength(int maxFieldLength) {\n    ensureOpen();\n    this.maxFieldLength = maxFieldLength;\n    docWriter.setMaxFieldLength(maxFieldLength);\n    if (infoStream != null)\n      message(\"setMaxFieldLength \" + maxFieldLength);\n    // Required so config.getMaxFieldLength returns the right value. But this\n    // will go away together with the method in 4.0.\n    config.setMaxFieldLength(maxFieldLength);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"334c1175813aea771a71728cd2c4ee4754fd0603","date":1279710173,"type":0,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#setMaxFieldLength(int).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * The maximum number of terms that will be indexed for a single field in a\n   * document.  This limits the amount of memory required for indexing, so that\n   * collections with very large files will not crash the indexing process by\n   * running out of memory.  This setting refers to the number of running terms,\n   * not to the number of different terms.<p/>\n   * <strong>Note:</strong> this silently truncates large documents, excluding from the\n   * index all terms that occur further in the document.  If you know your source\n   * documents are large, be sure to set this value high enough to accomodate\n   * the expected size.  If you set it to Integer.MAX_VALUE, then the only limit\n   * is your memory, but you should anticipate an OutOfMemoryError.<p/>\n   * By default, no more than {@link #DEFAULT_MAX_FIELD_LENGTH} terms\n   * will be indexed for a field.\n   * @deprecated use {@link IndexWriterConfig#setMaxFieldLength(int)} instead\n   */\n  public void setMaxFieldLength(int maxFieldLength) {\n    ensureOpen();\n    this.maxFieldLength = maxFieldLength;\n    docWriter.setMaxFieldLength(maxFieldLength);\n    if (infoStream != null)\n      message(\"setMaxFieldLength \" + maxFieldLength);\n    // Required so config.getMaxFieldLength returns the right value. But this\n    // will go away together with the method in 4.0.\n    config.setMaxFieldLength(maxFieldLength);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8fe956d65251358d755c56f14fe8380644790e47","date":1279711318,"type":4,"author":"Michael Busch","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#setMaxFieldLength(int).mjava","sourceNew":null,"sourceOld":"  /**\n   * The maximum number of terms that will be indexed for a single field in a\n   * document.  This limits the amount of memory required for indexing, so that\n   * collections with very large files will not crash the indexing process by\n   * running out of memory.  This setting refers to the number of running terms,\n   * not to the number of different terms.<p/>\n   * <strong>Note:</strong> this silently truncates large documents, excluding from the\n   * index all terms that occur further in the document.  If you know your source\n   * documents are large, be sure to set this value high enough to accomodate\n   * the expected size.  If you set it to Integer.MAX_VALUE, then the only limit\n   * is your memory, but you should anticipate an OutOfMemoryError.<p/>\n   * By default, no more than {@link #DEFAULT_MAX_FIELD_LENGTH} terms\n   * will be indexed for a field.\n   * @deprecated use {@link IndexWriterConfig#setMaxFieldLength(int)} instead\n   */\n  public void setMaxFieldLength(int maxFieldLength) {\n    ensureOpen();\n    this.maxFieldLength = maxFieldLength;\n    docWriter.setMaxFieldLength(maxFieldLength);\n    if (infoStream != null)\n      message(\"setMaxFieldLength \" + maxFieldLength);\n    // Required so config.getMaxFieldLength returns the right value. But this\n    // will go away together with the method in 4.0.\n    config.setMaxFieldLength(maxFieldLength);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"068265517d1fbc623f5aeaee57fcd8df925678e4","date":1286043654,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#setMaxFieldLength(int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#setMaxFieldLength(int).mjava","sourceNew":"  /**\n   * The maximum number of terms that will be indexed for a single field in a\n   * document.  This limits the amount of memory required for indexing, so that\n   * collections with very large files will not crash the indexing process by\n   * running out of memory.  This setting refers to the number of running terms,\n   * not to the number of different terms.<p/>\n   * <strong>Note:</strong> this silently truncates large documents, excluding from the\n   * index all terms that occur further in the document.  If you know your source\n   * documents are large, be sure to set this value high enough to accomodate\n   * the expected size.  If you set it to Integer.MAX_VALUE, then the only limit\n   * is your memory, but you should anticipate an OutOfMemoryError.<p/>\n   * By default, no more than {@link #DEFAULT_MAX_FIELD_LENGTH} terms\n   * will be indexed for a field.\n   * @deprecated use {@link IndexWriterConfig#setMaxFieldLength(int)} instead\n   */\n  @Deprecated\n  public void setMaxFieldLength(int maxFieldLength) {\n    ensureOpen();\n    this.maxFieldLength = maxFieldLength;\n    docWriter.setMaxFieldLength(maxFieldLength);\n    if (infoStream != null)\n      message(\"setMaxFieldLength \" + maxFieldLength);\n    // Required so config.getMaxFieldLength returns the right value. But this\n    // will go away together with the method in 4.0.\n    config.setMaxFieldLength(maxFieldLength);\n  }\n\n","sourceOld":"  /**\n   * The maximum number of terms that will be indexed for a single field in a\n   * document.  This limits the amount of memory required for indexing, so that\n   * collections with very large files will not crash the indexing process by\n   * running out of memory.  This setting refers to the number of running terms,\n   * not to the number of different terms.<p/>\n   * <strong>Note:</strong> this silently truncates large documents, excluding from the\n   * index all terms that occur further in the document.  If you know your source\n   * documents are large, be sure to set this value high enough to accomodate\n   * the expected size.  If you set it to Integer.MAX_VALUE, then the only limit\n   * is your memory, but you should anticipate an OutOfMemoryError.<p/>\n   * By default, no more than {@link #DEFAULT_MAX_FIELD_LENGTH} terms\n   * will be indexed for a field.\n   * @deprecated use {@link IndexWriterConfig#setMaxFieldLength(int)} instead\n   */\n  public void setMaxFieldLength(int maxFieldLength) {\n    ensureOpen();\n    this.maxFieldLength = maxFieldLength;\n    docWriter.setMaxFieldLength(maxFieldLength);\n    if (infoStream != null)\n      message(\"setMaxFieldLength \" + maxFieldLength);\n    // Required so config.getMaxFieldLength returns the right value. But this\n    // will go away together with the method in 4.0.\n    config.setMaxFieldLength(maxFieldLength);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4e8cc373c801e54cec75daf9f52792cb4b17f536","date":1291116159,"type":4,"author":"Robert Muir","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#setMaxFieldLength(int).mjava","sourceNew":null,"sourceOld":"  /**\n   * The maximum number of terms that will be indexed for a single field in a\n   * document.  This limits the amount of memory required for indexing, so that\n   * collections with very large files will not crash the indexing process by\n   * running out of memory.  This setting refers to the number of running terms,\n   * not to the number of different terms.<p/>\n   * <strong>Note:</strong> this silently truncates large documents, excluding from the\n   * index all terms that occur further in the document.  If you know your source\n   * documents are large, be sure to set this value high enough to accomodate\n   * the expected size.  If you set it to Integer.MAX_VALUE, then the only limit\n   * is your memory, but you should anticipate an OutOfMemoryError.<p/>\n   * By default, no more than {@link #DEFAULT_MAX_FIELD_LENGTH} terms\n   * will be indexed for a field.\n   * @deprecated use {@link IndexWriterConfig#setMaxFieldLength(int)} instead\n   */\n  @Deprecated\n  public void setMaxFieldLength(int maxFieldLength) {\n    ensureOpen();\n    this.maxFieldLength = maxFieldLength;\n    docWriter.setMaxFieldLength(maxFieldLength);\n    if (infoStream != null)\n      message(\"setMaxFieldLength \" + maxFieldLength);\n    // Required so config.getMaxFieldLength returns the right value. But this\n    // will go away together with the method in 4.0.\n    config.setMaxFieldLength(maxFieldLength);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3bb13258feba31ab676502787ab2e1779f129b7a","date":1291596436,"type":4,"author":"Simon Willnauer","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#setMaxFieldLength(int).mjava","sourceNew":null,"sourceOld":"  /**\n   * The maximum number of terms that will be indexed for a single field in a\n   * document.  This limits the amount of memory required for indexing, so that\n   * collections with very large files will not crash the indexing process by\n   * running out of memory.  This setting refers to the number of running terms,\n   * not to the number of different terms.<p/>\n   * <strong>Note:</strong> this silently truncates large documents, excluding from the\n   * index all terms that occur further in the document.  If you know your source\n   * documents are large, be sure to set this value high enough to accomodate\n   * the expected size.  If you set it to Integer.MAX_VALUE, then the only limit\n   * is your memory, but you should anticipate an OutOfMemoryError.<p/>\n   * By default, no more than {@link #DEFAULT_MAX_FIELD_LENGTH} terms\n   * will be indexed for a field.\n   * @deprecated use {@link IndexWriterConfig#setMaxFieldLength(int)} instead\n   */\n  @Deprecated\n  public void setMaxFieldLength(int maxFieldLength) {\n    ensureOpen();\n    this.maxFieldLength = maxFieldLength;\n    docWriter.setMaxFieldLength(maxFieldLength);\n    if (infoStream != null)\n      message(\"setMaxFieldLength \" + maxFieldLength);\n    // Required so config.getMaxFieldLength returns the right value. But this\n    // will go away together with the method in 4.0.\n    config.setMaxFieldLength(maxFieldLength);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"7ab99e8c71442b92c320e218141dee04a9b91ce8":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"068265517d1fbc623f5aeaee57fcd8df925678e4":["334c1175813aea771a71728cd2c4ee4754fd0603"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"8fe956d65251358d755c56f14fe8380644790e47":["7ab99e8c71442b92c320e218141dee04a9b91ce8"],"334c1175813aea771a71728cd2c4ee4754fd0603":["9b832cbed6eb3d54a8bb9339296bdda8eeb53014"],"9b832cbed6eb3d54a8bb9339296bdda8eeb53014":["7ab99e8c71442b92c320e218141dee04a9b91ce8"],"3bb13258feba31ab676502787ab2e1779f129b7a":["068265517d1fbc623f5aeaee57fcd8df925678e4","4e8cc373c801e54cec75daf9f52792cb4b17f536"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["4e8cc373c801e54cec75daf9f52792cb4b17f536"],"4e8cc373c801e54cec75daf9f52792cb4b17f536":["068265517d1fbc623f5aeaee57fcd8df925678e4"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"7ab99e8c71442b92c320e218141dee04a9b91ce8":["8fe956d65251358d755c56f14fe8380644790e47","9b832cbed6eb3d54a8bb9339296bdda8eeb53014"],"068265517d1fbc623f5aeaee57fcd8df925678e4":["3bb13258feba31ab676502787ab2e1779f129b7a","4e8cc373c801e54cec75daf9f52792cb4b17f536"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"8fe956d65251358d755c56f14fe8380644790e47":[],"334c1175813aea771a71728cd2c4ee4754fd0603":["068265517d1fbc623f5aeaee57fcd8df925678e4"],"9b832cbed6eb3d54a8bb9339296bdda8eeb53014":["334c1175813aea771a71728cd2c4ee4754fd0603"],"3bb13258feba31ab676502787ab2e1779f129b7a":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["7ab99e8c71442b92c320e218141dee04a9b91ce8"],"4e8cc373c801e54cec75daf9f52792cb4b17f536":["3bb13258feba31ab676502787ab2e1779f129b7a","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["8fe956d65251358d755c56f14fe8380644790e47","3bb13258feba31ab676502787ab2e1779f129b7a","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}