{"path":"lucene/core/src/test/org/apache/lucene/search/TestBoolean2#queriesTest(Query,int[]).mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestBoolean2#queriesTest(Query,int[]).mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestBoolean2#queriesTest(Query,int[]).mjava","sourceNew":"  public void queriesTest(Query query, int[] expDocNrs) throws Exception {\n    TopScoreDocCollector collector = TopScoreDocCollector.create(1000, false);\n    searcher.search(query, null, collector);\n    ScoreDoc[] hits1 = collector.topDocs().scoreDocs;\n\n    collector = TopScoreDocCollector.create(1000, true);\n    searcher.search(query, null, collector);\n    ScoreDoc[] hits2 = collector.topDocs().scoreDocs; \n\n    assertEquals(mulFactor * collector.totalHits,\n                 bigSearcher.search(query, 1).totalHits);\n      \n    CheckHits.checkHitsQuery(query, hits1, hits2, expDocNrs);\n  }\n\n","sourceOld":"  public void queriesTest(Query query, int[] expDocNrs) throws Exception {\n    TopScoreDocCollector collector = TopScoreDocCollector.create(1000, false);\n    searcher.search(query, null, collector);\n    ScoreDoc[] hits1 = collector.topDocs().scoreDocs;\n\n    collector = TopScoreDocCollector.create(1000, true);\n    searcher.search(query, null, collector);\n    ScoreDoc[] hits2 = collector.topDocs().scoreDocs; \n\n    assertEquals(mulFactor * collector.totalHits,\n                 bigSearcher.search(query, 1).totalHits);\n      \n    CheckHits.checkHitsQuery(query, hits1, hits2, expDocNrs);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f582f18c13d4852b01d4fe0a0196432c5c6f2b7f","date":1421314520,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestBoolean2#queriesTest(Query,int[]).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestBoolean2#queriesTest(Query,int[]).mjava","sourceNew":"  public void queriesTest(Query query, int[] expDocNrs) throws Exception {\n    // The asserting searcher will sometimes return the bulk scorer and\n    // sometimes return a default impl around the scorer so that we can\n    // compare BS1 and BS2\n    TopScoreDocCollector collector = TopScoreDocCollector.create(1000);\n    searcher.search(query, null, collector);\n    ScoreDoc[] hits1 = collector.topDocs().scoreDocs;\n\n    collector = TopScoreDocCollector.create(1000);\n    searcher.search(query, null, collector);\n    ScoreDoc[] hits2 = collector.topDocs().scoreDocs; \n\n    assertEquals(mulFactor * collector.totalHits,\n                 bigSearcher.search(query, 1).totalHits);\n      \n    CheckHits.checkHitsQuery(query, hits1, hits2, expDocNrs);\n  }\n\n","sourceOld":"  public void queriesTest(Query query, int[] expDocNrs) throws Exception {\n    TopScoreDocCollector collector = TopScoreDocCollector.create(1000, false);\n    searcher.search(query, null, collector);\n    ScoreDoc[] hits1 = collector.topDocs().scoreDocs;\n\n    collector = TopScoreDocCollector.create(1000, true);\n    searcher.search(query, null, collector);\n    ScoreDoc[] hits2 = collector.topDocs().scoreDocs; \n\n    assertEquals(mulFactor * collector.totalHits,\n                 bigSearcher.search(query, 1).totalHits);\n      \n    CheckHits.checkHitsQuery(query, hits1, hits2, expDocNrs);\n  }\n\n","bugFix":null,"bugIntro":["7c82b0d4b7bf499a159eeff92add20bac6599cc1"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc","date":1424799790,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestBoolean2#queriesTest(Query,int[]).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestBoolean2#queriesTest(Query,int[]).mjava","sourceNew":"  public void queriesTest(Query query, int[] expDocNrs) throws Exception {\n    // The asserting searcher will sometimes return the bulk scorer and\n    // sometimes return a default impl around the scorer so that we can\n    // compare BS1 and BS2\n    TopScoreDocCollector collector = TopScoreDocCollector.create(1000);\n    searcher.search(query, collector);\n    ScoreDoc[] hits1 = collector.topDocs().scoreDocs;\n\n    collector = TopScoreDocCollector.create(1000);\n    searcher.search(query, collector);\n    ScoreDoc[] hits2 = collector.topDocs().scoreDocs; \n\n    assertEquals(mulFactor * collector.totalHits,\n                 bigSearcher.search(query, 1).totalHits);\n      \n    CheckHits.checkHitsQuery(query, hits1, hits2, expDocNrs);\n  }\n\n","sourceOld":"  public void queriesTest(Query query, int[] expDocNrs) throws Exception {\n    // The asserting searcher will sometimes return the bulk scorer and\n    // sometimes return a default impl around the scorer so that we can\n    // compare BS1 and BS2\n    TopScoreDocCollector collector = TopScoreDocCollector.create(1000);\n    searcher.search(query, null, collector);\n    ScoreDoc[] hits1 = collector.topDocs().scoreDocs;\n\n    collector = TopScoreDocCollector.create(1000);\n    searcher.search(query, null, collector);\n    ScoreDoc[] hits2 = collector.topDocs().scoreDocs; \n\n    assertEquals(mulFactor * collector.totalHits,\n                 bigSearcher.search(query, 1).totalHits);\n      \n    CheckHits.checkHitsQuery(query, hits1, hits2, expDocNrs);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7c82b0d4b7bf499a159eeff92add20bac6599cc1","date":1465223716,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestBoolean2#queriesTest(Query,int[]).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestBoolean2#queriesTest(Query,int[]).mjava","sourceNew":"  public void queriesTest(Query query, int[] expDocNrs) throws Exception {\n\n    // adjust the expected doc numbers according to our filler docs\n    if (0 < NUM_FILLER_DOCS) {\n      expDocNrs = Arrays.copyOf(expDocNrs, expDocNrs.length);\n      for (int i=0; i < expDocNrs.length; i++) {\n        expDocNrs[i] = PRE_FILLER_DOCS + ((NUM_FILLER_DOCS + 1) * expDocNrs[i]);\n      }\n    }\n    \n    final int topDocsToCheck = atLeast(1000);\n    // The asserting searcher will sometimes return the bulk scorer and\n    // sometimes return a default impl around the scorer so that we can\n    // compare BS1 and BS2\n    TopScoreDocCollector collector = TopScoreDocCollector.create(topDocsToCheck);\n    searcher.search(query, collector);\n    ScoreDoc[] hits1 = collector.topDocs().scoreDocs;\n    collector = TopScoreDocCollector.create(topDocsToCheck);\n    searcher.search(query, collector);\n    ScoreDoc[] hits2 = collector.topDocs().scoreDocs; \n\n    CheckHits.checkHitsQuery(query, hits1, hits2, expDocNrs);\n\n    // Since we have no deleted docs, we should also be able to verify identical matches &\n    // scores against an single segment copy of our index\n    collector = TopScoreDocCollector.create(topDocsToCheck);\n    singleSegmentSearcher.search(query, collector);\n    hits2 = collector.topDocs().scoreDocs; \n    CheckHits.checkHitsQuery(query, hits1, hits2, expDocNrs);\n    \n    // sanity check expected num matches in bigSearcher\n    assertEquals(mulFactor * collector.totalHits,\n                 bigSearcher.search(query, 1).totalHits);\n\n    // now check 2 diff scorers from the bigSearcher as well\n    collector = TopScoreDocCollector.create(topDocsToCheck);\n    bigSearcher.search(query, collector);\n    hits1 = collector.topDocs().scoreDocs;\n    collector = TopScoreDocCollector.create(topDocsToCheck);\n    bigSearcher.search(query, collector);\n    hits2 = collector.topDocs().scoreDocs; \n\n    // NOTE: just comparing results, not vetting against expDocNrs\n    // since we have dups in bigSearcher\n    CheckHits.checkEqual(query, hits1, hits2);\n      \n  }\n\n","sourceOld":"  public void queriesTest(Query query, int[] expDocNrs) throws Exception {\n    // The asserting searcher will sometimes return the bulk scorer and\n    // sometimes return a default impl around the scorer so that we can\n    // compare BS1 and BS2\n    TopScoreDocCollector collector = TopScoreDocCollector.create(1000);\n    searcher.search(query, collector);\n    ScoreDoc[] hits1 = collector.topDocs().scoreDocs;\n\n    collector = TopScoreDocCollector.create(1000);\n    searcher.search(query, collector);\n    ScoreDoc[] hits2 = collector.topDocs().scoreDocs; \n\n    assertEquals(mulFactor * collector.totalHits,\n                 bigSearcher.search(query, 1).totalHits);\n      \n    CheckHits.checkHitsQuery(query, hits1, hits2, expDocNrs);\n  }\n\n","bugFix":["a4411d2e118cb48fb6415f6ac00117fd1c570dff","f582f18c13d4852b01d4fe0a0196432c5c6f2b7f"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"191128ac5b85671b1671e2c857437694283b6ebf","date":1465297861,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestBoolean2#queriesTest(Query,int[]).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestBoolean2#queriesTest(Query,int[]).mjava","sourceNew":"  public void queriesTest(Query query, int[] expDocNrs) throws Exception {\n\n    // adjust the expected doc numbers according to our filler docs\n    if (0 < NUM_FILLER_DOCS) {\n      expDocNrs = Arrays.copyOf(expDocNrs, expDocNrs.length);\n      for (int i=0; i < expDocNrs.length; i++) {\n        expDocNrs[i] = PRE_FILLER_DOCS + ((NUM_FILLER_DOCS + 1) * expDocNrs[i]);\n      }\n    }\n    \n    final int topDocsToCheck = atLeast(1000);\n    // The asserting searcher will sometimes return the bulk scorer and\n    // sometimes return a default impl around the scorer so that we can\n    // compare BS1 and BS2\n    TopScoreDocCollector collector = TopScoreDocCollector.create(topDocsToCheck);\n    searcher.search(query, collector);\n    ScoreDoc[] hits1 = collector.topDocs().scoreDocs;\n    collector = TopScoreDocCollector.create(topDocsToCheck);\n    searcher.search(query, collector);\n    ScoreDoc[] hits2 = collector.topDocs().scoreDocs; \n\n    CheckHits.checkHitsQuery(query, hits1, hits2, expDocNrs);\n\n    // Since we have no deleted docs, we should also be able to verify identical matches &\n    // scores against an single segment copy of our index\n    collector = TopScoreDocCollector.create(topDocsToCheck);\n    singleSegmentSearcher.search(query, collector);\n    hits2 = collector.topDocs().scoreDocs; \n    CheckHits.checkHitsQuery(query, hits1, hits2, expDocNrs);\n    \n    // sanity check expected num matches in bigSearcher\n    assertEquals(mulFactor * collector.totalHits,\n                 bigSearcher.search(query, 1).totalHits);\n\n    // now check 2 diff scorers from the bigSearcher as well\n    collector = TopScoreDocCollector.create(topDocsToCheck);\n    bigSearcher.search(query, collector);\n    hits1 = collector.topDocs().scoreDocs;\n    collector = TopScoreDocCollector.create(topDocsToCheck);\n    bigSearcher.search(query, collector);\n    hits2 = collector.topDocs().scoreDocs; \n\n    // NOTE: just comparing results, not vetting against expDocNrs\n    // since we have dups in bigSearcher\n    CheckHits.checkEqual(query, hits1, hits2);\n      \n  }\n\n","sourceOld":"  public void queriesTest(Query query, int[] expDocNrs) throws Exception {\n    // The asserting searcher will sometimes return the bulk scorer and\n    // sometimes return a default impl around the scorer so that we can\n    // compare BS1 and BS2\n    TopScoreDocCollector collector = TopScoreDocCollector.create(1000);\n    searcher.search(query, collector);\n    ScoreDoc[] hits1 = collector.topDocs().scoreDocs;\n\n    collector = TopScoreDocCollector.create(1000);\n    searcher.search(query, collector);\n    ScoreDoc[] hits2 = collector.topDocs().scoreDocs; \n\n    assertEquals(mulFactor * collector.totalHits,\n                 bigSearcher.search(query, 1).totalHits);\n      \n    CheckHits.checkHitsQuery(query, hits1, hits2, expDocNrs);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestBoolean2#queriesTest(Query,int[]).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestBoolean2#queriesTest(Query,int[]).mjava","sourceNew":"  public void queriesTest(Query query, int[] expDocNrs) throws Exception {\n\n    // adjust the expected doc numbers according to our filler docs\n    if (0 < NUM_FILLER_DOCS) {\n      expDocNrs = Arrays.copyOf(expDocNrs, expDocNrs.length);\n      for (int i=0; i < expDocNrs.length; i++) {\n        expDocNrs[i] = PRE_FILLER_DOCS + ((NUM_FILLER_DOCS + 1) * expDocNrs[i]);\n      }\n    }\n    \n    final int topDocsToCheck = atLeast(1000);\n    // The asserting searcher will sometimes return the bulk scorer and\n    // sometimes return a default impl around the scorer so that we can\n    // compare BS1 and BS2\n    TopScoreDocCollector collector = TopScoreDocCollector.create(topDocsToCheck);\n    searcher.search(query, collector);\n    ScoreDoc[] hits1 = collector.topDocs().scoreDocs;\n    collector = TopScoreDocCollector.create(topDocsToCheck);\n    searcher.search(query, collector);\n    ScoreDoc[] hits2 = collector.topDocs().scoreDocs; \n\n    CheckHits.checkHitsQuery(query, hits1, hits2, expDocNrs);\n\n    // Since we have no deleted docs, we should also be able to verify identical matches &\n    // scores against an single segment copy of our index\n    collector = TopScoreDocCollector.create(topDocsToCheck);\n    singleSegmentSearcher.search(query, collector);\n    hits2 = collector.topDocs().scoreDocs; \n    CheckHits.checkHitsQuery(query, hits1, hits2, expDocNrs);\n    \n    // sanity check expected num matches in bigSearcher\n    assertEquals(mulFactor * collector.totalHits,\n                 bigSearcher.search(query, 1).totalHits);\n\n    // now check 2 diff scorers from the bigSearcher as well\n    collector = TopScoreDocCollector.create(topDocsToCheck);\n    bigSearcher.search(query, collector);\n    hits1 = collector.topDocs().scoreDocs;\n    collector = TopScoreDocCollector.create(topDocsToCheck);\n    bigSearcher.search(query, collector);\n    hits2 = collector.topDocs().scoreDocs; \n\n    // NOTE: just comparing results, not vetting against expDocNrs\n    // since we have dups in bigSearcher\n    CheckHits.checkEqual(query, hits1, hits2);\n      \n  }\n\n","sourceOld":"  public void queriesTest(Query query, int[] expDocNrs) throws Exception {\n    // The asserting searcher will sometimes return the bulk scorer and\n    // sometimes return a default impl around the scorer so that we can\n    // compare BS1 and BS2\n    TopScoreDocCollector collector = TopScoreDocCollector.create(1000);\n    searcher.search(query, collector);\n    ScoreDoc[] hits1 = collector.topDocs().scoreDocs;\n\n    collector = TopScoreDocCollector.create(1000);\n    searcher.search(query, collector);\n    ScoreDoc[] hits2 = collector.topDocs().scoreDocs; \n\n    assertEquals(mulFactor * collector.totalHits,\n                 bigSearcher.search(query, 1).totalHits);\n      \n    CheckHits.checkHitsQuery(query, hits1, hits2, expDocNrs);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9798d0818e7a880546802b509792d3f3d57babd2","date":1528358901,"type":3,"author":"Nhat Nguyen","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestBoolean2#queriesTest(Query,int[]).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestBoolean2#queriesTest(Query,int[]).mjava","sourceNew":"  public void queriesTest(Query query, int[] expDocNrs) throws Exception {\n\n    // adjust the expected doc numbers according to our filler docs\n    if (0 < NUM_FILLER_DOCS) {\n      expDocNrs = ArrayUtil.copyOfSubArray(expDocNrs, 0, expDocNrs.length);\n      for (int i=0; i < expDocNrs.length; i++) {\n        expDocNrs[i] = PRE_FILLER_DOCS + ((NUM_FILLER_DOCS + 1) * expDocNrs[i]);\n      }\n    }\n    \n    final int topDocsToCheck = atLeast(1000);\n    // The asserting searcher will sometimes return the bulk scorer and\n    // sometimes return a default impl around the scorer so that we can\n    // compare BS1 and BS2\n    TopScoreDocCollector collector = TopScoreDocCollector.create(topDocsToCheck);\n    searcher.search(query, collector);\n    ScoreDoc[] hits1 = collector.topDocs().scoreDocs;\n    collector = TopScoreDocCollector.create(topDocsToCheck);\n    searcher.search(query, collector);\n    ScoreDoc[] hits2 = collector.topDocs().scoreDocs; \n\n    CheckHits.checkHitsQuery(query, hits1, hits2, expDocNrs);\n\n    // Since we have no deleted docs, we should also be able to verify identical matches &\n    // scores against an single segment copy of our index\n    collector = TopScoreDocCollector.create(topDocsToCheck);\n    singleSegmentSearcher.search(query, collector);\n    hits2 = collector.topDocs().scoreDocs; \n    CheckHits.checkHitsQuery(query, hits1, hits2, expDocNrs);\n    \n    // sanity check expected num matches in bigSearcher\n    assertEquals(mulFactor * collector.totalHits,\n                 bigSearcher.search(query, 1).totalHits);\n\n    // now check 2 diff scorers from the bigSearcher as well\n    collector = TopScoreDocCollector.create(topDocsToCheck);\n    bigSearcher.search(query, collector);\n    hits1 = collector.topDocs().scoreDocs;\n    collector = TopScoreDocCollector.create(topDocsToCheck);\n    bigSearcher.search(query, collector);\n    hits2 = collector.topDocs().scoreDocs; \n\n    // NOTE: just comparing results, not vetting against expDocNrs\n    // since we have dups in bigSearcher\n    CheckHits.checkEqual(query, hits1, hits2);\n      \n  }\n\n","sourceOld":"  public void queriesTest(Query query, int[] expDocNrs) throws Exception {\n\n    // adjust the expected doc numbers according to our filler docs\n    if (0 < NUM_FILLER_DOCS) {\n      expDocNrs = Arrays.copyOf(expDocNrs, expDocNrs.length);\n      for (int i=0; i < expDocNrs.length; i++) {\n        expDocNrs[i] = PRE_FILLER_DOCS + ((NUM_FILLER_DOCS + 1) * expDocNrs[i]);\n      }\n    }\n    \n    final int topDocsToCheck = atLeast(1000);\n    // The asserting searcher will sometimes return the bulk scorer and\n    // sometimes return a default impl around the scorer so that we can\n    // compare BS1 and BS2\n    TopScoreDocCollector collector = TopScoreDocCollector.create(topDocsToCheck);\n    searcher.search(query, collector);\n    ScoreDoc[] hits1 = collector.topDocs().scoreDocs;\n    collector = TopScoreDocCollector.create(topDocsToCheck);\n    searcher.search(query, collector);\n    ScoreDoc[] hits2 = collector.topDocs().scoreDocs; \n\n    CheckHits.checkHitsQuery(query, hits1, hits2, expDocNrs);\n\n    // Since we have no deleted docs, we should also be able to verify identical matches &\n    // scores against an single segment copy of our index\n    collector = TopScoreDocCollector.create(topDocsToCheck);\n    singleSegmentSearcher.search(query, collector);\n    hits2 = collector.topDocs().scoreDocs; \n    CheckHits.checkHitsQuery(query, hits1, hits2, expDocNrs);\n    \n    // sanity check expected num matches in bigSearcher\n    assertEquals(mulFactor * collector.totalHits,\n                 bigSearcher.search(query, 1).totalHits);\n\n    // now check 2 diff scorers from the bigSearcher as well\n    collector = TopScoreDocCollector.create(topDocsToCheck);\n    bigSearcher.search(query, collector);\n    hits1 = collector.topDocs().scoreDocs;\n    collector = TopScoreDocCollector.create(topDocsToCheck);\n    bigSearcher.search(query, collector);\n    hits2 = collector.topDocs().scoreDocs; \n\n    // NOTE: just comparing results, not vetting against expDocNrs\n    // since we have dups in bigSearcher\n    CheckHits.checkEqual(query, hits1, hits2);\n      \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b70042a8a492f7054d480ccdd2be9796510d4327","date":1528386658,"type":3,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestBoolean2#queriesTest(Query,int[]).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestBoolean2#queriesTest(Query,int[]).mjava","sourceNew":"  public void queriesTest(Query query, int[] expDocNrs) throws Exception {\n\n    // adjust the expected doc numbers according to our filler docs\n    if (0 < NUM_FILLER_DOCS) {\n      expDocNrs = ArrayUtil.copyOfSubArray(expDocNrs, 0, expDocNrs.length);\n      for (int i=0; i < expDocNrs.length; i++) {\n        expDocNrs[i] = PRE_FILLER_DOCS + ((NUM_FILLER_DOCS + 1) * expDocNrs[i]);\n      }\n    }\n    \n    final int topDocsToCheck = atLeast(1000);\n    // The asserting searcher will sometimes return the bulk scorer and\n    // sometimes return a default impl around the scorer so that we can\n    // compare BS1 and BS2\n    TopScoreDocCollector collector = TopScoreDocCollector.create(topDocsToCheck);\n    searcher.search(query, collector);\n    ScoreDoc[] hits1 = collector.topDocs().scoreDocs;\n    collector = TopScoreDocCollector.create(topDocsToCheck);\n    searcher.search(query, collector);\n    ScoreDoc[] hits2 = collector.topDocs().scoreDocs; \n\n    CheckHits.checkHitsQuery(query, hits1, hits2, expDocNrs);\n\n    // Since we have no deleted docs, we should also be able to verify identical matches &\n    // scores against an single segment copy of our index\n    collector = TopScoreDocCollector.create(topDocsToCheck);\n    singleSegmentSearcher.search(query, collector);\n    hits2 = collector.topDocs().scoreDocs; \n    CheckHits.checkHitsQuery(query, hits1, hits2, expDocNrs);\n    \n    // sanity check expected num matches in bigSearcher\n    assertEquals(mulFactor * collector.totalHits,\n                 bigSearcher.search(query, 1).totalHits);\n\n    // now check 2 diff scorers from the bigSearcher as well\n    collector = TopScoreDocCollector.create(topDocsToCheck);\n    bigSearcher.search(query, collector);\n    hits1 = collector.topDocs().scoreDocs;\n    collector = TopScoreDocCollector.create(topDocsToCheck);\n    bigSearcher.search(query, collector);\n    hits2 = collector.topDocs().scoreDocs; \n\n    // NOTE: just comparing results, not vetting against expDocNrs\n    // since we have dups in bigSearcher\n    CheckHits.checkEqual(query, hits1, hits2);\n      \n  }\n\n","sourceOld":"  public void queriesTest(Query query, int[] expDocNrs) throws Exception {\n\n    // adjust the expected doc numbers according to our filler docs\n    if (0 < NUM_FILLER_DOCS) {\n      expDocNrs = Arrays.copyOf(expDocNrs, expDocNrs.length);\n      for (int i=0; i < expDocNrs.length; i++) {\n        expDocNrs[i] = PRE_FILLER_DOCS + ((NUM_FILLER_DOCS + 1) * expDocNrs[i]);\n      }\n    }\n    \n    final int topDocsToCheck = atLeast(1000);\n    // The asserting searcher will sometimes return the bulk scorer and\n    // sometimes return a default impl around the scorer so that we can\n    // compare BS1 and BS2\n    TopScoreDocCollector collector = TopScoreDocCollector.create(topDocsToCheck);\n    searcher.search(query, collector);\n    ScoreDoc[] hits1 = collector.topDocs().scoreDocs;\n    collector = TopScoreDocCollector.create(topDocsToCheck);\n    searcher.search(query, collector);\n    ScoreDoc[] hits2 = collector.topDocs().scoreDocs; \n\n    CheckHits.checkHitsQuery(query, hits1, hits2, expDocNrs);\n\n    // Since we have no deleted docs, we should also be able to verify identical matches &\n    // scores against an single segment copy of our index\n    collector = TopScoreDocCollector.create(topDocsToCheck);\n    singleSegmentSearcher.search(query, collector);\n    hits2 = collector.topDocs().scoreDocs; \n    CheckHits.checkHitsQuery(query, hits1, hits2, expDocNrs);\n    \n    // sanity check expected num matches in bigSearcher\n    assertEquals(mulFactor * collector.totalHits,\n                 bigSearcher.search(query, 1).totalHits);\n\n    // now check 2 diff scorers from the bigSearcher as well\n    collector = TopScoreDocCollector.create(topDocsToCheck);\n    bigSearcher.search(query, collector);\n    hits1 = collector.topDocs().scoreDocs;\n    collector = TopScoreDocCollector.create(topDocsToCheck);\n    bigSearcher.search(query, collector);\n    hits2 = collector.topDocs().scoreDocs; \n\n    // NOTE: just comparing results, not vetting against expDocNrs\n    // since we have dups in bigSearcher\n    CheckHits.checkEqual(query, hits1, hits2);\n      \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26","date":1531589977,"type":3,"author":"Michael Braun","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestBoolean2#queriesTest(Query,int[]).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestBoolean2#queriesTest(Query,int[]).mjava","sourceNew":"  public void queriesTest(Query query, int[] expDocNrs) throws Exception {\n\n    // adjust the expected doc numbers according to our filler docs\n    if (0 < NUM_FILLER_DOCS) {\n      expDocNrs = ArrayUtil.copyOfSubArray(expDocNrs, 0, expDocNrs.length);\n      for (int i=0; i < expDocNrs.length; i++) {\n        expDocNrs[i] = PRE_FILLER_DOCS + ((NUM_FILLER_DOCS + 1) * expDocNrs[i]);\n      }\n    }\n    \n    final int topDocsToCheck = atLeast(1000);\n    // The asserting searcher will sometimes return the bulk scorer and\n    // sometimes return a default impl around the scorer so that we can\n    // compare BS1 and BS2\n    TopScoreDocCollector collector = TopScoreDocCollector.create(topDocsToCheck);\n    searcher.search(query, collector);\n    ScoreDoc[] hits1 = collector.topDocs().scoreDocs;\n    collector = TopScoreDocCollector.create(topDocsToCheck);\n    searcher.search(query, collector);\n    ScoreDoc[] hits2 = collector.topDocs().scoreDocs; \n\n    CheckHits.checkHitsQuery(query, hits1, hits2, expDocNrs);\n\n    // Since we have no deleted docs, we should also be able to verify identical matches &\n    // scores against an single segment copy of our index\n    collector = TopScoreDocCollector.create(topDocsToCheck);\n    singleSegmentSearcher.search(query, collector);\n    hits2 = collector.topDocs().scoreDocs; \n    CheckHits.checkHitsQuery(query, hits1, hits2, expDocNrs);\n    \n    // sanity check expected num matches in bigSearcher\n    assertEquals(mulFactor * collector.totalHits,\n                 bigSearcher.search(query, 1).totalHits);\n\n    // now check 2 diff scorers from the bigSearcher as well\n    collector = TopScoreDocCollector.create(topDocsToCheck);\n    bigSearcher.search(query, collector);\n    hits1 = collector.topDocs().scoreDocs;\n    collector = TopScoreDocCollector.create(topDocsToCheck);\n    bigSearcher.search(query, collector);\n    hits2 = collector.topDocs().scoreDocs; \n\n    // NOTE: just comparing results, not vetting against expDocNrs\n    // since we have dups in bigSearcher\n    CheckHits.checkEqual(query, hits1, hits2);\n      \n  }\n\n","sourceOld":"  public void queriesTest(Query query, int[] expDocNrs) throws Exception {\n\n    // adjust the expected doc numbers according to our filler docs\n    if (0 < NUM_FILLER_DOCS) {\n      expDocNrs = Arrays.copyOf(expDocNrs, expDocNrs.length);\n      for (int i=0; i < expDocNrs.length; i++) {\n        expDocNrs[i] = PRE_FILLER_DOCS + ((NUM_FILLER_DOCS + 1) * expDocNrs[i]);\n      }\n    }\n    \n    final int topDocsToCheck = atLeast(1000);\n    // The asserting searcher will sometimes return the bulk scorer and\n    // sometimes return a default impl around the scorer so that we can\n    // compare BS1 and BS2\n    TopScoreDocCollector collector = TopScoreDocCollector.create(topDocsToCheck);\n    searcher.search(query, collector);\n    ScoreDoc[] hits1 = collector.topDocs().scoreDocs;\n    collector = TopScoreDocCollector.create(topDocsToCheck);\n    searcher.search(query, collector);\n    ScoreDoc[] hits2 = collector.topDocs().scoreDocs; \n\n    CheckHits.checkHitsQuery(query, hits1, hits2, expDocNrs);\n\n    // Since we have no deleted docs, we should also be able to verify identical matches &\n    // scores against an single segment copy of our index\n    collector = TopScoreDocCollector.create(topDocsToCheck);\n    singleSegmentSearcher.search(query, collector);\n    hits2 = collector.topDocs().scoreDocs; \n    CheckHits.checkHitsQuery(query, hits1, hits2, expDocNrs);\n    \n    // sanity check expected num matches in bigSearcher\n    assertEquals(mulFactor * collector.totalHits,\n                 bigSearcher.search(query, 1).totalHits);\n\n    // now check 2 diff scorers from the bigSearcher as well\n    collector = TopScoreDocCollector.create(topDocsToCheck);\n    bigSearcher.search(query, collector);\n    hits1 = collector.topDocs().scoreDocs;\n    collector = TopScoreDocCollector.create(topDocsToCheck);\n    bigSearcher.search(query, collector);\n    hits2 = collector.topDocs().scoreDocs; \n\n    // NOTE: just comparing results, not vetting against expDocNrs\n    // since we have dups in bigSearcher\n    CheckHits.checkEqual(query, hits1, hits2);\n      \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"83788ad129a5154d5c6562c4e8ce3db48793aada","date":1532961485,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestBoolean2#queriesTest(Query,int[]).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestBoolean2#queriesTest(Query,int[]).mjava","sourceNew":"  public void queriesTest(Query query, int[] expDocNrs) throws Exception {\n\n    // adjust the expected doc numbers according to our filler docs\n    if (0 < NUM_FILLER_DOCS) {\n      expDocNrs = ArrayUtil.copyOfSubArray(expDocNrs, 0, expDocNrs.length);\n      for (int i=0; i < expDocNrs.length; i++) {\n        expDocNrs[i] = PRE_FILLER_DOCS + ((NUM_FILLER_DOCS + 1) * expDocNrs[i]);\n      }\n    }\n    \n    final int topDocsToCheck = atLeast(1000);\n    // The asserting searcher will sometimes return the bulk scorer and\n    // sometimes return a default impl around the scorer so that we can\n    // compare BS1 and BS2\n    TopScoreDocCollector collector = TopScoreDocCollector.create(topDocsToCheck);\n    searcher.search(query, collector);\n    ScoreDoc[] hits1 = collector.topDocs().scoreDocs;\n    collector = TopScoreDocCollector.create(topDocsToCheck);\n    searcher.search(query, collector);\n    ScoreDoc[] hits2 = collector.topDocs().scoreDocs; \n\n    CheckHits.checkHitsQuery(query, hits1, hits2, expDocNrs);\n\n    // Since we have no deleted docs, we should also be able to verify identical matches &\n    // scores against an single segment copy of our index\n    collector = TopScoreDocCollector.create(topDocsToCheck);\n    singleSegmentSearcher.search(query, collector);\n    hits2 = collector.topDocs().scoreDocs; \n    CheckHits.checkHitsQuery(query, hits1, hits2, expDocNrs);\n    \n    // sanity check expected num matches in bigSearcher\n    assertEquals(mulFactor * collector.totalHits,\n                 bigSearcher.search(query, 1).totalHits.value);\n\n    // now check 2 diff scorers from the bigSearcher as well\n    collector = TopScoreDocCollector.create(topDocsToCheck);\n    bigSearcher.search(query, collector);\n    hits1 = collector.topDocs().scoreDocs;\n    collector = TopScoreDocCollector.create(topDocsToCheck);\n    bigSearcher.search(query, collector);\n    hits2 = collector.topDocs().scoreDocs; \n\n    // NOTE: just comparing results, not vetting against expDocNrs\n    // since we have dups in bigSearcher\n    CheckHits.checkEqual(query, hits1, hits2);\n      \n  }\n\n","sourceOld":"  public void queriesTest(Query query, int[] expDocNrs) throws Exception {\n\n    // adjust the expected doc numbers according to our filler docs\n    if (0 < NUM_FILLER_DOCS) {\n      expDocNrs = ArrayUtil.copyOfSubArray(expDocNrs, 0, expDocNrs.length);\n      for (int i=0; i < expDocNrs.length; i++) {\n        expDocNrs[i] = PRE_FILLER_DOCS + ((NUM_FILLER_DOCS + 1) * expDocNrs[i]);\n      }\n    }\n    \n    final int topDocsToCheck = atLeast(1000);\n    // The asserting searcher will sometimes return the bulk scorer and\n    // sometimes return a default impl around the scorer so that we can\n    // compare BS1 and BS2\n    TopScoreDocCollector collector = TopScoreDocCollector.create(topDocsToCheck);\n    searcher.search(query, collector);\n    ScoreDoc[] hits1 = collector.topDocs().scoreDocs;\n    collector = TopScoreDocCollector.create(topDocsToCheck);\n    searcher.search(query, collector);\n    ScoreDoc[] hits2 = collector.topDocs().scoreDocs; \n\n    CheckHits.checkHitsQuery(query, hits1, hits2, expDocNrs);\n\n    // Since we have no deleted docs, we should also be able to verify identical matches &\n    // scores against an single segment copy of our index\n    collector = TopScoreDocCollector.create(topDocsToCheck);\n    singleSegmentSearcher.search(query, collector);\n    hits2 = collector.topDocs().scoreDocs; \n    CheckHits.checkHitsQuery(query, hits1, hits2, expDocNrs);\n    \n    // sanity check expected num matches in bigSearcher\n    assertEquals(mulFactor * collector.totalHits,\n                 bigSearcher.search(query, 1).totalHits);\n\n    // now check 2 diff scorers from the bigSearcher as well\n    collector = TopScoreDocCollector.create(topDocsToCheck);\n    bigSearcher.search(query, collector);\n    hits1 = collector.topDocs().scoreDocs;\n    collector = TopScoreDocCollector.create(topDocsToCheck);\n    bigSearcher.search(query, collector);\n    hits2 = collector.topDocs().scoreDocs; \n\n    // NOTE: just comparing results, not vetting against expDocNrs\n    // since we have dups in bigSearcher\n    CheckHits.checkEqual(query, hits1, hits2);\n      \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fe3c6364bed04a73ad0884b05401d80ce96027a9","date":1532961485,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestBoolean2#queriesTest(Query,int[]).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestBoolean2#queriesTest(Query,int[]).mjava","sourceNew":"  public void queriesTest(Query query, int[] expDocNrs) throws Exception {\n\n    // adjust the expected doc numbers according to our filler docs\n    if (0 < NUM_FILLER_DOCS) {\n      expDocNrs = ArrayUtil.copyOfSubArray(expDocNrs, 0, expDocNrs.length);\n      for (int i=0; i < expDocNrs.length; i++) {\n        expDocNrs[i] = PRE_FILLER_DOCS + ((NUM_FILLER_DOCS + 1) * expDocNrs[i]);\n      }\n    }\n    \n    final int topDocsToCheck = atLeast(1000);\n    // The asserting searcher will sometimes return the bulk scorer and\n    // sometimes return a default impl around the scorer so that we can\n    // compare BS1 and BS2\n    TopScoreDocCollector collector = TopScoreDocCollector.create(topDocsToCheck, Integer.MAX_VALUE);\n    searcher.search(query, collector);\n    ScoreDoc[] hits1 = collector.topDocs().scoreDocs;\n    collector = TopScoreDocCollector.create(topDocsToCheck, Integer.MAX_VALUE);\n    searcher.search(query, collector);\n    ScoreDoc[] hits2 = collector.topDocs().scoreDocs; \n\n    CheckHits.checkHitsQuery(query, hits1, hits2, expDocNrs);\n\n    // Since we have no deleted docs, we should also be able to verify identical matches &\n    // scores against an single segment copy of our index\n    collector = TopScoreDocCollector.create(topDocsToCheck, Integer.MAX_VALUE);\n    singleSegmentSearcher.search(query, collector);\n    hits2 = collector.topDocs().scoreDocs; \n    CheckHits.checkHitsQuery(query, hits1, hits2, expDocNrs);\n    \n    // sanity check expected num matches in bigSearcher\n    assertEquals(mulFactor * collector.totalHits,\n                 bigSearcher.search(query, 1).totalHits.value);\n\n    // now check 2 diff scorers from the bigSearcher as well\n    collector = TopScoreDocCollector.create(topDocsToCheck, Integer.MAX_VALUE);\n    bigSearcher.search(query, collector);\n    hits1 = collector.topDocs().scoreDocs;\n    collector = TopScoreDocCollector.create(topDocsToCheck, Integer.MAX_VALUE);\n    bigSearcher.search(query, collector);\n    hits2 = collector.topDocs().scoreDocs; \n\n    // NOTE: just comparing results, not vetting against expDocNrs\n    // since we have dups in bigSearcher\n    CheckHits.checkEqual(query, hits1, hits2);\n      \n  }\n\n","sourceOld":"  public void queriesTest(Query query, int[] expDocNrs) throws Exception {\n\n    // adjust the expected doc numbers according to our filler docs\n    if (0 < NUM_FILLER_DOCS) {\n      expDocNrs = ArrayUtil.copyOfSubArray(expDocNrs, 0, expDocNrs.length);\n      for (int i=0; i < expDocNrs.length; i++) {\n        expDocNrs[i] = PRE_FILLER_DOCS + ((NUM_FILLER_DOCS + 1) * expDocNrs[i]);\n      }\n    }\n    \n    final int topDocsToCheck = atLeast(1000);\n    // The asserting searcher will sometimes return the bulk scorer and\n    // sometimes return a default impl around the scorer so that we can\n    // compare BS1 and BS2\n    TopScoreDocCollector collector = TopScoreDocCollector.create(topDocsToCheck);\n    searcher.search(query, collector);\n    ScoreDoc[] hits1 = collector.topDocs().scoreDocs;\n    collector = TopScoreDocCollector.create(topDocsToCheck);\n    searcher.search(query, collector);\n    ScoreDoc[] hits2 = collector.topDocs().scoreDocs; \n\n    CheckHits.checkHitsQuery(query, hits1, hits2, expDocNrs);\n\n    // Since we have no deleted docs, we should also be able to verify identical matches &\n    // scores against an single segment copy of our index\n    collector = TopScoreDocCollector.create(topDocsToCheck);\n    singleSegmentSearcher.search(query, collector);\n    hits2 = collector.topDocs().scoreDocs; \n    CheckHits.checkHitsQuery(query, hits1, hits2, expDocNrs);\n    \n    // sanity check expected num matches in bigSearcher\n    assertEquals(mulFactor * collector.totalHits,\n                 bigSearcher.search(query, 1).totalHits.value);\n\n    // now check 2 diff scorers from the bigSearcher as well\n    collector = TopScoreDocCollector.create(topDocsToCheck);\n    bigSearcher.search(query, collector);\n    hits1 = collector.topDocs().scoreDocs;\n    collector = TopScoreDocCollector.create(topDocsToCheck);\n    bigSearcher.search(query, collector);\n    hits2 = collector.topDocs().scoreDocs; \n\n    // NOTE: just comparing results, not vetting against expDocNrs\n    // since we have dups in bigSearcher\n    CheckHits.checkEqual(query, hits1, hits2);\n      \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e708f948b384f9aa85c665caee4486eb2d9e197d","date":1533106881,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestBoolean2#queriesTest(Query,int[]).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestBoolean2#queriesTest(Query,int[]).mjava","sourceNew":"  public void queriesTest(Query query, int[] expDocNrs) throws Exception {\n\n    // adjust the expected doc numbers according to our filler docs\n    if (0 < NUM_FILLER_DOCS) {\n      expDocNrs = ArrayUtil.copyOfSubArray(expDocNrs, 0, expDocNrs.length);\n      for (int i=0; i < expDocNrs.length; i++) {\n        expDocNrs[i] = PRE_FILLER_DOCS + ((NUM_FILLER_DOCS + 1) * expDocNrs[i]);\n      }\n    }\n    \n    final int topDocsToCheck = atLeast(1000);\n    // The asserting searcher will sometimes return the bulk scorer and\n    // sometimes return a default impl around the scorer so that we can\n    // compare BS1 and BS2\n    TopScoreDocCollector collector = TopScoreDocCollector.create(topDocsToCheck, Integer.MAX_VALUE);\n    searcher.search(query, collector);\n    ScoreDoc[] hits1 = collector.topDocs().scoreDocs;\n    collector = TopScoreDocCollector.create(topDocsToCheck, Integer.MAX_VALUE);\n    searcher.search(query, collector);\n    ScoreDoc[] hits2 = collector.topDocs().scoreDocs; \n\n    CheckHits.checkHitsQuery(query, hits1, hits2, expDocNrs);\n\n    // Since we have no deleted docs, we should also be able to verify identical matches &\n    // scores against an single segment copy of our index\n    collector = TopScoreDocCollector.create(topDocsToCheck, Integer.MAX_VALUE);\n    singleSegmentSearcher.search(query, collector);\n    hits2 = collector.topDocs().scoreDocs; \n    CheckHits.checkHitsQuery(query, hits1, hits2, expDocNrs);\n    \n    // sanity check expected num matches in bigSearcher\n    assertEquals(mulFactor * collector.totalHits,\n                 bigSearcher.count(query));\n\n    // now check 2 diff scorers from the bigSearcher as well\n    collector = TopScoreDocCollector.create(topDocsToCheck, Integer.MAX_VALUE);\n    bigSearcher.search(query, collector);\n    hits1 = collector.topDocs().scoreDocs;\n    collector = TopScoreDocCollector.create(topDocsToCheck, Integer.MAX_VALUE);\n    bigSearcher.search(query, collector);\n    hits2 = collector.topDocs().scoreDocs; \n\n    // NOTE: just comparing results, not vetting against expDocNrs\n    // since we have dups in bigSearcher\n    CheckHits.checkEqual(query, hits1, hits2);\n      \n  }\n\n","sourceOld":"  public void queriesTest(Query query, int[] expDocNrs) throws Exception {\n\n    // adjust the expected doc numbers according to our filler docs\n    if (0 < NUM_FILLER_DOCS) {\n      expDocNrs = ArrayUtil.copyOfSubArray(expDocNrs, 0, expDocNrs.length);\n      for (int i=0; i < expDocNrs.length; i++) {\n        expDocNrs[i] = PRE_FILLER_DOCS + ((NUM_FILLER_DOCS + 1) * expDocNrs[i]);\n      }\n    }\n    \n    final int topDocsToCheck = atLeast(1000);\n    // The asserting searcher will sometimes return the bulk scorer and\n    // sometimes return a default impl around the scorer so that we can\n    // compare BS1 and BS2\n    TopScoreDocCollector collector = TopScoreDocCollector.create(topDocsToCheck, Integer.MAX_VALUE);\n    searcher.search(query, collector);\n    ScoreDoc[] hits1 = collector.topDocs().scoreDocs;\n    collector = TopScoreDocCollector.create(topDocsToCheck, Integer.MAX_VALUE);\n    searcher.search(query, collector);\n    ScoreDoc[] hits2 = collector.topDocs().scoreDocs; \n\n    CheckHits.checkHitsQuery(query, hits1, hits2, expDocNrs);\n\n    // Since we have no deleted docs, we should also be able to verify identical matches &\n    // scores against an single segment copy of our index\n    collector = TopScoreDocCollector.create(topDocsToCheck, Integer.MAX_VALUE);\n    singleSegmentSearcher.search(query, collector);\n    hits2 = collector.topDocs().scoreDocs; \n    CheckHits.checkHitsQuery(query, hits1, hits2, expDocNrs);\n    \n    // sanity check expected num matches in bigSearcher\n    assertEquals(mulFactor * collector.totalHits,\n                 bigSearcher.search(query, 1).totalHits.value);\n\n    // now check 2 diff scorers from the bigSearcher as well\n    collector = TopScoreDocCollector.create(topDocsToCheck, Integer.MAX_VALUE);\n    bigSearcher.search(query, collector);\n    hits1 = collector.topDocs().scoreDocs;\n    collector = TopScoreDocCollector.create(topDocsToCheck, Integer.MAX_VALUE);\n    bigSearcher.search(query, collector);\n    hits2 = collector.topDocs().scoreDocs; \n\n    // NOTE: just comparing results, not vetting against expDocNrs\n    // since we have dups in bigSearcher\n    CheckHits.checkEqual(query, hits1, hits2);\n      \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"e708f948b384f9aa85c665caee4486eb2d9e197d":["fe3c6364bed04a73ad0884b05401d80ce96027a9"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"191128ac5b85671b1671e2c857437694283b6ebf":["f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc","7c82b0d4b7bf499a159eeff92add20bac6599cc1"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc","191128ac5b85671b1671e2c857437694283b6ebf"],"7c82b0d4b7bf499a159eeff92add20bac6599cc1":["f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc"],"f582f18c13d4852b01d4fe0a0196432c5c6f2b7f":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc":["f582f18c13d4852b01d4fe0a0196432c5c6f2b7f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b70042a8a492f7054d480ccdd2be9796510d4327":["191128ac5b85671b1671e2c857437694283b6ebf","9798d0818e7a880546802b509792d3f3d57babd2"],"83788ad129a5154d5c6562c4e8ce3db48793aada":["9798d0818e7a880546802b509792d3f3d57babd2"],"9798d0818e7a880546802b509792d3f3d57babd2":["191128ac5b85671b1671e2c857437694283b6ebf"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["e708f948b384f9aa85c665caee4486eb2d9e197d"],"fe3c6364bed04a73ad0884b05401d80ce96027a9":["83788ad129a5154d5c6562c4e8ce3db48793aada"],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":["191128ac5b85671b1671e2c857437694283b6ebf","9798d0818e7a880546802b509792d3f3d57babd2"]},"commit2Childs":{"e708f948b384f9aa85c665caee4486eb2d9e197d":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["f582f18c13d4852b01d4fe0a0196432c5c6f2b7f"],"191128ac5b85671b1671e2c857437694283b6ebf":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","b70042a8a492f7054d480ccdd2be9796510d4327","9798d0818e7a880546802b509792d3f3d57babd2","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"7c82b0d4b7bf499a159eeff92add20bac6599cc1":["191128ac5b85671b1671e2c857437694283b6ebf"],"f582f18c13d4852b01d4fe0a0196432c5c6f2b7f":["f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc":["191128ac5b85671b1671e2c857437694283b6ebf","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","7c82b0d4b7bf499a159eeff92add20bac6599cc1"],"b70042a8a492f7054d480ccdd2be9796510d4327":[],"83788ad129a5154d5c6562c4e8ce3db48793aada":["fe3c6364bed04a73ad0884b05401d80ce96027a9"],"9798d0818e7a880546802b509792d3f3d57babd2":["b70042a8a492f7054d480ccdd2be9796510d4327","83788ad129a5154d5c6562c4e8ce3db48793aada","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"fe3c6364bed04a73ad0884b05401d80ce96027a9":["e708f948b384f9aa85c665caee4486eb2d9e197d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":[]},"heads":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","b70042a8a492f7054d480ccdd2be9796510d4327","cd5edd1f2b162a5cfa08efd17851a07373a96817","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}