{"path":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testOnUseWithRandomFirstSegmentSkipping().mjava","commits":[{"id":"0bf09e549fa47b894ce44baafdf8031eba2445c6","date":1436204317,"type":0,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testOnUseWithRandomFirstSegmentSkipping().mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Tests CachingWrapperWeight.scorer() propagation of {@link QueryCachingPolicy#onUse(Query)} when the first segment\n   * is skipped.\n   *\n   * #f:foo #f:bar causes all frequencies to increment\n   * #f:bar #f:foo does not increment the frequency for f:foo\n   */\n  public void testOnUseWithRandomFirstSegmentSkipping() throws IOException {\n    try (final Directory directory = newDirectory()) {\n      try (final RandomIndexWriter indexWriter = new RandomIndexWriter(random(), directory, newIndexWriterConfig().setMergePolicy(NoMergePolicy.INSTANCE))) {\n        Document doc = new Document();\n        doc.add(new StringField(\"f\", \"bar\", Store.NO));\n        indexWriter.addDocument(doc);\n        if (random().nextBoolean()) {\n          indexWriter.getReader().close();\n        }\n        doc = new Document();\n        doc.add(new StringField(\"f\", \"foo\", Store.NO));\n        doc.add(new StringField(\"f\", \"bar\", Store.NO));\n        indexWriter.addDocument(doc);\n        indexWriter.commit();\n      }\n      try (final IndexReader indexReader = DirectoryReader.open(directory)) {\n        final FrequencyCountingPolicy policy = new FrequencyCountingPolicy();\n        final IndexSearcher indexSearcher = new IndexSearcher(indexReader);\n        indexSearcher.setQueryCache(new LRUQueryCache(100, 10240));\n        indexSearcher.setQueryCachingPolicy(policy);\n        final Query foo = new TermQuery(new Term(\"f\", \"foo\"));\n        final Query bar = new TermQuery(new Term(\"f\", \"bar\"));\n        final BooleanQuery.Builder query = new BooleanQuery.Builder();\n        if (random().nextBoolean()) {\n          query.add(foo, Occur.FILTER);\n          query.add(bar, Occur.FILTER);\n        } else {\n          query.add(bar, Occur.FILTER);\n          query.add(foo, Occur.FILTER);\n        }\n        indexSearcher.count(query.build());\n        assertEquals(1, policy.frequency(query.build()));\n        assertEquals(1, policy.frequency(foo));\n        assertEquals(1, policy.frequency(bar));\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"aac61ee5b4492f174e60bd54939aba9539906edf","date":1461245473,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testOnUseWithRandomFirstSegmentSkipping().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testOnUseWithRandomFirstSegmentSkipping().mjava","sourceNew":"  /**\n   * Tests CachingWrapperWeight.scorer() propagation of {@link QueryCachingPolicy#onUse(Query)} when the first segment\n   * is skipped.\n   *\n   * #f:foo #f:bar causes all frequencies to increment\n   * #f:bar #f:foo does not increment the frequency for f:foo\n   */\n  public void testOnUseWithRandomFirstSegmentSkipping() throws IOException {\n    try (final Directory directory = newDirectory()) {\n      try (final RandomIndexWriter indexWriter = new RandomIndexWriter(random(), directory, newIndexWriterConfig().setMergePolicy(NoMergePolicy.INSTANCE))) {\n        Document doc = new Document();\n        doc.add(new StringField(\"f\", \"bar\", Store.NO));\n        indexWriter.addDocument(doc);\n        if (random().nextBoolean()) {\n          indexWriter.getReader().close();\n        }\n        doc = new Document();\n        doc.add(new StringField(\"f\", \"foo\", Store.NO));\n        doc.add(new StringField(\"f\", \"bar\", Store.NO));\n        indexWriter.addDocument(doc);\n        indexWriter.commit();\n      }\n      try (final IndexReader indexReader = DirectoryReader.open(directory)) {\n        final FrequencyCountingPolicy policy = new FrequencyCountingPolicy();\n        final IndexSearcher indexSearcher = new IndexSearcher(indexReader);\n        indexSearcher.setQueryCache(new LRUQueryCache(100, 10240, context -> random().nextBoolean()));\n        indexSearcher.setQueryCachingPolicy(policy);\n        final Query foo = new TermQuery(new Term(\"f\", \"foo\"));\n        final Query bar = new TermQuery(new Term(\"f\", \"bar\"));\n        final BooleanQuery.Builder query = new BooleanQuery.Builder();\n        if (random().nextBoolean()) {\n          query.add(foo, Occur.FILTER);\n          query.add(bar, Occur.FILTER);\n        } else {\n          query.add(bar, Occur.FILTER);\n          query.add(foo, Occur.FILTER);\n        }\n        indexSearcher.count(query.build());\n        assertEquals(1, policy.frequency(query.build()));\n        assertEquals(1, policy.frequency(foo));\n        assertEquals(1, policy.frequency(bar));\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Tests CachingWrapperWeight.scorer() propagation of {@link QueryCachingPolicy#onUse(Query)} when the first segment\n   * is skipped.\n   *\n   * #f:foo #f:bar causes all frequencies to increment\n   * #f:bar #f:foo does not increment the frequency for f:foo\n   */\n  public void testOnUseWithRandomFirstSegmentSkipping() throws IOException {\n    try (final Directory directory = newDirectory()) {\n      try (final RandomIndexWriter indexWriter = new RandomIndexWriter(random(), directory, newIndexWriterConfig().setMergePolicy(NoMergePolicy.INSTANCE))) {\n        Document doc = new Document();\n        doc.add(new StringField(\"f\", \"bar\", Store.NO));\n        indexWriter.addDocument(doc);\n        if (random().nextBoolean()) {\n          indexWriter.getReader().close();\n        }\n        doc = new Document();\n        doc.add(new StringField(\"f\", \"foo\", Store.NO));\n        doc.add(new StringField(\"f\", \"bar\", Store.NO));\n        indexWriter.addDocument(doc);\n        indexWriter.commit();\n      }\n      try (final IndexReader indexReader = DirectoryReader.open(directory)) {\n        final FrequencyCountingPolicy policy = new FrequencyCountingPolicy();\n        final IndexSearcher indexSearcher = new IndexSearcher(indexReader);\n        indexSearcher.setQueryCache(new LRUQueryCache(100, 10240));\n        indexSearcher.setQueryCachingPolicy(policy);\n        final Query foo = new TermQuery(new Term(\"f\", \"foo\"));\n        final Query bar = new TermQuery(new Term(\"f\", \"bar\"));\n        final BooleanQuery.Builder query = new BooleanQuery.Builder();\n        if (random().nextBoolean()) {\n          query.add(foo, Occur.FILTER);\n          query.add(bar, Occur.FILTER);\n        } else {\n          query.add(bar, Occur.FILTER);\n          query.add(foo, Occur.FILTER);\n        }\n        indexSearcher.count(query.build());\n        assertEquals(1, policy.frequency(query.build()));\n        assertEquals(1, policy.frequency(foo));\n        assertEquals(1, policy.frequency(bar));\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c7732a106554be0db3e03ac5211e46f6e0c285b8","date":1511975378,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testOnUseWithRandomFirstSegmentSkipping().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testOnUseWithRandomFirstSegmentSkipping().mjava","sourceNew":"  /**\n   * Tests CachingWrapperWeight.scorer() propagation of {@link QueryCachingPolicy#onUse(Query)} when the first segment\n   * is skipped.\n   *\n   * #f:foo #f:bar causes all frequencies to increment\n   * #f:bar #f:foo does not increment the frequency for f:foo\n   */\n  public void testOnUseWithRandomFirstSegmentSkipping() throws IOException {\n    try (final Directory directory = newDirectory()) {\n      try (final RandomIndexWriter indexWriter = new RandomIndexWriter(random(), directory, newIndexWriterConfig().setMergePolicy(NoMergePolicy.INSTANCE))) {\n        Document doc = new Document();\n        doc.add(new StringField(\"f\", \"bar\", Store.NO));\n        indexWriter.addDocument(doc);\n        if (random().nextBoolean()) {\n          indexWriter.getReader().close();\n        }\n        doc = new Document();\n        doc.add(new StringField(\"f\", \"foo\", Store.NO));\n        doc.add(new StringField(\"f\", \"bar\", Store.NO));\n        indexWriter.addDocument(doc);\n        indexWriter.commit();\n      }\n      try (final IndexReader indexReader = DirectoryReader.open(directory)) {\n        final FrequencyCountingPolicy policy = new FrequencyCountingPolicy();\n        final IndexSearcher indexSearcher = new IndexSearcher(indexReader);\n        indexSearcher.setQueryCache(new LRUQueryCache(100, 10240, context -> random().nextBoolean(), Float.POSITIVE_INFINITY));\n        indexSearcher.setQueryCachingPolicy(policy);\n        final Query foo = new TermQuery(new Term(\"f\", \"foo\"));\n        final Query bar = new TermQuery(new Term(\"f\", \"bar\"));\n        final BooleanQuery.Builder query = new BooleanQuery.Builder();\n        if (random().nextBoolean()) {\n          query.add(foo, Occur.FILTER);\n          query.add(bar, Occur.FILTER);\n        } else {\n          query.add(bar, Occur.FILTER);\n          query.add(foo, Occur.FILTER);\n        }\n        indexSearcher.count(query.build());\n        assertEquals(1, policy.frequency(query.build()));\n        assertEquals(1, policy.frequency(foo));\n        assertEquals(1, policy.frequency(bar));\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Tests CachingWrapperWeight.scorer() propagation of {@link QueryCachingPolicy#onUse(Query)} when the first segment\n   * is skipped.\n   *\n   * #f:foo #f:bar causes all frequencies to increment\n   * #f:bar #f:foo does not increment the frequency for f:foo\n   */\n  public void testOnUseWithRandomFirstSegmentSkipping() throws IOException {\n    try (final Directory directory = newDirectory()) {\n      try (final RandomIndexWriter indexWriter = new RandomIndexWriter(random(), directory, newIndexWriterConfig().setMergePolicy(NoMergePolicy.INSTANCE))) {\n        Document doc = new Document();\n        doc.add(new StringField(\"f\", \"bar\", Store.NO));\n        indexWriter.addDocument(doc);\n        if (random().nextBoolean()) {\n          indexWriter.getReader().close();\n        }\n        doc = new Document();\n        doc.add(new StringField(\"f\", \"foo\", Store.NO));\n        doc.add(new StringField(\"f\", \"bar\", Store.NO));\n        indexWriter.addDocument(doc);\n        indexWriter.commit();\n      }\n      try (final IndexReader indexReader = DirectoryReader.open(directory)) {\n        final FrequencyCountingPolicy policy = new FrequencyCountingPolicy();\n        final IndexSearcher indexSearcher = new IndexSearcher(indexReader);\n        indexSearcher.setQueryCache(new LRUQueryCache(100, 10240, context -> random().nextBoolean()));\n        indexSearcher.setQueryCachingPolicy(policy);\n        final Query foo = new TermQuery(new Term(\"f\", \"foo\"));\n        final Query bar = new TermQuery(new Term(\"f\", \"bar\"));\n        final BooleanQuery.Builder query = new BooleanQuery.Builder();\n        if (random().nextBoolean()) {\n          query.add(foo, Occur.FILTER);\n          query.add(bar, Occur.FILTER);\n        } else {\n          query.add(bar, Occur.FILTER);\n          query.add(foo, Occur.FILTER);\n        }\n        indexSearcher.count(query.build());\n        assertEquals(1, policy.frequency(query.build()));\n        assertEquals(1, policy.frequency(foo));\n        assertEquals(1, policy.frequency(bar));\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1aad05eeff7818b0833c02ac6b743aa72054963b","date":1512093122,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testOnUseWithRandomFirstSegmentSkipping().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testOnUseWithRandomFirstSegmentSkipping().mjava","sourceNew":"  /**\n   * Tests CachingWrapperWeight.scorer() propagation of {@link QueryCachingPolicy#onUse(Query)} when the first segment\n   * is skipped.\n   *\n   * #f:foo #f:bar causes all frequencies to increment\n   * #f:bar #f:foo does not increment the frequency for f:foo\n   */\n  public void testOnUseWithRandomFirstSegmentSkipping() throws IOException {\n    try (final Directory directory = newDirectory()) {\n      try (final RandomIndexWriter indexWriter = new RandomIndexWriter(random(), directory, newIndexWriterConfig().setMergePolicy(NoMergePolicy.INSTANCE))) {\n        Document doc = new Document();\n        doc.add(new StringField(\"f\", \"bar\", Store.NO));\n        indexWriter.addDocument(doc);\n        if (random().nextBoolean()) {\n          indexWriter.getReader().close();\n        }\n        doc = new Document();\n        doc.add(new StringField(\"f\", \"foo\", Store.NO));\n        doc.add(new StringField(\"f\", \"bar\", Store.NO));\n        indexWriter.addDocument(doc);\n        indexWriter.commit();\n      }\n      try (final IndexReader indexReader = DirectoryReader.open(directory)) {\n        final FrequencyCountingPolicy policy = new FrequencyCountingPolicy();\n        final IndexSearcher indexSearcher = new IndexSearcher(indexReader);\n        indexSearcher.setQueryCache(new LRUQueryCache(100, 10240, context -> random().nextBoolean(), Float.POSITIVE_INFINITY));\n        indexSearcher.setQueryCachingPolicy(policy);\n        final Query foo = new TermQuery(new Term(\"f\", \"foo\"));\n        final Query bar = new TermQuery(new Term(\"f\", \"bar\"));\n        final BooleanQuery.Builder query = new BooleanQuery.Builder();\n        if (random().nextBoolean()) {\n          query.add(foo, Occur.FILTER);\n          query.add(bar, Occur.FILTER);\n        } else {\n          query.add(bar, Occur.FILTER);\n          query.add(foo, Occur.FILTER);\n        }\n        indexSearcher.count(query.build());\n        assertEquals(1, policy.frequency(query.build()));\n        assertEquals(1, policy.frequency(foo));\n        assertEquals(1, policy.frequency(bar));\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Tests CachingWrapperWeight.scorer() propagation of {@link QueryCachingPolicy#onUse(Query)} when the first segment\n   * is skipped.\n   *\n   * #f:foo #f:bar causes all frequencies to increment\n   * #f:bar #f:foo does not increment the frequency for f:foo\n   */\n  public void testOnUseWithRandomFirstSegmentSkipping() throws IOException {\n    try (final Directory directory = newDirectory()) {\n      try (final RandomIndexWriter indexWriter = new RandomIndexWriter(random(), directory, newIndexWriterConfig().setMergePolicy(NoMergePolicy.INSTANCE))) {\n        Document doc = new Document();\n        doc.add(new StringField(\"f\", \"bar\", Store.NO));\n        indexWriter.addDocument(doc);\n        if (random().nextBoolean()) {\n          indexWriter.getReader().close();\n        }\n        doc = new Document();\n        doc.add(new StringField(\"f\", \"foo\", Store.NO));\n        doc.add(new StringField(\"f\", \"bar\", Store.NO));\n        indexWriter.addDocument(doc);\n        indexWriter.commit();\n      }\n      try (final IndexReader indexReader = DirectoryReader.open(directory)) {\n        final FrequencyCountingPolicy policy = new FrequencyCountingPolicy();\n        final IndexSearcher indexSearcher = new IndexSearcher(indexReader);\n        indexSearcher.setQueryCache(new LRUQueryCache(100, 10240, context -> random().nextBoolean()));\n        indexSearcher.setQueryCachingPolicy(policy);\n        final Query foo = new TermQuery(new Term(\"f\", \"foo\"));\n        final Query bar = new TermQuery(new Term(\"f\", \"bar\"));\n        final BooleanQuery.Builder query = new BooleanQuery.Builder();\n        if (random().nextBoolean()) {\n          query.add(foo, Occur.FILTER);\n          query.add(bar, Occur.FILTER);\n        } else {\n          query.add(bar, Occur.FILTER);\n          query.add(foo, Occur.FILTER);\n        }\n        indexSearcher.count(query.build());\n        assertEquals(1, policy.frequency(query.build()));\n        assertEquals(1, policy.frequency(foo));\n        assertEquals(1, policy.frequency(bar));\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"789fb338d3c53b4478938723d60f6623e764ca38","date":1521535944,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testOnUseWithRandomFirstSegmentSkipping().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testOnUseWithRandomFirstSegmentSkipping().mjava","sourceNew":"  /**\n   * Tests CachingWrapperWeight.scorer() propagation of {@link QueryCachingPolicy#onUse(Query)} when the first segment\n   * is skipped.\n   *\n   * #f:foo #f:bar causes all frequencies to increment\n   * #f:bar #f:foo does not increment the frequency for f:foo\n   */\n  public void testOnUseWithRandomFirstSegmentSkipping() throws IOException {\n    try (final Directory directory = newDirectory()) {\n      try (final RandomIndexWriter indexWriter = new RandomIndexWriter(random(), directory, newIndexWriterConfig().setMergePolicy(NoMergePolicy.INSTANCE))) {\n        Document doc = new Document();\n        doc.add(new StringField(\"f\", \"bar\", Store.NO));\n        indexWriter.addDocument(doc);\n        if (random().nextBoolean()) {\n          indexWriter.getReader().close();\n        }\n        doc = new Document();\n        doc.add(new StringField(\"f\", \"foo\", Store.NO));\n        doc.add(new StringField(\"f\", \"bar\", Store.NO));\n        indexWriter.addDocument(doc);\n        indexWriter.commit();\n      }\n      try (final IndexReader indexReader = DirectoryReader.open(directory)) {\n        final FrequencyCountingPolicy policy = new FrequencyCountingPolicy();\n        final IndexSearcher indexSearcher = new IndexSearcher(indexReader);\n        indexSearcher.setQueryCache(new LRUQueryCache(100, 10240, context -> random().nextBoolean()));\n        indexSearcher.setQueryCachingPolicy(policy);\n        final Query foo = new TermQuery(new Term(\"f\", \"foo\"));\n        final Query bar = new TermQuery(new Term(\"f\", \"bar\"));\n        final BooleanQuery.Builder query = new BooleanQuery.Builder();\n        if (random().nextBoolean()) {\n          query.add(foo, Occur.FILTER);\n          query.add(bar, Occur.FILTER);\n        } else {\n          query.add(bar, Occur.FILTER);\n          query.add(foo, Occur.FILTER);\n        }\n        indexSearcher.count(query.build());\n        assertEquals(1, policy.frequency(query.build()));\n        assertEquals(1, policy.frequency(foo));\n        assertEquals(1, policy.frequency(bar));\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Tests CachingWrapperWeight.scorer() propagation of {@link QueryCachingPolicy#onUse(Query)} when the first segment\n   * is skipped.\n   *\n   * #f:foo #f:bar causes all frequencies to increment\n   * #f:bar #f:foo does not increment the frequency for f:foo\n   */\n  public void testOnUseWithRandomFirstSegmentSkipping() throws IOException {\n    try (final Directory directory = newDirectory()) {\n      try (final RandomIndexWriter indexWriter = new RandomIndexWriter(random(), directory, newIndexWriterConfig().setMergePolicy(NoMergePolicy.INSTANCE))) {\n        Document doc = new Document();\n        doc.add(new StringField(\"f\", \"bar\", Store.NO));\n        indexWriter.addDocument(doc);\n        if (random().nextBoolean()) {\n          indexWriter.getReader().close();\n        }\n        doc = new Document();\n        doc.add(new StringField(\"f\", \"foo\", Store.NO));\n        doc.add(new StringField(\"f\", \"bar\", Store.NO));\n        indexWriter.addDocument(doc);\n        indexWriter.commit();\n      }\n      try (final IndexReader indexReader = DirectoryReader.open(directory)) {\n        final FrequencyCountingPolicy policy = new FrequencyCountingPolicy();\n        final IndexSearcher indexSearcher = new IndexSearcher(indexReader);\n        indexSearcher.setQueryCache(new LRUQueryCache(100, 10240, context -> random().nextBoolean(), Float.POSITIVE_INFINITY));\n        indexSearcher.setQueryCachingPolicy(policy);\n        final Query foo = new TermQuery(new Term(\"f\", \"foo\"));\n        final Query bar = new TermQuery(new Term(\"f\", \"bar\"));\n        final BooleanQuery.Builder query = new BooleanQuery.Builder();\n        if (random().nextBoolean()) {\n          query.add(foo, Occur.FILTER);\n          query.add(bar, Occur.FILTER);\n        } else {\n          query.add(bar, Occur.FILTER);\n          query.add(foo, Occur.FILTER);\n        }\n        indexSearcher.count(query.build());\n        assertEquals(1, policy.frequency(query.build()));\n        assertEquals(1, policy.frequency(foo));\n        assertEquals(1, policy.frequency(bar));\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6815b5b5d6334b2245dd7be2f8b6cca949bf7f43","date":1521731438,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testOnUseWithRandomFirstSegmentSkipping().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testOnUseWithRandomFirstSegmentSkipping().mjava","sourceNew":"  /**\n   * Tests CachingWrapperWeight.scorer() propagation of {@link QueryCachingPolicy#onUse(Query)} when the first segment\n   * is skipped.\n   *\n   * #f:foo #f:bar causes all frequencies to increment\n   * #f:bar #f:foo does not increment the frequency for f:foo\n   */\n  public void testOnUseWithRandomFirstSegmentSkipping() throws IOException {\n    try (final Directory directory = newDirectory()) {\n      try (final RandomIndexWriter indexWriter = new RandomIndexWriter(random(), directory, newIndexWriterConfig().setMergePolicy(NoMergePolicy.INSTANCE))) {\n        Document doc = new Document();\n        doc.add(new StringField(\"f\", \"bar\", Store.NO));\n        indexWriter.addDocument(doc);\n        if (random().nextBoolean()) {\n          indexWriter.getReader().close();\n        }\n        doc = new Document();\n        doc.add(new StringField(\"f\", \"foo\", Store.NO));\n        doc.add(new StringField(\"f\", \"bar\", Store.NO));\n        indexWriter.addDocument(doc);\n        indexWriter.commit();\n      }\n      try (final IndexReader indexReader = DirectoryReader.open(directory)) {\n        final FrequencyCountingPolicy policy = new FrequencyCountingPolicy();\n        final IndexSearcher indexSearcher = new IndexSearcher(indexReader);\n        indexSearcher.setQueryCache(new LRUQueryCache(100, 10240, context -> random().nextBoolean()));\n        indexSearcher.setQueryCachingPolicy(policy);\n        final Query foo = new TermQuery(new Term(\"f\", \"foo\"));\n        final Query bar = new TermQuery(new Term(\"f\", \"bar\"));\n        final BooleanQuery.Builder query = new BooleanQuery.Builder();\n        if (random().nextBoolean()) {\n          query.add(foo, Occur.FILTER);\n          query.add(bar, Occur.FILTER);\n        } else {\n          query.add(bar, Occur.FILTER);\n          query.add(foo, Occur.FILTER);\n        }\n        indexSearcher.count(query.build());\n        assertEquals(1, policy.frequency(query.build()));\n        assertEquals(1, policy.frequency(foo));\n        assertEquals(1, policy.frequency(bar));\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Tests CachingWrapperWeight.scorer() propagation of {@link QueryCachingPolicy#onUse(Query)} when the first segment\n   * is skipped.\n   *\n   * #f:foo #f:bar causes all frequencies to increment\n   * #f:bar #f:foo does not increment the frequency for f:foo\n   */\n  public void testOnUseWithRandomFirstSegmentSkipping() throws IOException {\n    try (final Directory directory = newDirectory()) {\n      try (final RandomIndexWriter indexWriter = new RandomIndexWriter(random(), directory, newIndexWriterConfig().setMergePolicy(NoMergePolicy.INSTANCE))) {\n        Document doc = new Document();\n        doc.add(new StringField(\"f\", \"bar\", Store.NO));\n        indexWriter.addDocument(doc);\n        if (random().nextBoolean()) {\n          indexWriter.getReader().close();\n        }\n        doc = new Document();\n        doc.add(new StringField(\"f\", \"foo\", Store.NO));\n        doc.add(new StringField(\"f\", \"bar\", Store.NO));\n        indexWriter.addDocument(doc);\n        indexWriter.commit();\n      }\n      try (final IndexReader indexReader = DirectoryReader.open(directory)) {\n        final FrequencyCountingPolicy policy = new FrequencyCountingPolicy();\n        final IndexSearcher indexSearcher = new IndexSearcher(indexReader);\n        indexSearcher.setQueryCache(new LRUQueryCache(100, 10240, context -> random().nextBoolean(), Float.POSITIVE_INFINITY));\n        indexSearcher.setQueryCachingPolicy(policy);\n        final Query foo = new TermQuery(new Term(\"f\", \"foo\"));\n        final Query bar = new TermQuery(new Term(\"f\", \"bar\"));\n        final BooleanQuery.Builder query = new BooleanQuery.Builder();\n        if (random().nextBoolean()) {\n          query.add(foo, Occur.FILTER);\n          query.add(bar, Occur.FILTER);\n        } else {\n          query.add(bar, Occur.FILTER);\n          query.add(foo, Occur.FILTER);\n        }\n        indexSearcher.count(query.build());\n        assertEquals(1, policy.frequency(query.build()));\n        assertEquals(1, policy.frequency(foo));\n        assertEquals(1, policy.frequency(bar));\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b5754bd6f04f13b67e9575f8b226a0303c31c7d5","date":1573506453,"type":3,"author":"ginger","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testOnUseWithRandomFirstSegmentSkipping().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testOnUseWithRandomFirstSegmentSkipping().mjava","sourceNew":"  /**\n   * Tests CachingWrapperWeight.scorer() propagation of {@link QueryCachingPolicy#onUse(Query)} when the first segment\n   * is skipped.\n   *\n   * #f:foo #f:bar causes all frequencies to increment\n   * #f:bar #f:foo does not increment the frequency for f:foo\n   */\n  public void testOnUseWithRandomFirstSegmentSkipping() throws IOException {\n    try (final Directory directory = newDirectory()) {\n      try (final RandomIndexWriter indexWriter = new RandomIndexWriter(random(), directory, newIndexWriterConfig().setMergePolicy(NoMergePolicy.INSTANCE))) {\n        Document doc = new Document();\n        doc.add(new StringField(\"f\", \"bar\", Store.NO));\n        indexWriter.addDocument(doc);\n        if (random().nextBoolean()) {\n          indexWriter.getReader().close();\n        }\n        doc = new Document();\n        doc.add(new StringField(\"f\", \"foo\", Store.NO));\n        doc.add(new StringField(\"f\", \"bar\", Store.NO));\n        indexWriter.addDocument(doc);\n        indexWriter.commit();\n      }\n      try (final IndexReader indexReader = DirectoryReader.open(directory)) {\n        final FrequencyCountingPolicy policy = new FrequencyCountingPolicy();\n        final IndexSearcher indexSearcher = new IndexSearcher(indexReader);\n        indexSearcher.setQueryCache(new LRUQueryCache(100, 10240, context -> random().nextBoolean(), Float.POSITIVE_INFINITY));\n        indexSearcher.setQueryCachingPolicy(policy);\n        final Query foo = new TermQuery(new Term(\"f\", \"foo\"));\n        final Query bar = new TermQuery(new Term(\"f\", \"bar\"));\n        final BooleanQuery.Builder query = new BooleanQuery.Builder();\n        if (random().nextBoolean()) {\n          query.add(foo, Occur.FILTER);\n          query.add(bar, Occur.FILTER);\n        } else {\n          query.add(bar, Occur.FILTER);\n          query.add(foo, Occur.FILTER);\n        }\n        indexSearcher.count(query.build());\n        assertEquals(1, policy.frequency(query.build()));\n        assertEquals(1, policy.frequency(foo));\n        assertEquals(1, policy.frequency(bar));\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Tests CachingWrapperWeight.scorer() propagation of {@link QueryCachingPolicy#onUse(Query)} when the first segment\n   * is skipped.\n   *\n   * #f:foo #f:bar causes all frequencies to increment\n   * #f:bar #f:foo does not increment the frequency for f:foo\n   */\n  public void testOnUseWithRandomFirstSegmentSkipping() throws IOException {\n    try (final Directory directory = newDirectory()) {\n      try (final RandomIndexWriter indexWriter = new RandomIndexWriter(random(), directory, newIndexWriterConfig().setMergePolicy(NoMergePolicy.INSTANCE))) {\n        Document doc = new Document();\n        doc.add(new StringField(\"f\", \"bar\", Store.NO));\n        indexWriter.addDocument(doc);\n        if (random().nextBoolean()) {\n          indexWriter.getReader().close();\n        }\n        doc = new Document();\n        doc.add(new StringField(\"f\", \"foo\", Store.NO));\n        doc.add(new StringField(\"f\", \"bar\", Store.NO));\n        indexWriter.addDocument(doc);\n        indexWriter.commit();\n      }\n      try (final IndexReader indexReader = DirectoryReader.open(directory)) {\n        final FrequencyCountingPolicy policy = new FrequencyCountingPolicy();\n        final IndexSearcher indexSearcher = new IndexSearcher(indexReader);\n        indexSearcher.setQueryCache(new LRUQueryCache(100, 10240, context -> random().nextBoolean()));\n        indexSearcher.setQueryCachingPolicy(policy);\n        final Query foo = new TermQuery(new Term(\"f\", \"foo\"));\n        final Query bar = new TermQuery(new Term(\"f\", \"bar\"));\n        final BooleanQuery.Builder query = new BooleanQuery.Builder();\n        if (random().nextBoolean()) {\n          query.add(foo, Occur.FILTER);\n          query.add(bar, Occur.FILTER);\n        } else {\n          query.add(bar, Occur.FILTER);\n          query.add(foo, Occur.FILTER);\n        }\n        indexSearcher.count(query.build());\n        assertEquals(1, policy.frequency(query.build()));\n        assertEquals(1, policy.frequency(foo));\n        assertEquals(1, policy.frequency(bar));\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"c7732a106554be0db3e03ac5211e46f6e0c285b8":["aac61ee5b4492f174e60bd54939aba9539906edf"],"1aad05eeff7818b0833c02ac6b743aa72054963b":["aac61ee5b4492f174e60bd54939aba9539906edf","c7732a106554be0db3e03ac5211e46f6e0c285b8"],"6815b5b5d6334b2245dd7be2f8b6cca949bf7f43":["1aad05eeff7818b0833c02ac6b743aa72054963b","789fb338d3c53b4478938723d60f6623e764ca38"],"aac61ee5b4492f174e60bd54939aba9539906edf":["0bf09e549fa47b894ce44baafdf8031eba2445c6"],"0bf09e549fa47b894ce44baafdf8031eba2445c6":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"789fb338d3c53b4478938723d60f6623e764ca38":["1aad05eeff7818b0833c02ac6b743aa72054963b"],"b5754bd6f04f13b67e9575f8b226a0303c31c7d5":["6815b5b5d6334b2245dd7be2f8b6cca949bf7f43"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b5754bd6f04f13b67e9575f8b226a0303c31c7d5"]},"commit2Childs":{"c7732a106554be0db3e03ac5211e46f6e0c285b8":["1aad05eeff7818b0833c02ac6b743aa72054963b"],"1aad05eeff7818b0833c02ac6b743aa72054963b":["6815b5b5d6334b2245dd7be2f8b6cca949bf7f43","789fb338d3c53b4478938723d60f6623e764ca38"],"6815b5b5d6334b2245dd7be2f8b6cca949bf7f43":["b5754bd6f04f13b67e9575f8b226a0303c31c7d5"],"aac61ee5b4492f174e60bd54939aba9539906edf":["c7732a106554be0db3e03ac5211e46f6e0c285b8","1aad05eeff7818b0833c02ac6b743aa72054963b"],"0bf09e549fa47b894ce44baafdf8031eba2445c6":["aac61ee5b4492f174e60bd54939aba9539906edf"],"789fb338d3c53b4478938723d60f6623e764ca38":["6815b5b5d6334b2245dd7be2f8b6cca949bf7f43"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["0bf09e549fa47b894ce44baafdf8031eba2445c6"],"b5754bd6f04f13b67e9575f8b226a0303c31c7d5":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}