{"path":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#createIndex(String,boolean).mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#createIndex(String,boolean).mjava","pathOld":"src/test/org/apache/lucene/index/TestBackwardsCompatibility#createIndex(String,boolean).mjava","sourceNew":"  public void createIndex(String dirName, boolean doCFS) throws IOException {\n\n    rmDir(dirName);\n\n    dirName = fullDir(dirName);\n\n    Directory dir = FSDirectory.open(new File(dirName));\n    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)).setMaxBufferedDocs(10));\n    ((LogMergePolicy) writer.getMergePolicy()).setUseCompoundFile(doCFS);\n    ((LogMergePolicy) writer.getMergePolicy()).setUseCompoundDocStore(doCFS);\n    \n    for(int i=0;i<35;i++) {\n      addDoc(writer, i);\n    }\n    assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n    writer.close();\n\n    // open fresh writer so we get no prx file in the added segment\n    writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)).setMaxBufferedDocs(10));\n    ((LogMergePolicy) writer.getMergePolicy()).setUseCompoundFile(doCFS);\n    ((LogMergePolicy) writer.getMergePolicy()).setUseCompoundDocStore(doCFS);\n    addNoProxDoc(writer);\n    writer.close();\n\n    // Delete one doc so we get a .del file:\n    IndexReader reader = IndexReader.open(dir, false);\n    Term searchTerm = new Term(\"id\", \"7\");\n    int delCount = reader.deleteDocuments(searchTerm);\n    assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n    // Set one norm so we get a .s0 file:\n    reader.setNorm(21, \"content\", (float) 1.5);\n    reader.close();\n  }\n\n","sourceOld":"  public void createIndex(String dirName, boolean doCFS) throws IOException {\n\n    rmDir(dirName);\n\n    dirName = fullDir(dirName);\n\n    Directory dir = FSDirectory.open(new File(dirName));\n    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)).setMaxBufferedDocs(10));\n    ((LogMergePolicy) writer.getMergePolicy()).setUseCompoundFile(doCFS);\n    ((LogMergePolicy) writer.getMergePolicy()).setUseCompoundDocStore(doCFS);\n    \n    for(int i=0;i<35;i++) {\n      addDoc(writer, i);\n    }\n    assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n    writer.close();\n\n    // open fresh writer so we get no prx file in the added segment\n    writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)).setMaxBufferedDocs(10));\n    ((LogMergePolicy) writer.getMergePolicy()).setUseCompoundFile(doCFS);\n    ((LogMergePolicy) writer.getMergePolicy()).setUseCompoundDocStore(doCFS);\n    addNoProxDoc(writer);\n    writer.close();\n\n    // Delete one doc so we get a .del file:\n    IndexReader reader = IndexReader.open(dir, false);\n    Term searchTerm = new Term(\"id\", \"7\");\n    int delCount = reader.deleteDocuments(searchTerm);\n    assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n    // Set one norm so we get a .s0 file:\n    reader.setNorm(21, \"content\", (float) 1.5);\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7ab99e8c71442b92c320e218141dee04a9b91ce8","date":1269203801,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#createIndex(String,boolean).mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#createIndex(String,boolean).mjava","sourceNew":"  public void createIndex(String dirName, boolean doCFS) throws IOException {\n\n    rmDir(dirName);\n\n    dirName = fullDir(dirName);\n\n    Directory dir = FSDirectory.open(new File(dirName));\n    IndexWriterConfig conf = new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)).setMaxBufferedDocs(10);\n    ((LogMergePolicy) conf.getMergePolicy()).setUseCompoundFile(doCFS);\n    ((LogMergePolicy) conf.getMergePolicy()).setUseCompoundDocStore(doCFS);\n    IndexWriter writer = new IndexWriter(dir, conf);\n    \n    for(int i=0;i<35;i++) {\n      addDoc(writer, i);\n    }\n    assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n    writer.close();\n\n    // open fresh writer so we get no prx file in the added segment\n    conf = new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)).setMaxBufferedDocs(10);\n    ((LogMergePolicy) conf.getMergePolicy()).setUseCompoundFile(doCFS);\n    ((LogMergePolicy) conf.getMergePolicy()).setUseCompoundDocStore(doCFS);\n    writer = new IndexWriter(dir, conf);\n    addNoProxDoc(writer);\n    writer.close();\n\n    // Delete one doc so we get a .del file:\n    IndexReader reader = IndexReader.open(dir, false);\n    Term searchTerm = new Term(\"id\", \"7\");\n    int delCount = reader.deleteDocuments(searchTerm);\n    assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n    // Set one norm so we get a .s0 file:\n    reader.setNorm(21, \"content\", (float) 1.5);\n    reader.close();\n  }\n\n","sourceOld":"  public void createIndex(String dirName, boolean doCFS) throws IOException {\n\n    rmDir(dirName);\n\n    dirName = fullDir(dirName);\n\n    Directory dir = FSDirectory.open(new File(dirName));\n    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)).setMaxBufferedDocs(10));\n    ((LogMergePolicy) writer.getMergePolicy()).setUseCompoundFile(doCFS);\n    ((LogMergePolicy) writer.getMergePolicy()).setUseCompoundDocStore(doCFS);\n    \n    for(int i=0;i<35;i++) {\n      addDoc(writer, i);\n    }\n    assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n    writer.close();\n\n    // open fresh writer so we get no prx file in the added segment\n    writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)).setMaxBufferedDocs(10));\n    ((LogMergePolicy) writer.getMergePolicy()).setUseCompoundFile(doCFS);\n    ((LogMergePolicy) writer.getMergePolicy()).setUseCompoundDocStore(doCFS);\n    addNoProxDoc(writer);\n    writer.close();\n\n    // Delete one doc so we get a .del file:\n    IndexReader reader = IndexReader.open(dir, false);\n    Term searchTerm = new Term(\"id\", \"7\");\n    int delCount = reader.deleteDocuments(searchTerm);\n    assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n    // Set one norm so we get a .s0 file:\n    reader.setNorm(21, \"content\", (float) 1.5);\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d572389229127c297dd1fa5ce4758e1cec41e799","date":1273610938,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#createIndex(String,boolean).mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#createIndex(String,boolean).mjava","sourceNew":"  public void createIndex(String dirName, boolean doCFS) throws IOException {\n\n    rmDir(dirName);\n\n    dirName = fullDir(dirName);\n\n    Directory dir = FSDirectory.open(new File(dirName));\n    IndexWriterConfig conf = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10);\n    ((LogMergePolicy) conf.getMergePolicy()).setUseCompoundFile(doCFS);\n    ((LogMergePolicy) conf.getMergePolicy()).setUseCompoundDocStore(doCFS);\n    IndexWriter writer = new IndexWriter(dir, conf);\n    \n    for(int i=0;i<35;i++) {\n      addDoc(writer, i);\n    }\n    assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n    writer.close();\n\n    // open fresh writer so we get no prx file in the added segment\n    conf = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10);\n    ((LogMergePolicy) conf.getMergePolicy()).setUseCompoundFile(doCFS);\n    ((LogMergePolicy) conf.getMergePolicy()).setUseCompoundDocStore(doCFS);\n    writer = new IndexWriter(dir, conf);\n    addNoProxDoc(writer);\n    writer.close();\n\n    // Delete one doc so we get a .del file:\n    IndexReader reader = IndexReader.open(dir, false);\n    Term searchTerm = new Term(\"id\", \"7\");\n    int delCount = reader.deleteDocuments(searchTerm);\n    assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n    // Set one norm so we get a .s0 file:\n    reader.setNorm(21, \"content\", (float) 1.5);\n    reader.close();\n  }\n\n","sourceOld":"  public void createIndex(String dirName, boolean doCFS) throws IOException {\n\n    rmDir(dirName);\n\n    dirName = fullDir(dirName);\n\n    Directory dir = FSDirectory.open(new File(dirName));\n    IndexWriterConfig conf = new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)).setMaxBufferedDocs(10);\n    ((LogMergePolicy) conf.getMergePolicy()).setUseCompoundFile(doCFS);\n    ((LogMergePolicy) conf.getMergePolicy()).setUseCompoundDocStore(doCFS);\n    IndexWriter writer = new IndexWriter(dir, conf);\n    \n    for(int i=0;i<35;i++) {\n      addDoc(writer, i);\n    }\n    assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n    writer.close();\n\n    // open fresh writer so we get no prx file in the added segment\n    conf = new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)).setMaxBufferedDocs(10);\n    ((LogMergePolicy) conf.getMergePolicy()).setUseCompoundFile(doCFS);\n    ((LogMergePolicy) conf.getMergePolicy()).setUseCompoundDocStore(doCFS);\n    writer = new IndexWriter(dir, conf);\n    addNoProxDoc(writer);\n    writer.close();\n\n    // Delete one doc so we get a .del file:\n    IndexReader reader = IndexReader.open(dir, false);\n    Term searchTerm = new Term(\"id\", \"7\");\n    int delCount = reader.deleteDocuments(searchTerm);\n    assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n    // Set one norm so we get a .s0 file:\n    reader.setNorm(21, \"content\", (float) 1.5);\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8dc26bfa5ebbc55b5a04fbec545dfcec647b046b","date":1280297653,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#createIndex(String,boolean).mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#createIndex(String,boolean).mjava","sourceNew":"  public void createIndex(String dirName, boolean doCFS) throws IOException {\n\n    rmDir(dirName);\n\n    dirName = fullDir(dirName);\n\n    Directory dir = FSDirectory.open(new File(dirName));\n    IndexWriterConfig conf = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10);\n    ((LogMergePolicy) conf.getMergePolicy()).setUseCompoundFile(doCFS);\n    IndexWriter writer = new IndexWriter(dir, conf);\n    \n    for(int i=0;i<35;i++) {\n      addDoc(writer, i);\n    }\n    assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n    writer.close();\n\n    // open fresh writer so we get no prx file in the added segment\n    conf = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10);\n    ((LogMergePolicy) conf.getMergePolicy()).setUseCompoundFile(doCFS);\n    writer = new IndexWriter(dir, conf);\n    addNoProxDoc(writer);\n    writer.close();\n\n    // Delete one doc so we get a .del file:\n    IndexReader reader = IndexReader.open(dir, false);\n    Term searchTerm = new Term(\"id\", \"7\");\n    int delCount = reader.deleteDocuments(searchTerm);\n    assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n    // Set one norm so we get a .s0 file:\n    reader.setNorm(21, \"content\", (float) 1.5);\n    reader.close();\n  }\n\n","sourceOld":"  public void createIndex(String dirName, boolean doCFS) throws IOException {\n\n    rmDir(dirName);\n\n    dirName = fullDir(dirName);\n\n    Directory dir = FSDirectory.open(new File(dirName));\n    IndexWriterConfig conf = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10);\n    ((LogMergePolicy) conf.getMergePolicy()).setUseCompoundFile(doCFS);\n    ((LogMergePolicy) conf.getMergePolicy()).setUseCompoundDocStore(doCFS);\n    IndexWriter writer = new IndexWriter(dir, conf);\n    \n    for(int i=0;i<35;i++) {\n      addDoc(writer, i);\n    }\n    assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n    writer.close();\n\n    // open fresh writer so we get no prx file in the added segment\n    conf = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10);\n    ((LogMergePolicy) conf.getMergePolicy()).setUseCompoundFile(doCFS);\n    ((LogMergePolicy) conf.getMergePolicy()).setUseCompoundDocStore(doCFS);\n    writer = new IndexWriter(dir, conf);\n    addNoProxDoc(writer);\n    writer.close();\n\n    // Delete one doc so we get a .del file:\n    IndexReader reader = IndexReader.open(dir, false);\n    Term searchTerm = new Term(\"id\", \"7\");\n    int delCount = reader.deleteDocuments(searchTerm);\n    assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n    // Set one norm so we get a .s0 file:\n    reader.setNorm(21, \"content\", (float) 1.5);\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b21422ff1d1d56499dec481f193b402e5e8def5b","date":1281472367,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#createIndex(Random,String,boolean).mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#createIndex(String,boolean).mjava","sourceNew":"  public void createIndex(Random random, String dirName, boolean doCFS) throws IOException {\n\n    rmDir(dirName);\n\n    dirName = fullDir(dirName);\n\n    Directory dir = FSDirectory.open(new File(dirName));\n    IndexWriterConfig conf = newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10);\n    ((LogMergePolicy) conf.getMergePolicy()).setUseCompoundFile(doCFS);\n    ((LogMergePolicy) conf.getMergePolicy()).setUseCompoundDocStore(doCFS);\n    IndexWriter writer = new IndexWriter(dir, conf);\n    \n    for(int i=0;i<35;i++) {\n      addDoc(writer, i);\n    }\n    assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n    writer.close();\n\n    // open fresh writer so we get no prx file in the added segment\n    conf = newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10);\n    ((LogMergePolicy) conf.getMergePolicy()).setUseCompoundFile(doCFS);\n    ((LogMergePolicy) conf.getMergePolicy()).setUseCompoundDocStore(doCFS);\n    writer = new IndexWriter(dir, conf);\n    addNoProxDoc(writer);\n    writer.close();\n\n    // Delete one doc so we get a .del file:\n    IndexReader reader = IndexReader.open(dir, false);\n    Term searchTerm = new Term(\"id\", \"7\");\n    int delCount = reader.deleteDocuments(searchTerm);\n    assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n    // Set one norm so we get a .s0 file:\n    reader.setNorm(21, \"content\", (float) 1.5);\n    reader.close();\n  }\n\n","sourceOld":"  public void createIndex(String dirName, boolean doCFS) throws IOException {\n\n    rmDir(dirName);\n\n    dirName = fullDir(dirName);\n\n    Directory dir = FSDirectory.open(new File(dirName));\n    IndexWriterConfig conf = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10);\n    ((LogMergePolicy) conf.getMergePolicy()).setUseCompoundFile(doCFS);\n    ((LogMergePolicy) conf.getMergePolicy()).setUseCompoundDocStore(doCFS);\n    IndexWriter writer = new IndexWriter(dir, conf);\n    \n    for(int i=0;i<35;i++) {\n      addDoc(writer, i);\n    }\n    assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n    writer.close();\n\n    // open fresh writer so we get no prx file in the added segment\n    conf = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10);\n    ((LogMergePolicy) conf.getMergePolicy()).setUseCompoundFile(doCFS);\n    ((LogMergePolicy) conf.getMergePolicy()).setUseCompoundDocStore(doCFS);\n    writer = new IndexWriter(dir, conf);\n    addNoProxDoc(writer);\n    writer.close();\n\n    // Delete one doc so we get a .del file:\n    IndexReader reader = IndexReader.open(dir, false);\n    Term searchTerm = new Term(\"id\", \"7\");\n    int delCount = reader.deleteDocuments(searchTerm);\n    assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n    // Set one norm so we get a .s0 file:\n    reader.setNorm(21, \"content\", (float) 1.5);\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":4,"author":"Michael Busch","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#createIndex(String,boolean).mjava","sourceNew":null,"sourceOld":"  public void createIndex(String dirName, boolean doCFS) throws IOException {\n\n    rmDir(dirName);\n\n    dirName = fullDir(dirName);\n\n    Directory dir = FSDirectory.open(new File(dirName));\n    IndexWriterConfig conf = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10);\n    ((LogMergePolicy) conf.getMergePolicy()).setUseCompoundFile(doCFS);\n    IndexWriter writer = new IndexWriter(dir, conf);\n    \n    for(int i=0;i<35;i++) {\n      addDoc(writer, i);\n    }\n    assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n    writer.close();\n\n    // open fresh writer so we get no prx file in the added segment\n    conf = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10);\n    ((LogMergePolicy) conf.getMergePolicy()).setUseCompoundFile(doCFS);\n    writer = new IndexWriter(dir, conf);\n    addNoProxDoc(writer);\n    writer.close();\n\n    // Delete one doc so we get a .del file:\n    IndexReader reader = IndexReader.open(dir, false);\n    Term searchTerm = new Term(\"id\", \"7\");\n    int delCount = reader.deleteDocuments(searchTerm);\n    assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n    // Set one norm so we get a .s0 file:\n    reader.setNorm(21, \"content\", (float) 1.5);\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"7ab99e8c71442b92c320e218141dee04a9b91ce8":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d572389229127c297dd1fa5ce4758e1cec41e799":["7ab99e8c71442b92c320e218141dee04a9b91ce8"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["8dc26bfa5ebbc55b5a04fbec545dfcec647b046b","b21422ff1d1d56499dec481f193b402e5e8def5b"],"b21422ff1d1d56499dec481f193b402e5e8def5b":["d572389229127c297dd1fa5ce4758e1cec41e799"],"8dc26bfa5ebbc55b5a04fbec545dfcec647b046b":["d572389229127c297dd1fa5ce4758e1cec41e799"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b21422ff1d1d56499dec481f193b402e5e8def5b"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"7ab99e8c71442b92c320e218141dee04a9b91ce8":["d572389229127c297dd1fa5ce4758e1cec41e799"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"d572389229127c297dd1fa5ce4758e1cec41e799":["b21422ff1d1d56499dec481f193b402e5e8def5b","8dc26bfa5ebbc55b5a04fbec545dfcec647b046b"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":[],"8dc26bfa5ebbc55b5a04fbec545dfcec647b046b":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"b21422ff1d1d56499dec481f193b402e5e8def5b":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["7ab99e8c71442b92c320e218141dee04a9b91ce8"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}