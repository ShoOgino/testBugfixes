{"path":"lucene/src/test/org/apache/lucene/index/TestIndexWriterDelete#testApplyDeletesOnFlush().mjava","commits":[{"id":"b7465988fd0a9c673dcb88f51473300c41d630f0","date":1311685662,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterDelete#testApplyDeletesOnFlush().mjava","pathOld":"/dev/null","sourceNew":"  // Make sure buffered (pushed) deletes don't use up so\n  // much RAM that it forces long tail of tiny segments:\n  public void testApplyDeletesOnFlush() throws Exception {\n    Directory dir = newDirectory();\n    // Cannot use RandomIndexWriter because we don't want to\n    // ever call commit() for this test:\n    final AtomicInteger docsInSegment = new AtomicInteger();\n    final AtomicBoolean closing = new AtomicBoolean();\n    final AtomicBoolean sawAfterFlush = new AtomicBoolean();\n    IndexWriter w = new IndexWriter(dir,\n                                    newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n                                    setRAMBufferSizeMB(0.5).setMaxBufferedDocs(-1).setMergePolicy(NoMergePolicy.NO_COMPOUND_FILES).setReaderPooling(false)) {\n        @Override\n        public void doAfterFlush() {\n          assertTrue(\"only \" + docsInSegment.get() + \" in segment\", closing.get() || docsInSegment.get() >= 10);\n          docsInSegment.set(0);\n          sawAfterFlush.set(true);\n        }\n      };\n    w.setInfoStream(VERBOSE ? System.out : null);\n    int id = 0;\n    while(true) {\n      StringBuilder sb = new StringBuilder();\n      for(int termIDX=0;termIDX<100;termIDX++) {\n        sb.append(' ').append(_TestUtil.randomRealisticUnicodeString(random));\n      }\n      if (id == 500) {\n        w.deleteDocuments(new Term(\"id\", \"0\"));\n      }\n      Document doc = new Document();\n      doc.add(newField(\"id\", \"\"+id, Field.Index.NOT_ANALYZED));\n      doc.add(newField(\"body\", sb.toString(), Field.Index.ANALYZED));\n      w.updateDocument(new Term(\"id\", \"\"+id), doc);\n      docsInSegment.incrementAndGet();\n      if (dir.fileExists(\"_0_1.del\")) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: deletes created @ id=\" + id);\n        }\n        break;\n      }\n      id++;\n    }\n    closing.set(true);\n    assertTrue(sawAfterFlush.get());\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"48821e00f3b31e6ac7a5ec276fec2cb6c4f3cc12","date":1311763517,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterDelete#testApplyDeletesOnFlush().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterDelete#testApplyDeletesOnFlush().mjava","sourceNew":"  // Make sure buffered (pushed) deletes don't use up so\n  // much RAM that it forces long tail of tiny segments:\n  public void testApplyDeletesOnFlush() throws Exception {\n    Directory dir = newDirectory();\n    // Cannot use RandomIndexWriter because we don't want to\n    // ever call commit() for this test:\n    final AtomicInteger docsInSegment = new AtomicInteger();\n    final AtomicBoolean closing = new AtomicBoolean();\n    final AtomicBoolean sawAfterFlush = new AtomicBoolean();\n    IndexWriter w = new IndexWriter(dir,\n                                    newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n                                    setRAMBufferSizeMB(0.5).setMaxBufferedDocs(-1).setMergePolicy(NoMergePolicy.NO_COMPOUND_FILES).setReaderPooling(false)) {\n        @Override\n        public void doAfterFlush() {\n          assertTrue(\"only \" + docsInSegment.get() + \" in segment\", closing.get() || docsInSegment.get() >= 7);\n          docsInSegment.set(0);\n          sawAfterFlush.set(true);\n        }\n      };\n    w.setInfoStream(VERBOSE ? System.out : null);\n    int id = 0;\n    while(true) {\n      StringBuilder sb = new StringBuilder();\n      for(int termIDX=0;termIDX<100;termIDX++) {\n        sb.append(' ').append(_TestUtil.randomRealisticUnicodeString(random));\n      }\n      if (id == 500) {\n        w.deleteDocuments(new Term(\"id\", \"0\"));\n      }\n      Document doc = new Document();\n      doc.add(newField(\"id\", \"\"+id, Field.Index.NOT_ANALYZED));\n      doc.add(newField(\"body\", sb.toString(), Field.Index.ANALYZED));\n      w.updateDocument(new Term(\"id\", \"\"+id), doc);\n      docsInSegment.incrementAndGet();\n      if (dir.fileExists(\"_0_1.del\")) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: deletes created @ id=\" + id);\n        }\n        break;\n      }\n      id++;\n    }\n    closing.set(true);\n    assertTrue(sawAfterFlush.get());\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Make sure buffered (pushed) deletes don't use up so\n  // much RAM that it forces long tail of tiny segments:\n  public void testApplyDeletesOnFlush() throws Exception {\n    Directory dir = newDirectory();\n    // Cannot use RandomIndexWriter because we don't want to\n    // ever call commit() for this test:\n    final AtomicInteger docsInSegment = new AtomicInteger();\n    final AtomicBoolean closing = new AtomicBoolean();\n    final AtomicBoolean sawAfterFlush = new AtomicBoolean();\n    IndexWriter w = new IndexWriter(dir,\n                                    newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n                                    setRAMBufferSizeMB(0.5).setMaxBufferedDocs(-1).setMergePolicy(NoMergePolicy.NO_COMPOUND_FILES).setReaderPooling(false)) {\n        @Override\n        public void doAfterFlush() {\n          assertTrue(\"only \" + docsInSegment.get() + \" in segment\", closing.get() || docsInSegment.get() >= 10);\n          docsInSegment.set(0);\n          sawAfterFlush.set(true);\n        }\n      };\n    w.setInfoStream(VERBOSE ? System.out : null);\n    int id = 0;\n    while(true) {\n      StringBuilder sb = new StringBuilder();\n      for(int termIDX=0;termIDX<100;termIDX++) {\n        sb.append(' ').append(_TestUtil.randomRealisticUnicodeString(random));\n      }\n      if (id == 500) {\n        w.deleteDocuments(new Term(\"id\", \"0\"));\n      }\n      Document doc = new Document();\n      doc.add(newField(\"id\", \"\"+id, Field.Index.NOT_ANALYZED));\n      doc.add(newField(\"body\", sb.toString(), Field.Index.ANALYZED));\n      w.updateDocument(new Term(\"id\", \"\"+id), doc);\n      docsInSegment.incrementAndGet();\n      if (dir.fileExists(\"_0_1.del\")) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: deletes created @ id=\" + id);\n        }\n        break;\n      }\n      id++;\n    }\n    closing.set(true);\n    assertTrue(sawAfterFlush.get());\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1509f151d7692d84fae414b2b799ac06ba60fcb4","date":1314451621,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterDelete#testApplyDeletesOnFlush().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterDelete#testApplyDeletesOnFlush().mjava","sourceNew":"  // Make sure buffered (pushed) deletes don't use up so\n  // much RAM that it forces long tail of tiny segments:\n  public void testApplyDeletesOnFlush() throws Exception {\n    Directory dir = newDirectory();\n    // Cannot use RandomIndexWriter because we don't want to\n    // ever call commit() for this test:\n    final AtomicInteger docsInSegment = new AtomicInteger();\n    final AtomicBoolean closing = new AtomicBoolean();\n    final AtomicBoolean sawAfterFlush = new AtomicBoolean();\n    IndexWriter w = new IndexWriter(dir,\n                                    newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n                                    setRAMBufferSizeMB(0.5).setMaxBufferedDocs(-1).setMergePolicy(NoMergePolicy.NO_COMPOUND_FILES).setReaderPooling(false)) {\n        @Override\n        public void doAfterFlush() {\n          assertTrue(\"only \" + docsInSegment.get() + \" in segment\", closing.get() || docsInSegment.get() >= 7);\n          docsInSegment.set(0);\n          sawAfterFlush.set(true);\n        }\n      };\n    w.setInfoStream(VERBOSE ? System.out : null);\n    int id = 0;\n    while(true) {\n      StringBuilder sb = new StringBuilder();\n      for(int termIDX=0;termIDX<100;termIDX++) {\n        sb.append(' ').append(_TestUtil.randomRealisticUnicodeString(random));\n      }\n      if (id == 500) {\n        w.deleteDocuments(new Term(\"id\", \"0\"));\n      }\n      Document doc = new Document();\n      doc.add(newField(\"id\", \"\"+id, StringField.TYPE_UNSTORED));\n      doc.add(newField(\"body\", sb.toString(), TextField.TYPE_UNSTORED));\n      w.updateDocument(new Term(\"id\", \"\"+id), doc);\n      docsInSegment.incrementAndGet();\n      if (dir.fileExists(\"_0_1.del\")) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: deletes created @ id=\" + id);\n        }\n        break;\n      }\n      id++;\n    }\n    closing.set(true);\n    assertTrue(sawAfterFlush.get());\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Make sure buffered (pushed) deletes don't use up so\n  // much RAM that it forces long tail of tiny segments:\n  public void testApplyDeletesOnFlush() throws Exception {\n    Directory dir = newDirectory();\n    // Cannot use RandomIndexWriter because we don't want to\n    // ever call commit() for this test:\n    final AtomicInteger docsInSegment = new AtomicInteger();\n    final AtomicBoolean closing = new AtomicBoolean();\n    final AtomicBoolean sawAfterFlush = new AtomicBoolean();\n    IndexWriter w = new IndexWriter(dir,\n                                    newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n                                    setRAMBufferSizeMB(0.5).setMaxBufferedDocs(-1).setMergePolicy(NoMergePolicy.NO_COMPOUND_FILES).setReaderPooling(false)) {\n        @Override\n        public void doAfterFlush() {\n          assertTrue(\"only \" + docsInSegment.get() + \" in segment\", closing.get() || docsInSegment.get() >= 7);\n          docsInSegment.set(0);\n          sawAfterFlush.set(true);\n        }\n      };\n    w.setInfoStream(VERBOSE ? System.out : null);\n    int id = 0;\n    while(true) {\n      StringBuilder sb = new StringBuilder();\n      for(int termIDX=0;termIDX<100;termIDX++) {\n        sb.append(' ').append(_TestUtil.randomRealisticUnicodeString(random));\n      }\n      if (id == 500) {\n        w.deleteDocuments(new Term(\"id\", \"0\"));\n      }\n      Document doc = new Document();\n      doc.add(newField(\"id\", \"\"+id, Field.Index.NOT_ANALYZED));\n      doc.add(newField(\"body\", sb.toString(), Field.Index.ANALYZED));\n      w.updateDocument(new Term(\"id\", \"\"+id), doc);\n      docsInSegment.incrementAndGet();\n      if (dir.fileExists(\"_0_1.del\")) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: deletes created @ id=\" + id);\n        }\n        break;\n      }\n      id++;\n    }\n    closing.set(true);\n    assertTrue(sawAfterFlush.get());\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"06584e6e98d592b34e1329b384182f368d2025e8","date":1320850353,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterDelete#testApplyDeletesOnFlush().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterDelete#testApplyDeletesOnFlush().mjava","sourceNew":"  // Make sure buffered (pushed) deletes don't use up so\n  // much RAM that it forces long tail of tiny segments:\n  public void testApplyDeletesOnFlush() throws Exception {\n    Directory dir = newDirectory();\n    // Cannot use RandomIndexWriter because we don't want to\n    // ever call commit() for this test:\n    final AtomicInteger docsInSegment = new AtomicInteger();\n    final AtomicBoolean closing = new AtomicBoolean();\n    final AtomicBoolean sawAfterFlush = new AtomicBoolean();\n    IndexWriter w = new IndexWriter(dir,\n                                    newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n                                    setRAMBufferSizeMB(0.5).setMaxBufferedDocs(-1).setMergePolicy(NoMergePolicy.NO_COMPOUND_FILES).setReaderPooling(false)) {\n        @Override\n        public void doAfterFlush() {\n          assertTrue(\"only \" + docsInSegment.get() + \" in segment\", closing.get() || docsInSegment.get() >= 7);\n          docsInSegment.set(0);\n          sawAfterFlush.set(true);\n        }\n      };\n    int id = 0;\n    while(true) {\n      StringBuilder sb = new StringBuilder();\n      for(int termIDX=0;termIDX<100;termIDX++) {\n        sb.append(' ').append(_TestUtil.randomRealisticUnicodeString(random));\n      }\n      if (id == 500) {\n        w.deleteDocuments(new Term(\"id\", \"0\"));\n      }\n      Document doc = new Document();\n      doc.add(newField(\"id\", \"\"+id, StringField.TYPE_UNSTORED));\n      doc.add(newField(\"body\", sb.toString(), TextField.TYPE_UNSTORED));\n      w.updateDocument(new Term(\"id\", \"\"+id), doc);\n      docsInSegment.incrementAndGet();\n      if (dir.fileExists(\"_0_1.del\")) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: deletes created @ id=\" + id);\n        }\n        break;\n      }\n      id++;\n    }\n    closing.set(true);\n    assertTrue(sawAfterFlush.get());\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Make sure buffered (pushed) deletes don't use up so\n  // much RAM that it forces long tail of tiny segments:\n  public void testApplyDeletesOnFlush() throws Exception {\n    Directory dir = newDirectory();\n    // Cannot use RandomIndexWriter because we don't want to\n    // ever call commit() for this test:\n    final AtomicInteger docsInSegment = new AtomicInteger();\n    final AtomicBoolean closing = new AtomicBoolean();\n    final AtomicBoolean sawAfterFlush = new AtomicBoolean();\n    IndexWriter w = new IndexWriter(dir,\n                                    newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n                                    setRAMBufferSizeMB(0.5).setMaxBufferedDocs(-1).setMergePolicy(NoMergePolicy.NO_COMPOUND_FILES).setReaderPooling(false)) {\n        @Override\n        public void doAfterFlush() {\n          assertTrue(\"only \" + docsInSegment.get() + \" in segment\", closing.get() || docsInSegment.get() >= 7);\n          docsInSegment.set(0);\n          sawAfterFlush.set(true);\n        }\n      };\n    w.setInfoStream(VERBOSE ? System.out : null);\n    int id = 0;\n    while(true) {\n      StringBuilder sb = new StringBuilder();\n      for(int termIDX=0;termIDX<100;termIDX++) {\n        sb.append(' ').append(_TestUtil.randomRealisticUnicodeString(random));\n      }\n      if (id == 500) {\n        w.deleteDocuments(new Term(\"id\", \"0\"));\n      }\n      Document doc = new Document();\n      doc.add(newField(\"id\", \"\"+id, StringField.TYPE_UNSTORED));\n      doc.add(newField(\"body\", sb.toString(), TextField.TYPE_UNSTORED));\n      w.updateDocument(new Term(\"id\", \"\"+id), doc);\n      docsInSegment.incrementAndGet();\n      if (dir.fileExists(\"_0_1.del\")) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: deletes created @ id=\" + id);\n        }\n        break;\n      }\n      id++;\n    }\n    closing.set(true);\n    assertTrue(sawAfterFlush.get());\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8be580b58bcc650d428f3f22de81cadcf51d650a","date":1325279655,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterDelete#testApplyDeletesOnFlush().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterDelete#testApplyDeletesOnFlush().mjava","sourceNew":"  // Make sure buffered (pushed) deletes don't use up so\n  // much RAM that it forces long tail of tiny segments:\n  @Nightly\n  public void testApplyDeletesOnFlush() throws Exception {\n    Directory dir = newDirectory();\n    // Cannot use RandomIndexWriter because we don't want to\n    // ever call commit() for this test:\n    final AtomicInteger docsInSegment = new AtomicInteger();\n    final AtomicBoolean closing = new AtomicBoolean();\n    final AtomicBoolean sawAfterFlush = new AtomicBoolean();\n    IndexWriter w = new IndexWriter(dir,\n                                    newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n                                    setRAMBufferSizeMB(0.5).setMaxBufferedDocs(-1).setMergePolicy(NoMergePolicy.NO_COMPOUND_FILES).setReaderPooling(false)) {\n        @Override\n        public void doAfterFlush() {\n          assertTrue(\"only \" + docsInSegment.get() + \" in segment\", closing.get() || docsInSegment.get() >= 7);\n          docsInSegment.set(0);\n          sawAfterFlush.set(true);\n        }\n      };\n    int id = 0;\n    while(true) {\n      StringBuilder sb = new StringBuilder();\n      for(int termIDX=0;termIDX<100;termIDX++) {\n        sb.append(' ').append(_TestUtil.randomRealisticUnicodeString(random));\n      }\n      if (id == 500) {\n        w.deleteDocuments(new Term(\"id\", \"0\"));\n      }\n      Document doc = new Document();\n      doc.add(newField(\"id\", \"\"+id, StringField.TYPE_UNSTORED));\n      doc.add(newField(\"body\", sb.toString(), TextField.TYPE_UNSTORED));\n      w.updateDocument(new Term(\"id\", \"\"+id), doc);\n      docsInSegment.incrementAndGet();\n      if (dir.fileExists(\"_0_1.del\")) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: deletes created @ id=\" + id);\n        }\n        break;\n      }\n      id++;\n    }\n    closing.set(true);\n    assertTrue(sawAfterFlush.get());\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Make sure buffered (pushed) deletes don't use up so\n  // much RAM that it forces long tail of tiny segments:\n  public void testApplyDeletesOnFlush() throws Exception {\n    Directory dir = newDirectory();\n    // Cannot use RandomIndexWriter because we don't want to\n    // ever call commit() for this test:\n    final AtomicInteger docsInSegment = new AtomicInteger();\n    final AtomicBoolean closing = new AtomicBoolean();\n    final AtomicBoolean sawAfterFlush = new AtomicBoolean();\n    IndexWriter w = new IndexWriter(dir,\n                                    newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n                                    setRAMBufferSizeMB(0.5).setMaxBufferedDocs(-1).setMergePolicy(NoMergePolicy.NO_COMPOUND_FILES).setReaderPooling(false)) {\n        @Override\n        public void doAfterFlush() {\n          assertTrue(\"only \" + docsInSegment.get() + \" in segment\", closing.get() || docsInSegment.get() >= 7);\n          docsInSegment.set(0);\n          sawAfterFlush.set(true);\n        }\n      };\n    int id = 0;\n    while(true) {\n      StringBuilder sb = new StringBuilder();\n      for(int termIDX=0;termIDX<100;termIDX++) {\n        sb.append(' ').append(_TestUtil.randomRealisticUnicodeString(random));\n      }\n      if (id == 500) {\n        w.deleteDocuments(new Term(\"id\", \"0\"));\n      }\n      Document doc = new Document();\n      doc.add(newField(\"id\", \"\"+id, StringField.TYPE_UNSTORED));\n      doc.add(newField(\"body\", sb.toString(), TextField.TYPE_UNSTORED));\n      w.updateDocument(new Term(\"id\", \"\"+id), doc);\n      docsInSegment.incrementAndGet();\n      if (dir.fileExists(\"_0_1.del\")) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: deletes created @ id=\" + id);\n        }\n        break;\n      }\n      id++;\n    }\n    closing.set(true);\n    assertTrue(sawAfterFlush.get());\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2972b4f2d23be6887a2f48be21a969d8a98610d6","date":1327078547,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterDelete#testApplyDeletesOnFlush().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterDelete#testApplyDeletesOnFlush().mjava","sourceNew":"  // Make sure buffered (pushed) deletes don't use up so\n  // much RAM that it forces long tail of tiny segments:\n  @Nightly\n  public void testApplyDeletesOnFlush() throws Exception {\n    Directory dir = newDirectory();\n    // Cannot use RandomIndexWriter because we don't want to\n    // ever call commit() for this test:\n    final AtomicInteger docsInSegment = new AtomicInteger();\n    final AtomicBoolean closing = new AtomicBoolean();\n    final AtomicBoolean sawAfterFlush = new AtomicBoolean();\n    IndexWriter w = new IndexWriter(dir,\n                                    newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n                                    setRAMBufferSizeMB(0.5).setMaxBufferedDocs(-1).setMergePolicy(NoMergePolicy.NO_COMPOUND_FILES).setReaderPooling(false)) {\n        @Override\n        public void doAfterFlush() {\n          assertTrue(\"only \" + docsInSegment.get() + \" in segment\", closing.get() || docsInSegment.get() >= 7);\n          docsInSegment.set(0);\n          sawAfterFlush.set(true);\n        }\n      };\n    int id = 0;\n    while(true) {\n      StringBuilder sb = new StringBuilder();\n      for(int termIDX=0;termIDX<100;termIDX++) {\n        sb.append(' ').append(_TestUtil.randomRealisticUnicodeString(random));\n      }\n      if (id == 500) {\n        w.deleteDocuments(new Term(\"id\", \"0\"));\n      }\n      Document doc = new Document();\n      doc.add(newField(\"id\", \"\"+id, StringField.TYPE_UNSTORED));\n      doc.add(newField(\"body\", sb.toString(), TextField.TYPE_UNSTORED));\n      w.updateDocument(new Term(\"id\", \"\"+id), doc);\n      docsInSegment.incrementAndGet();\n      // TODO: fix this test\n      if (dir.fileExists(\"_0_1.del\") || dir.fileExists(\"_0_1.liv\")) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: deletes created @ id=\" + id);\n        }\n        break;\n      }\n      id++;\n    }\n    closing.set(true);\n    assertTrue(sawAfterFlush.get());\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Make sure buffered (pushed) deletes don't use up so\n  // much RAM that it forces long tail of tiny segments:\n  @Nightly\n  public void testApplyDeletesOnFlush() throws Exception {\n    Directory dir = newDirectory();\n    // Cannot use RandomIndexWriter because we don't want to\n    // ever call commit() for this test:\n    final AtomicInteger docsInSegment = new AtomicInteger();\n    final AtomicBoolean closing = new AtomicBoolean();\n    final AtomicBoolean sawAfterFlush = new AtomicBoolean();\n    IndexWriter w = new IndexWriter(dir,\n                                    newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n                                    setRAMBufferSizeMB(0.5).setMaxBufferedDocs(-1).setMergePolicy(NoMergePolicy.NO_COMPOUND_FILES).setReaderPooling(false)) {\n        @Override\n        public void doAfterFlush() {\n          assertTrue(\"only \" + docsInSegment.get() + \" in segment\", closing.get() || docsInSegment.get() >= 7);\n          docsInSegment.set(0);\n          sawAfterFlush.set(true);\n        }\n      };\n    int id = 0;\n    while(true) {\n      StringBuilder sb = new StringBuilder();\n      for(int termIDX=0;termIDX<100;termIDX++) {\n        sb.append(' ').append(_TestUtil.randomRealisticUnicodeString(random));\n      }\n      if (id == 500) {\n        w.deleteDocuments(new Term(\"id\", \"0\"));\n      }\n      Document doc = new Document();\n      doc.add(newField(\"id\", \"\"+id, StringField.TYPE_UNSTORED));\n      doc.add(newField(\"body\", sb.toString(), TextField.TYPE_UNSTORED));\n      w.updateDocument(new Term(\"id\", \"\"+id), doc);\n      docsInSegment.incrementAndGet();\n      if (dir.fileExists(\"_0_1.del\")) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: deletes created @ id=\" + id);\n        }\n        break;\n      }\n      id++;\n    }\n    closing.set(true);\n    assertTrue(sawAfterFlush.get());\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c9f2d6bb11ccaac366d9b7652b2feb0c715d9c31","date":1327836826,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterDelete#testApplyDeletesOnFlush().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterDelete#testApplyDeletesOnFlush().mjava","sourceNew":"  // Make sure buffered (pushed) deletes don't use up so\n  // much RAM that it forces long tail of tiny segments:\n  @Nightly\n  public void testApplyDeletesOnFlush() throws Exception {\n    Directory dir = newDirectory();\n    // Cannot use RandomIndexWriter because we don't want to\n    // ever call commit() for this test:\n    final AtomicInteger docsInSegment = new AtomicInteger();\n    final AtomicBoolean closing = new AtomicBoolean();\n    final AtomicBoolean sawAfterFlush = new AtomicBoolean();\n    IndexWriter w = new IndexWriter(dir,\n                                    newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n                                    setRAMBufferSizeMB(0.5).setMaxBufferedDocs(-1).setMergePolicy(NoMergePolicy.NO_COMPOUND_FILES).setReaderPooling(false)) {\n        @Override\n        public void doAfterFlush() {\n          assertTrue(\"only \" + docsInSegment.get() + \" in segment\", closing.get() || docsInSegment.get() >= 7);\n          docsInSegment.set(0);\n          sawAfterFlush.set(true);\n        }\n      };\n    int id = 0;\n    while(true) {\n      StringBuilder sb = new StringBuilder();\n      for(int termIDX=0;termIDX<100;termIDX++) {\n        sb.append(' ').append(_TestUtil.randomRealisticUnicodeString(random));\n      }\n      if (id == 500) {\n        w.deleteDocuments(new Term(\"id\", \"0\"));\n      }\n      Document doc = new Document();\n      doc.add(newField(\"id\", \"\"+id, StringField.TYPE_UNSTORED));\n      doc.add(newField(\"body\", sb.toString(), TextField.TYPE_UNSTORED));\n      w.updateDocument(new Term(\"id\", \"\"+id), doc);\n      docsInSegment.incrementAndGet();\n      // TODO: fix this test\n      if (dir.fileExists(\"_0_1.del\") || dir.fileExists(\"_0_1.liv\")) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: deletes created @ id=\" + id);\n        }\n        break;\n      }\n      id++;\n    }\n    closing.set(true);\n    assertTrue(sawAfterFlush.get());\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Make sure buffered (pushed) deletes don't use up so\n  // much RAM that it forces long tail of tiny segments:\n  @Nightly\n  public void testApplyDeletesOnFlush() throws Exception {\n    Directory dir = newDirectory();\n    // Cannot use RandomIndexWriter because we don't want to\n    // ever call commit() for this test:\n    final AtomicInteger docsInSegment = new AtomicInteger();\n    final AtomicBoolean closing = new AtomicBoolean();\n    final AtomicBoolean sawAfterFlush = new AtomicBoolean();\n    IndexWriter w = new IndexWriter(dir,\n                                    newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n                                    setRAMBufferSizeMB(0.5).setMaxBufferedDocs(-1).setMergePolicy(NoMergePolicy.NO_COMPOUND_FILES).setReaderPooling(false)) {\n        @Override\n        public void doAfterFlush() {\n          assertTrue(\"only \" + docsInSegment.get() + \" in segment\", closing.get() || docsInSegment.get() >= 7);\n          docsInSegment.set(0);\n          sawAfterFlush.set(true);\n        }\n      };\n    int id = 0;\n    while(true) {\n      StringBuilder sb = new StringBuilder();\n      for(int termIDX=0;termIDX<100;termIDX++) {\n        sb.append(' ').append(_TestUtil.randomRealisticUnicodeString(random));\n      }\n      if (id == 500) {\n        w.deleteDocuments(new Term(\"id\", \"0\"));\n      }\n      Document doc = new Document();\n      doc.add(newField(\"id\", \"\"+id, StringField.TYPE_UNSTORED));\n      doc.add(newField(\"body\", sb.toString(), TextField.TYPE_UNSTORED));\n      w.updateDocument(new Term(\"id\", \"\"+id), doc);\n      docsInSegment.incrementAndGet();\n      if (dir.fileExists(\"_0_1.del\")) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: deletes created @ id=\" + id);\n        }\n        break;\n      }\n      id++;\n    }\n    closing.set(true);\n    assertTrue(sawAfterFlush.get());\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fd92b8bcc88e969302510acf77bd6970da3994c4","date":1327839530,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterDelete#testApplyDeletesOnFlush().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterDelete#testApplyDeletesOnFlush().mjava","sourceNew":"  // Make sure buffered (pushed) deletes don't use up so\n  // much RAM that it forces long tail of tiny segments:\n  @Nightly\n  public void testApplyDeletesOnFlush() throws Exception {\n    Directory dir = newDirectory();\n    // Cannot use RandomIndexWriter because we don't want to\n    // ever call commit() for this test:\n    final AtomicInteger docsInSegment = new AtomicInteger();\n    final AtomicBoolean closing = new AtomicBoolean();\n    final AtomicBoolean sawAfterFlush = new AtomicBoolean();\n    IndexWriter w = new IndexWriter(dir,\n                                    newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n                                    setRAMBufferSizeMB(0.5).setMaxBufferedDocs(-1).setMergePolicy(NoMergePolicy.NO_COMPOUND_FILES).setReaderPooling(false)) {\n        @Override\n        public void doAfterFlush() {\n          assertTrue(\"only \" + docsInSegment.get() + \" in segment\", closing.get() || docsInSegment.get() >= 7);\n          docsInSegment.set(0);\n          sawAfterFlush.set(true);\n        }\n      };\n    int id = 0;\n    while(true) {\n      StringBuilder sb = new StringBuilder();\n      for(int termIDX=0;termIDX<100;termIDX++) {\n        sb.append(' ').append(_TestUtil.randomRealisticUnicodeString(random));\n      }\n      if (id == 500) {\n        w.deleteDocuments(new Term(\"id\", \"0\"));\n      }\n      Document doc = new Document();\n      doc.add(newField(\"id\", \"\"+id, StringField.TYPE_UNSTORED));\n      doc.add(newField(\"body\", sb.toString(), TextField.TYPE_UNSTORED));\n      w.updateDocument(new Term(\"id\", \"\"+id), doc);\n      docsInSegment.incrementAndGet();\n      // TODO: fix this test\n      if (dir.fileExists(\"_0_1.del\") || dir.fileExists(\"_0_1.liv\")) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: deletes created @ id=\" + id);\n        }\n        break;\n      }\n      id++;\n    }\n    closing.set(true);\n    assertTrue(sawAfterFlush.get());\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Make sure buffered (pushed) deletes don't use up so\n  // much RAM that it forces long tail of tiny segments:\n  @Nightly\n  public void testApplyDeletesOnFlush() throws Exception {\n    Directory dir = newDirectory();\n    // Cannot use RandomIndexWriter because we don't want to\n    // ever call commit() for this test:\n    final AtomicInteger docsInSegment = new AtomicInteger();\n    final AtomicBoolean closing = new AtomicBoolean();\n    final AtomicBoolean sawAfterFlush = new AtomicBoolean();\n    IndexWriter w = new IndexWriter(dir,\n                                    newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n                                    setRAMBufferSizeMB(0.5).setMaxBufferedDocs(-1).setMergePolicy(NoMergePolicy.NO_COMPOUND_FILES).setReaderPooling(false)) {\n        @Override\n        public void doAfterFlush() {\n          assertTrue(\"only \" + docsInSegment.get() + \" in segment\", closing.get() || docsInSegment.get() >= 7);\n          docsInSegment.set(0);\n          sawAfterFlush.set(true);\n        }\n      };\n    int id = 0;\n    while(true) {\n      StringBuilder sb = new StringBuilder();\n      for(int termIDX=0;termIDX<100;termIDX++) {\n        sb.append(' ').append(_TestUtil.randomRealisticUnicodeString(random));\n      }\n      if (id == 500) {\n        w.deleteDocuments(new Term(\"id\", \"0\"));\n      }\n      Document doc = new Document();\n      doc.add(newField(\"id\", \"\"+id, StringField.TYPE_UNSTORED));\n      doc.add(newField(\"body\", sb.toString(), TextField.TYPE_UNSTORED));\n      w.updateDocument(new Term(\"id\", \"\"+id), doc);\n      docsInSegment.incrementAndGet();\n      if (dir.fileExists(\"_0_1.del\")) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: deletes created @ id=\" + id);\n        }\n        break;\n      }\n      id++;\n    }\n    closing.set(true);\n    assertTrue(sawAfterFlush.get());\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#testApplyDeletesOnFlush().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterDelete#testApplyDeletesOnFlush().mjava","sourceNew":"  // Make sure buffered (pushed) deletes don't use up so\n  // much RAM that it forces long tail of tiny segments:\n  @Nightly\n  public void testApplyDeletesOnFlush() throws Exception {\n    Directory dir = newDirectory();\n    // Cannot use RandomIndexWriter because we don't want to\n    // ever call commit() for this test:\n    final AtomicInteger docsInSegment = new AtomicInteger();\n    final AtomicBoolean closing = new AtomicBoolean();\n    final AtomicBoolean sawAfterFlush = new AtomicBoolean();\n    IndexWriter w = new IndexWriter(dir,\n                                    newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n                                    setRAMBufferSizeMB(0.5).setMaxBufferedDocs(-1).setMergePolicy(NoMergePolicy.NO_COMPOUND_FILES).setReaderPooling(false)) {\n        @Override\n        public void doAfterFlush() {\n          assertTrue(\"only \" + docsInSegment.get() + \" in segment\", closing.get() || docsInSegment.get() >= 7);\n          docsInSegment.set(0);\n          sawAfterFlush.set(true);\n        }\n      };\n    int id = 0;\n    while(true) {\n      StringBuilder sb = new StringBuilder();\n      for(int termIDX=0;termIDX<100;termIDX++) {\n        sb.append(' ').append(_TestUtil.randomRealisticUnicodeString(random));\n      }\n      if (id == 500) {\n        w.deleteDocuments(new Term(\"id\", \"0\"));\n      }\n      Document doc = new Document();\n      doc.add(newField(\"id\", \"\"+id, StringField.TYPE_UNSTORED));\n      doc.add(newField(\"body\", sb.toString(), TextField.TYPE_UNSTORED));\n      w.updateDocument(new Term(\"id\", \"\"+id), doc);\n      docsInSegment.incrementAndGet();\n      // TODO: fix this test\n      if (dir.fileExists(\"_0_1.del\") || dir.fileExists(\"_0_1.liv\")) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: deletes created @ id=\" + id);\n        }\n        break;\n      }\n      id++;\n    }\n    closing.set(true);\n    assertTrue(sawAfterFlush.get());\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Make sure buffered (pushed) deletes don't use up so\n  // much RAM that it forces long tail of tiny segments:\n  @Nightly\n  public void testApplyDeletesOnFlush() throws Exception {\n    Directory dir = newDirectory();\n    // Cannot use RandomIndexWriter because we don't want to\n    // ever call commit() for this test:\n    final AtomicInteger docsInSegment = new AtomicInteger();\n    final AtomicBoolean closing = new AtomicBoolean();\n    final AtomicBoolean sawAfterFlush = new AtomicBoolean();\n    IndexWriter w = new IndexWriter(dir,\n                                    newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n                                    setRAMBufferSizeMB(0.5).setMaxBufferedDocs(-1).setMergePolicy(NoMergePolicy.NO_COMPOUND_FILES).setReaderPooling(false)) {\n        @Override\n        public void doAfterFlush() {\n          assertTrue(\"only \" + docsInSegment.get() + \" in segment\", closing.get() || docsInSegment.get() >= 7);\n          docsInSegment.set(0);\n          sawAfterFlush.set(true);\n        }\n      };\n    int id = 0;\n    while(true) {\n      StringBuilder sb = new StringBuilder();\n      for(int termIDX=0;termIDX<100;termIDX++) {\n        sb.append(' ').append(_TestUtil.randomRealisticUnicodeString(random));\n      }\n      if (id == 500) {\n        w.deleteDocuments(new Term(\"id\", \"0\"));\n      }\n      Document doc = new Document();\n      doc.add(newField(\"id\", \"\"+id, StringField.TYPE_UNSTORED));\n      doc.add(newField(\"body\", sb.toString(), TextField.TYPE_UNSTORED));\n      w.updateDocument(new Term(\"id\", \"\"+id), doc);\n      docsInSegment.incrementAndGet();\n      // TODO: fix this test\n      if (dir.fileExists(\"_0_1.del\") || dir.fileExists(\"_0_1.liv\")) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: deletes created @ id=\" + id);\n        }\n        break;\n      }\n      id++;\n    }\n    closing.set(true);\n    assertTrue(sawAfterFlush.get());\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"48821e00f3b31e6ac7a5ec276fec2cb6c4f3cc12":["b7465988fd0a9c673dcb88f51473300c41d630f0"],"2972b4f2d23be6887a2f48be21a969d8a98610d6":["8be580b58bcc650d428f3f22de81cadcf51d650a"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["c9f2d6bb11ccaac366d9b7652b2feb0c715d9c31"],"06584e6e98d592b34e1329b384182f368d2025e8":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"b7465988fd0a9c673dcb88f51473300c41d630f0":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"fd92b8bcc88e969302510acf77bd6970da3994c4":["8be580b58bcc650d428f3f22de81cadcf51d650a","c9f2d6bb11ccaac366d9b7652b2feb0c715d9c31"],"8be580b58bcc650d428f3f22de81cadcf51d650a":["06584e6e98d592b34e1329b384182f368d2025e8"],"c9f2d6bb11ccaac366d9b7652b2feb0c715d9c31":["8be580b58bcc650d428f3f22de81cadcf51d650a","2972b4f2d23be6887a2f48be21a969d8a98610d6"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["48821e00f3b31e6ac7a5ec276fec2cb6c4f3cc12"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"]},"commit2Childs":{"48821e00f3b31e6ac7a5ec276fec2cb6c4f3cc12":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"2972b4f2d23be6887a2f48be21a969d8a98610d6":["c9f2d6bb11ccaac366d9b7652b2feb0c715d9c31"],"b7465988fd0a9c673dcb88f51473300c41d630f0":["48821e00f3b31e6ac7a5ec276fec2cb6c4f3cc12"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"06584e6e98d592b34e1329b384182f368d2025e8":["8be580b58bcc650d428f3f22de81cadcf51d650a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b7465988fd0a9c673dcb88f51473300c41d630f0"],"fd92b8bcc88e969302510acf77bd6970da3994c4":[],"8be580b58bcc650d428f3f22de81cadcf51d650a":["2972b4f2d23be6887a2f48be21a969d8a98610d6","fd92b8bcc88e969302510acf77bd6970da3994c4","c9f2d6bb11ccaac366d9b7652b2feb0c715d9c31"],"c9f2d6bb11ccaac366d9b7652b2feb0c715d9c31":["3a119bbc8703c10faa329ec201c654b3a35a1e3e","fd92b8bcc88e969302510acf77bd6970da3994c4"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["06584e6e98d592b34e1329b384182f368d2025e8"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["fd92b8bcc88e969302510acf77bd6970da3994c4","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}