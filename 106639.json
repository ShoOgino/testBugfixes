{"path":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextPointsWriter#writeField(FieldInfo,PointsReader,double).mjava","commits":[{"id":"10005c6013abbd1102f2463cf95604d4c8774c99","date":1469460814,"type":1,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextPointsWriter#writeField(FieldInfo,PointsReader,double).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextPointsWriter#writeField(FieldInfo,PointsReader).mjava","sourceNew":"  @Override\n  public void writeField(FieldInfo fieldInfo, PointsReader values, double maxMBSortInHeap) throws IOException {\n\n    boolean singleValuePerDoc = values.size(fieldInfo.name) == values.getDocCount(fieldInfo.name);\n\n    // We use the normal BKDWriter, but subclass to customize how it writes the index and blocks to disk:\n    try (BKDWriter writer = new BKDWriter(writeState.segmentInfo.maxDoc(),\n                                          writeState.directory,\n                                          writeState.segmentInfo.name,\n                                          fieldInfo.getPointDimensionCount(),\n                                          fieldInfo.getPointNumBytes(),\n                                          BKDWriter.DEFAULT_MAX_POINTS_IN_LEAF_NODE,\n                                          maxMBSortInHeap,\n                                          values.size(fieldInfo.name),\n                                          singleValuePerDoc) {\n\n        @Override\n        protected void writeIndex(IndexOutput out, long[] leafBlockFPs, byte[] splitPackedValues) throws IOException {\n          write(out, NUM_DIMS);\n          writeInt(out, numDims);\n          newline(out);\n\n          write(out, BYTES_PER_DIM);\n          writeInt(out, bytesPerDim);\n          newline(out);\n\n          write(out, MAX_LEAF_POINTS);\n          writeInt(out, maxPointsInLeafNode);\n          newline(out);\n\n          write(out, INDEX_COUNT);\n          writeInt(out, leafBlockFPs.length);\n          newline(out);\n\n          write(out, MIN_VALUE);\n          BytesRef br = new BytesRef(minPackedValue, 0, minPackedValue.length);\n          write(out, br.toString());\n          newline(out);\n\n          write(out, MAX_VALUE);\n          br = new BytesRef(maxPackedValue, 0, maxPackedValue.length);\n          write(out, br.toString());\n          newline(out);\n\n          write(out, POINT_COUNT);\n          writeLong(out, pointCount);\n          newline(out);\n\n          write(out, DOC_COUNT);\n          writeInt(out, docsSeen.cardinality());\n          newline(out);\n\n          for(int i=0;i<leafBlockFPs.length;i++) {\n            write(out, BLOCK_FP);\n            writeLong(out, leafBlockFPs[i]);\n            newline(out);\n          }\n\n          assert (splitPackedValues.length % (1 + fieldInfo.getPointNumBytes())) == 0;\n          int count = splitPackedValues.length / (1 + fieldInfo.getPointNumBytes());\n          assert count == leafBlockFPs.length;\n\n          write(out, SPLIT_COUNT);\n          writeInt(out, count);\n          newline(out);\n\n          for(int i=0;i<count;i++) {\n            write(out, SPLIT_DIM);\n            writeInt(out, splitPackedValues[i * (1 + fieldInfo.getPointNumBytes())] & 0xff);\n            newline(out);\n            write(out, SPLIT_VALUE);\n            br = new BytesRef(splitPackedValues, 1+(i * (1+fieldInfo.getPointNumBytes())), fieldInfo.getPointNumBytes());\n            write(out, br.toString());\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeLeafBlockDocs(IndexOutput out, int[] docIDs, int start, int count) throws IOException {\n          write(out, BLOCK_COUNT);\n          writeInt(out, count);\n          newline(out);\n          for(int i=0;i<count;i++) {\n            write(out, BLOCK_DOC_ID);\n            writeInt(out, docIDs[start+i]);\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeCommonPrefixes(IndexOutput out, int[] commonPrefixLengths, byte[] packedValue) {\n          // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n        }\n\n        @Override\n        protected void writeLeafBlockPackedValues(IndexOutput out, int[] commonPrefixLengths, int count, int sortedDim, IntFunction<BytesRef> packedValues) throws IOException {\n          for (int i = 0; i < count; ++i) {\n            BytesRef packedValue = packedValues.apply(i);\n            // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n            write(out, BLOCK_VALUE);\n            write(out, packedValue.toString());\n            newline(out);\n          }\n        }\n      }) {\n\n      values.intersect(fieldInfo.name, new IntersectVisitor() {\n          @Override\n          public void visit(int docID) {\n            throw new IllegalStateException();\n          }\n\n          public void visit(int docID, byte[] packedValue) throws IOException {\n            writer.add(packedValue, docID);\n          }\n\n          @Override\n          public Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n            return Relation.CELL_CROSSES_QUERY;\n          }\n        });\n\n      // We could have 0 points on merge since all docs with points may be deleted:\n      if (writer.getPointCount() > 0) {\n        indexFPs.put(fieldInfo.name, writer.finish(dataOut));\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void writeField(FieldInfo fieldInfo, PointsReader values) throws IOException {\n\n    boolean singleValuePerDoc = values.size(fieldInfo.name) == values.getDocCount(fieldInfo.name);\n\n    // We use the normal BKDWriter, but subclass to customize how it writes the index and blocks to disk:\n    try (BKDWriter writer = new BKDWriter(writeState.segmentInfo.maxDoc(),\n                                          writeState.directory,\n                                          writeState.segmentInfo.name,\n                                          fieldInfo.getPointDimensionCount(),\n                                          fieldInfo.getPointNumBytes(),\n                                          BKDWriter.DEFAULT_MAX_POINTS_IN_LEAF_NODE,\n                                          BKDWriter.DEFAULT_MAX_MB_SORT_IN_HEAP,\n                                          values.size(fieldInfo.name),\n                                          singleValuePerDoc) {\n\n        @Override\n        protected void writeIndex(IndexOutput out, long[] leafBlockFPs, byte[] splitPackedValues) throws IOException {\n          write(out, NUM_DIMS);\n          writeInt(out, numDims);\n          newline(out);\n\n          write(out, BYTES_PER_DIM);\n          writeInt(out, bytesPerDim);\n          newline(out);\n\n          write(out, MAX_LEAF_POINTS);\n          writeInt(out, maxPointsInLeafNode);\n          newline(out);\n\n          write(out, INDEX_COUNT);\n          writeInt(out, leafBlockFPs.length);\n          newline(out);\n\n          write(out, MIN_VALUE);\n          BytesRef br = new BytesRef(minPackedValue, 0, minPackedValue.length);\n          write(out, br.toString());\n          newline(out);\n\n          write(out, MAX_VALUE);\n          br = new BytesRef(maxPackedValue, 0, maxPackedValue.length);\n          write(out, br.toString());\n          newline(out);\n\n          write(out, POINT_COUNT);\n          writeLong(out, pointCount);\n          newline(out);\n\n          write(out, DOC_COUNT);\n          writeInt(out, docsSeen.cardinality());\n          newline(out);\n\n          for(int i=0;i<leafBlockFPs.length;i++) {\n            write(out, BLOCK_FP);\n            writeLong(out, leafBlockFPs[i]);\n            newline(out);\n          }\n\n          assert (splitPackedValues.length % (1 + fieldInfo.getPointNumBytes())) == 0;\n          int count = splitPackedValues.length / (1 + fieldInfo.getPointNumBytes());\n          assert count == leafBlockFPs.length;\n\n          write(out, SPLIT_COUNT);\n          writeInt(out, count);\n          newline(out);\n\n          for(int i=0;i<count;i++) {\n            write(out, SPLIT_DIM);\n            writeInt(out, splitPackedValues[i * (1 + fieldInfo.getPointNumBytes())] & 0xff);\n            newline(out);\n            write(out, SPLIT_VALUE);\n            br = new BytesRef(splitPackedValues, 1+(i * (1+fieldInfo.getPointNumBytes())), fieldInfo.getPointNumBytes());\n            write(out, br.toString());\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeLeafBlockDocs(IndexOutput out, int[] docIDs, int start, int count) throws IOException {\n          write(out, BLOCK_COUNT);\n          writeInt(out, count);\n          newline(out);\n          for(int i=0;i<count;i++) {\n            write(out, BLOCK_DOC_ID);\n            writeInt(out, docIDs[start+i]);\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeCommonPrefixes(IndexOutput out, int[] commonPrefixLengths, byte[] packedValue) {\n          // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n        }\n\n        @Override\n        protected void writeLeafBlockPackedValues(IndexOutput out, int[] commonPrefixLengths, int count, int sortedDim, IntFunction<BytesRef> packedValues) throws IOException {\n          for (int i = 0; i < count; ++i) {\n            BytesRef packedValue = packedValues.apply(i);\n            // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n            write(out, BLOCK_VALUE);\n            write(out, packedValue.toString());\n            newline(out);\n          }\n        }\n      }) {\n\n      values.intersect(fieldInfo.name, new IntersectVisitor() {\n          @Override\n          public void visit(int docID) {\n            throw new IllegalStateException();\n          }\n\n          public void visit(int docID, byte[] packedValue) throws IOException {\n            writer.add(packedValue, docID);\n          }\n\n          @Override\n          public Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n            return Relation.CELL_CROSSES_QUERY;\n          }\n        });\n\n      // We could have 0 points on merge since all docs with points may be deleted:\n      if (writer.getPointCount() > 0) {\n        indexFPs.put(fieldInfo.name, writer.finish(dataOut));\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d08973aa47f2cf98a588293a53af4e948952ccfb","date":1469518724,"type":1,"author":"Noble Paul","isMerge":true,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextPointsWriter#writeField(FieldInfo,PointsReader,double).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextPointsWriter#writeField(FieldInfo,PointsReader).mjava","sourceNew":"  @Override\n  public void writeField(FieldInfo fieldInfo, PointsReader values, double maxMBSortInHeap) throws IOException {\n\n    boolean singleValuePerDoc = values.size(fieldInfo.name) == values.getDocCount(fieldInfo.name);\n\n    // We use the normal BKDWriter, but subclass to customize how it writes the index and blocks to disk:\n    try (BKDWriter writer = new BKDWriter(writeState.segmentInfo.maxDoc(),\n                                          writeState.directory,\n                                          writeState.segmentInfo.name,\n                                          fieldInfo.getPointDimensionCount(),\n                                          fieldInfo.getPointNumBytes(),\n                                          BKDWriter.DEFAULT_MAX_POINTS_IN_LEAF_NODE,\n                                          maxMBSortInHeap,\n                                          values.size(fieldInfo.name),\n                                          singleValuePerDoc) {\n\n        @Override\n        protected void writeIndex(IndexOutput out, long[] leafBlockFPs, byte[] splitPackedValues) throws IOException {\n          write(out, NUM_DIMS);\n          writeInt(out, numDims);\n          newline(out);\n\n          write(out, BYTES_PER_DIM);\n          writeInt(out, bytesPerDim);\n          newline(out);\n\n          write(out, MAX_LEAF_POINTS);\n          writeInt(out, maxPointsInLeafNode);\n          newline(out);\n\n          write(out, INDEX_COUNT);\n          writeInt(out, leafBlockFPs.length);\n          newline(out);\n\n          write(out, MIN_VALUE);\n          BytesRef br = new BytesRef(minPackedValue, 0, minPackedValue.length);\n          write(out, br.toString());\n          newline(out);\n\n          write(out, MAX_VALUE);\n          br = new BytesRef(maxPackedValue, 0, maxPackedValue.length);\n          write(out, br.toString());\n          newline(out);\n\n          write(out, POINT_COUNT);\n          writeLong(out, pointCount);\n          newline(out);\n\n          write(out, DOC_COUNT);\n          writeInt(out, docsSeen.cardinality());\n          newline(out);\n\n          for(int i=0;i<leafBlockFPs.length;i++) {\n            write(out, BLOCK_FP);\n            writeLong(out, leafBlockFPs[i]);\n            newline(out);\n          }\n\n          assert (splitPackedValues.length % (1 + fieldInfo.getPointNumBytes())) == 0;\n          int count = splitPackedValues.length / (1 + fieldInfo.getPointNumBytes());\n          assert count == leafBlockFPs.length;\n\n          write(out, SPLIT_COUNT);\n          writeInt(out, count);\n          newline(out);\n\n          for(int i=0;i<count;i++) {\n            write(out, SPLIT_DIM);\n            writeInt(out, splitPackedValues[i * (1 + fieldInfo.getPointNumBytes())] & 0xff);\n            newline(out);\n            write(out, SPLIT_VALUE);\n            br = new BytesRef(splitPackedValues, 1+(i * (1+fieldInfo.getPointNumBytes())), fieldInfo.getPointNumBytes());\n            write(out, br.toString());\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeLeafBlockDocs(IndexOutput out, int[] docIDs, int start, int count) throws IOException {\n          write(out, BLOCK_COUNT);\n          writeInt(out, count);\n          newline(out);\n          for(int i=0;i<count;i++) {\n            write(out, BLOCK_DOC_ID);\n            writeInt(out, docIDs[start+i]);\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeCommonPrefixes(IndexOutput out, int[] commonPrefixLengths, byte[] packedValue) {\n          // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n        }\n\n        @Override\n        protected void writeLeafBlockPackedValues(IndexOutput out, int[] commonPrefixLengths, int count, int sortedDim, IntFunction<BytesRef> packedValues) throws IOException {\n          for (int i = 0; i < count; ++i) {\n            BytesRef packedValue = packedValues.apply(i);\n            // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n            write(out, BLOCK_VALUE);\n            write(out, packedValue.toString());\n            newline(out);\n          }\n        }\n      }) {\n\n      values.intersect(fieldInfo.name, new IntersectVisitor() {\n          @Override\n          public void visit(int docID) {\n            throw new IllegalStateException();\n          }\n\n          public void visit(int docID, byte[] packedValue) throws IOException {\n            writer.add(packedValue, docID);\n          }\n\n          @Override\n          public Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n            return Relation.CELL_CROSSES_QUERY;\n          }\n        });\n\n      // We could have 0 points on merge since all docs with points may be deleted:\n      if (writer.getPointCount() > 0) {\n        indexFPs.put(fieldInfo.name, writer.finish(dataOut));\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void writeField(FieldInfo fieldInfo, PointsReader values) throws IOException {\n\n    boolean singleValuePerDoc = values.size(fieldInfo.name) == values.getDocCount(fieldInfo.name);\n\n    // We use the normal BKDWriter, but subclass to customize how it writes the index and blocks to disk:\n    try (BKDWriter writer = new BKDWriter(writeState.segmentInfo.maxDoc(),\n                                          writeState.directory,\n                                          writeState.segmentInfo.name,\n                                          fieldInfo.getPointDimensionCount(),\n                                          fieldInfo.getPointNumBytes(),\n                                          BKDWriter.DEFAULT_MAX_POINTS_IN_LEAF_NODE,\n                                          BKDWriter.DEFAULT_MAX_MB_SORT_IN_HEAP,\n                                          values.size(fieldInfo.name),\n                                          singleValuePerDoc) {\n\n        @Override\n        protected void writeIndex(IndexOutput out, long[] leafBlockFPs, byte[] splitPackedValues) throws IOException {\n          write(out, NUM_DIMS);\n          writeInt(out, numDims);\n          newline(out);\n\n          write(out, BYTES_PER_DIM);\n          writeInt(out, bytesPerDim);\n          newline(out);\n\n          write(out, MAX_LEAF_POINTS);\n          writeInt(out, maxPointsInLeafNode);\n          newline(out);\n\n          write(out, INDEX_COUNT);\n          writeInt(out, leafBlockFPs.length);\n          newline(out);\n\n          write(out, MIN_VALUE);\n          BytesRef br = new BytesRef(minPackedValue, 0, minPackedValue.length);\n          write(out, br.toString());\n          newline(out);\n\n          write(out, MAX_VALUE);\n          br = new BytesRef(maxPackedValue, 0, maxPackedValue.length);\n          write(out, br.toString());\n          newline(out);\n\n          write(out, POINT_COUNT);\n          writeLong(out, pointCount);\n          newline(out);\n\n          write(out, DOC_COUNT);\n          writeInt(out, docsSeen.cardinality());\n          newline(out);\n\n          for(int i=0;i<leafBlockFPs.length;i++) {\n            write(out, BLOCK_FP);\n            writeLong(out, leafBlockFPs[i]);\n            newline(out);\n          }\n\n          assert (splitPackedValues.length % (1 + fieldInfo.getPointNumBytes())) == 0;\n          int count = splitPackedValues.length / (1 + fieldInfo.getPointNumBytes());\n          assert count == leafBlockFPs.length;\n\n          write(out, SPLIT_COUNT);\n          writeInt(out, count);\n          newline(out);\n\n          for(int i=0;i<count;i++) {\n            write(out, SPLIT_DIM);\n            writeInt(out, splitPackedValues[i * (1 + fieldInfo.getPointNumBytes())] & 0xff);\n            newline(out);\n            write(out, SPLIT_VALUE);\n            br = new BytesRef(splitPackedValues, 1+(i * (1+fieldInfo.getPointNumBytes())), fieldInfo.getPointNumBytes());\n            write(out, br.toString());\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeLeafBlockDocs(IndexOutput out, int[] docIDs, int start, int count) throws IOException {\n          write(out, BLOCK_COUNT);\n          writeInt(out, count);\n          newline(out);\n          for(int i=0;i<count;i++) {\n            write(out, BLOCK_DOC_ID);\n            writeInt(out, docIDs[start+i]);\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeCommonPrefixes(IndexOutput out, int[] commonPrefixLengths, byte[] packedValue) {\n          // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n        }\n\n        @Override\n        protected void writeLeafBlockPackedValues(IndexOutput out, int[] commonPrefixLengths, int count, int sortedDim, IntFunction<BytesRef> packedValues) throws IOException {\n          for (int i = 0; i < count; ++i) {\n            BytesRef packedValue = packedValues.apply(i);\n            // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n            write(out, BLOCK_VALUE);\n            write(out, packedValue.toString());\n            newline(out);\n          }\n        }\n      }) {\n\n      values.intersect(fieldInfo.name, new IntersectVisitor() {\n          @Override\n          public void visit(int docID) {\n            throw new IllegalStateException();\n          }\n\n          public void visit(int docID, byte[] packedValue) throws IOException {\n            writer.add(packedValue, docID);\n          }\n\n          @Override\n          public Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n            return Relation.CELL_CROSSES_QUERY;\n          }\n        });\n\n      // We could have 0 points on merge since all docs with points may be deleted:\n      if (writer.getPointCount() > 0) {\n        indexFPs.put(fieldInfo.name, writer.finish(dataOut));\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b0567940defa1ea6eb8a039d9d36e3682063f8a4","date":1469815320,"type":5,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextPointsWriter#writeField(FieldInfo,PointsReader).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextPointsWriter#writeField(FieldInfo,PointsReader,double).mjava","sourceNew":"  @Override\n  public void writeField(FieldInfo fieldInfo, PointsReader values) throws IOException {\n\n    boolean singleValuePerDoc = values.size(fieldInfo.name) == values.getDocCount(fieldInfo.name);\n\n    // We use the normal BKDWriter, but subclass to customize how it writes the index and blocks to disk:\n    try (BKDWriter writer = new BKDWriter(writeState.segmentInfo.maxDoc(),\n                                          writeState.directory,\n                                          writeState.segmentInfo.name,\n                                          fieldInfo.getPointDimensionCount(),\n                                          fieldInfo.getPointNumBytes(),\n                                          BKDWriter.DEFAULT_MAX_POINTS_IN_LEAF_NODE,\n                                          BKDWriter.DEFAULT_MAX_MB_SORT_IN_HEAP,\n                                          values.size(fieldInfo.name),\n                                          singleValuePerDoc) {\n\n        @Override\n        protected void writeIndex(IndexOutput out, long[] leafBlockFPs, byte[] splitPackedValues) throws IOException {\n          write(out, NUM_DIMS);\n          writeInt(out, numDims);\n          newline(out);\n\n          write(out, BYTES_PER_DIM);\n          writeInt(out, bytesPerDim);\n          newline(out);\n\n          write(out, MAX_LEAF_POINTS);\n          writeInt(out, maxPointsInLeafNode);\n          newline(out);\n\n          write(out, INDEX_COUNT);\n          writeInt(out, leafBlockFPs.length);\n          newline(out);\n\n          write(out, MIN_VALUE);\n          BytesRef br = new BytesRef(minPackedValue, 0, minPackedValue.length);\n          write(out, br.toString());\n          newline(out);\n\n          write(out, MAX_VALUE);\n          br = new BytesRef(maxPackedValue, 0, maxPackedValue.length);\n          write(out, br.toString());\n          newline(out);\n\n          write(out, POINT_COUNT);\n          writeLong(out, pointCount);\n          newline(out);\n\n          write(out, DOC_COUNT);\n          writeInt(out, docsSeen.cardinality());\n          newline(out);\n\n          for(int i=0;i<leafBlockFPs.length;i++) {\n            write(out, BLOCK_FP);\n            writeLong(out, leafBlockFPs[i]);\n            newline(out);\n          }\n\n          assert (splitPackedValues.length % (1 + fieldInfo.getPointNumBytes())) == 0;\n          int count = splitPackedValues.length / (1 + fieldInfo.getPointNumBytes());\n          assert count == leafBlockFPs.length;\n\n          write(out, SPLIT_COUNT);\n          writeInt(out, count);\n          newline(out);\n\n          for(int i=0;i<count;i++) {\n            write(out, SPLIT_DIM);\n            writeInt(out, splitPackedValues[i * (1 + fieldInfo.getPointNumBytes())] & 0xff);\n            newline(out);\n            write(out, SPLIT_VALUE);\n            br = new BytesRef(splitPackedValues, 1+(i * (1+fieldInfo.getPointNumBytes())), fieldInfo.getPointNumBytes());\n            write(out, br.toString());\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeLeafBlockDocs(IndexOutput out, int[] docIDs, int start, int count) throws IOException {\n          write(out, BLOCK_COUNT);\n          writeInt(out, count);\n          newline(out);\n          for(int i=0;i<count;i++) {\n            write(out, BLOCK_DOC_ID);\n            writeInt(out, docIDs[start+i]);\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeCommonPrefixes(IndexOutput out, int[] commonPrefixLengths, byte[] packedValue) {\n          // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n        }\n\n        @Override\n        protected void writeLeafBlockPackedValues(IndexOutput out, int[] commonPrefixLengths, int count, int sortedDim, IntFunction<BytesRef> packedValues) throws IOException {\n          for (int i = 0; i < count; ++i) {\n            BytesRef packedValue = packedValues.apply(i);\n            // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n            write(out, BLOCK_VALUE);\n            write(out, packedValue.toString());\n            newline(out);\n          }\n        }\n      }) {\n\n      values.intersect(fieldInfo.name, new IntersectVisitor() {\n          @Override\n          public void visit(int docID) {\n            throw new IllegalStateException();\n          }\n\n          public void visit(int docID, byte[] packedValue) throws IOException {\n            writer.add(packedValue, docID);\n          }\n\n          @Override\n          public Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n            return Relation.CELL_CROSSES_QUERY;\n          }\n        });\n\n      // We could have 0 points on merge since all docs with points may be deleted:\n      if (writer.getPointCount() > 0) {\n        indexFPs.put(fieldInfo.name, writer.finish(dataOut));\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void writeField(FieldInfo fieldInfo, PointsReader values, double maxMBSortInHeap) throws IOException {\n\n    boolean singleValuePerDoc = values.size(fieldInfo.name) == values.getDocCount(fieldInfo.name);\n\n    // We use the normal BKDWriter, but subclass to customize how it writes the index and blocks to disk:\n    try (BKDWriter writer = new BKDWriter(writeState.segmentInfo.maxDoc(),\n                                          writeState.directory,\n                                          writeState.segmentInfo.name,\n                                          fieldInfo.getPointDimensionCount(),\n                                          fieldInfo.getPointNumBytes(),\n                                          BKDWriter.DEFAULT_MAX_POINTS_IN_LEAF_NODE,\n                                          maxMBSortInHeap,\n                                          values.size(fieldInfo.name),\n                                          singleValuePerDoc) {\n\n        @Override\n        protected void writeIndex(IndexOutput out, long[] leafBlockFPs, byte[] splitPackedValues) throws IOException {\n          write(out, NUM_DIMS);\n          writeInt(out, numDims);\n          newline(out);\n\n          write(out, BYTES_PER_DIM);\n          writeInt(out, bytesPerDim);\n          newline(out);\n\n          write(out, MAX_LEAF_POINTS);\n          writeInt(out, maxPointsInLeafNode);\n          newline(out);\n\n          write(out, INDEX_COUNT);\n          writeInt(out, leafBlockFPs.length);\n          newline(out);\n\n          write(out, MIN_VALUE);\n          BytesRef br = new BytesRef(minPackedValue, 0, minPackedValue.length);\n          write(out, br.toString());\n          newline(out);\n\n          write(out, MAX_VALUE);\n          br = new BytesRef(maxPackedValue, 0, maxPackedValue.length);\n          write(out, br.toString());\n          newline(out);\n\n          write(out, POINT_COUNT);\n          writeLong(out, pointCount);\n          newline(out);\n\n          write(out, DOC_COUNT);\n          writeInt(out, docsSeen.cardinality());\n          newline(out);\n\n          for(int i=0;i<leafBlockFPs.length;i++) {\n            write(out, BLOCK_FP);\n            writeLong(out, leafBlockFPs[i]);\n            newline(out);\n          }\n\n          assert (splitPackedValues.length % (1 + fieldInfo.getPointNumBytes())) == 0;\n          int count = splitPackedValues.length / (1 + fieldInfo.getPointNumBytes());\n          assert count == leafBlockFPs.length;\n\n          write(out, SPLIT_COUNT);\n          writeInt(out, count);\n          newline(out);\n\n          for(int i=0;i<count;i++) {\n            write(out, SPLIT_DIM);\n            writeInt(out, splitPackedValues[i * (1 + fieldInfo.getPointNumBytes())] & 0xff);\n            newline(out);\n            write(out, SPLIT_VALUE);\n            br = new BytesRef(splitPackedValues, 1+(i * (1+fieldInfo.getPointNumBytes())), fieldInfo.getPointNumBytes());\n            write(out, br.toString());\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeLeafBlockDocs(IndexOutput out, int[] docIDs, int start, int count) throws IOException {\n          write(out, BLOCK_COUNT);\n          writeInt(out, count);\n          newline(out);\n          for(int i=0;i<count;i++) {\n            write(out, BLOCK_DOC_ID);\n            writeInt(out, docIDs[start+i]);\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeCommonPrefixes(IndexOutput out, int[] commonPrefixLengths, byte[] packedValue) {\n          // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n        }\n\n        @Override\n        protected void writeLeafBlockPackedValues(IndexOutput out, int[] commonPrefixLengths, int count, int sortedDim, IntFunction<BytesRef> packedValues) throws IOException {\n          for (int i = 0; i < count; ++i) {\n            BytesRef packedValue = packedValues.apply(i);\n            // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n            write(out, BLOCK_VALUE);\n            write(out, packedValue.toString());\n            newline(out);\n          }\n        }\n      }) {\n\n      values.intersect(fieldInfo.name, new IntersectVisitor() {\n          @Override\n          public void visit(int docID) {\n            throw new IllegalStateException();\n          }\n\n          public void visit(int docID, byte[] packedValue) throws IOException {\n            writer.add(packedValue, docID);\n          }\n\n          @Override\n          public Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n            return Relation.CELL_CROSSES_QUERY;\n          }\n        });\n\n      // We could have 0 points on merge since all docs with points may be deleted:\n      if (writer.getPointCount() > 0) {\n        indexFPs.put(fieldInfo.name, writer.finish(dataOut));\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3b013574eedcdbac35dc7e35b0ee616ffc38895d","date":1470897818,"type":4,"author":"Noble Paul","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextPointsWriter#writeField(FieldInfo,PointsReader,double).mjava","sourceNew":null,"sourceOld":"  @Override\n  public void writeField(FieldInfo fieldInfo, PointsReader values, double maxMBSortInHeap) throws IOException {\n\n    boolean singleValuePerDoc = values.size(fieldInfo.name) == values.getDocCount(fieldInfo.name);\n\n    // We use the normal BKDWriter, but subclass to customize how it writes the index and blocks to disk:\n    try (BKDWriter writer = new BKDWriter(writeState.segmentInfo.maxDoc(),\n                                          writeState.directory,\n                                          writeState.segmentInfo.name,\n                                          fieldInfo.getPointDimensionCount(),\n                                          fieldInfo.getPointNumBytes(),\n                                          BKDWriter.DEFAULT_MAX_POINTS_IN_LEAF_NODE,\n                                          maxMBSortInHeap,\n                                          values.size(fieldInfo.name),\n                                          singleValuePerDoc) {\n\n        @Override\n        protected void writeIndex(IndexOutput out, long[] leafBlockFPs, byte[] splitPackedValues) throws IOException {\n          write(out, NUM_DIMS);\n          writeInt(out, numDims);\n          newline(out);\n\n          write(out, BYTES_PER_DIM);\n          writeInt(out, bytesPerDim);\n          newline(out);\n\n          write(out, MAX_LEAF_POINTS);\n          writeInt(out, maxPointsInLeafNode);\n          newline(out);\n\n          write(out, INDEX_COUNT);\n          writeInt(out, leafBlockFPs.length);\n          newline(out);\n\n          write(out, MIN_VALUE);\n          BytesRef br = new BytesRef(minPackedValue, 0, minPackedValue.length);\n          write(out, br.toString());\n          newline(out);\n\n          write(out, MAX_VALUE);\n          br = new BytesRef(maxPackedValue, 0, maxPackedValue.length);\n          write(out, br.toString());\n          newline(out);\n\n          write(out, POINT_COUNT);\n          writeLong(out, pointCount);\n          newline(out);\n\n          write(out, DOC_COUNT);\n          writeInt(out, docsSeen.cardinality());\n          newline(out);\n\n          for(int i=0;i<leafBlockFPs.length;i++) {\n            write(out, BLOCK_FP);\n            writeLong(out, leafBlockFPs[i]);\n            newline(out);\n          }\n\n          assert (splitPackedValues.length % (1 + fieldInfo.getPointNumBytes())) == 0;\n          int count = splitPackedValues.length / (1 + fieldInfo.getPointNumBytes());\n          assert count == leafBlockFPs.length;\n\n          write(out, SPLIT_COUNT);\n          writeInt(out, count);\n          newline(out);\n\n          for(int i=0;i<count;i++) {\n            write(out, SPLIT_DIM);\n            writeInt(out, splitPackedValues[i * (1 + fieldInfo.getPointNumBytes())] & 0xff);\n            newline(out);\n            write(out, SPLIT_VALUE);\n            br = new BytesRef(splitPackedValues, 1+(i * (1+fieldInfo.getPointNumBytes())), fieldInfo.getPointNumBytes());\n            write(out, br.toString());\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeLeafBlockDocs(IndexOutput out, int[] docIDs, int start, int count) throws IOException {\n          write(out, BLOCK_COUNT);\n          writeInt(out, count);\n          newline(out);\n          for(int i=0;i<count;i++) {\n            write(out, BLOCK_DOC_ID);\n            writeInt(out, docIDs[start+i]);\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeCommonPrefixes(IndexOutput out, int[] commonPrefixLengths, byte[] packedValue) {\n          // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n        }\n\n        @Override\n        protected void writeLeafBlockPackedValues(IndexOutput out, int[] commonPrefixLengths, int count, int sortedDim, IntFunction<BytesRef> packedValues) throws IOException {\n          for (int i = 0; i < count; ++i) {\n            BytesRef packedValue = packedValues.apply(i);\n            // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n            write(out, BLOCK_VALUE);\n            write(out, packedValue.toString());\n            newline(out);\n          }\n        }\n      }) {\n\n      values.intersect(fieldInfo.name, new IntersectVisitor() {\n          @Override\n          public void visit(int docID) {\n            throw new IllegalStateException();\n          }\n\n          public void visit(int docID, byte[] packedValue) throws IOException {\n            writer.add(packedValue, docID);\n          }\n\n          @Override\n          public Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n            return Relation.CELL_CROSSES_QUERY;\n          }\n        });\n\n      // We could have 0 points on merge since all docs with points may be deleted:\n      if (writer.getPointCount() > 0) {\n        indexFPs.put(fieldInfo.name, writer.finish(dataOut));\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"b0567940defa1ea6eb8a039d9d36e3682063f8a4":["d08973aa47f2cf98a588293a53af4e948952ccfb"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"10005c6013abbd1102f2463cf95604d4c8774c99":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"d08973aa47f2cf98a588293a53af4e948952ccfb":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","10005c6013abbd1102f2463cf95604d4c8774c99"],"3b013574eedcdbac35dc7e35b0ee616ffc38895d":["d08973aa47f2cf98a588293a53af4e948952ccfb","b0567940defa1ea6eb8a039d9d36e3682063f8a4"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b0567940defa1ea6eb8a039d9d36e3682063f8a4"]},"commit2Childs":{"b0567940defa1ea6eb8a039d9d36e3682063f8a4":["3b013574eedcdbac35dc7e35b0ee616ffc38895d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["10005c6013abbd1102f2463cf95604d4c8774c99","d08973aa47f2cf98a588293a53af4e948952ccfb"],"10005c6013abbd1102f2463cf95604d4c8774c99":["d08973aa47f2cf98a588293a53af4e948952ccfb"],"d08973aa47f2cf98a588293a53af4e948952ccfb":["b0567940defa1ea6eb8a039d9d36e3682063f8a4","3b013574eedcdbac35dc7e35b0ee616ffc38895d"],"3b013574eedcdbac35dc7e35b0ee616ffc38895d":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["3b013574eedcdbac35dc7e35b0ee616ffc38895d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}