{"path":"lucene/analysis/common/src/test/org/apache/lucene/analysis/payloads/TokenOffsetPayloadTokenFilterTest#test().mjava","commits":[{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/payloads/TokenOffsetPayloadTokenFilterTest#test().mjava","pathOld":"modules/analysis/common/src/test/org/apache/lucene/analysis/payloads/TokenOffsetPayloadTokenFilterTest#test().mjava","sourceNew":"  public void test() throws IOException {\n    String test = \"The quick red fox jumped over the lazy brown dogs\";\n\n    TokenOffsetPayloadTokenFilter nptf = new TokenOffsetPayloadTokenFilter(new MockTokenizer(new StringReader(test), MockTokenizer.WHITESPACE, false));\n    int count = 0;\n    PayloadAttribute payloadAtt = nptf.getAttribute(PayloadAttribute.class);\n    OffsetAttribute offsetAtt = nptf.getAttribute(OffsetAttribute.class);\n    nptf.reset();\n    while (nptf.incrementToken()) {\n      Payload pay = payloadAtt.getPayload();\n      assertTrue(\"pay is null and it shouldn't be\", pay != null);\n      byte [] data = pay.getData();\n      int start = PayloadHelper.decodeInt(data, 0);\n      assertTrue(start + \" does not equal: \" + offsetAtt.startOffset(), start == offsetAtt.startOffset());\n      int end = PayloadHelper.decodeInt(data, 4);\n      assertTrue(end + \" does not equal: \" + offsetAtt.endOffset(), end == offsetAtt.endOffset());\n      count++;\n    }\n    assertTrue(count + \" does not equal: \" + 10, count == 10);\n\n  }\n\n","sourceOld":"  public void test() throws IOException {\n    String test = \"The quick red fox jumped over the lazy brown dogs\";\n\n    TokenOffsetPayloadTokenFilter nptf = new TokenOffsetPayloadTokenFilter(new MockTokenizer(new StringReader(test), MockTokenizer.WHITESPACE, false));\n    int count = 0;\n    PayloadAttribute payloadAtt = nptf.getAttribute(PayloadAttribute.class);\n    OffsetAttribute offsetAtt = nptf.getAttribute(OffsetAttribute.class);\n    nptf.reset();\n    while (nptf.incrementToken()) {\n      Payload pay = payloadAtt.getPayload();\n      assertTrue(\"pay is null and it shouldn't be\", pay != null);\n      byte [] data = pay.getData();\n      int start = PayloadHelper.decodeInt(data, 0);\n      assertTrue(start + \" does not equal: \" + offsetAtt.startOffset(), start == offsetAtt.startOffset());\n      int end = PayloadHelper.decodeInt(data, 4);\n      assertTrue(end + \" does not equal: \" + offsetAtt.endOffset(), end == offsetAtt.endOffset());\n      count++;\n    }\n    assertTrue(count + \" does not equal: \" + 10, count == 10);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"76fa9933adb0556e752e8af9734c4d0ae14622ff","date":1339178321,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/payloads/TokenOffsetPayloadTokenFilterTest#test().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/payloads/TokenOffsetPayloadTokenFilterTest#test().mjava","sourceNew":"  public void test() throws IOException {\n    String test = \"The quick red fox jumped over the lazy brown dogs\";\n\n    TokenOffsetPayloadTokenFilter nptf = new TokenOffsetPayloadTokenFilter(new MockTokenizer(new StringReader(test), MockTokenizer.WHITESPACE, false));\n    int count = 0;\n    PayloadAttribute payloadAtt = nptf.getAttribute(PayloadAttribute.class);\n    OffsetAttribute offsetAtt = nptf.getAttribute(OffsetAttribute.class);\n    nptf.reset();\n    while (nptf.incrementToken()) {\n      BytesRef pay = payloadAtt.getPayload();\n      assertTrue(\"pay is null and it shouldn't be\", pay != null);\n      byte [] data = pay.bytes;\n      int start = PayloadHelper.decodeInt(data, 0);\n      assertTrue(start + \" does not equal: \" + offsetAtt.startOffset(), start == offsetAtt.startOffset());\n      int end = PayloadHelper.decodeInt(data, 4);\n      assertTrue(end + \" does not equal: \" + offsetAtt.endOffset(), end == offsetAtt.endOffset());\n      count++;\n    }\n    assertTrue(count + \" does not equal: \" + 10, count == 10);\n\n  }\n\n","sourceOld":"  public void test() throws IOException {\n    String test = \"The quick red fox jumped over the lazy brown dogs\";\n\n    TokenOffsetPayloadTokenFilter nptf = new TokenOffsetPayloadTokenFilter(new MockTokenizer(new StringReader(test), MockTokenizer.WHITESPACE, false));\n    int count = 0;\n    PayloadAttribute payloadAtt = nptf.getAttribute(PayloadAttribute.class);\n    OffsetAttribute offsetAtt = nptf.getAttribute(OffsetAttribute.class);\n    nptf.reset();\n    while (nptf.incrementToken()) {\n      Payload pay = payloadAtt.getPayload();\n      assertTrue(\"pay is null and it shouldn't be\", pay != null);\n      byte [] data = pay.getData();\n      int start = PayloadHelper.decodeInt(data, 0);\n      assertTrue(start + \" does not equal: \" + offsetAtt.startOffset(), start == offsetAtt.startOffset());\n      int end = PayloadHelper.decodeInt(data, 4);\n      assertTrue(end + \" does not equal: \" + offsetAtt.endOffset(), end == offsetAtt.endOffset());\n      count++;\n    }\n    assertTrue(count + \" does not equal: \" + 10, count == 10);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae889fd5c8a69f6b5d130d3c895bfa5b04d07338","date":1389274049,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/payloads/TokenOffsetPayloadTokenFilterTest#test().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/payloads/TokenOffsetPayloadTokenFilterTest#test().mjava","sourceNew":"  public void test() throws IOException {\n    String test = \"The quick red fox jumped over the lazy brown dogs\";\n\n    TokenOffsetPayloadTokenFilter nptf = new TokenOffsetPayloadTokenFilter(whitespaceMockTokenizer(test));\n    int count = 0;\n    PayloadAttribute payloadAtt = nptf.getAttribute(PayloadAttribute.class);\n    OffsetAttribute offsetAtt = nptf.getAttribute(OffsetAttribute.class);\n    nptf.reset();\n    while (nptf.incrementToken()) {\n      BytesRef pay = payloadAtt.getPayload();\n      assertTrue(\"pay is null and it shouldn't be\", pay != null);\n      byte [] data = pay.bytes;\n      int start = PayloadHelper.decodeInt(data, 0);\n      assertTrue(start + \" does not equal: \" + offsetAtt.startOffset(), start == offsetAtt.startOffset());\n      int end = PayloadHelper.decodeInt(data, 4);\n      assertTrue(end + \" does not equal: \" + offsetAtt.endOffset(), end == offsetAtt.endOffset());\n      count++;\n    }\n    assertTrue(count + \" does not equal: \" + 10, count == 10);\n\n  }\n\n","sourceOld":"  public void test() throws IOException {\n    String test = \"The quick red fox jumped over the lazy brown dogs\";\n\n    TokenOffsetPayloadTokenFilter nptf = new TokenOffsetPayloadTokenFilter(new MockTokenizer(new StringReader(test), MockTokenizer.WHITESPACE, false));\n    int count = 0;\n    PayloadAttribute payloadAtt = nptf.getAttribute(PayloadAttribute.class);\n    OffsetAttribute offsetAtt = nptf.getAttribute(OffsetAttribute.class);\n    nptf.reset();\n    while (nptf.incrementToken()) {\n      BytesRef pay = payloadAtt.getPayload();\n      assertTrue(\"pay is null and it shouldn't be\", pay != null);\n      byte [] data = pay.bytes;\n      int start = PayloadHelper.decodeInt(data, 0);\n      assertTrue(start + \" does not equal: \" + offsetAtt.startOffset(), start == offsetAtt.startOffset());\n      int end = PayloadHelper.decodeInt(data, 4);\n      assertTrue(end + \" does not equal: \" + offsetAtt.endOffset(), end == offsetAtt.endOffset());\n      count++;\n    }\n    assertTrue(count + \" does not equal: \" + 10, count == 10);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"ae889fd5c8a69f6b5d130d3c895bfa5b04d07338":["76fa9933adb0556e752e8af9734c4d0ae14622ff"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"76fa9933adb0556e752e8af9734c4d0ae14622ff":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["ae889fd5c8a69f6b5d130d3c895bfa5b04d07338"]},"commit2Childs":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["76fa9933adb0556e752e8af9734c4d0ae14622ff"],"ae889fd5c8a69f6b5d130d3c895bfa5b04d07338":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"76fa9933adb0556e752e8af9734c4d0ae14622ff":["ae889fd5c8a69f6b5d130d3c895bfa5b04d07338"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}