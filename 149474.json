{"path":"lucene/analysis/common/src/test/org/apache/lucene/analysis/shingle/ShingleFilterTest#testPositionLength().mjava","commits":[{"id":"bce5c9637fdd284e5990e2e810bc9faafa336bc5","date":1487975857,"type":0,"author":"Jim Ferenczi","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/shingle/ShingleFilterTest#testPositionLength().mjava","pathOld":"/dev/null","sourceNew":"  public void testPositionLength() throws Exception {\n    Analyzer a = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        ShingleFilter filter = new ShingleFilter(tokenizer, 4, 4);\n        filter.setOutputUnigrams(false);\n        return new TokenStreamComponents(tokenizer, filter);\n      }\n    };\n    assertTokenStreamContents(a.tokenStream(\"\", \"to be or not to be\"),\n        new String[] {\"to be or not\", \"be or not to\", \"or not to be\"},\n        new int[] {0, 3, 6},\n        new int[] {12, 15, 18},\n        null,\n        new int[] {1, 1, 1},\n        new int[] {1, 1, 1},\n        18,\n        // offsets are correct but assertTokenStreamContents does not handle multiple terms with different offsets\n        // finishing at the same position\n        false);\n\n\n    a = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        ShingleFilter filter = new ShingleFilter(tokenizer, 2, 4);\n        filter.setOutputUnigrams(false);\n        return new TokenStreamComponents(tokenizer, filter);\n      }\n    };\n    assertTokenStreamContents(a.tokenStream(\"\", \"to be or not to be\"),\n        new String[] {\"to be\", \"to be or\", \"to be or not\", \"be or\", \"be or not\", \"be or not to\", \"or not\", \"or not to\",\n            \"or not to be\", \"not to\", \"not to be\", \"to be\"},\n        new int[] {0, 0, 0, 3, 3, 3, 6, 6, 6, 9, 9, 13},\n        new int[] {5, 8, 12, 8, 12, 15, 12, 15, 18, 15, 18, 18},\n        null,\n        new int[] {1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1},\n        new int[] {1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 1},\n        18,\n        // offsets are correct but assertTokenStreamContents does not handle multiple terms with different offsets\n        // finishing at the same position\n        false);\n\n    a = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        ShingleFilter filter = new ShingleFilter(tokenizer, 3, 4);\n        filter.setOutputUnigrams(false);\n        return new TokenStreamComponents(tokenizer, filter);\n      }\n    };\n\n    assertTokenStreamContents(a.tokenStream(\"\", \"to be or not to be\"),\n        new String[] {\"to be or\", \"to be or not\", \"be or not\", \"be or not to\", \"or not to\",\n            \"or not to be\", \"not to be\"},\n        new int[] {0, 0, 3, 3, 6, 6, 9},\n        new int[] {8, 12, 12, 15, 15, 18, 18},\n        null,\n        new int[] {1, 0, 1, 0, 1, 0, 1, 0},\n        new int[] {1, 2, 1, 2, 1, 2, 1, 2},\n        18,\n        // offsets are correct but assertTokenStreamContents does not handle multiple terms with different offsets\n        // finishing at the same position\n        false);\n\n    a = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        ShingleFilter filter = new ShingleFilter(tokenizer, 3, 5);\n        filter.setOutputUnigrams(false);\n        return new TokenStreamComponents(tokenizer, filter);\n      }\n    };\n    assertTokenStreamContents(a.tokenStream(\"\", \"to be or not to be\"),\n        new String[] {\"to be or\", \"to be or not\", \"to be or not to\", \"be or not\", \"be or not to\",\n            \"be or not to be\", \"or not to\", \"or not to be\", \"not to be\"},\n        new int[] {0, 0, 0, 3, 3, 3, 6, 6, 9, 9},\n        new int[] {8, 12, 15, 12, 15, 18, 15, 18, 18},\n        null,\n        new int[] {1, 0, 0, 1, 0, 0, 1, 0, 1, 0},\n        new int[] {1, 2, 3, 1, 2, 3, 1, 2, 1},\n        18,\n        // offsets are correct but assertTokenStreamContents does not handle multiple terms with different offsets\n        // finishing at the same position\n        false);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"bce5c9637fdd284e5990e2e810bc9faafa336bc5":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["bce5c9637fdd284e5990e2e810bc9faafa336bc5"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["bce5c9637fdd284e5990e2e810bc9faafa336bc5"],"bce5c9637fdd284e5990e2e810bc9faafa336bc5":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}