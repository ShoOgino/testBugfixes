{"path":"lucene/luke/src/java/org/apache/lucene/luke/models/analysis/AnalysisImpl#analyzeTokenStream(TokenStream,List[Token]).mjava","commits":[{"id":"7b7dac0d1d148a67a2728aa772cf93b6a3ef6e77","date":1561188146,"type":0,"author":"Tomoko Uchida","isMerge":false,"pathNew":"lucene/luke/src/java/org/apache/lucene/luke/models/analysis/AnalysisImpl#analyzeTokenStream(TokenStream,List[Token]).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Analyzes the given TokenStream, collecting the Tokens it produces.\n   *\n   * @param tokenStream TokenStream to analyze\n   *\n   * @return List of tokens produced from the TokenStream\n   */\n  private List<AttributeSource> analyzeTokenStream(TokenStream tokenStream, List<Token> result) {\n    final List<AttributeSource> tokens = new ArrayList<>();\n    try {\n      tokenStream.reset();\n      CharTermAttribute charAtt = tokenStream.getAttribute(CharTermAttribute.class);\n      while (tokenStream.incrementToken()) {\n        tokens.add(tokenStream.cloneAttributes());\n        List<TokenAttribute> attributes = copyAttributes(tokenStream, charAtt);\n        result.add(new Token(charAtt.toString(), attributes));\n      }\n      tokenStream.end();\n    } catch (IOException ioe) {\n      throw new RuntimeException(\"Error occurred while iterating over TokenStream\", ioe);\n    } finally {\n      IOUtils.closeWhileHandlingException(tokenStream);\n    }\n    return tokens;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"dde00f8ce3ea6870a348e607a273123f0895ec87","date":1561189287,"type":0,"author":"Tomoko Uchida","isMerge":true,"pathNew":"lucene/luke/src/java/org/apache/lucene/luke/models/analysis/AnalysisImpl#analyzeTokenStream(TokenStream,List[Token]).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Analyzes the given TokenStream, collecting the Tokens it produces.\n   *\n   * @param tokenStream TokenStream to analyze\n   *\n   * @return List of tokens produced from the TokenStream\n   */\n  private List<AttributeSource> analyzeTokenStream(TokenStream tokenStream, List<Token> result) {\n    final List<AttributeSource> tokens = new ArrayList<>();\n    try {\n      tokenStream.reset();\n      CharTermAttribute charAtt = tokenStream.getAttribute(CharTermAttribute.class);\n      while (tokenStream.incrementToken()) {\n        tokens.add(tokenStream.cloneAttributes());\n        List<TokenAttribute> attributes = copyAttributes(tokenStream, charAtt);\n        result.add(new Token(charAtt.toString(), attributes));\n      }\n      tokenStream.end();\n    } catch (IOException ioe) {\n      throw new RuntimeException(\"Error occurred while iterating over TokenStream\", ioe);\n    } finally {\n      IOUtils.closeWhileHandlingException(tokenStream);\n    }\n    return tokens;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"dde00f8ce3ea6870a348e607a273123f0895ec87":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","7b7dac0d1d148a67a2728aa772cf93b6a3ef6e77"],"7b7dac0d1d148a67a2728aa772cf93b6a3ef6e77":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["dde00f8ce3ea6870a348e607a273123f0895ec87"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["dde00f8ce3ea6870a348e607a273123f0895ec87","7b7dac0d1d148a67a2728aa772cf93b6a3ef6e77"],"dde00f8ce3ea6870a348e607a273123f0895ec87":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"7b7dac0d1d148a67a2728aa772cf93b6a3ef6e77":["dde00f8ce3ea6870a348e607a273123f0895ec87"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}