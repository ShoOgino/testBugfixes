{"path":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextDimensionalWriter#writeField(FieldInfo,DimensionalReader).mjava","commits":[{"id":"ca792c26af46bd6c4a08d81117c60440cf6a7e3d","date":1445938295,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextDimensionalWriter#writeField(FieldInfo,DimensionalReader).mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public void writeField(FieldInfo fieldInfo, DimensionalReader values) throws IOException {\n\n    // We use the normal BKDWriter, but subclass to customize how it writes the index and blocks to disk:\n    BKDWriter writer = new BKDWriter(writeState.directory,\n                                     writeState.segmentInfo.name,\n                                     fieldInfo.getDimensionCount(),\n                                     fieldInfo.getDimensionNumBytes(),\n                                     BKDWriter.DEFAULT_MAX_POINTS_IN_LEAF_NODE,\n                                     BKDWriter.DEFAULT_MAX_MB_SORT_IN_HEAP) {\n\n        @Override\n        protected void writeIndex(IndexOutput out, long[] leafBlockFPs, byte[] splitPackedValues) throws IOException {\n          write(out, NUM_DIMS);\n          writeInt(out, numDims);\n          newline(out);\n\n          write(out, BYTES_PER_DIM);\n          writeInt(out, bytesPerDim);\n          newline(out);\n\n          write(out, MAX_LEAF_POINTS);\n          writeInt(out, maxPointsInLeafNode);\n          newline(out);\n\n          write(out, INDEX_COUNT);\n          writeInt(out, leafBlockFPs.length);\n          newline(out);\n\n          for(int i=0;i<leafBlockFPs.length;i++) {\n            write(out, BLOCK_FP);\n            writeLong(out, leafBlockFPs[i]);\n            newline(out);\n          }\n\n          assert (splitPackedValues.length % (1 + fieldInfo.getDimensionNumBytes())) == 0;\n          int count = splitPackedValues.length / (1 + fieldInfo.getDimensionNumBytes());\n          assert count == leafBlockFPs.length;\n\n          write(out, SPLIT_COUNT);\n          writeInt(out, count);\n          newline(out);\n\n          for(int i=0;i<count;i++) {\n            write(out, SPLIT_DIM);\n            writeInt(out, splitPackedValues[i * (1 + fieldInfo.getDimensionNumBytes())] & 0xff);\n            newline(out);\n            write(out, SPLIT_VALUE);\n            BytesRef br = new BytesRef(splitPackedValues, 1+(i * (1+fieldInfo.getDimensionNumBytes())), fieldInfo.getDimensionNumBytes());\n            write(out, br.toString());\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeLeafBlockDocs(IndexOutput out, int[] docIDs, int start, int count) throws IOException {\n          write(out, BLOCK_COUNT);\n          writeInt(out, count);\n          newline(out);\n          for(int i=0;i<count;i++) {\n            write(out, BLOCK_DOC_ID);\n            writeInt(out, docIDs[start+i]);\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeLeafBlockPackedValue(IndexOutput out, byte[] bytes, int offset, int length) throws IOException {\n          assert length == packedBytesLength;\n          write(out, BLOCK_VALUE);\n          write(out, new BytesRef(bytes, offset, length).toString());\n          newline(out);\n        }          \n      };\n\n    values.intersect(fieldInfo.name, new IntersectVisitor() {\n        @Override\n        public void visit(int docID) {\n          throw new IllegalStateException();\n        }\n\n        public void visit(int docID, byte[] packedValue) throws IOException {\n          writer.add(packedValue, docID);\n        }\n\n        @Override\n        public Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n          return Relation.QUERY_CROSSES_CELL;\n        }\n      });\n    indexFPs.put(fieldInfo.name, writer.finish(dataOut));\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["d2d93e80a51ae7994e1639fbd83763acdef9beb1"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1904709ea0185dc04e3d77ea01c79e909caf2796","date":1447006699,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextDimensionalWriter#writeField(FieldInfo,DimensionalReader).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextDimensionalWriter#writeField(FieldInfo,DimensionalReader).mjava","sourceNew":"  @Override\n  public void writeField(FieldInfo fieldInfo, DimensionalReader values) throws IOException {\n\n    // We use the normal BKDWriter, but subclass to customize how it writes the index and blocks to disk:\n    BKDWriter writer = new BKDWriter(writeState.directory,\n                                     writeState.segmentInfo.name,\n                                     fieldInfo.getDimensionCount(),\n                                     fieldInfo.getDimensionNumBytes(),\n                                     BKDWriter.DEFAULT_MAX_POINTS_IN_LEAF_NODE,\n                                     BKDWriter.DEFAULT_MAX_MB_SORT_IN_HEAP) {\n\n        @Override\n        protected void writeIndex(IndexOutput out, long[] leafBlockFPs, byte[] splitPackedValues) throws IOException {\n          write(out, NUM_DIMS);\n          writeInt(out, numDims);\n          newline(out);\n\n          write(out, BYTES_PER_DIM);\n          writeInt(out, bytesPerDim);\n          newline(out);\n\n          write(out, MAX_LEAF_POINTS);\n          writeInt(out, maxPointsInLeafNode);\n          newline(out);\n\n          write(out, INDEX_COUNT);\n          writeInt(out, leafBlockFPs.length);\n          newline(out);\n\n          for(int i=0;i<leafBlockFPs.length;i++) {\n            write(out, BLOCK_FP);\n            writeLong(out, leafBlockFPs[i]);\n            newline(out);\n          }\n\n          assert (splitPackedValues.length % (1 + fieldInfo.getDimensionNumBytes())) == 0;\n          int count = splitPackedValues.length / (1 + fieldInfo.getDimensionNumBytes());\n          assert count == leafBlockFPs.length;\n\n          write(out, SPLIT_COUNT);\n          writeInt(out, count);\n          newline(out);\n\n          for(int i=0;i<count;i++) {\n            write(out, SPLIT_DIM);\n            writeInt(out, splitPackedValues[i * (1 + fieldInfo.getDimensionNumBytes())] & 0xff);\n            newline(out);\n            write(out, SPLIT_VALUE);\n            BytesRef br = new BytesRef(splitPackedValues, 1+(i * (1+fieldInfo.getDimensionNumBytes())), fieldInfo.getDimensionNumBytes());\n            write(out, br.toString());\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeLeafBlockDocs(IndexOutput out, int[] docIDs, int start, int count) throws IOException {\n          write(out, BLOCK_COUNT);\n          writeInt(out, count);\n          newline(out);\n          for(int i=0;i<count;i++) {\n            write(out, BLOCK_DOC_ID);\n            writeInt(out, docIDs[start+i]);\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeLeafBlockPackedValue(IndexOutput out, byte[] bytes, int offset, int length) throws IOException {\n          assert length == packedBytesLength;\n          write(out, BLOCK_VALUE);\n          write(out, new BytesRef(bytes, offset, length).toString());\n          newline(out);\n        }          \n      };\n\n    values.intersect(fieldInfo.name, new IntersectVisitor() {\n        @Override\n        public void visit(int docID) {\n          throw new IllegalStateException();\n        }\n\n        public void visit(int docID, byte[] packedValue) throws IOException {\n          writer.add(packedValue, docID);\n        }\n\n        @Override\n        public Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n          return Relation.CELL_CROSSES_QUERY;\n        }\n      });\n    indexFPs.put(fieldInfo.name, writer.finish(dataOut));\n  }\n\n","sourceOld":"  @Override\n  public void writeField(FieldInfo fieldInfo, DimensionalReader values) throws IOException {\n\n    // We use the normal BKDWriter, but subclass to customize how it writes the index and blocks to disk:\n    BKDWriter writer = new BKDWriter(writeState.directory,\n                                     writeState.segmentInfo.name,\n                                     fieldInfo.getDimensionCount(),\n                                     fieldInfo.getDimensionNumBytes(),\n                                     BKDWriter.DEFAULT_MAX_POINTS_IN_LEAF_NODE,\n                                     BKDWriter.DEFAULT_MAX_MB_SORT_IN_HEAP) {\n\n        @Override\n        protected void writeIndex(IndexOutput out, long[] leafBlockFPs, byte[] splitPackedValues) throws IOException {\n          write(out, NUM_DIMS);\n          writeInt(out, numDims);\n          newline(out);\n\n          write(out, BYTES_PER_DIM);\n          writeInt(out, bytesPerDim);\n          newline(out);\n\n          write(out, MAX_LEAF_POINTS);\n          writeInt(out, maxPointsInLeafNode);\n          newline(out);\n\n          write(out, INDEX_COUNT);\n          writeInt(out, leafBlockFPs.length);\n          newline(out);\n\n          for(int i=0;i<leafBlockFPs.length;i++) {\n            write(out, BLOCK_FP);\n            writeLong(out, leafBlockFPs[i]);\n            newline(out);\n          }\n\n          assert (splitPackedValues.length % (1 + fieldInfo.getDimensionNumBytes())) == 0;\n          int count = splitPackedValues.length / (1 + fieldInfo.getDimensionNumBytes());\n          assert count == leafBlockFPs.length;\n\n          write(out, SPLIT_COUNT);\n          writeInt(out, count);\n          newline(out);\n\n          for(int i=0;i<count;i++) {\n            write(out, SPLIT_DIM);\n            writeInt(out, splitPackedValues[i * (1 + fieldInfo.getDimensionNumBytes())] & 0xff);\n            newline(out);\n            write(out, SPLIT_VALUE);\n            BytesRef br = new BytesRef(splitPackedValues, 1+(i * (1+fieldInfo.getDimensionNumBytes())), fieldInfo.getDimensionNumBytes());\n            write(out, br.toString());\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeLeafBlockDocs(IndexOutput out, int[] docIDs, int start, int count) throws IOException {\n          write(out, BLOCK_COUNT);\n          writeInt(out, count);\n          newline(out);\n          for(int i=0;i<count;i++) {\n            write(out, BLOCK_DOC_ID);\n            writeInt(out, docIDs[start+i]);\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeLeafBlockPackedValue(IndexOutput out, byte[] bytes, int offset, int length) throws IOException {\n          assert length == packedBytesLength;\n          write(out, BLOCK_VALUE);\n          write(out, new BytesRef(bytes, offset, length).toString());\n          newline(out);\n        }          \n      };\n\n    values.intersect(fieldInfo.name, new IntersectVisitor() {\n        @Override\n        public void visit(int docID) {\n          throw new IllegalStateException();\n        }\n\n        public void visit(int docID, byte[] packedValue) throws IOException {\n          writer.add(packedValue, docID);\n        }\n\n        @Override\n        public Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n          return Relation.QUERY_CROSSES_CELL;\n        }\n      });\n    indexFPs.put(fieldInfo.name, writer.finish(dataOut));\n  }\n\n","bugFix":null,"bugIntro":["d2d93e80a51ae7994e1639fbd83763acdef9beb1"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b9f70b31079ec002469ee49df3b8f9bd8d10df23","date":1447755747,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextDimensionalWriter#writeField(FieldInfo,DimensionalReader).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextDimensionalWriter#writeField(FieldInfo,DimensionalReader).mjava","sourceNew":"  @Override\n  public void writeField(FieldInfo fieldInfo, DimensionalReader values) throws IOException {\n\n    // We use the normal BKDWriter, but subclass to customize how it writes the index and blocks to disk:\n    BKDWriter writer = new BKDWriter(writeState.directory,\n                                     writeState.segmentInfo.name,\n                                     fieldInfo.getDimensionCount(),\n                                     fieldInfo.getDimensionNumBytes(),\n                                     BKDWriter.DEFAULT_MAX_POINTS_IN_LEAF_NODE,\n                                     BKDWriter.DEFAULT_MAX_MB_SORT_IN_HEAP) {\n\n        @Override\n        protected void writeIndex(IndexOutput out, long[] leafBlockFPs, byte[] splitPackedValues) throws IOException {\n          write(out, NUM_DIMS);\n          writeInt(out, numDims);\n          newline(out);\n\n          write(out, BYTES_PER_DIM);\n          writeInt(out, bytesPerDim);\n          newline(out);\n\n          write(out, MAX_LEAF_POINTS);\n          writeInt(out, maxPointsInLeafNode);\n          newline(out);\n\n          write(out, INDEX_COUNT);\n          writeInt(out, leafBlockFPs.length);\n          newline(out);\n\n          for(int i=0;i<leafBlockFPs.length;i++) {\n            write(out, BLOCK_FP);\n            writeLong(out, leafBlockFPs[i]);\n            newline(out);\n          }\n\n          assert (splitPackedValues.length % (1 + fieldInfo.getDimensionNumBytes())) == 0;\n          int count = splitPackedValues.length / (1 + fieldInfo.getDimensionNumBytes());\n          assert count == leafBlockFPs.length;\n\n          write(out, SPLIT_COUNT);\n          writeInt(out, count);\n          newline(out);\n\n          for(int i=0;i<count;i++) {\n            write(out, SPLIT_DIM);\n            writeInt(out, splitPackedValues[i * (1 + fieldInfo.getDimensionNumBytes())] & 0xff);\n            newline(out);\n            write(out, SPLIT_VALUE);\n            BytesRef br = new BytesRef(splitPackedValues, 1+(i * (1+fieldInfo.getDimensionNumBytes())), fieldInfo.getDimensionNumBytes());\n            write(out, br.toString());\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeLeafBlockDocs(IndexOutput out, int[] docIDs, int start, int count) throws IOException {\n          write(out, BLOCK_COUNT);\n          writeInt(out, count);\n          newline(out);\n          for(int i=0;i<count;i++) {\n            write(out, BLOCK_DOC_ID);\n            writeInt(out, docIDs[start+i]);\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeCommonPrefixes(IndexOutput out, int[] commonPrefixLengths, byte[] packedValue) {\n          // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n        }\n\n        @Override\n        protected void writeLeafBlockPackedValue(IndexOutput out, int[] commonPrefixLengths, byte[] bytes) throws IOException {\n          // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n          assert bytes.length == packedBytesLength;\n          write(out, BLOCK_VALUE);\n          write(out, new BytesRef(bytes, 0, bytes.length).toString());\n          newline(out);\n        }          \n      };\n\n    values.intersect(fieldInfo.name, new IntersectVisitor() {\n        @Override\n        public void visit(int docID) {\n          throw new IllegalStateException();\n        }\n\n        public void visit(int docID, byte[] packedValue) throws IOException {\n          writer.add(packedValue, docID);\n        }\n\n        @Override\n        public Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n          return Relation.CELL_CROSSES_QUERY;\n        }\n      });\n    indexFPs.put(fieldInfo.name, writer.finish(dataOut));\n  }\n\n","sourceOld":"  @Override\n  public void writeField(FieldInfo fieldInfo, DimensionalReader values) throws IOException {\n\n    // We use the normal BKDWriter, but subclass to customize how it writes the index and blocks to disk:\n    BKDWriter writer = new BKDWriter(writeState.directory,\n                                     writeState.segmentInfo.name,\n                                     fieldInfo.getDimensionCount(),\n                                     fieldInfo.getDimensionNumBytes(),\n                                     BKDWriter.DEFAULT_MAX_POINTS_IN_LEAF_NODE,\n                                     BKDWriter.DEFAULT_MAX_MB_SORT_IN_HEAP) {\n\n        @Override\n        protected void writeIndex(IndexOutput out, long[] leafBlockFPs, byte[] splitPackedValues) throws IOException {\n          write(out, NUM_DIMS);\n          writeInt(out, numDims);\n          newline(out);\n\n          write(out, BYTES_PER_DIM);\n          writeInt(out, bytesPerDim);\n          newline(out);\n\n          write(out, MAX_LEAF_POINTS);\n          writeInt(out, maxPointsInLeafNode);\n          newline(out);\n\n          write(out, INDEX_COUNT);\n          writeInt(out, leafBlockFPs.length);\n          newline(out);\n\n          for(int i=0;i<leafBlockFPs.length;i++) {\n            write(out, BLOCK_FP);\n            writeLong(out, leafBlockFPs[i]);\n            newline(out);\n          }\n\n          assert (splitPackedValues.length % (1 + fieldInfo.getDimensionNumBytes())) == 0;\n          int count = splitPackedValues.length / (1 + fieldInfo.getDimensionNumBytes());\n          assert count == leafBlockFPs.length;\n\n          write(out, SPLIT_COUNT);\n          writeInt(out, count);\n          newline(out);\n\n          for(int i=0;i<count;i++) {\n            write(out, SPLIT_DIM);\n            writeInt(out, splitPackedValues[i * (1 + fieldInfo.getDimensionNumBytes())] & 0xff);\n            newline(out);\n            write(out, SPLIT_VALUE);\n            BytesRef br = new BytesRef(splitPackedValues, 1+(i * (1+fieldInfo.getDimensionNumBytes())), fieldInfo.getDimensionNumBytes());\n            write(out, br.toString());\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeLeafBlockDocs(IndexOutput out, int[] docIDs, int start, int count) throws IOException {\n          write(out, BLOCK_COUNT);\n          writeInt(out, count);\n          newline(out);\n          for(int i=0;i<count;i++) {\n            write(out, BLOCK_DOC_ID);\n            writeInt(out, docIDs[start+i]);\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeLeafBlockPackedValue(IndexOutput out, byte[] bytes, int offset, int length) throws IOException {\n          assert length == packedBytesLength;\n          write(out, BLOCK_VALUE);\n          write(out, new BytesRef(bytes, offset, length).toString());\n          newline(out);\n        }          \n      };\n\n    values.intersect(fieldInfo.name, new IntersectVisitor() {\n        @Override\n        public void visit(int docID) {\n          throw new IllegalStateException();\n        }\n\n        public void visit(int docID, byte[] packedValue) throws IOException {\n          writer.add(packedValue, docID);\n        }\n\n        @Override\n        public Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n          return Relation.CELL_CROSSES_QUERY;\n        }\n      });\n    indexFPs.put(fieldInfo.name, writer.finish(dataOut));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d0c44765ee347f8c49bc6c0ffe1cdfb42738bd6a","date":1450910176,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextDimensionalWriter#writeField(FieldInfo,DimensionalReader).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextDimensionalWriter#writeField(FieldInfo,DimensionalReader).mjava","sourceNew":"  @Override\n  public void writeField(FieldInfo fieldInfo, DimensionalReader values) throws IOException {\n\n    // We use the normal BKDWriter, but subclass to customize how it writes the index and blocks to disk:\n    BKDWriter writer = new BKDWriter(writeState.directory,\n                                     writeState.segmentInfo.name,\n                                     fieldInfo.getDimensionCount(),\n                                     fieldInfo.getDimensionNumBytes(),\n                                     BKDWriter.DEFAULT_MAX_POINTS_IN_LEAF_NODE,\n                                     BKDWriter.DEFAULT_MAX_MB_SORT_IN_HEAP) {\n\n        @Override\n        protected void writeIndex(IndexOutput out, long[] leafBlockFPs, byte[] splitPackedValues) throws IOException {\n          write(out, NUM_DIMS);\n          writeInt(out, numDims);\n          newline(out);\n\n          write(out, BYTES_PER_DIM);\n          writeInt(out, bytesPerDim);\n          newline(out);\n\n          write(out, MAX_LEAF_POINTS);\n          writeInt(out, maxPointsInLeafNode);\n          newline(out);\n\n          write(out, INDEX_COUNT);\n          writeInt(out, leafBlockFPs.length);\n          newline(out);\n\n          for(int i=0;i<leafBlockFPs.length;i++) {\n            write(out, BLOCK_FP);\n            writeLong(out, leafBlockFPs[i]);\n            newline(out);\n          }\n\n          assert (splitPackedValues.length % (1 + fieldInfo.getDimensionNumBytes())) == 0;\n          int count = splitPackedValues.length / (1 + fieldInfo.getDimensionNumBytes());\n          assert count == leafBlockFPs.length;\n\n          write(out, SPLIT_COUNT);\n          writeInt(out, count);\n          newline(out);\n\n          for(int i=0;i<count;i++) {\n            write(out, SPLIT_DIM);\n            writeInt(out, splitPackedValues[i * (1 + fieldInfo.getDimensionNumBytes())] & 0xff);\n            newline(out);\n            write(out, SPLIT_VALUE);\n            BytesRef br = new BytesRef(splitPackedValues, 1+(i * (1+fieldInfo.getDimensionNumBytes())), fieldInfo.getDimensionNumBytes());\n            write(out, br.toString());\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeLeafBlockDocs(IndexOutput out, int[] docIDs, int start, int count) throws IOException {\n          write(out, BLOCK_COUNT);\n          writeInt(out, count);\n          newline(out);\n          for(int i=0;i<count;i++) {\n            write(out, BLOCK_DOC_ID);\n            writeInt(out, docIDs[start+i]);\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeCommonPrefixes(IndexOutput out, int[] commonPrefixLengths, byte[] packedValue) {\n          // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n        }\n\n        @Override\n        protected void writeLeafBlockPackedValue(IndexOutput out, int[] commonPrefixLengths, byte[] bytes) throws IOException {\n          // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n          assert bytes.length == packedBytesLength;\n          write(out, BLOCK_VALUE);\n          write(out, new BytesRef(bytes, 0, bytes.length).toString());\n          newline(out);\n        }          \n      };\n\n    values.intersect(fieldInfo.name, new IntersectVisitor() {\n        @Override\n        public void visit(int docID) {\n          throw new IllegalStateException();\n        }\n\n        public void visit(int docID, byte[] packedValue) throws IOException {\n          writer.add(packedValue, docID);\n        }\n\n        @Override\n        public Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n          return Relation.CELL_CROSSES_QUERY;\n        }\n      });\n\n    // We could have 0 points on merge since all docs with dimensional fields may be deleted:\n    if (writer.getPointCount() > 0) {\n      indexFPs.put(fieldInfo.name, writer.finish(dataOut));\n    }\n  }\n\n","sourceOld":"  @Override\n  public void writeField(FieldInfo fieldInfo, DimensionalReader values) throws IOException {\n\n    // We use the normal BKDWriter, but subclass to customize how it writes the index and blocks to disk:\n    BKDWriter writer = new BKDWriter(writeState.directory,\n                                     writeState.segmentInfo.name,\n                                     fieldInfo.getDimensionCount(),\n                                     fieldInfo.getDimensionNumBytes(),\n                                     BKDWriter.DEFAULT_MAX_POINTS_IN_LEAF_NODE,\n                                     BKDWriter.DEFAULT_MAX_MB_SORT_IN_HEAP) {\n\n        @Override\n        protected void writeIndex(IndexOutput out, long[] leafBlockFPs, byte[] splitPackedValues) throws IOException {\n          write(out, NUM_DIMS);\n          writeInt(out, numDims);\n          newline(out);\n\n          write(out, BYTES_PER_DIM);\n          writeInt(out, bytesPerDim);\n          newline(out);\n\n          write(out, MAX_LEAF_POINTS);\n          writeInt(out, maxPointsInLeafNode);\n          newline(out);\n\n          write(out, INDEX_COUNT);\n          writeInt(out, leafBlockFPs.length);\n          newline(out);\n\n          for(int i=0;i<leafBlockFPs.length;i++) {\n            write(out, BLOCK_FP);\n            writeLong(out, leafBlockFPs[i]);\n            newline(out);\n          }\n\n          assert (splitPackedValues.length % (1 + fieldInfo.getDimensionNumBytes())) == 0;\n          int count = splitPackedValues.length / (1 + fieldInfo.getDimensionNumBytes());\n          assert count == leafBlockFPs.length;\n\n          write(out, SPLIT_COUNT);\n          writeInt(out, count);\n          newline(out);\n\n          for(int i=0;i<count;i++) {\n            write(out, SPLIT_DIM);\n            writeInt(out, splitPackedValues[i * (1 + fieldInfo.getDimensionNumBytes())] & 0xff);\n            newline(out);\n            write(out, SPLIT_VALUE);\n            BytesRef br = new BytesRef(splitPackedValues, 1+(i * (1+fieldInfo.getDimensionNumBytes())), fieldInfo.getDimensionNumBytes());\n            write(out, br.toString());\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeLeafBlockDocs(IndexOutput out, int[] docIDs, int start, int count) throws IOException {\n          write(out, BLOCK_COUNT);\n          writeInt(out, count);\n          newline(out);\n          for(int i=0;i<count;i++) {\n            write(out, BLOCK_DOC_ID);\n            writeInt(out, docIDs[start+i]);\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeCommonPrefixes(IndexOutput out, int[] commonPrefixLengths, byte[] packedValue) {\n          // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n        }\n\n        @Override\n        protected void writeLeafBlockPackedValue(IndexOutput out, int[] commonPrefixLengths, byte[] bytes) throws IOException {\n          // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n          assert bytes.length == packedBytesLength;\n          write(out, BLOCK_VALUE);\n          write(out, new BytesRef(bytes, 0, bytes.length).toString());\n          newline(out);\n        }          \n      };\n\n    values.intersect(fieldInfo.name, new IntersectVisitor() {\n        @Override\n        public void visit(int docID) {\n          throw new IllegalStateException();\n        }\n\n        public void visit(int docID, byte[] packedValue) throws IOException {\n          writer.add(packedValue, docID);\n        }\n\n        @Override\n        public Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n          return Relation.CELL_CROSSES_QUERY;\n        }\n      });\n    indexFPs.put(fieldInfo.name, writer.finish(dataOut));\n  }\n\n","bugFix":null,"bugIntro":["d2d93e80a51ae7994e1639fbd83763acdef9beb1"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ecf331f9d7bdd234863d2df2bb5c1f019979422f","date":1452250335,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextDimensionalWriter#writeField(FieldInfo,DimensionalReader).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextDimensionalWriter#writeField(FieldInfo,DimensionalReader).mjava","sourceNew":"  @Override\n  public void writeField(FieldInfo fieldInfo, DimensionalReader values) throws IOException {\n\n    // We use the normal BKDWriter, but subclass to customize how it writes the index and blocks to disk:\n    BKDWriter writer = new BKDWriter(writeState.directory,\n                                     writeState.segmentInfo.name,\n                                     fieldInfo.getDimensionCount(),\n                                     fieldInfo.getDimensionNumBytes(),\n                                     BKDWriter.DEFAULT_MAX_POINTS_IN_LEAF_NODE,\n                                     BKDWriter.DEFAULT_MAX_MB_SORT_IN_HEAP) {\n\n        @Override\n        protected void writeIndex(IndexOutput out, long[] leafBlockFPs, byte[] splitPackedValues) throws IOException {\n          write(out, NUM_DIMS);\n          writeInt(out, numDims);\n          newline(out);\n\n          write(out, BYTES_PER_DIM);\n          writeInt(out, bytesPerDim);\n          newline(out);\n\n          write(out, MAX_LEAF_POINTS);\n          writeInt(out, maxPointsInLeafNode);\n          newline(out);\n\n          write(out, INDEX_COUNT);\n          writeInt(out, leafBlockFPs.length);\n          newline(out);\n\n          write(out, MIN_VALUE);\n          BytesRef br = new BytesRef(minPackedValue, 0, minPackedValue.length);\n          write(out, br.toString());\n\n          write(out, MAX_VALUE);\n          br = new BytesRef(maxPackedValue, 0, maxPackedValue.length);\n          write(out, br.toString());\n\n          for(int i=0;i<leafBlockFPs.length;i++) {\n            write(out, BLOCK_FP);\n            writeLong(out, leafBlockFPs[i]);\n            newline(out);\n          }\n\n          assert (splitPackedValues.length % (1 + fieldInfo.getDimensionNumBytes())) == 0;\n          int count = splitPackedValues.length / (1 + fieldInfo.getDimensionNumBytes());\n          assert count == leafBlockFPs.length;\n\n          write(out, SPLIT_COUNT);\n          writeInt(out, count);\n          newline(out);\n\n          for(int i=0;i<count;i++) {\n            write(out, SPLIT_DIM);\n            writeInt(out, splitPackedValues[i * (1 + fieldInfo.getDimensionNumBytes())] & 0xff);\n            newline(out);\n            write(out, SPLIT_VALUE);\n            br = new BytesRef(splitPackedValues, 1+(i * (1+fieldInfo.getDimensionNumBytes())), fieldInfo.getDimensionNumBytes());\n            write(out, br.toString());\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeLeafBlockDocs(IndexOutput out, int[] docIDs, int start, int count) throws IOException {\n          write(out, BLOCK_COUNT);\n          writeInt(out, count);\n          newline(out);\n          for(int i=0;i<count;i++) {\n            write(out, BLOCK_DOC_ID);\n            writeInt(out, docIDs[start+i]);\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeCommonPrefixes(IndexOutput out, int[] commonPrefixLengths, byte[] packedValue) {\n          // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n        }\n\n        @Override\n        protected void writeLeafBlockPackedValue(IndexOutput out, int[] commonPrefixLengths, byte[] bytes) throws IOException {\n          // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n          assert bytes.length == packedBytesLength;\n          write(out, BLOCK_VALUE);\n          write(out, new BytesRef(bytes, 0, bytes.length).toString());\n          newline(out);\n        }          \n      };\n\n    values.intersect(fieldInfo.name, new IntersectVisitor() {\n        @Override\n        public void visit(int docID) {\n          throw new IllegalStateException();\n        }\n\n        public void visit(int docID, byte[] packedValue) throws IOException {\n          writer.add(packedValue, docID);\n        }\n\n        @Override\n        public Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n          return Relation.CELL_CROSSES_QUERY;\n        }\n      });\n\n    // We could have 0 points on merge since all docs with dimensional fields may be deleted:\n    if (writer.getPointCount() > 0) {\n      indexFPs.put(fieldInfo.name, writer.finish(dataOut));\n    }\n  }\n\n","sourceOld":"  @Override\n  public void writeField(FieldInfo fieldInfo, DimensionalReader values) throws IOException {\n\n    // We use the normal BKDWriter, but subclass to customize how it writes the index and blocks to disk:\n    BKDWriter writer = new BKDWriter(writeState.directory,\n                                     writeState.segmentInfo.name,\n                                     fieldInfo.getDimensionCount(),\n                                     fieldInfo.getDimensionNumBytes(),\n                                     BKDWriter.DEFAULT_MAX_POINTS_IN_LEAF_NODE,\n                                     BKDWriter.DEFAULT_MAX_MB_SORT_IN_HEAP) {\n\n        @Override\n        protected void writeIndex(IndexOutput out, long[] leafBlockFPs, byte[] splitPackedValues) throws IOException {\n          write(out, NUM_DIMS);\n          writeInt(out, numDims);\n          newline(out);\n\n          write(out, BYTES_PER_DIM);\n          writeInt(out, bytesPerDim);\n          newline(out);\n\n          write(out, MAX_LEAF_POINTS);\n          writeInt(out, maxPointsInLeafNode);\n          newline(out);\n\n          write(out, INDEX_COUNT);\n          writeInt(out, leafBlockFPs.length);\n          newline(out);\n\n          for(int i=0;i<leafBlockFPs.length;i++) {\n            write(out, BLOCK_FP);\n            writeLong(out, leafBlockFPs[i]);\n            newline(out);\n          }\n\n          assert (splitPackedValues.length % (1 + fieldInfo.getDimensionNumBytes())) == 0;\n          int count = splitPackedValues.length / (1 + fieldInfo.getDimensionNumBytes());\n          assert count == leafBlockFPs.length;\n\n          write(out, SPLIT_COUNT);\n          writeInt(out, count);\n          newline(out);\n\n          for(int i=0;i<count;i++) {\n            write(out, SPLIT_DIM);\n            writeInt(out, splitPackedValues[i * (1 + fieldInfo.getDimensionNumBytes())] & 0xff);\n            newline(out);\n            write(out, SPLIT_VALUE);\n            BytesRef br = new BytesRef(splitPackedValues, 1+(i * (1+fieldInfo.getDimensionNumBytes())), fieldInfo.getDimensionNumBytes());\n            write(out, br.toString());\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeLeafBlockDocs(IndexOutput out, int[] docIDs, int start, int count) throws IOException {\n          write(out, BLOCK_COUNT);\n          writeInt(out, count);\n          newline(out);\n          for(int i=0;i<count;i++) {\n            write(out, BLOCK_DOC_ID);\n            writeInt(out, docIDs[start+i]);\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeCommonPrefixes(IndexOutput out, int[] commonPrefixLengths, byte[] packedValue) {\n          // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n        }\n\n        @Override\n        protected void writeLeafBlockPackedValue(IndexOutput out, int[] commonPrefixLengths, byte[] bytes) throws IOException {\n          // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n          assert bytes.length == packedBytesLength;\n          write(out, BLOCK_VALUE);\n          write(out, new BytesRef(bytes, 0, bytes.length).toString());\n          newline(out);\n        }          \n      };\n\n    values.intersect(fieldInfo.name, new IntersectVisitor() {\n        @Override\n        public void visit(int docID) {\n          throw new IllegalStateException();\n        }\n\n        public void visit(int docID, byte[] packedValue) throws IOException {\n          writer.add(packedValue, docID);\n        }\n\n        @Override\n        public Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n          return Relation.CELL_CROSSES_QUERY;\n        }\n      });\n\n    // We could have 0 points on merge since all docs with dimensional fields may be deleted:\n    if (writer.getPointCount() > 0) {\n      indexFPs.put(fieldInfo.name, writer.finish(dataOut));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ada1b4034d1ebb880ab99cc1dd16fdb7be511f4d","date":1452262416,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextDimensionalWriter#writeField(FieldInfo,DimensionalReader).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextDimensionalWriter#writeField(FieldInfo,DimensionalReader).mjava","sourceNew":"  @Override\n  public void writeField(FieldInfo fieldInfo, DimensionalReader values) throws IOException {\n\n    // We use the normal BKDWriter, but subclass to customize how it writes the index and blocks to disk:\n    BKDWriter writer = new BKDWriter(writeState.directory,\n                                     writeState.segmentInfo.name,\n                                     fieldInfo.getDimensionCount(),\n                                     fieldInfo.getDimensionNumBytes(),\n                                     BKDWriter.DEFAULT_MAX_POINTS_IN_LEAF_NODE,\n                                     BKDWriter.DEFAULT_MAX_MB_SORT_IN_HEAP) {\n\n        @Override\n        protected void writeIndex(IndexOutput out, long[] leafBlockFPs, byte[] splitPackedValues) throws IOException {\n          write(out, NUM_DIMS);\n          writeInt(out, numDims);\n          newline(out);\n\n          write(out, BYTES_PER_DIM);\n          writeInt(out, bytesPerDim);\n          newline(out);\n\n          write(out, MAX_LEAF_POINTS);\n          writeInt(out, maxPointsInLeafNode);\n          newline(out);\n\n          write(out, INDEX_COUNT);\n          writeInt(out, leafBlockFPs.length);\n          newline(out);\n\n          write(out, MIN_VALUE);\n          BytesRef br = new BytesRef(minPackedValue, 0, minPackedValue.length);\n          write(out, br.toString());\n          newline(out);\n\n          write(out, MAX_VALUE);\n          br = new BytesRef(maxPackedValue, 0, maxPackedValue.length);\n          write(out, br.toString());\n          newline(out);\n\n          for(int i=0;i<leafBlockFPs.length;i++) {\n            write(out, BLOCK_FP);\n            writeLong(out, leafBlockFPs[i]);\n            newline(out);\n          }\n\n          assert (splitPackedValues.length % (1 + fieldInfo.getDimensionNumBytes())) == 0;\n          int count = splitPackedValues.length / (1 + fieldInfo.getDimensionNumBytes());\n          assert count == leafBlockFPs.length;\n\n          write(out, SPLIT_COUNT);\n          writeInt(out, count);\n          newline(out);\n\n          for(int i=0;i<count;i++) {\n            write(out, SPLIT_DIM);\n            writeInt(out, splitPackedValues[i * (1 + fieldInfo.getDimensionNumBytes())] & 0xff);\n            newline(out);\n            write(out, SPLIT_VALUE);\n            br = new BytesRef(splitPackedValues, 1+(i * (1+fieldInfo.getDimensionNumBytes())), fieldInfo.getDimensionNumBytes());\n            write(out, br.toString());\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeLeafBlockDocs(IndexOutput out, int[] docIDs, int start, int count) throws IOException {\n          write(out, BLOCK_COUNT);\n          writeInt(out, count);\n          newline(out);\n          for(int i=0;i<count;i++) {\n            write(out, BLOCK_DOC_ID);\n            writeInt(out, docIDs[start+i]);\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeCommonPrefixes(IndexOutput out, int[] commonPrefixLengths, byte[] packedValue) {\n          // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n        }\n\n        @Override\n        protected void writeLeafBlockPackedValue(IndexOutput out, int[] commonPrefixLengths, byte[] bytes) throws IOException {\n          // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n          assert bytes.length == packedBytesLength;\n          write(out, BLOCK_VALUE);\n          write(out, new BytesRef(bytes, 0, bytes.length).toString());\n          newline(out);\n        }          \n      };\n\n    values.intersect(fieldInfo.name, new IntersectVisitor() {\n        @Override\n        public void visit(int docID) {\n          throw new IllegalStateException();\n        }\n\n        public void visit(int docID, byte[] packedValue) throws IOException {\n          writer.add(packedValue, docID);\n        }\n\n        @Override\n        public Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n          return Relation.CELL_CROSSES_QUERY;\n        }\n      });\n\n    // We could have 0 points on merge since all docs with dimensional fields may be deleted:\n    if (writer.getPointCount() > 0) {\n      indexFPs.put(fieldInfo.name, writer.finish(dataOut));\n    }\n  }\n\n","sourceOld":"  @Override\n  public void writeField(FieldInfo fieldInfo, DimensionalReader values) throws IOException {\n\n    // We use the normal BKDWriter, but subclass to customize how it writes the index and blocks to disk:\n    BKDWriter writer = new BKDWriter(writeState.directory,\n                                     writeState.segmentInfo.name,\n                                     fieldInfo.getDimensionCount(),\n                                     fieldInfo.getDimensionNumBytes(),\n                                     BKDWriter.DEFAULT_MAX_POINTS_IN_LEAF_NODE,\n                                     BKDWriter.DEFAULT_MAX_MB_SORT_IN_HEAP) {\n\n        @Override\n        protected void writeIndex(IndexOutput out, long[] leafBlockFPs, byte[] splitPackedValues) throws IOException {\n          write(out, NUM_DIMS);\n          writeInt(out, numDims);\n          newline(out);\n\n          write(out, BYTES_PER_DIM);\n          writeInt(out, bytesPerDim);\n          newline(out);\n\n          write(out, MAX_LEAF_POINTS);\n          writeInt(out, maxPointsInLeafNode);\n          newline(out);\n\n          write(out, INDEX_COUNT);\n          writeInt(out, leafBlockFPs.length);\n          newline(out);\n\n          write(out, MIN_VALUE);\n          BytesRef br = new BytesRef(minPackedValue, 0, minPackedValue.length);\n          write(out, br.toString());\n\n          write(out, MAX_VALUE);\n          br = new BytesRef(maxPackedValue, 0, maxPackedValue.length);\n          write(out, br.toString());\n\n          for(int i=0;i<leafBlockFPs.length;i++) {\n            write(out, BLOCK_FP);\n            writeLong(out, leafBlockFPs[i]);\n            newline(out);\n          }\n\n          assert (splitPackedValues.length % (1 + fieldInfo.getDimensionNumBytes())) == 0;\n          int count = splitPackedValues.length / (1 + fieldInfo.getDimensionNumBytes());\n          assert count == leafBlockFPs.length;\n\n          write(out, SPLIT_COUNT);\n          writeInt(out, count);\n          newline(out);\n\n          for(int i=0;i<count;i++) {\n            write(out, SPLIT_DIM);\n            writeInt(out, splitPackedValues[i * (1 + fieldInfo.getDimensionNumBytes())] & 0xff);\n            newline(out);\n            write(out, SPLIT_VALUE);\n            br = new BytesRef(splitPackedValues, 1+(i * (1+fieldInfo.getDimensionNumBytes())), fieldInfo.getDimensionNumBytes());\n            write(out, br.toString());\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeLeafBlockDocs(IndexOutput out, int[] docIDs, int start, int count) throws IOException {\n          write(out, BLOCK_COUNT);\n          writeInt(out, count);\n          newline(out);\n          for(int i=0;i<count;i++) {\n            write(out, BLOCK_DOC_ID);\n            writeInt(out, docIDs[start+i]);\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeCommonPrefixes(IndexOutput out, int[] commonPrefixLengths, byte[] packedValue) {\n          // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n        }\n\n        @Override\n        protected void writeLeafBlockPackedValue(IndexOutput out, int[] commonPrefixLengths, byte[] bytes) throws IOException {\n          // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n          assert bytes.length == packedBytesLength;\n          write(out, BLOCK_VALUE);\n          write(out, new BytesRef(bytes, 0, bytes.length).toString());\n          newline(out);\n        }          \n      };\n\n    values.intersect(fieldInfo.name, new IntersectVisitor() {\n        @Override\n        public void visit(int docID) {\n          throw new IllegalStateException();\n        }\n\n        public void visit(int docID, byte[] packedValue) throws IOException {\n          writer.add(packedValue, docID);\n        }\n\n        @Override\n        public Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n          return Relation.CELL_CROSSES_QUERY;\n        }\n      });\n\n    // We could have 0 points on merge since all docs with dimensional fields may be deleted:\n    if (writer.getPointCount() > 0) {\n      indexFPs.put(fieldInfo.name, writer.finish(dataOut));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"cab7a79353f33d1a94cd307bf33aa5148601ebe6","date":1453391888,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextPointWriter#writeField(FieldInfo,PointReader).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextDimensionalWriter#writeField(FieldInfo,DimensionalReader).mjava","sourceNew":"  @Override\n  public void writeField(FieldInfo fieldInfo, PointReader values) throws IOException {\n\n    // We use the normal BKDWriter, but subclass to customize how it writes the index and blocks to disk:\n    BKDWriter writer = new BKDWriter(writeState.directory,\n                                     writeState.segmentInfo.name,\n                                     fieldInfo.getPointDimensionCount(),\n                                     fieldInfo.getPointNumBytes(),\n                                     BKDWriter.DEFAULT_MAX_POINTS_IN_LEAF_NODE,\n                                     BKDWriter.DEFAULT_MAX_MB_SORT_IN_HEAP) {\n\n        @Override\n        protected void writeIndex(IndexOutput out, long[] leafBlockFPs, byte[] splitPackedValues) throws IOException {\n          write(out, NUM_DIMS);\n          writeInt(out, numDims);\n          newline(out);\n\n          write(out, BYTES_PER_DIM);\n          writeInt(out, bytesPerDim);\n          newline(out);\n\n          write(out, MAX_LEAF_POINTS);\n          writeInt(out, maxPointsInLeafNode);\n          newline(out);\n\n          write(out, INDEX_COUNT);\n          writeInt(out, leafBlockFPs.length);\n          newline(out);\n\n          write(out, MIN_VALUE);\n          BytesRef br = new BytesRef(minPackedValue, 0, minPackedValue.length);\n          write(out, br.toString());\n          newline(out);\n\n          write(out, MAX_VALUE);\n          br = new BytesRef(maxPackedValue, 0, maxPackedValue.length);\n          write(out, br.toString());\n          newline(out);\n\n          for(int i=0;i<leafBlockFPs.length;i++) {\n            write(out, BLOCK_FP);\n            writeLong(out, leafBlockFPs[i]);\n            newline(out);\n          }\n\n          assert (splitPackedValues.length % (1 + fieldInfo.getPointNumBytes())) == 0;\n          int count = splitPackedValues.length / (1 + fieldInfo.getPointNumBytes());\n          assert count == leafBlockFPs.length;\n\n          write(out, SPLIT_COUNT);\n          writeInt(out, count);\n          newline(out);\n\n          for(int i=0;i<count;i++) {\n            write(out, SPLIT_DIM);\n            writeInt(out, splitPackedValues[i * (1 + fieldInfo.getPointNumBytes())] & 0xff);\n            newline(out);\n            write(out, SPLIT_VALUE);\n            br = new BytesRef(splitPackedValues, 1+(i * (1+fieldInfo.getPointNumBytes())), fieldInfo.getPointNumBytes());\n            write(out, br.toString());\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeLeafBlockDocs(IndexOutput out, int[] docIDs, int start, int count) throws IOException {\n          write(out, BLOCK_COUNT);\n          writeInt(out, count);\n          newline(out);\n          for(int i=0;i<count;i++) {\n            write(out, BLOCK_DOC_ID);\n            writeInt(out, docIDs[start+i]);\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeCommonPrefixes(IndexOutput out, int[] commonPrefixLengths, byte[] packedValue) {\n          // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n        }\n\n        @Override\n        protected void writeLeafBlockPackedValue(IndexOutput out, int[] commonPrefixLengths, byte[] bytes) throws IOException {\n          // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n          assert bytes.length == packedBytesLength;\n          write(out, BLOCK_VALUE);\n          write(out, new BytesRef(bytes, 0, bytes.length).toString());\n          newline(out);\n        }          \n      };\n\n    values.intersect(fieldInfo.name, new IntersectVisitor() {\n        @Override\n        public void visit(int docID) {\n          throw new IllegalStateException();\n        }\n\n        public void visit(int docID, byte[] packedValue) throws IOException {\n          writer.add(packedValue, docID);\n        }\n\n        @Override\n        public Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n          return Relation.CELL_CROSSES_QUERY;\n        }\n      });\n\n    // We could have 0 points on merge since all docs with points may be deleted:\n    if (writer.getPointCount() > 0) {\n      indexFPs.put(fieldInfo.name, writer.finish(dataOut));\n    }\n  }\n\n","sourceOld":"  @Override\n  public void writeField(FieldInfo fieldInfo, DimensionalReader values) throws IOException {\n\n    // We use the normal BKDWriter, but subclass to customize how it writes the index and blocks to disk:\n    BKDWriter writer = new BKDWriter(writeState.directory,\n                                     writeState.segmentInfo.name,\n                                     fieldInfo.getDimensionCount(),\n                                     fieldInfo.getDimensionNumBytes(),\n                                     BKDWriter.DEFAULT_MAX_POINTS_IN_LEAF_NODE,\n                                     BKDWriter.DEFAULT_MAX_MB_SORT_IN_HEAP) {\n\n        @Override\n        protected void writeIndex(IndexOutput out, long[] leafBlockFPs, byte[] splitPackedValues) throws IOException {\n          write(out, NUM_DIMS);\n          writeInt(out, numDims);\n          newline(out);\n\n          write(out, BYTES_PER_DIM);\n          writeInt(out, bytesPerDim);\n          newline(out);\n\n          write(out, MAX_LEAF_POINTS);\n          writeInt(out, maxPointsInLeafNode);\n          newline(out);\n\n          write(out, INDEX_COUNT);\n          writeInt(out, leafBlockFPs.length);\n          newline(out);\n\n          write(out, MIN_VALUE);\n          BytesRef br = new BytesRef(minPackedValue, 0, minPackedValue.length);\n          write(out, br.toString());\n          newline(out);\n\n          write(out, MAX_VALUE);\n          br = new BytesRef(maxPackedValue, 0, maxPackedValue.length);\n          write(out, br.toString());\n          newline(out);\n\n          for(int i=0;i<leafBlockFPs.length;i++) {\n            write(out, BLOCK_FP);\n            writeLong(out, leafBlockFPs[i]);\n            newline(out);\n          }\n\n          assert (splitPackedValues.length % (1 + fieldInfo.getDimensionNumBytes())) == 0;\n          int count = splitPackedValues.length / (1 + fieldInfo.getDimensionNumBytes());\n          assert count == leafBlockFPs.length;\n\n          write(out, SPLIT_COUNT);\n          writeInt(out, count);\n          newline(out);\n\n          for(int i=0;i<count;i++) {\n            write(out, SPLIT_DIM);\n            writeInt(out, splitPackedValues[i * (1 + fieldInfo.getDimensionNumBytes())] & 0xff);\n            newline(out);\n            write(out, SPLIT_VALUE);\n            br = new BytesRef(splitPackedValues, 1+(i * (1+fieldInfo.getDimensionNumBytes())), fieldInfo.getDimensionNumBytes());\n            write(out, br.toString());\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeLeafBlockDocs(IndexOutput out, int[] docIDs, int start, int count) throws IOException {\n          write(out, BLOCK_COUNT);\n          writeInt(out, count);\n          newline(out);\n          for(int i=0;i<count;i++) {\n            write(out, BLOCK_DOC_ID);\n            writeInt(out, docIDs[start+i]);\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeCommonPrefixes(IndexOutput out, int[] commonPrefixLengths, byte[] packedValue) {\n          // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n        }\n\n        @Override\n        protected void writeLeafBlockPackedValue(IndexOutput out, int[] commonPrefixLengths, byte[] bytes) throws IOException {\n          // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n          assert bytes.length == packedBytesLength;\n          write(out, BLOCK_VALUE);\n          write(out, new BytesRef(bytes, 0, bytes.length).toString());\n          newline(out);\n        }          \n      };\n\n    values.intersect(fieldInfo.name, new IntersectVisitor() {\n        @Override\n        public void visit(int docID) {\n          throw new IllegalStateException();\n        }\n\n        public void visit(int docID, byte[] packedValue) throws IOException {\n          writer.add(packedValue, docID);\n        }\n\n        @Override\n        public Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n          return Relation.CELL_CROSSES_QUERY;\n        }\n      });\n\n    // We could have 0 points on merge since all docs with dimensional fields may be deleted:\n    if (writer.getPointCount() > 0) {\n      indexFPs.put(fieldInfo.name, writer.finish(dataOut));\n    }\n  }\n\n","bugFix":null,"bugIntro":["d2d93e80a51ae7994e1639fbd83763acdef9beb1"],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"cab7a79353f33d1a94cd307bf33aa5148601ebe6":["ada1b4034d1ebb880ab99cc1dd16fdb7be511f4d"],"ecf331f9d7bdd234863d2df2bb5c1f019979422f":["d0c44765ee347f8c49bc6c0ffe1cdfb42738bd6a"],"b9f70b31079ec002469ee49df3b8f9bd8d10df23":["1904709ea0185dc04e3d77ea01c79e909caf2796"],"ada1b4034d1ebb880ab99cc1dd16fdb7be511f4d":["ecf331f9d7bdd234863d2df2bb5c1f019979422f"],"ca792c26af46bd6c4a08d81117c60440cf6a7e3d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"1904709ea0185dc04e3d77ea01c79e909caf2796":["ca792c26af46bd6c4a08d81117c60440cf6a7e3d"],"d0c44765ee347f8c49bc6c0ffe1cdfb42738bd6a":["b9f70b31079ec002469ee49df3b8f9bd8d10df23"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["cab7a79353f33d1a94cd307bf33aa5148601ebe6"]},"commit2Childs":{"cab7a79353f33d1a94cd307bf33aa5148601ebe6":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"ecf331f9d7bdd234863d2df2bb5c1f019979422f":["ada1b4034d1ebb880ab99cc1dd16fdb7be511f4d"],"b9f70b31079ec002469ee49df3b8f9bd8d10df23":["d0c44765ee347f8c49bc6c0ffe1cdfb42738bd6a"],"ada1b4034d1ebb880ab99cc1dd16fdb7be511f4d":["cab7a79353f33d1a94cd307bf33aa5148601ebe6"],"ca792c26af46bd6c4a08d81117c60440cf6a7e3d":["1904709ea0185dc04e3d77ea01c79e909caf2796"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["ca792c26af46bd6c4a08d81117c60440cf6a7e3d"],"1904709ea0185dc04e3d77ea01c79e909caf2796":["b9f70b31079ec002469ee49df3b8f9bd8d10df23"],"d0c44765ee347f8c49bc6c0ffe1cdfb42738bd6a":["ecf331f9d7bdd234863d2df2bb5c1f019979422f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}