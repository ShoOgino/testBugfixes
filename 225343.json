{"path":"lucene/facet/src/test/org/apache/lucene/facet/TestRandomSamplingFacetsCollector#testRandomSampling().mjava","commits":[{"id":"2428b3de33c400750a32591679fd9ee6d6d706dc","date":1395315031,"type":0,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/TestRandomSamplingFacetsCollector#testRandomSampling().mjava","pathOld":"/dev/null","sourceNew":"  public void testRandomSampling() throws Exception {\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    \n    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir);\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    \n    FacetsConfig config = new FacetsConfig();\n    \n    int numDocs = atLeast(10000);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      doc.add(new StringField(\"EvenOdd\", (i % 2 == 0) ? \"even\" : \"odd\", Store.NO));\n      doc.add(new FacetField(\"iMod10\", String.valueOf(i % 10)));\n      writer.addDocument(config.build(taxoWriter, doc));\n    }\n    Random random = random();\n    \n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    IOUtils.close(writer, taxoWriter);\n    \n    // Test empty results\n    RandomSamplingFacetsCollector collectRandomZeroResults = new RandomSamplingFacetsCollector(numDocs / 10, random.nextLong());\n    \n    // There should be no divisions by zero\n    searcher.search(new TermQuery(new Term(\"EvenOdd\", \"NeverMatches\")), collectRandomZeroResults);\n    \n    // There should be no divisions by zero and no null result\n    assertNotNull(collectRandomZeroResults.getMatchingDocs());\n    \n    // There should be no results at all\n    for (MatchingDocs doc : collectRandomZeroResults.getMatchingDocs()) {\n      assertEquals(0, doc.totalHits);\n    }\n    \n    // Now start searching and retrieve results.\n    \n    // Use a query to select half of the documents.\n    TermQuery query = new TermQuery(new Term(\"EvenOdd\", \"even\"));\n    \n    // there will be 5 facet values (0, 2, 4, 6 and 8), as only the even (i %\n    // 10) are hits.\n    // there is a REAL small chance that one of the 5 values will be missed when\n    // sampling.\n    // but is that 0.8 (chance not to take a value) ^ 2000 * 5 (any can be\n    // missing) ~ 10^-193\n    // so that is probably not going to happen.\n    int maxNumChildren = 5;\n    \n    RandomSamplingFacetsCollector random100Percent = new RandomSamplingFacetsCollector(numDocs, random.nextLong()); // no sampling\n    RandomSamplingFacetsCollector random10Percent = new RandomSamplingFacetsCollector(numDocs / 10, random.nextLong()); // 10 % of total docs, 20% of the hits\n\n    FacetsCollector fc = new FacetsCollector();\n    \n    searcher.search(query, MultiCollector.wrap(fc, random100Percent, random10Percent));\n    \n    FastTaxonomyFacetCounts random10FacetCounts = new FastTaxonomyFacetCounts(taxoReader, config, random10Percent);\n    FastTaxonomyFacetCounts random100FacetCounts = new FastTaxonomyFacetCounts(taxoReader, config, random100Percent);\n    FastTaxonomyFacetCounts exactFacetCounts = new FastTaxonomyFacetCounts(taxoReader, config, fc);\n    \n    FacetResult random10Result = random10Percent.amortizeFacetCounts(random10FacetCounts.getTopChildren(10, \"iMod10\"), config, searcher);\n    FacetResult random100Result = random100FacetCounts.getTopChildren(10, \"iMod10\");\n    FacetResult exactResult = exactFacetCounts.getTopChildren(10, \"iMod10\");\n    \n    assertEquals(random100Result, exactResult);\n    \n    // we should have five children, but there is a small chance we have less.\n    // (see above).\n    assertTrue(random10Result.childCount <= maxNumChildren);\n    // there should be one child at least.\n    assertTrue(random10Result.childCount >= 1);\n    \n    // now calculate some statistics to determine if the sampled result is 'ok'.\n    // because random sampling is used, the results will vary each time.\n    int sum = 0;\n    for (LabelAndValue lav : random10Result.labelValues) {\n      sum += lav.value.intValue();\n    }\n    float mu = (float) sum / (float) maxNumChildren;\n    \n    float variance = 0;\n    for (LabelAndValue lav : random10Result.labelValues) {\n      variance += Math.pow((mu - lav.value.intValue()), 2);\n    }\n    variance = variance / maxNumChildren;\n    float sigma = (float) Math.sqrt(variance);\n    \n    // we query only half the documents and have 5 categories. The average\n    // number of docs in a category will thus be the total divided by 5*2\n    float targetMu = numDocs / (5.0f * 2.0f);\n    \n    // the average should be in the range and the standard deviation should not\n    // be too great\n    assertTrue(sigma < 200);\n    assertTrue(targetMu - 3 * sigma < mu && mu < targetMu + 3 * sigma);\n    \n    IOUtils.close(searcher.getIndexReader(), taxoReader, dir, taxoDir);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/TestRandomSamplingFacetsCollector#testRandomSampling().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/TestRandomSamplingFacetsCollector#testRandomSampling().mjava","sourceNew":"  public void testRandomSampling() throws Exception {\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    \n    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir);\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    \n    FacetsConfig config = new FacetsConfig();\n    \n    int numDocs = atLeast(10000);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      doc.add(new StringField(\"EvenOdd\", (i % 2 == 0) ? \"even\" : \"odd\", Store.NO));\n      doc.add(new FacetField(\"iMod10\", String.valueOf(i % 10)));\n      writer.addDocument(config.build(taxoWriter, doc));\n    }\n    Random random = random();\n    \n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    writer.shutdown();\n    IOUtils.close(taxoWriter);\n    \n    // Test empty results\n    RandomSamplingFacetsCollector collectRandomZeroResults = new RandomSamplingFacetsCollector(numDocs / 10, random.nextLong());\n    \n    // There should be no divisions by zero\n    searcher.search(new TermQuery(new Term(\"EvenOdd\", \"NeverMatches\")), collectRandomZeroResults);\n    \n    // There should be no divisions by zero and no null result\n    assertNotNull(collectRandomZeroResults.getMatchingDocs());\n    \n    // There should be no results at all\n    for (MatchingDocs doc : collectRandomZeroResults.getMatchingDocs()) {\n      assertEquals(0, doc.totalHits);\n    }\n    \n    // Now start searching and retrieve results.\n    \n    // Use a query to select half of the documents.\n    TermQuery query = new TermQuery(new Term(\"EvenOdd\", \"even\"));\n    \n    // there will be 5 facet values (0, 2, 4, 6 and 8), as only the even (i %\n    // 10) are hits.\n    // there is a REAL small chance that one of the 5 values will be missed when\n    // sampling.\n    // but is that 0.8 (chance not to take a value) ^ 2000 * 5 (any can be\n    // missing) ~ 10^-193\n    // so that is probably not going to happen.\n    int maxNumChildren = 5;\n    \n    RandomSamplingFacetsCollector random100Percent = new RandomSamplingFacetsCollector(numDocs, random.nextLong()); // no sampling\n    RandomSamplingFacetsCollector random10Percent = new RandomSamplingFacetsCollector(numDocs / 10, random.nextLong()); // 10 % of total docs, 20% of the hits\n\n    FacetsCollector fc = new FacetsCollector();\n    \n    searcher.search(query, MultiCollector.wrap(fc, random100Percent, random10Percent));\n    \n    FastTaxonomyFacetCounts random10FacetCounts = new FastTaxonomyFacetCounts(taxoReader, config, random10Percent);\n    FastTaxonomyFacetCounts random100FacetCounts = new FastTaxonomyFacetCounts(taxoReader, config, random100Percent);\n    FastTaxonomyFacetCounts exactFacetCounts = new FastTaxonomyFacetCounts(taxoReader, config, fc);\n    \n    FacetResult random10Result = random10Percent.amortizeFacetCounts(random10FacetCounts.getTopChildren(10, \"iMod10\"), config, searcher);\n    FacetResult random100Result = random100FacetCounts.getTopChildren(10, \"iMod10\");\n    FacetResult exactResult = exactFacetCounts.getTopChildren(10, \"iMod10\");\n    \n    assertEquals(random100Result, exactResult);\n    \n    // we should have five children, but there is a small chance we have less.\n    // (see above).\n    assertTrue(random10Result.childCount <= maxNumChildren);\n    // there should be one child at least.\n    assertTrue(random10Result.childCount >= 1);\n    \n    // now calculate some statistics to determine if the sampled result is 'ok'.\n    // because random sampling is used, the results will vary each time.\n    int sum = 0;\n    for (LabelAndValue lav : random10Result.labelValues) {\n      sum += lav.value.intValue();\n    }\n    float mu = (float) sum / (float) maxNumChildren;\n    \n    float variance = 0;\n    for (LabelAndValue lav : random10Result.labelValues) {\n      variance += Math.pow((mu - lav.value.intValue()), 2);\n    }\n    variance = variance / maxNumChildren;\n    float sigma = (float) Math.sqrt(variance);\n    \n    // we query only half the documents and have 5 categories. The average\n    // number of docs in a category will thus be the total divided by 5*2\n    float targetMu = numDocs / (5.0f * 2.0f);\n    \n    // the average should be in the range and the standard deviation should not\n    // be too great\n    assertTrue(sigma < 200);\n    assertTrue(targetMu - 3 * sigma < mu && mu < targetMu + 3 * sigma);\n    \n    IOUtils.close(searcher.getIndexReader(), taxoReader, dir, taxoDir);\n  }\n\n","sourceOld":"  public void testRandomSampling() throws Exception {\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    \n    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir);\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    \n    FacetsConfig config = new FacetsConfig();\n    \n    int numDocs = atLeast(10000);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      doc.add(new StringField(\"EvenOdd\", (i % 2 == 0) ? \"even\" : \"odd\", Store.NO));\n      doc.add(new FacetField(\"iMod10\", String.valueOf(i % 10)));\n      writer.addDocument(config.build(taxoWriter, doc));\n    }\n    Random random = random();\n    \n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    IOUtils.close(writer, taxoWriter);\n    \n    // Test empty results\n    RandomSamplingFacetsCollector collectRandomZeroResults = new RandomSamplingFacetsCollector(numDocs / 10, random.nextLong());\n    \n    // There should be no divisions by zero\n    searcher.search(new TermQuery(new Term(\"EvenOdd\", \"NeverMatches\")), collectRandomZeroResults);\n    \n    // There should be no divisions by zero and no null result\n    assertNotNull(collectRandomZeroResults.getMatchingDocs());\n    \n    // There should be no results at all\n    for (MatchingDocs doc : collectRandomZeroResults.getMatchingDocs()) {\n      assertEquals(0, doc.totalHits);\n    }\n    \n    // Now start searching and retrieve results.\n    \n    // Use a query to select half of the documents.\n    TermQuery query = new TermQuery(new Term(\"EvenOdd\", \"even\"));\n    \n    // there will be 5 facet values (0, 2, 4, 6 and 8), as only the even (i %\n    // 10) are hits.\n    // there is a REAL small chance that one of the 5 values will be missed when\n    // sampling.\n    // but is that 0.8 (chance not to take a value) ^ 2000 * 5 (any can be\n    // missing) ~ 10^-193\n    // so that is probably not going to happen.\n    int maxNumChildren = 5;\n    \n    RandomSamplingFacetsCollector random100Percent = new RandomSamplingFacetsCollector(numDocs, random.nextLong()); // no sampling\n    RandomSamplingFacetsCollector random10Percent = new RandomSamplingFacetsCollector(numDocs / 10, random.nextLong()); // 10 % of total docs, 20% of the hits\n\n    FacetsCollector fc = new FacetsCollector();\n    \n    searcher.search(query, MultiCollector.wrap(fc, random100Percent, random10Percent));\n    \n    FastTaxonomyFacetCounts random10FacetCounts = new FastTaxonomyFacetCounts(taxoReader, config, random10Percent);\n    FastTaxonomyFacetCounts random100FacetCounts = new FastTaxonomyFacetCounts(taxoReader, config, random100Percent);\n    FastTaxonomyFacetCounts exactFacetCounts = new FastTaxonomyFacetCounts(taxoReader, config, fc);\n    \n    FacetResult random10Result = random10Percent.amortizeFacetCounts(random10FacetCounts.getTopChildren(10, \"iMod10\"), config, searcher);\n    FacetResult random100Result = random100FacetCounts.getTopChildren(10, \"iMod10\");\n    FacetResult exactResult = exactFacetCounts.getTopChildren(10, \"iMod10\");\n    \n    assertEquals(random100Result, exactResult);\n    \n    // we should have five children, but there is a small chance we have less.\n    // (see above).\n    assertTrue(random10Result.childCount <= maxNumChildren);\n    // there should be one child at least.\n    assertTrue(random10Result.childCount >= 1);\n    \n    // now calculate some statistics to determine if the sampled result is 'ok'.\n    // because random sampling is used, the results will vary each time.\n    int sum = 0;\n    for (LabelAndValue lav : random10Result.labelValues) {\n      sum += lav.value.intValue();\n    }\n    float mu = (float) sum / (float) maxNumChildren;\n    \n    float variance = 0;\n    for (LabelAndValue lav : random10Result.labelValues) {\n      variance += Math.pow((mu - lav.value.intValue()), 2);\n    }\n    variance = variance / maxNumChildren;\n    float sigma = (float) Math.sqrt(variance);\n    \n    // we query only half the documents and have 5 categories. The average\n    // number of docs in a category will thus be the total divided by 5*2\n    float targetMu = numDocs / (5.0f * 2.0f);\n    \n    // the average should be in the range and the standard deviation should not\n    // be too great\n    assertTrue(sigma < 200);\n    assertTrue(targetMu - 3 * sigma < mu && mu < targetMu + 3 * sigma);\n    \n    IOUtils.close(searcher.getIndexReader(), taxoReader, dir, taxoDir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/TestRandomSamplingFacetsCollector#testRandomSampling().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/TestRandomSamplingFacetsCollector#testRandomSampling().mjava","sourceNew":"  public void testRandomSampling() throws Exception {\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    \n    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir);\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    \n    FacetsConfig config = new FacetsConfig();\n    \n    int numDocs = atLeast(10000);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      doc.add(new StringField(\"EvenOdd\", (i % 2 == 0) ? \"even\" : \"odd\", Store.NO));\n      doc.add(new FacetField(\"iMod10\", String.valueOf(i % 10)));\n      writer.addDocument(config.build(taxoWriter, doc));\n    }\n    Random random = random();\n    \n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    writer.close();\n    IOUtils.close(taxoWriter);\n    \n    // Test empty results\n    RandomSamplingFacetsCollector collectRandomZeroResults = new RandomSamplingFacetsCollector(numDocs / 10, random.nextLong());\n    \n    // There should be no divisions by zero\n    searcher.search(new TermQuery(new Term(\"EvenOdd\", \"NeverMatches\")), collectRandomZeroResults);\n    \n    // There should be no divisions by zero and no null result\n    assertNotNull(collectRandomZeroResults.getMatchingDocs());\n    \n    // There should be no results at all\n    for (MatchingDocs doc : collectRandomZeroResults.getMatchingDocs()) {\n      assertEquals(0, doc.totalHits);\n    }\n    \n    // Now start searching and retrieve results.\n    \n    // Use a query to select half of the documents.\n    TermQuery query = new TermQuery(new Term(\"EvenOdd\", \"even\"));\n    \n    // there will be 5 facet values (0, 2, 4, 6 and 8), as only the even (i %\n    // 10) are hits.\n    // there is a REAL small chance that one of the 5 values will be missed when\n    // sampling.\n    // but is that 0.8 (chance not to take a value) ^ 2000 * 5 (any can be\n    // missing) ~ 10^-193\n    // so that is probably not going to happen.\n    int maxNumChildren = 5;\n    \n    RandomSamplingFacetsCollector random100Percent = new RandomSamplingFacetsCollector(numDocs, random.nextLong()); // no sampling\n    RandomSamplingFacetsCollector random10Percent = new RandomSamplingFacetsCollector(numDocs / 10, random.nextLong()); // 10 % of total docs, 20% of the hits\n\n    FacetsCollector fc = new FacetsCollector();\n    \n    searcher.search(query, MultiCollector.wrap(fc, random100Percent, random10Percent));\n    \n    FastTaxonomyFacetCounts random10FacetCounts = new FastTaxonomyFacetCounts(taxoReader, config, random10Percent);\n    FastTaxonomyFacetCounts random100FacetCounts = new FastTaxonomyFacetCounts(taxoReader, config, random100Percent);\n    FastTaxonomyFacetCounts exactFacetCounts = new FastTaxonomyFacetCounts(taxoReader, config, fc);\n    \n    FacetResult random10Result = random10Percent.amortizeFacetCounts(random10FacetCounts.getTopChildren(10, \"iMod10\"), config, searcher);\n    FacetResult random100Result = random100FacetCounts.getTopChildren(10, \"iMod10\");\n    FacetResult exactResult = exactFacetCounts.getTopChildren(10, \"iMod10\");\n    \n    assertEquals(random100Result, exactResult);\n    \n    // we should have five children, but there is a small chance we have less.\n    // (see above).\n    assertTrue(random10Result.childCount <= maxNumChildren);\n    // there should be one child at least.\n    assertTrue(random10Result.childCount >= 1);\n    \n    // now calculate some statistics to determine if the sampled result is 'ok'.\n    // because random sampling is used, the results will vary each time.\n    int sum = 0;\n    for (LabelAndValue lav : random10Result.labelValues) {\n      sum += lav.value.intValue();\n    }\n    float mu = (float) sum / (float) maxNumChildren;\n    \n    float variance = 0;\n    for (LabelAndValue lav : random10Result.labelValues) {\n      variance += Math.pow((mu - lav.value.intValue()), 2);\n    }\n    variance = variance / maxNumChildren;\n    float sigma = (float) Math.sqrt(variance);\n    \n    // we query only half the documents and have 5 categories. The average\n    // number of docs in a category will thus be the total divided by 5*2\n    float targetMu = numDocs / (5.0f * 2.0f);\n    \n    // the average should be in the range and the standard deviation should not\n    // be too great\n    assertTrue(sigma < 200);\n    assertTrue(targetMu - 3 * sigma < mu && mu < targetMu + 3 * sigma);\n    \n    IOUtils.close(searcher.getIndexReader(), taxoReader, dir, taxoDir);\n  }\n\n","sourceOld":"  public void testRandomSampling() throws Exception {\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    \n    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir);\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    \n    FacetsConfig config = new FacetsConfig();\n    \n    int numDocs = atLeast(10000);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      doc.add(new StringField(\"EvenOdd\", (i % 2 == 0) ? \"even\" : \"odd\", Store.NO));\n      doc.add(new FacetField(\"iMod10\", String.valueOf(i % 10)));\n      writer.addDocument(config.build(taxoWriter, doc));\n    }\n    Random random = random();\n    \n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    writer.shutdown();\n    IOUtils.close(taxoWriter);\n    \n    // Test empty results\n    RandomSamplingFacetsCollector collectRandomZeroResults = new RandomSamplingFacetsCollector(numDocs / 10, random.nextLong());\n    \n    // There should be no divisions by zero\n    searcher.search(new TermQuery(new Term(\"EvenOdd\", \"NeverMatches\")), collectRandomZeroResults);\n    \n    // There should be no divisions by zero and no null result\n    assertNotNull(collectRandomZeroResults.getMatchingDocs());\n    \n    // There should be no results at all\n    for (MatchingDocs doc : collectRandomZeroResults.getMatchingDocs()) {\n      assertEquals(0, doc.totalHits);\n    }\n    \n    // Now start searching and retrieve results.\n    \n    // Use a query to select half of the documents.\n    TermQuery query = new TermQuery(new Term(\"EvenOdd\", \"even\"));\n    \n    // there will be 5 facet values (0, 2, 4, 6 and 8), as only the even (i %\n    // 10) are hits.\n    // there is a REAL small chance that one of the 5 values will be missed when\n    // sampling.\n    // but is that 0.8 (chance not to take a value) ^ 2000 * 5 (any can be\n    // missing) ~ 10^-193\n    // so that is probably not going to happen.\n    int maxNumChildren = 5;\n    \n    RandomSamplingFacetsCollector random100Percent = new RandomSamplingFacetsCollector(numDocs, random.nextLong()); // no sampling\n    RandomSamplingFacetsCollector random10Percent = new RandomSamplingFacetsCollector(numDocs / 10, random.nextLong()); // 10 % of total docs, 20% of the hits\n\n    FacetsCollector fc = new FacetsCollector();\n    \n    searcher.search(query, MultiCollector.wrap(fc, random100Percent, random10Percent));\n    \n    FastTaxonomyFacetCounts random10FacetCounts = new FastTaxonomyFacetCounts(taxoReader, config, random10Percent);\n    FastTaxonomyFacetCounts random100FacetCounts = new FastTaxonomyFacetCounts(taxoReader, config, random100Percent);\n    FastTaxonomyFacetCounts exactFacetCounts = new FastTaxonomyFacetCounts(taxoReader, config, fc);\n    \n    FacetResult random10Result = random10Percent.amortizeFacetCounts(random10FacetCounts.getTopChildren(10, \"iMod10\"), config, searcher);\n    FacetResult random100Result = random100FacetCounts.getTopChildren(10, \"iMod10\");\n    FacetResult exactResult = exactFacetCounts.getTopChildren(10, \"iMod10\");\n    \n    assertEquals(random100Result, exactResult);\n    \n    // we should have five children, but there is a small chance we have less.\n    // (see above).\n    assertTrue(random10Result.childCount <= maxNumChildren);\n    // there should be one child at least.\n    assertTrue(random10Result.childCount >= 1);\n    \n    // now calculate some statistics to determine if the sampled result is 'ok'.\n    // because random sampling is used, the results will vary each time.\n    int sum = 0;\n    for (LabelAndValue lav : random10Result.labelValues) {\n      sum += lav.value.intValue();\n    }\n    float mu = (float) sum / (float) maxNumChildren;\n    \n    float variance = 0;\n    for (LabelAndValue lav : random10Result.labelValues) {\n      variance += Math.pow((mu - lav.value.intValue()), 2);\n    }\n    variance = variance / maxNumChildren;\n    float sigma = (float) Math.sqrt(variance);\n    \n    // we query only half the documents and have 5 categories. The average\n    // number of docs in a category will thus be the total divided by 5*2\n    float targetMu = numDocs / (5.0f * 2.0f);\n    \n    // the average should be in the range and the standard deviation should not\n    // be too great\n    assertTrue(sigma < 200);\n    assertTrue(targetMu - 3 * sigma < mu && mu < targetMu + 3 * sigma);\n    \n    IOUtils.close(searcher.getIndexReader(), taxoReader, dir, taxoDir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3d91157396d7b759e122a236b85a6e1c954df083","date":1415176463,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/TestRandomSamplingFacetsCollector#testRandomSampling().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/TestRandomSamplingFacetsCollector#testRandomSampling().mjava","sourceNew":"  public void testRandomSampling() throws Exception {\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    \n    Random random = random();\n    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir);\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir);\n    \n    FacetsConfig config = new FacetsConfig();\n    \n    final int numCategories = 10;\n    int numDocs = atLeast(10000);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      doc.add(new StringField(\"EvenOdd\", (i % 2 == 0) ? \"even\" : \"odd\", Store.NO));\n      doc.add(new FacetField(\"iMod10\", Integer.toString(i % numCategories)));\n      writer.addDocument(config.build(taxoWriter, doc));\n    }\n    \n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    IOUtils.close(writer, taxoWriter);\n    \n    // Test empty results\n    RandomSamplingFacetsCollector collectRandomZeroResults = new RandomSamplingFacetsCollector(numDocs / 10, random.nextLong());\n    \n    // There should be no divisions by zero\n    searcher.search(new TermQuery(new Term(\"EvenOdd\", \"NeverMatches\")), collectRandomZeroResults);\n    \n    // There should be no divisions by zero and no null result\n    assertNotNull(collectRandomZeroResults.getMatchingDocs());\n    \n    // There should be no results at all\n    for (MatchingDocs doc : collectRandomZeroResults.getMatchingDocs()) {\n      assertEquals(0, doc.totalHits);\n    }\n    \n    // Now start searching and retrieve results.\n    \n    // Use a query to select half of the documents.\n    TermQuery query = new TermQuery(new Term(\"EvenOdd\", \"even\"));\n    \n    RandomSamplingFacetsCollector random10Percent = new RandomSamplingFacetsCollector(numDocs / 10, random.nextLong()); // 10% of total docs, 20% of the hits\n\n    FacetsCollector fc = new FacetsCollector();\n    \n    searcher.search(query, MultiCollector.wrap(fc, random10Percent));\n    \n    final List<MatchingDocs> matchingDocs = random10Percent.getMatchingDocs();\n\n    // count the total hits and sampled docs, also store the number of sampled\n    // docs per segment\n    int totalSampledDocs = 0, totalHits = 0;\n    int[] numSampledDocs = new int[matchingDocs.size()];\n//    System.out.println(\"numSegments=\" + numSampledDocs.length);\n    for (int i = 0; i < numSampledDocs.length; i++) {\n      MatchingDocs md = matchingDocs.get(i);\n      final DocIdSetIterator iter = md.bits.iterator();\n      while (iter.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) ++numSampledDocs[i];\n      totalSampledDocs += numSampledDocs[i];\n      totalHits += md.totalHits;\n    }\n    \n    // compute the chi-square value for the sampled documents' distribution\n    float chi_square = 0;\n    for (int i = 0; i < numSampledDocs.length; i++) {\n      MatchingDocs md = matchingDocs.get(i);\n      float ei = (float) md.totalHits / totalHits;\n      if (ei > 0.0f) {\n        float oi = (float) numSampledDocs[i] / totalSampledDocs;\n        chi_square += (Math.pow(ei - oi, 2) / ei);\n      }\n    }\n    \n    // Verify that the chi-square value isn't too big. According to\n    // http://en.wikipedia.org/wiki/Chi-squared_distribution#Table_of_.CF.872_value_vs_p-value,\n    // we basically verify that there is a really small chance of hitting a very\n    // bad sample (p-value < 0.05), for n-degrees of freedom. The number 'n' depends\n    // on the number of segments.\n    assertTrue(\"chisquare not statistically significant enough: \" + chi_square, chi_square < CHI_SQUARE_VALUES[numSampledDocs.length]);\n    \n    // Test amortized counts - should be 5X the sampled count, but maximum numDocs/10\n    final FastTaxonomyFacetCounts random10FacetCounts = new FastTaxonomyFacetCounts(taxoReader, config, random10Percent);\n    final FacetResult random10Result = random10FacetCounts.getTopChildren(10, \"iMod10\");\n    final FacetResult amortized10Result = random10Percent.amortizeFacetCounts(random10Result, config, searcher);\n    for (int i = 0; i < amortized10Result.labelValues.length; i++) {\n      LabelAndValue amortized = amortized10Result.labelValues[i];\n      LabelAndValue sampled = random10Result.labelValues[i];\n      // since numDocs may not divide by 10 exactly, allow for some slack in the amortized count \n      assertEquals(amortized.value.floatValue(), Math.min(5 * sampled.value.floatValue(), numDocs / 10.f), 1.0);\n    }\n    \n    IOUtils.close(searcher.getIndexReader(), taxoReader, dir, taxoDir);\n  }\n\n","sourceOld":"  public void testRandomSampling() throws Exception {\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    \n    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir);\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    \n    FacetsConfig config = new FacetsConfig();\n    \n    int numDocs = atLeast(10000);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      doc.add(new StringField(\"EvenOdd\", (i % 2 == 0) ? \"even\" : \"odd\", Store.NO));\n      doc.add(new FacetField(\"iMod10\", String.valueOf(i % 10)));\n      writer.addDocument(config.build(taxoWriter, doc));\n    }\n    Random random = random();\n    \n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    writer.close();\n    IOUtils.close(taxoWriter);\n    \n    // Test empty results\n    RandomSamplingFacetsCollector collectRandomZeroResults = new RandomSamplingFacetsCollector(numDocs / 10, random.nextLong());\n    \n    // There should be no divisions by zero\n    searcher.search(new TermQuery(new Term(\"EvenOdd\", \"NeverMatches\")), collectRandomZeroResults);\n    \n    // There should be no divisions by zero and no null result\n    assertNotNull(collectRandomZeroResults.getMatchingDocs());\n    \n    // There should be no results at all\n    for (MatchingDocs doc : collectRandomZeroResults.getMatchingDocs()) {\n      assertEquals(0, doc.totalHits);\n    }\n    \n    // Now start searching and retrieve results.\n    \n    // Use a query to select half of the documents.\n    TermQuery query = new TermQuery(new Term(\"EvenOdd\", \"even\"));\n    \n    // there will be 5 facet values (0, 2, 4, 6 and 8), as only the even (i %\n    // 10) are hits.\n    // there is a REAL small chance that one of the 5 values will be missed when\n    // sampling.\n    // but is that 0.8 (chance not to take a value) ^ 2000 * 5 (any can be\n    // missing) ~ 10^-193\n    // so that is probably not going to happen.\n    int maxNumChildren = 5;\n    \n    RandomSamplingFacetsCollector random100Percent = new RandomSamplingFacetsCollector(numDocs, random.nextLong()); // no sampling\n    RandomSamplingFacetsCollector random10Percent = new RandomSamplingFacetsCollector(numDocs / 10, random.nextLong()); // 10 % of total docs, 20% of the hits\n\n    FacetsCollector fc = new FacetsCollector();\n    \n    searcher.search(query, MultiCollector.wrap(fc, random100Percent, random10Percent));\n    \n    FastTaxonomyFacetCounts random10FacetCounts = new FastTaxonomyFacetCounts(taxoReader, config, random10Percent);\n    FastTaxonomyFacetCounts random100FacetCounts = new FastTaxonomyFacetCounts(taxoReader, config, random100Percent);\n    FastTaxonomyFacetCounts exactFacetCounts = new FastTaxonomyFacetCounts(taxoReader, config, fc);\n    \n    FacetResult random10Result = random10Percent.amortizeFacetCounts(random10FacetCounts.getTopChildren(10, \"iMod10\"), config, searcher);\n    FacetResult random100Result = random100FacetCounts.getTopChildren(10, \"iMod10\");\n    FacetResult exactResult = exactFacetCounts.getTopChildren(10, \"iMod10\");\n    \n    assertEquals(random100Result, exactResult);\n    \n    // we should have five children, but there is a small chance we have less.\n    // (see above).\n    assertTrue(random10Result.childCount <= maxNumChildren);\n    // there should be one child at least.\n    assertTrue(random10Result.childCount >= 1);\n    \n    // now calculate some statistics to determine if the sampled result is 'ok'.\n    // because random sampling is used, the results will vary each time.\n    int sum = 0;\n    for (LabelAndValue lav : random10Result.labelValues) {\n      sum += lav.value.intValue();\n    }\n    float mu = (float) sum / (float) maxNumChildren;\n    \n    float variance = 0;\n    for (LabelAndValue lav : random10Result.labelValues) {\n      variance += Math.pow((mu - lav.value.intValue()), 2);\n    }\n    variance = variance / maxNumChildren;\n    float sigma = (float) Math.sqrt(variance);\n    \n    // we query only half the documents and have 5 categories. The average\n    // number of docs in a category will thus be the total divided by 5*2\n    float targetMu = numDocs / (5.0f * 2.0f);\n    \n    // the average should be in the range and the standard deviation should not\n    // be too great\n    assertTrue(sigma < 200);\n    assertTrue(targetMu - 3 * sigma < mu && mu < targetMu + 3 * sigma);\n    \n    IOUtils.close(searcher.getIndexReader(), taxoReader, dir, taxoDir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0916c270352fa5ad054475c0f9a37d60d74361a9","date":1437393781,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/TestRandomSamplingFacetsCollector#testRandomSampling().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/TestRandomSamplingFacetsCollector#testRandomSampling().mjava","sourceNew":"  public void testRandomSampling() throws Exception {\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    \n    Random random = random();\n    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir);\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir);\n    \n    FacetsConfig config = new FacetsConfig();\n    \n    final int numCategories = 10;\n    int numDocs = atLeast(10000);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      doc.add(new StringField(\"EvenOdd\", (i % 2 == 0) ? \"even\" : \"odd\", Store.NO));\n      doc.add(new FacetField(\"iMod10\", Integer.toString(i % numCategories)));\n      writer.addDocument(config.build(taxoWriter, doc));\n    }\n    writer.forceMerge(CHI_SQUARE_VALUES.length - 1);\n    \n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    IOUtils.close(writer, taxoWriter);\n    \n    // Test empty results\n    RandomSamplingFacetsCollector collectRandomZeroResults = new RandomSamplingFacetsCollector(numDocs / 10, random.nextLong());\n    \n    // There should be no divisions by zero\n    searcher.search(new TermQuery(new Term(\"EvenOdd\", \"NeverMatches\")), collectRandomZeroResults);\n    \n    // There should be no divisions by zero and no null result\n    assertNotNull(collectRandomZeroResults.getMatchingDocs());\n    \n    // There should be no results at all\n    for (MatchingDocs doc : collectRandomZeroResults.getMatchingDocs()) {\n      assertEquals(0, doc.totalHits);\n    }\n    \n    // Now start searching and retrieve results.\n    \n    // Use a query to select half of the documents.\n    TermQuery query = new TermQuery(new Term(\"EvenOdd\", \"even\"));\n    \n    RandomSamplingFacetsCollector random10Percent = new RandomSamplingFacetsCollector(numDocs / 10, random.nextLong()); // 10% of total docs, 20% of the hits\n\n    FacetsCollector fc = new FacetsCollector();\n    \n    searcher.search(query, MultiCollector.wrap(fc, random10Percent));\n    \n    final List<MatchingDocs> matchingDocs = random10Percent.getMatchingDocs();\n\n    // count the total hits and sampled docs, also store the number of sampled\n    // docs per segment\n    int totalSampledDocs = 0, totalHits = 0;\n    int[] numSampledDocs = new int[matchingDocs.size()];\n//    System.out.println(\"numSegments=\" + numSampledDocs.length);\n    for (int i = 0; i < numSampledDocs.length; i++) {\n      MatchingDocs md = matchingDocs.get(i);\n      final DocIdSetIterator iter = md.bits.iterator();\n      while (iter.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) ++numSampledDocs[i];\n      totalSampledDocs += numSampledDocs[i];\n      totalHits += md.totalHits;\n    }\n    \n    // compute the chi-square value for the sampled documents' distribution\n    float chi_square = 0;\n    for (int i = 0; i < numSampledDocs.length; i++) {\n      MatchingDocs md = matchingDocs.get(i);\n      float ei = (float) md.totalHits / totalHits;\n      if (ei > 0.0f) {\n        float oi = (float) numSampledDocs[i] / totalSampledDocs;\n        chi_square += (Math.pow(ei - oi, 2) / ei);\n      }\n    }\n    \n    // Verify that the chi-square value isn't too big. According to\n    // http://en.wikipedia.org/wiki/Chi-squared_distribution#Table_of_.CF.872_value_vs_p-value,\n    // we basically verify that there is a really small chance of hitting a very\n    // bad sample (p-value < 0.05), for n-degrees of freedom. The number 'n' depends\n    // on the number of segments.\n    assertTrue(\"chisquare not statistically significant enough: \" + chi_square, chi_square < CHI_SQUARE_VALUES[numSampledDocs.length]);\n    \n    // Test amortized counts - should be 5X the sampled count, but maximum numDocs/10\n    final FastTaxonomyFacetCounts random10FacetCounts = new FastTaxonomyFacetCounts(taxoReader, config, random10Percent);\n    final FacetResult random10Result = random10FacetCounts.getTopChildren(10, \"iMod10\");\n    final FacetResult amortized10Result = random10Percent.amortizeFacetCounts(random10Result, config, searcher);\n    for (int i = 0; i < amortized10Result.labelValues.length; i++) {\n      LabelAndValue amortized = amortized10Result.labelValues[i];\n      LabelAndValue sampled = random10Result.labelValues[i];\n      // since numDocs may not divide by 10 exactly, allow for some slack in the amortized count \n      assertEquals(amortized.value.floatValue(), Math.min(5 * sampled.value.floatValue(), numDocs / 10.f), 1.0);\n    }\n    \n    IOUtils.close(searcher.getIndexReader(), taxoReader, dir, taxoDir);\n  }\n\n","sourceOld":"  public void testRandomSampling() throws Exception {\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    \n    Random random = random();\n    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir);\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir);\n    \n    FacetsConfig config = new FacetsConfig();\n    \n    final int numCategories = 10;\n    int numDocs = atLeast(10000);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      doc.add(new StringField(\"EvenOdd\", (i % 2 == 0) ? \"even\" : \"odd\", Store.NO));\n      doc.add(new FacetField(\"iMod10\", Integer.toString(i % numCategories)));\n      writer.addDocument(config.build(taxoWriter, doc));\n    }\n    \n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    IOUtils.close(writer, taxoWriter);\n    \n    // Test empty results\n    RandomSamplingFacetsCollector collectRandomZeroResults = new RandomSamplingFacetsCollector(numDocs / 10, random.nextLong());\n    \n    // There should be no divisions by zero\n    searcher.search(new TermQuery(new Term(\"EvenOdd\", \"NeverMatches\")), collectRandomZeroResults);\n    \n    // There should be no divisions by zero and no null result\n    assertNotNull(collectRandomZeroResults.getMatchingDocs());\n    \n    // There should be no results at all\n    for (MatchingDocs doc : collectRandomZeroResults.getMatchingDocs()) {\n      assertEquals(0, doc.totalHits);\n    }\n    \n    // Now start searching and retrieve results.\n    \n    // Use a query to select half of the documents.\n    TermQuery query = new TermQuery(new Term(\"EvenOdd\", \"even\"));\n    \n    RandomSamplingFacetsCollector random10Percent = new RandomSamplingFacetsCollector(numDocs / 10, random.nextLong()); // 10% of total docs, 20% of the hits\n\n    FacetsCollector fc = new FacetsCollector();\n    \n    searcher.search(query, MultiCollector.wrap(fc, random10Percent));\n    \n    final List<MatchingDocs> matchingDocs = random10Percent.getMatchingDocs();\n\n    // count the total hits and sampled docs, also store the number of sampled\n    // docs per segment\n    int totalSampledDocs = 0, totalHits = 0;\n    int[] numSampledDocs = new int[matchingDocs.size()];\n//    System.out.println(\"numSegments=\" + numSampledDocs.length);\n    for (int i = 0; i < numSampledDocs.length; i++) {\n      MatchingDocs md = matchingDocs.get(i);\n      final DocIdSetIterator iter = md.bits.iterator();\n      while (iter.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) ++numSampledDocs[i];\n      totalSampledDocs += numSampledDocs[i];\n      totalHits += md.totalHits;\n    }\n    \n    // compute the chi-square value for the sampled documents' distribution\n    float chi_square = 0;\n    for (int i = 0; i < numSampledDocs.length; i++) {\n      MatchingDocs md = matchingDocs.get(i);\n      float ei = (float) md.totalHits / totalHits;\n      if (ei > 0.0f) {\n        float oi = (float) numSampledDocs[i] / totalSampledDocs;\n        chi_square += (Math.pow(ei - oi, 2) / ei);\n      }\n    }\n    \n    // Verify that the chi-square value isn't too big. According to\n    // http://en.wikipedia.org/wiki/Chi-squared_distribution#Table_of_.CF.872_value_vs_p-value,\n    // we basically verify that there is a really small chance of hitting a very\n    // bad sample (p-value < 0.05), for n-degrees of freedom. The number 'n' depends\n    // on the number of segments.\n    assertTrue(\"chisquare not statistically significant enough: \" + chi_square, chi_square < CHI_SQUARE_VALUES[numSampledDocs.length]);\n    \n    // Test amortized counts - should be 5X the sampled count, but maximum numDocs/10\n    final FastTaxonomyFacetCounts random10FacetCounts = new FastTaxonomyFacetCounts(taxoReader, config, random10Percent);\n    final FacetResult random10Result = random10FacetCounts.getTopChildren(10, \"iMod10\");\n    final FacetResult amortized10Result = random10Percent.amortizeFacetCounts(random10Result, config, searcher);\n    for (int i = 0; i < amortized10Result.labelValues.length; i++) {\n      LabelAndValue amortized = amortized10Result.labelValues[i];\n      LabelAndValue sampled = random10Result.labelValues[i];\n      // since numDocs may not divide by 10 exactly, allow for some slack in the amortized count \n      assertEquals(amortized.value.floatValue(), Math.min(5 * sampled.value.floatValue(), numDocs / 10.f), 1.0);\n    }\n    \n    IOUtils.close(searcher.getIndexReader(), taxoReader, dir, taxoDir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"0916c270352fa5ad054475c0f9a37d60d74361a9":["3d91157396d7b759e122a236b85a6e1c954df083"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["2428b3de33c400750a32591679fd9ee6d6d706dc"],"2428b3de33c400750a32591679fd9ee6d6d706dc":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"3d91157396d7b759e122a236b85a6e1c954df083":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["0916c270352fa5ad054475c0f9a37d60d74361a9"]},"commit2Childs":{"0916c270352fa5ad054475c0f9a37d60d74361a9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["2428b3de33c400750a32591679fd9ee6d6d706dc"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["3d91157396d7b759e122a236b85a6e1c954df083"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"2428b3de33c400750a32591679fd9ee6d6d706dc":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"3d91157396d7b759e122a236b85a6e1c954df083":["0916c270352fa5ad054475c0f9a37d60d74361a9"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}