{"path":"lucene/core/src/test/org/apache/lucene/analysis/TestMockAnalyzer#testChangeGaps().mjava","commits":[{"id":"fa1d846349fbfeb8946cba47ab179b4878a6b2e0","date":1383563805,"type":0,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/analysis/TestMockAnalyzer#testChangeGaps().mjava","pathOld":"/dev/null","sourceNew":"  public void testChangeGaps() throws Exception {\n    // LUCENE-5324: check that it is possible to change the wrapper's gaps\n    final int positionGap = random().nextInt(1000);\n    final int offsetGap = random().nextInt(1000);\n    final Analyzer delegate = new MockAnalyzer(random());\n    final Analyzer a = new AnalyzerWrapper(delegate.getReuseStrategy()) {      \n      @Override\n      protected Analyzer getWrappedAnalyzer(String fieldName) {\n        return delegate;\n      }\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return positionGap;\n      }\n      @Override\n      public int getOffsetGap(String fieldName) {\n        return offsetGap;\n      }\n    };\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), newDirectory());\n    final Document doc = new Document();\n    final FieldType ft = new FieldType();\n    ft.setIndexed(true);\n    ft.setTokenized(true);\n    ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    doc.add(new Field(\"f\", \"a\", ft));\n    doc.add(new Field(\"f\", \"a\", ft));\n    writer.addDocument(doc, a);\n    final AtomicReader reader = getOnlySegmentReader(writer.getReader());\n    final Fields fields = reader.fields();\n    final Terms terms = fields.terms(\"f\");\n    final TermsEnum te = terms.iterator(null);\n    assertEquals(new BytesRef(\"a\"), te.next());\n    final DocsAndPositionsEnum dpe = te.docsAndPositions(null, null);\n    assertEquals(0, dpe.nextDoc());\n    assertEquals(2, dpe.freq());\n    assertEquals(0, dpe.nextPosition());\n    assertEquals(0, dpe.startOffset());\n    final int endOffset = dpe.endOffset();\n    assertEquals(1 + positionGap, dpe.nextPosition());\n    assertEquals(1 + endOffset + offsetGap, dpe.endOffset());\n    assertEquals(null, te.next());\n    reader.close();\n    writer.close();\n    writer.w.getDirectory().close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d233139eaa55e91b9340518db818b712a7b0f4de","date":1383585686,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/analysis/TestMockAnalyzer#testChangeGaps().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/analysis/TestMockAnalyzer#testChangeGaps().mjava","sourceNew":"  public void testChangeGaps() throws Exception {\n    // LUCENE-5324: check that it is possible to change the wrapper's gaps\n    final int positionGap = random().nextInt(1000);\n    final int offsetGap = random().nextInt(1000);\n    final Analyzer delegate = new MockAnalyzer(random());\n    final Analyzer a = new AnalyzerWrapper(delegate.getReuseStrategy()) {      \n      @Override\n      protected Analyzer getWrappedAnalyzer(String fieldName) {\n        return delegate;\n      }\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return positionGap;\n      }\n      @Override\n      public int getOffsetGap(String fieldName) {\n        return offsetGap;\n      }\n    };\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), newDirectory());\n    final Document doc = new Document();\n    final FieldType ft = new FieldType();\n    ft.setIndexed(true);\n    ft.setIndexOptions(IndexOptions.DOCS_ONLY);\n    ft.setTokenized(true);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorPositions(true);\n    ft.setStoreTermVectorOffsets(true);\n    doc.add(new Field(\"f\", \"a\", ft));\n    doc.add(new Field(\"f\", \"a\", ft));\n    writer.addDocument(doc, a);\n    final AtomicReader reader = getOnlySegmentReader(writer.getReader());\n    final Fields fields = reader.getTermVectors(0);\n    final Terms terms = fields.terms(\"f\");\n    final TermsEnum te = terms.iterator(null);\n    assertEquals(new BytesRef(\"a\"), te.next());\n    final DocsAndPositionsEnum dpe = te.docsAndPositions(null, null);\n    assertEquals(0, dpe.nextDoc());\n    assertEquals(2, dpe.freq());\n    assertEquals(0, dpe.nextPosition());\n    assertEquals(0, dpe.startOffset());\n    final int endOffset = dpe.endOffset();\n    assertEquals(1 + positionGap, dpe.nextPosition());\n    assertEquals(1 + endOffset + offsetGap, dpe.endOffset());\n    assertEquals(null, te.next());\n    reader.close();\n    writer.close();\n    writer.w.getDirectory().close();\n  }\n\n","sourceOld":"  public void testChangeGaps() throws Exception {\n    // LUCENE-5324: check that it is possible to change the wrapper's gaps\n    final int positionGap = random().nextInt(1000);\n    final int offsetGap = random().nextInt(1000);\n    final Analyzer delegate = new MockAnalyzer(random());\n    final Analyzer a = new AnalyzerWrapper(delegate.getReuseStrategy()) {      \n      @Override\n      protected Analyzer getWrappedAnalyzer(String fieldName) {\n        return delegate;\n      }\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return positionGap;\n      }\n      @Override\n      public int getOffsetGap(String fieldName) {\n        return offsetGap;\n      }\n    };\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), newDirectory());\n    final Document doc = new Document();\n    final FieldType ft = new FieldType();\n    ft.setIndexed(true);\n    ft.setTokenized(true);\n    ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    doc.add(new Field(\"f\", \"a\", ft));\n    doc.add(new Field(\"f\", \"a\", ft));\n    writer.addDocument(doc, a);\n    final AtomicReader reader = getOnlySegmentReader(writer.getReader());\n    final Fields fields = reader.fields();\n    final Terms terms = fields.terms(\"f\");\n    final TermsEnum te = terms.iterator(null);\n    assertEquals(new BytesRef(\"a\"), te.next());\n    final DocsAndPositionsEnum dpe = te.docsAndPositions(null, null);\n    assertEquals(0, dpe.nextDoc());\n    assertEquals(2, dpe.freq());\n    assertEquals(0, dpe.nextPosition());\n    assertEquals(0, dpe.startOffset());\n    final int endOffset = dpe.endOffset();\n    assertEquals(1 + positionGap, dpe.nextPosition());\n    assertEquals(1 + endOffset + offsetGap, dpe.endOffset());\n    assertEquals(null, te.next());\n    reader.close();\n    writer.close();\n    writer.w.getDirectory().close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/analysis/TestMockAnalyzer#testChangeGaps().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/analysis/TestMockAnalyzer#testChangeGaps().mjava","sourceNew":"  public void testChangeGaps() throws Exception {\n    // LUCENE-5324: check that it is possible to change the wrapper's gaps\n    final int positionGap = random().nextInt(1000);\n    final int offsetGap = random().nextInt(1000);\n    final Analyzer delegate = new MockAnalyzer(random());\n    final Analyzer a = new AnalyzerWrapper(delegate.getReuseStrategy()) {      \n      @Override\n      protected Analyzer getWrappedAnalyzer(String fieldName) {\n        return delegate;\n      }\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return positionGap;\n      }\n      @Override\n      public int getOffsetGap(String fieldName) {\n        return offsetGap;\n      }\n    };\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), newDirectory());\n    final Document doc = new Document();\n    final FieldType ft = new FieldType();\n    ft.setIndexed(true);\n    ft.setIndexOptions(IndexOptions.DOCS_ONLY);\n    ft.setTokenized(true);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorPositions(true);\n    ft.setStoreTermVectorOffsets(true);\n    doc.add(new Field(\"f\", \"a\", ft));\n    doc.add(new Field(\"f\", \"a\", ft));\n    writer.addDocument(doc, a);\n    final AtomicReader reader = getOnlySegmentReader(writer.getReader());\n    final Fields fields = reader.getTermVectors(0);\n    final Terms terms = fields.terms(\"f\");\n    final TermsEnum te = terms.iterator(null);\n    assertEquals(new BytesRef(\"a\"), te.next());\n    final DocsAndPositionsEnum dpe = te.docsAndPositions(null, null);\n    assertEquals(0, dpe.nextDoc());\n    assertEquals(2, dpe.freq());\n    assertEquals(0, dpe.nextPosition());\n    assertEquals(0, dpe.startOffset());\n    final int endOffset = dpe.endOffset();\n    assertEquals(1 + positionGap, dpe.nextPosition());\n    assertEquals(1 + endOffset + offsetGap, dpe.endOffset());\n    assertEquals(null, te.next());\n    reader.close();\n    writer.shutdown();\n    writer.w.getDirectory().close();\n  }\n\n","sourceOld":"  public void testChangeGaps() throws Exception {\n    // LUCENE-5324: check that it is possible to change the wrapper's gaps\n    final int positionGap = random().nextInt(1000);\n    final int offsetGap = random().nextInt(1000);\n    final Analyzer delegate = new MockAnalyzer(random());\n    final Analyzer a = new AnalyzerWrapper(delegate.getReuseStrategy()) {      \n      @Override\n      protected Analyzer getWrappedAnalyzer(String fieldName) {\n        return delegate;\n      }\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return positionGap;\n      }\n      @Override\n      public int getOffsetGap(String fieldName) {\n        return offsetGap;\n      }\n    };\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), newDirectory());\n    final Document doc = new Document();\n    final FieldType ft = new FieldType();\n    ft.setIndexed(true);\n    ft.setIndexOptions(IndexOptions.DOCS_ONLY);\n    ft.setTokenized(true);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorPositions(true);\n    ft.setStoreTermVectorOffsets(true);\n    doc.add(new Field(\"f\", \"a\", ft));\n    doc.add(new Field(\"f\", \"a\", ft));\n    writer.addDocument(doc, a);\n    final AtomicReader reader = getOnlySegmentReader(writer.getReader());\n    final Fields fields = reader.getTermVectors(0);\n    final Terms terms = fields.terms(\"f\");\n    final TermsEnum te = terms.iterator(null);\n    assertEquals(new BytesRef(\"a\"), te.next());\n    final DocsAndPositionsEnum dpe = te.docsAndPositions(null, null);\n    assertEquals(0, dpe.nextDoc());\n    assertEquals(2, dpe.freq());\n    assertEquals(0, dpe.nextPosition());\n    assertEquals(0, dpe.startOffset());\n    final int endOffset = dpe.endOffset();\n    assertEquals(1 + positionGap, dpe.nextPosition());\n    assertEquals(1 + endOffset + offsetGap, dpe.endOffset());\n    assertEquals(null, te.next());\n    reader.close();\n    writer.close();\n    writer.w.getDirectory().close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6e6076d5869e894e98558285d9c9be9179d93921","date":1404559951,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/analysis/TestMockAnalyzer#testChangeGaps().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/analysis/TestMockAnalyzer#testChangeGaps().mjava","sourceNew":"  public void testChangeGaps() throws Exception {\n    // LUCENE-5324: check that it is possible to change the wrapper's gaps\n    final int positionGap = random().nextInt(1000);\n    final int offsetGap = random().nextInt(1000);\n    final Analyzer delegate = new MockAnalyzer(random());\n    final Analyzer a = new DelegatingAnalyzerWrapper(delegate.getReuseStrategy()) {\n      @Override\n      protected Analyzer getWrappedAnalyzer(String fieldName) {\n        return delegate;\n      }\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return positionGap;\n      }\n      @Override\n      public int getOffsetGap(String fieldName) {\n        return offsetGap;\n      }\n    };\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), newDirectory());\n    final Document doc = new Document();\n    final FieldType ft = new FieldType();\n    ft.setIndexed(true);\n    ft.setIndexOptions(IndexOptions.DOCS_ONLY);\n    ft.setTokenized(true);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorPositions(true);\n    ft.setStoreTermVectorOffsets(true);\n    doc.add(new Field(\"f\", \"a\", ft));\n    doc.add(new Field(\"f\", \"a\", ft));\n    writer.addDocument(doc, a);\n    final AtomicReader reader = getOnlySegmentReader(writer.getReader());\n    final Fields fields = reader.getTermVectors(0);\n    final Terms terms = fields.terms(\"f\");\n    final TermsEnum te = terms.iterator(null);\n    assertEquals(new BytesRef(\"a\"), te.next());\n    final DocsAndPositionsEnum dpe = te.docsAndPositions(null, null);\n    assertEquals(0, dpe.nextDoc());\n    assertEquals(2, dpe.freq());\n    assertEquals(0, dpe.nextPosition());\n    assertEquals(0, dpe.startOffset());\n    final int endOffset = dpe.endOffset();\n    assertEquals(1 + positionGap, dpe.nextPosition());\n    assertEquals(1 + endOffset + offsetGap, dpe.endOffset());\n    assertEquals(null, te.next());\n    reader.close();\n    writer.shutdown();\n    writer.w.getDirectory().close();\n  }\n\n","sourceOld":"  public void testChangeGaps() throws Exception {\n    // LUCENE-5324: check that it is possible to change the wrapper's gaps\n    final int positionGap = random().nextInt(1000);\n    final int offsetGap = random().nextInt(1000);\n    final Analyzer delegate = new MockAnalyzer(random());\n    final Analyzer a = new AnalyzerWrapper(delegate.getReuseStrategy()) {      \n      @Override\n      protected Analyzer getWrappedAnalyzer(String fieldName) {\n        return delegate;\n      }\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return positionGap;\n      }\n      @Override\n      public int getOffsetGap(String fieldName) {\n        return offsetGap;\n      }\n    };\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), newDirectory());\n    final Document doc = new Document();\n    final FieldType ft = new FieldType();\n    ft.setIndexed(true);\n    ft.setIndexOptions(IndexOptions.DOCS_ONLY);\n    ft.setTokenized(true);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorPositions(true);\n    ft.setStoreTermVectorOffsets(true);\n    doc.add(new Field(\"f\", \"a\", ft));\n    doc.add(new Field(\"f\", \"a\", ft));\n    writer.addDocument(doc, a);\n    final AtomicReader reader = getOnlySegmentReader(writer.getReader());\n    final Fields fields = reader.getTermVectors(0);\n    final Terms terms = fields.terms(\"f\");\n    final TermsEnum te = terms.iterator(null);\n    assertEquals(new BytesRef(\"a\"), te.next());\n    final DocsAndPositionsEnum dpe = te.docsAndPositions(null, null);\n    assertEquals(0, dpe.nextDoc());\n    assertEquals(2, dpe.freq());\n    assertEquals(0, dpe.nextPosition());\n    assertEquals(0, dpe.startOffset());\n    final int endOffset = dpe.endOffset();\n    assertEquals(1 + positionGap, dpe.nextPosition());\n    assertEquals(1 + endOffset + offsetGap, dpe.endOffset());\n    assertEquals(null, te.next());\n    reader.close();\n    writer.shutdown();\n    writer.w.getDirectory().close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/analysis/TestMockAnalyzer#testChangeGaps().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/analysis/TestMockAnalyzer#testChangeGaps().mjava","sourceNew":"  public void testChangeGaps() throws Exception {\n    // LUCENE-5324: check that it is possible to change the wrapper's gaps\n    final int positionGap = random().nextInt(1000);\n    final int offsetGap = random().nextInt(1000);\n    final Analyzer delegate = new MockAnalyzer(random());\n    final Analyzer a = new DelegatingAnalyzerWrapper(delegate.getReuseStrategy()) {\n      @Override\n      protected Analyzer getWrappedAnalyzer(String fieldName) {\n        return delegate;\n      }\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return positionGap;\n      }\n      @Override\n      public int getOffsetGap(String fieldName) {\n        return offsetGap;\n      }\n    };\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), newDirectory());\n    final Document doc = new Document();\n    final FieldType ft = new FieldType();\n    ft.setIndexed(true);\n    ft.setIndexOptions(IndexOptions.DOCS_ONLY);\n    ft.setTokenized(true);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorPositions(true);\n    ft.setStoreTermVectorOffsets(true);\n    doc.add(new Field(\"f\", \"a\", ft));\n    doc.add(new Field(\"f\", \"a\", ft));\n    writer.addDocument(doc, a);\n    final AtomicReader reader = getOnlySegmentReader(writer.getReader());\n    final Fields fields = reader.getTermVectors(0);\n    final Terms terms = fields.terms(\"f\");\n    final TermsEnum te = terms.iterator(null);\n    assertEquals(new BytesRef(\"a\"), te.next());\n    final DocsAndPositionsEnum dpe = te.docsAndPositions(null, null);\n    assertEquals(0, dpe.nextDoc());\n    assertEquals(2, dpe.freq());\n    assertEquals(0, dpe.nextPosition());\n    assertEquals(0, dpe.startOffset());\n    final int endOffset = dpe.endOffset();\n    assertEquals(1 + positionGap, dpe.nextPosition());\n    assertEquals(1 + endOffset + offsetGap, dpe.endOffset());\n    assertEquals(null, te.next());\n    reader.close();\n    writer.close();\n    writer.w.getDirectory().close();\n  }\n\n","sourceOld":"  public void testChangeGaps() throws Exception {\n    // LUCENE-5324: check that it is possible to change the wrapper's gaps\n    final int positionGap = random().nextInt(1000);\n    final int offsetGap = random().nextInt(1000);\n    final Analyzer delegate = new MockAnalyzer(random());\n    final Analyzer a = new DelegatingAnalyzerWrapper(delegate.getReuseStrategy()) {\n      @Override\n      protected Analyzer getWrappedAnalyzer(String fieldName) {\n        return delegate;\n      }\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return positionGap;\n      }\n      @Override\n      public int getOffsetGap(String fieldName) {\n        return offsetGap;\n      }\n    };\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), newDirectory());\n    final Document doc = new Document();\n    final FieldType ft = new FieldType();\n    ft.setIndexed(true);\n    ft.setIndexOptions(IndexOptions.DOCS_ONLY);\n    ft.setTokenized(true);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorPositions(true);\n    ft.setStoreTermVectorOffsets(true);\n    doc.add(new Field(\"f\", \"a\", ft));\n    doc.add(new Field(\"f\", \"a\", ft));\n    writer.addDocument(doc, a);\n    final AtomicReader reader = getOnlySegmentReader(writer.getReader());\n    final Fields fields = reader.getTermVectors(0);\n    final Terms terms = fields.terms(\"f\");\n    final TermsEnum te = terms.iterator(null);\n    assertEquals(new BytesRef(\"a\"), te.next());\n    final DocsAndPositionsEnum dpe = te.docsAndPositions(null, null);\n    assertEquals(0, dpe.nextDoc());\n    assertEquals(2, dpe.freq());\n    assertEquals(0, dpe.nextPosition());\n    assertEquals(0, dpe.startOffset());\n    final int endOffset = dpe.endOffset();\n    assertEquals(1 + positionGap, dpe.nextPosition());\n    assertEquals(1 + endOffset + offsetGap, dpe.endOffset());\n    assertEquals(null, te.next());\n    reader.close();\n    writer.shutdown();\n    writer.w.getDirectory().close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c9fb5f46e264daf5ba3860defe623a89d202dd87","date":1411516315,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/analysis/TestMockAnalyzer#testChangeGaps().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/analysis/TestMockAnalyzer#testChangeGaps().mjava","sourceNew":"  public void testChangeGaps() throws Exception {\n    // LUCENE-5324: check that it is possible to change the wrapper's gaps\n    final int positionGap = random().nextInt(1000);\n    final int offsetGap = random().nextInt(1000);\n    final Analyzer delegate = new MockAnalyzer(random());\n    final Analyzer a = new DelegatingAnalyzerWrapper(delegate.getReuseStrategy()) {\n      @Override\n      protected Analyzer getWrappedAnalyzer(String fieldName) {\n        return delegate;\n      }\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return positionGap;\n      }\n      @Override\n      public int getOffsetGap(String fieldName) {\n        return offsetGap;\n      }\n    };\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), newDirectory());\n    final Document doc = new Document();\n    final FieldType ft = new FieldType();\n    ft.setIndexed(true);\n    ft.setIndexOptions(IndexOptions.DOCS_ONLY);\n    ft.setTokenized(true);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorPositions(true);\n    ft.setStoreTermVectorOffsets(true);\n    doc.add(new Field(\"f\", \"a\", ft));\n    doc.add(new Field(\"f\", \"a\", ft));\n    writer.addDocument(doc, a);\n    final LeafReader reader = getOnlySegmentReader(writer.getReader());\n    final Fields fields = reader.getTermVectors(0);\n    final Terms terms = fields.terms(\"f\");\n    final TermsEnum te = terms.iterator(null);\n    assertEquals(new BytesRef(\"a\"), te.next());\n    final DocsAndPositionsEnum dpe = te.docsAndPositions(null, null);\n    assertEquals(0, dpe.nextDoc());\n    assertEquals(2, dpe.freq());\n    assertEquals(0, dpe.nextPosition());\n    assertEquals(0, dpe.startOffset());\n    final int endOffset = dpe.endOffset();\n    assertEquals(1 + positionGap, dpe.nextPosition());\n    assertEquals(1 + endOffset + offsetGap, dpe.endOffset());\n    assertEquals(null, te.next());\n    reader.close();\n    writer.close();\n    writer.w.getDirectory().close();\n  }\n\n","sourceOld":"  public void testChangeGaps() throws Exception {\n    // LUCENE-5324: check that it is possible to change the wrapper's gaps\n    final int positionGap = random().nextInt(1000);\n    final int offsetGap = random().nextInt(1000);\n    final Analyzer delegate = new MockAnalyzer(random());\n    final Analyzer a = new DelegatingAnalyzerWrapper(delegate.getReuseStrategy()) {\n      @Override\n      protected Analyzer getWrappedAnalyzer(String fieldName) {\n        return delegate;\n      }\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return positionGap;\n      }\n      @Override\n      public int getOffsetGap(String fieldName) {\n        return offsetGap;\n      }\n    };\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), newDirectory());\n    final Document doc = new Document();\n    final FieldType ft = new FieldType();\n    ft.setIndexed(true);\n    ft.setIndexOptions(IndexOptions.DOCS_ONLY);\n    ft.setTokenized(true);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorPositions(true);\n    ft.setStoreTermVectorOffsets(true);\n    doc.add(new Field(\"f\", \"a\", ft));\n    doc.add(new Field(\"f\", \"a\", ft));\n    writer.addDocument(doc, a);\n    final AtomicReader reader = getOnlySegmentReader(writer.getReader());\n    final Fields fields = reader.getTermVectors(0);\n    final Terms terms = fields.terms(\"f\");\n    final TermsEnum te = terms.iterator(null);\n    assertEquals(new BytesRef(\"a\"), te.next());\n    final DocsAndPositionsEnum dpe = te.docsAndPositions(null, null);\n    assertEquals(0, dpe.nextDoc());\n    assertEquals(2, dpe.freq());\n    assertEquals(0, dpe.nextPosition());\n    assertEquals(0, dpe.startOffset());\n    final int endOffset = dpe.endOffset();\n    assertEquals(1 + positionGap, dpe.nextPosition());\n    assertEquals(1 + endOffset + offsetGap, dpe.endOffset());\n    assertEquals(null, te.next());\n    reader.close();\n    writer.close();\n    writer.w.getDirectory().close();\n  }\n\n","bugFix":null,"bugIntro":["0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3184874f7f3aca850248483485b4995343066875","date":1413876758,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/analysis/TestMockAnalyzer#testChangeGaps().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/analysis/TestMockAnalyzer#testChangeGaps().mjava","sourceNew":"  public void testChangeGaps() throws Exception {\n    // LUCENE-5324: check that it is possible to change the wrapper's gaps\n    final int positionGap = random().nextInt(1000);\n    final int offsetGap = random().nextInt(1000);\n    final Analyzer delegate = new MockAnalyzer(random());\n    final Analyzer a = new DelegatingAnalyzerWrapper(delegate.getReuseStrategy()) {\n      @Override\n      protected Analyzer getWrappedAnalyzer(String fieldName) {\n        return delegate;\n      }\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return positionGap;\n      }\n      @Override\n      public int getOffsetGap(String fieldName) {\n        return offsetGap;\n      }\n    };\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), newDirectory());\n    final Document doc = new Document();\n    final FieldType ft = new FieldType();\n    ft.setIndexOptions(IndexOptions.DOCS_ONLY);\n    ft.setTokenized(true);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorPositions(true);\n    ft.setStoreTermVectorOffsets(true);\n    doc.add(new Field(\"f\", \"a\", ft));\n    doc.add(new Field(\"f\", \"a\", ft));\n    writer.addDocument(doc, a);\n    final LeafReader reader = getOnlySegmentReader(writer.getReader());\n    final Fields fields = reader.getTermVectors(0);\n    final Terms terms = fields.terms(\"f\");\n    final TermsEnum te = terms.iterator(null);\n    assertEquals(new BytesRef(\"a\"), te.next());\n    final DocsAndPositionsEnum dpe = te.docsAndPositions(null, null);\n    assertEquals(0, dpe.nextDoc());\n    assertEquals(2, dpe.freq());\n    assertEquals(0, dpe.nextPosition());\n    assertEquals(0, dpe.startOffset());\n    final int endOffset = dpe.endOffset();\n    assertEquals(1 + positionGap, dpe.nextPosition());\n    assertEquals(1 + endOffset + offsetGap, dpe.endOffset());\n    assertEquals(null, te.next());\n    reader.close();\n    writer.close();\n    writer.w.getDirectory().close();\n  }\n\n","sourceOld":"  public void testChangeGaps() throws Exception {\n    // LUCENE-5324: check that it is possible to change the wrapper's gaps\n    final int positionGap = random().nextInt(1000);\n    final int offsetGap = random().nextInt(1000);\n    final Analyzer delegate = new MockAnalyzer(random());\n    final Analyzer a = new DelegatingAnalyzerWrapper(delegate.getReuseStrategy()) {\n      @Override\n      protected Analyzer getWrappedAnalyzer(String fieldName) {\n        return delegate;\n      }\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return positionGap;\n      }\n      @Override\n      public int getOffsetGap(String fieldName) {\n        return offsetGap;\n      }\n    };\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), newDirectory());\n    final Document doc = new Document();\n    final FieldType ft = new FieldType();\n    ft.setIndexed(true);\n    ft.setIndexOptions(IndexOptions.DOCS_ONLY);\n    ft.setTokenized(true);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorPositions(true);\n    ft.setStoreTermVectorOffsets(true);\n    doc.add(new Field(\"f\", \"a\", ft));\n    doc.add(new Field(\"f\", \"a\", ft));\n    writer.addDocument(doc, a);\n    final LeafReader reader = getOnlySegmentReader(writer.getReader());\n    final Fields fields = reader.getTermVectors(0);\n    final Terms terms = fields.terms(\"f\");\n    final TermsEnum te = terms.iterator(null);\n    assertEquals(new BytesRef(\"a\"), te.next());\n    final DocsAndPositionsEnum dpe = te.docsAndPositions(null, null);\n    assertEquals(0, dpe.nextDoc());\n    assertEquals(2, dpe.freq());\n    assertEquals(0, dpe.nextPosition());\n    assertEquals(0, dpe.startOffset());\n    final int endOffset = dpe.endOffset();\n    assertEquals(1 + positionGap, dpe.nextPosition());\n    assertEquals(1 + endOffset + offsetGap, dpe.endOffset());\n    assertEquals(null, te.next());\n    reader.close();\n    writer.close();\n    writer.w.getDirectory().close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0a22eafe3f72a4c2945eaad9547e6c78816978f4","date":1413956657,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/analysis/TestMockAnalyzer#testChangeGaps().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/analysis/TestMockAnalyzer#testChangeGaps().mjava","sourceNew":"  public void testChangeGaps() throws Exception {\n    // LUCENE-5324: check that it is possible to change the wrapper's gaps\n    final int positionGap = random().nextInt(1000);\n    final int offsetGap = random().nextInt(1000);\n    final Analyzer delegate = new MockAnalyzer(random());\n    final Analyzer a = new DelegatingAnalyzerWrapper(delegate.getReuseStrategy()) {\n      @Override\n      protected Analyzer getWrappedAnalyzer(String fieldName) {\n        return delegate;\n      }\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return positionGap;\n      }\n      @Override\n      public int getOffsetGap(String fieldName) {\n        return offsetGap;\n      }\n    };\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), newDirectory());\n    final Document doc = new Document();\n    final FieldType ft = new FieldType();\n    ft.setIndexOptions(IndexOptions.DOCS_ONLY);\n    ft.setTokenized(true);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorPositions(true);\n    ft.setStoreTermVectorOffsets(true);\n    doc.add(new Field(\"f\", \"a\", ft));\n    doc.add(new Field(\"f\", \"a\", ft));\n    writer.addDocument(doc, a);\n    final LeafReader reader = getOnlySegmentReader(writer.getReader());\n    final Fields fields = reader.getTermVectors(0);\n    final Terms terms = fields.terms(\"f\");\n    final TermsEnum te = terms.iterator(null);\n    assertEquals(new BytesRef(\"a\"), te.next());\n    final DocsAndPositionsEnum dpe = te.docsAndPositions(null, null);\n    assertEquals(0, dpe.nextDoc());\n    assertEquals(2, dpe.freq());\n    assertEquals(0, dpe.nextPosition());\n    assertEquals(0, dpe.startOffset());\n    final int endOffset = dpe.endOffset();\n    assertEquals(1 + positionGap, dpe.nextPosition());\n    assertEquals(1 + endOffset + offsetGap, dpe.endOffset());\n    assertEquals(null, te.next());\n    reader.close();\n    writer.close();\n    writer.w.getDirectory().close();\n  }\n\n","sourceOld":"  public void testChangeGaps() throws Exception {\n    // LUCENE-5324: check that it is possible to change the wrapper's gaps\n    final int positionGap = random().nextInt(1000);\n    final int offsetGap = random().nextInt(1000);\n    final Analyzer delegate = new MockAnalyzer(random());\n    final Analyzer a = new DelegatingAnalyzerWrapper(delegate.getReuseStrategy()) {\n      @Override\n      protected Analyzer getWrappedAnalyzer(String fieldName) {\n        return delegate;\n      }\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return positionGap;\n      }\n      @Override\n      public int getOffsetGap(String fieldName) {\n        return offsetGap;\n      }\n    };\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), newDirectory());\n    final Document doc = new Document();\n    final FieldType ft = new FieldType();\n    ft.setIndexed(true);\n    ft.setIndexOptions(IndexOptions.DOCS_ONLY);\n    ft.setTokenized(true);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorPositions(true);\n    ft.setStoreTermVectorOffsets(true);\n    doc.add(new Field(\"f\", \"a\", ft));\n    doc.add(new Field(\"f\", \"a\", ft));\n    writer.addDocument(doc, a);\n    final LeafReader reader = getOnlySegmentReader(writer.getReader());\n    final Fields fields = reader.getTermVectors(0);\n    final Terms terms = fields.terms(\"f\");\n    final TermsEnum te = terms.iterator(null);\n    assertEquals(new BytesRef(\"a\"), te.next());\n    final DocsAndPositionsEnum dpe = te.docsAndPositions(null, null);\n    assertEquals(0, dpe.nextDoc());\n    assertEquals(2, dpe.freq());\n    assertEquals(0, dpe.nextPosition());\n    assertEquals(0, dpe.startOffset());\n    final int endOffset = dpe.endOffset();\n    assertEquals(1 + positionGap, dpe.nextPosition());\n    assertEquals(1 + endOffset + offsetGap, dpe.endOffset());\n    assertEquals(null, te.next());\n    reader.close();\n    writer.close();\n    writer.w.getDirectory().close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2bb2842e561df4e8e9ad89010605fc86ac265465","date":1414768208,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/analysis/TestMockAnalyzer#testChangeGaps().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/analysis/TestMockAnalyzer#testChangeGaps().mjava","sourceNew":"  public void testChangeGaps() throws Exception {\n    // LUCENE-5324: check that it is possible to change the wrapper's gaps\n    final int positionGap = random().nextInt(1000);\n    final int offsetGap = random().nextInt(1000);\n    final Analyzer delegate = new MockAnalyzer(random());\n    final Analyzer a = new DelegatingAnalyzerWrapper(delegate.getReuseStrategy()) {\n      @Override\n      protected Analyzer getWrappedAnalyzer(String fieldName) {\n        return delegate;\n      }\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return positionGap;\n      }\n      @Override\n      public int getOffsetGap(String fieldName) {\n        return offsetGap;\n      }\n    };\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), newDirectory());\n    final Document doc = new Document();\n    final FieldType ft = new FieldType();\n    ft.setIndexOptions(IndexOptions.DOCS);\n    ft.setTokenized(true);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorPositions(true);\n    ft.setStoreTermVectorOffsets(true);\n    doc.add(new Field(\"f\", \"a\", ft));\n    doc.add(new Field(\"f\", \"a\", ft));\n    writer.addDocument(doc, a);\n    final LeafReader reader = getOnlySegmentReader(writer.getReader());\n    final Fields fields = reader.getTermVectors(0);\n    final Terms terms = fields.terms(\"f\");\n    final TermsEnum te = terms.iterator(null);\n    assertEquals(new BytesRef(\"a\"), te.next());\n    final DocsAndPositionsEnum dpe = te.docsAndPositions(null, null);\n    assertEquals(0, dpe.nextDoc());\n    assertEquals(2, dpe.freq());\n    assertEquals(0, dpe.nextPosition());\n    assertEquals(0, dpe.startOffset());\n    final int endOffset = dpe.endOffset();\n    assertEquals(1 + positionGap, dpe.nextPosition());\n    assertEquals(1 + endOffset + offsetGap, dpe.endOffset());\n    assertEquals(null, te.next());\n    reader.close();\n    writer.close();\n    writer.w.getDirectory().close();\n  }\n\n","sourceOld":"  public void testChangeGaps() throws Exception {\n    // LUCENE-5324: check that it is possible to change the wrapper's gaps\n    final int positionGap = random().nextInt(1000);\n    final int offsetGap = random().nextInt(1000);\n    final Analyzer delegate = new MockAnalyzer(random());\n    final Analyzer a = new DelegatingAnalyzerWrapper(delegate.getReuseStrategy()) {\n      @Override\n      protected Analyzer getWrappedAnalyzer(String fieldName) {\n        return delegate;\n      }\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return positionGap;\n      }\n      @Override\n      public int getOffsetGap(String fieldName) {\n        return offsetGap;\n      }\n    };\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), newDirectory());\n    final Document doc = new Document();\n    final FieldType ft = new FieldType();\n    ft.setIndexOptions(IndexOptions.DOCS_ONLY);\n    ft.setTokenized(true);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorPositions(true);\n    ft.setStoreTermVectorOffsets(true);\n    doc.add(new Field(\"f\", \"a\", ft));\n    doc.add(new Field(\"f\", \"a\", ft));\n    writer.addDocument(doc, a);\n    final LeafReader reader = getOnlySegmentReader(writer.getReader());\n    final Fields fields = reader.getTermVectors(0);\n    final Terms terms = fields.terms(\"f\");\n    final TermsEnum te = terms.iterator(null);\n    assertEquals(new BytesRef(\"a\"), te.next());\n    final DocsAndPositionsEnum dpe = te.docsAndPositions(null, null);\n    assertEquals(0, dpe.nextDoc());\n    assertEquals(2, dpe.freq());\n    assertEquals(0, dpe.nextPosition());\n    assertEquals(0, dpe.startOffset());\n    final int endOffset = dpe.endOffset();\n    assertEquals(1 + positionGap, dpe.nextPosition());\n    assertEquals(1 + endOffset + offsetGap, dpe.endOffset());\n    assertEquals(null, te.next());\n    reader.close();\n    writer.close();\n    writer.w.getDirectory().close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5c1c5aa8e88aa52c9e1cbfc696b611d3a56223c0","date":1422781929,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/analysis/TestMockAnalyzer#testChangeGaps().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/analysis/TestMockAnalyzer#testChangeGaps().mjava","sourceNew":"  public void testChangeGaps() throws Exception {\n    // LUCENE-5324: check that it is possible to change the wrapper's gaps\n    final int positionGap = random().nextInt(1000);\n    final int offsetGap = random().nextInt(1000);\n    final Analyzer delegate = new MockAnalyzer(random());\n    final Analyzer a = new DelegatingAnalyzerWrapper(delegate.getReuseStrategy()) {\n      @Override\n      protected Analyzer getWrappedAnalyzer(String fieldName) {\n        return delegate;\n      }\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return positionGap;\n      }\n      @Override\n      public int getOffsetGap(String fieldName) {\n        return offsetGap;\n      }\n    };\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), newDirectory(), a);\n    final Document doc = new Document();\n    final FieldType ft = new FieldType();\n    ft.setIndexOptions(IndexOptions.DOCS);\n    ft.setTokenized(true);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorPositions(true);\n    ft.setStoreTermVectorOffsets(true);\n    doc.add(new Field(\"f\", \"a\", ft));\n    doc.add(new Field(\"f\", \"a\", ft));\n    writer.addDocument(doc);\n    final LeafReader reader = getOnlySegmentReader(writer.getReader());\n    final Fields fields = reader.getTermVectors(0);\n    final Terms terms = fields.terms(\"f\");\n    final TermsEnum te = terms.iterator(null);\n    assertEquals(new BytesRef(\"a\"), te.next());\n    final DocsAndPositionsEnum dpe = te.docsAndPositions(null, null);\n    assertEquals(0, dpe.nextDoc());\n    assertEquals(2, dpe.freq());\n    assertEquals(0, dpe.nextPosition());\n    assertEquals(0, dpe.startOffset());\n    final int endOffset = dpe.endOffset();\n    assertEquals(1 + positionGap, dpe.nextPosition());\n    assertEquals(1 + endOffset + offsetGap, dpe.endOffset());\n    assertEquals(null, te.next());\n    reader.close();\n    writer.close();\n    writer.w.getDirectory().close();\n  }\n\n","sourceOld":"  public void testChangeGaps() throws Exception {\n    // LUCENE-5324: check that it is possible to change the wrapper's gaps\n    final int positionGap = random().nextInt(1000);\n    final int offsetGap = random().nextInt(1000);\n    final Analyzer delegate = new MockAnalyzer(random());\n    final Analyzer a = new DelegatingAnalyzerWrapper(delegate.getReuseStrategy()) {\n      @Override\n      protected Analyzer getWrappedAnalyzer(String fieldName) {\n        return delegate;\n      }\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return positionGap;\n      }\n      @Override\n      public int getOffsetGap(String fieldName) {\n        return offsetGap;\n      }\n    };\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), newDirectory());\n    final Document doc = new Document();\n    final FieldType ft = new FieldType();\n    ft.setIndexOptions(IndexOptions.DOCS);\n    ft.setTokenized(true);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorPositions(true);\n    ft.setStoreTermVectorOffsets(true);\n    doc.add(new Field(\"f\", \"a\", ft));\n    doc.add(new Field(\"f\", \"a\", ft));\n    writer.addDocument(doc, a);\n    final LeafReader reader = getOnlySegmentReader(writer.getReader());\n    final Fields fields = reader.getTermVectors(0);\n    final Terms terms = fields.terms(\"f\");\n    final TermsEnum te = terms.iterator(null);\n    assertEquals(new BytesRef(\"a\"), te.next());\n    final DocsAndPositionsEnum dpe = te.docsAndPositions(null, null);\n    assertEquals(0, dpe.nextDoc());\n    assertEquals(2, dpe.freq());\n    assertEquals(0, dpe.nextPosition());\n    assertEquals(0, dpe.startOffset());\n    final int endOffset = dpe.endOffset();\n    assertEquals(1 + positionGap, dpe.nextPosition());\n    assertEquals(1 + endOffset + offsetGap, dpe.endOffset());\n    assertEquals(null, te.next());\n    reader.close();\n    writer.close();\n    writer.w.getDirectory().close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"51f5280f31484820499077f41fcdfe92d527d9dc","date":1423229122,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/analysis/TestMockAnalyzer#testChangeGaps().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/analysis/TestMockAnalyzer#testChangeGaps().mjava","sourceNew":"  public void testChangeGaps() throws Exception {\n    // LUCENE-5324: check that it is possible to change the wrapper's gaps\n    final int positionGap = random().nextInt(1000);\n    final int offsetGap = random().nextInt(1000);\n    final Analyzer delegate = new MockAnalyzer(random());\n    final Analyzer a = new DelegatingAnalyzerWrapper(delegate.getReuseStrategy()) {\n      @Override\n      protected Analyzer getWrappedAnalyzer(String fieldName) {\n        return delegate;\n      }\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return positionGap;\n      }\n      @Override\n      public int getOffsetGap(String fieldName) {\n        return offsetGap;\n      }\n    };\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), newDirectory(), a);\n    final Document doc = new Document();\n    final FieldType ft = new FieldType();\n    ft.setIndexOptions(IndexOptions.DOCS);\n    ft.setTokenized(true);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorPositions(true);\n    ft.setStoreTermVectorOffsets(true);\n    doc.add(new Field(\"f\", \"a\", ft));\n    doc.add(new Field(\"f\", \"a\", ft));\n    writer.addDocument(doc);\n    final LeafReader reader = getOnlySegmentReader(writer.getReader());\n    final Fields fields = reader.getTermVectors(0);\n    final Terms terms = fields.terms(\"f\");\n    final TermsEnum te = terms.iterator(null);\n    assertEquals(new BytesRef(\"a\"), te.next());\n    final PostingsEnum dpe = te.postings(null, null, PostingsEnum.FLAG_ALL);\n    assertEquals(0, dpe.nextDoc());\n    assertEquals(2, dpe.freq());\n    assertEquals(0, dpe.nextPosition());\n    assertEquals(0, dpe.startOffset());\n    final int endOffset = dpe.endOffset();\n    assertEquals(1 + positionGap, dpe.nextPosition());\n    assertEquals(1 + endOffset + offsetGap, dpe.endOffset());\n    assertEquals(null, te.next());\n    reader.close();\n    writer.close();\n    writer.w.getDirectory().close();\n  }\n\n","sourceOld":"  public void testChangeGaps() throws Exception {\n    // LUCENE-5324: check that it is possible to change the wrapper's gaps\n    final int positionGap = random().nextInt(1000);\n    final int offsetGap = random().nextInt(1000);\n    final Analyzer delegate = new MockAnalyzer(random());\n    final Analyzer a = new DelegatingAnalyzerWrapper(delegate.getReuseStrategy()) {\n      @Override\n      protected Analyzer getWrappedAnalyzer(String fieldName) {\n        return delegate;\n      }\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return positionGap;\n      }\n      @Override\n      public int getOffsetGap(String fieldName) {\n        return offsetGap;\n      }\n    };\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), newDirectory(), a);\n    final Document doc = new Document();\n    final FieldType ft = new FieldType();\n    ft.setIndexOptions(IndexOptions.DOCS);\n    ft.setTokenized(true);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorPositions(true);\n    ft.setStoreTermVectorOffsets(true);\n    doc.add(new Field(\"f\", \"a\", ft));\n    doc.add(new Field(\"f\", \"a\", ft));\n    writer.addDocument(doc);\n    final LeafReader reader = getOnlySegmentReader(writer.getReader());\n    final Fields fields = reader.getTermVectors(0);\n    final Terms terms = fields.terms(\"f\");\n    final TermsEnum te = terms.iterator(null);\n    assertEquals(new BytesRef(\"a\"), te.next());\n    final DocsAndPositionsEnum dpe = te.docsAndPositions(null, null);\n    assertEquals(0, dpe.nextDoc());\n    assertEquals(2, dpe.freq());\n    assertEquals(0, dpe.nextPosition());\n    assertEquals(0, dpe.startOffset());\n    final int endOffset = dpe.endOffset();\n    assertEquals(1 + positionGap, dpe.nextPosition());\n    assertEquals(1 + endOffset + offsetGap, dpe.endOffset());\n    assertEquals(null, te.next());\n    reader.close();\n    writer.close();\n    writer.w.getDirectory().close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e73063b92d958076ef4ae8beb5f493e8ccdcecb4","date":1424177215,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/analysis/TestMockAnalyzer#testChangeGaps().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/analysis/TestMockAnalyzer#testChangeGaps().mjava","sourceNew":"  public void testChangeGaps() throws Exception {\n    // LUCENE-5324: check that it is possible to change the wrapper's gaps\n    final int positionGap = random().nextInt(1000);\n    final int offsetGap = random().nextInt(1000);\n    final Analyzer delegate = new MockAnalyzer(random());\n    final Analyzer a = new DelegatingAnalyzerWrapper(delegate.getReuseStrategy()) {\n      @Override\n      protected Analyzer getWrappedAnalyzer(String fieldName) {\n        return delegate;\n      }\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return positionGap;\n      }\n      @Override\n      public int getOffsetGap(String fieldName) {\n        return offsetGap;\n      }\n    };\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), newDirectory(), a);\n    final Document doc = new Document();\n    final FieldType ft = new FieldType();\n    ft.setIndexOptions(IndexOptions.DOCS);\n    ft.setTokenized(true);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorPositions(true);\n    ft.setStoreTermVectorOffsets(true);\n    doc.add(new Field(\"f\", \"a\", ft));\n    doc.add(new Field(\"f\", \"a\", ft));\n    writer.addDocument(doc);\n    final LeafReader reader = getOnlySegmentReader(writer.getReader());\n    final Fields fields = reader.getTermVectors(0);\n    final Terms terms = fields.terms(\"f\");\n    final TermsEnum te = terms.iterator(null);\n    assertEquals(new BytesRef(\"a\"), te.next());\n    final PostingsEnum dpe = te.postings(null, null, PostingsEnum.ALL);\n    assertEquals(0, dpe.nextDoc());\n    assertEquals(2, dpe.freq());\n    assertEquals(0, dpe.nextPosition());\n    assertEquals(0, dpe.startOffset());\n    final int endOffset = dpe.endOffset();\n    assertEquals(1 + positionGap, dpe.nextPosition());\n    assertEquals(1 + endOffset + offsetGap, dpe.endOffset());\n    assertEquals(null, te.next());\n    reader.close();\n    writer.close();\n    writer.w.getDirectory().close();\n  }\n\n","sourceOld":"  public void testChangeGaps() throws Exception {\n    // LUCENE-5324: check that it is possible to change the wrapper's gaps\n    final int positionGap = random().nextInt(1000);\n    final int offsetGap = random().nextInt(1000);\n    final Analyzer delegate = new MockAnalyzer(random());\n    final Analyzer a = new DelegatingAnalyzerWrapper(delegate.getReuseStrategy()) {\n      @Override\n      protected Analyzer getWrappedAnalyzer(String fieldName) {\n        return delegate;\n      }\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return positionGap;\n      }\n      @Override\n      public int getOffsetGap(String fieldName) {\n        return offsetGap;\n      }\n    };\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), newDirectory(), a);\n    final Document doc = new Document();\n    final FieldType ft = new FieldType();\n    ft.setIndexOptions(IndexOptions.DOCS);\n    ft.setTokenized(true);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorPositions(true);\n    ft.setStoreTermVectorOffsets(true);\n    doc.add(new Field(\"f\", \"a\", ft));\n    doc.add(new Field(\"f\", \"a\", ft));\n    writer.addDocument(doc);\n    final LeafReader reader = getOnlySegmentReader(writer.getReader());\n    final Fields fields = reader.getTermVectors(0);\n    final Terms terms = fields.terms(\"f\");\n    final TermsEnum te = terms.iterator(null);\n    assertEquals(new BytesRef(\"a\"), te.next());\n    final PostingsEnum dpe = te.postings(null, null, PostingsEnum.FLAG_ALL);\n    assertEquals(0, dpe.nextDoc());\n    assertEquals(2, dpe.freq());\n    assertEquals(0, dpe.nextPosition());\n    assertEquals(0, dpe.startOffset());\n    final int endOffset = dpe.endOffset();\n    assertEquals(1 + positionGap, dpe.nextPosition());\n    assertEquals(1 + endOffset + offsetGap, dpe.endOffset());\n    assertEquals(null, te.next());\n    reader.close();\n    writer.close();\n    writer.w.getDirectory().close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82","date":1428522487,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/analysis/TestMockAnalyzer#testChangeGaps().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/analysis/TestMockAnalyzer#testChangeGaps().mjava","sourceNew":"  public void testChangeGaps() throws Exception {\n    // LUCENE-5324: check that it is possible to change the wrapper's gaps\n    final int positionGap = random().nextInt(1000);\n    final int offsetGap = random().nextInt(1000);\n    final Analyzer delegate = new MockAnalyzer(random());\n    final Analyzer a = new DelegatingAnalyzerWrapper(delegate.getReuseStrategy()) {\n      @Override\n      protected Analyzer getWrappedAnalyzer(String fieldName) {\n        return delegate;\n      }\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return positionGap;\n      }\n      @Override\n      public int getOffsetGap(String fieldName) {\n        return offsetGap;\n      }\n    };\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), newDirectory(), a);\n    final Document doc = new Document();\n    final FieldType ft = new FieldType();\n    ft.setIndexOptions(IndexOptions.DOCS);\n    ft.setTokenized(true);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorPositions(true);\n    ft.setStoreTermVectorOffsets(true);\n    doc.add(new Field(\"f\", \"a\", ft));\n    doc.add(new Field(\"f\", \"a\", ft));\n    writer.addDocument(doc);\n    final LeafReader reader = getOnlySegmentReader(writer.getReader());\n    final Fields fields = reader.getTermVectors(0);\n    final Terms terms = fields.terms(\"f\");\n    final TermsEnum te = terms.iterator();\n    assertEquals(new BytesRef(\"a\"), te.next());\n    final PostingsEnum dpe = te.postings(null, null, PostingsEnum.ALL);\n    assertEquals(0, dpe.nextDoc());\n    assertEquals(2, dpe.freq());\n    assertEquals(0, dpe.nextPosition());\n    assertEquals(0, dpe.startOffset());\n    final int endOffset = dpe.endOffset();\n    assertEquals(1 + positionGap, dpe.nextPosition());\n    assertEquals(1 + endOffset + offsetGap, dpe.endOffset());\n    assertEquals(null, te.next());\n    reader.close();\n    writer.close();\n    writer.w.getDirectory().close();\n  }\n\n","sourceOld":"  public void testChangeGaps() throws Exception {\n    // LUCENE-5324: check that it is possible to change the wrapper's gaps\n    final int positionGap = random().nextInt(1000);\n    final int offsetGap = random().nextInt(1000);\n    final Analyzer delegate = new MockAnalyzer(random());\n    final Analyzer a = new DelegatingAnalyzerWrapper(delegate.getReuseStrategy()) {\n      @Override\n      protected Analyzer getWrappedAnalyzer(String fieldName) {\n        return delegate;\n      }\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return positionGap;\n      }\n      @Override\n      public int getOffsetGap(String fieldName) {\n        return offsetGap;\n      }\n    };\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), newDirectory(), a);\n    final Document doc = new Document();\n    final FieldType ft = new FieldType();\n    ft.setIndexOptions(IndexOptions.DOCS);\n    ft.setTokenized(true);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorPositions(true);\n    ft.setStoreTermVectorOffsets(true);\n    doc.add(new Field(\"f\", \"a\", ft));\n    doc.add(new Field(\"f\", \"a\", ft));\n    writer.addDocument(doc);\n    final LeafReader reader = getOnlySegmentReader(writer.getReader());\n    final Fields fields = reader.getTermVectors(0);\n    final Terms terms = fields.terms(\"f\");\n    final TermsEnum te = terms.iterator(null);\n    assertEquals(new BytesRef(\"a\"), te.next());\n    final PostingsEnum dpe = te.postings(null, null, PostingsEnum.ALL);\n    assertEquals(0, dpe.nextDoc());\n    assertEquals(2, dpe.freq());\n    assertEquals(0, dpe.nextPosition());\n    assertEquals(0, dpe.startOffset());\n    final int endOffset = dpe.endOffset();\n    assertEquals(1 + positionGap, dpe.nextPosition());\n    assertEquals(1 + endOffset + offsetGap, dpe.endOffset());\n    assertEquals(null, te.next());\n    reader.close();\n    writer.close();\n    writer.w.getDirectory().close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b52491e71f0d5d0f0160d6ed0d39e0dd661be68a","date":1429550638,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/test-framework/src/test/org/apache/lucene/analysis/TestMockAnalyzer#testChangeGaps().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/analysis/TestMockAnalyzer#testChangeGaps().mjava","sourceNew":"  public void testChangeGaps() throws Exception {\n    // LUCENE-5324: check that it is possible to change the wrapper's gaps\n    final int positionGap = random().nextInt(1000);\n    final int offsetGap = random().nextInt(1000);\n    final Analyzer delegate = new MockAnalyzer(random());\n    final Analyzer a = new DelegatingAnalyzerWrapper(delegate.getReuseStrategy()) {\n      @Override\n      protected Analyzer getWrappedAnalyzer(String fieldName) {\n        return delegate;\n      }\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return positionGap;\n      }\n      @Override\n      public int getOffsetGap(String fieldName) {\n        return offsetGap;\n      }\n    };\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), newDirectory(), a);\n    final Document doc = new Document();\n    final FieldType ft = new FieldType();\n    ft.setIndexOptions(IndexOptions.DOCS);\n    ft.setTokenized(true);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorPositions(true);\n    ft.setStoreTermVectorOffsets(true);\n    doc.add(new Field(\"f\", \"a\", ft));\n    doc.add(new Field(\"f\", \"a\", ft));\n    writer.addDocument(doc);\n    final LeafReader reader = getOnlySegmentReader(writer.getReader());\n    final Fields fields = reader.getTermVectors(0);\n    final Terms terms = fields.terms(\"f\");\n    final TermsEnum te = terms.iterator();\n    assertEquals(new BytesRef(\"a\"), te.next());\n    final PostingsEnum dpe = te.postings(null, null, PostingsEnum.ALL);\n    assertEquals(0, dpe.nextDoc());\n    assertEquals(2, dpe.freq());\n    assertEquals(0, dpe.nextPosition());\n    assertEquals(0, dpe.startOffset());\n    final int endOffset = dpe.endOffset();\n    assertEquals(1 + positionGap, dpe.nextPosition());\n    assertEquals(1 + endOffset + offsetGap, dpe.endOffset());\n    assertEquals(null, te.next());\n    reader.close();\n    writer.close();\n    writer.w.getDirectory().close();\n  }\n\n","sourceOld":"  public void testChangeGaps() throws Exception {\n    // LUCENE-5324: check that it is possible to change the wrapper's gaps\n    final int positionGap = random().nextInt(1000);\n    final int offsetGap = random().nextInt(1000);\n    final Analyzer delegate = new MockAnalyzer(random());\n    final Analyzer a = new DelegatingAnalyzerWrapper(delegate.getReuseStrategy()) {\n      @Override\n      protected Analyzer getWrappedAnalyzer(String fieldName) {\n        return delegate;\n      }\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return positionGap;\n      }\n      @Override\n      public int getOffsetGap(String fieldName) {\n        return offsetGap;\n      }\n    };\n\n    final RandomIndexWriter writer = new RandomIndexWriter(random(), newDirectory(), a);\n    final Document doc = new Document();\n    final FieldType ft = new FieldType();\n    ft.setIndexOptions(IndexOptions.DOCS);\n    ft.setTokenized(true);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorPositions(true);\n    ft.setStoreTermVectorOffsets(true);\n    doc.add(new Field(\"f\", \"a\", ft));\n    doc.add(new Field(\"f\", \"a\", ft));\n    writer.addDocument(doc);\n    final LeafReader reader = getOnlySegmentReader(writer.getReader());\n    final Fields fields = reader.getTermVectors(0);\n    final Terms terms = fields.terms(\"f\");\n    final TermsEnum te = terms.iterator();\n    assertEquals(new BytesRef(\"a\"), te.next());\n    final PostingsEnum dpe = te.postings(null, null, PostingsEnum.ALL);\n    assertEquals(0, dpe.nextDoc());\n    assertEquals(2, dpe.freq());\n    assertEquals(0, dpe.nextPosition());\n    assertEquals(0, dpe.startOffset());\n    final int endOffset = dpe.endOffset();\n    assertEquals(1 + positionGap, dpe.nextPosition());\n    assertEquals(1 + endOffset + offsetGap, dpe.endOffset());\n    assertEquals(null, te.next());\n    reader.close();\n    writer.close();\n    writer.w.getDirectory().close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82":["e73063b92d958076ef4ae8beb5f493e8ccdcecb4"],"fa1d846349fbfeb8946cba47ab179b4878a6b2e0":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"2bb2842e561df4e8e9ad89010605fc86ac265465":["3184874f7f3aca850248483485b4995343066875"],"b52491e71f0d5d0f0160d6ed0d39e0dd661be68a":["0a773283ef5eab2e9c7136eeb66574a4b7a2dc82"],"d233139eaa55e91b9340518db818b712a7b0f4de":["fa1d846349fbfeb8946cba47ab179b4878a6b2e0"],"51f5280f31484820499077f41fcdfe92d527d9dc":["5c1c5aa8e88aa52c9e1cbfc696b611d3a56223c0"],"3184874f7f3aca850248483485b4995343066875":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"5c1c5aa8e88aa52c9e1cbfc696b611d3a56223c0":["2bb2842e561df4e8e9ad89010605fc86ac265465"],"e73063b92d958076ef4ae8beb5f493e8ccdcecb4":["51f5280f31484820499077f41fcdfe92d527d9dc"],"0a22eafe3f72a4c2945eaad9547e6c78816978f4":["c9fb5f46e264daf5ba3860defe623a89d202dd87","3184874f7f3aca850248483485b4995343066875"],"6e6076d5869e894e98558285d9c9be9179d93921":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["6e6076d5869e894e98558285d9c9be9179d93921"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["d233139eaa55e91b9340518db818b712a7b0f4de"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b52491e71f0d5d0f0160d6ed0d39e0dd661be68a"]},"commit2Childs":{"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82":["b52491e71f0d5d0f0160d6ed0d39e0dd661be68a"],"fa1d846349fbfeb8946cba47ab179b4878a6b2e0":["d233139eaa55e91b9340518db818b712a7b0f4de"],"2bb2842e561df4e8e9ad89010605fc86ac265465":["5c1c5aa8e88aa52c9e1cbfc696b611d3a56223c0"],"b52491e71f0d5d0f0160d6ed0d39e0dd661be68a":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"d233139eaa55e91b9340518db818b712a7b0f4de":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"51f5280f31484820499077f41fcdfe92d527d9dc":["e73063b92d958076ef4ae8beb5f493e8ccdcecb4"],"3184874f7f3aca850248483485b4995343066875":["2bb2842e561df4e8e9ad89010605fc86ac265465","0a22eafe3f72a4c2945eaad9547e6c78816978f4"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["3184874f7f3aca850248483485b4995343066875","0a22eafe3f72a4c2945eaad9547e6c78816978f4"],"5c1c5aa8e88aa52c9e1cbfc696b611d3a56223c0":["51f5280f31484820499077f41fcdfe92d527d9dc"],"e73063b92d958076ef4ae8beb5f493e8ccdcecb4":["0a773283ef5eab2e9c7136eeb66574a4b7a2dc82"],"0a22eafe3f72a4c2945eaad9547e6c78816978f4":[],"6e6076d5869e894e98558285d9c9be9179d93921":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["fa1d846349fbfeb8946cba47ab179b4878a6b2e0"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["6e6076d5869e894e98558285d9c9be9179d93921"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["0a22eafe3f72a4c2945eaad9547e6c78816978f4","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}