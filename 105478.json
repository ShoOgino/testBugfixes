{"path":"solr/core/src/test/org/apache/solr/cloud/DistribJoinFromCollectionTest#test().mjava","commits":[{"id":"da22fc4f0d847980f460da30f3b68afbf2249d70","date":1422932846,"type":0,"author":"Timothy Potter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/DistribJoinFromCollectionTest#test().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void test() throws Exception {\n    // create a collection holding data for the \"to\" side of the JOIN\n    String toColl = \"to_2x2\";\n    createCollection(toColl, 2, 2, 2);\n    ensureAllReplicasAreActive(toColl, \"shard1\", 2, 2, 30);\n    ensureAllReplicasAreActive(toColl, \"shard2\", 2, 2, 30);\n\n    // get the set of nodes where replicas for the \"to\" collection exist\n    Set<String> nodeSet = new HashSet<>();\n    ClusterState cs = cloudClient.getZkStateReader().getClusterState();\n    for (Slice slice : cs.getActiveSlices(toColl))\n      for (Replica replica : slice.getReplicas())\n        nodeSet.add(replica.getNodeName());\n    assertTrue(nodeSet.size() > 0);\n\n    // deploy the \"from\" collection to all nodes where the \"to\" collection exists\n    String fromColl = \"from_1x2\";\n    createCollection(null, fromColl, 1, nodeSet.size(), 1, null, StringUtils.join(nodeSet,\",\"));\n    ensureAllReplicasAreActive(fromColl, \"shard1\", 1, nodeSet.size(), 30);\n\n    // both to and from collections are up and active, index some docs ...\n    Integer toDocId = indexDoc(toColl, 1001, \"a\", null, \"b\");\n    indexDoc(fromColl, 2001, \"a\", \"c\", null);\n\n    Thread.sleep(1000); // so the commits fire\n\n    // verify the join with fromIndex works\n    String joinQ = \"{!join from=join_s fromIndex=\"+fromColl+\" to=join_s}match_s:c\";\n    QueryRequest qr = new QueryRequest(params(\"collection\", toColl, \"q\", joinQ, \"fl\", \"id,get_s\"));\n    QueryResponse rsp = new QueryResponse(cloudClient.request(qr), cloudClient);\n    SolrDocumentList hits = rsp.getResults();\n    assertTrue(\"Expected 1 doc\", hits.getNumFound() == 1);\n    SolrDocument doc = hits.get(0);\n    assertEquals(toDocId, doc.getFirstValue(\"id\"));\n    assertEquals(\"b\", doc.getFirstValue(\"get_s\"));\n\n    // create an alias for the fromIndex and then query through the alias\n    String alias = fromColl+\"Alias\";\n    CollectionAdminRequest.CreateAlias request = new CollectionAdminRequest.CreateAlias();\n    request.setAliasName(alias);\n    request.setAliasedCollections(fromColl);\n    request.process(cloudClient);\n\n    joinQ = \"{!join from=join_s fromIndex=\"+alias+\" to=join_s}match_s:c\";\n    qr = new QueryRequest(params(\"collection\", toColl, \"q\", joinQ, \"fl\", \"id,get_s\"));\n    rsp = new QueryResponse(cloudClient.request(qr), cloudClient);\n    hits = rsp.getResults();\n    assertTrue(\"Expected 1 doc\", hits.getNumFound() == 1);\n    doc = hits.get(0);\n    assertEquals(toDocId, doc.getFirstValue(\"id\"));\n    assertEquals(\"b\", doc.getFirstValue(\"get_s\"));\n\n    // verify join doesn't work if no match in the \"from\" index\n    joinQ = \"{!join from=join_s fromIndex=\"+fromColl+\" to=join_s}match_s:d\";\n    qr = new QueryRequest(params(\"collection\", toColl, \"q\", joinQ, \"fl\", \"id,get_s\"));\n    rsp = new QueryResponse(cloudClient.request(qr), cloudClient);\n    hits = rsp.getResults();\n    assertTrue(\"Expected no hits\", hits.getNumFound() == 0);\n\n    log.info(\"DistribJoinFromCollectionTest logic complete ... deleting the \" + toColl + \" and \" + fromColl + \" collections\");\n\n    // try to clean up\n    for (String c : new String[]{ toColl, fromColl }) {\n      try {\n        CollectionAdminRequest.Delete req = new CollectionAdminRequest.Delete();\n        req.setCollectionName(c);\n        req.process(cloudClient);\n      } catch (Exception e) {\n        // don't fail the test\n        log.warn(\"Could not delete collection {} after test completed due to: \"+e, c);\n      }\n    }\n\n    log.info(\"DistribJoinFromCollectionTest succeeded ... shutting down now!\");\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"182acd29cf4cb1644a02b8517f3a5b867c0d7cce","date":1432665213,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/DistribJoinFromCollectionTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/DistribJoinFromCollectionTest#test().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n    // create a collection holding data for the \"to\" side of the JOIN\n    String toColl = \"to_2x2\";\n    createCollection(toColl, 2, 2, 2);\n    ensureAllReplicasAreActive(toColl, \"shard1\", 2, 2, 30);\n    ensureAllReplicasAreActive(toColl, \"shard2\", 2, 2, 30);\n\n    // get the set of nodes where replicas for the \"to\" collection exist\n    Set<String> nodeSet = new HashSet<>();\n    ClusterState cs = cloudClient.getZkStateReader().getClusterState();\n    for (Slice slice : cs.getActiveSlices(toColl))\n      for (Replica replica : slice.getReplicas())\n        nodeSet.add(replica.getNodeName());\n    assertTrue(nodeSet.size() > 0);\n\n    // deploy the \"from\" collection to all nodes where the \"to\" collection exists\n    String fromColl = \"from_1x2\";\n    createCollection(null, fromColl, 1, nodeSet.size(), 1, null, StringUtils.join(nodeSet,\",\"));\n    ensureAllReplicasAreActive(fromColl, \"shard1\", 1, nodeSet.size(), 30);\n\n    // both to and from collections are up and active, index some docs ...\n    Integer toDocId = indexDoc(toColl, 1001, \"a\", null, \"b\");\n    indexDoc(fromColl, 2001, \"a\", \"c\", null);\n\n    Thread.sleep(1000); // so the commits fire\n\n    // verify the join with fromIndex works\n    String joinQ = \"{!join from=join_s fromIndex=\"+fromColl+\" to=join_s}match_s:c\";\n    QueryRequest qr = new QueryRequest(params(\"collection\", toColl, \"q\", joinQ, \"fl\", \"id,get_s\"));\n    QueryResponse rsp = new QueryResponse(cloudClient.request(qr), cloudClient);\n    SolrDocumentList hits = rsp.getResults();\n    assertTrue(\"Expected 1 doc\", hits.getNumFound() == 1);\n    SolrDocument doc = hits.get(0);\n    assertEquals(toDocId, doc.getFirstValue(\"id\"));\n    assertEquals(\"b\", doc.getFirstValue(\"get_s\"));\n\n    // create an alias for the fromIndex and then query through the alias\n    String alias = fromColl+\"Alias\";\n    CollectionAdminRequest.CreateAlias request = new CollectionAdminRequest.CreateAlias();\n    request.setAliasName(alias);\n    request.setAliasedCollections(fromColl);\n    request.process(cloudClient);\n\n    joinQ = \"{!join from=join_s fromIndex=\"+alias+\" to=join_s}match_s:c\";\n    qr = new QueryRequest(params(\"collection\", toColl, \"q\", joinQ, \"fl\", \"id,get_s\"));\n    rsp = new QueryResponse(cloudClient.request(qr), cloudClient);\n    hits = rsp.getResults();\n    assertTrue(\"Expected 1 doc\", hits.getNumFound() == 1);\n    doc = hits.get(0);\n    assertEquals(toDocId, doc.getFirstValue(\"id\"));\n    assertEquals(\"b\", doc.getFirstValue(\"get_s\"));\n\n    // verify join doesn't work if no match in the \"from\" index\n    joinQ = \"{!join from=join_s fromIndex=\"+fromColl+\" to=join_s}match_s:d\";\n    qr = new QueryRequest(params(\"collection\", toColl, \"q\", joinQ, \"fl\", \"id,get_s\"));\n    rsp = new QueryResponse(cloudClient.request(qr), cloudClient);\n    hits = rsp.getResults();\n    assertTrue(\"Expected no hits\", hits.getNumFound() == 0);\n\n    log.info(\"DistribJoinFromCollectionTest logic complete ... deleting the \" + toColl + \" and \" + fromColl + \" collections\");\n\n    // try to clean up\n    for (String c : new String[]{ toColl, fromColl }) {\n      try {\n        CollectionAdminRequest.Delete req = new CollectionAdminRequest.Delete()\n                .setCollectionName(c);\n        req.process(cloudClient);\n      } catch (Exception e) {\n        // don't fail the test\n        log.warn(\"Could not delete collection {} after test completed due to: \"+e, c);\n      }\n    }\n\n    log.info(\"DistribJoinFromCollectionTest succeeded ... shutting down now!\");\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n    // create a collection holding data for the \"to\" side of the JOIN\n    String toColl = \"to_2x2\";\n    createCollection(toColl, 2, 2, 2);\n    ensureAllReplicasAreActive(toColl, \"shard1\", 2, 2, 30);\n    ensureAllReplicasAreActive(toColl, \"shard2\", 2, 2, 30);\n\n    // get the set of nodes where replicas for the \"to\" collection exist\n    Set<String> nodeSet = new HashSet<>();\n    ClusterState cs = cloudClient.getZkStateReader().getClusterState();\n    for (Slice slice : cs.getActiveSlices(toColl))\n      for (Replica replica : slice.getReplicas())\n        nodeSet.add(replica.getNodeName());\n    assertTrue(nodeSet.size() > 0);\n\n    // deploy the \"from\" collection to all nodes where the \"to\" collection exists\n    String fromColl = \"from_1x2\";\n    createCollection(null, fromColl, 1, nodeSet.size(), 1, null, StringUtils.join(nodeSet,\",\"));\n    ensureAllReplicasAreActive(fromColl, \"shard1\", 1, nodeSet.size(), 30);\n\n    // both to and from collections are up and active, index some docs ...\n    Integer toDocId = indexDoc(toColl, 1001, \"a\", null, \"b\");\n    indexDoc(fromColl, 2001, \"a\", \"c\", null);\n\n    Thread.sleep(1000); // so the commits fire\n\n    // verify the join with fromIndex works\n    String joinQ = \"{!join from=join_s fromIndex=\"+fromColl+\" to=join_s}match_s:c\";\n    QueryRequest qr = new QueryRequest(params(\"collection\", toColl, \"q\", joinQ, \"fl\", \"id,get_s\"));\n    QueryResponse rsp = new QueryResponse(cloudClient.request(qr), cloudClient);\n    SolrDocumentList hits = rsp.getResults();\n    assertTrue(\"Expected 1 doc\", hits.getNumFound() == 1);\n    SolrDocument doc = hits.get(0);\n    assertEquals(toDocId, doc.getFirstValue(\"id\"));\n    assertEquals(\"b\", doc.getFirstValue(\"get_s\"));\n\n    // create an alias for the fromIndex and then query through the alias\n    String alias = fromColl+\"Alias\";\n    CollectionAdminRequest.CreateAlias request = new CollectionAdminRequest.CreateAlias();\n    request.setAliasName(alias);\n    request.setAliasedCollections(fromColl);\n    request.process(cloudClient);\n\n    joinQ = \"{!join from=join_s fromIndex=\"+alias+\" to=join_s}match_s:c\";\n    qr = new QueryRequest(params(\"collection\", toColl, \"q\", joinQ, \"fl\", \"id,get_s\"));\n    rsp = new QueryResponse(cloudClient.request(qr), cloudClient);\n    hits = rsp.getResults();\n    assertTrue(\"Expected 1 doc\", hits.getNumFound() == 1);\n    doc = hits.get(0);\n    assertEquals(toDocId, doc.getFirstValue(\"id\"));\n    assertEquals(\"b\", doc.getFirstValue(\"get_s\"));\n\n    // verify join doesn't work if no match in the \"from\" index\n    joinQ = \"{!join from=join_s fromIndex=\"+fromColl+\" to=join_s}match_s:d\";\n    qr = new QueryRequest(params(\"collection\", toColl, \"q\", joinQ, \"fl\", \"id,get_s\"));\n    rsp = new QueryResponse(cloudClient.request(qr), cloudClient);\n    hits = rsp.getResults();\n    assertTrue(\"Expected no hits\", hits.getNumFound() == 0);\n\n    log.info(\"DistribJoinFromCollectionTest logic complete ... deleting the \" + toColl + \" and \" + fromColl + \" collections\");\n\n    // try to clean up\n    for (String c : new String[]{ toColl, fromColl }) {\n      try {\n        CollectionAdminRequest.Delete req = new CollectionAdminRequest.Delete();\n        req.setCollectionName(c);\n        req.process(cloudClient);\n      } catch (Exception e) {\n        // don't fail the test\n        log.warn(\"Could not delete collection {} after test completed due to: \"+e, c);\n      }\n    }\n\n    log.info(\"DistribJoinFromCollectionTest succeeded ... shutting down now!\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"118ba480e87dfe453a6b47a320429be33f1d1653","date":1440320558,"type":3,"author":"Mikhail Khludnev","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/DistribJoinFromCollectionTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/DistribJoinFromCollectionTest#test().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n    // create a collection holding data for the \"to\" side of the JOIN\n    String toColl = \"to_2x2\";\n    createCollection(toColl, 2, 2, 2);\n    ensureAllReplicasAreActive(toColl, \"shard1\", 2, 2, 30);\n    ensureAllReplicasAreActive(toColl, \"shard2\", 2, 2, 30);\n\n    // get the set of nodes where replicas for the \"to\" collection exist\n    Set<String> nodeSet = new HashSet<>();\n    ClusterState cs = cloudClient.getZkStateReader().getClusterState();\n    for (Slice slice : cs.getActiveSlices(toColl))\n      for (Replica replica : slice.getReplicas())\n        nodeSet.add(replica.getNodeName());\n    assertTrue(nodeSet.size() > 0);\n\n    // deploy the \"from\" collection to all nodes where the \"to\" collection exists\n    String fromColl = \"from_1x2\";\n    createCollection(null, fromColl, 1, nodeSet.size(), 1, null, StringUtils.join(nodeSet,\",\"));\n    ensureAllReplicasAreActive(fromColl, \"shard1\", 1, nodeSet.size(), 30);\n\n    // both to and from collections are up and active, index some docs ...\n    Integer toDocId = indexDoc(toColl, 1001, \"a\", null, \"b\");\n    indexDoc(fromColl, 2001, \"a\", \"c\", null);\n\n    Thread.sleep(1000); // so the commits fire\n\n    //without score\n    testJoins(toColl, fromColl, toDocId, false);\n\n    //with score\n    testJoins(toColl, fromColl, toDocId, true);\n\n    log.info(\"DistribJoinFromCollectionTest logic complete ... deleting the \" + toColl + \" and \" + fromColl + \" collections\");\n\n    // try to clean up\n    for (String c : new String[]{ toColl, fromColl }) {\n      try {\n        CollectionAdminRequest.Delete req = new CollectionAdminRequest.Delete()\n                .setCollectionName(c);\n        req.process(cloudClient);\n      } catch (Exception e) {\n        // don't fail the test\n        log.warn(\"Could not delete collection {} after test completed due to: \" + e, c);\n      }\n    }\n\n    log.info(\"DistribJoinFromCollectionTest succeeded ... shutting down now!\");\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n    // create a collection holding data for the \"to\" side of the JOIN\n    String toColl = \"to_2x2\";\n    createCollection(toColl, 2, 2, 2);\n    ensureAllReplicasAreActive(toColl, \"shard1\", 2, 2, 30);\n    ensureAllReplicasAreActive(toColl, \"shard2\", 2, 2, 30);\n\n    // get the set of nodes where replicas for the \"to\" collection exist\n    Set<String> nodeSet = new HashSet<>();\n    ClusterState cs = cloudClient.getZkStateReader().getClusterState();\n    for (Slice slice : cs.getActiveSlices(toColl))\n      for (Replica replica : slice.getReplicas())\n        nodeSet.add(replica.getNodeName());\n    assertTrue(nodeSet.size() > 0);\n\n    // deploy the \"from\" collection to all nodes where the \"to\" collection exists\n    String fromColl = \"from_1x2\";\n    createCollection(null, fromColl, 1, nodeSet.size(), 1, null, StringUtils.join(nodeSet,\",\"));\n    ensureAllReplicasAreActive(fromColl, \"shard1\", 1, nodeSet.size(), 30);\n\n    // both to and from collections are up and active, index some docs ...\n    Integer toDocId = indexDoc(toColl, 1001, \"a\", null, \"b\");\n    indexDoc(fromColl, 2001, \"a\", \"c\", null);\n\n    Thread.sleep(1000); // so the commits fire\n\n    // verify the join with fromIndex works\n    String joinQ = \"{!join from=join_s fromIndex=\"+fromColl+\" to=join_s}match_s:c\";\n    QueryRequest qr = new QueryRequest(params(\"collection\", toColl, \"q\", joinQ, \"fl\", \"id,get_s\"));\n    QueryResponse rsp = new QueryResponse(cloudClient.request(qr), cloudClient);\n    SolrDocumentList hits = rsp.getResults();\n    assertTrue(\"Expected 1 doc\", hits.getNumFound() == 1);\n    SolrDocument doc = hits.get(0);\n    assertEquals(toDocId, doc.getFirstValue(\"id\"));\n    assertEquals(\"b\", doc.getFirstValue(\"get_s\"));\n\n    // create an alias for the fromIndex and then query through the alias\n    String alias = fromColl+\"Alias\";\n    CollectionAdminRequest.CreateAlias request = new CollectionAdminRequest.CreateAlias();\n    request.setAliasName(alias);\n    request.setAliasedCollections(fromColl);\n    request.process(cloudClient);\n\n    joinQ = \"{!join from=join_s fromIndex=\"+alias+\" to=join_s}match_s:c\";\n    qr = new QueryRequest(params(\"collection\", toColl, \"q\", joinQ, \"fl\", \"id,get_s\"));\n    rsp = new QueryResponse(cloudClient.request(qr), cloudClient);\n    hits = rsp.getResults();\n    assertTrue(\"Expected 1 doc\", hits.getNumFound() == 1);\n    doc = hits.get(0);\n    assertEquals(toDocId, doc.getFirstValue(\"id\"));\n    assertEquals(\"b\", doc.getFirstValue(\"get_s\"));\n\n    // verify join doesn't work if no match in the \"from\" index\n    joinQ = \"{!join from=join_s fromIndex=\"+fromColl+\" to=join_s}match_s:d\";\n    qr = new QueryRequest(params(\"collection\", toColl, \"q\", joinQ, \"fl\", \"id,get_s\"));\n    rsp = new QueryResponse(cloudClient.request(qr), cloudClient);\n    hits = rsp.getResults();\n    assertTrue(\"Expected no hits\", hits.getNumFound() == 0);\n\n    log.info(\"DistribJoinFromCollectionTest logic complete ... deleting the \" + toColl + \" and \" + fromColl + \" collections\");\n\n    // try to clean up\n    for (String c : new String[]{ toColl, fromColl }) {\n      try {\n        CollectionAdminRequest.Delete req = new CollectionAdminRequest.Delete()\n                .setCollectionName(c);\n        req.process(cloudClient);\n      } catch (Exception e) {\n        // don't fail the test\n        log.warn(\"Could not delete collection {} after test completed due to: \"+e, c);\n      }\n    }\n\n    log.info(\"DistribJoinFromCollectionTest succeeded ... shutting down now!\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"da83c90417e805f2b355afc2d79f4d2b2ce27469","date":1464346037,"type":4,"author":"Mikhail Khludnev","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/core/src/test/org/apache/solr/cloud/DistribJoinFromCollectionTest#test().mjava","sourceNew":null,"sourceOld":"  @Test\n  public void test() throws Exception {\n    // create a collection holding data for the \"to\" side of the JOIN\n    String toColl = \"to_2x2\";\n    createCollection(toColl, 2, 2, 2);\n    ensureAllReplicasAreActive(toColl, \"shard1\", 2, 2, 30);\n    ensureAllReplicasAreActive(toColl, \"shard2\", 2, 2, 30);\n\n    // get the set of nodes where replicas for the \"to\" collection exist\n    Set<String> nodeSet = new HashSet<>();\n    ClusterState cs = cloudClient.getZkStateReader().getClusterState();\n    for (Slice slice : cs.getActiveSlices(toColl))\n      for (Replica replica : slice.getReplicas())\n        nodeSet.add(replica.getNodeName());\n    assertTrue(nodeSet.size() > 0);\n\n    // deploy the \"from\" collection to all nodes where the \"to\" collection exists\n    String fromColl = \"from_1x2\";\n    createCollection(null, fromColl, 1, nodeSet.size(), 1, null, StringUtils.join(nodeSet,\",\"));\n    ensureAllReplicasAreActive(fromColl, \"shard1\", 1, nodeSet.size(), 30);\n\n    // both to and from collections are up and active, index some docs ...\n    Integer toDocId = indexDoc(toColl, 1001, \"a\", null, \"b\");\n    indexDoc(fromColl, 2001, \"a\", \"c\", null);\n\n    Thread.sleep(1000); // so the commits fire\n\n    //without score\n    testJoins(toColl, fromColl, toDocId, false);\n\n    //with score\n    testJoins(toColl, fromColl, toDocId, true);\n\n    log.info(\"DistribJoinFromCollectionTest logic complete ... deleting the \" + toColl + \" and \" + fromColl + \" collections\");\n\n    // try to clean up\n    for (String c : new String[]{ toColl, fromColl }) {\n      try {\n        CollectionAdminRequest.Delete req = new CollectionAdminRequest.Delete()\n                .setCollectionName(c);\n        req.process(cloudClient);\n      } catch (Exception e) {\n        // don't fail the test\n        log.warn(\"Could not delete collection {} after test completed due to: \" + e, c);\n      }\n    }\n\n    log.info(\"DistribJoinFromCollectionTest succeeded ... shutting down now!\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"da8a02bef7458089240404614139b53c9f875ec7","date":1464597207,"type":4,"author":"Mike McCandless","isMerge":true,"pathNew":"/dev/null","pathOld":"solr/core/src/test/org/apache/solr/cloud/DistribJoinFromCollectionTest#test().mjava","sourceNew":null,"sourceOld":"  @Test\n  public void test() throws Exception {\n    // create a collection holding data for the \"to\" side of the JOIN\n    String toColl = \"to_2x2\";\n    createCollection(toColl, 2, 2, 2);\n    ensureAllReplicasAreActive(toColl, \"shard1\", 2, 2, 30);\n    ensureAllReplicasAreActive(toColl, \"shard2\", 2, 2, 30);\n\n    // get the set of nodes where replicas for the \"to\" collection exist\n    Set<String> nodeSet = new HashSet<>();\n    ClusterState cs = cloudClient.getZkStateReader().getClusterState();\n    for (Slice slice : cs.getActiveSlices(toColl))\n      for (Replica replica : slice.getReplicas())\n        nodeSet.add(replica.getNodeName());\n    assertTrue(nodeSet.size() > 0);\n\n    // deploy the \"from\" collection to all nodes where the \"to\" collection exists\n    String fromColl = \"from_1x2\";\n    createCollection(null, fromColl, 1, nodeSet.size(), 1, null, StringUtils.join(nodeSet,\",\"));\n    ensureAllReplicasAreActive(fromColl, \"shard1\", 1, nodeSet.size(), 30);\n\n    // both to and from collections are up and active, index some docs ...\n    Integer toDocId = indexDoc(toColl, 1001, \"a\", null, \"b\");\n    indexDoc(fromColl, 2001, \"a\", \"c\", null);\n\n    Thread.sleep(1000); // so the commits fire\n\n    //without score\n    testJoins(toColl, fromColl, toDocId, false);\n\n    //with score\n    testJoins(toColl, fromColl, toDocId, true);\n\n    log.info(\"DistribJoinFromCollectionTest logic complete ... deleting the \" + toColl + \" and \" + fromColl + \" collections\");\n\n    // try to clean up\n    for (String c : new String[]{ toColl, fromColl }) {\n      try {\n        CollectionAdminRequest.Delete req = new CollectionAdminRequest.Delete()\n                .setCollectionName(c);\n        req.process(cloudClient);\n      } catch (Exception e) {\n        // don't fail the test\n        log.warn(\"Could not delete collection {} after test completed due to: \" + e, c);\n      }\n    }\n\n    log.info(\"DistribJoinFromCollectionTest succeeded ... shutting down now!\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5b8ee93140fd0efef7e101786e3ed5160a700b5f","date":1464820111,"type":4,"author":"Mike McCandless","isMerge":true,"pathNew":"/dev/null","pathOld":"solr/core/src/test/org/apache/solr/cloud/DistribJoinFromCollectionTest#test().mjava","sourceNew":null,"sourceOld":"  @Test\n  public void test() throws Exception {\n    // create a collection holding data for the \"to\" side of the JOIN\n    String toColl = \"to_2x2\";\n    createCollection(toColl, 2, 2, 2);\n    ensureAllReplicasAreActive(toColl, \"shard1\", 2, 2, 30);\n    ensureAllReplicasAreActive(toColl, \"shard2\", 2, 2, 30);\n\n    // get the set of nodes where replicas for the \"to\" collection exist\n    Set<String> nodeSet = new HashSet<>();\n    ClusterState cs = cloudClient.getZkStateReader().getClusterState();\n    for (Slice slice : cs.getActiveSlices(toColl))\n      for (Replica replica : slice.getReplicas())\n        nodeSet.add(replica.getNodeName());\n    assertTrue(nodeSet.size() > 0);\n\n    // deploy the \"from\" collection to all nodes where the \"to\" collection exists\n    String fromColl = \"from_1x2\";\n    createCollection(null, fromColl, 1, nodeSet.size(), 1, null, StringUtils.join(nodeSet,\",\"));\n    ensureAllReplicasAreActive(fromColl, \"shard1\", 1, nodeSet.size(), 30);\n\n    // both to and from collections are up and active, index some docs ...\n    Integer toDocId = indexDoc(toColl, 1001, \"a\", null, \"b\");\n    indexDoc(fromColl, 2001, \"a\", \"c\", null);\n\n    Thread.sleep(1000); // so the commits fire\n\n    //without score\n    testJoins(toColl, fromColl, toDocId, false);\n\n    //with score\n    testJoins(toColl, fromColl, toDocId, true);\n\n    log.info(\"DistribJoinFromCollectionTest logic complete ... deleting the \" + toColl + \" and \" + fromColl + \" collections\");\n\n    // try to clean up\n    for (String c : new String[]{ toColl, fromColl }) {\n      try {\n        CollectionAdminRequest.Delete req = new CollectionAdminRequest.Delete()\n                .setCollectionName(c);\n        req.process(cloudClient);\n      } catch (Exception e) {\n        // don't fail the test\n        log.warn(\"Could not delete collection {} after test completed due to: \" + e, c);\n      }\n    }\n\n    log.info(\"DistribJoinFromCollectionTest succeeded ... shutting down now!\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":4,"author":"Kevin Risden","isMerge":true,"pathNew":"/dev/null","pathOld":"solr/core/src/test/org/apache/solr/cloud/DistribJoinFromCollectionTest#test().mjava","sourceNew":null,"sourceOld":"  @Test\n  public void test() throws Exception {\n    // create a collection holding data for the \"to\" side of the JOIN\n    String toColl = \"to_2x2\";\n    createCollection(toColl, 2, 2, 2);\n    ensureAllReplicasAreActive(toColl, \"shard1\", 2, 2, 30);\n    ensureAllReplicasAreActive(toColl, \"shard2\", 2, 2, 30);\n\n    // get the set of nodes where replicas for the \"to\" collection exist\n    Set<String> nodeSet = new HashSet<>();\n    ClusterState cs = cloudClient.getZkStateReader().getClusterState();\n    for (Slice slice : cs.getActiveSlices(toColl))\n      for (Replica replica : slice.getReplicas())\n        nodeSet.add(replica.getNodeName());\n    assertTrue(nodeSet.size() > 0);\n\n    // deploy the \"from\" collection to all nodes where the \"to\" collection exists\n    String fromColl = \"from_1x2\";\n    createCollection(null, fromColl, 1, nodeSet.size(), 1, null, StringUtils.join(nodeSet,\",\"));\n    ensureAllReplicasAreActive(fromColl, \"shard1\", 1, nodeSet.size(), 30);\n\n    // both to and from collections are up and active, index some docs ...\n    Integer toDocId = indexDoc(toColl, 1001, \"a\", null, \"b\");\n    indexDoc(fromColl, 2001, \"a\", \"c\", null);\n\n    Thread.sleep(1000); // so the commits fire\n\n    //without score\n    testJoins(toColl, fromColl, toDocId, false);\n\n    //with score\n    testJoins(toColl, fromColl, toDocId, true);\n\n    log.info(\"DistribJoinFromCollectionTest logic complete ... deleting the \" + toColl + \" and \" + fromColl + \" collections\");\n\n    // try to clean up\n    for (String c : new String[]{ toColl, fromColl }) {\n      try {\n        CollectionAdminRequest.Delete req = new CollectionAdminRequest.Delete()\n                .setCollectionName(c);\n        req.process(cloudClient);\n      } catch (Exception e) {\n        // don't fail the test\n        log.warn(\"Could not delete collection {} after test completed due to: \" + e, c);\n      }\n    }\n\n    log.info(\"DistribJoinFromCollectionTest succeeded ... shutting down now!\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"da8a02bef7458089240404614139b53c9f875ec7":["118ba480e87dfe453a6b47a320429be33f1d1653","da83c90417e805f2b355afc2d79f4d2b2ce27469"],"da83c90417e805f2b355afc2d79f4d2b2ce27469":["118ba480e87dfe453a6b47a320429be33f1d1653"],"da22fc4f0d847980f460da30f3b68afbf2249d70":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"118ba480e87dfe453a6b47a320429be33f1d1653":["182acd29cf4cb1644a02b8517f3a5b867c0d7cce"],"182acd29cf4cb1644a02b8517f3a5b867c0d7cce":["da22fc4f0d847980f460da30f3b68afbf2249d70"],"5b8ee93140fd0efef7e101786e3ed5160a700b5f":["118ba480e87dfe453a6b47a320429be33f1d1653","da83c90417e805f2b355afc2d79f4d2b2ce27469"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["118ba480e87dfe453a6b47a320429be33f1d1653","da83c90417e805f2b355afc2d79f4d2b2ce27469"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["da83c90417e805f2b355afc2d79f4d2b2ce27469"]},"commit2Childs":{"da8a02bef7458089240404614139b53c9f875ec7":[],"da83c90417e805f2b355afc2d79f4d2b2ce27469":["da8a02bef7458089240404614139b53c9f875ec7","5b8ee93140fd0efef7e101786e3ed5160a700b5f","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"da22fc4f0d847980f460da30f3b68afbf2249d70":["182acd29cf4cb1644a02b8517f3a5b867c0d7cce"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["da22fc4f0d847980f460da30f3b68afbf2249d70"],"118ba480e87dfe453a6b47a320429be33f1d1653":["da8a02bef7458089240404614139b53c9f875ec7","da83c90417e805f2b355afc2d79f4d2b2ce27469","5b8ee93140fd0efef7e101786e3ed5160a700b5f","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"182acd29cf4cb1644a02b8517f3a5b867c0d7cce":["118ba480e87dfe453a6b47a320429be33f1d1653"],"5b8ee93140fd0efef7e101786e3ed5160a700b5f":[],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["da8a02bef7458089240404614139b53c9f875ec7","5b8ee93140fd0efef7e101786e3ed5160a700b5f","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}