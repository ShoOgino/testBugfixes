{"path":"backwards/src/test/org/apache/lucene/index/TestIndexReader#testBinaryFields().mjava","commits":[{"id":"480d01e5b0ef8efb136d51670fec297ae5ae2c9c","date":1268821447,"type":0,"author":"Uwe Schindler","isMerge":false,"pathNew":"backwards/src/test/org/apache/lucene/index/TestIndexReader#testBinaryFields().mjava","pathOld":"/dev/null","sourceNew":"    public void testBinaryFields() throws IOException\n    {\n        Directory dir = new RAMDirectory();\n        byte[] bin = new byte[]{0, 1, 2, 3, 4, 5, 6, 7, 8, 9};\n        \n        IndexWriter writer = new IndexWriter(dir, new WhitespaceAnalyzer(), true, IndexWriter.MaxFieldLength.UNLIMITED);\n        \n        for (int i = 0; i < 10; i++) {\n          addDoc(writer, \"document number \" + (i + 1));\n          addDocumentWithFields(writer);\n          addDocumentWithDifferentFields(writer);\n          addDocumentWithTermVectorFields(writer);\n        }\n        writer.close();\n        writer = new IndexWriter(dir, new WhitespaceAnalyzer(), false, IndexWriter.MaxFieldLength.LIMITED);\n        Document doc = new Document();\n        doc.add(new Field(\"bin1\", bin, Field.Store.YES));\n        doc.add(new Field(\"junk\", \"junk text\", Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(doc);\n        writer.close();\n        IndexReader reader = IndexReader.open(dir, false);\n        doc = reader.document(reader.maxDoc() - 1);\n        Field[] fields = doc.getFields(\"bin1\");\n        assertNotNull(fields);\n        assertEquals(1, fields.length);\n        Field b1 = fields[0];\n        assertTrue(b1.isBinary());\n        byte[] data1 = b1.getBinaryValue();\n        assertEquals(bin.length, b1.getBinaryLength());\n        for (int i = 0; i < bin.length; i++) {\n          assertEquals(bin[i], data1[i + b1.getBinaryOffset()]);\n        }\n        Set lazyFields = new HashSet();\n        lazyFields.add(\"bin1\");\n        FieldSelector sel = new SetBasedFieldSelector(new HashSet(), lazyFields);\n        doc = reader.document(reader.maxDoc() - 1, sel);\n        Fieldable[] fieldables = doc.getFieldables(\"bin1\");\n        assertNotNull(fieldables);\n        assertEquals(1, fieldables.length);\n        Fieldable fb1 = fieldables[0];\n        assertTrue(fb1.isBinary());\n        assertEquals(bin.length, fb1.getBinaryLength());\n        data1 = fb1.getBinaryValue();\n        assertEquals(bin.length, fb1.getBinaryLength());\n        for (int i = 0; i < bin.length; i++) {\n          assertEquals(bin[i], data1[i + fb1.getBinaryOffset()]);\n        }\n        reader.close();\n        // force optimize\n\n\n        writer = new IndexWriter(dir, new WhitespaceAnalyzer(), false, IndexWriter.MaxFieldLength.LIMITED);\n        writer.optimize();\n        writer.close();\n        reader = IndexReader.open(dir, false);\n        doc = reader.document(reader.maxDoc() - 1);\n        fields = doc.getFields(\"bin1\");\n        assertNotNull(fields);\n        assertEquals(1, fields.length);\n        b1 = fields[0];\n        assertTrue(b1.isBinary());\n        data1 = b1.getBinaryValue();\n        assertEquals(bin.length, b1.getBinaryLength());\n        for (int i = 0; i < bin.length; i++) {\n          assertEquals(bin[i], data1[i + b1.getBinaryOffset()]);\n        }\n        reader.close();\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/backwards/src/test/org/apache/lucene/index/TestIndexReader#testBinaryFields().mjava","pathOld":"backwards/src/test/org/apache/lucene/index/TestIndexReader#testBinaryFields().mjava","sourceNew":"    public void testBinaryFields() throws IOException\n    {\n        Directory dir = new RAMDirectory();\n        byte[] bin = new byte[]{0, 1, 2, 3, 4, 5, 6, 7, 8, 9};\n        \n        IndexWriter writer = new IndexWriter(dir, new WhitespaceAnalyzer(), true, IndexWriter.MaxFieldLength.UNLIMITED);\n        \n        for (int i = 0; i < 10; i++) {\n          addDoc(writer, \"document number \" + (i + 1));\n          addDocumentWithFields(writer);\n          addDocumentWithDifferentFields(writer);\n          addDocumentWithTermVectorFields(writer);\n        }\n        writer.close();\n        writer = new IndexWriter(dir, new WhitespaceAnalyzer(), false, IndexWriter.MaxFieldLength.LIMITED);\n        Document doc = new Document();\n        doc.add(new Field(\"bin1\", bin, Field.Store.YES));\n        doc.add(new Field(\"junk\", \"junk text\", Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(doc);\n        writer.close();\n        IndexReader reader = IndexReader.open(dir, false);\n        doc = reader.document(reader.maxDoc() - 1);\n        Field[] fields = doc.getFields(\"bin1\");\n        assertNotNull(fields);\n        assertEquals(1, fields.length);\n        Field b1 = fields[0];\n        assertTrue(b1.isBinary());\n        byte[] data1 = b1.getBinaryValue();\n        assertEquals(bin.length, b1.getBinaryLength());\n        for (int i = 0; i < bin.length; i++) {\n          assertEquals(bin[i], data1[i + b1.getBinaryOffset()]);\n        }\n        Set lazyFields = new HashSet();\n        lazyFields.add(\"bin1\");\n        FieldSelector sel = new SetBasedFieldSelector(new HashSet(), lazyFields);\n        doc = reader.document(reader.maxDoc() - 1, sel);\n        Fieldable[] fieldables = doc.getFieldables(\"bin1\");\n        assertNotNull(fieldables);\n        assertEquals(1, fieldables.length);\n        Fieldable fb1 = fieldables[0];\n        assertTrue(fb1.isBinary());\n        assertEquals(bin.length, fb1.getBinaryLength());\n        data1 = fb1.getBinaryValue();\n        assertEquals(bin.length, fb1.getBinaryLength());\n        for (int i = 0; i < bin.length; i++) {\n          assertEquals(bin[i], data1[i + fb1.getBinaryOffset()]);\n        }\n        reader.close();\n        // force optimize\n\n\n        writer = new IndexWriter(dir, new WhitespaceAnalyzer(), false, IndexWriter.MaxFieldLength.LIMITED);\n        writer.optimize();\n        writer.close();\n        reader = IndexReader.open(dir, false);\n        doc = reader.document(reader.maxDoc() - 1);\n        fields = doc.getFields(\"bin1\");\n        assertNotNull(fields);\n        assertEquals(1, fields.length);\n        b1 = fields[0];\n        assertTrue(b1.isBinary());\n        data1 = b1.getBinaryValue();\n        assertEquals(bin.length, b1.getBinaryLength());\n        for (int i = 0; i < bin.length; i++) {\n          assertEquals(bin[i], data1[i + b1.getBinaryOffset()]);\n        }\n        reader.close();\n    }\n\n","sourceOld":"    public void testBinaryFields() throws IOException\n    {\n        Directory dir = new RAMDirectory();\n        byte[] bin = new byte[]{0, 1, 2, 3, 4, 5, 6, 7, 8, 9};\n        \n        IndexWriter writer = new IndexWriter(dir, new WhitespaceAnalyzer(), true, IndexWriter.MaxFieldLength.UNLIMITED);\n        \n        for (int i = 0; i < 10; i++) {\n          addDoc(writer, \"document number \" + (i + 1));\n          addDocumentWithFields(writer);\n          addDocumentWithDifferentFields(writer);\n          addDocumentWithTermVectorFields(writer);\n        }\n        writer.close();\n        writer = new IndexWriter(dir, new WhitespaceAnalyzer(), false, IndexWriter.MaxFieldLength.LIMITED);\n        Document doc = new Document();\n        doc.add(new Field(\"bin1\", bin, Field.Store.YES));\n        doc.add(new Field(\"junk\", \"junk text\", Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(doc);\n        writer.close();\n        IndexReader reader = IndexReader.open(dir, false);\n        doc = reader.document(reader.maxDoc() - 1);\n        Field[] fields = doc.getFields(\"bin1\");\n        assertNotNull(fields);\n        assertEquals(1, fields.length);\n        Field b1 = fields[0];\n        assertTrue(b1.isBinary());\n        byte[] data1 = b1.getBinaryValue();\n        assertEquals(bin.length, b1.getBinaryLength());\n        for (int i = 0; i < bin.length; i++) {\n          assertEquals(bin[i], data1[i + b1.getBinaryOffset()]);\n        }\n        Set lazyFields = new HashSet();\n        lazyFields.add(\"bin1\");\n        FieldSelector sel = new SetBasedFieldSelector(new HashSet(), lazyFields);\n        doc = reader.document(reader.maxDoc() - 1, sel);\n        Fieldable[] fieldables = doc.getFieldables(\"bin1\");\n        assertNotNull(fieldables);\n        assertEquals(1, fieldables.length);\n        Fieldable fb1 = fieldables[0];\n        assertTrue(fb1.isBinary());\n        assertEquals(bin.length, fb1.getBinaryLength());\n        data1 = fb1.getBinaryValue();\n        assertEquals(bin.length, fb1.getBinaryLength());\n        for (int i = 0; i < bin.length; i++) {\n          assertEquals(bin[i], data1[i + fb1.getBinaryOffset()]);\n        }\n        reader.close();\n        // force optimize\n\n\n        writer = new IndexWriter(dir, new WhitespaceAnalyzer(), false, IndexWriter.MaxFieldLength.LIMITED);\n        writer.optimize();\n        writer.close();\n        reader = IndexReader.open(dir, false);\n        doc = reader.document(reader.maxDoc() - 1);\n        fields = doc.getFields(\"bin1\");\n        assertNotNull(fields);\n        assertEquals(1, fields.length);\n        b1 = fields[0];\n        assertTrue(b1.isBinary());\n        data1 = b1.getBinaryValue();\n        assertEquals(bin.length, b1.getBinaryLength());\n        for (int i = 0; i < bin.length; i++) {\n          assertEquals(bin[i], data1[i + b1.getBinaryOffset()]);\n        }\n        reader.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"480d01e5b0ef8efb136d51670fec297ae5ae2c9c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["480d01e5b0ef8efb136d51670fec297ae5ae2c9c"]},"commit2Childs":{"480d01e5b0ef8efb136d51670fec297ae5ae2c9c":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["480d01e5b0ef8efb136d51670fec297ae5ae2c9c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}