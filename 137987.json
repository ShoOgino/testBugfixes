{"path":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","pathOld":"src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","sourceNew":"    public void testDiverseDocs() throws IOException {\n      RAMDirectory dir = new RAMDirectory();      \n      IndexWriter writer  = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)).setRAMBufferSizeMB(0.5));\n      Random rand = newRandom();\n      for(int i=0;i<3;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(new Field(\"field\", Integer.toString(rand.nextInt()), Field.Store.YES, Field.Index.ANALYZED));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(new Field(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(new Field(\"field\", longTerm, Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexSearcher searcher = new IndexSearcher(dir, false);\n      ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1000).scoreDocs;\n      assertEquals(300, hits.length);\n      searcher.close();\n\n      dir.close();\n    }\n\n","sourceOld":"    public void testDiverseDocs() throws IOException {\n      RAMDirectory dir = new RAMDirectory();      \n      IndexWriter writer  = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)).setRAMBufferSizeMB(0.5));\n      Random rand = newRandom();\n      for(int i=0;i<3;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(new Field(\"field\", Integer.toString(rand.nextInt()), Field.Store.YES, Field.Index.ANALYZED));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(new Field(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(new Field(\"field\", longTerm, Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexSearcher searcher = new IndexSearcher(dir, false);\n      ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1000).scoreDocs;\n      assertEquals(300, hits.length);\n      searcher.close();\n\n      dir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d572389229127c297dd1fa5ce4758e1cec41e799","date":1273610938,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","sourceNew":"    public void testDiverseDocs() throws IOException {\n      RAMDirectory dir = new RAMDirectory();      \n      IndexWriter writer  = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setRAMBufferSizeMB(0.5));\n      Random rand = newRandom();\n      for(int i=0;i<3;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(new Field(\"field\", Integer.toString(rand.nextInt()), Field.Store.YES, Field.Index.ANALYZED));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(new Field(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(new Field(\"field\", longTerm, Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexSearcher searcher = new IndexSearcher(dir, false);\n      ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1000).scoreDocs;\n      assertEquals(300, hits.length);\n      searcher.close();\n\n      dir.close();\n    }\n\n","sourceOld":"    public void testDiverseDocs() throws IOException {\n      RAMDirectory dir = new RAMDirectory();      \n      IndexWriter writer  = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)).setRAMBufferSizeMB(0.5));\n      Random rand = newRandom();\n      for(int i=0;i<3;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(new Field(\"field\", Integer.toString(rand.nextInt()), Field.Store.YES, Field.Index.ANALYZED));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(new Field(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(new Field(\"field\", longTerm, Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexSearcher searcher = new IndexSearcher(dir, false);\n      ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1000).scoreDocs;\n      assertEquals(300, hits.length);\n      searcher.close();\n\n      dir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b21422ff1d1d56499dec481f193b402e5e8def5b","date":1281472367,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","sourceNew":"    public void testDiverseDocs() throws IOException {\n      RAMDirectory dir = new RAMDirectory();      \n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setRAMBufferSizeMB(0.5));\n      for(int i=0;i<3;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(new Field(\"field\", Integer.toString(random.nextInt()), Field.Store.YES, Field.Index.ANALYZED));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(new Field(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(new Field(\"field\", longTerm, Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexSearcher searcher = new IndexSearcher(dir, false);\n      ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1000).scoreDocs;\n      assertEquals(300, hits.length);\n      searcher.close();\n\n      dir.close();\n    }\n\n","sourceOld":"    public void testDiverseDocs() throws IOException {\n      RAMDirectory dir = new RAMDirectory();      \n      IndexWriter writer  = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setRAMBufferSizeMB(0.5));\n      Random rand = newRandom();\n      for(int i=0;i<3;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(new Field(\"field\", Integer.toString(rand.nextInt()), Field.Store.YES, Field.Index.ANALYZED));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(new Field(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(new Field(\"field\", longTerm, Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexSearcher searcher = new IndexSearcher(dir, false);\n      ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1000).scoreDocs;\n      assertEquals(300, hits.length);\n      searcher.close();\n\n      dir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1a2e46fd1b7cbc52d7d6461a6ef99e7107ae2a9c","date":1281477834,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","sourceNew":"    public void testDiverseDocs() throws IOException {\n      MockRAMDirectory dir = new MockRAMDirectory();      \n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setRAMBufferSizeMB(0.5));\n      for(int i=0;i<3;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(new Field(\"field\", Integer.toString(random.nextInt()), Field.Store.YES, Field.Index.ANALYZED));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(new Field(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(new Field(\"field\", longTerm, Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexSearcher searcher = new IndexSearcher(dir, false);\n      ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1000).scoreDocs;\n      assertEquals(300, hits.length);\n      searcher.close();\n\n      dir.close();\n    }\n\n","sourceOld":"    public void testDiverseDocs() throws IOException {\n      RAMDirectory dir = new RAMDirectory();      \n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setRAMBufferSizeMB(0.5));\n      for(int i=0;i<3;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(new Field(\"field\", Integer.toString(random.nextInt()), Field.Store.YES, Field.Index.ANALYZED));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(new Field(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(new Field(\"field\", longTerm, Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexSearcher searcher = new IndexSearcher(dir, false);\n      ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1000).scoreDocs;\n      assertEquals(300, hits.length);\n      searcher.close();\n\n      dir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c","date":1281646583,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","sourceNew":"    public void testDiverseDocs() throws IOException {\n      MockRAMDirectory dir = newDirectory(random);      \n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setRAMBufferSizeMB(0.5));\n      for(int i=0;i<3;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(new Field(\"field\", Integer.toString(random.nextInt()), Field.Store.YES, Field.Index.ANALYZED));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(new Field(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(new Field(\"field\", longTerm, Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexSearcher searcher = new IndexSearcher(dir, false);\n      ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1000).scoreDocs;\n      assertEquals(300, hits.length);\n      searcher.close();\n\n      dir.close();\n    }\n\n","sourceOld":"    public void testDiverseDocs() throws IOException {\n      MockRAMDirectory dir = new MockRAMDirectory();      \n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setRAMBufferSizeMB(0.5));\n      for(int i=0;i<3;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(new Field(\"field\", Integer.toString(random.nextInt()), Field.Store.YES, Field.Index.ANALYZED));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(new Field(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(new Field(\"field\", longTerm, Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexSearcher searcher = new IndexSearcher(dir, false);\n      ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1000).scoreDocs;\n      assertEquals(300, hits.length);\n      searcher.close();\n\n      dir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a05409176bd65129d67a785ee70e881e238a9aef","date":1282582843,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","sourceNew":"    public void testDiverseDocs() throws IOException {\n      MockDirectoryWrapper dir = newDirectory(random);      \n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setRAMBufferSizeMB(0.5));\n      for(int i=0;i<3;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(new Field(\"field\", Integer.toString(random.nextInt()), Field.Store.YES, Field.Index.ANALYZED));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(new Field(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(new Field(\"field\", longTerm, Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexSearcher searcher = new IndexSearcher(dir, false);\n      ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1000).scoreDocs;\n      assertEquals(300, hits.length);\n      searcher.close();\n\n      dir.close();\n    }\n\n","sourceOld":"    public void testDiverseDocs() throws IOException {\n      MockRAMDirectory dir = newDirectory(random);      \n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setRAMBufferSizeMB(0.5));\n      for(int i=0;i<3;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(new Field(\"field\", Integer.toString(random.nextInt()), Field.Store.YES, Field.Index.ANALYZED));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(new Field(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(new Field(\"field\", longTerm, Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexSearcher searcher = new IndexSearcher(dir, false);\n      ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1000).scoreDocs;\n      assertEquals(300, hits.length);\n      searcher.close();\n\n      dir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1f653cfcf159baeaafe5d01682a911e95bba4012","date":1284122058,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","sourceNew":"    public void testDiverseDocs() throws IOException {\n      MockDirectoryWrapper dir = newDirectory();      \n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setRAMBufferSizeMB(0.5));\n      for(int i=0;i<3;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(new Field(\"field\", Integer.toString(random.nextInt()), Field.Store.YES, Field.Index.ANALYZED));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(new Field(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(new Field(\"field\", longTerm, Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexSearcher searcher = new IndexSearcher(dir, false);\n      ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1000).scoreDocs;\n      assertEquals(300, hits.length);\n      searcher.close();\n\n      dir.close();\n    }\n\n","sourceOld":"    public void testDiverseDocs() throws IOException {\n      MockDirectoryWrapper dir = newDirectory(random);      \n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setRAMBufferSizeMB(0.5));\n      for(int i=0;i<3;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(new Field(\"field\", Integer.toString(random.nextInt()), Field.Store.YES, Field.Index.ANALYZED));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(new Field(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(new Field(\"field\", longTerm, Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexSearcher searcher = new IndexSearcher(dir, false);\n      ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1000).scoreDocs;\n      assertEquals(300, hits.length);\n      searcher.close();\n\n      dir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"132903c28af3aa6f67284b78de91c0f0a99488c2","date":1284282129,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","sourceNew":"    public void testDiverseDocs() throws IOException {\n      MockDirectoryWrapper dir = newDirectory();      \n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setRAMBufferSizeMB(0.5));\n      for(int i=0;i<3;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(newField(\"field\", Integer.toString(random.nextInt()), Field.Store.YES, Field.Index.ANALYZED));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(newField(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(newField(\"field\", longTerm, Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexSearcher searcher = new IndexSearcher(dir, false);\n      ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1000).scoreDocs;\n      assertEquals(300, hits.length);\n      searcher.close();\n\n      dir.close();\n    }\n\n","sourceOld":"    public void testDiverseDocs() throws IOException {\n      MockDirectoryWrapper dir = newDirectory();      \n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setRAMBufferSizeMB(0.5));\n      for(int i=0;i<3;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(new Field(\"field\", Integer.toString(random.nextInt()), Field.Store.YES, Field.Index.ANALYZED));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(new Field(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(new Field(\"field\", longTerm, Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexSearcher searcher = new IndexSearcher(dir, false);\n      ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1000).scoreDocs;\n      assertEquals(300, hits.length);\n      searcher.close();\n\n      dir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","sourceNew":"    public void testDiverseDocs() throws IOException {\n      MockDirectoryWrapper dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setRAMBufferSizeMB(0.5));\n      for(int i=0;i<3;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(newField(\"field\", Integer.toString(random.nextInt()), Field.Store.YES, Field.Index.ANALYZED));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(newField(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(newField(\"field\", longTerm, Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexSearcher searcher = new IndexSearcher(dir, false);\n      ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1000).scoreDocs;\n      assertEquals(300, hits.length);\n      searcher.close();\n\n      dir.close();\n    }\n\n","sourceOld":"    public void testDiverseDocs() throws IOException {\n      RAMDirectory dir = new RAMDirectory();      \n      IndexWriter writer  = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setRAMBufferSizeMB(0.5));\n      Random rand = newRandom();\n      for(int i=0;i<3;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(new Field(\"field\", Integer.toString(rand.nextInt()), Field.Store.YES, Field.Index.ANALYZED));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(new Field(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(new Field(\"field\", longTerm, Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexSearcher searcher = new IndexSearcher(dir, false);\n      ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1000).scoreDocs;\n      assertEquals(300, hits.length);\n      searcher.close();\n\n      dir.close();\n    }\n\n","bugFix":null,"bugIntro":["d19974432be9aed28ee7dca73bdf01d139e763a9"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f2c5f0cb44df114db4228c8f77861714b5cabaea","date":1302542431,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","sourceNew":"    public void testDiverseDocs() throws IOException {\n      MockDirectoryWrapper dir = newDirectory();      \n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setRAMBufferSizeMB(0.5));\n      for(int i=0;i<3;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(newField(\"field\", Integer.toString(random.nextInt()), Field.Store.YES, Field.Index.ANALYZED));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(newField(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(newField(\"field\", longTerm, Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexSearcher searcher = new IndexSearcher(dir, false);\n      ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1000).scoreDocs;\n      assertEquals(300, hits.length);\n      searcher.close();\n\n      dir.close();\n    }\n\n","sourceOld":"    public void testDiverseDocs() throws IOException {\n      MockDirectoryWrapper dir = newDirectory();      \n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setRAMBufferSizeMB(0.5));\n      for(int i=0;i<3;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(newField(\"field\", Integer.toString(random.nextInt()), Field.Store.YES, Field.Index.ANALYZED));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(newField(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(newField(\"field\", longTerm, Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexSearcher searcher = new IndexSearcher(dir, false);\n      ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1000).scoreDocs;\n      assertEquals(300, hits.length);\n      searcher.close();\n\n      dir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"962d04139994fce5193143ef35615499a9a96d78","date":1302693744,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","sourceNew":"    public void testDiverseDocs() throws IOException {\n      MockDirectoryWrapper dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setRAMBufferSizeMB(0.5));\n      for(int i=0;i<3;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(newField(\"field\", Integer.toString(random.nextInt()), Field.Store.YES, Field.Index.ANALYZED));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(newField(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(newField(\"field\", longTerm, Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexSearcher searcher = new IndexSearcher(dir, false);\n      ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1000).scoreDocs;\n      assertEquals(300, hits.length);\n      searcher.close();\n\n      dir.close();\n    }\n\n","sourceOld":"    public void testDiverseDocs() throws IOException {\n      MockDirectoryWrapper dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setRAMBufferSizeMB(0.5));\n      for(int i=0;i<3;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(newField(\"field\", Integer.toString(random.nextInt()), Field.Store.YES, Field.Index.ANALYZED));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(newField(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(newField(\"field\", longTerm, Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexSearcher searcher = new IndexSearcher(dir, false);\n      ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1000).scoreDocs;\n      assertEquals(300, hits.length);\n      searcher.close();\n\n      dir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b3e06be49006ecac364d39d12b9c9f74882f9b9f","date":1304289513,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","sourceNew":"    public void testDiverseDocs() throws IOException {\n      MockDirectoryWrapper dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setRAMBufferSizeMB(0.5));\n      for(int i=0;i<3;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(newField(\"field\", Integer.toString(random.nextInt()), Field.Store.YES, Field.Index.ANALYZED));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(newField(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(newField(\"field\", longTerm, Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexSearcher searcher = new IndexSearcher(dir, false);\n      ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1000).scoreDocs;\n      assertEquals(300, hits.length);\n      searcher.close();\n\n      dir.close();\n    }\n\n","sourceOld":"    public void testDiverseDocs() throws IOException {\n      MockDirectoryWrapper dir = newDirectory();      \n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setRAMBufferSizeMB(0.5));\n      for(int i=0;i<3;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(newField(\"field\", Integer.toString(random.nextInt()), Field.Store.YES, Field.Index.ANALYZED));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(newField(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(newField(\"field\", longTerm, Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexSearcher searcher = new IndexSearcher(dir, false);\n      ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1000).scoreDocs;\n      assertEquals(300, hits.length);\n      searcher.close();\n\n      dir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"135621f3a0670a9394eb563224a3b76cc4dddc0f","date":1304344257,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","sourceNew":"    public void testDiverseDocs() throws IOException {\n      MockDirectoryWrapper dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setRAMBufferSizeMB(0.5));\n      for(int i=0;i<3;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(newField(\"field\", Integer.toString(random.nextInt()), Field.Store.YES, Field.Index.ANALYZED));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(newField(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(newField(\"field\", longTerm, Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexSearcher searcher = new IndexSearcher(dir, false);\n      ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1000).scoreDocs;\n      assertEquals(300, hits.length);\n      searcher.close();\n\n      dir.close();\n    }\n\n","sourceOld":"    public void testDiverseDocs() throws IOException {\n      MockDirectoryWrapper dir = newDirectory();      \n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setRAMBufferSizeMB(0.5));\n      for(int i=0;i<3;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(newField(\"field\", Integer.toString(random.nextInt()), Field.Store.YES, Field.Index.ANALYZED));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(newField(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(newField(\"field\", longTerm, Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexSearcher searcher = new IndexSearcher(dir, false);\n      ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1000).scoreDocs;\n      assertEquals(300, hits.length);\n      searcher.close();\n\n      dir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","sourceNew":"    public void testDiverseDocs() throws IOException {\n      MockDirectoryWrapper dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setRAMBufferSizeMB(0.5));\n      for(int i=0;i<3;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(newField(\"field\", Integer.toString(random.nextInt()), Field.Store.YES, Field.Index.ANALYZED));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(newField(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(newField(\"field\", longTerm, Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexSearcher searcher = new IndexSearcher(dir, false);\n      ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1000).scoreDocs;\n      assertEquals(300, hits.length);\n      searcher.close();\n\n      dir.close();\n    }\n\n","sourceOld":"    public void testDiverseDocs() throws IOException {\n      MockDirectoryWrapper dir = newDirectory();      \n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setRAMBufferSizeMB(0.5));\n      for(int i=0;i<3;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(newField(\"field\", Integer.toString(random.nextInt()), Field.Store.YES, Field.Index.ANALYZED));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(newField(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(newField(\"field\", longTerm, Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexSearcher searcher = new IndexSearcher(dir, false);\n      ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1000).scoreDocs;\n      assertEquals(300, hits.length);\n      searcher.close();\n\n      dir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1509f151d7692d84fae414b2b799ac06ba60fcb4","date":1314451621,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","sourceNew":"    public void testDiverseDocs() throws IOException {\n      MockDirectoryWrapper dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setRAMBufferSizeMB(0.5));\n      for(int i=0;i<3;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(newField(\"field\", Integer.toString(random.nextInt()), storedTextType));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(newField(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", storedTextType));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(newField(\"field\", longTerm, storedTextType));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexSearcher searcher = new IndexSearcher(dir, false);\n      ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1000).scoreDocs;\n      assertEquals(300, hits.length);\n      searcher.close();\n\n      dir.close();\n    }\n\n","sourceOld":"    public void testDiverseDocs() throws IOException {\n      MockDirectoryWrapper dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setRAMBufferSizeMB(0.5));\n      for(int i=0;i<3;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(newField(\"field\", Integer.toString(random.nextInt()), Field.Store.YES, Field.Index.ANALYZED));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(newField(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(newField(\"field\", longTerm, Field.Store.YES, Field.Index.ANALYZED));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexSearcher searcher = new IndexSearcher(dir, false);\n      ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1000).scoreDocs;\n      assertEquals(300, hits.length);\n      searcher.close();\n\n      dir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a3a0403b45dfe384fae4a1b6e96c3265d000c498","date":1321445981,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","sourceNew":"    public void testDiverseDocs() throws IOException {\n      MockDirectoryWrapper dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setRAMBufferSizeMB(0.5));\n      for(int i=0;i<3;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(newField(\"field\", Integer.toString(random.nextInt()), storedTextType));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(newField(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", storedTextType));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(newField(\"field\", longTerm, storedTextType));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexReader reader = IndexReader.open(dir, false);\n      IndexSearcher searcher = new IndexSearcher(reader);\n      ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1000).scoreDocs;\n      assertEquals(300, hits.length);\n      searcher.close();\n      reader.close();\n\n      dir.close();\n    }\n\n","sourceOld":"    public void testDiverseDocs() throws IOException {\n      MockDirectoryWrapper dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setRAMBufferSizeMB(0.5));\n      for(int i=0;i<3;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(newField(\"field\", Integer.toString(random.nextInt()), storedTextType));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(newField(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", storedTextType));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(newField(\"field\", longTerm, storedTextType));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexSearcher searcher = new IndexSearcher(dir, false);\n      ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1000).scoreDocs;\n      assertEquals(300, hits.length);\n      searcher.close();\n\n      dir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1c5b026d03cbbb03ca4c0b97d14e9839682281dc","date":1323049298,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","sourceNew":"    public void testDiverseDocs() throws IOException {\n      MockDirectoryWrapper dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setRAMBufferSizeMB(0.5));\n      for(int i=0;i<3;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(newField(\"field\", Integer.toString(random.nextInt()), storedTextType));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(newField(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", storedTextType));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(newField(\"field\", longTerm, storedTextType));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexReader reader = IndexReader.open(dir);\n      IndexSearcher searcher = new IndexSearcher(reader);\n      ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1000).scoreDocs;\n      assertEquals(300, hits.length);\n      searcher.close();\n      reader.close();\n\n      dir.close();\n    }\n\n","sourceOld":"    public void testDiverseDocs() throws IOException {\n      MockDirectoryWrapper dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setRAMBufferSizeMB(0.5));\n      for(int i=0;i<3;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(newField(\"field\", Integer.toString(random.nextInt()), storedTextType));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(newField(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", storedTextType));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(newField(\"field\", longTerm, storedTextType));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexReader reader = IndexReader.open(dir, false);\n      IndexSearcher searcher = new IndexSearcher(reader);\n      ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1000).scoreDocs;\n      assertEquals(300, hits.length);\n      searcher.close();\n      reader.close();\n\n      dir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3615ce4a1f785ae1b779244de52c6a7d99227e60","date":1323422019,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","sourceNew":"    public void testDiverseDocs() throws IOException {\n      MockDirectoryWrapper dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setRAMBufferSizeMB(0.5));\n      for(int i=0;i<3;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(newField(\"field\", Integer.toString(random.nextInt()), storedTextType));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(newField(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", storedTextType));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(newField(\"field\", longTerm, storedTextType));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexReader reader = IndexReader.open(dir);\n      IndexSearcher searcher = new IndexSearcher(reader);\n      ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1000).scoreDocs;\n      assertEquals(300, hits.length);\n      searcher.close();\n      reader.close();\n\n      dir.close();\n    }\n\n","sourceOld":"    public void testDiverseDocs() throws IOException {\n      MockDirectoryWrapper dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setRAMBufferSizeMB(0.5));\n      for(int i=0;i<3;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(newField(\"field\", Integer.toString(random.nextInt()), storedTextType));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(newField(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", storedTextType));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(newField(\"field\", longTerm, storedTextType));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexReader reader = IndexReader.open(dir, false);\n      IndexSearcher searcher = new IndexSearcher(reader);\n      ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1000).scoreDocs;\n      assertEquals(300, hits.length);\n      searcher.close();\n      reader.close();\n\n      dir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","date":1323437438,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","sourceNew":"    public void testDiverseDocs() throws IOException {\n      MockDirectoryWrapper dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setRAMBufferSizeMB(0.5));\n      for(int i=0;i<3;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(newField(\"field\", Integer.toString(random.nextInt()), storedTextType));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(newField(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", storedTextType));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(newField(\"field\", longTerm, storedTextType));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexReader reader = IndexReader.open(dir);\n      IndexSearcher searcher = new IndexSearcher(reader);\n      ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1000).scoreDocs;\n      assertEquals(300, hits.length);\n      searcher.close();\n      reader.close();\n\n      dir.close();\n    }\n\n","sourceOld":"    public void testDiverseDocs() throws IOException {\n      MockDirectoryWrapper dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setRAMBufferSizeMB(0.5));\n      for(int i=0;i<3;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(newField(\"field\", Integer.toString(random.nextInt()), storedTextType));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(newField(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", storedTextType));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(newField(\"field\", longTerm, storedTextType));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexReader reader = IndexReader.open(dir, false);\n      IndexSearcher searcher = new IndexSearcher(reader);\n      ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1000).scoreDocs;\n      assertEquals(300, hits.length);\n      searcher.close();\n      reader.close();\n\n      dir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0e7c2454a6a8237bfd0e953f5b940838408c9055","date":1323649300,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","sourceNew":"    public void testDiverseDocs() throws IOException {\n      MockDirectoryWrapper dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setRAMBufferSizeMB(0.5));\n      for(int i=0;i<3;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(newField(\"field\", Integer.toString(random.nextInt()), storedTextType));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(newField(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", storedTextType));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(newField(\"field\", longTerm, storedTextType));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexReader reader = IndexReader.open(dir);\n      IndexSearcher searcher = new IndexSearcher(reader);\n      ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1000).scoreDocs;\n      assertEquals(300, hits.length);\n      reader.close();\n\n      dir.close();\n    }\n\n","sourceOld":"    public void testDiverseDocs() throws IOException {\n      MockDirectoryWrapper dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setRAMBufferSizeMB(0.5));\n      for(int i=0;i<3;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(newField(\"field\", Integer.toString(random.nextInt()), storedTextType));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(newField(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", storedTextType));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(newField(\"field\", longTerm, storedTextType));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexReader reader = IndexReader.open(dir);\n      IndexSearcher searcher = new IndexSearcher(reader);\n      ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1000).scoreDocs;\n      assertEquals(300, hits.length);\n      searcher.close();\n      reader.close();\n\n      dir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"93ccd971aca7fb61b7f1b946e44714cfc80bfc7c","date":1323720782,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","sourceNew":"    public void testDiverseDocs() throws IOException {\n      MockDirectoryWrapper dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setRAMBufferSizeMB(0.5));\n      for(int i=0;i<3;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(newField(\"field\", Integer.toString(random.nextInt()), storedTextType));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(newField(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", storedTextType));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(newField(\"field\", longTerm, storedTextType));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexReader reader = IndexReader.open(dir);\n      IndexSearcher searcher = new IndexSearcher(reader);\n      ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1000).scoreDocs;\n      assertEquals(300, hits.length);\n      reader.close();\n\n      dir.close();\n    }\n\n","sourceOld":"    public void testDiverseDocs() throws IOException {\n      MockDirectoryWrapper dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setRAMBufferSizeMB(0.5));\n      for(int i=0;i<3;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(newField(\"field\", Integer.toString(random.nextInt()), storedTextType));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(newField(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", storedTextType));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(newField(\"field\", longTerm, storedTextType));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexReader reader = IndexReader.open(dir);\n      IndexSearcher searcher = new IndexSearcher(reader);\n      ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1000).scoreDocs;\n      assertEquals(300, hits.length);\n      searcher.close();\n      reader.close();\n\n      dir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8be580b58bcc650d428f3f22de81cadcf51d650a","date":1325279655,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","sourceNew":"    public void testDiverseDocs() throws IOException {\n      MockDirectoryWrapper dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setRAMBufferSizeMB(0.5));\n      int n = atLeast(1);\n      for(int i=0;i<n;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(newField(\"field\", Integer.toString(random.nextInt()), storedTextType));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(newField(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", storedTextType));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(newField(\"field\", longTerm, storedTextType));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexReader reader = IndexReader.open(dir);\n      IndexSearcher searcher = new IndexSearcher(reader);\n      ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1000).scoreDocs;\n      assertEquals(n*100, hits.length);\n      reader.close();\n\n      dir.close();\n    }\n\n","sourceOld":"    public void testDiverseDocs() throws IOException {\n      MockDirectoryWrapper dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setRAMBufferSizeMB(0.5));\n      for(int i=0;i<3;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(newField(\"field\", Integer.toString(random.nextInt()), storedTextType));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(newField(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", storedTextType));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(newField(\"field\", longTerm, storedTextType));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexReader reader = IndexReader.open(dir);\n      IndexSearcher searcher = new IndexSearcher(reader);\n      ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1000).scoreDocs;\n      assertEquals(300, hits.length);\n      reader.close();\n\n      dir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6d8586807c39821ddee3082a1614a727742cf5b5","date":1325520994,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","sourceNew":"    public void testDiverseDocs() throws IOException {\n      MockDirectoryWrapper dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setRAMBufferSizeMB(0.5));\n      int n = atLeast(1);\n      for(int i=0;i<n;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(newField(\"field\", Integer.toString(random.nextInt()), storedTextType));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(newField(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", storedTextType));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(newField(\"field\", longTerm, storedTextType));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexReader reader = IndexReader.open(dir);\n      IndexSearcher searcher = new IndexSearcher(reader);\n      int totalHits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1).totalHits;\n      assertEquals(n*100, totalHits);\n      reader.close();\n\n      dir.close();\n    }\n\n","sourceOld":"    public void testDiverseDocs() throws IOException {\n      MockDirectoryWrapper dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setRAMBufferSizeMB(0.5));\n      int n = atLeast(1);\n      for(int i=0;i<n;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(newField(\"field\", Integer.toString(random.nextInt()), storedTextType));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(newField(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", storedTextType));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(newField(\"field\", longTerm, storedTextType));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexReader reader = IndexReader.open(dir);\n      IndexSearcher searcher = new IndexSearcher(reader);\n      ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1000).scoreDocs;\n      assertEquals(n*100, hits.length);\n      reader.close();\n\n      dir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","sourceNew":"    public void testDiverseDocs() throws IOException {\n      MockDirectoryWrapper dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setRAMBufferSizeMB(0.5));\n      int n = atLeast(1);\n      for(int i=0;i<n;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(newField(\"field\", Integer.toString(random.nextInt()), storedTextType));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(newField(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", storedTextType));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(newField(\"field\", longTerm, storedTextType));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexReader reader = IndexReader.open(dir);\n      IndexSearcher searcher = new IndexSearcher(reader);\n      int totalHits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1).totalHits;\n      assertEquals(n*100, totalHits);\n      reader.close();\n\n      dir.close();\n    }\n\n","sourceOld":"    public void testDiverseDocs() throws IOException {\n      MockDirectoryWrapper dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setRAMBufferSizeMB(0.5));\n      int n = atLeast(1);\n      for(int i=0;i<n;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(newField(\"field\", Integer.toString(random.nextInt()), storedTextType));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(newField(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", storedTextType));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(newField(\"field\", longTerm, storedTextType));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexReader reader = IndexReader.open(dir);\n      IndexSearcher searcher = new IndexSearcher(reader);\n      int totalHits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1).totalHits;\n      assertEquals(n*100, totalHits);\n      reader.close();\n\n      dir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00":["a3a0403b45dfe384fae4a1b6e96c3265d000c498","3615ce4a1f785ae1b779244de52c6a7d99227e60"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["6d8586807c39821ddee3082a1614a727742cf5b5"],"93ccd971aca7fb61b7f1b946e44714cfc80bfc7c":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","0e7c2454a6a8237bfd0e953f5b940838408c9055"],"1c5b026d03cbbb03ca4c0b97d14e9839682281dc":["a3a0403b45dfe384fae4a1b6e96c3265d000c498"],"132903c28af3aa6f67284b78de91c0f0a99488c2":["1f653cfcf159baeaafe5d01682a911e95bba4012"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["d572389229127c297dd1fa5ce4758e1cec41e799","132903c28af3aa6f67284b78de91c0f0a99488c2"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["132903c28af3aa6f67284b78de91c0f0a99488c2"],"0e7c2454a6a8237bfd0e953f5b940838408c9055":["3615ce4a1f785ae1b779244de52c6a7d99227e60"],"1f653cfcf159baeaafe5d01682a911e95bba4012":["a05409176bd65129d67a785ee70e881e238a9aef"],"1a2e46fd1b7cbc52d7d6461a6ef99e7107ae2a9c":["b21422ff1d1d56499dec481f193b402e5e8def5b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a05409176bd65129d67a785ee70e881e238a9aef":["ab9633cb67e3c0aec3c066147a23a957d6e7ad8c"],"a3a0403b45dfe384fae4a1b6e96c3265d000c498":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["b3e06be49006ecac364d39d12b9c9f74882f9b9f"],"b21422ff1d1d56499dec481f193b402e5e8def5b":["d572389229127c297dd1fa5ce4758e1cec41e799"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c":["1a2e46fd1b7cbc52d7d6461a6ef99e7107ae2a9c"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["132903c28af3aa6f67284b78de91c0f0a99488c2","b3e06be49006ecac364d39d12b9c9f74882f9b9f"],"d572389229127c297dd1fa5ce4758e1cec41e799":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"b3e06be49006ecac364d39d12b9c9f74882f9b9f":["f2c5f0cb44df114db4228c8f77861714b5cabaea","962d04139994fce5193143ef35615499a9a96d78"],"8be580b58bcc650d428f3f22de81cadcf51d650a":["0e7c2454a6a8237bfd0e953f5b940838408c9055"],"962d04139994fce5193143ef35615499a9a96d78":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"6d8586807c39821ddee3082a1614a727742cf5b5":["8be580b58bcc650d428f3f22de81cadcf51d650a"],"a3776dccca01c11e7046323cfad46a3b4a471233":["132903c28af3aa6f67284b78de91c0f0a99488c2","b3e06be49006ecac364d39d12b9c9f74882f9b9f"],"3615ce4a1f785ae1b779244de52c6a7d99227e60":["a3a0403b45dfe384fae4a1b6e96c3265d000c498","1c5b026d03cbbb03ca4c0b97d14e9839682281dc"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"]},"commit2Childs":{"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00":["93ccd971aca7fb61b7f1b946e44714cfc80bfc7c"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"93ccd971aca7fb61b7f1b946e44714cfc80bfc7c":[],"1c5b026d03cbbb03ca4c0b97d14e9839682281dc":["3615ce4a1f785ae1b779244de52c6a7d99227e60"],"132903c28af3aa6f67284b78de91c0f0a99488c2":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","f2c5f0cb44df114db4228c8f77861714b5cabaea","135621f3a0670a9394eb563224a3b76cc4dddc0f","a3776dccca01c11e7046323cfad46a3b4a471233"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["962d04139994fce5193143ef35615499a9a96d78"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["b3e06be49006ecac364d39d12b9c9f74882f9b9f","962d04139994fce5193143ef35615499a9a96d78"],"0e7c2454a6a8237bfd0e953f5b940838408c9055":["93ccd971aca7fb61b7f1b946e44714cfc80bfc7c","8be580b58bcc650d428f3f22de81cadcf51d650a"],"1f653cfcf159baeaafe5d01682a911e95bba4012":["132903c28af3aa6f67284b78de91c0f0a99488c2"],"1a2e46fd1b7cbc52d7d6461a6ef99e7107ae2a9c":["ab9633cb67e3c0aec3c066147a23a957d6e7ad8c"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"a05409176bd65129d67a785ee70e881e238a9aef":["1f653cfcf159baeaafe5d01682a911e95bba4012"],"a3a0403b45dfe384fae4a1b6e96c3265d000c498":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","1c5b026d03cbbb03ca4c0b97d14e9839682281dc","3615ce4a1f785ae1b779244de52c6a7d99227e60"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["a3a0403b45dfe384fae4a1b6e96c3265d000c498"],"b21422ff1d1d56499dec481f193b402e5e8def5b":["1a2e46fd1b7cbc52d7d6461a6ef99e7107ae2a9c"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["d572389229127c297dd1fa5ce4758e1cec41e799"],"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c":["a05409176bd65129d67a785ee70e881e238a9aef"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":[],"d572389229127c297dd1fa5ce4758e1cec41e799":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","b21422ff1d1d56499dec481f193b402e5e8def5b"],"b3e06be49006ecac364d39d12b9c9f74882f9b9f":["1509f151d7692d84fae414b2b799ac06ba60fcb4","135621f3a0670a9394eb563224a3b76cc4dddc0f","a3776dccca01c11e7046323cfad46a3b4a471233"],"962d04139994fce5193143ef35615499a9a96d78":["b3e06be49006ecac364d39d12b9c9f74882f9b9f"],"8be580b58bcc650d428f3f22de81cadcf51d650a":["6d8586807c39821ddee3082a1614a727742cf5b5"],"6d8586807c39821ddee3082a1614a727742cf5b5":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"a3776dccca01c11e7046323cfad46a3b4a471233":[],"3615ce4a1f785ae1b779244de52c6a7d99227e60":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","0e7c2454a6a8237bfd0e953f5b940838408c9055"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["93ccd971aca7fb61b7f1b946e44714cfc80bfc7c","135621f3a0670a9394eb563224a3b76cc4dddc0f","a3776dccca01c11e7046323cfad46a3b4a471233","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}