{"path":"lucene/core/src/test/org/apache/lucene/search/TestDocIdSet#testNullIteratorFilteredDocIdSet().mjava","commits":[{"id":"63d5e77dc0c22fbe4ab2445099a883b7218cb1f5","date":1329917688,"type":0,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestDocIdSet#testNullIteratorFilteredDocIdSet().mjava","pathOld":"/dev/null","sourceNew":"  public void testNullIteratorFilteredDocIdSet() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir);\n    Document doc = new Document();\n    doc.add(newField(\"c\", \"val\", StringField.TYPE_UNSTORED));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    // First verify the document is searchable.\n    IndexSearcher searcher = newSearcher(reader);\n    Assert.assertEquals(1, searcher.search(new MatchAllDocsQuery(), 10).totalHits);\n    \n      // Now search w/ a Filter which returns a null DocIdSet\n    Filter f = new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n        final DocIdSet innerNullIteratorSet = new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return null;\n          } \n        };\n        return new FilteredDocIdSet(innerNullIteratorSet) {\n          @Override\n          protected boolean match(int docid) {\n            return true;\n          }\t\n        };\n      }\n    };\n    \n    Assert.assertEquals(0, searcher.search(new MatchAllDocsQuery(), f, 10).totalHits);\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["04f07771a2a7dd3a395700665ed839c3dae2def2","4d3e8520fd031bab31fd0e4d480e55958bc45efe"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","date":1331075828,"type":0,"author":"Ryan McKinley","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestDocIdSet#testNullIteratorFilteredDocIdSet().mjava","pathOld":"/dev/null","sourceNew":"  public void testNullIteratorFilteredDocIdSet() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir);\n    Document doc = new Document();\n    doc.add(newField(\"c\", \"val\", StringField.TYPE_UNSTORED));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    // First verify the document is searchable.\n    IndexSearcher searcher = newSearcher(reader);\n    Assert.assertEquals(1, searcher.search(new MatchAllDocsQuery(), 10).totalHits);\n    \n      // Now search w/ a Filter which returns a null DocIdSet\n    Filter f = new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n        final DocIdSet innerNullIteratorSet = new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return null;\n          } \n        };\n        return new FilteredDocIdSet(innerNullIteratorSet) {\n          @Override\n          protected boolean match(int docid) {\n            return true;\n          }\t\n        };\n      }\n    };\n    \n    Assert.assertEquals(0, searcher.search(new MatchAllDocsQuery(), f, 10).totalHits);\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestDocIdSet#testNullIteratorFilteredDocIdSet().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestDocIdSet#testNullIteratorFilteredDocIdSet().mjava","sourceNew":"  public void testNullIteratorFilteredDocIdSet() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newField(\"c\", \"val\", StringField.TYPE_UNSTORED));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    // First verify the document is searchable.\n    IndexSearcher searcher = newSearcher(reader);\n    Assert.assertEquals(1, searcher.search(new MatchAllDocsQuery(), 10).totalHits);\n    \n      // Now search w/ a Filter which returns a null DocIdSet\n    Filter f = new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n        final DocIdSet innerNullIteratorSet = new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return null;\n          } \n        };\n        return new FilteredDocIdSet(innerNullIteratorSet) {\n          @Override\n          protected boolean match(int docid) {\n            return true;\n          }\t\n        };\n      }\n    };\n    \n    Assert.assertEquals(0, searcher.search(new MatchAllDocsQuery(), f, 10).totalHits);\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testNullIteratorFilteredDocIdSet() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir);\n    Document doc = new Document();\n    doc.add(newField(\"c\", \"val\", StringField.TYPE_UNSTORED));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    // First verify the document is searchable.\n    IndexSearcher searcher = newSearcher(reader);\n    Assert.assertEquals(1, searcher.search(new MatchAllDocsQuery(), 10).totalHits);\n    \n      // Now search w/ a Filter which returns a null DocIdSet\n    Filter f = new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n        final DocIdSet innerNullIteratorSet = new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return null;\n          } \n        };\n        return new FilteredDocIdSet(innerNullIteratorSet) {\n          @Override\n          protected boolean match(int docid) {\n            return true;\n          }\t\n        };\n      }\n    };\n    \n    Assert.assertEquals(0, searcher.search(new MatchAllDocsQuery(), f, 10).totalHits);\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"04f07771a2a7dd3a395700665ed839c3dae2def2","date":1339350139,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestDocIdSet#testNullIteratorFilteredDocIdSet().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestDocIdSet#testNullIteratorFilteredDocIdSet().mjava","sourceNew":"  public void testNullIteratorFilteredDocIdSet() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"c\", \"val\", Field.Store.NO));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    // First verify the document is searchable.\n    IndexSearcher searcher = newSearcher(reader);\n    Assert.assertEquals(1, searcher.search(new MatchAllDocsQuery(), 10).totalHits);\n    \n      // Now search w/ a Filter which returns a null DocIdSet\n    Filter f = new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n        final DocIdSet innerNullIteratorSet = new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return null;\n          } \n        };\n        return new FilteredDocIdSet(innerNullIteratorSet) {\n          @Override\n          protected boolean match(int docid) {\n            return true;\n          }\t\n        };\n      }\n    };\n    \n    Assert.assertEquals(0, searcher.search(new MatchAllDocsQuery(), f, 10).totalHits);\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testNullIteratorFilteredDocIdSet() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newField(\"c\", \"val\", StringField.TYPE_UNSTORED));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    // First verify the document is searchable.\n    IndexSearcher searcher = newSearcher(reader);\n    Assert.assertEquals(1, searcher.search(new MatchAllDocsQuery(), 10).totalHits);\n    \n      // Now search w/ a Filter which returns a null DocIdSet\n    Filter f = new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n        final DocIdSet innerNullIteratorSet = new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return null;\n          } \n        };\n        return new FilteredDocIdSet(innerNullIteratorSet) {\n          @Override\n          protected boolean match(int docid) {\n            return true;\n          }\t\n        };\n      }\n    };\n    \n    Assert.assertEquals(0, searcher.search(new MatchAllDocsQuery(), f, 10).totalHits);\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":["63d5e77dc0c22fbe4ab2445099a883b7218cb1f5"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4d3e8520fd031bab31fd0e4d480e55958bc45efe","date":1340901565,"type":3,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestDocIdSet#testNullIteratorFilteredDocIdSet().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestDocIdSet#testNullIteratorFilteredDocIdSet().mjava","sourceNew":"  public void testNullIteratorFilteredDocIdSet() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"c\", \"val\", Field.Store.NO));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    // First verify the document is searchable.\n    IndexSearcher searcher = newSearcher(reader);\n    Assert.assertEquals(1, searcher.search(new MatchAllDocsQuery(), 10).totalHits);\n    \n      // Now search w/ a Filter which returns a null DocIdSet\n    Filter f = new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) {\n        final DocIdSet innerNullIteratorSet = new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return null;\n          } \n        };\n        return new FilteredDocIdSet(innerNullIteratorSet) {\n          @Override\n          protected boolean match(int docid) {\n            return true;\n          }\t\n        };\n      }\n    };\n    \n    Assert.assertEquals(0, searcher.search(new MatchAllDocsQuery(), f, 10).totalHits);\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testNullIteratorFilteredDocIdSet() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"c\", \"val\", Field.Store.NO));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    // First verify the document is searchable.\n    IndexSearcher searcher = newSearcher(reader);\n    Assert.assertEquals(1, searcher.search(new MatchAllDocsQuery(), 10).totalHits);\n    \n      // Now search w/ a Filter which returns a null DocIdSet\n    Filter f = new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n        final DocIdSet innerNullIteratorSet = new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return null;\n          } \n        };\n        return new FilteredDocIdSet(innerNullIteratorSet) {\n          @Override\n          protected boolean match(int docid) {\n            return true;\n          }\t\n        };\n      }\n    };\n    \n    Assert.assertEquals(0, searcher.search(new MatchAllDocsQuery(), f, 10).totalHits);\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":["63d5e77dc0c22fbe4ab2445099a883b7218cb1f5"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fe33227f6805edab2036cbb80645cc4e2d1fa424","date":1342713534,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestDocIdSet#testNullIteratorFilteredDocIdSet().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestDocIdSet#testNullIteratorFilteredDocIdSet().mjava","sourceNew":"  public void testNullIteratorFilteredDocIdSet() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"c\", \"val\", Field.Store.NO));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    // First verify the document is searchable.\n    IndexSearcher searcher = newSearcher(reader);\n    Assert.assertEquals(1, searcher.search(new MatchAllDocsQuery(), 10).totalHits);\n    \n      // Now search w/ a Filter which returns a null DocIdSet\n    Filter f = new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) {\n        final DocIdSet innerNullIteratorSet = new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return null;\n          } \n        };\n        return new FilteredDocIdSet(innerNullIteratorSet) {\n          @Override\n          protected boolean match(int docid) {\n            return true;\n          }\t\n        };\n      }\n    };\n    \n    Assert.assertEquals(0, searcher.search(new MatchAllDocsQuery(), f, 10).totalHits);\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testNullIteratorFilteredDocIdSet() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"c\", \"val\", Field.Store.NO));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    // First verify the document is searchable.\n    IndexSearcher searcher = newSearcher(reader);\n    Assert.assertEquals(1, searcher.search(new MatchAllDocsQuery(), 10).totalHits);\n    \n      // Now search w/ a Filter which returns a null DocIdSet\n    Filter f = new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n        final DocIdSet innerNullIteratorSet = new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return null;\n          } \n        };\n        return new FilteredDocIdSet(innerNullIteratorSet) {\n          @Override\n          protected boolean match(int docid) {\n            return true;\n          }\t\n        };\n      }\n    };\n    \n    Assert.assertEquals(0, searcher.search(new MatchAllDocsQuery(), f, 10).totalHits);\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4093b270ba337f9c25a4c0e6cb2ae2c07f697376","date":1347897716,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestDocIdSet#testNullIteratorFilteredDocIdSet().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestDocIdSet#testNullIteratorFilteredDocIdSet().mjava","sourceNew":"  public void testNullIteratorFilteredDocIdSet() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"c\", \"val\", Field.Store.NO));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    // First verify the document is searchable.\n    IndexSearcher searcher = newSearcher(reader);\n    Assert.assertEquals(1, searcher.search(new MatchAllDocsQuery(), 10).totalHits);\n    \n      // Now search w/ a Filter which returns a null DocIdSet\n    Filter f = new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) {\n        final DocIdSet innerNullIteratorSet = new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return null;\n          } \n        };\n        return new FilteredDocIdSet(innerNullIteratorSet) {\n          @Override\n          protected boolean match(int docid) {\n            return true;\n          }\n        };\n      }\n    };\n    \n    Assert.assertEquals(0, searcher.search(new MatchAllDocsQuery(), f, 10).totalHits);\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testNullIteratorFilteredDocIdSet() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"c\", \"val\", Field.Store.NO));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    // First verify the document is searchable.\n    IndexSearcher searcher = newSearcher(reader);\n    Assert.assertEquals(1, searcher.search(new MatchAllDocsQuery(), 10).totalHits);\n    \n      // Now search w/ a Filter which returns a null DocIdSet\n    Filter f = new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) {\n        final DocIdSet innerNullIteratorSet = new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return null;\n          } \n        };\n        return new FilteredDocIdSet(innerNullIteratorSet) {\n          @Override\n          protected boolean match(int docid) {\n            return true;\n          }\t\n        };\n      }\n    };\n    \n    Assert.assertEquals(0, searcher.search(new MatchAllDocsQuery(), f, 10).totalHits);\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestDocIdSet#testNullIteratorFilteredDocIdSet().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestDocIdSet#testNullIteratorFilteredDocIdSet().mjava","sourceNew":"  public void testNullIteratorFilteredDocIdSet() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"c\", \"val\", Field.Store.NO));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.shutdown();\n    \n    // First verify the document is searchable.\n    IndexSearcher searcher = newSearcher(reader);\n    Assert.assertEquals(1, searcher.search(new MatchAllDocsQuery(), 10).totalHits);\n    \n      // Now search w/ a Filter which returns a null DocIdSet\n    Filter f = new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) {\n        final DocIdSet innerNullIteratorSet = new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return null;\n          } \n        };\n        return new FilteredDocIdSet(innerNullIteratorSet) {\n          @Override\n          protected boolean match(int docid) {\n            return true;\n          }\n        };\n      }\n    };\n    \n    Assert.assertEquals(0, searcher.search(new MatchAllDocsQuery(), f, 10).totalHits);\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testNullIteratorFilteredDocIdSet() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"c\", \"val\", Field.Store.NO));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    // First verify the document is searchable.\n    IndexSearcher searcher = newSearcher(reader);\n    Assert.assertEquals(1, searcher.search(new MatchAllDocsQuery(), 10).totalHits);\n    \n      // Now search w/ a Filter which returns a null DocIdSet\n    Filter f = new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) {\n        final DocIdSet innerNullIteratorSet = new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return null;\n          } \n        };\n        return new FilteredDocIdSet(innerNullIteratorSet) {\n          @Override\n          protected boolean match(int docid) {\n            return true;\n          }\n        };\n      }\n    };\n    \n    Assert.assertEquals(0, searcher.search(new MatchAllDocsQuery(), f, 10).totalHits);\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54ea8c8c94ae9da9a366175e2abbe1dde3aa0453","date":1402659583,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestDocIdSet#testNullIteratorFilteredDocIdSet().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestDocIdSet#testNullIteratorFilteredDocIdSet().mjava","sourceNew":"  public void testNullIteratorFilteredDocIdSet() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"c\", \"val\", Field.Store.NO));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.shutdown();\n    \n    // First verify the document is searchable.\n    IndexSearcher searcher = newSearcher(reader);\n    Assert.assertEquals(1, searcher.search(new MatchAllDocsQuery(), 10).totalHits);\n    \n      // Now search w/ a Filter which returns a null DocIdSet\n    Filter f = new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) {\n        final DocIdSet innerNullIteratorSet = new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return null;\n          } \n\n          @Override\n          public long ramBytesUsed() {\n            return 0L;\n          }\n        };\n        return new FilteredDocIdSet(innerNullIteratorSet) {\n          @Override\n          protected boolean match(int docid) {\n            return true;\n          }\n        };\n      }\n    };\n    \n    Assert.assertEquals(0, searcher.search(new MatchAllDocsQuery(), f, 10).totalHits);\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testNullIteratorFilteredDocIdSet() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"c\", \"val\", Field.Store.NO));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.shutdown();\n    \n    // First verify the document is searchable.\n    IndexSearcher searcher = newSearcher(reader);\n    Assert.assertEquals(1, searcher.search(new MatchAllDocsQuery(), 10).totalHits);\n    \n      // Now search w/ a Filter which returns a null DocIdSet\n    Filter f = new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) {\n        final DocIdSet innerNullIteratorSet = new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return null;\n          } \n        };\n        return new FilteredDocIdSet(innerNullIteratorSet) {\n          @Override\n          protected boolean match(int docid) {\n            return true;\n          }\n        };\n      }\n    };\n    \n    Assert.assertEquals(0, searcher.search(new MatchAllDocsQuery(), f, 10).totalHits);\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c6f080a2ab37c464dd98db173f6cbf10dc74f211","date":1402946779,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestDocIdSet#testNullIteratorFilteredDocIdSet().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestDocIdSet#testNullIteratorFilteredDocIdSet().mjava","sourceNew":"  public void testNullIteratorFilteredDocIdSet() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"c\", \"val\", Field.Store.NO));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.shutdown();\n    \n    // First verify the document is searchable.\n    IndexSearcher searcher = newSearcher(reader);\n    Assert.assertEquals(1, searcher.search(new MatchAllDocsQuery(), 10).totalHits);\n    \n      // Now search w/ a Filter which returns a null DocIdSet\n    Filter f = new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) {\n        final DocIdSet innerNullIteratorSet = new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return null;\n          } \n\n          @Override\n          public long ramBytesUsed() {\n            return 0L;\n          }\n        };\n        return new FilteredDocIdSet(innerNullIteratorSet) {\n          @Override\n          protected boolean match(int docid) {\n            return true;\n          }\n        };\n      }\n    };\n    \n    Assert.assertEquals(0, searcher.search(new MatchAllDocsQuery(), f, 10).totalHits);\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testNullIteratorFilteredDocIdSet() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"c\", \"val\", Field.Store.NO));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.shutdown();\n    \n    // First verify the document is searchable.\n    IndexSearcher searcher = newSearcher(reader);\n    Assert.assertEquals(1, searcher.search(new MatchAllDocsQuery(), 10).totalHits);\n    \n      // Now search w/ a Filter which returns a null DocIdSet\n    Filter f = new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) {\n        final DocIdSet innerNullIteratorSet = new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return null;\n          } \n        };\n        return new FilteredDocIdSet(innerNullIteratorSet) {\n          @Override\n          protected boolean match(int docid) {\n            return true;\n          }\n        };\n      }\n    };\n    \n    Assert.assertEquals(0, searcher.search(new MatchAllDocsQuery(), f, 10).totalHits);\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestDocIdSet#testNullIteratorFilteredDocIdSet().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestDocIdSet#testNullIteratorFilteredDocIdSet().mjava","sourceNew":"  public void testNullIteratorFilteredDocIdSet() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"c\", \"val\", Field.Store.NO));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    // First verify the document is searchable.\n    IndexSearcher searcher = newSearcher(reader);\n    Assert.assertEquals(1, searcher.search(new MatchAllDocsQuery(), 10).totalHits);\n    \n      // Now search w/ a Filter which returns a null DocIdSet\n    Filter f = new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) {\n        final DocIdSet innerNullIteratorSet = new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return null;\n          } \n\n          @Override\n          public long ramBytesUsed() {\n            return 0L;\n          }\n        };\n        return new FilteredDocIdSet(innerNullIteratorSet) {\n          @Override\n          protected boolean match(int docid) {\n            return true;\n          }\n        };\n      }\n    };\n    \n    Assert.assertEquals(0, searcher.search(new MatchAllDocsQuery(), f, 10).totalHits);\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testNullIteratorFilteredDocIdSet() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"c\", \"val\", Field.Store.NO));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.shutdown();\n    \n    // First verify the document is searchable.\n    IndexSearcher searcher = newSearcher(reader);\n    Assert.assertEquals(1, searcher.search(new MatchAllDocsQuery(), 10).totalHits);\n    \n      // Now search w/ a Filter which returns a null DocIdSet\n    Filter f = new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) {\n        final DocIdSet innerNullIteratorSet = new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return null;\n          } \n\n          @Override\n          public long ramBytesUsed() {\n            return 0L;\n          }\n        };\n        return new FilteredDocIdSet(innerNullIteratorSet) {\n          @Override\n          protected boolean match(int docid) {\n            return true;\n          }\n        };\n      }\n    };\n    \n    Assert.assertEquals(0, searcher.search(new MatchAllDocsQuery(), f, 10).totalHits);\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c9fb5f46e264daf5ba3860defe623a89d202dd87","date":1411516315,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestDocIdSet#testNullIteratorFilteredDocIdSet().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestDocIdSet#testNullIteratorFilteredDocIdSet().mjava","sourceNew":"  public void testNullIteratorFilteredDocIdSet() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"c\", \"val\", Field.Store.NO));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    // First verify the document is searchable.\n    IndexSearcher searcher = newSearcher(reader);\n    Assert.assertEquals(1, searcher.search(new MatchAllDocsQuery(), 10).totalHits);\n    \n      // Now search w/ a Filter which returns a null DocIdSet\n    Filter f = new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(LeafReaderContext context, Bits acceptDocs) {\n        final DocIdSet innerNullIteratorSet = new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return null;\n          } \n\n          @Override\n          public long ramBytesUsed() {\n            return 0L;\n          }\n        };\n        return new FilteredDocIdSet(innerNullIteratorSet) {\n          @Override\n          protected boolean match(int docid) {\n            return true;\n          }\n        };\n      }\n    };\n    \n    Assert.assertEquals(0, searcher.search(new MatchAllDocsQuery(), f, 10).totalHits);\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testNullIteratorFilteredDocIdSet() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"c\", \"val\", Field.Store.NO));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    // First verify the document is searchable.\n    IndexSearcher searcher = newSearcher(reader);\n    Assert.assertEquals(1, searcher.search(new MatchAllDocsQuery(), 10).totalHits);\n    \n      // Now search w/ a Filter which returns a null DocIdSet\n    Filter f = new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) {\n        final DocIdSet innerNullIteratorSet = new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return null;\n          } \n\n          @Override\n          public long ramBytesUsed() {\n            return 0L;\n          }\n        };\n        return new FilteredDocIdSet(innerNullIteratorSet) {\n          @Override\n          protected boolean match(int docid) {\n            return true;\n          }\n        };\n      }\n    };\n    \n    Assert.assertEquals(0, searcher.search(new MatchAllDocsQuery(), f, 10).totalHits);\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fb58c5f77afb63ba911f6d62f4c1d89f15e56dc6","date":1424027250,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestDocIdSet#testNullIteratorFilteredDocIdSet().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestDocIdSet#testNullIteratorFilteredDocIdSet().mjava","sourceNew":"  public void testNullIteratorFilteredDocIdSet() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"c\", \"val\", Field.Store.NO));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    // First verify the document is searchable.\n    IndexSearcher searcher = newSearcher(reader);\n    Assert.assertEquals(1, searcher.search(new MatchAllDocsQuery(), 10).totalHits);\n    \n      // Now search w/ a Filter which returns a null DocIdSet\n    Filter f = new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(LeafReaderContext context, Bits acceptDocs) {\n        final DocIdSet innerNullIteratorSet = new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return null;\n          } \n\n          @Override\n          public long ramBytesUsed() {\n            return 0L;\n          }\n        };\n        return new FilteredDocIdSet(innerNullIteratorSet) {\n          @Override\n          protected boolean match(int docid) {\n            return true;\n          }\n        };\n      }\n      @Override\n      public String toString(String field) {\n        return \"nullDocIdSetFilter\";\n      }\n    };\n    \n    Assert.assertEquals(0, searcher.search(new MatchAllDocsQuery(), f, 10).totalHits);\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testNullIteratorFilteredDocIdSet() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"c\", \"val\", Field.Store.NO));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    // First verify the document is searchable.\n    IndexSearcher searcher = newSearcher(reader);\n    Assert.assertEquals(1, searcher.search(new MatchAllDocsQuery(), 10).totalHits);\n    \n      // Now search w/ a Filter which returns a null DocIdSet\n    Filter f = new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(LeafReaderContext context, Bits acceptDocs) {\n        final DocIdSet innerNullIteratorSet = new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return null;\n          } \n\n          @Override\n          public long ramBytesUsed() {\n            return 0L;\n          }\n        };\n        return new FilteredDocIdSet(innerNullIteratorSet) {\n          @Override\n          protected boolean match(int docid) {\n            return true;\n          }\n        };\n      }\n    };\n    \n    Assert.assertEquals(0, searcher.search(new MatchAllDocsQuery(), f, 10).totalHits);\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc","date":1424799790,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestDocIdSet#testNullIteratorFilteredDocIdSet().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestDocIdSet#testNullIteratorFilteredDocIdSet().mjava","sourceNew":"  public void testNullIteratorFilteredDocIdSet() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"c\", \"val\", Field.Store.NO));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    // First verify the document is searchable.\n    IndexSearcher searcher = newSearcher(reader);\n    Assert.assertEquals(1, searcher.search(new MatchAllDocsQuery(), 10).totalHits);\n    \n      // Now search w/ a Filter which returns a null DocIdSet\n    Filter f = new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(LeafReaderContext context, Bits acceptDocs) {\n        final DocIdSet innerNullIteratorSet = new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return null;\n          } \n\n          @Override\n          public long ramBytesUsed() {\n            return 0L;\n          }\n        };\n        return new FilteredDocIdSet(innerNullIteratorSet) {\n          @Override\n          protected boolean match(int docid) {\n            return true;\n          }\n        };\n      }\n      @Override\n      public String toString(String field) {\n        return \"nullDocIdSetFilter\";\n      }\n    };\n    \n    Assert.assertEquals(0, searcher.search(new FilteredQuery(new MatchAllDocsQuery(), f), 10).totalHits);\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testNullIteratorFilteredDocIdSet() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"c\", \"val\", Field.Store.NO));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    // First verify the document is searchable.\n    IndexSearcher searcher = newSearcher(reader);\n    Assert.assertEquals(1, searcher.search(new MatchAllDocsQuery(), 10).totalHits);\n    \n      // Now search w/ a Filter which returns a null DocIdSet\n    Filter f = new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(LeafReaderContext context, Bits acceptDocs) {\n        final DocIdSet innerNullIteratorSet = new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return null;\n          } \n\n          @Override\n          public long ramBytesUsed() {\n            return 0L;\n          }\n        };\n        return new FilteredDocIdSet(innerNullIteratorSet) {\n          @Override\n          protected boolean match(int docid) {\n            return true;\n          }\n        };\n      }\n      @Override\n      public String toString(String field) {\n        return \"nullDocIdSetFilter\";\n      }\n    };\n    \n    Assert.assertEquals(0, searcher.search(new MatchAllDocsQuery(), f, 10).totalHits);\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1db68e96dd908fcd79ef809095822736aa601d08","date":1434630596,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestDocIdSet#testNullIteratorFilteredDocIdSet().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestDocIdSet#testNullIteratorFilteredDocIdSet().mjava","sourceNew":"  public void testNullIteratorFilteredDocIdSet() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"c\", \"val\", Field.Store.NO));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    // First verify the document is searchable.\n    IndexSearcher searcher = newSearcher(reader);\n    Assert.assertEquals(1, searcher.search(new MatchAllDocsQuery(), 10).totalHits);\n    \n      // Now search w/ a Filter which returns a null DocIdSet\n    Filter f = new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(LeafReaderContext context, Bits acceptDocs) {\n        final DocIdSet innerNullIteratorSet = new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return null;\n          } \n\n          @Override\n          public long ramBytesUsed() {\n            return 0L;\n          }\n        };\n        return new FilteredDocIdSet(innerNullIteratorSet) {\n          @Override\n          protected boolean match(int docid) {\n            return true;\n          }\n        };\n      }\n      @Override\n      public String toString(String field) {\n        return \"nullDocIdSetFilter\";\n      }\n    };\n    \n    Query filtered = new BooleanQuery.Builder()\n        .add(new MatchAllDocsQuery(), Occur.MUST)\n        .add(f, Occur.FILTER)\n        .build();\n    Assert.assertEquals(0, searcher.search(filtered, 10).totalHits);\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testNullIteratorFilteredDocIdSet() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"c\", \"val\", Field.Store.NO));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    // First verify the document is searchable.\n    IndexSearcher searcher = newSearcher(reader);\n    Assert.assertEquals(1, searcher.search(new MatchAllDocsQuery(), 10).totalHits);\n    \n      // Now search w/ a Filter which returns a null DocIdSet\n    Filter f = new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(LeafReaderContext context, Bits acceptDocs) {\n        final DocIdSet innerNullIteratorSet = new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return null;\n          } \n\n          @Override\n          public long ramBytesUsed() {\n            return 0L;\n          }\n        };\n        return new FilteredDocIdSet(innerNullIteratorSet) {\n          @Override\n          protected boolean match(int docid) {\n            return true;\n          }\n        };\n      }\n      @Override\n      public String toString(String field) {\n        return \"nullDocIdSetFilter\";\n      }\n    };\n    \n    Assert.assertEquals(0, searcher.search(new FilteredQuery(new MatchAllDocsQuery(), f), 10).totalHits);\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d52e48927ca4ef3655a261f2230b968b6fdf3608","date":1444652107,"type":5,"author":"Adrien Grand","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestFilteredDocIdSet#testNullIteratorFilteredDocIdSet().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestDocIdSet#testNullIteratorFilteredDocIdSet().mjava","sourceNew":"  public void testNullIteratorFilteredDocIdSet() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"c\", \"val\", Field.Store.NO));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    // First verify the document is searchable.\n    IndexSearcher searcher = newSearcher(reader);\n    Assert.assertEquals(1, searcher.search(new MatchAllDocsQuery(), 10).totalHits);\n    \n      // Now search w/ a Filter which returns a null DocIdSet\n    Filter f = new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(LeafReaderContext context, Bits acceptDocs) {\n        final DocIdSet innerNullIteratorSet = new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return null;\n          } \n\n          @Override\n          public long ramBytesUsed() {\n            return 0L;\n          }\n        };\n        return new FilteredDocIdSet(innerNullIteratorSet) {\n          @Override\n          protected boolean match(int docid) {\n            return true;\n          }\n        };\n      }\n      @Override\n      public String toString(String field) {\n        return \"nullDocIdSetFilter\";\n      }\n    };\n    \n    Query filtered = new BooleanQuery.Builder()\n        .add(new MatchAllDocsQuery(), Occur.MUST)\n        .add(f, Occur.FILTER)\n        .build();\n    Assert.assertEquals(0, searcher.search(filtered, 10).totalHits);\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testNullIteratorFilteredDocIdSet() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    Document doc = new Document();\n    doc.add(newStringField(\"c\", \"val\", Field.Store.NO));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    // First verify the document is searchable.\n    IndexSearcher searcher = newSearcher(reader);\n    Assert.assertEquals(1, searcher.search(new MatchAllDocsQuery(), 10).totalHits);\n    \n      // Now search w/ a Filter which returns a null DocIdSet\n    Filter f = new Filter() {\n      @Override\n      public DocIdSet getDocIdSet(LeafReaderContext context, Bits acceptDocs) {\n        final DocIdSet innerNullIteratorSet = new DocIdSet() {\n          @Override\n          public DocIdSetIterator iterator() {\n            return null;\n          } \n\n          @Override\n          public long ramBytesUsed() {\n            return 0L;\n          }\n        };\n        return new FilteredDocIdSet(innerNullIteratorSet) {\n          @Override\n          protected boolean match(int docid) {\n            return true;\n          }\n        };\n      }\n      @Override\n      public String toString(String field) {\n        return \"nullDocIdSetFilter\";\n      }\n    };\n    \n    Query filtered = new BooleanQuery.Builder()\n        .add(new MatchAllDocsQuery(), Occur.MUST)\n        .add(f, Occur.FILTER)\n        .build();\n    Assert.assertEquals(0, searcher.search(filtered, 10).totalHits);\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"63d5e77dc0c22fbe4ab2445099a883b7218cb1f5":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"54ea8c8c94ae9da9a366175e2abbe1dde3aa0453":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","63d5e77dc0c22fbe4ab2445099a883b7218cb1f5"],"c6f080a2ab37c464dd98db173f6cbf10dc74f211":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a","54ea8c8c94ae9da9a366175e2abbe1dde3aa0453"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"fb58c5f77afb63ba911f6d62f4c1d89f15e56dc6":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"04f07771a2a7dd3a395700665ed839c3dae2def2":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"1db68e96dd908fcd79ef809095822736aa601d08":["f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc"],"d52e48927ca4ef3655a261f2230b968b6fdf3608":["1db68e96dd908fcd79ef809095822736aa601d08"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":["04f07771a2a7dd3a395700665ed839c3dae2def2","4d3e8520fd031bab31fd0e4d480e55958bc45efe"],"f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc":["fb58c5f77afb63ba911f6d62f4c1d89f15e56dc6"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["54ea8c8c94ae9da9a366175e2abbe1dde3aa0453"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["4093b270ba337f9c25a4c0e6cb2ae2c07f697376"],"4d3e8520fd031bab31fd0e4d480e55958bc45efe":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["63d5e77dc0c22fbe4ab2445099a883b7218cb1f5"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["d52e48927ca4ef3655a261f2230b968b6fdf3608"],"4093b270ba337f9c25a4c0e6cb2ae2c07f697376":["4d3e8520fd031bab31fd0e4d480e55958bc45efe"]},"commit2Childs":{"63d5e77dc0c22fbe4ab2445099a883b7218cb1f5":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"54ea8c8c94ae9da9a366175e2abbe1dde3aa0453":["c6f080a2ab37c464dd98db173f6cbf10dc74f211","d0ef034a4f10871667ae75181537775ddcf8ade4"],"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab":[],"c6f080a2ab37c464dd98db173f6cbf10dc74f211":[],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["fb58c5f77afb63ba911f6d62f4c1d89f15e56dc6"],"fb58c5f77afb63ba911f6d62f4c1d89f15e56dc6":["f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc"],"04f07771a2a7dd3a395700665ed839c3dae2def2":["fe33227f6805edab2036cbb80645cc4e2d1fa424","4d3e8520fd031bab31fd0e4d480e55958bc45efe"],"1db68e96dd908fcd79ef809095822736aa601d08":["d52e48927ca4ef3655a261f2230b968b6fdf3608"],"d52e48927ca4ef3655a261f2230b968b6fdf3608":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["63d5e77dc0c22fbe4ab2445099a883b7218cb1f5","9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab"],"f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc":["1db68e96dd908fcd79ef809095822736aa601d08"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["54ea8c8c94ae9da9a366175e2abbe1dde3aa0453","c6f080a2ab37c464dd98db173f6cbf10dc74f211"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"4d3e8520fd031bab31fd0e4d480e55958bc45efe":["fe33227f6805edab2036cbb80645cc4e2d1fa424","4093b270ba337f9c25a4c0e6cb2ae2c07f697376"],"4093b270ba337f9c25a4c0e6cb2ae2c07f697376":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","c6f080a2ab37c464dd98db173f6cbf10dc74f211","fe33227f6805edab2036cbb80645cc4e2d1fa424","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}