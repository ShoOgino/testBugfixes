{"path":"lucene/core/src/java/org/apache/lucene/index/IndexWriter.ReaderPool#release(ReadersAndLiveDocs,boolean).mjava","commits":[{"id":"8da3c22a3b1a00ae6e2664f3ac0d82cfa3a8f666","date":1381263930,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter.ReaderPool#release(ReadersAndLiveDocs,boolean).mjava","pathOld":"/dev/null","sourceNew":"    public synchronized void release(ReadersAndLiveDocs rld, boolean assertInfoLive) throws IOException {\n\n      // Matches incRef in get:\n      rld.decRef();\n\n      // Pool still holds a ref:\n      assert rld.refCount() >= 1;\n\n      if (!poolReaders && rld.refCount() == 1) {\n        // This is the last ref to this RLD, and we're not\n        // pooling, so remove it:\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"] ReaderPool.release: \" + rld.info);\n        if (rld.writeLiveDocs(directory)) {\n          // Make sure we only write del docs and field updates for a live segment:\n          assert assertInfoLive == false || infoIsLive(rld.info);\n          // Must checkpoint because we just\n          // created new _X_N.del and field updates files;\n          // don't call IW.checkpoint because that also\n          // increments SIS.version, which we do not want to\n          // do here: it was done previously (after we\n          // invoked BDS.applyDeletes), whereas here all we\n          // did was move the state to disk:\n          checkpointNoSIS();\n        }\n        //System.out.println(\"IW: done writeLiveDocs for info=\" + rld.info);\n\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"] ReaderPool.release: drop readers \" + rld.info);\n        rld.dropReaders();\n        readerMap.remove(rld.info);\n      }\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1bae040fd1d5e03e0d8d695a9c25cf4f402e7ffe","date":1381909398,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter.ReaderPool#release(ReadersAndLiveDocs,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter.ReaderPool#release(ReadersAndLiveDocs,boolean).mjava","sourceNew":"    public synchronized void release(ReadersAndLiveDocs rld, boolean assertInfoLive) throws IOException {\n\n      // Matches incRef in get:\n      rld.decRef();\n\n      // Pool still holds a ref:\n      assert rld.refCount() >= 1;\n\n      if (!poolReaders && rld.refCount() == 1) {\n        // This is the last ref to this RLD, and we're not\n        // pooling, so remove it:\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"] ReaderPool.release: \" + rld.info);\n        if (rld.writeLiveDocs(directory)) {\n          // Make sure we only write del docs for a live segment:\n          assert assertInfoLive == false || infoIsLive(rld.info);\n          // Must checkpoint because we just\n          // created new _X_N.del and field updates files;\n          // don't call IW.checkpoint because that also\n          // increments SIS.version, which we do not want to\n          // do here: it was done previously (after we\n          // invoked BDS.applyDeletes), whereas here all we\n          // did was move the state to disk:\n          checkpointNoSIS();\n        }\n        //System.out.println(\"IW: done writeLiveDocs for info=\" + rld.info);\n\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"] ReaderPool.release: drop readers \" + rld.info);\n        rld.dropReaders();\n        readerMap.remove(rld.info);\n      }\n    }\n\n","sourceOld":"    public synchronized void release(ReadersAndLiveDocs rld, boolean assertInfoLive) throws IOException {\n\n      // Matches incRef in get:\n      rld.decRef();\n\n      // Pool still holds a ref:\n      assert rld.refCount() >= 1;\n\n      if (!poolReaders && rld.refCount() == 1) {\n        // This is the last ref to this RLD, and we're not\n        // pooling, so remove it:\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"] ReaderPool.release: \" + rld.info);\n        if (rld.writeLiveDocs(directory)) {\n          // Make sure we only write del docs and field updates for a live segment:\n          assert assertInfoLive == false || infoIsLive(rld.info);\n          // Must checkpoint because we just\n          // created new _X_N.del and field updates files;\n          // don't call IW.checkpoint because that also\n          // increments SIS.version, which we do not want to\n          // do here: it was done previously (after we\n          // invoked BDS.applyDeletes), whereas here all we\n          // did was move the state to disk:\n          checkpointNoSIS();\n        }\n        //System.out.println(\"IW: done writeLiveDocs for info=\" + rld.info);\n\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"] ReaderPool.release: drop readers \" + rld.info);\n        rld.dropReaders();\n        readerMap.remove(rld.info);\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0","date":1383367127,"type":5,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter.ReaderPool#release(ReadersAndUpdates,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter.ReaderPool#release(ReadersAndLiveDocs,boolean).mjava","sourceNew":"    public synchronized void release(ReadersAndUpdates rld, boolean assertInfoLive) throws IOException {\n\n      // Matches incRef in get:\n      rld.decRef();\n\n      // Pool still holds a ref:\n      assert rld.refCount() >= 1;\n\n      if (!poolReaders && rld.refCount() == 1) {\n        // This is the last ref to this RLD, and we're not\n        // pooling, so remove it:\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"] ReaderPool.release: \" + rld.info);\n        if (rld.writeLiveDocs(directory)) {\n          // Make sure we only write del docs for a live segment:\n          assert assertInfoLive == false || infoIsLive(rld.info);\n          // Must checkpoint because we just\n          // created new _X_N.del and field updates files;\n          // don't call IW.checkpoint because that also\n          // increments SIS.version, which we do not want to\n          // do here: it was done previously (after we\n          // invoked BDS.applyDeletes), whereas here all we\n          // did was move the state to disk:\n          checkpointNoSIS();\n        }\n        //System.out.println(\"IW: done writeLiveDocs for info=\" + rld.info);\n\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"] ReaderPool.release: drop readers \" + rld.info);\n        rld.dropReaders();\n        readerMap.remove(rld.info);\n      }\n    }\n\n","sourceOld":"    public synchronized void release(ReadersAndLiveDocs rld, boolean assertInfoLive) throws IOException {\n\n      // Matches incRef in get:\n      rld.decRef();\n\n      // Pool still holds a ref:\n      assert rld.refCount() >= 1;\n\n      if (!poolReaders && rld.refCount() == 1) {\n        // This is the last ref to this RLD, and we're not\n        // pooling, so remove it:\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"] ReaderPool.release: \" + rld.info);\n        if (rld.writeLiveDocs(directory)) {\n          // Make sure we only write del docs for a live segment:\n          assert assertInfoLive == false || infoIsLive(rld.info);\n          // Must checkpoint because we just\n          // created new _X_N.del and field updates files;\n          // don't call IW.checkpoint because that also\n          // increments SIS.version, which we do not want to\n          // do here: it was done previously (after we\n          // invoked BDS.applyDeletes), whereas here all we\n          // did was move the state to disk:\n          checkpointNoSIS();\n        }\n        //System.out.println(\"IW: done writeLiveDocs for info=\" + rld.info);\n\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"] ReaderPool.release: drop readers \" + rld.info);\n        rld.dropReaders();\n        readerMap.remove(rld.info);\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"8da3c22a3b1a00ae6e2664f3ac0d82cfa3a8f666":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0":["1bae040fd1d5e03e0d8d695a9c25cf4f402e7ffe"],"1bae040fd1d5e03e0d8d695a9c25cf4f402e7ffe":["8da3c22a3b1a00ae6e2664f3ac0d82cfa3a8f666"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0"]},"commit2Childs":{"8da3c22a3b1a00ae6e2664f3ac0d82cfa3a8f666":["1bae040fd1d5e03e0d8d695a9c25cf4f402e7ffe"],"73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"1bae040fd1d5e03e0d8d695a9c25cf4f402e7ffe":["73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["8da3c22a3b1a00ae6e2664f3ac0d82cfa3a8f666"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}