{"path":"src/test/org/apache/lucene/analysis/TestStopAnalyzer#testStopListPositions().mjava","commits":[{"id":"693d6573b6621fc1265316fc6b042c24235c81d8","date":1199049557,"type":0,"author":"Doron Cohen","isMerge":false,"pathNew":"src/test/org/apache/lucene/analysis/TestStopAnalyzer#testStopListPositions().mjava","pathOld":"/dev/null","sourceNew":"  public void testStopListPositions() throws IOException {\n    boolean defaultEnable = StopFilter.getEnablePositionIncrementsDefault();\n    StopFilter.setEnablePositionIncrementsDefault(true);\n    try {\n      Set stopWordsSet = new HashSet();\n      stopWordsSet.add(\"good\");\n      stopWordsSet.add(\"test\");\n      stopWordsSet.add(\"analyzer\");\n      StopAnalyzer newStop = new StopAnalyzer((String[])stopWordsSet.toArray(new String[3]));\n      StringReader reader = new StringReader(\"This is a good test of the english stop analyzer with positions\");\n      int expectedIncr[] =                  { 1,   1, 1,          3, 1,  1,      1,            2,   1};\n      TokenStream stream = newStop.tokenStream(\"test\", reader);\n      assertNotNull(stream);\n      Token token = null;\n      int i = 0;\n      while ((token = stream.next()) != null) {\n        String text = token.termText();\n        assertFalse(stopWordsSet.contains(text));\n        assertEquals(expectedIncr[i++],token.getPositionIncrement());\n      }\n    } finally {\n      StopFilter.setEnablePositionIncrementsDefault(defaultEnable);\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7e2cb543b41c145f33390f460ee743d6693c9c6c","date":1219243087,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/analysis/TestStopAnalyzer#testStopListPositions().mjava","pathOld":"src/test/org/apache/lucene/analysis/TestStopAnalyzer#testStopListPositions().mjava","sourceNew":"  public void testStopListPositions() throws IOException {\n    boolean defaultEnable = StopFilter.getEnablePositionIncrementsDefault();\n    StopFilter.setEnablePositionIncrementsDefault(true);\n    try {\n      Set stopWordsSet = new HashSet();\n      stopWordsSet.add(\"good\");\n      stopWordsSet.add(\"test\");\n      stopWordsSet.add(\"analyzer\");\n      StopAnalyzer newStop = new StopAnalyzer((String[])stopWordsSet.toArray(new String[3]));\n      StringReader reader = new StringReader(\"This is a good test of the english stop analyzer with positions\");\n      int expectedIncr[] =                  { 1,   1, 1,          3, 1,  1,      1,            2,   1};\n      TokenStream stream = newStop.tokenStream(\"test\", reader);\n      assertNotNull(stream);\n      int i = 0;\n      final Token reusableToken = new Token();\n      for (Token nextToken = stream.next(reusableToken); nextToken != null; nextToken = stream.next(reusableToken)) {\n        String text = nextToken.term();\n        assertFalse(stopWordsSet.contains(text));\n        assertEquals(expectedIncr[i++],nextToken.getPositionIncrement());\n      }\n    } finally {\n      StopFilter.setEnablePositionIncrementsDefault(defaultEnable);\n    }\n  }\n\n","sourceOld":"  public void testStopListPositions() throws IOException {\n    boolean defaultEnable = StopFilter.getEnablePositionIncrementsDefault();\n    StopFilter.setEnablePositionIncrementsDefault(true);\n    try {\n      Set stopWordsSet = new HashSet();\n      stopWordsSet.add(\"good\");\n      stopWordsSet.add(\"test\");\n      stopWordsSet.add(\"analyzer\");\n      StopAnalyzer newStop = new StopAnalyzer((String[])stopWordsSet.toArray(new String[3]));\n      StringReader reader = new StringReader(\"This is a good test of the english stop analyzer with positions\");\n      int expectedIncr[] =                  { 1,   1, 1,          3, 1,  1,      1,            2,   1};\n      TokenStream stream = newStop.tokenStream(\"test\", reader);\n      assertNotNull(stream);\n      Token token = null;\n      int i = 0;\n      while ((token = stream.next()) != null) {\n        String text = token.termText();\n        assertFalse(stopWordsSet.contains(text));\n        assertEquals(expectedIncr[i++],token.getPositionIncrement());\n      }\n    } finally {\n      StopFilter.setEnablePositionIncrementsDefault(defaultEnable);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"74a5e7f20b4a444da9df3b2c0f331fa7a1f64223","date":1227051709,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"src/test/org/apache/lucene/analysis/TestStopAnalyzer#testStopListPositions().mjava","pathOld":"src/test/org/apache/lucene/analysis/TestStopAnalyzer#testStopListPositions().mjava","sourceNew":"  public void testStopListPositions() throws IOException {\n    boolean defaultEnable = StopFilter.getEnablePositionIncrementsDefault();\n    StopFilter.setEnablePositionIncrementsDefault(true);\n    try {\n      Set stopWordsSet = new HashSet();\n      stopWordsSet.add(\"good\");\n      stopWordsSet.add(\"test\");\n      stopWordsSet.add(\"analyzer\");\n      StopAnalyzer newStop = new StopAnalyzer((String[])stopWordsSet.toArray(new String[3]));\n      StringReader reader = new StringReader(\"This is a good test of the english stop analyzer with positions\");\n      int expectedIncr[] =                  { 1,   1, 1,          3, 1,  1,      1,            2,   1};\n      TokenStream stream = newStop.tokenStream(\"test\", reader);\n      assertNotNull(stream);\n      int i = 0;\n      TermAttribute termAtt = (TermAttribute) stream.getAttribute(TermAttribute.class);\n      PositionIncrementAttribute posIncrAtt = (PositionIncrementAttribute) stream.addAttribute(PositionIncrementAttribute.class);\n\n      while (stream.incrementToken()) {\n        String text = termAtt.term();\n        assertFalse(stopWordsSet.contains(text));\n        assertEquals(expectedIncr[i++],posIncrAtt.getPositionIncrement());\n      }\n    } finally {\n      StopFilter.setEnablePositionIncrementsDefault(defaultEnable);\n    }\n  }\n\n","sourceOld":"  public void testStopListPositions() throws IOException {\n    boolean defaultEnable = StopFilter.getEnablePositionIncrementsDefault();\n    StopFilter.setEnablePositionIncrementsDefault(true);\n    try {\n      Set stopWordsSet = new HashSet();\n      stopWordsSet.add(\"good\");\n      stopWordsSet.add(\"test\");\n      stopWordsSet.add(\"analyzer\");\n      StopAnalyzer newStop = new StopAnalyzer((String[])stopWordsSet.toArray(new String[3]));\n      StringReader reader = new StringReader(\"This is a good test of the english stop analyzer with positions\");\n      int expectedIncr[] =                  { 1,   1, 1,          3, 1,  1,      1,            2,   1};\n      TokenStream stream = newStop.tokenStream(\"test\", reader);\n      assertNotNull(stream);\n      int i = 0;\n      final Token reusableToken = new Token();\n      for (Token nextToken = stream.next(reusableToken); nextToken != null; nextToken = stream.next(reusableToken)) {\n        String text = nextToken.term();\n        assertFalse(stopWordsSet.contains(text));\n        assertEquals(expectedIncr[i++],nextToken.getPositionIncrement());\n      }\n    } finally {\n      StopFilter.setEnablePositionIncrementsDefault(defaultEnable);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8d78f014fded44fbde905f4f84cdc21907b371e8","date":1254383623,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/test/org/apache/lucene/analysis/TestStopAnalyzer#testStopListPositions().mjava","pathOld":"src/test/org/apache/lucene/analysis/TestStopAnalyzer#testStopListPositions().mjava","sourceNew":"  public void testStopListPositions() throws IOException {\n    boolean defaultEnable = StopFilter.getEnablePositionIncrementsDefault();\n    StopFilter.setEnablePositionIncrementsDefault(true);\n    try {\n      Set stopWordsSet = new HashSet();\n      stopWordsSet.add(\"good\");\n      stopWordsSet.add(\"test\");\n      stopWordsSet.add(\"analyzer\");\n      StopAnalyzer newStop = new StopAnalyzer((String[])stopWordsSet.toArray(new String[3]));\n      StringReader reader = new StringReader(\"This is a good test of the english stop analyzer with positions\");\n      int expectedIncr[] =                  { 1,   1, 1,          3, 1,  1,      1,            2,   1};\n      TokenStream stream = newStop.tokenStream(\"test\", reader);\n      assertNotNull(stream);\n      int i = 0;\n      TermAttribute termAtt = stream.getAttribute(TermAttribute.class);\n      PositionIncrementAttribute posIncrAtt = stream.addAttribute(PositionIncrementAttribute.class);\n\n      while (stream.incrementToken()) {\n        String text = termAtt.term();\n        assertFalse(stopWordsSet.contains(text));\n        assertEquals(expectedIncr[i++],posIncrAtt.getPositionIncrement());\n      }\n    } finally {\n      StopFilter.setEnablePositionIncrementsDefault(defaultEnable);\n    }\n  }\n\n","sourceOld":"  public void testStopListPositions() throws IOException {\n    boolean defaultEnable = StopFilter.getEnablePositionIncrementsDefault();\n    StopFilter.setEnablePositionIncrementsDefault(true);\n    try {\n      Set stopWordsSet = new HashSet();\n      stopWordsSet.add(\"good\");\n      stopWordsSet.add(\"test\");\n      stopWordsSet.add(\"analyzer\");\n      StopAnalyzer newStop = new StopAnalyzer((String[])stopWordsSet.toArray(new String[3]));\n      StringReader reader = new StringReader(\"This is a good test of the english stop analyzer with positions\");\n      int expectedIncr[] =                  { 1,   1, 1,          3, 1,  1,      1,            2,   1};\n      TokenStream stream = newStop.tokenStream(\"test\", reader);\n      assertNotNull(stream);\n      int i = 0;\n      TermAttribute termAtt = (TermAttribute) stream.getAttribute(TermAttribute.class);\n      PositionIncrementAttribute posIncrAtt = (PositionIncrementAttribute) stream.addAttribute(PositionIncrementAttribute.class);\n\n      while (stream.incrementToken()) {\n        String text = termAtt.term();\n        assertFalse(stopWordsSet.contains(text));\n        assertEquals(expectedIncr[i++],posIncrAtt.getPositionIncrement());\n      }\n    } finally {\n      StopFilter.setEnablePositionIncrementsDefault(defaultEnable);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4b41b991de69ba7b72d5e90cfcee25699a1a7fc9","date":1256127131,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/test/org/apache/lucene/analysis/TestStopAnalyzer#testStopListPositions().mjava","pathOld":"src/test/org/apache/lucene/analysis/TestStopAnalyzer#testStopListPositions().mjava","sourceNew":"  public void testStopListPositions() throws IOException {\n    Set stopWordsSet = new HashSet();\n    stopWordsSet.add(\"good\");\n    stopWordsSet.add(\"test\");\n    stopWordsSet.add(\"analyzer\");\n    StopAnalyzer newStop = new StopAnalyzer(stopWordsSet, true);\n    StringReader reader = new StringReader(\"This is a good test of the english stop analyzer with positions\");\n    int expectedIncr[] =                  { 1,   1, 1,          3, 1,  1,      1,            2,   1};\n    TokenStream stream = newStop.tokenStream(\"test\", reader);\n    assertNotNull(stream);\n    int i = 0;\n    TermAttribute termAtt = stream.getAttribute(TermAttribute.class);\n    PositionIncrementAttribute posIncrAtt = stream.addAttribute(PositionIncrementAttribute.class);\n\n    while (stream.incrementToken()) {\n      String text = termAtt.term();\n      assertFalse(stopWordsSet.contains(text));\n      assertEquals(expectedIncr[i++],posIncrAtt.getPositionIncrement());\n    }\n  }\n\n","sourceOld":"  public void testStopListPositions() throws IOException {\n    boolean defaultEnable = StopFilter.getEnablePositionIncrementsDefault();\n    StopFilter.setEnablePositionIncrementsDefault(true);\n    try {\n      Set stopWordsSet = new HashSet();\n      stopWordsSet.add(\"good\");\n      stopWordsSet.add(\"test\");\n      stopWordsSet.add(\"analyzer\");\n      StopAnalyzer newStop = new StopAnalyzer((String[])stopWordsSet.toArray(new String[3]));\n      StringReader reader = new StringReader(\"This is a good test of the english stop analyzer with positions\");\n      int expectedIncr[] =                  { 1,   1, 1,          3, 1,  1,      1,            2,   1};\n      TokenStream stream = newStop.tokenStream(\"test\", reader);\n      assertNotNull(stream);\n      int i = 0;\n      TermAttribute termAtt = stream.getAttribute(TermAttribute.class);\n      PositionIncrementAttribute posIncrAtt = stream.addAttribute(PositionIncrementAttribute.class);\n\n      while (stream.incrementToken()) {\n        String text = termAtt.term();\n        assertFalse(stopWordsSet.contains(text));\n        assertEquals(expectedIncr[i++],posIncrAtt.getPositionIncrement());\n      }\n    } finally {\n      StopFilter.setEnablePositionIncrementsDefault(defaultEnable);\n    }\n  }\n\n","bugFix":null,"bugIntro":["c39363fefe2d7f6a6d50ce8e8b758c17a257c58e","c83d6c4335f31cae14f625a222bc842f20073dcd","782ed6a4b4ba50ec19734fc8db4e570ee193d627"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ba1116b3450a9c1642c89445d131b37344055245","date":1256329517,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/analysis/TestStopAnalyzer#testStopListPositions().mjava","pathOld":"src/test/org/apache/lucene/analysis/TestStopAnalyzer#testStopListPositions().mjava","sourceNew":"  public void testStopListPositions() throws IOException {\n    Set stopWordsSet = new HashSet();\n    stopWordsSet.add(\"good\");\n    stopWordsSet.add(\"test\");\n    stopWordsSet.add(\"analyzer\");\n    StopAnalyzer newStop = new StopAnalyzer(Version.LUCENE_CURRENT, stopWordsSet);\n    StringReader reader = new StringReader(\"This is a good test of the english stop analyzer with positions\");\n    int expectedIncr[] =                  { 1,   1, 1,          3, 1,  1,      1,            2,   1};\n    TokenStream stream = newStop.tokenStream(\"test\", reader);\n    assertNotNull(stream);\n    int i = 0;\n    TermAttribute termAtt = stream.getAttribute(TermAttribute.class);\n    PositionIncrementAttribute posIncrAtt = stream.addAttribute(PositionIncrementAttribute.class);\n\n    while (stream.incrementToken()) {\n      String text = termAtt.term();\n      assertFalse(stopWordsSet.contains(text));\n      assertEquals(expectedIncr[i++],posIncrAtt.getPositionIncrement());\n    }\n  }\n\n","sourceOld":"  public void testStopListPositions() throws IOException {\n    Set stopWordsSet = new HashSet();\n    stopWordsSet.add(\"good\");\n    stopWordsSet.add(\"test\");\n    stopWordsSet.add(\"analyzer\");\n    StopAnalyzer newStop = new StopAnalyzer(stopWordsSet, true);\n    StringReader reader = new StringReader(\"This is a good test of the english stop analyzer with positions\");\n    int expectedIncr[] =                  { 1,   1, 1,          3, 1,  1,      1,            2,   1};\n    TokenStream stream = newStop.tokenStream(\"test\", reader);\n    assertNotNull(stream);\n    int i = 0;\n    TermAttribute termAtt = stream.getAttribute(TermAttribute.class);\n    PositionIncrementAttribute posIncrAtt = stream.addAttribute(PositionIncrementAttribute.class);\n\n    while (stream.incrementToken()) {\n      String text = termAtt.term();\n      assertFalse(stopWordsSet.contains(text));\n      assertEquals(expectedIncr[i++],posIncrAtt.getPositionIncrement());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e450c7d50c2fc84c963d0d7ade9d3217d868064d","date":1259932067,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/analysis/TestStopAnalyzer#testStopListPositions().mjava","pathOld":"src/test/org/apache/lucene/analysis/TestStopAnalyzer#testStopListPositions().mjava","sourceNew":"  public void testStopListPositions() throws IOException {\n    Set<Object> stopWordsSet = new HashSet<Object>();\n    stopWordsSet.add(\"good\");\n    stopWordsSet.add(\"test\");\n    stopWordsSet.add(\"analyzer\");\n    StopAnalyzer newStop = new StopAnalyzer(Version.LUCENE_CURRENT, stopWordsSet);\n    StringReader reader = new StringReader(\"This is a good test of the english stop analyzer with positions\");\n    int expectedIncr[] =                  { 1,   1, 1,          3, 1,  1,      1,            2,   1};\n    TokenStream stream = newStop.tokenStream(\"test\", reader);\n    assertNotNull(stream);\n    int i = 0;\n    TermAttribute termAtt = stream.getAttribute(TermAttribute.class);\n    PositionIncrementAttribute posIncrAtt = stream.addAttribute(PositionIncrementAttribute.class);\n\n    while (stream.incrementToken()) {\n      String text = termAtt.term();\n      assertFalse(stopWordsSet.contains(text));\n      assertEquals(expectedIncr[i++],posIncrAtt.getPositionIncrement());\n    }\n  }\n\n","sourceOld":"  public void testStopListPositions() throws IOException {\n    Set stopWordsSet = new HashSet();\n    stopWordsSet.add(\"good\");\n    stopWordsSet.add(\"test\");\n    stopWordsSet.add(\"analyzer\");\n    StopAnalyzer newStop = new StopAnalyzer(Version.LUCENE_CURRENT, stopWordsSet);\n    StringReader reader = new StringReader(\"This is a good test of the english stop analyzer with positions\");\n    int expectedIncr[] =                  { 1,   1, 1,          3, 1,  1,      1,            2,   1};\n    TokenStream stream = newStop.tokenStream(\"test\", reader);\n    assertNotNull(stream);\n    int i = 0;\n    TermAttribute termAtt = stream.getAttribute(TermAttribute.class);\n    PositionIncrementAttribute posIncrAtt = stream.addAttribute(PositionIncrementAttribute.class);\n\n    while (stream.incrementToken()) {\n      String text = termAtt.term();\n      assertFalse(stopWordsSet.contains(text));\n      assertEquals(expectedIncr[i++],posIncrAtt.getPositionIncrement());\n    }\n  }\n\n","bugFix":null,"bugIntro":["c39363fefe2d7f6a6d50ce8e8b758c17a257c58e"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"55f083e91bb056b57de136da1dfc3b9b6ecc4ef6","date":1265808957,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/test/org/apache/lucene/analysis/TestStopAnalyzer#testStopListPositions().mjava","pathOld":"src/test/org/apache/lucene/analysis/TestStopAnalyzer#testStopListPositions().mjava","sourceNew":"  public void testStopListPositions() throws IOException {\n    Set<Object> stopWordsSet = new HashSet<Object>();\n    stopWordsSet.add(\"good\");\n    stopWordsSet.add(\"test\");\n    stopWordsSet.add(\"analyzer\");\n    StopAnalyzer newStop = new StopAnalyzer(TEST_VERSION_CURRENT, stopWordsSet);\n    StringReader reader = new StringReader(\"This is a good test of the english stop analyzer with positions\");\n    int expectedIncr[] =                  { 1,   1, 1,          3, 1,  1,      1,            2,   1};\n    TokenStream stream = newStop.tokenStream(\"test\", reader);\n    assertNotNull(stream);\n    int i = 0;\n    TermAttribute termAtt = stream.getAttribute(TermAttribute.class);\n    PositionIncrementAttribute posIncrAtt = stream.addAttribute(PositionIncrementAttribute.class);\n\n    while (stream.incrementToken()) {\n      String text = termAtt.term();\n      assertFalse(stopWordsSet.contains(text));\n      assertEquals(expectedIncr[i++],posIncrAtt.getPositionIncrement());\n    }\n  }\n\n","sourceOld":"  public void testStopListPositions() throws IOException {\n    Set<Object> stopWordsSet = new HashSet<Object>();\n    stopWordsSet.add(\"good\");\n    stopWordsSet.add(\"test\");\n    stopWordsSet.add(\"analyzer\");\n    StopAnalyzer newStop = new StopAnalyzer(Version.LUCENE_CURRENT, stopWordsSet);\n    StringReader reader = new StringReader(\"This is a good test of the english stop analyzer with positions\");\n    int expectedIncr[] =                  { 1,   1, 1,          3, 1,  1,      1,            2,   1};\n    TokenStream stream = newStop.tokenStream(\"test\", reader);\n    assertNotNull(stream);\n    int i = 0;\n    TermAttribute termAtt = stream.getAttribute(TermAttribute.class);\n    PositionIncrementAttribute posIncrAtt = stream.addAttribute(PositionIncrementAttribute.class);\n\n    while (stream.incrementToken()) {\n      String text = termAtt.term();\n      assertFalse(stopWordsSet.contains(text));\n      assertEquals(expectedIncr[i++],posIncrAtt.getPositionIncrement());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/analysis/TestStopAnalyzer#testStopListPositions().mjava","pathOld":"src/test/org/apache/lucene/analysis/TestStopAnalyzer#testStopListPositions().mjava","sourceNew":"  public void testStopListPositions() throws IOException {\n    Set<Object> stopWordsSet = new HashSet<Object>();\n    stopWordsSet.add(\"good\");\n    stopWordsSet.add(\"test\");\n    stopWordsSet.add(\"analyzer\");\n    StopAnalyzer newStop = new StopAnalyzer(TEST_VERSION_CURRENT, stopWordsSet);\n    StringReader reader = new StringReader(\"This is a good test of the english stop analyzer with positions\");\n    int expectedIncr[] =                  { 1,   1, 1,          3, 1,  1,      1,            2,   1};\n    TokenStream stream = newStop.tokenStream(\"test\", reader);\n    assertNotNull(stream);\n    int i = 0;\n    TermAttribute termAtt = stream.getAttribute(TermAttribute.class);\n    PositionIncrementAttribute posIncrAtt = stream.addAttribute(PositionIncrementAttribute.class);\n\n    while (stream.incrementToken()) {\n      String text = termAtt.term();\n      assertFalse(stopWordsSet.contains(text));\n      assertEquals(expectedIncr[i++],posIncrAtt.getPositionIncrement());\n    }\n  }\n\n","sourceOld":"  public void testStopListPositions() throws IOException {\n    Set<Object> stopWordsSet = new HashSet<Object>();\n    stopWordsSet.add(\"good\");\n    stopWordsSet.add(\"test\");\n    stopWordsSet.add(\"analyzer\");\n    StopAnalyzer newStop = new StopAnalyzer(TEST_VERSION_CURRENT, stopWordsSet);\n    StringReader reader = new StringReader(\"This is a good test of the english stop analyzer with positions\");\n    int expectedIncr[] =                  { 1,   1, 1,          3, 1,  1,      1,            2,   1};\n    TokenStream stream = newStop.tokenStream(\"test\", reader);\n    assertNotNull(stream);\n    int i = 0;\n    TermAttribute termAtt = stream.getAttribute(TermAttribute.class);\n    PositionIncrementAttribute posIncrAtt = stream.addAttribute(PositionIncrementAttribute.class);\n\n    while (stream.incrementToken()) {\n      String text = termAtt.term();\n      assertFalse(stopWordsSet.contains(text));\n      assertEquals(expectedIncr[i++],posIncrAtt.getPositionIncrement());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"7e2cb543b41c145f33390f460ee743d6693c9c6c":["693d6573b6621fc1265316fc6b042c24235c81d8"],"74a5e7f20b4a444da9df3b2c0f331fa7a1f64223":["7e2cb543b41c145f33390f460ee743d6693c9c6c"],"55f083e91bb056b57de136da1dfc3b9b6ecc4ef6":["e450c7d50c2fc84c963d0d7ade9d3217d868064d"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"4b41b991de69ba7b72d5e90cfcee25699a1a7fc9":["8d78f014fded44fbde905f4f84cdc21907b371e8"],"8d78f014fded44fbde905f4f84cdc21907b371e8":["74a5e7f20b4a444da9df3b2c0f331fa7a1f64223"],"693d6573b6621fc1265316fc6b042c24235c81d8":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"e450c7d50c2fc84c963d0d7ade9d3217d868064d":["ba1116b3450a9c1642c89445d131b37344055245"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["55f083e91bb056b57de136da1dfc3b9b6ecc4ef6"],"ba1116b3450a9c1642c89445d131b37344055245":["4b41b991de69ba7b72d5e90cfcee25699a1a7fc9"]},"commit2Childs":{"7e2cb543b41c145f33390f460ee743d6693c9c6c":["74a5e7f20b4a444da9df3b2c0f331fa7a1f64223"],"74a5e7f20b4a444da9df3b2c0f331fa7a1f64223":["8d78f014fded44fbde905f4f84cdc21907b371e8"],"55f083e91bb056b57de136da1dfc3b9b6ecc4ef6":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["693d6573b6621fc1265316fc6b042c24235c81d8"],"4b41b991de69ba7b72d5e90cfcee25699a1a7fc9":["ba1116b3450a9c1642c89445d131b37344055245"],"8d78f014fded44fbde905f4f84cdc21907b371e8":["4b41b991de69ba7b72d5e90cfcee25699a1a7fc9"],"693d6573b6621fc1265316fc6b042c24235c81d8":["7e2cb543b41c145f33390f460ee743d6693c9c6c"],"e450c7d50c2fc84c963d0d7ade9d3217d868064d":["55f083e91bb056b57de136da1dfc3b9b6ecc4ef6"],"ba1116b3450a9c1642c89445d131b37344055245":["e450c7d50c2fc84c963d0d7ade9d3217d868064d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}