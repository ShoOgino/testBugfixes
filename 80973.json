{"path":"lucene/core/src/test/org/apache/lucene/index/TestCustomNorms#testIllegalCustomEncoder().mjava","commits":[{"id":"83cf9687053878376848c49a4e7c29d033569fea","date":1339197725,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCustomNorms#testIllegalCustomEncoder().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestNorms#testIllegalCustomEncoder().mjava","sourceNew":"  public void testIllegalCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IllegalCustomEncodingSimilarity similarity = new IllegalCustomEncodingSimilarity();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    config.setSimilarity(similarity);\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newField(\"foo\", \"\", TextField.TYPE_UNSTORED);\n    Field bar = newField(\"bar\", \"\", TextField.TYPE_UNSTORED);\n    doc.add(foo);\n    doc.add(bar);\n    \n    int numAdded = 0;\n    for (int i = 0; i < 100; i++) {\n      try {\n        bar.setStringValue(\"singleton\");\n        similarity.useByte = random().nextBoolean();\n        writer.addDocument(doc);\n        numAdded++;\n      } catch (IllegalArgumentException e) {}\n    }\n    \n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    assertEquals(numAdded, reader.numDocs());\n    IndexReaderContext topReaderContext = reader.getTopReaderContext();\n    AtomicReaderContext[] leaves = topReaderContext.leaves();\n    for (int j = 0; j < leaves.length; j++) {\n      AtomicReader atomicReader = leaves[j].reader();\n    Source source = random().nextBoolean() ? atomicReader.normValues(\"foo\").getSource() : atomicReader.normValues(\"foo\").getDirectSource();\n    Bits liveDocs = atomicReader.getLiveDocs();\n    Type t = source.getType();\n    for (int i = 0; i < atomicReader.maxDoc(); i++) {\n        assertEquals(0, source.getFloat(i), 0.000f);\n    }\n    \n\n    source = random().nextBoolean() ? atomicReader.normValues(\"bar\").getSource() : atomicReader.normValues(\"bar\").getDirectSource();\n    for (int i = 0; i < atomicReader.maxDoc(); i++) {\n      if (liveDocs == null || liveDocs.get(i)) {\n        assertEquals(\"type: \" + t, 1, source.getFloat(i), 0.000f);\n      } else {\n        assertEquals(\"type: \" + t, 0, source.getFloat(i), 0.000f);\n      }\n    }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testIllegalCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IllegalCustomEncodingSimilarity similarity = new IllegalCustomEncodingSimilarity();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    config.setSimilarity(similarity);\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newField(\"foo\", \"\", TextField.TYPE_UNSTORED);\n    Field bar = newField(\"bar\", \"\", TextField.TYPE_UNSTORED);\n    doc.add(foo);\n    doc.add(bar);\n    \n    int numAdded = 0;\n    for (int i = 0; i < 100; i++) {\n      try {\n        bar.setStringValue(\"singleton\");\n        similarity.useByte = random().nextBoolean();\n        writer.addDocument(doc);\n        numAdded++;\n      } catch (IllegalArgumentException e) {}\n    }\n    \n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    assertEquals(numAdded, reader.numDocs());\n    IndexReaderContext topReaderContext = reader.getTopReaderContext();\n    AtomicReaderContext[] leaves = topReaderContext.leaves();\n    for (int j = 0; j < leaves.length; j++) {\n      AtomicReader atomicReader = leaves[j].reader();\n    Source source = random().nextBoolean() ? atomicReader.normValues(\"foo\").getSource() : atomicReader.normValues(\"foo\").getDirectSource();\n    Bits liveDocs = atomicReader.getLiveDocs();\n    Type t = source.getType();\n    for (int i = 0; i < atomicReader.maxDoc(); i++) {\n        assertEquals(0, source.getFloat(i), 0.000f);\n    }\n    \n\n    source = random().nextBoolean() ? atomicReader.normValues(\"bar\").getSource() : atomicReader.normValues(\"bar\").getDirectSource();\n    for (int i = 0; i < atomicReader.maxDoc(); i++) {\n      if (liveDocs == null || liveDocs.get(i)) {\n        assertEquals(\"type: \" + t, 1, source.getFloat(i), 0.000f);\n      } else {\n        assertEquals(\"type: \" + t, 0, source.getFloat(i), 0.000f);\n      }\n    }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"04f07771a2a7dd3a395700665ed839c3dae2def2","date":1339350139,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCustomNorms#testIllegalCustomEncoder().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCustomNorms#testIllegalCustomEncoder().mjava","sourceNew":"  public void testIllegalCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IllegalCustomEncodingSimilarity similarity = new IllegalCustomEncodingSimilarity();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    config.setSimilarity(similarity);\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newTextField(\"foo\", \"\", Field.Store.NO);\n    Field bar = newTextField(\"bar\", \"\", Field.Store.NO);\n    doc.add(foo);\n    doc.add(bar);\n    \n    int numAdded = 0;\n    for (int i = 0; i < 100; i++) {\n      try {\n        bar.setStringValue(\"singleton\");\n        similarity.useByte = random().nextBoolean();\n        writer.addDocument(doc);\n        numAdded++;\n      } catch (IllegalArgumentException e) {}\n    }\n    \n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    assertEquals(numAdded, reader.numDocs());\n    IndexReaderContext topReaderContext = reader.getTopReaderContext();\n    AtomicReaderContext[] leaves = topReaderContext.leaves();\n    for (int j = 0; j < leaves.length; j++) {\n      AtomicReader atomicReader = leaves[j].reader();\n    Source source = random().nextBoolean() ? atomicReader.normValues(\"foo\").getSource() : atomicReader.normValues(\"foo\").getDirectSource();\n    Bits liveDocs = atomicReader.getLiveDocs();\n    Type t = source.getType();\n    for (int i = 0; i < atomicReader.maxDoc(); i++) {\n        assertEquals(0, source.getFloat(i), 0.000f);\n    }\n    \n\n    source = random().nextBoolean() ? atomicReader.normValues(\"bar\").getSource() : atomicReader.normValues(\"bar\").getDirectSource();\n    for (int i = 0; i < atomicReader.maxDoc(); i++) {\n      if (liveDocs == null || liveDocs.get(i)) {\n        assertEquals(\"type: \" + t, 1, source.getFloat(i), 0.000f);\n      } else {\n        assertEquals(\"type: \" + t, 0, source.getFloat(i), 0.000f);\n      }\n    }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testIllegalCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IllegalCustomEncodingSimilarity similarity = new IllegalCustomEncodingSimilarity();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    config.setSimilarity(similarity);\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newField(\"foo\", \"\", TextField.TYPE_UNSTORED);\n    Field bar = newField(\"bar\", \"\", TextField.TYPE_UNSTORED);\n    doc.add(foo);\n    doc.add(bar);\n    \n    int numAdded = 0;\n    for (int i = 0; i < 100; i++) {\n      try {\n        bar.setStringValue(\"singleton\");\n        similarity.useByte = random().nextBoolean();\n        writer.addDocument(doc);\n        numAdded++;\n      } catch (IllegalArgumentException e) {}\n    }\n    \n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    assertEquals(numAdded, reader.numDocs());\n    IndexReaderContext topReaderContext = reader.getTopReaderContext();\n    AtomicReaderContext[] leaves = topReaderContext.leaves();\n    for (int j = 0; j < leaves.length; j++) {\n      AtomicReader atomicReader = leaves[j].reader();\n    Source source = random().nextBoolean() ? atomicReader.normValues(\"foo\").getSource() : atomicReader.normValues(\"foo\").getDirectSource();\n    Bits liveDocs = atomicReader.getLiveDocs();\n    Type t = source.getType();\n    for (int i = 0; i < atomicReader.maxDoc(); i++) {\n        assertEquals(0, source.getFloat(i), 0.000f);\n    }\n    \n\n    source = random().nextBoolean() ? atomicReader.normValues(\"bar\").getSource() : atomicReader.normValues(\"bar\").getDirectSource();\n    for (int i = 0; i < atomicReader.maxDoc(); i++) {\n      if (liveDocs == null || liveDocs.get(i)) {\n        assertEquals(\"type: \" + t, 1, source.getFloat(i), 0.000f);\n      } else {\n        assertEquals(\"type: \" + t, 0, source.getFloat(i), 0.000f);\n      }\n    }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":["cc8f931c07d7930ebee666cf6d69b1b6d9f9cd18"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c","date":1340090669,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCustomNorms#testIllegalCustomEncoder().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCustomNorms#testIllegalCustomEncoder().mjava","sourceNew":"  public void testIllegalCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IllegalCustomEncodingSimilarity similarity = new IllegalCustomEncodingSimilarity();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    config.setSimilarity(similarity);\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newTextField(\"foo\", \"\", Field.Store.NO);\n    Field bar = newTextField(\"bar\", \"\", Field.Store.NO);\n    doc.add(foo);\n    doc.add(bar);\n    \n    int numAdded = 0;\n    for (int i = 0; i < 100; i++) {\n      try {\n        bar.setStringValue(\"singleton\");\n        similarity.useByte = random().nextBoolean();\n        writer.addDocument(doc);\n        numAdded++;\n      } catch (IllegalArgumentException e) {}\n    }\n    \n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    assertEquals(numAdded, reader.numDocs());\n    IndexReaderContext topReaderContext = reader.getTopReaderContext();\n    for (final AtomicReaderContext ctx : topReaderContext.leaves()) {\n      AtomicReader atomicReader = ctx.reader();\n      Source source = random().nextBoolean() ? atomicReader.normValues(\"foo\").getSource() : atomicReader.normValues(\"foo\").getDirectSource();\n      Bits liveDocs = atomicReader.getLiveDocs();\n      Type t = source.getType();\n      for (int i = 0; i < atomicReader.maxDoc(); i++) {\n          assertEquals(0, source.getFloat(i), 0.000f);\n      }\n      \n  \n      source = random().nextBoolean() ? atomicReader.normValues(\"bar\").getSource() : atomicReader.normValues(\"bar\").getDirectSource();\n      for (int i = 0; i < atomicReader.maxDoc(); i++) {\n        if (liveDocs == null || liveDocs.get(i)) {\n          assertEquals(\"type: \" + t, 1, source.getFloat(i), 0.000f);\n        } else {\n          assertEquals(\"type: \" + t, 0, source.getFloat(i), 0.000f);\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testIllegalCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IllegalCustomEncodingSimilarity similarity = new IllegalCustomEncodingSimilarity();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    config.setSimilarity(similarity);\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newTextField(\"foo\", \"\", Field.Store.NO);\n    Field bar = newTextField(\"bar\", \"\", Field.Store.NO);\n    doc.add(foo);\n    doc.add(bar);\n    \n    int numAdded = 0;\n    for (int i = 0; i < 100; i++) {\n      try {\n        bar.setStringValue(\"singleton\");\n        similarity.useByte = random().nextBoolean();\n        writer.addDocument(doc);\n        numAdded++;\n      } catch (IllegalArgumentException e) {}\n    }\n    \n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    assertEquals(numAdded, reader.numDocs());\n    IndexReaderContext topReaderContext = reader.getTopReaderContext();\n    AtomicReaderContext[] leaves = topReaderContext.leaves();\n    for (int j = 0; j < leaves.length; j++) {\n      AtomicReader atomicReader = leaves[j].reader();\n    Source source = random().nextBoolean() ? atomicReader.normValues(\"foo\").getSource() : atomicReader.normValues(\"foo\").getDirectSource();\n    Bits liveDocs = atomicReader.getLiveDocs();\n    Type t = source.getType();\n    for (int i = 0; i < atomicReader.maxDoc(); i++) {\n        assertEquals(0, source.getFloat(i), 0.000f);\n    }\n    \n\n    source = random().nextBoolean() ? atomicReader.normValues(\"bar\").getSource() : atomicReader.normValues(\"bar\").getDirectSource();\n    for (int i = 0; i < atomicReader.maxDoc(); i++) {\n      if (liveDocs == null || liveDocs.get(i)) {\n        assertEquals(\"type: \" + t, 1, source.getFloat(i), 0.000f);\n      } else {\n        assertEquals(\"type: \" + t, 0, source.getFloat(i), 0.000f);\n      }\n    }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"211b1506e56f7860762fbd4698f6d1d1b57f672c","date":1344976996,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCustomNorms#testIllegalCustomEncoder().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCustomNorms#testIllegalCustomEncoder().mjava","sourceNew":"  public void testIllegalCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IllegalCustomEncodingSimilarity similarity = new IllegalCustomEncodingSimilarity();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    config.setSimilarity(similarity);\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newTextField(\"foo\", \"\", Field.Store.NO);\n    Field bar = newTextField(\"bar\", \"\", Field.Store.NO);\n    doc.add(foo);\n    doc.add(bar);\n    \n    int numAdded = 0;\n    for (int i = 0; i < 100; i++) {\n      try {\n        bar.setStringValue(\"singleton\");\n        similarity.useByte = random().nextBoolean();\n        writer.addDocument(doc);\n        numAdded++;\n      } catch (IllegalArgumentException e) {}\n    }\n    \n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    assertEquals(numAdded, reader.numDocs());\n    IndexReaderContext topReaderContext = reader.getContext();\n    for (final AtomicReaderContext ctx : topReaderContext.leaves()) {\n      AtomicReader atomicReader = ctx.reader();\n      Source source = random().nextBoolean() ? atomicReader.normValues(\"foo\").getSource() : atomicReader.normValues(\"foo\").getDirectSource();\n      Bits liveDocs = atomicReader.getLiveDocs();\n      Type t = source.getType();\n      for (int i = 0; i < atomicReader.maxDoc(); i++) {\n          assertEquals(0, source.getFloat(i), 0.000f);\n      }\n      \n  \n      source = random().nextBoolean() ? atomicReader.normValues(\"bar\").getSource() : atomicReader.normValues(\"bar\").getDirectSource();\n      for (int i = 0; i < atomicReader.maxDoc(); i++) {\n        if (liveDocs == null || liveDocs.get(i)) {\n          assertEquals(\"type: \" + t, 1, source.getFloat(i), 0.000f);\n        } else {\n          assertEquals(\"type: \" + t, 0, source.getFloat(i), 0.000f);\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testIllegalCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IllegalCustomEncodingSimilarity similarity = new IllegalCustomEncodingSimilarity();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    config.setSimilarity(similarity);\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newTextField(\"foo\", \"\", Field.Store.NO);\n    Field bar = newTextField(\"bar\", \"\", Field.Store.NO);\n    doc.add(foo);\n    doc.add(bar);\n    \n    int numAdded = 0;\n    for (int i = 0; i < 100; i++) {\n      try {\n        bar.setStringValue(\"singleton\");\n        similarity.useByte = random().nextBoolean();\n        writer.addDocument(doc);\n        numAdded++;\n      } catch (IllegalArgumentException e) {}\n    }\n    \n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    assertEquals(numAdded, reader.numDocs());\n    IndexReaderContext topReaderContext = reader.getTopReaderContext();\n    for (final AtomicReaderContext ctx : topReaderContext.leaves()) {\n      AtomicReader atomicReader = ctx.reader();\n      Source source = random().nextBoolean() ? atomicReader.normValues(\"foo\").getSource() : atomicReader.normValues(\"foo\").getDirectSource();\n      Bits liveDocs = atomicReader.getLiveDocs();\n      Type t = source.getType();\n      for (int i = 0; i < atomicReader.maxDoc(); i++) {\n          assertEquals(0, source.getFloat(i), 0.000f);\n      }\n      \n  \n      source = random().nextBoolean() ? atomicReader.normValues(\"bar\").getSource() : atomicReader.normValues(\"bar\").getDirectSource();\n      for (int i = 0; i < atomicReader.maxDoc(); i++) {\n        if (liveDocs == null || liveDocs.get(i)) {\n          assertEquals(\"type: \" + t, 1, source.getFloat(i), 0.000f);\n        } else {\n          assertEquals(\"type: \" + t, 0, source.getFloat(i), 0.000f);\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198","date":1345029782,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCustomNorms#testIllegalCustomEncoder().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCustomNorms#testIllegalCustomEncoder().mjava","sourceNew":"  public void testIllegalCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IllegalCustomEncodingSimilarity similarity = new IllegalCustomEncodingSimilarity();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    config.setSimilarity(similarity);\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newTextField(\"foo\", \"\", Field.Store.NO);\n    Field bar = newTextField(\"bar\", \"\", Field.Store.NO);\n    doc.add(foo);\n    doc.add(bar);\n    \n    int numAdded = 0;\n    for (int i = 0; i < 100; i++) {\n      try {\n        bar.setStringValue(\"singleton\");\n        similarity.useByte = random().nextBoolean();\n        writer.addDocument(doc);\n        numAdded++;\n      } catch (IllegalArgumentException e) {}\n    }\n    \n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    assertEquals(numAdded, reader.numDocs());\n    IndexReaderContext topReaderContext = reader.getContext();\n    for (final AtomicReaderContext ctx : topReaderContext.leaves()) {\n      AtomicReader atomicReader = ctx.reader();\n      Source source = random().nextBoolean() ? atomicReader.normValues(\"foo\").getSource() : atomicReader.normValues(\"foo\").getDirectSource();\n      Bits liveDocs = atomicReader.getLiveDocs();\n      Type t = source.getType();\n      for (int i = 0; i < atomicReader.maxDoc(); i++) {\n          assertEquals(0, source.getFloat(i), 0.000f);\n      }\n      \n  \n      source = random().nextBoolean() ? atomicReader.normValues(\"bar\").getSource() : atomicReader.normValues(\"bar\").getDirectSource();\n      for (int i = 0; i < atomicReader.maxDoc(); i++) {\n        if (liveDocs == null || liveDocs.get(i)) {\n          assertEquals(\"type: \" + t, 1, source.getFloat(i), 0.000f);\n        } else {\n          assertEquals(\"type: \" + t, 0, source.getFloat(i), 0.000f);\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testIllegalCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IllegalCustomEncodingSimilarity similarity = new IllegalCustomEncodingSimilarity();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    config.setSimilarity(similarity);\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newTextField(\"foo\", \"\", Field.Store.NO);\n    Field bar = newTextField(\"bar\", \"\", Field.Store.NO);\n    doc.add(foo);\n    doc.add(bar);\n    \n    int numAdded = 0;\n    for (int i = 0; i < 100; i++) {\n      try {\n        bar.setStringValue(\"singleton\");\n        similarity.useByte = random().nextBoolean();\n        writer.addDocument(doc);\n        numAdded++;\n      } catch (IllegalArgumentException e) {}\n    }\n    \n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    assertEquals(numAdded, reader.numDocs());\n    IndexReaderContext topReaderContext = reader.getTopReaderContext();\n    for (final AtomicReaderContext ctx : topReaderContext.leaves()) {\n      AtomicReader atomicReader = ctx.reader();\n      Source source = random().nextBoolean() ? atomicReader.normValues(\"foo\").getSource() : atomicReader.normValues(\"foo\").getDirectSource();\n      Bits liveDocs = atomicReader.getLiveDocs();\n      Type t = source.getType();\n      for (int i = 0; i < atomicReader.maxDoc(); i++) {\n          assertEquals(0, source.getFloat(i), 0.000f);\n      }\n      \n  \n      source = random().nextBoolean() ? atomicReader.normValues(\"bar\").getSource() : atomicReader.normValues(\"bar\").getDirectSource();\n      for (int i = 0; i < atomicReader.maxDoc(); i++) {\n        if (liveDocs == null || liveDocs.get(i)) {\n          assertEquals(\"type: \" + t, 1, source.getFloat(i), 0.000f);\n        } else {\n          assertEquals(\"type: \" + t, 0, source.getFloat(i), 0.000f);\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3c188105a9aae04f56c24996f98f8333fc825d2e","date":1345031914,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCustomNorms#testIllegalCustomEncoder().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCustomNorms#testIllegalCustomEncoder().mjava","sourceNew":"  public void testIllegalCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IllegalCustomEncodingSimilarity similarity = new IllegalCustomEncodingSimilarity();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    config.setSimilarity(similarity);\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newTextField(\"foo\", \"\", Field.Store.NO);\n    Field bar = newTextField(\"bar\", \"\", Field.Store.NO);\n    doc.add(foo);\n    doc.add(bar);\n    \n    int numAdded = 0;\n    for (int i = 0; i < 100; i++) {\n      try {\n        bar.setStringValue(\"singleton\");\n        similarity.useByte = random().nextBoolean();\n        writer.addDocument(doc);\n        numAdded++;\n      } catch (IllegalArgumentException e) {}\n    }\n    \n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    assertEquals(numAdded, reader.numDocs());\n    IndexReaderContext topReaderContext = reader.getContext();\n    for (final AtomicReaderContext ctx : topReaderContext.leaves()) {\n      AtomicReader atomicReader = ctx.reader();\n      Source source = random().nextBoolean() ? atomicReader.normValues(\"foo\").getSource() : atomicReader.normValues(\"foo\").getDirectSource();\n      Bits liveDocs = atomicReader.getLiveDocs();\n      Type t = source.getType();\n      for (int i = 0; i < atomicReader.maxDoc(); i++) {\n          assertEquals(0, source.getFloat(i), 0.000f);\n      }\n      \n  \n      source = random().nextBoolean() ? atomicReader.normValues(\"bar\").getSource() : atomicReader.normValues(\"bar\").getDirectSource();\n      for (int i = 0; i < atomicReader.maxDoc(); i++) {\n        if (liveDocs == null || liveDocs.get(i)) {\n          assertEquals(\"type: \" + t, 1, source.getFloat(i), 0.000f);\n        } else {\n          assertEquals(\"type: \" + t, 0, source.getFloat(i), 0.000f);\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testIllegalCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IllegalCustomEncodingSimilarity similarity = new IllegalCustomEncodingSimilarity();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    config.setSimilarity(similarity);\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newTextField(\"foo\", \"\", Field.Store.NO);\n    Field bar = newTextField(\"bar\", \"\", Field.Store.NO);\n    doc.add(foo);\n    doc.add(bar);\n    \n    int numAdded = 0;\n    for (int i = 0; i < 100; i++) {\n      try {\n        bar.setStringValue(\"singleton\");\n        similarity.useByte = random().nextBoolean();\n        writer.addDocument(doc);\n        numAdded++;\n      } catch (IllegalArgumentException e) {}\n    }\n    \n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    assertEquals(numAdded, reader.numDocs());\n    IndexReaderContext topReaderContext = reader.getTopReaderContext();\n    for (final AtomicReaderContext ctx : topReaderContext.leaves()) {\n      AtomicReader atomicReader = ctx.reader();\n      Source source = random().nextBoolean() ? atomicReader.normValues(\"foo\").getSource() : atomicReader.normValues(\"foo\").getDirectSource();\n      Bits liveDocs = atomicReader.getLiveDocs();\n      Type t = source.getType();\n      for (int i = 0; i < atomicReader.maxDoc(); i++) {\n          assertEquals(0, source.getFloat(i), 0.000f);\n      }\n      \n  \n      source = random().nextBoolean() ? atomicReader.normValues(\"bar\").getSource() : atomicReader.normValues(\"bar\").getDirectSource();\n      for (int i = 0; i < atomicReader.maxDoc(); i++) {\n        if (liveDocs == null || liveDocs.get(i)) {\n          assertEquals(\"type: \" + t, 1, source.getFloat(i), 0.000f);\n        } else {\n          assertEquals(\"type: \" + t, 0, source.getFloat(i), 0.000f);\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1c93396a1df03720cb20e2c2f513a6fa59b21e4c","date":1345032673,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCustomNorms#testIllegalCustomEncoder().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCustomNorms#testIllegalCustomEncoder().mjava","sourceNew":"  public void testIllegalCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IllegalCustomEncodingSimilarity similarity = new IllegalCustomEncodingSimilarity();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    config.setSimilarity(similarity);\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newTextField(\"foo\", \"\", Field.Store.NO);\n    Field bar = newTextField(\"bar\", \"\", Field.Store.NO);\n    doc.add(foo);\n    doc.add(bar);\n    \n    int numAdded = 0;\n    for (int i = 0; i < 100; i++) {\n      try {\n        bar.setStringValue(\"singleton\");\n        similarity.useByte = random().nextBoolean();\n        writer.addDocument(doc);\n        numAdded++;\n      } catch (IllegalArgumentException e) {}\n    }\n    \n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    assertEquals(numAdded, reader.numDocs());\n    IndexReaderContext topReaderContext = reader.getTopReaderContext();\n    for (final AtomicReaderContext ctx : topReaderContext.leaves()) {\n      AtomicReader atomicReader = ctx.reader();\n      Source source = random().nextBoolean() ? atomicReader.normValues(\"foo\").getSource() : atomicReader.normValues(\"foo\").getDirectSource();\n      Bits liveDocs = atomicReader.getLiveDocs();\n      Type t = source.getType();\n      for (int i = 0; i < atomicReader.maxDoc(); i++) {\n          assertEquals(0, source.getFloat(i), 0.000f);\n      }\n      \n  \n      source = random().nextBoolean() ? atomicReader.normValues(\"bar\").getSource() : atomicReader.normValues(\"bar\").getDirectSource();\n      for (int i = 0; i < atomicReader.maxDoc(); i++) {\n        if (liveDocs == null || liveDocs.get(i)) {\n          assertEquals(\"type: \" + t, 1, source.getFloat(i), 0.000f);\n        } else {\n          assertEquals(\"type: \" + t, 0, source.getFloat(i), 0.000f);\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testIllegalCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IllegalCustomEncodingSimilarity similarity = new IllegalCustomEncodingSimilarity();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    config.setSimilarity(similarity);\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newTextField(\"foo\", \"\", Field.Store.NO);\n    Field bar = newTextField(\"bar\", \"\", Field.Store.NO);\n    doc.add(foo);\n    doc.add(bar);\n    \n    int numAdded = 0;\n    for (int i = 0; i < 100; i++) {\n      try {\n        bar.setStringValue(\"singleton\");\n        similarity.useByte = random().nextBoolean();\n        writer.addDocument(doc);\n        numAdded++;\n      } catch (IllegalArgumentException e) {}\n    }\n    \n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    assertEquals(numAdded, reader.numDocs());\n    IndexReaderContext topReaderContext = reader.getContext();\n    for (final AtomicReaderContext ctx : topReaderContext.leaves()) {\n      AtomicReader atomicReader = ctx.reader();\n      Source source = random().nextBoolean() ? atomicReader.normValues(\"foo\").getSource() : atomicReader.normValues(\"foo\").getDirectSource();\n      Bits liveDocs = atomicReader.getLiveDocs();\n      Type t = source.getType();\n      for (int i = 0; i < atomicReader.maxDoc(); i++) {\n          assertEquals(0, source.getFloat(i), 0.000f);\n      }\n      \n  \n      source = random().nextBoolean() ? atomicReader.normValues(\"bar\").getSource() : atomicReader.normValues(\"bar\").getDirectSource();\n      for (int i = 0; i < atomicReader.maxDoc(); i++) {\n        if (liveDocs == null || liveDocs.get(i)) {\n          assertEquals(\"type: \" + t, 1, source.getFloat(i), 0.000f);\n        } else {\n          assertEquals(\"type: \" + t, 0, source.getFloat(i), 0.000f);\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b05c56a41b733e02a189c48895922b5bd8c7f3d1","date":1345033322,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCustomNorms#testIllegalCustomEncoder().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCustomNorms#testIllegalCustomEncoder().mjava","sourceNew":"  public void testIllegalCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IllegalCustomEncodingSimilarity similarity = new IllegalCustomEncodingSimilarity();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    config.setSimilarity(similarity);\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newTextField(\"foo\", \"\", Field.Store.NO);\n    Field bar = newTextField(\"bar\", \"\", Field.Store.NO);\n    doc.add(foo);\n    doc.add(bar);\n    \n    int numAdded = 0;\n    for (int i = 0; i < 100; i++) {\n      try {\n        bar.setStringValue(\"singleton\");\n        similarity.useByte = random().nextBoolean();\n        writer.addDocument(doc);\n        numAdded++;\n      } catch (IllegalArgumentException e) {}\n    }\n    \n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    assertEquals(numAdded, reader.numDocs());\n    IndexReaderContext topReaderContext = reader.getContext();\n    for (final AtomicReaderContext ctx : topReaderContext.leaves()) {\n      AtomicReader atomicReader = ctx.reader();\n      Source source = random().nextBoolean() ? atomicReader.normValues(\"foo\").getSource() : atomicReader.normValues(\"foo\").getDirectSource();\n      Bits liveDocs = atomicReader.getLiveDocs();\n      Type t = source.getType();\n      for (int i = 0; i < atomicReader.maxDoc(); i++) {\n          assertEquals(0, source.getFloat(i), 0.000f);\n      }\n      \n  \n      source = random().nextBoolean() ? atomicReader.normValues(\"bar\").getSource() : atomicReader.normValues(\"bar\").getDirectSource();\n      for (int i = 0; i < atomicReader.maxDoc(); i++) {\n        if (liveDocs == null || liveDocs.get(i)) {\n          assertEquals(\"type: \" + t, 1, source.getFloat(i), 0.000f);\n        } else {\n          assertEquals(\"type: \" + t, 0, source.getFloat(i), 0.000f);\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testIllegalCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IllegalCustomEncodingSimilarity similarity = new IllegalCustomEncodingSimilarity();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    config.setSimilarity(similarity);\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newTextField(\"foo\", \"\", Field.Store.NO);\n    Field bar = newTextField(\"bar\", \"\", Field.Store.NO);\n    doc.add(foo);\n    doc.add(bar);\n    \n    int numAdded = 0;\n    for (int i = 0; i < 100; i++) {\n      try {\n        bar.setStringValue(\"singleton\");\n        similarity.useByte = random().nextBoolean();\n        writer.addDocument(doc);\n        numAdded++;\n      } catch (IllegalArgumentException e) {}\n    }\n    \n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    assertEquals(numAdded, reader.numDocs());\n    IndexReaderContext topReaderContext = reader.getTopReaderContext();\n    for (final AtomicReaderContext ctx : topReaderContext.leaves()) {\n      AtomicReader atomicReader = ctx.reader();\n      Source source = random().nextBoolean() ? atomicReader.normValues(\"foo\").getSource() : atomicReader.normValues(\"foo\").getDirectSource();\n      Bits liveDocs = atomicReader.getLiveDocs();\n      Type t = source.getType();\n      for (int i = 0; i < atomicReader.maxDoc(); i++) {\n          assertEquals(0, source.getFloat(i), 0.000f);\n      }\n      \n  \n      source = random().nextBoolean() ? atomicReader.normValues(\"bar\").getSource() : atomicReader.normValues(\"bar\").getDirectSource();\n      for (int i = 0; i < atomicReader.maxDoc(); i++) {\n        if (liveDocs == null || liveDocs.get(i)) {\n          assertEquals(\"type: \" + t, 1, source.getFloat(i), 0.000f);\n        } else {\n          assertEquals(\"type: \" + t, 0, source.getFloat(i), 0.000f);\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0837ab0472feecb3a54260729d845f839e1cbd72","date":1358283639,"type":4,"author":"Robert Muir","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCustomNorms#testIllegalCustomEncoder().mjava","sourceNew":null,"sourceOld":"  public void testIllegalCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IllegalCustomEncodingSimilarity similarity = new IllegalCustomEncodingSimilarity();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    config.setSimilarity(similarity);\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newTextField(\"foo\", \"\", Field.Store.NO);\n    Field bar = newTextField(\"bar\", \"\", Field.Store.NO);\n    doc.add(foo);\n    doc.add(bar);\n    \n    int numAdded = 0;\n    for (int i = 0; i < 100; i++) {\n      try {\n        bar.setStringValue(\"singleton\");\n        similarity.useByte = random().nextBoolean();\n        writer.addDocument(doc);\n        numAdded++;\n      } catch (IllegalArgumentException e) {}\n    }\n    \n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    assertEquals(numAdded, reader.numDocs());\n    IndexReaderContext topReaderContext = reader.getContext();\n    for (final AtomicReaderContext ctx : topReaderContext.leaves()) {\n      AtomicReader atomicReader = ctx.reader();\n      Source source = random().nextBoolean() ? atomicReader.normValues(\"foo\").getSource() : atomicReader.normValues(\"foo\").getDirectSource();\n      Bits liveDocs = atomicReader.getLiveDocs();\n      Type t = source.getType();\n      for (int i = 0; i < atomicReader.maxDoc(); i++) {\n          assertEquals(0, source.getFloat(i), 0.000f);\n      }\n      \n  \n      source = random().nextBoolean() ? atomicReader.normValues(\"bar\").getSource() : atomicReader.normValues(\"bar\").getDirectSource();\n      for (int i = 0; i < atomicReader.maxDoc(); i++) {\n        if (liveDocs == null || liveDocs.get(i)) {\n          assertEquals(\"type: \" + t, 1, source.getFloat(i), 0.000f);\n        } else {\n          assertEquals(\"type: \" + t, 0, source.getFloat(i), 0.000f);\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d4d69c535930b5cce125cff868d40f6373dc27d4","date":1360270101,"type":4,"author":"Robert Muir","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCustomNorms#testIllegalCustomEncoder().mjava","sourceNew":null,"sourceOld":"  public void testIllegalCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IllegalCustomEncodingSimilarity similarity = new IllegalCustomEncodingSimilarity();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    config.setSimilarity(similarity);\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newTextField(\"foo\", \"\", Field.Store.NO);\n    Field bar = newTextField(\"bar\", \"\", Field.Store.NO);\n    doc.add(foo);\n    doc.add(bar);\n    \n    int numAdded = 0;\n    for (int i = 0; i < 100; i++) {\n      try {\n        bar.setStringValue(\"singleton\");\n        similarity.useByte = random().nextBoolean();\n        writer.addDocument(doc);\n        numAdded++;\n      } catch (IllegalArgumentException e) {}\n    }\n    \n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    assertEquals(numAdded, reader.numDocs());\n    IndexReaderContext topReaderContext = reader.getContext();\n    for (final AtomicReaderContext ctx : topReaderContext.leaves()) {\n      AtomicReader atomicReader = ctx.reader();\n      Source source = random().nextBoolean() ? atomicReader.normValues(\"foo\").getSource() : atomicReader.normValues(\"foo\").getDirectSource();\n      Bits liveDocs = atomicReader.getLiveDocs();\n      Type t = source.getType();\n      for (int i = 0; i < atomicReader.maxDoc(); i++) {\n          assertEquals(0, source.getFloat(i), 0.000f);\n      }\n      \n  \n      source = random().nextBoolean() ? atomicReader.normValues(\"bar\").getSource() : atomicReader.normValues(\"bar\").getDirectSource();\n      for (int i = 0; i < atomicReader.maxDoc(); i++) {\n        if (liveDocs == null || liveDocs.get(i)) {\n          assertEquals(\"type: \" + t, 1, source.getFloat(i), 0.000f);\n        } else {\n          assertEquals(\"type: \" + t, 0, source.getFloat(i), 0.000f);\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"04f07771a2a7dd3a395700665ed839c3dae2def2":["83cf9687053878376848c49a4e7c29d033569fea"],"83cf9687053878376848c49a4e7c29d033569fea":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"d4d69c535930b5cce125cff868d40f6373dc27d4":["211b1506e56f7860762fbd4698f6d1d1b57f672c","0837ab0472feecb3a54260729d845f839e1cbd72"],"3c188105a9aae04f56c24996f98f8333fc825d2e":["4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c"],"4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"b05c56a41b733e02a189c48895922b5bd8c7f3d1":["1c93396a1df03720cb20e2c2f513a6fa59b21e4c","211b1506e56f7860762fbd4698f6d1d1b57f672c"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"1c93396a1df03720cb20e2c2f513a6fa59b21e4c":["3c188105a9aae04f56c24996f98f8333fc825d2e"],"211b1506e56f7860762fbd4698f6d1d1b57f672c":["4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c"],"0837ab0472feecb3a54260729d845f839e1cbd72":["211b1506e56f7860762fbd4698f6d1d1b57f672c"],"c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198":["4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c","211b1506e56f7860762fbd4698f6d1d1b57f672c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["d4d69c535930b5cce125cff868d40f6373dc27d4"]},"commit2Childs":{"04f07771a2a7dd3a395700665ed839c3dae2def2":["4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c"],"83cf9687053878376848c49a4e7c29d033569fea":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"d4d69c535930b5cce125cff868d40f6373dc27d4":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3c188105a9aae04f56c24996f98f8333fc825d2e":["1c93396a1df03720cb20e2c2f513a6fa59b21e4c"],"4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c":["3c188105a9aae04f56c24996f98f8333fc825d2e","211b1506e56f7860762fbd4698f6d1d1b57f672c","c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198"],"b05c56a41b733e02a189c48895922b5bd8c7f3d1":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["83cf9687053878376848c49a4e7c29d033569fea"],"1c93396a1df03720cb20e2c2f513a6fa59b21e4c":["b05c56a41b733e02a189c48895922b5bd8c7f3d1"],"211b1506e56f7860762fbd4698f6d1d1b57f672c":["d4d69c535930b5cce125cff868d40f6373dc27d4","b05c56a41b733e02a189c48895922b5bd8c7f3d1","0837ab0472feecb3a54260729d845f839e1cbd72","c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198"],"0837ab0472feecb3a54260729d845f839e1cbd72":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["b05c56a41b733e02a189c48895922b5bd8c7f3d1","c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}