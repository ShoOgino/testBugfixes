{"path":"src/java/org/apache/lucene/index/IndexWriter#setRAMBufferSizeMB(double).mjava","commits":[{"id":"4350b17bd363cd13a95171b8df1ca62ea4c3e71c","date":1183562198,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#setRAMBufferSizeMB(double).mjava","pathOld":"/dev/null","sourceNew":"  /** Determines the amount of RAM that may be used for\n   * buffering added documents before they are flushed as a\n   * new Segment.  Generally for faster indexing performance\n   * it's best to flush by RAM usage instead of document\n   * count and use as large a RAM buffer as you can.\n   *\n   * <p>When this is set, the writer will flush whenever\n   * buffered documents use this much RAM.</p>\n   *\n   * <p> The default value is {@link #DEFAULT_RAM_BUFFER_SIZE_MB}.</p>\n   */\n  public void setRAMBufferSizeMB(double mb) {\n    if (mb <= 0.0)\n      throw new IllegalArgumentException(\"ramBufferSize should be > 0.0 MB\");\n    docWriter.setRAMBufferSizeMB(mb);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["4404b358bf2902b2da0b8eef5ea0a68acd37674b"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2558ddf9e14a97bc597f5b72bb3ecb5b7f6bba8e","date":1191352543,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#setRAMBufferSizeMB(double).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#setRAMBufferSizeMB(double).mjava","sourceNew":"  /** Determines the amount of RAM that may be used for\n   * buffering added documents before they are flushed as a\n   * new Segment.  Generally for faster indexing performance\n   * it's best to flush by RAM usage instead of document\n   * count and use as large a RAM buffer as you can.\n   *\n   * <p>When this is set, the writer will flush whenever\n   * buffered documents use this much RAM.  Pass in {@link\n   * #DISABLE_AUTO_FLUSH} to prevent triggering a flush due\n   * to RAM usage.  Note that if flushing by document count\n   * is also enabled, then the flush will be triggered by\n   * whichever comes first.</p>\n   *\n   * <p> The default value is {@link #DEFAULT_RAM_BUFFER_SIZE_MB}.</p>\n   * \n   * @throws IllegalArgumentException if ramBufferSize is\n   * enabled but non-positive, or it disables ramBufferSize\n   * when maxBufferedDocs is already disabled\n   */\n  public void setRAMBufferSizeMB(double mb) {\n    if (mb != DISABLE_AUTO_FLUSH && mb <= 0.0)\n      throw new IllegalArgumentException(\n          \"ramBufferSize should be > 0.0 MB when enabled\");\n    if (mb == DISABLE_AUTO_FLUSH && getMaxBufferedDocs() == DISABLE_AUTO_FLUSH)\n      throw new IllegalArgumentException(\n          \"at least one of ramBufferSize and maxBufferedDocs must be enabled\");\n    docWriter.setRAMBufferSizeMB(mb);\n  }\n\n","sourceOld":"  /** Determines the amount of RAM that may be used for\n   * buffering added documents before they are flushed as a\n   * new Segment.  Generally for faster indexing performance\n   * it's best to flush by RAM usage instead of document\n   * count and use as large a RAM buffer as you can.\n   *\n   * <p>When this is set, the writer will flush whenever\n   * buffered documents use this much RAM.</p>\n   *\n   * <p> The default value is {@link #DEFAULT_RAM_BUFFER_SIZE_MB}.</p>\n   */\n  public void setRAMBufferSizeMB(double mb) {\n    if (mb <= 0.0)\n      throw new IllegalArgumentException(\"ramBufferSize should be > 0.0 MB\");\n    docWriter.setRAMBufferSizeMB(mb);\n  }\n\n","bugFix":null,"bugIntro":["4404b358bf2902b2da0b8eef5ea0a68acd37674b"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"67006a60923e2124212d3baa0d29b444bcbd8373","date":1191425052,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#setRAMBufferSizeMB(double).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#setRAMBufferSizeMB(double).mjava","sourceNew":"  /** Determines the amount of RAM that may be used for\n   * buffering added documents before they are flushed as a\n   * new Segment.  Generally for faster indexing performance\n   * it's best to flush by RAM usage instead of document\n   * count and use as large a RAM buffer as you can.\n   *\n   * <p>When this is set, the writer will flush whenever\n   * buffered documents use this much RAM.  Pass in {@link\n   * #DISABLE_AUTO_FLUSH} to prevent triggering a flush due\n   * to RAM usage.  Note that if flushing by document count\n   * is also enabled, then the flush will be triggered by\n   * whichever comes first.</p>\n   *\n   * <p> The default value is {@link #DEFAULT_RAM_BUFFER_SIZE_MB}.</p>\n   * \n   * @throws IllegalArgumentException if ramBufferSize is\n   * enabled but non-positive, or it disables ramBufferSize\n   * when maxBufferedDocs is already disabled\n   */\n  public void setRAMBufferSizeMB(double mb) {\n    if (mb != DISABLE_AUTO_FLUSH && mb <= 0.0)\n      throw new IllegalArgumentException(\n          \"ramBufferSize should be > 0.0 MB when enabled\");\n    if (mb == DISABLE_AUTO_FLUSH && getMaxBufferedDocs() == DISABLE_AUTO_FLUSH)\n      throw new IllegalArgumentException(\n          \"at least one of ramBufferSize and maxBufferedDocs must be enabled\");\n    docWriter.setRAMBufferSizeMB(mb);\n    if (infoStream != null)\n      message(\"setRAMBufferSizeMB \" + mb);\n  }\n\n","sourceOld":"  /** Determines the amount of RAM that may be used for\n   * buffering added documents before they are flushed as a\n   * new Segment.  Generally for faster indexing performance\n   * it's best to flush by RAM usage instead of document\n   * count and use as large a RAM buffer as you can.\n   *\n   * <p>When this is set, the writer will flush whenever\n   * buffered documents use this much RAM.  Pass in {@link\n   * #DISABLE_AUTO_FLUSH} to prevent triggering a flush due\n   * to RAM usage.  Note that if flushing by document count\n   * is also enabled, then the flush will be triggered by\n   * whichever comes first.</p>\n   *\n   * <p> The default value is {@link #DEFAULT_RAM_BUFFER_SIZE_MB}.</p>\n   * \n   * @throws IllegalArgumentException if ramBufferSize is\n   * enabled but non-positive, or it disables ramBufferSize\n   * when maxBufferedDocs is already disabled\n   */\n  public void setRAMBufferSizeMB(double mb) {\n    if (mb != DISABLE_AUTO_FLUSH && mb <= 0.0)\n      throw new IllegalArgumentException(\n          \"ramBufferSize should be > 0.0 MB when enabled\");\n    if (mb == DISABLE_AUTO_FLUSH && getMaxBufferedDocs() == DISABLE_AUTO_FLUSH)\n      throw new IllegalArgumentException(\n          \"at least one of ramBufferSize and maxBufferedDocs must be enabled\");\n    docWriter.setRAMBufferSizeMB(mb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4404b358bf2902b2da0b8eef5ea0a68acd37674b","date":1247143497,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#setRAMBufferSizeMB(double).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#setRAMBufferSizeMB(double).mjava","sourceNew":"  /** Determines the amount of RAM that may be used for\n   * buffering added documents and deletions before they are\n   * flushed to the Directory.  Generally for faster\n   * indexing performance it's best to flush by RAM usage\n   * instead of document count and use as large a RAM buffer\n   * as you can.\n   *\n   * <p>When this is set, the writer will flush whenever\n   * buffered documents and deletions use this much RAM.\n   * Pass in {@link #DISABLE_AUTO_FLUSH} to prevent\n   * triggering a flush due to RAM usage.  Note that if\n   * flushing by document count is also enabled, then the\n   * flush will be triggered by whichever comes first.</p>\n   *\n   * <p> <b>NOTE</b>: the account of RAM usage for pending\n   * deletions is only approximate.  Specifically, if you\n   * delete by Query, Lucene currently has no way to measure\n   * the RAM usage if individual Queries so the accounting\n   * will under-estimate and you should compensate by either\n   * calling commit() periodically yourself, or by using\n   * {@link #setMaxBufferedDeleteTerms} to flush by count\n   * instead of RAM usage (each buffered delete Query counts\n   * as one).\n   *\n   * <p> The default value is {@link #DEFAULT_RAM_BUFFER_SIZE_MB}.</p>\n   * \n   * @throws IllegalArgumentException if ramBufferSize is\n   * enabled but non-positive, or it disables ramBufferSize\n   * when maxBufferedDocs is already disabled\n   */\n  public void setRAMBufferSizeMB(double mb) {\n    if (mb != DISABLE_AUTO_FLUSH && mb <= 0.0)\n      throw new IllegalArgumentException(\n          \"ramBufferSize should be > 0.0 MB when enabled\");\n    if (mb == DISABLE_AUTO_FLUSH && getMaxBufferedDocs() == DISABLE_AUTO_FLUSH)\n      throw new IllegalArgumentException(\n          \"at least one of ramBufferSize and maxBufferedDocs must be enabled\");\n    docWriter.setRAMBufferSizeMB(mb);\n    if (infoStream != null)\n      message(\"setRAMBufferSizeMB \" + mb);\n  }\n\n","sourceOld":"  /** Determines the amount of RAM that may be used for\n   * buffering added documents before they are flushed as a\n   * new Segment.  Generally for faster indexing performance\n   * it's best to flush by RAM usage instead of document\n   * count and use as large a RAM buffer as you can.\n   *\n   * <p>When this is set, the writer will flush whenever\n   * buffered documents use this much RAM.  Pass in {@link\n   * #DISABLE_AUTO_FLUSH} to prevent triggering a flush due\n   * to RAM usage.  Note that if flushing by document count\n   * is also enabled, then the flush will be triggered by\n   * whichever comes first.</p>\n   *\n   * <p> The default value is {@link #DEFAULT_RAM_BUFFER_SIZE_MB}.</p>\n   * \n   * @throws IllegalArgumentException if ramBufferSize is\n   * enabled but non-positive, or it disables ramBufferSize\n   * when maxBufferedDocs is already disabled\n   */\n  public void setRAMBufferSizeMB(double mb) {\n    if (mb != DISABLE_AUTO_FLUSH && mb <= 0.0)\n      throw new IllegalArgumentException(\n          \"ramBufferSize should be > 0.0 MB when enabled\");\n    if (mb == DISABLE_AUTO_FLUSH && getMaxBufferedDocs() == DISABLE_AUTO_FLUSH)\n      throw new IllegalArgumentException(\n          \"at least one of ramBufferSize and maxBufferedDocs must be enabled\");\n    docWriter.setRAMBufferSizeMB(mb);\n    if (infoStream != null)\n      message(\"setRAMBufferSizeMB \" + mb);\n  }\n\n","bugFix":["4350b17bd363cd13a95171b8df1ca62ea4c3e71c","2558ddf9e14a97bc597f5b72bb3ecb5b7f6bba8e"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c9aa9db2f72562312035d57c5b4f76601cacf26e","date":1256029491,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#setRAMBufferSizeMB(double).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#setRAMBufferSizeMB(double).mjava","sourceNew":"  /** Determines the amount of RAM that may be used for\n   * buffering added documents and deletions before they are\n   * flushed to the Directory.  Generally for faster\n   * indexing performance it's best to flush by RAM usage\n   * instead of document count and use as large a RAM buffer\n   * as you can.\n   *\n   * <p>When this is set, the writer will flush whenever\n   * buffered documents and deletions use this much RAM.\n   * Pass in {@link #DISABLE_AUTO_FLUSH} to prevent\n   * triggering a flush due to RAM usage.  Note that if\n   * flushing by document count is also enabled, then the\n   * flush will be triggered by whichever comes first.</p>\n   *\n   * <p> <b>NOTE</b>: the account of RAM usage for pending\n   * deletions is only approximate.  Specifically, if you\n   * delete by Query, Lucene currently has no way to measure\n   * the RAM usage if individual Queries so the accounting\n   * will under-estimate and you should compensate by either\n   * calling commit() periodically yourself, or by using\n   * {@link #setMaxBufferedDeleteTerms} to flush by count\n   * instead of RAM usage (each buffered delete Query counts\n   * as one).\n   *\n   * <p> <b>NOTE</b>: because IndexWriter uses\n   * <code>int</code>s when managing its internal storage,\n   * the absolute maximum value for this setting is somewhat\n   * less than 2048 MB.  The precise limit depends on\n   * various factors, such as how large your documents are,\n   * how many fields have norms, etc., so it's best to set\n   * this value comfortably under 2048.</p>\n   *\n   * <p> The default value is {@link #DEFAULT_RAM_BUFFER_SIZE_MB}.</p>\n   * \n   * @throws IllegalArgumentException if ramBufferSize is\n   * enabled but non-positive, or it disables ramBufferSize\n   * when maxBufferedDocs is already disabled\n   */\n  public void setRAMBufferSizeMB(double mb) {\n    if (mb > 2048.0) {\n      throw new IllegalArgumentException(\"ramBufferSize \" + mb + \" is too large; should be comfortably less than 2048\");\n    }\n    if (mb != DISABLE_AUTO_FLUSH && mb <= 0.0)\n      throw new IllegalArgumentException(\n          \"ramBufferSize should be > 0.0 MB when enabled\");\n    if (mb == DISABLE_AUTO_FLUSH && getMaxBufferedDocs() == DISABLE_AUTO_FLUSH)\n      throw new IllegalArgumentException(\n          \"at least one of ramBufferSize and maxBufferedDocs must be enabled\");\n    docWriter.setRAMBufferSizeMB(mb);\n    if (infoStream != null)\n      message(\"setRAMBufferSizeMB \" + mb);\n  }\n\n","sourceOld":"  /** Determines the amount of RAM that may be used for\n   * buffering added documents and deletions before they are\n   * flushed to the Directory.  Generally for faster\n   * indexing performance it's best to flush by RAM usage\n   * instead of document count and use as large a RAM buffer\n   * as you can.\n   *\n   * <p>When this is set, the writer will flush whenever\n   * buffered documents and deletions use this much RAM.\n   * Pass in {@link #DISABLE_AUTO_FLUSH} to prevent\n   * triggering a flush due to RAM usage.  Note that if\n   * flushing by document count is also enabled, then the\n   * flush will be triggered by whichever comes first.</p>\n   *\n   * <p> <b>NOTE</b>: the account of RAM usage for pending\n   * deletions is only approximate.  Specifically, if you\n   * delete by Query, Lucene currently has no way to measure\n   * the RAM usage if individual Queries so the accounting\n   * will under-estimate and you should compensate by either\n   * calling commit() periodically yourself, or by using\n   * {@link #setMaxBufferedDeleteTerms} to flush by count\n   * instead of RAM usage (each buffered delete Query counts\n   * as one).\n   *\n   * <p> The default value is {@link #DEFAULT_RAM_BUFFER_SIZE_MB}.</p>\n   * \n   * @throws IllegalArgumentException if ramBufferSize is\n   * enabled but non-positive, or it disables ramBufferSize\n   * when maxBufferedDocs is already disabled\n   */\n  public void setRAMBufferSizeMB(double mb) {\n    if (mb != DISABLE_AUTO_FLUSH && mb <= 0.0)\n      throw new IllegalArgumentException(\n          \"ramBufferSize should be > 0.0 MB when enabled\");\n    if (mb == DISABLE_AUTO_FLUSH && getMaxBufferedDocs() == DISABLE_AUTO_FLUSH)\n      throw new IllegalArgumentException(\n          \"at least one of ramBufferSize and maxBufferedDocs must be enabled\");\n    docWriter.setRAMBufferSizeMB(mb);\n    if (infoStream != null)\n      message(\"setRAMBufferSizeMB \" + mb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1cedb00d2dd44640194401179358a2e3ba6051bf","date":1268243626,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#setRAMBufferSizeMB(double).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#setRAMBufferSizeMB(double).mjava","sourceNew":"  /** Determines the amount of RAM that may be used for\n   * buffering added documents and deletions before they are\n   * flushed to the Directory.  Generally for faster\n   * indexing performance it's best to flush by RAM usage\n   * instead of document count and use as large a RAM buffer\n   * as you can.\n   *\n   * <p>When this is set, the writer will flush whenever\n   * buffered documents and deletions use this much RAM.\n   * Pass in {@link #DISABLE_AUTO_FLUSH} to prevent\n   * triggering a flush due to RAM usage.  Note that if\n   * flushing by document count is also enabled, then the\n   * flush will be triggered by whichever comes first.</p>\n   *\n   * <p> <b>NOTE</b>: the account of RAM usage for pending\n   * deletions is only approximate.  Specifically, if you\n   * delete by Query, Lucene currently has no way to measure\n   * the RAM usage if individual Queries so the accounting\n   * will under-estimate and you should compensate by either\n   * calling commit() periodically yourself, or by using\n   * {@link #setMaxBufferedDeleteTerms} to flush by count\n   * instead of RAM usage (each buffered delete Query counts\n   * as one).\n   *\n   * <p> <b>NOTE</b>: because IndexWriter uses\n   * <code>int</code>s when managing its internal storage,\n   * the absolute maximum value for this setting is somewhat\n   * less than 2048 MB.  The precise limit depends on\n   * various factors, such as how large your documents are,\n   * how many fields have norms, etc., so it's best to set\n   * this value comfortably under 2048.</p>\n   *\n   * <p> The default value is {@link #DEFAULT_RAM_BUFFER_SIZE_MB}.</p>\n   * \n   * @throws IllegalArgumentException if ramBufferSize is\n   * enabled but non-positive, or it disables ramBufferSize\n   * when maxBufferedDocs is already disabled\n   * @deprecated use {@link IndexWriterConfig#setRAMBufferSizeMB(double)} instead.\n   */\n  public void setRAMBufferSizeMB(double mb) {\n    if (mb > 2048.0) {\n      throw new IllegalArgumentException(\"ramBufferSize \" + mb + \" is too large; should be comfortably less than 2048\");\n    }\n    if (mb != DISABLE_AUTO_FLUSH && mb <= 0.0)\n      throw new IllegalArgumentException(\n          \"ramBufferSize should be > 0.0 MB when enabled\");\n    if (mb == DISABLE_AUTO_FLUSH && getMaxBufferedDocs() == DISABLE_AUTO_FLUSH)\n      throw new IllegalArgumentException(\n          \"at least one of ramBufferSize and maxBufferedDocs must be enabled\");\n    docWriter.setRAMBufferSizeMB(mb);\n    if (infoStream != null)\n      message(\"setRAMBufferSizeMB \" + mb);\n    // Required so config.getSimilarity returns the right value. But this will\n    // go away together with the method in 4.0.\n    config.setRAMBufferSizeMB(mb);\n  }\n\n","sourceOld":"  /** Determines the amount of RAM that may be used for\n   * buffering added documents and deletions before they are\n   * flushed to the Directory.  Generally for faster\n   * indexing performance it's best to flush by RAM usage\n   * instead of document count and use as large a RAM buffer\n   * as you can.\n   *\n   * <p>When this is set, the writer will flush whenever\n   * buffered documents and deletions use this much RAM.\n   * Pass in {@link #DISABLE_AUTO_FLUSH} to prevent\n   * triggering a flush due to RAM usage.  Note that if\n   * flushing by document count is also enabled, then the\n   * flush will be triggered by whichever comes first.</p>\n   *\n   * <p> <b>NOTE</b>: the account of RAM usage for pending\n   * deletions is only approximate.  Specifically, if you\n   * delete by Query, Lucene currently has no way to measure\n   * the RAM usage if individual Queries so the accounting\n   * will under-estimate and you should compensate by either\n   * calling commit() periodically yourself, or by using\n   * {@link #setMaxBufferedDeleteTerms} to flush by count\n   * instead of RAM usage (each buffered delete Query counts\n   * as one).\n   *\n   * <p> <b>NOTE</b>: because IndexWriter uses\n   * <code>int</code>s when managing its internal storage,\n   * the absolute maximum value for this setting is somewhat\n   * less than 2048 MB.  The precise limit depends on\n   * various factors, such as how large your documents are,\n   * how many fields have norms, etc., so it's best to set\n   * this value comfortably under 2048.</p>\n   *\n   * <p> The default value is {@link #DEFAULT_RAM_BUFFER_SIZE_MB}.</p>\n   * \n   * @throws IllegalArgumentException if ramBufferSize is\n   * enabled but non-positive, or it disables ramBufferSize\n   * when maxBufferedDocs is already disabled\n   */\n  public void setRAMBufferSizeMB(double mb) {\n    if (mb > 2048.0) {\n      throw new IllegalArgumentException(\"ramBufferSize \" + mb + \" is too large; should be comfortably less than 2048\");\n    }\n    if (mb != DISABLE_AUTO_FLUSH && mb <= 0.0)\n      throw new IllegalArgumentException(\n          \"ramBufferSize should be > 0.0 MB when enabled\");\n    if (mb == DISABLE_AUTO_FLUSH && getMaxBufferedDocs() == DISABLE_AUTO_FLUSH)\n      throw new IllegalArgumentException(\n          \"at least one of ramBufferSize and maxBufferedDocs must be enabled\");\n    docWriter.setRAMBufferSizeMB(mb);\n    if (infoStream != null)\n      message(\"setRAMBufferSizeMB \" + mb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e52fea2c4081a1e552b98506691990be59503168","date":1268250331,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#setRAMBufferSizeMB(double).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#setRAMBufferSizeMB(double).mjava","sourceNew":"  /** Determines the amount of RAM that may be used for\n   * buffering added documents and deletions before they are\n   * flushed to the Directory.  Generally for faster\n   * indexing performance it's best to flush by RAM usage\n   * instead of document count and use as large a RAM buffer\n   * as you can.\n   *\n   * <p>When this is set, the writer will flush whenever\n   * buffered documents and deletions use this much RAM.\n   * Pass in {@link #DISABLE_AUTO_FLUSH} to prevent\n   * triggering a flush due to RAM usage.  Note that if\n   * flushing by document count is also enabled, then the\n   * flush will be triggered by whichever comes first.</p>\n   *\n   * <p> <b>NOTE</b>: the account of RAM usage for pending\n   * deletions is only approximate.  Specifically, if you\n   * delete by Query, Lucene currently has no way to measure\n   * the RAM usage if individual Queries so the accounting\n   * will under-estimate and you should compensate by either\n   * calling commit() periodically yourself, or by using\n   * {@link #setMaxBufferedDeleteTerms} to flush by count\n   * instead of RAM usage (each buffered delete Query counts\n   * as one).\n   *\n   * <p> <b>NOTE</b>: because IndexWriter uses\n   * <code>int</code>s when managing its internal storage,\n   * the absolute maximum value for this setting is somewhat\n   * less than 2048 MB.  The precise limit depends on\n   * various factors, such as how large your documents are,\n   * how many fields have norms, etc., so it's best to set\n   * this value comfortably under 2048.</p>\n   *\n   * <p> The default value is {@link #DEFAULT_RAM_BUFFER_SIZE_MB}.</p>\n   * \n   * @throws IllegalArgumentException if ramBufferSize is\n   * enabled but non-positive, or it disables ramBufferSize\n   * when maxBufferedDocs is already disabled\n   */\n  public void setRAMBufferSizeMB(double mb) {\n    if (mb > 2048.0) {\n      throw new IllegalArgumentException(\"ramBufferSize \" + mb + \" is too large; should be comfortably less than 2048\");\n    }\n    if (mb != DISABLE_AUTO_FLUSH && mb <= 0.0)\n      throw new IllegalArgumentException(\n          \"ramBufferSize should be > 0.0 MB when enabled\");\n    if (mb == DISABLE_AUTO_FLUSH && getMaxBufferedDocs() == DISABLE_AUTO_FLUSH)\n      throw new IllegalArgumentException(\n          \"at least one of ramBufferSize and maxBufferedDocs must be enabled\");\n    docWriter.setRAMBufferSizeMB(mb);\n    if (infoStream != null)\n      message(\"setRAMBufferSizeMB \" + mb);\n  }\n\n","sourceOld":"  /** Determines the amount of RAM that may be used for\n   * buffering added documents and deletions before they are\n   * flushed to the Directory.  Generally for faster\n   * indexing performance it's best to flush by RAM usage\n   * instead of document count and use as large a RAM buffer\n   * as you can.\n   *\n   * <p>When this is set, the writer will flush whenever\n   * buffered documents and deletions use this much RAM.\n   * Pass in {@link #DISABLE_AUTO_FLUSH} to prevent\n   * triggering a flush due to RAM usage.  Note that if\n   * flushing by document count is also enabled, then the\n   * flush will be triggered by whichever comes first.</p>\n   *\n   * <p> <b>NOTE</b>: the account of RAM usage for pending\n   * deletions is only approximate.  Specifically, if you\n   * delete by Query, Lucene currently has no way to measure\n   * the RAM usage if individual Queries so the accounting\n   * will under-estimate and you should compensate by either\n   * calling commit() periodically yourself, or by using\n   * {@link #setMaxBufferedDeleteTerms} to flush by count\n   * instead of RAM usage (each buffered delete Query counts\n   * as one).\n   *\n   * <p> <b>NOTE</b>: because IndexWriter uses\n   * <code>int</code>s when managing its internal storage,\n   * the absolute maximum value for this setting is somewhat\n   * less than 2048 MB.  The precise limit depends on\n   * various factors, such as how large your documents are,\n   * how many fields have norms, etc., so it's best to set\n   * this value comfortably under 2048.</p>\n   *\n   * <p> The default value is {@link #DEFAULT_RAM_BUFFER_SIZE_MB}.</p>\n   * \n   * @throws IllegalArgumentException if ramBufferSize is\n   * enabled but non-positive, or it disables ramBufferSize\n   * when maxBufferedDocs is already disabled\n   * @deprecated use {@link IndexWriterConfig#setRAMBufferSizeMB(double)} instead.\n   */\n  public void setRAMBufferSizeMB(double mb) {\n    if (mb > 2048.0) {\n      throw new IllegalArgumentException(\"ramBufferSize \" + mb + \" is too large; should be comfortably less than 2048\");\n    }\n    if (mb != DISABLE_AUTO_FLUSH && mb <= 0.0)\n      throw new IllegalArgumentException(\n          \"ramBufferSize should be > 0.0 MB when enabled\");\n    if (mb == DISABLE_AUTO_FLUSH && getMaxBufferedDocs() == DISABLE_AUTO_FLUSH)\n      throw new IllegalArgumentException(\n          \"at least one of ramBufferSize and maxBufferedDocs must be enabled\");\n    docWriter.setRAMBufferSizeMB(mb);\n    if (infoStream != null)\n      message(\"setRAMBufferSizeMB \" + mb);\n    // Required so config.getSimilarity returns the right value. But this will\n    // go away together with the method in 4.0.\n    config.setRAMBufferSizeMB(mb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8","date":1268494368,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#setRAMBufferSizeMB(double).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#setRAMBufferSizeMB(double).mjava","sourceNew":"  /** Determines the amount of RAM that may be used for\n   * buffering added documents and deletions before they are\n   * flushed to the Directory.  Generally for faster\n   * indexing performance it's best to flush by RAM usage\n   * instead of document count and use as large a RAM buffer\n   * as you can.\n   *\n   * <p>When this is set, the writer will flush whenever\n   * buffered documents and deletions use this much RAM.\n   * Pass in {@link #DISABLE_AUTO_FLUSH} to prevent\n   * triggering a flush due to RAM usage.  Note that if\n   * flushing by document count is also enabled, then the\n   * flush will be triggered by whichever comes first.</p>\n   *\n   * <p> <b>NOTE</b>: the account of RAM usage for pending\n   * deletions is only approximate.  Specifically, if you\n   * delete by Query, Lucene currently has no way to measure\n   * the RAM usage if individual Queries so the accounting\n   * will under-estimate and you should compensate by either\n   * calling commit() periodically yourself, or by using\n   * {@link #setMaxBufferedDeleteTerms} to flush by count\n   * instead of RAM usage (each buffered delete Query counts\n   * as one).\n   *\n   * <p> <b>NOTE</b>: because IndexWriter uses\n   * <code>int</code>s when managing its internal storage,\n   * the absolute maximum value for this setting is somewhat\n   * less than 2048 MB.  The precise limit depends on\n   * various factors, such as how large your documents are,\n   * how many fields have norms, etc., so it's best to set\n   * this value comfortably under 2048.</p>\n   *\n   * <p> The default value is {@link #DEFAULT_RAM_BUFFER_SIZE_MB}.</p>\n   * \n   * @throws IllegalArgumentException if ramBufferSize is\n   * enabled but non-positive, or it disables ramBufferSize\n   * when maxBufferedDocs is already disabled\n   * @deprecated use {@link IndexWriterConfig#setRAMBufferSizeMB(double)} instead.\n   */\n  public void setRAMBufferSizeMB(double mb) {\n    if (mb > 2048.0) {\n      throw new IllegalArgumentException(\"ramBufferSize \" + mb + \" is too large; should be comfortably less than 2048\");\n    }\n    if (mb != DISABLE_AUTO_FLUSH && mb <= 0.0)\n      throw new IllegalArgumentException(\n          \"ramBufferSize should be > 0.0 MB when enabled\");\n    if (mb == DISABLE_AUTO_FLUSH && getMaxBufferedDocs() == DISABLE_AUTO_FLUSH)\n      throw new IllegalArgumentException(\n          \"at least one of ramBufferSize and maxBufferedDocs must be enabled\");\n    docWriter.setRAMBufferSizeMB(mb);\n    if (infoStream != null)\n      message(\"setRAMBufferSizeMB \" + mb);\n    // Required so config.getSimilarity returns the right value. But this will\n    // go away together with the method in 4.0.\n    config.setRAMBufferSizeMB(mb);\n  }\n\n","sourceOld":"  /** Determines the amount of RAM that may be used for\n   * buffering added documents and deletions before they are\n   * flushed to the Directory.  Generally for faster\n   * indexing performance it's best to flush by RAM usage\n   * instead of document count and use as large a RAM buffer\n   * as you can.\n   *\n   * <p>When this is set, the writer will flush whenever\n   * buffered documents and deletions use this much RAM.\n   * Pass in {@link #DISABLE_AUTO_FLUSH} to prevent\n   * triggering a flush due to RAM usage.  Note that if\n   * flushing by document count is also enabled, then the\n   * flush will be triggered by whichever comes first.</p>\n   *\n   * <p> <b>NOTE</b>: the account of RAM usage for pending\n   * deletions is only approximate.  Specifically, if you\n   * delete by Query, Lucene currently has no way to measure\n   * the RAM usage if individual Queries so the accounting\n   * will under-estimate and you should compensate by either\n   * calling commit() periodically yourself, or by using\n   * {@link #setMaxBufferedDeleteTerms} to flush by count\n   * instead of RAM usage (each buffered delete Query counts\n   * as one).\n   *\n   * <p> <b>NOTE</b>: because IndexWriter uses\n   * <code>int</code>s when managing its internal storage,\n   * the absolute maximum value for this setting is somewhat\n   * less than 2048 MB.  The precise limit depends on\n   * various factors, such as how large your documents are,\n   * how many fields have norms, etc., so it's best to set\n   * this value comfortably under 2048.</p>\n   *\n   * <p> The default value is {@link #DEFAULT_RAM_BUFFER_SIZE_MB}.</p>\n   * \n   * @throws IllegalArgumentException if ramBufferSize is\n   * enabled but non-positive, or it disables ramBufferSize\n   * when maxBufferedDocs is already disabled\n   */\n  public void setRAMBufferSizeMB(double mb) {\n    if (mb > 2048.0) {\n      throw new IllegalArgumentException(\"ramBufferSize \" + mb + \" is too large; should be comfortably less than 2048\");\n    }\n    if (mb != DISABLE_AUTO_FLUSH && mb <= 0.0)\n      throw new IllegalArgumentException(\n          \"ramBufferSize should be > 0.0 MB when enabled\");\n    if (mb == DISABLE_AUTO_FLUSH && getMaxBufferedDocs() == DISABLE_AUTO_FLUSH)\n      throw new IllegalArgumentException(\n          \"at least one of ramBufferSize and maxBufferedDocs must be enabled\");\n    docWriter.setRAMBufferSizeMB(mb);\n    if (infoStream != null)\n      message(\"setRAMBufferSizeMB \" + mb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#setRAMBufferSizeMB(double).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#setRAMBufferSizeMB(double).mjava","sourceNew":"  /** Determines the amount of RAM that may be used for\n   * buffering added documents and deletions before they are\n   * flushed to the Directory.  Generally for faster\n   * indexing performance it's best to flush by RAM usage\n   * instead of document count and use as large a RAM buffer\n   * as you can.\n   *\n   * <p>When this is set, the writer will flush whenever\n   * buffered documents and deletions use this much RAM.\n   * Pass in {@link #DISABLE_AUTO_FLUSH} to prevent\n   * triggering a flush due to RAM usage.  Note that if\n   * flushing by document count is also enabled, then the\n   * flush will be triggered by whichever comes first.</p>\n   *\n   * <p> <b>NOTE</b>: the account of RAM usage for pending\n   * deletions is only approximate.  Specifically, if you\n   * delete by Query, Lucene currently has no way to measure\n   * the RAM usage if individual Queries so the accounting\n   * will under-estimate and you should compensate by either\n   * calling commit() periodically yourself, or by using\n   * {@link #setMaxBufferedDeleteTerms} to flush by count\n   * instead of RAM usage (each buffered delete Query counts\n   * as one).\n   *\n   * <p> <b>NOTE</b>: because IndexWriter uses\n   * <code>int</code>s when managing its internal storage,\n   * the absolute maximum value for this setting is somewhat\n   * less than 2048 MB.  The precise limit depends on\n   * various factors, such as how large your documents are,\n   * how many fields have norms, etc., so it's best to set\n   * this value comfortably under 2048.</p>\n   *\n   * <p> The default value is {@link #DEFAULT_RAM_BUFFER_SIZE_MB}.</p>\n   * \n   * @throws IllegalArgumentException if ramBufferSize is\n   * enabled but non-positive, or it disables ramBufferSize\n   * when maxBufferedDocs is already disabled\n   * @deprecated use {@link IndexWriterConfig#setRAMBufferSizeMB(double)} instead.\n   */\n  public void setRAMBufferSizeMB(double mb) {\n    if (mb > 2048.0) {\n      throw new IllegalArgumentException(\"ramBufferSize \" + mb + \" is too large; should be comfortably less than 2048\");\n    }\n    if (mb != DISABLE_AUTO_FLUSH && mb <= 0.0)\n      throw new IllegalArgumentException(\n          \"ramBufferSize should be > 0.0 MB when enabled\");\n    if (mb == DISABLE_AUTO_FLUSH && getMaxBufferedDocs() == DISABLE_AUTO_FLUSH)\n      throw new IllegalArgumentException(\n          \"at least one of ramBufferSize and maxBufferedDocs must be enabled\");\n    docWriter.setRAMBufferSizeMB(mb);\n    if (infoStream != null)\n      message(\"setRAMBufferSizeMB \" + mb);\n    // Required so config.getSimilarity returns the right value. But this will\n    // go away together with the method in 4.0.\n    config.setRAMBufferSizeMB(mb);\n  }\n\n","sourceOld":"  /** Determines the amount of RAM that may be used for\n   * buffering added documents and deletions before they are\n   * flushed to the Directory.  Generally for faster\n   * indexing performance it's best to flush by RAM usage\n   * instead of document count and use as large a RAM buffer\n   * as you can.\n   *\n   * <p>When this is set, the writer will flush whenever\n   * buffered documents and deletions use this much RAM.\n   * Pass in {@link #DISABLE_AUTO_FLUSH} to prevent\n   * triggering a flush due to RAM usage.  Note that if\n   * flushing by document count is also enabled, then the\n   * flush will be triggered by whichever comes first.</p>\n   *\n   * <p> <b>NOTE</b>: the account of RAM usage for pending\n   * deletions is only approximate.  Specifically, if you\n   * delete by Query, Lucene currently has no way to measure\n   * the RAM usage if individual Queries so the accounting\n   * will under-estimate and you should compensate by either\n   * calling commit() periodically yourself, or by using\n   * {@link #setMaxBufferedDeleteTerms} to flush by count\n   * instead of RAM usage (each buffered delete Query counts\n   * as one).\n   *\n   * <p> <b>NOTE</b>: because IndexWriter uses\n   * <code>int</code>s when managing its internal storage,\n   * the absolute maximum value for this setting is somewhat\n   * less than 2048 MB.  The precise limit depends on\n   * various factors, such as how large your documents are,\n   * how many fields have norms, etc., so it's best to set\n   * this value comfortably under 2048.</p>\n   *\n   * <p> The default value is {@link #DEFAULT_RAM_BUFFER_SIZE_MB}.</p>\n   * \n   * @throws IllegalArgumentException if ramBufferSize is\n   * enabled but non-positive, or it disables ramBufferSize\n   * when maxBufferedDocs is already disabled\n   * @deprecated use {@link IndexWriterConfig#setRAMBufferSizeMB(double)} instead.\n   */\n  public void setRAMBufferSizeMB(double mb) {\n    if (mb > 2048.0) {\n      throw new IllegalArgumentException(\"ramBufferSize \" + mb + \" is too large; should be comfortably less than 2048\");\n    }\n    if (mb != DISABLE_AUTO_FLUSH && mb <= 0.0)\n      throw new IllegalArgumentException(\n          \"ramBufferSize should be > 0.0 MB when enabled\");\n    if (mb == DISABLE_AUTO_FLUSH && getMaxBufferedDocs() == DISABLE_AUTO_FLUSH)\n      throw new IllegalArgumentException(\n          \"at least one of ramBufferSize and maxBufferedDocs must be enabled\");\n    docWriter.setRAMBufferSizeMB(mb);\n    if (infoStream != null)\n      message(\"setRAMBufferSizeMB \" + mb);\n    // Required so config.getSimilarity returns the right value. But this will\n    // go away together with the method in 4.0.\n    config.setRAMBufferSizeMB(mb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8":["e52fea2c4081a1e552b98506691990be59503168"],"67006a60923e2124212d3baa0d29b444bcbd8373":["2558ddf9e14a97bc597f5b72bb3ecb5b7f6bba8e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"1cedb00d2dd44640194401179358a2e3ba6051bf":["c9aa9db2f72562312035d57c5b4f76601cacf26e"],"c9aa9db2f72562312035d57c5b4f76601cacf26e":["4404b358bf2902b2da0b8eef5ea0a68acd37674b"],"2558ddf9e14a97bc597f5b72bb3ecb5b7f6bba8e":["4350b17bd363cd13a95171b8df1ca62ea4c3e71c"],"e52fea2c4081a1e552b98506691990be59503168":["1cedb00d2dd44640194401179358a2e3ba6051bf"],"4404b358bf2902b2da0b8eef5ea0a68acd37674b":["67006a60923e2124212d3baa0d29b444bcbd8373"],"4350b17bd363cd13a95171b8df1ca62ea4c3e71c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8"]},"commit2Childs":{"84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"67006a60923e2124212d3baa0d29b444bcbd8373":["4404b358bf2902b2da0b8eef5ea0a68acd37674b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["4350b17bd363cd13a95171b8df1ca62ea4c3e71c"],"1cedb00d2dd44640194401179358a2e3ba6051bf":["e52fea2c4081a1e552b98506691990be59503168"],"c9aa9db2f72562312035d57c5b4f76601cacf26e":["1cedb00d2dd44640194401179358a2e3ba6051bf"],"2558ddf9e14a97bc597f5b72bb3ecb5b7f6bba8e":["67006a60923e2124212d3baa0d29b444bcbd8373"],"e52fea2c4081a1e552b98506691990be59503168":["84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8"],"4404b358bf2902b2da0b8eef5ea0a68acd37674b":["c9aa9db2f72562312035d57c5b4f76601cacf26e"],"4350b17bd363cd13a95171b8df1ca62ea4c3e71c":["2558ddf9e14a97bc597f5b72bb3ecb5b7f6bba8e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}