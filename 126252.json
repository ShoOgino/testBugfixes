{"path":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testAddDocumentOnDiskFull().mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testAddDocumentOnDiskFull().mjava","pathOld":"src/test/org/apache/lucene/index/TestIndexWriter#testAddDocumentOnDiskFull().mjava","sourceNew":"    /*\n     * Make sure IndexWriter cleans up on hitting a disk\n     * full exception in addDocument.\n     */\n    public void testAddDocumentOnDiskFull() throws IOException {\n\n      for(int pass=0;pass<2;pass++) {\n        if (VERBOSE)\n          System.out.println(\"TEST: pass=\" + pass);\n        boolean doAbort = pass == 1;\n        long diskFree = 200;\n        while(true) {\n          if (VERBOSE)\n            System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n          MockRAMDirectory dir = new MockRAMDirectory();\n          dir.setMaxSizeInBytes(diskFree);\n          IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)));\n\n          MergeScheduler ms = writer.getConfig().getMergeScheduler();\n          if (ms instanceof ConcurrentMergeScheduler)\n            // This test intentionally produces exceptions\n            // in the threads that CMS launches; we don't\n            // want to pollute test output with these.\n            ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n\n          boolean hitError = false;\n          try {\n            for(int i=0;i<200;i++) {\n              addDoc(writer);\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: exception on addDoc\");\n              e.printStackTrace(System.out);\n            }\n            hitError = true;\n          }\n\n          if (hitError) {\n            if (doAbort) {\n              writer.rollback();\n            } else {\n              try {\n                writer.close();\n              } catch (IOException e) {\n                if (VERBOSE) {\n                  System.out.println(\"TEST: exception on close\");\n                  e.printStackTrace(System.out);\n                }\n                dir.setMaxSizeInBytes(0);\n                writer.close();\n              }\n            }\n\n            _TestUtil.syncConcurrentMerges(ms);\n\n            assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n\n            // Make sure reader can open the index:\n            IndexReader.open(dir, true).close();\n\n            dir.close();\n\n            // Now try again w/ more space:\n            diskFree += 500;\n          } else {\n            _TestUtil.syncConcurrentMerges(writer);\n            dir.close();\n            break;\n          }\n        }\n      }\n    }                                               \n\n","sourceOld":"    /*\n     * Make sure IndexWriter cleans up on hitting a disk\n     * full exception in addDocument.\n     */\n    public void testAddDocumentOnDiskFull() throws IOException {\n\n      for(int pass=0;pass<2;pass++) {\n        if (VERBOSE)\n          System.out.println(\"TEST: pass=\" + pass);\n        boolean doAbort = pass == 1;\n        long diskFree = 200;\n        while(true) {\n          if (VERBOSE)\n            System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n          MockRAMDirectory dir = new MockRAMDirectory();\n          dir.setMaxSizeInBytes(diskFree);\n          IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)));\n\n          MergeScheduler ms = writer.getConfig().getMergeScheduler();\n          if (ms instanceof ConcurrentMergeScheduler)\n            // This test intentionally produces exceptions\n            // in the threads that CMS launches; we don't\n            // want to pollute test output with these.\n            ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n\n          boolean hitError = false;\n          try {\n            for(int i=0;i<200;i++) {\n              addDoc(writer);\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: exception on addDoc\");\n              e.printStackTrace(System.out);\n            }\n            hitError = true;\n          }\n\n          if (hitError) {\n            if (doAbort) {\n              writer.rollback();\n            } else {\n              try {\n                writer.close();\n              } catch (IOException e) {\n                if (VERBOSE) {\n                  System.out.println(\"TEST: exception on close\");\n                  e.printStackTrace(System.out);\n                }\n                dir.setMaxSizeInBytes(0);\n                writer.close();\n              }\n            }\n\n            _TestUtil.syncConcurrentMerges(ms);\n\n            assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n\n            // Make sure reader can open the index:\n            IndexReader.open(dir, true).close();\n\n            dir.close();\n\n            // Now try again w/ more space:\n            diskFree += 500;\n          } else {\n            _TestUtil.syncConcurrentMerges(writer);\n            dir.close();\n            break;\n          }\n        }\n      }\n    }                                               \n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d572389229127c297dd1fa5ce4758e1cec41e799","date":1273610938,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testAddDocumentOnDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testAddDocumentOnDiskFull().mjava","sourceNew":"    /*\n     * Make sure IndexWriter cleans up on hitting a disk\n     * full exception in addDocument.\n     */\n    public void testAddDocumentOnDiskFull() throws IOException {\n\n      for(int pass=0;pass<2;pass++) {\n        if (VERBOSE)\n          System.out.println(\"TEST: pass=\" + pass);\n        boolean doAbort = pass == 1;\n        long diskFree = 200;\n        while(true) {\n          if (VERBOSE)\n            System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n          MockRAMDirectory dir = new MockRAMDirectory();\n          dir.setMaxSizeInBytes(diskFree);\n          IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n\n          MergeScheduler ms = writer.getConfig().getMergeScheduler();\n          if (ms instanceof ConcurrentMergeScheduler)\n            // This test intentionally produces exceptions\n            // in the threads that CMS launches; we don't\n            // want to pollute test output with these.\n            ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n\n          boolean hitError = false;\n          try {\n            for(int i=0;i<200;i++) {\n              addDoc(writer);\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: exception on addDoc\");\n              e.printStackTrace(System.out);\n            }\n            hitError = true;\n          }\n\n          if (hitError) {\n            if (doAbort) {\n              writer.rollback();\n            } else {\n              try {\n                writer.close();\n              } catch (IOException e) {\n                if (VERBOSE) {\n                  System.out.println(\"TEST: exception on close\");\n                  e.printStackTrace(System.out);\n                }\n                dir.setMaxSizeInBytes(0);\n                writer.close();\n              }\n            }\n\n            _TestUtil.syncConcurrentMerges(ms);\n\n            assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n\n            // Make sure reader can open the index:\n            IndexReader.open(dir, true).close();\n\n            dir.close();\n\n            // Now try again w/ more space:\n            diskFree += 500;\n          } else {\n            _TestUtil.syncConcurrentMerges(writer);\n            dir.close();\n            break;\n          }\n        }\n      }\n    }                                               \n\n","sourceOld":"    /*\n     * Make sure IndexWriter cleans up on hitting a disk\n     * full exception in addDocument.\n     */\n    public void testAddDocumentOnDiskFull() throws IOException {\n\n      for(int pass=0;pass<2;pass++) {\n        if (VERBOSE)\n          System.out.println(\"TEST: pass=\" + pass);\n        boolean doAbort = pass == 1;\n        long diskFree = 200;\n        while(true) {\n          if (VERBOSE)\n            System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n          MockRAMDirectory dir = new MockRAMDirectory();\n          dir.setMaxSizeInBytes(diskFree);\n          IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)));\n\n          MergeScheduler ms = writer.getConfig().getMergeScheduler();\n          if (ms instanceof ConcurrentMergeScheduler)\n            // This test intentionally produces exceptions\n            // in the threads that CMS launches; we don't\n            // want to pollute test output with these.\n            ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n\n          boolean hitError = false;\n          try {\n            for(int i=0;i<200;i++) {\n              addDoc(writer);\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: exception on addDoc\");\n              e.printStackTrace(System.out);\n            }\n            hitError = true;\n          }\n\n          if (hitError) {\n            if (doAbort) {\n              writer.rollback();\n            } else {\n              try {\n                writer.close();\n              } catch (IOException e) {\n                if (VERBOSE) {\n                  System.out.println(\"TEST: exception on close\");\n                  e.printStackTrace(System.out);\n                }\n                dir.setMaxSizeInBytes(0);\n                writer.close();\n              }\n            }\n\n            _TestUtil.syncConcurrentMerges(ms);\n\n            assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n\n            // Make sure reader can open the index:\n            IndexReader.open(dir, true).close();\n\n            dir.close();\n\n            // Now try again w/ more space:\n            diskFree += 500;\n          } else {\n            _TestUtil.syncConcurrentMerges(writer);\n            dir.close();\n            break;\n          }\n        }\n      }\n    }                                               \n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b21422ff1d1d56499dec481f193b402e5e8def5b","date":1281472367,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testAddDocumentOnDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testAddDocumentOnDiskFull().mjava","sourceNew":"    /*\n     * Make sure IndexWriter cleans up on hitting a disk\n     * full exception in addDocument.\n     */\n    public void testAddDocumentOnDiskFull() throws IOException {\n\n      for(int pass=0;pass<2;pass++) {\n        if (VERBOSE)\n          System.out.println(\"TEST: pass=\" + pass);\n        boolean doAbort = pass == 1;\n        long diskFree = 200;\n        while(true) {\n          if (VERBOSE)\n            System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n          MockRAMDirectory dir = new MockRAMDirectory();\n          dir.setMaxSizeInBytes(diskFree);\n          IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));\n          MergeScheduler ms = writer.getConfig().getMergeScheduler();\n          if (ms instanceof ConcurrentMergeScheduler)\n            // This test intentionally produces exceptions\n            // in the threads that CMS launches; we don't\n            // want to pollute test output with these.\n            ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n\n          boolean hitError = false;\n          try {\n            for(int i=0;i<200;i++) {\n              addDoc(writer);\n            }\n            writer.commit();\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: exception on addDoc\");\n              e.printStackTrace(System.out);\n            }\n            hitError = true;\n          }\n\n          if (hitError) {\n            if (doAbort) {\n              writer.rollback();\n            } else {\n              try {\n                writer.close();\n              } catch (IOException e) {\n                if (VERBOSE) {\n                  System.out.println(\"TEST: exception on close\");\n                  e.printStackTrace(System.out);\n                }\n                dir.setMaxSizeInBytes(0);\n                writer.close();\n              }\n            }\n\n            //_TestUtil.syncConcurrentMerges(ms);\n\n            if (dir.listAll().length > 0) {\n              assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n              \n              // Make sure reader can open the index:\n              IndexReader.open(dir, true).close();\n            }\n              \n            dir.close();\n            // Now try again w/ more space:\n\n            diskFree += 500;\n          } else {\n            //_TestUtil.syncConcurrentMerges(writer);\n            writer.close();\n            dir.close();\n            break;\n          }\n        }\n      }\n    }                                               \n\n","sourceOld":"    /*\n     * Make sure IndexWriter cleans up on hitting a disk\n     * full exception in addDocument.\n     */\n    public void testAddDocumentOnDiskFull() throws IOException {\n\n      for(int pass=0;pass<2;pass++) {\n        if (VERBOSE)\n          System.out.println(\"TEST: pass=\" + pass);\n        boolean doAbort = pass == 1;\n        long diskFree = 200;\n        while(true) {\n          if (VERBOSE)\n            System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n          MockRAMDirectory dir = new MockRAMDirectory();\n          dir.setMaxSizeInBytes(diskFree);\n          IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n\n          MergeScheduler ms = writer.getConfig().getMergeScheduler();\n          if (ms instanceof ConcurrentMergeScheduler)\n            // This test intentionally produces exceptions\n            // in the threads that CMS launches; we don't\n            // want to pollute test output with these.\n            ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n\n          boolean hitError = false;\n          try {\n            for(int i=0;i<200;i++) {\n              addDoc(writer);\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: exception on addDoc\");\n              e.printStackTrace(System.out);\n            }\n            hitError = true;\n          }\n\n          if (hitError) {\n            if (doAbort) {\n              writer.rollback();\n            } else {\n              try {\n                writer.close();\n              } catch (IOException e) {\n                if (VERBOSE) {\n                  System.out.println(\"TEST: exception on close\");\n                  e.printStackTrace(System.out);\n                }\n                dir.setMaxSizeInBytes(0);\n                writer.close();\n              }\n            }\n\n            _TestUtil.syncConcurrentMerges(ms);\n\n            assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n\n            // Make sure reader can open the index:\n            IndexReader.open(dir, true).close();\n\n            dir.close();\n\n            // Now try again w/ more space:\n            diskFree += 500;\n          } else {\n            _TestUtil.syncConcurrentMerges(writer);\n            dir.close();\n            break;\n          }\n        }\n      }\n    }                                               \n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c","date":1281646583,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testAddDocumentOnDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testAddDocumentOnDiskFull().mjava","sourceNew":"    /*\n     * Make sure IndexWriter cleans up on hitting a disk\n     * full exception in addDocument.\n     */\n    public void testAddDocumentOnDiskFull() throws IOException {\n\n      for(int pass=0;pass<2;pass++) {\n        if (VERBOSE)\n          System.out.println(\"TEST: pass=\" + pass);\n        boolean doAbort = pass == 1;\n        long diskFree = 200;\n        while(true) {\n          if (VERBOSE)\n            System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n          MockRAMDirectory dir = newDirectory(random);\n          dir.setMaxSizeInBytes(diskFree);\n          IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));\n          MergeScheduler ms = writer.getConfig().getMergeScheduler();\n          if (ms instanceof ConcurrentMergeScheduler)\n            // This test intentionally produces exceptions\n            // in the threads that CMS launches; we don't\n            // want to pollute test output with these.\n            ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n\n          boolean hitError = false;\n          try {\n            for(int i=0;i<200;i++) {\n              addDoc(writer);\n            }\n            writer.commit();\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: exception on addDoc\");\n              e.printStackTrace(System.out);\n            }\n            hitError = true;\n          }\n\n          if (hitError) {\n            if (doAbort) {\n              writer.rollback();\n            } else {\n              try {\n                writer.close();\n              } catch (IOException e) {\n                if (VERBOSE) {\n                  System.out.println(\"TEST: exception on close\");\n                  e.printStackTrace(System.out);\n                }\n                dir.setMaxSizeInBytes(0);\n                writer.close();\n              }\n            }\n\n            //_TestUtil.syncConcurrentMerges(ms);\n\n            if (dir.listAll().length > 0) {\n              assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n              \n              // Make sure reader can open the index:\n              IndexReader.open(dir, true).close();\n            }\n              \n            dir.close();\n            // Now try again w/ more space:\n\n            diskFree += 500;\n          } else {\n            //_TestUtil.syncConcurrentMerges(writer);\n            writer.close();\n            dir.close();\n            break;\n          }\n        }\n      }\n    }                                               \n\n","sourceOld":"    /*\n     * Make sure IndexWriter cleans up on hitting a disk\n     * full exception in addDocument.\n     */\n    public void testAddDocumentOnDiskFull() throws IOException {\n\n      for(int pass=0;pass<2;pass++) {\n        if (VERBOSE)\n          System.out.println(\"TEST: pass=\" + pass);\n        boolean doAbort = pass == 1;\n        long diskFree = 200;\n        while(true) {\n          if (VERBOSE)\n            System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n          MockRAMDirectory dir = new MockRAMDirectory();\n          dir.setMaxSizeInBytes(diskFree);\n          IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));\n          MergeScheduler ms = writer.getConfig().getMergeScheduler();\n          if (ms instanceof ConcurrentMergeScheduler)\n            // This test intentionally produces exceptions\n            // in the threads that CMS launches; we don't\n            // want to pollute test output with these.\n            ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n\n          boolean hitError = false;\n          try {\n            for(int i=0;i<200;i++) {\n              addDoc(writer);\n            }\n            writer.commit();\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: exception on addDoc\");\n              e.printStackTrace(System.out);\n            }\n            hitError = true;\n          }\n\n          if (hitError) {\n            if (doAbort) {\n              writer.rollback();\n            } else {\n              try {\n                writer.close();\n              } catch (IOException e) {\n                if (VERBOSE) {\n                  System.out.println(\"TEST: exception on close\");\n                  e.printStackTrace(System.out);\n                }\n                dir.setMaxSizeInBytes(0);\n                writer.close();\n              }\n            }\n\n            //_TestUtil.syncConcurrentMerges(ms);\n\n            if (dir.listAll().length > 0) {\n              assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n              \n              // Make sure reader can open the index:\n              IndexReader.open(dir, true).close();\n            }\n              \n            dir.close();\n            // Now try again w/ more space:\n\n            diskFree += 500;\n          } else {\n            //_TestUtil.syncConcurrentMerges(writer);\n            writer.close();\n            dir.close();\n            break;\n          }\n        }\n      }\n    }                                               \n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a05409176bd65129d67a785ee70e881e238a9aef","date":1282582843,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testAddDocumentOnDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testAddDocumentOnDiskFull().mjava","sourceNew":"    /*\n     * Make sure IndexWriter cleans up on hitting a disk\n     * full exception in addDocument.\n     */\n    public void testAddDocumentOnDiskFull() throws IOException {\n\n      for(int pass=0;pass<2;pass++) {\n        if (VERBOSE)\n          System.out.println(\"TEST: pass=\" + pass);\n        boolean doAbort = pass == 1;\n        long diskFree = 200;\n        while(true) {\n          if (VERBOSE)\n            System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n          MockDirectoryWrapper dir = newDirectory(random);\n          dir.setMaxSizeInBytes(diskFree);\n          IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));\n          MergeScheduler ms = writer.getConfig().getMergeScheduler();\n          if (ms instanceof ConcurrentMergeScheduler)\n            // This test intentionally produces exceptions\n            // in the threads that CMS launches; we don't\n            // want to pollute test output with these.\n            ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n\n          boolean hitError = false;\n          try {\n            for(int i=0;i<200;i++) {\n              addDoc(writer);\n            }\n            writer.commit();\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: exception on addDoc\");\n              e.printStackTrace(System.out);\n            }\n            hitError = true;\n          }\n\n          if (hitError) {\n            if (doAbort) {\n              writer.rollback();\n            } else {\n              try {\n                writer.close();\n              } catch (IOException e) {\n                if (VERBOSE) {\n                  System.out.println(\"TEST: exception on close\");\n                  e.printStackTrace(System.out);\n                }\n                dir.setMaxSizeInBytes(0);\n                writer.close();\n              }\n            }\n\n            //_TestUtil.syncConcurrentMerges(ms);\n\n            if (dir.listAll().length > 0) {\n              assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n              \n              // Make sure reader can open the index:\n              IndexReader.open(dir, true).close();\n            }\n              \n            dir.close();\n            // Now try again w/ more space:\n\n            diskFree += 500;\n          } else {\n            //_TestUtil.syncConcurrentMerges(writer);\n            writer.close();\n            dir.close();\n            break;\n          }\n        }\n      }\n    }                                               \n\n","sourceOld":"    /*\n     * Make sure IndexWriter cleans up on hitting a disk\n     * full exception in addDocument.\n     */\n    public void testAddDocumentOnDiskFull() throws IOException {\n\n      for(int pass=0;pass<2;pass++) {\n        if (VERBOSE)\n          System.out.println(\"TEST: pass=\" + pass);\n        boolean doAbort = pass == 1;\n        long diskFree = 200;\n        while(true) {\n          if (VERBOSE)\n            System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n          MockRAMDirectory dir = newDirectory(random);\n          dir.setMaxSizeInBytes(diskFree);\n          IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));\n          MergeScheduler ms = writer.getConfig().getMergeScheduler();\n          if (ms instanceof ConcurrentMergeScheduler)\n            // This test intentionally produces exceptions\n            // in the threads that CMS launches; we don't\n            // want to pollute test output with these.\n            ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n\n          boolean hitError = false;\n          try {\n            for(int i=0;i<200;i++) {\n              addDoc(writer);\n            }\n            writer.commit();\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: exception on addDoc\");\n              e.printStackTrace(System.out);\n            }\n            hitError = true;\n          }\n\n          if (hitError) {\n            if (doAbort) {\n              writer.rollback();\n            } else {\n              try {\n                writer.close();\n              } catch (IOException e) {\n                if (VERBOSE) {\n                  System.out.println(\"TEST: exception on close\");\n                  e.printStackTrace(System.out);\n                }\n                dir.setMaxSizeInBytes(0);\n                writer.close();\n              }\n            }\n\n            //_TestUtil.syncConcurrentMerges(ms);\n\n            if (dir.listAll().length > 0) {\n              assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n              \n              // Make sure reader can open the index:\n              IndexReader.open(dir, true).close();\n            }\n              \n            dir.close();\n            // Now try again w/ more space:\n\n            diskFree += 500;\n          } else {\n            //_TestUtil.syncConcurrentMerges(writer);\n            writer.close();\n            dir.close();\n            break;\n          }\n        }\n      }\n    }                                               \n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3eaa8ca351aa7eefa5bd5bf249e9dd9bb0830c54","date":1282658201,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testAddDocumentOnDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testAddDocumentOnDiskFull().mjava","sourceNew":"    /*\n     * Make sure IndexWriter cleans up on hitting a disk\n     * full exception in addDocument.\n     */\n    public void testAddDocumentOnDiskFull() throws IOException {\n\n      for(int pass=0;pass<2;pass++) {\n        if (VERBOSE)\n          System.out.println(\"TEST: pass=\" + pass);\n        boolean doAbort = pass == 1;\n        long diskFree = 200;\n        while(true) {\n          if (VERBOSE)\n            System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n          MockDirectoryWrapper dir = newDirectory(random);\n          dir.setMaxSizeInBytes(diskFree);\n          IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));\n          MergeScheduler ms = writer.getConfig().getMergeScheduler();\n          if (ms instanceof ConcurrentMergeScheduler)\n            // This test intentionally produces exceptions\n            // in the threads that CMS launches; we don't\n            // want to pollute test output with these.\n            ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n\n          boolean hitError = false;\n          try {\n            for(int i=0;i<200;i++) {\n              addDoc(writer);\n            }\n            writer.commit();\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: exception on addDoc\");\n              e.printStackTrace(System.out);\n            }\n            hitError = true;\n          }\n\n          if (hitError) {\n            if (doAbort) {\n              writer.rollback();\n            } else {\n              try {\n                writer.close();\n              } catch (IOException e) {\n                if (VERBOSE) {\n                  System.out.println(\"TEST: exception on close\");\n                  e.printStackTrace(System.out);\n                }\n                dir.setMaxSizeInBytes(0);\n                writer.close();\n              }\n            }\n\n            //_TestUtil.syncConcurrentMerges(ms);\n\n            if (_TestUtil.anyFilesExceptWriteLock(dir)) {\n              assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n              \n              // Make sure reader can open the index:\n              IndexReader.open(dir, true).close();\n            }\n              \n            dir.close();\n            // Now try again w/ more space:\n\n            diskFree += 500;\n          } else {\n            //_TestUtil.syncConcurrentMerges(writer);\n            writer.close();\n            dir.close();\n            break;\n          }\n        }\n      }\n    }                                               \n\n","sourceOld":"    /*\n     * Make sure IndexWriter cleans up on hitting a disk\n     * full exception in addDocument.\n     */\n    public void testAddDocumentOnDiskFull() throws IOException {\n\n      for(int pass=0;pass<2;pass++) {\n        if (VERBOSE)\n          System.out.println(\"TEST: pass=\" + pass);\n        boolean doAbort = pass == 1;\n        long diskFree = 200;\n        while(true) {\n          if (VERBOSE)\n            System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n          MockDirectoryWrapper dir = newDirectory(random);\n          dir.setMaxSizeInBytes(diskFree);\n          IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));\n          MergeScheduler ms = writer.getConfig().getMergeScheduler();\n          if (ms instanceof ConcurrentMergeScheduler)\n            // This test intentionally produces exceptions\n            // in the threads that CMS launches; we don't\n            // want to pollute test output with these.\n            ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n\n          boolean hitError = false;\n          try {\n            for(int i=0;i<200;i++) {\n              addDoc(writer);\n            }\n            writer.commit();\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: exception on addDoc\");\n              e.printStackTrace(System.out);\n            }\n            hitError = true;\n          }\n\n          if (hitError) {\n            if (doAbort) {\n              writer.rollback();\n            } else {\n              try {\n                writer.close();\n              } catch (IOException e) {\n                if (VERBOSE) {\n                  System.out.println(\"TEST: exception on close\");\n                  e.printStackTrace(System.out);\n                }\n                dir.setMaxSizeInBytes(0);\n                writer.close();\n              }\n            }\n\n            //_TestUtil.syncConcurrentMerges(ms);\n\n            if (dir.listAll().length > 0) {\n              assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n              \n              // Make sure reader can open the index:\n              IndexReader.open(dir, true).close();\n            }\n              \n            dir.close();\n            // Now try again w/ more space:\n\n            diskFree += 500;\n          } else {\n            //_TestUtil.syncConcurrentMerges(writer);\n            writer.close();\n            dir.close();\n            break;\n          }\n        }\n      }\n    }                                               \n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3c67eeef613da82630d157ce32b4eea2cf9e4934","date":1282681667,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testAddDocumentOnDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testAddDocumentOnDiskFull().mjava","sourceNew":"    /*\n     * Make sure IndexWriter cleans up on hitting a disk\n     * full exception in addDocument.\n     * TODO: how to do this on windows with FSDirectory?\n     */\n    public void testAddDocumentOnDiskFull() throws IOException {\n\n      for(int pass=0;pass<2;pass++) {\n        if (VERBOSE)\n          System.out.println(\"TEST: pass=\" + pass);\n        boolean doAbort = pass == 1;\n        long diskFree = 200;\n        while(true) {\n          if (VERBOSE)\n            System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n          MockDirectoryWrapper dir = new MockDirectoryWrapper(new RAMDirectory());\n          dir.setMaxSizeInBytes(diskFree);\n          IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));\n          MergeScheduler ms = writer.getConfig().getMergeScheduler();\n          if (ms instanceof ConcurrentMergeScheduler)\n            // This test intentionally produces exceptions\n            // in the threads that CMS launches; we don't\n            // want to pollute test output with these.\n            ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n\n          boolean hitError = false;\n          try {\n            for(int i=0;i<200;i++) {\n              addDoc(writer);\n            }\n            writer.commit();\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: exception on addDoc\");\n              e.printStackTrace(System.out);\n            }\n            hitError = true;\n          }\n\n          if (hitError) {\n            if (doAbort) {\n              writer.rollback();\n            } else {\n              try {\n                writer.close();\n              } catch (IOException e) {\n                if (VERBOSE) {\n                  System.out.println(\"TEST: exception on close\");\n                  e.printStackTrace(System.out);\n                }\n                dir.setMaxSizeInBytes(0);\n                writer.close();\n              }\n            }\n\n            //_TestUtil.syncConcurrentMerges(ms);\n\n            if (_TestUtil.anyFilesExceptWriteLock(dir)) {\n              assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n              \n              // Make sure reader can open the index:\n              IndexReader.open(dir, true).close();\n            }\n              \n            dir.close();\n            // Now try again w/ more space:\n\n            diskFree += 500;\n          } else {\n            //_TestUtil.syncConcurrentMerges(writer);\n            writer.close();\n            dir.close();\n            break;\n          }\n        }\n      }\n    }                                               \n\n","sourceOld":"    /*\n     * Make sure IndexWriter cleans up on hitting a disk\n     * full exception in addDocument.\n     */\n    public void testAddDocumentOnDiskFull() throws IOException {\n\n      for(int pass=0;pass<2;pass++) {\n        if (VERBOSE)\n          System.out.println(\"TEST: pass=\" + pass);\n        boolean doAbort = pass == 1;\n        long diskFree = 200;\n        while(true) {\n          if (VERBOSE)\n            System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n          MockDirectoryWrapper dir = newDirectory(random);\n          dir.setMaxSizeInBytes(diskFree);\n          IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));\n          MergeScheduler ms = writer.getConfig().getMergeScheduler();\n          if (ms instanceof ConcurrentMergeScheduler)\n            // This test intentionally produces exceptions\n            // in the threads that CMS launches; we don't\n            // want to pollute test output with these.\n            ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n\n          boolean hitError = false;\n          try {\n            for(int i=0;i<200;i++) {\n              addDoc(writer);\n            }\n            writer.commit();\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: exception on addDoc\");\n              e.printStackTrace(System.out);\n            }\n            hitError = true;\n          }\n\n          if (hitError) {\n            if (doAbort) {\n              writer.rollback();\n            } else {\n              try {\n                writer.close();\n              } catch (IOException e) {\n                if (VERBOSE) {\n                  System.out.println(\"TEST: exception on close\");\n                  e.printStackTrace(System.out);\n                }\n                dir.setMaxSizeInBytes(0);\n                writer.close();\n              }\n            }\n\n            //_TestUtil.syncConcurrentMerges(ms);\n\n            if (_TestUtil.anyFilesExceptWriteLock(dir)) {\n              assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n              \n              // Make sure reader can open the index:\n              IndexReader.open(dir, true).close();\n            }\n              \n            dir.close();\n            // Now try again w/ more space:\n\n            diskFree += 500;\n          } else {\n            //_TestUtil.syncConcurrentMerges(writer);\n            writer.close();\n            dir.close();\n            break;\n          }\n        }\n      }\n    }                                               \n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1f653cfcf159baeaafe5d01682a911e95bba4012","date":1284122058,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testAddDocumentOnDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testAddDocumentOnDiskFull().mjava","sourceNew":"    /*\n     * Make sure IndexWriter cleans up on hitting a disk\n     * full exception in addDocument.\n     * TODO: how to do this on windows with FSDirectory?\n     */\n    public void testAddDocumentOnDiskFull() throws IOException {\n\n      for(int pass=0;pass<2;pass++) {\n        if (VERBOSE)\n          System.out.println(\"TEST: pass=\" + pass);\n        boolean doAbort = pass == 1;\n        long diskFree = 200;\n        while(true) {\n          if (VERBOSE)\n            System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n          MockDirectoryWrapper dir = new MockDirectoryWrapper(new RAMDirectory());\n          dir.setMaxSizeInBytes(diskFree);\n          IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n          MergeScheduler ms = writer.getConfig().getMergeScheduler();\n          if (ms instanceof ConcurrentMergeScheduler)\n            // This test intentionally produces exceptions\n            // in the threads that CMS launches; we don't\n            // want to pollute test output with these.\n            ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n\n          boolean hitError = false;\n          try {\n            for(int i=0;i<200;i++) {\n              addDoc(writer);\n            }\n            writer.commit();\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: exception on addDoc\");\n              e.printStackTrace(System.out);\n            }\n            hitError = true;\n          }\n\n          if (hitError) {\n            if (doAbort) {\n              writer.rollback();\n            } else {\n              try {\n                writer.close();\n              } catch (IOException e) {\n                if (VERBOSE) {\n                  System.out.println(\"TEST: exception on close\");\n                  e.printStackTrace(System.out);\n                }\n                dir.setMaxSizeInBytes(0);\n                writer.close();\n              }\n            }\n\n            //_TestUtil.syncConcurrentMerges(ms);\n\n            if (_TestUtil.anyFilesExceptWriteLock(dir)) {\n              assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n              \n              // Make sure reader can open the index:\n              IndexReader.open(dir, true).close();\n            }\n              \n            dir.close();\n            // Now try again w/ more space:\n\n            diskFree += 500;\n          } else {\n            //_TestUtil.syncConcurrentMerges(writer);\n            writer.close();\n            dir.close();\n            break;\n          }\n        }\n      }\n    }                                               \n\n","sourceOld":"    /*\n     * Make sure IndexWriter cleans up on hitting a disk\n     * full exception in addDocument.\n     * TODO: how to do this on windows with FSDirectory?\n     */\n    public void testAddDocumentOnDiskFull() throws IOException {\n\n      for(int pass=0;pass<2;pass++) {\n        if (VERBOSE)\n          System.out.println(\"TEST: pass=\" + pass);\n        boolean doAbort = pass == 1;\n        long diskFree = 200;\n        while(true) {\n          if (VERBOSE)\n            System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n          MockDirectoryWrapper dir = new MockDirectoryWrapper(new RAMDirectory());\n          dir.setMaxSizeInBytes(diskFree);\n          IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));\n          MergeScheduler ms = writer.getConfig().getMergeScheduler();\n          if (ms instanceof ConcurrentMergeScheduler)\n            // This test intentionally produces exceptions\n            // in the threads that CMS launches; we don't\n            // want to pollute test output with these.\n            ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n\n          boolean hitError = false;\n          try {\n            for(int i=0;i<200;i++) {\n              addDoc(writer);\n            }\n            writer.commit();\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: exception on addDoc\");\n              e.printStackTrace(System.out);\n            }\n            hitError = true;\n          }\n\n          if (hitError) {\n            if (doAbort) {\n              writer.rollback();\n            } else {\n              try {\n                writer.close();\n              } catch (IOException e) {\n                if (VERBOSE) {\n                  System.out.println(\"TEST: exception on close\");\n                  e.printStackTrace(System.out);\n                }\n                dir.setMaxSizeInBytes(0);\n                writer.close();\n              }\n            }\n\n            //_TestUtil.syncConcurrentMerges(ms);\n\n            if (_TestUtil.anyFilesExceptWriteLock(dir)) {\n              assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n              \n              // Make sure reader can open the index:\n              IndexReader.open(dir, true).close();\n            }\n              \n            dir.close();\n            // Now try again w/ more space:\n\n            diskFree += 500;\n          } else {\n            //_TestUtil.syncConcurrentMerges(writer);\n            writer.close();\n            dir.close();\n            break;\n          }\n        }\n      }\n    }                                               \n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"84b590669deb3d3a471cec6cb13b104b2ee94418","date":1288889547,"type":4,"author":"Robert Muir","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testAddDocumentOnDiskFull().mjava","sourceNew":null,"sourceOld":"    /*\n     * Make sure IndexWriter cleans up on hitting a disk\n     * full exception in addDocument.\n     * TODO: how to do this on windows with FSDirectory?\n     */\n    public void testAddDocumentOnDiskFull() throws IOException {\n\n      for(int pass=0;pass<2;pass++) {\n        if (VERBOSE)\n          System.out.println(\"TEST: pass=\" + pass);\n        boolean doAbort = pass == 1;\n        long diskFree = 200;\n        while(true) {\n          if (VERBOSE)\n            System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n          MockDirectoryWrapper dir = new MockDirectoryWrapper(new RAMDirectory());\n          dir.setMaxSizeInBytes(diskFree);\n          IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n          MergeScheduler ms = writer.getConfig().getMergeScheduler();\n          if (ms instanceof ConcurrentMergeScheduler)\n            // This test intentionally produces exceptions\n            // in the threads that CMS launches; we don't\n            // want to pollute test output with these.\n            ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n\n          boolean hitError = false;\n          try {\n            for(int i=0;i<200;i++) {\n              addDoc(writer);\n            }\n            writer.commit();\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: exception on addDoc\");\n              e.printStackTrace(System.out);\n            }\n            hitError = true;\n          }\n\n          if (hitError) {\n            if (doAbort) {\n              writer.rollback();\n            } else {\n              try {\n                writer.close();\n              } catch (IOException e) {\n                if (VERBOSE) {\n                  System.out.println(\"TEST: exception on close\");\n                  e.printStackTrace(System.out);\n                }\n                dir.setMaxSizeInBytes(0);\n                writer.close();\n              }\n            }\n\n            //_TestUtil.syncConcurrentMerges(ms);\n\n            if (_TestUtil.anyFilesExceptWriteLock(dir)) {\n              assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n              \n              // Make sure reader can open the index:\n              IndexReader.open(dir, true).close();\n            }\n              \n            dir.close();\n            // Now try again w/ more space:\n\n            diskFree += 500;\n          } else {\n            //_TestUtil.syncConcurrentMerges(writer);\n            writer.close();\n            dir.close();\n            break;\n          }\n        }\n      }\n    }                                               \n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"85a883878c0af761245ab048babc63d099f835f3","date":1289553330,"type":4,"author":"Simon Willnauer","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testAddDocumentOnDiskFull().mjava","sourceNew":null,"sourceOld":"    /*\n     * Make sure IndexWriter cleans up on hitting a disk\n     * full exception in addDocument.\n     * TODO: how to do this on windows with FSDirectory?\n     */\n    public void testAddDocumentOnDiskFull() throws IOException {\n\n      for(int pass=0;pass<2;pass++) {\n        if (VERBOSE)\n          System.out.println(\"TEST: pass=\" + pass);\n        boolean doAbort = pass == 1;\n        long diskFree = 200;\n        while(true) {\n          if (VERBOSE)\n            System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n          MockDirectoryWrapper dir = new MockDirectoryWrapper(new RAMDirectory());\n          dir.setMaxSizeInBytes(diskFree);\n          IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n          MergeScheduler ms = writer.getConfig().getMergeScheduler();\n          if (ms instanceof ConcurrentMergeScheduler)\n            // This test intentionally produces exceptions\n            // in the threads that CMS launches; we don't\n            // want to pollute test output with these.\n            ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n\n          boolean hitError = false;\n          try {\n            for(int i=0;i<200;i++) {\n              addDoc(writer);\n            }\n            writer.commit();\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: exception on addDoc\");\n              e.printStackTrace(System.out);\n            }\n            hitError = true;\n          }\n\n          if (hitError) {\n            if (doAbort) {\n              writer.rollback();\n            } else {\n              try {\n                writer.close();\n              } catch (IOException e) {\n                if (VERBOSE) {\n                  System.out.println(\"TEST: exception on close\");\n                  e.printStackTrace(System.out);\n                }\n                dir.setMaxSizeInBytes(0);\n                writer.close();\n              }\n            }\n\n            //_TestUtil.syncConcurrentMerges(ms);\n\n            if (_TestUtil.anyFilesExceptWriteLock(dir)) {\n              assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n              \n              // Make sure reader can open the index:\n              IndexReader.open(dir, true).close();\n            }\n              \n            dir.close();\n            // Now try again w/ more space:\n\n            diskFree += 500;\n          } else {\n            //_TestUtil.syncConcurrentMerges(writer);\n            writer.close();\n            dir.close();\n            break;\n          }\n        }\n      }\n    }                                               \n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":4,"author":"Michael Busch","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testAddDocumentOnDiskFull().mjava","sourceNew":null,"sourceOld":"    /*\n     * Make sure IndexWriter cleans up on hitting a disk\n     * full exception in addDocument.\n     */\n    public void testAddDocumentOnDiskFull() throws IOException {\n\n      for(int pass=0;pass<2;pass++) {\n        if (VERBOSE)\n          System.out.println(\"TEST: pass=\" + pass);\n        boolean doAbort = pass == 1;\n        long diskFree = 200;\n        while(true) {\n          if (VERBOSE)\n            System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n          MockRAMDirectory dir = new MockRAMDirectory();\n          dir.setMaxSizeInBytes(diskFree);\n          IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n\n          MergeScheduler ms = writer.getConfig().getMergeScheduler();\n          if (ms instanceof ConcurrentMergeScheduler)\n            // This test intentionally produces exceptions\n            // in the threads that CMS launches; we don't\n            // want to pollute test output with these.\n            ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n\n          boolean hitError = false;\n          try {\n            for(int i=0;i<200;i++) {\n              addDoc(writer);\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: exception on addDoc\");\n              e.printStackTrace(System.out);\n            }\n            hitError = true;\n          }\n\n          if (hitError) {\n            if (doAbort) {\n              writer.rollback();\n            } else {\n              try {\n                writer.close();\n              } catch (IOException e) {\n                if (VERBOSE) {\n                  System.out.println(\"TEST: exception on close\");\n                  e.printStackTrace(System.out);\n                }\n                dir.setMaxSizeInBytes(0);\n                writer.close();\n              }\n            }\n\n            _TestUtil.syncConcurrentMerges(ms);\n\n            assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n\n            // Make sure reader can open the index:\n            IndexReader.open(dir, true).close();\n\n            dir.close();\n\n            // Now try again w/ more space:\n            diskFree += 500;\n          } else {\n            _TestUtil.syncConcurrentMerges(writer);\n            dir.close();\n            break;\n          }\n        }\n      }\n    }                                               \n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c":["b21422ff1d1d56499dec481f193b402e5e8def5b"],"85a883878c0af761245ab048babc63d099f835f3":["1f653cfcf159baeaafe5d01682a911e95bba4012","84b590669deb3d3a471cec6cb13b104b2ee94418"],"d572389229127c297dd1fa5ce4758e1cec41e799":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["d572389229127c297dd1fa5ce4758e1cec41e799","84b590669deb3d3a471cec6cb13b104b2ee94418"],"84b590669deb3d3a471cec6cb13b104b2ee94418":["1f653cfcf159baeaafe5d01682a911e95bba4012"],"1f653cfcf159baeaafe5d01682a911e95bba4012":["3c67eeef613da82630d157ce32b4eea2cf9e4934"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a05409176bd65129d67a785ee70e881e238a9aef":["ab9633cb67e3c0aec3c066147a23a957d6e7ad8c"],"3eaa8ca351aa7eefa5bd5bf249e9dd9bb0830c54":["a05409176bd65129d67a785ee70e881e238a9aef"],"3c67eeef613da82630d157ce32b4eea2cf9e4934":["3eaa8ca351aa7eefa5bd5bf249e9dd9bb0830c54"],"b21422ff1d1d56499dec481f193b402e5e8def5b":["d572389229127c297dd1fa5ce4758e1cec41e799"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["84b590669deb3d3a471cec6cb13b104b2ee94418"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c":["a05409176bd65129d67a785ee70e881e238a9aef"],"85a883878c0af761245ab048babc63d099f835f3":[],"d572389229127c297dd1fa5ce4758e1cec41e799":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","b21422ff1d1d56499dec481f193b402e5e8def5b"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":[],"84b590669deb3d3a471cec6cb13b104b2ee94418":["85a883878c0af761245ab048babc63d099f835f3","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"1f653cfcf159baeaafe5d01682a911e95bba4012":["85a883878c0af761245ab048babc63d099f835f3","84b590669deb3d3a471cec6cb13b104b2ee94418"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"a05409176bd65129d67a785ee70e881e238a9aef":["3eaa8ca351aa7eefa5bd5bf249e9dd9bb0830c54"],"3eaa8ca351aa7eefa5bd5bf249e9dd9bb0830c54":["3c67eeef613da82630d157ce32b4eea2cf9e4934"],"3c67eeef613da82630d157ce32b4eea2cf9e4934":["1f653cfcf159baeaafe5d01682a911e95bba4012"],"b21422ff1d1d56499dec481f193b402e5e8def5b":["ab9633cb67e3c0aec3c066147a23a957d6e7ad8c"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["d572389229127c297dd1fa5ce4758e1cec41e799"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["85a883878c0af761245ab048babc63d099f835f3","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}