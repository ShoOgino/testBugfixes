{"path":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","sourceNew":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newDirectory();\n    // TODO: find the resource leak that only occurs sometimes here.\n    startDir.setNoDeleteOpenFile(false);\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newField(\"id\", Integer.toString(i), StringField.TYPE_STORED));\n      d.add(newField(\"content\", \"aaa \" + i, TextField.TYPE_UNSTORED));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir, newIOContext(random)));\n      dir.setPreventDoubleWrite(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(\n                                                                  TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMaxBufferedDeleteTerms(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newField(\"id\", Integer.toString(i), StringField.TYPE_STORED));\n                d.add(newField(\"content\", \"bbb \" + i, TextField.TYPE_UNSTORED));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n          }\n          modifier.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure there are\n        // no unreferenced files.\n        if (success) {\n          _TestUtil.checkIndex(dir);\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = IndexReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n      modifier.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newDirectory();\n    // TODO: find the resource leak that only occurs sometimes here.\n    startDir.setNoDeleteOpenFile(false);\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newField(\"id\", Integer.toString(i), StringField.TYPE_STORED));\n      d.add(newField(\"content\", \"aaa \" + i, TextField.TYPE_UNSTORED));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir, newIOContext(random)));\n      dir.setPreventDoubleWrite(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(\n                                                                  TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMaxBufferedDeleteTerms(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newField(\"id\", Integer.toString(i), StringField.TYPE_STORED));\n                d.add(newField(\"content\", \"bbb \" + i, TextField.TYPE_UNSTORED));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n          }\n          modifier.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure there are\n        // no unreferenced files.\n        if (success) {\n          _TestUtil.checkIndex(dir);\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = IndexReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n      modifier.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","sourceNew":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newDirectory();\n    // TODO: find the resource leak that only occurs sometimes here.\n    startDir.setNoDeleteOpenFile(false);\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newField(\"id\", Integer.toString(i), StringField.TYPE_STORED));\n      d.add(newField(\"content\", \"aaa \" + i, TextField.TYPE_UNSTORED));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), new RAMDirectory(startDir, newIOContext(random())));\n      dir.setPreventDoubleWrite(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(\n                                                                  TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMaxBufferedDeleteTerms(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newField(\"id\", Integer.toString(i), StringField.TYPE_STORED));\n                d.add(newField(\"content\", \"bbb \" + i, TextField.TYPE_UNSTORED));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n          }\n          modifier.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure there are\n        // no unreferenced files.\n        if (success) {\n          _TestUtil.checkIndex(dir);\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = IndexReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n      modifier.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newDirectory();\n    // TODO: find the resource leak that only occurs sometimes here.\n    startDir.setNoDeleteOpenFile(false);\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newField(\"id\", Integer.toString(i), StringField.TYPE_STORED));\n      d.add(newField(\"content\", \"aaa \" + i, TextField.TYPE_UNSTORED));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir, newIOContext(random)));\n      dir.setPreventDoubleWrite(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(\n                                                                  TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMaxBufferedDeleteTerms(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newField(\"id\", Integer.toString(i), StringField.TYPE_STORED));\n                d.add(newField(\"content\", \"bbb \" + i, TextField.TYPE_UNSTORED));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n          }\n          modifier.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure there are\n        // no unreferenced files.\n        if (success) {\n          _TestUtil.checkIndex(dir);\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = IndexReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n      modifier.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","bugFix":null,"bugIntro":["302be0cc5e6a28ebcebcac98aa81a92be2e94370"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f","date":1338430031,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","sourceNew":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newDirectory();\n    // TODO: find the resource leak that only occurs sometimes here.\n    startDir.setNoDeleteOpenFile(false);\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newField(\"id\", Integer.toString(i), StringField.TYPE_STORED));\n      d.add(newField(\"content\", \"aaa \" + i, TextField.TYPE_UNSTORED));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), new RAMDirectory(startDir, newIOContext(random())));\n      dir.setPreventDoubleWrite(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(\n                                                                  TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMaxBufferedDeleteTerms(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newField(\"id\", Integer.toString(i), StringField.TYPE_STORED));\n                d.add(newField(\"content\", \"bbb \" + i, TextField.TYPE_UNSTORED));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n          }\n          modifier.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure there are\n        // no unreferenced files.\n        if (success) {\n          _TestUtil.checkIndex(dir);\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = DirectoryReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n      modifier.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newDirectory();\n    // TODO: find the resource leak that only occurs sometimes here.\n    startDir.setNoDeleteOpenFile(false);\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newField(\"id\", Integer.toString(i), StringField.TYPE_STORED));\n      d.add(newField(\"content\", \"aaa \" + i, TextField.TYPE_UNSTORED));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), new RAMDirectory(startDir, newIOContext(random())));\n      dir.setPreventDoubleWrite(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(\n                                                                  TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMaxBufferedDeleteTerms(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newField(\"id\", Integer.toString(i), StringField.TYPE_STORED));\n                d.add(newField(\"content\", \"bbb \" + i, TextField.TYPE_UNSTORED));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n          }\n          modifier.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure there are\n        // no unreferenced files.\n        if (success) {\n          _TestUtil.checkIndex(dir);\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = IndexReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n      modifier.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"04f07771a2a7dd3a395700665ed839c3dae2def2","date":1339350139,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","sourceNew":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newDirectory();\n    // TODO: find the resource leak that only occurs sometimes here.\n    startDir.setNoDeleteOpenFile(false);\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n      d.add(newTextField(\"content\", \"aaa \" + i, Field.Store.NO));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), new RAMDirectory(startDir, newIOContext(random())));\n      dir.setPreventDoubleWrite(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(\n                                                                  TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMaxBufferedDeleteTerms(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n                d.add(newTextField(\"content\", \"bbb \" + i, Field.Store.NO));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n          }\n          modifier.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure there are\n        // no unreferenced files.\n        if (success) {\n          _TestUtil.checkIndex(dir);\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = DirectoryReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n      modifier.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newDirectory();\n    // TODO: find the resource leak that only occurs sometimes here.\n    startDir.setNoDeleteOpenFile(false);\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newField(\"id\", Integer.toString(i), StringField.TYPE_STORED));\n      d.add(newField(\"content\", \"aaa \" + i, TextField.TYPE_UNSTORED));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), new RAMDirectory(startDir, newIOContext(random())));\n      dir.setPreventDoubleWrite(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(\n                                                                  TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMaxBufferedDeleteTerms(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newField(\"id\", Integer.toString(i), StringField.TYPE_STORED));\n                d.add(newField(\"content\", \"bbb \" + i, TextField.TYPE_UNSTORED));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n          }\n          modifier.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure there are\n        // no unreferenced files.\n        if (success) {\n          _TestUtil.checkIndex(dir);\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = DirectoryReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n      modifier.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","bugFix":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d19974432be9aed28ee7dca73bdf01d139e763a9","date":1342822166,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","sourceNew":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newMockDirectory();\n    // TODO: find the resource leak that only occurs sometimes here.\n    startDir.setNoDeleteOpenFile(false);\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n      d.add(newTextField(\"content\", \"aaa \" + i, Field.Store.NO));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), new RAMDirectory(startDir, newIOContext(random())));\n      dir.setPreventDoubleWrite(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(\n                                                                  TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMaxBufferedDeleteTerms(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n                d.add(newTextField(\"content\", \"bbb \" + i, Field.Store.NO));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n          }\n          modifier.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure there are\n        // no unreferenced files.\n        if (success) {\n          _TestUtil.checkIndex(dir);\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = DirectoryReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n      modifier.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newDirectory();\n    // TODO: find the resource leak that only occurs sometimes here.\n    startDir.setNoDeleteOpenFile(false);\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n      d.add(newTextField(\"content\", \"aaa \" + i, Field.Store.NO));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), new RAMDirectory(startDir, newIOContext(random())));\n      dir.setPreventDoubleWrite(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(\n                                                                  TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMaxBufferedDeleteTerms(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n                d.add(newTextField(\"content\", \"bbb \" + i, Field.Store.NO));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n          }\n          modifier.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure there are\n        // no unreferenced files.\n        if (success) {\n          _TestUtil.checkIndex(dir);\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = DirectoryReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n      modifier.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","bugFix":["1f653cfcf159baeaafe5d01682a911e95bba4012"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4b51f65902cc2d20ddeb7a5b949aaddf990f31a7","date":1343059585,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","sourceNew":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newMockDirectory();\n    // TODO: find the resource leak that only occurs sometimes here.\n    startDir.setNoDeleteOpenFile(false);\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n      d.add(newTextField(\"content\", \"aaa \" + i, Field.Store.NO));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), new RAMDirectory(startDir, newIOContext(random())));\n      dir.setPreventDoubleWrite(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(\n                                                                  TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMaxBufferedDeleteTerms(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n                d.add(newTextField(\"content\", \"bbb \" + i, Field.Store.NO));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n          }\n          modifier.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure there are\n        // no unreferenced files.\n        if (success) {\n          _TestUtil.checkIndex(dir);\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = DirectoryReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n      modifier.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newDirectory();\n    // TODO: find the resource leak that only occurs sometimes here.\n    startDir.setNoDeleteOpenFile(false);\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n      d.add(newTextField(\"content\", \"aaa \" + i, Field.Store.NO));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), new RAMDirectory(startDir, newIOContext(random())));\n      dir.setPreventDoubleWrite(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(\n                                                                  TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMaxBufferedDeleteTerms(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n                d.add(newTextField(\"content\", \"bbb \" + i, Field.Store.NO));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n          }\n          modifier.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure there are\n        // no unreferenced files.\n        if (success) {\n          _TestUtil.checkIndex(dir);\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = DirectoryReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n      modifier.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"aba371508186796cc6151d8223a5b4e16d02e26e","date":1343474871,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","sourceNew":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newMockDirectory();\n    // TODO: find the resource leak that only occurs sometimes here.\n    startDir.setNoDeleteOpenFile(false);\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n      d.add(newTextField(\"content\", \"aaa \" + i, Field.Store.NO));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), new RAMDirectory(startDir, newIOContext(random())));\n      dir.setPreventDoubleWrite(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(\n                                                                  TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMaxBufferedDeleteTerms(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n                d.add(newTextField(\"content\", \"bbb \" + i, Field.Store.NO));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n          }\n          modifier.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure there are\n        // no unreferenced files.\n        if (success) {\n          _TestUtil.checkIndex(dir);\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = DirectoryReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n      modifier.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newDirectory();\n    // TODO: find the resource leak that only occurs sometimes here.\n    startDir.setNoDeleteOpenFile(false);\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n      d.add(newTextField(\"content\", \"aaa \" + i, Field.Store.NO));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), new RAMDirectory(startDir, newIOContext(random())));\n      dir.setPreventDoubleWrite(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(\n                                                                  TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMaxBufferedDeleteTerms(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n                d.add(newTextField(\"content\", \"bbb \" + i, Field.Store.NO));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n          }\n          modifier.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure there are\n        // no unreferenced files.\n        if (success) {\n          _TestUtil.checkIndex(dir);\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = DirectoryReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n      modifier.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"06054bbf4f2aaa2f864ecabac4b0e1db6f3b07eb","date":1358785243,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","sourceNew":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newMockDirectory();\n    // TODO: find the resource leak that only occurs sometimes here.\n    startDir.setNoDeleteOpenFile(false);\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n      d.add(newTextField(\"content\", \"aaa \" + i, Field.Store.NO));\n      d.add(new LongDocValuesField(\"dv\", i));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), new RAMDirectory(startDir, newIOContext(random())));\n      dir.setPreventDoubleWrite(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(\n                                                                  TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMaxBufferedDeleteTerms(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n                d.add(newTextField(\"content\", \"bbb \" + i, Field.Store.NO));\n                d.add(new LongDocValuesField(\"dv\", i));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n          }\n          modifier.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure there are\n        // no unreferenced files.\n        if (success) {\n          _TestUtil.checkIndex(dir);\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = DirectoryReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n      modifier.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newMockDirectory();\n    // TODO: find the resource leak that only occurs sometimes here.\n    startDir.setNoDeleteOpenFile(false);\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n      d.add(newTextField(\"content\", \"aaa \" + i, Field.Store.NO));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), new RAMDirectory(startDir, newIOContext(random())));\n      dir.setPreventDoubleWrite(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(\n                                                                  TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMaxBufferedDeleteTerms(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n                d.add(newTextField(\"content\", \"bbb \" + i, Field.Store.NO));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n          }\n          modifier.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure there are\n        // no unreferenced files.\n        if (success) {\n          _TestUtil.checkIndex(dir);\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = DirectoryReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n      modifier.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"423d89a2b3cc419b647c07c2b3fdbc54311d07f9","date":1358836612,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","sourceNew":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newMockDirectory();\n    // TODO: find the resource leak that only occurs sometimes here.\n    startDir.setNoDeleteOpenFile(false);\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n      d.add(newTextField(\"content\", \"aaa \" + i, Field.Store.NO));\n      d.add(new NumericDocValuesField(\"dv\", i));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), new RAMDirectory(startDir, newIOContext(random())));\n      dir.setPreventDoubleWrite(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(\n                                                                  TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMaxBufferedDeleteTerms(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n                d.add(newTextField(\"content\", \"bbb \" + i, Field.Store.NO));\n                d.add(new NumericDocValuesField(\"dv\", i));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n          }\n          modifier.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure there are\n        // no unreferenced files.\n        if (success) {\n          _TestUtil.checkIndex(dir);\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = DirectoryReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n      modifier.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newMockDirectory();\n    // TODO: find the resource leak that only occurs sometimes here.\n    startDir.setNoDeleteOpenFile(false);\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n      d.add(newTextField(\"content\", \"aaa \" + i, Field.Store.NO));\n      d.add(new LongDocValuesField(\"dv\", i));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), new RAMDirectory(startDir, newIOContext(random())));\n      dir.setPreventDoubleWrite(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(\n                                                                  TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMaxBufferedDeleteTerms(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n                d.add(newTextField(\"content\", \"bbb \" + i, Field.Store.NO));\n                d.add(new LongDocValuesField(\"dv\", i));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n          }\n          modifier.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure there are\n        // no unreferenced files.\n        if (success) {\n          _TestUtil.checkIndex(dir);\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = DirectoryReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n      modifier.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d4d69c535930b5cce125cff868d40f6373dc27d4","date":1360270101,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","sourceNew":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newMockDirectory();\n    // TODO: find the resource leak that only occurs sometimes here.\n    startDir.setNoDeleteOpenFile(false);\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n      d.add(newTextField(\"content\", \"aaa \" + i, Field.Store.NO));\n      d.add(new NumericDocValuesField(\"dv\", i));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), new RAMDirectory(startDir, newIOContext(random())));\n      dir.setPreventDoubleWrite(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(\n                                                                  TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMaxBufferedDeleteTerms(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n                d.add(newTextField(\"content\", \"bbb \" + i, Field.Store.NO));\n                d.add(new NumericDocValuesField(\"dv\", i));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n          }\n          modifier.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure there are\n        // no unreferenced files.\n        if (success) {\n          _TestUtil.checkIndex(dir);\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = DirectoryReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n      modifier.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newMockDirectory();\n    // TODO: find the resource leak that only occurs sometimes here.\n    startDir.setNoDeleteOpenFile(false);\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n      d.add(newTextField(\"content\", \"aaa \" + i, Field.Store.NO));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), new RAMDirectory(startDir, newIOContext(random())));\n      dir.setPreventDoubleWrite(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(\n                                                                  TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMaxBufferedDeleteTerms(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n                d.add(newTextField(\"content\", \"bbb \" + i, Field.Store.NO));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n          }\n          modifier.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure there are\n        // no unreferenced files.\n        if (success) {\n          _TestUtil.checkIndex(dir);\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = DirectoryReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n      modifier.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fc4053f65ade14b2ce1979911bc398299cc9c9ef","date":1365632447,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","sourceNew":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newMockDirectory();\n    // TODO: find the resource leak that only occurs sometimes here.\n    startDir.setNoDeleteOpenFile(false);\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n      d.add(newTextField(\"content\", \"aaa \" + i, Field.Store.NO));\n      d.add(new NumericDocValuesField(\"dv\", i));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), new RAMDirectory(startDir, newIOContext(random())));\n      dir.setPreventDoubleWrite(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(\n                                                                  TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMaxBufferedDeleteTerms(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n          dir.setRandomIOExceptionRateOnOpen(random().nextDouble()*0.01);\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n          dir.setRandomIOExceptionRateOnOpen(0.0);\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n                d.add(newTextField(\"content\", \"bbb \" + i, Field.Store.NO));\n                d.add(new NumericDocValuesField(\"dv\", i));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n          }\n          modifier.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure there are\n        // no unreferenced files.\n        if (success) {\n          _TestUtil.checkIndex(dir);\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = DirectoryReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n      modifier.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newMockDirectory();\n    // TODO: find the resource leak that only occurs sometimes here.\n    startDir.setNoDeleteOpenFile(false);\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n      d.add(newTextField(\"content\", \"aaa \" + i, Field.Store.NO));\n      d.add(new NumericDocValuesField(\"dv\", i));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), new RAMDirectory(startDir, newIOContext(random())));\n      dir.setPreventDoubleWrite(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(\n                                                                  TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMaxBufferedDeleteTerms(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n                d.add(newTextField(\"content\", \"bbb \" + i, Field.Store.NO));\n                d.add(new NumericDocValuesField(\"dv\", i));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n          }\n          modifier.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure there are\n        // no unreferenced files.\n        if (success) {\n          _TestUtil.checkIndex(dir);\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = DirectoryReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n      modifier.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6613659748fe4411a7dcf85266e55db1f95f7315","date":1392773913,"type":3,"author":"Benson Margulies","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","sourceNew":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newMockDirectory();\n    // TODO: find the resource leak that only occurs sometimes here.\n    startDir.setNoDeleteOpenFile(false);\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n      d.add(newTextField(\"content\", \"aaa \" + i, Field.Store.NO));\n      d.add(new NumericDocValuesField(\"dv\", i));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), new RAMDirectory(startDir, newIOContext(random())));\n      dir.setPreventDoubleWrite(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(\n                                                                  TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMaxBufferedDeleteTerms(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n          dir.setRandomIOExceptionRateOnOpen(random().nextDouble()*0.01);\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n          dir.setRandomIOExceptionRateOnOpen(0.0);\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n                d.add(newTextField(\"content\", \"bbb \" + i, Field.Store.NO));\n                d.add(new NumericDocValuesField(\"dv\", i));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n          }\n          modifier.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure there are\n        // no unreferenced files.\n        if (success) {\n          TestUtil.checkIndex(dir);\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = DirectoryReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n      modifier.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newMockDirectory();\n    // TODO: find the resource leak that only occurs sometimes here.\n    startDir.setNoDeleteOpenFile(false);\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n      d.add(newTextField(\"content\", \"aaa \" + i, Field.Store.NO));\n      d.add(new NumericDocValuesField(\"dv\", i));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), new RAMDirectory(startDir, newIOContext(random())));\n      dir.setPreventDoubleWrite(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(\n                                                                  TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMaxBufferedDeleteTerms(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n          dir.setRandomIOExceptionRateOnOpen(random().nextDouble()*0.01);\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n          dir.setRandomIOExceptionRateOnOpen(0.0);\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n                d.add(newTextField(\"content\", \"bbb \" + i, Field.Store.NO));\n                d.add(new NumericDocValuesField(\"dv\", i));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n          }\n          modifier.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure there are\n        // no unreferenced files.\n        if (success) {\n          _TestUtil.checkIndex(dir);\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = DirectoryReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n      modifier.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3b1518fdad7b84b251e9210a29419b2fd0fc7e6a","date":1395610047,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","sourceNew":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newMockDirectory();\n    // TODO: find the resource leak that only occurs sometimes here.\n    startDir.setNoDeleteOpenFile(false);\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n      d.add(newTextField(\"content\", \"aaa \" + i, Field.Store.NO));\n      d.add(new NumericDocValuesField(\"dv\", i));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), new RAMDirectory(startDir, newIOContext(random())));\n      dir.setPreventDoubleWrite(false);\n      dir.setAllowRandomFileNotFoundException(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(\n                                                                  TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMaxBufferedDeleteTerms(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n          dir.setRandomIOExceptionRateOnOpen(random().nextDouble()*0.01);\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n          dir.setRandomIOExceptionRateOnOpen(0.0);\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n                d.add(newTextField(\"content\", \"bbb \" + i, Field.Store.NO));\n                d.add(new NumericDocValuesField(\"dv\", i));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n          }\n          modifier.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure there are\n        // no unreferenced files.\n        if (success) {\n          TestUtil.checkIndex(dir);\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = DirectoryReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n      modifier.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newMockDirectory();\n    // TODO: find the resource leak that only occurs sometimes here.\n    startDir.setNoDeleteOpenFile(false);\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n      d.add(newTextField(\"content\", \"aaa \" + i, Field.Store.NO));\n      d.add(new NumericDocValuesField(\"dv\", i));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), new RAMDirectory(startDir, newIOContext(random())));\n      dir.setPreventDoubleWrite(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(\n                                                                  TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMaxBufferedDeleteTerms(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n          dir.setRandomIOExceptionRateOnOpen(random().nextDouble()*0.01);\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n          dir.setRandomIOExceptionRateOnOpen(0.0);\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n                d.add(newTextField(\"content\", \"bbb \" + i, Field.Store.NO));\n                d.add(new NumericDocValuesField(\"dv\", i));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n          }\n          modifier.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure there are\n        // no unreferenced files.\n        if (success) {\n          TestUtil.checkIndex(dir);\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = DirectoryReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n      modifier.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","sourceNew":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newMockDirectory();\n    // TODO: find the resource leak that only occurs sometimes here.\n    startDir.setNoDeleteOpenFile(false);\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n      d.add(newTextField(\"content\", \"aaa \" + i, Field.Store.NO));\n      d.add(new NumericDocValuesField(\"dv\", i));\n      writer.addDocument(d);\n    }\n    writer.shutdown();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), new RAMDirectory(startDir, newIOContext(random())));\n      dir.setPreventDoubleWrite(false);\n      dir.setAllowRandomFileNotFoundException(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(\n                                                                  TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMaxBufferedDeleteTerms(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n          dir.setRandomIOExceptionRateOnOpen(random().nextDouble()*0.01);\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n          dir.setRandomIOExceptionRateOnOpen(0.0);\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n                d.add(newTextField(\"content\", \"bbb \" + i, Field.Store.NO));\n                d.add(new NumericDocValuesField(\"dv\", i));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n            modifier.shutdown();\n          }\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure there are\n        // no unreferenced files.\n        if (success) {\n          TestUtil.checkIndex(dir);\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = DirectoryReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newMockDirectory();\n    // TODO: find the resource leak that only occurs sometimes here.\n    startDir.setNoDeleteOpenFile(false);\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n      d.add(newTextField(\"content\", \"aaa \" + i, Field.Store.NO));\n      d.add(new NumericDocValuesField(\"dv\", i));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), new RAMDirectory(startDir, newIOContext(random())));\n      dir.setPreventDoubleWrite(false);\n      dir.setAllowRandomFileNotFoundException(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(\n                                                                  TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMaxBufferedDeleteTerms(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n          dir.setRandomIOExceptionRateOnOpen(random().nextDouble()*0.01);\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n          dir.setRandomIOExceptionRateOnOpen(0.0);\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n                d.add(newTextField(\"content\", \"bbb \" + i, Field.Store.NO));\n                d.add(new NumericDocValuesField(\"dv\", i));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n          }\n          modifier.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure there are\n        // no unreferenced files.\n        if (success) {\n          TestUtil.checkIndex(dir);\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = DirectoryReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n      modifier.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","sourceNew":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newMockDirectory();\n    // TODO: find the resource leak that only occurs sometimes here.\n    startDir.setNoDeleteOpenFile(false);\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n      d.add(newTextField(\"content\", \"aaa \" + i, Field.Store.NO));\n      d.add(new NumericDocValuesField(\"dv\", i));\n      writer.addDocument(d);\n    }\n    writer.shutdown();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), new RAMDirectory(startDir, newIOContext(random())));\n      dir.setPreventDoubleWrite(false);\n      dir.setAllowRandomFileNotFoundException(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMaxBufferedDeleteTerms(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n          dir.setRandomIOExceptionRateOnOpen(random().nextDouble()*0.01);\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n          dir.setRandomIOExceptionRateOnOpen(0.0);\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n                d.add(newTextField(\"content\", \"bbb \" + i, Field.Store.NO));\n                d.add(new NumericDocValuesField(\"dv\", i));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n            modifier.shutdown();\n          }\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure there are\n        // no unreferenced files.\n        if (success) {\n          TestUtil.checkIndex(dir);\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = DirectoryReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newMockDirectory();\n    // TODO: find the resource leak that only occurs sometimes here.\n    startDir.setNoDeleteOpenFile(false);\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n      d.add(newTextField(\"content\", \"aaa \" + i, Field.Store.NO));\n      d.add(new NumericDocValuesField(\"dv\", i));\n      writer.addDocument(d);\n    }\n    writer.shutdown();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), new RAMDirectory(startDir, newIOContext(random())));\n      dir.setPreventDoubleWrite(false);\n      dir.setAllowRandomFileNotFoundException(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(\n                                                                  TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMaxBufferedDeleteTerms(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n          dir.setRandomIOExceptionRateOnOpen(random().nextDouble()*0.01);\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n          dir.setRandomIOExceptionRateOnOpen(0.0);\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n                d.add(newTextField(\"content\", \"bbb \" + i, Field.Store.NO));\n                d.add(new NumericDocValuesField(\"dv\", i));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n            modifier.shutdown();\n          }\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure there are\n        // no unreferenced files.\n        if (success) {\n          TestUtil.checkIndex(dir);\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = DirectoryReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","sourceNew":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newMockDirectory();\n    // TODO: find the resource leak that only occurs sometimes here.\n    startDir.setNoDeleteOpenFile(false);\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n      d.add(newTextField(\"content\", \"aaa \" + i, Field.Store.NO));\n      d.add(new NumericDocValuesField(\"dv\", i));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), new RAMDirectory(startDir, newIOContext(random())));\n      dir.setPreventDoubleWrite(false);\n      dir.setAllowRandomFileNotFoundException(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMaxBufferedDeleteTerms(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n          dir.setRandomIOExceptionRateOnOpen(random().nextDouble()*0.01);\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n          dir.setRandomIOExceptionRateOnOpen(0.0);\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n                d.add(newTextField(\"content\", \"bbb \" + i, Field.Store.NO));\n                d.add(new NumericDocValuesField(\"dv\", i));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n            modifier.close();\n          }\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure there are\n        // no unreferenced files.\n        if (success) {\n          TestUtil.checkIndex(dir);\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = DirectoryReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newMockDirectory();\n    // TODO: find the resource leak that only occurs sometimes here.\n    startDir.setNoDeleteOpenFile(false);\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n      d.add(newTextField(\"content\", \"aaa \" + i, Field.Store.NO));\n      d.add(new NumericDocValuesField(\"dv\", i));\n      writer.addDocument(d);\n    }\n    writer.shutdown();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), new RAMDirectory(startDir, newIOContext(random())));\n      dir.setPreventDoubleWrite(false);\n      dir.setAllowRandomFileNotFoundException(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMaxBufferedDeleteTerms(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n          dir.setRandomIOExceptionRateOnOpen(random().nextDouble()*0.01);\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n          dir.setRandomIOExceptionRateOnOpen(0.0);\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n                d.add(newTextField(\"content\", \"bbb \" + i, Field.Store.NO));\n                d.add(new NumericDocValuesField(\"dv\", i));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n            modifier.shutdown();\n          }\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure there are\n        // no unreferenced files.\n        if (success) {\n          TestUtil.checkIndex(dir);\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = DirectoryReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"98d2deb8c96c79ebef084a1f8e5a1a6c08608f13","date":1409346855,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","sourceNew":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newMockDirectory();\n    // TODO: find the resource leak that only occurs sometimes here.\n    startDir.setNoDeleteOpenFile(false);\n    // test uses IW unref'ed helper which is unaware of retries\n    startDir.setEnableVirusScanner(false);\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n      d.add(newTextField(\"content\", \"aaa \" + i, Field.Store.NO));\n      d.add(new NumericDocValuesField(\"dv\", i));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), new RAMDirectory(startDir, newIOContext(random())));\n      dir.setPreventDoubleWrite(false);\n      dir.setAllowRandomFileNotFoundException(false);\n      // test uses IW unref'ed helper which is unaware of retries\n      dir.setEnableVirusScanner(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMaxBufferedDeleteTerms(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n          dir.setRandomIOExceptionRateOnOpen(random().nextDouble()*0.01);\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n          dir.setRandomIOExceptionRateOnOpen(0.0);\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n                d.add(newTextField(\"content\", \"bbb \" + i, Field.Store.NO));\n                d.add(new NumericDocValuesField(\"dv\", i));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n            modifier.close();\n          }\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure there are\n        // no unreferenced files.\n        if (success) {\n          TestUtil.checkIndex(dir);\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = DirectoryReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newMockDirectory();\n    // TODO: find the resource leak that only occurs sometimes here.\n    startDir.setNoDeleteOpenFile(false);\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n      d.add(newTextField(\"content\", \"aaa \" + i, Field.Store.NO));\n      d.add(new NumericDocValuesField(\"dv\", i));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), new RAMDirectory(startDir, newIOContext(random())));\n      dir.setPreventDoubleWrite(false);\n      dir.setAllowRandomFileNotFoundException(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMaxBufferedDeleteTerms(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n          dir.setRandomIOExceptionRateOnOpen(random().nextDouble()*0.01);\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n          dir.setRandomIOExceptionRateOnOpen(0.0);\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n                d.add(newTextField(\"content\", \"bbb \" + i, Field.Store.NO));\n                d.add(new NumericDocValuesField(\"dv\", i));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n            modifier.close();\n          }\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure there are\n        // no unreferenced files.\n        if (success) {\n          TestUtil.checkIndex(dir);\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = DirectoryReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9299079153fd7895bf3cf6835cf7019af2ba89b3","date":1417813477,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","sourceNew":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newMockDirectory();\n    // TODO: find the resource leak that only occurs sometimes here.\n    startDir.setNoDeleteOpenFile(false);\n    // test uses IW unref'ed helper which is unaware of retries\n    startDir.setEnableVirusScanner(false);\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n      d.add(newTextField(\"content\", \"aaa \" + i, Field.Store.NO));\n      d.add(new NumericDocValuesField(\"dv\", i));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), new RAMDirectory(startDir, newIOContext(random())));\n      dir.setPreventDoubleWrite(false);\n      dir.setAllowRandomFileNotFoundException(false);\n      // test uses IW unref'ed helper which is unaware of retries\n      dir.setEnableVirusScanner(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMaxBufferedDeleteTerms(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n          dir.setRandomIOExceptionRateOnOpen(random().nextDouble()*0.01);\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n          dir.setRandomIOExceptionRateOnOpen(0.0);\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n                d.add(newTextField(\"content\", \"bbb \" + i, Field.Store.NO));\n                d.add(new NumericDocValuesField(\"dv\", i));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n            modifier.close();\n          }\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure index is OK:\n        if (success) {\n          TestUtil.checkIndex(dir);\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = DirectoryReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newMockDirectory();\n    // TODO: find the resource leak that only occurs sometimes here.\n    startDir.setNoDeleteOpenFile(false);\n    // test uses IW unref'ed helper which is unaware of retries\n    startDir.setEnableVirusScanner(false);\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n      d.add(newTextField(\"content\", \"aaa \" + i, Field.Store.NO));\n      d.add(new NumericDocValuesField(\"dv\", i));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), new RAMDirectory(startDir, newIOContext(random())));\n      dir.setPreventDoubleWrite(false);\n      dir.setAllowRandomFileNotFoundException(false);\n      // test uses IW unref'ed helper which is unaware of retries\n      dir.setEnableVirusScanner(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMaxBufferedDeleteTerms(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n          dir.setRandomIOExceptionRateOnOpen(random().nextDouble()*0.01);\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n          dir.setRandomIOExceptionRateOnOpen(0.0);\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n                d.add(newTextField(\"content\", \"bbb \" + i, Field.Store.NO));\n                d.add(new NumericDocValuesField(\"dv\", i));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n            modifier.close();\n          }\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure there are\n        // no unreferenced files.\n        if (success) {\n          TestUtil.checkIndex(dir);\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = DirectoryReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"302be0cc5e6a28ebcebcac98aa81a92be2e94370","date":1423848654,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","sourceNew":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newMockDirectory();\n    // TODO: find the resource leak that only occurs sometimes here.\n    startDir.setNoDeleteOpenFile(false);\n    // test uses IW unref'ed helper which is unaware of retries\n    startDir.setEnableVirusScanner(false);\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n      d.add(newTextField(\"content\", \"aaa \" + i, Field.Store.NO));\n      d.add(new NumericDocValuesField(\"dv\", i));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), TestUtil.ramCopyOf(startDir));\n      dir.setPreventDoubleWrite(false);\n      dir.setAllowRandomFileNotFoundException(false);\n      // test uses IW unref'ed helper which is unaware of retries\n      dir.setEnableVirusScanner(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMaxBufferedDeleteTerms(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n          dir.setRandomIOExceptionRateOnOpen(random().nextDouble()*0.01);\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n          dir.setRandomIOExceptionRateOnOpen(0.0);\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n                d.add(newTextField(\"content\", \"bbb \" + i, Field.Store.NO));\n                d.add(new NumericDocValuesField(\"dv\", i));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n            modifier.close();\n          }\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure index is OK:\n        if (success) {\n          TestUtil.checkIndex(dir);\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = DirectoryReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newMockDirectory();\n    // TODO: find the resource leak that only occurs sometimes here.\n    startDir.setNoDeleteOpenFile(false);\n    // test uses IW unref'ed helper which is unaware of retries\n    startDir.setEnableVirusScanner(false);\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n      d.add(newTextField(\"content\", \"aaa \" + i, Field.Store.NO));\n      d.add(new NumericDocValuesField(\"dv\", i));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), new RAMDirectory(startDir, newIOContext(random())));\n      dir.setPreventDoubleWrite(false);\n      dir.setAllowRandomFileNotFoundException(false);\n      // test uses IW unref'ed helper which is unaware of retries\n      dir.setEnableVirusScanner(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMaxBufferedDeleteTerms(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n          dir.setRandomIOExceptionRateOnOpen(random().nextDouble()*0.01);\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n          dir.setRandomIOExceptionRateOnOpen(0.0);\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n                d.add(newTextField(\"content\", \"bbb \" + i, Field.Store.NO));\n                d.add(new NumericDocValuesField(\"dv\", i));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n            modifier.close();\n          }\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure index is OK:\n        if (success) {\n          TestUtil.checkIndex(dir);\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = DirectoryReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","bugFix":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc","date":1424799790,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","sourceNew":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newMockDirectory();\n    // TODO: find the resource leak that only occurs sometimes here.\n    startDir.setNoDeleteOpenFile(false);\n    // test uses IW unref'ed helper which is unaware of retries\n    startDir.setEnableVirusScanner(false);\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n      d.add(newTextField(\"content\", \"aaa \" + i, Field.Store.NO));\n      d.add(new NumericDocValuesField(\"dv\", i));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), TestUtil.ramCopyOf(startDir));\n      dir.setPreventDoubleWrite(false);\n      dir.setAllowRandomFileNotFoundException(false);\n      // test uses IW unref'ed helper which is unaware of retries\n      dir.setEnableVirusScanner(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMaxBufferedDeleteTerms(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n          dir.setRandomIOExceptionRateOnOpen(random().nextDouble()*0.01);\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n          dir.setRandomIOExceptionRateOnOpen(0.0);\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n                d.add(newTextField(\"content\", \"bbb \" + i, Field.Store.NO));\n                d.add(new NumericDocValuesField(\"dv\", i));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n            modifier.close();\n          }\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure index is OK:\n        if (success) {\n          TestUtil.checkIndex(dir);\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = DirectoryReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newMockDirectory();\n    // TODO: find the resource leak that only occurs sometimes here.\n    startDir.setNoDeleteOpenFile(false);\n    // test uses IW unref'ed helper which is unaware of retries\n    startDir.setEnableVirusScanner(false);\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n      d.add(newTextField(\"content\", \"aaa \" + i, Field.Store.NO));\n      d.add(new NumericDocValuesField(\"dv\", i));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), TestUtil.ramCopyOf(startDir));\n      dir.setPreventDoubleWrite(false);\n      dir.setAllowRandomFileNotFoundException(false);\n      // test uses IW unref'ed helper which is unaware of retries\n      dir.setEnableVirusScanner(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMaxBufferedDeleteTerms(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n          dir.setRandomIOExceptionRateOnOpen(random().nextDouble()*0.01);\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n          dir.setRandomIOExceptionRateOnOpen(0.0);\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n                d.add(newTextField(\"content\", \"bbb \" + i, Field.Store.NO));\n                d.add(new NumericDocValuesField(\"dv\", i));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n            modifier.close();\n          }\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure index is OK:\n        if (success) {\n          TestUtil.checkIndex(dir);\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = DirectoryReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d9e22bdf0692bfa61e342b04a6ac7078670c1e16","date":1436866730,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","sourceNew":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newMockDirectory();\n    // TODO: find the resource leak that only occurs sometimes here.\n    startDir.setNoDeleteOpenFile(false);\n    // test uses IW unref'ed helper which is unaware of retries\n    startDir.setEnableVirusScanner(false);\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n      d.add(newTextField(\"content\", \"aaa \" + i, Field.Store.NO));\n      d.add(new NumericDocValuesField(\"dv\", i));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), TestUtil.ramCopyOf(startDir));\n      dir.setPreventDoubleWrite(false);\n      dir.setAllowRandomFileNotFoundException(false);\n      // test uses IW unref'ed helper which is unaware of retries\n      dir.setEnableVirusScanner(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMaxBufferedDeleteTerms(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n          dir.setRandomIOExceptionRateOnOpen(random().nextDouble()*0.01);\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n          dir.setRandomIOExceptionRateOnOpen(0.0);\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n                d.add(newTextField(\"content\", \"bbb \" + i, Field.Store.NO));\n                d.add(new NumericDocValuesField(\"dv\", i));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n            try {\n              modifier.close();\n            } catch (IllegalStateException ise) {\n              // ok\n              throw (IOException) ise.getCause();\n            }\n          }\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure index is OK:\n        if (success) {\n          TestUtil.checkIndex(dir);\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = DirectoryReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newMockDirectory();\n    // TODO: find the resource leak that only occurs sometimes here.\n    startDir.setNoDeleteOpenFile(false);\n    // test uses IW unref'ed helper which is unaware of retries\n    startDir.setEnableVirusScanner(false);\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n      d.add(newTextField(\"content\", \"aaa \" + i, Field.Store.NO));\n      d.add(new NumericDocValuesField(\"dv\", i));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), TestUtil.ramCopyOf(startDir));\n      dir.setPreventDoubleWrite(false);\n      dir.setAllowRandomFileNotFoundException(false);\n      // test uses IW unref'ed helper which is unaware of retries\n      dir.setEnableVirusScanner(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMaxBufferedDeleteTerms(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n          dir.setRandomIOExceptionRateOnOpen(random().nextDouble()*0.01);\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n          dir.setRandomIOExceptionRateOnOpen(0.0);\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n                d.add(newTextField(\"content\", \"bbb \" + i, Field.Store.NO));\n                d.add(new NumericDocValuesField(\"dv\", i));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n            modifier.close();\n          }\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure index is OK:\n        if (success) {\n          TestUtil.checkIndex(dir);\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = DirectoryReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6bfe104fc023fadc9e709f8d17403d2cc61133fe","date":1454446396,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","sourceNew":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newMockDirectory();\n\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n      d.add(newTextField(\"content\", \"aaa \" + i, Field.Store.NO));\n      d.add(new NumericDocValuesField(\"dv\", i));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), TestUtil.ramCopyOf(startDir));\n      dir.setPreventDoubleWrite(false);\n      dir.setAllowRandomFileNotFoundException(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMaxBufferedDeleteTerms(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n          dir.setRandomIOExceptionRateOnOpen(random().nextDouble()*0.01);\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n          dir.setRandomIOExceptionRateOnOpen(0.0);\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n                d.add(newTextField(\"content\", \"bbb \" + i, Field.Store.NO));\n                d.add(new NumericDocValuesField(\"dv\", i));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n            try {\n              modifier.close();\n            } catch (IllegalStateException ise) {\n              // ok\n              throw (IOException) ise.getCause();\n            }\n          }\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure index is OK:\n        if (success) {\n          TestUtil.checkIndex(dir);\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = DirectoryReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newMockDirectory();\n    // TODO: find the resource leak that only occurs sometimes here.\n    startDir.setNoDeleteOpenFile(false);\n    // test uses IW unref'ed helper which is unaware of retries\n    startDir.setEnableVirusScanner(false);\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n      d.add(newTextField(\"content\", \"aaa \" + i, Field.Store.NO));\n      d.add(new NumericDocValuesField(\"dv\", i));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), TestUtil.ramCopyOf(startDir));\n      dir.setPreventDoubleWrite(false);\n      dir.setAllowRandomFileNotFoundException(false);\n      // test uses IW unref'ed helper which is unaware of retries\n      dir.setEnableVirusScanner(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMaxBufferedDeleteTerms(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n          dir.setRandomIOExceptionRateOnOpen(random().nextDouble()*0.01);\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n          dir.setRandomIOExceptionRateOnOpen(0.0);\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n                d.add(newTextField(\"content\", \"bbb \" + i, Field.Store.NO));\n                d.add(new NumericDocValuesField(\"dv\", i));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n            try {\n              modifier.close();\n            } catch (IllegalStateException ise) {\n              // ok\n              throw (IOException) ise.getCause();\n            }\n          }\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure index is OK:\n        if (success) {\n          TestUtil.checkIndex(dir);\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = DirectoryReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b470f36a9372c97283360b1304eacbde22df6c0d","date":1454765175,"type":3,"author":"Mike McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","sourceNew":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newMockDirectory();\n\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n      d.add(newTextField(\"content\", \"aaa \" + i, Field.Store.NO));\n      d.add(new NumericDocValuesField(\"dv\", i));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), TestUtil.ramCopyOf(startDir));\n      dir.setPreventDoubleWrite(false);\n      dir.setAllowRandomFileNotFoundException(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMaxBufferedDeleteTerms(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n          dir.setRandomIOExceptionRateOnOpen(random().nextDouble()*0.01);\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n          dir.setRandomIOExceptionRateOnOpen(0.0);\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n                d.add(newTextField(\"content\", \"bbb \" + i, Field.Store.NO));\n                d.add(new NumericDocValuesField(\"dv\", i));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n            try {\n              modifier.close();\n            } catch (IllegalStateException ise) {\n              // ok\n              throw (IOException) ise.getCause();\n            }\n          }\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure index is OK:\n        if (success) {\n          TestUtil.checkIndex(dir);\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = DirectoryReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newMockDirectory();\n    // TODO: find the resource leak that only occurs sometimes here.\n    startDir.setNoDeleteOpenFile(false);\n    // test uses IW unref'ed helper which is unaware of retries\n    startDir.setEnableVirusScanner(false);\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n      d.add(newTextField(\"content\", \"aaa \" + i, Field.Store.NO));\n      d.add(new NumericDocValuesField(\"dv\", i));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), TestUtil.ramCopyOf(startDir));\n      dir.setPreventDoubleWrite(false);\n      dir.setAllowRandomFileNotFoundException(false);\n      // test uses IW unref'ed helper which is unaware of retries\n      dir.setEnableVirusScanner(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMaxBufferedDeleteTerms(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n          dir.setRandomIOExceptionRateOnOpen(random().nextDouble()*0.01);\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n          dir.setRandomIOExceptionRateOnOpen(0.0);\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n                d.add(newTextField(\"content\", \"bbb \" + i, Field.Store.NO));\n                d.add(new NumericDocValuesField(\"dv\", i));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n            try {\n              modifier.close();\n            } catch (IllegalStateException ise) {\n              // ok\n              throw (IOException) ise.getCause();\n            }\n          }\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure index is OK:\n        if (success) {\n          TestUtil.checkIndex(dir);\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = DirectoryReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1e6acbaae7af722f17204ceccf0f7db5753eccf3","date":1454775255,"type":3,"author":"Mike McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","sourceNew":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newMockDirectory();\n\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n      d.add(newTextField(\"content\", \"aaa \" + i, Field.Store.NO));\n      d.add(new NumericDocValuesField(\"dv\", i));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), TestUtil.ramCopyOf(startDir));\n      dir.setPreventDoubleWrite(false);\n      dir.setAllowRandomFileNotFoundException(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMaxBufferedDeleteTerms(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n          dir.setRandomIOExceptionRateOnOpen(random().nextDouble()*0.01);\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n          dir.setRandomIOExceptionRateOnOpen(0.0);\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n                d.add(newTextField(\"content\", \"bbb \" + i, Field.Store.NO));\n                d.add(new NumericDocValuesField(\"dv\", i));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n            try {\n              modifier.close();\n            } catch (IllegalStateException ise) {\n              // ok\n              throw (IOException) ise.getCause();\n            }\n          }\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure index is OK:\n        if (success) {\n          TestUtil.checkIndex(dir);\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = DirectoryReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newMockDirectory();\n    // TODO: find the resource leak that only occurs sometimes here.\n    startDir.setNoDeleteOpenFile(false);\n    // test uses IW unref'ed helper which is unaware of retries\n    startDir.setEnableVirusScanner(false);\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n      d.add(newTextField(\"content\", \"aaa \" + i, Field.Store.NO));\n      d.add(new NumericDocValuesField(\"dv\", i));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), TestUtil.ramCopyOf(startDir));\n      dir.setPreventDoubleWrite(false);\n      dir.setAllowRandomFileNotFoundException(false);\n      // test uses IW unref'ed helper which is unaware of retries\n      dir.setEnableVirusScanner(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMaxBufferedDeleteTerms(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n          dir.setRandomIOExceptionRateOnOpen(random().nextDouble()*0.01);\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n          dir.setRandomIOExceptionRateOnOpen(0.0);\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n                d.add(newTextField(\"content\", \"bbb \" + i, Field.Store.NO));\n                d.add(new NumericDocValuesField(\"dv\", i));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n            try {\n              modifier.close();\n            } catch (IllegalStateException ise) {\n              // ok\n              throw (IOException) ise.getCause();\n            }\n          }\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure index is OK:\n        if (success) {\n          TestUtil.checkIndex(dir);\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = DirectoryReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5a207d19eac354d649c3f0e2cce070017c78125e","date":1454776470,"type":3,"author":"Erick Erickson","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","sourceNew":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newMockDirectory();\n\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n      d.add(newTextField(\"content\", \"aaa \" + i, Field.Store.NO));\n      d.add(new NumericDocValuesField(\"dv\", i));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), TestUtil.ramCopyOf(startDir));\n      dir.setPreventDoubleWrite(false);\n      dir.setAllowRandomFileNotFoundException(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMaxBufferedDeleteTerms(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n          dir.setRandomIOExceptionRateOnOpen(random().nextDouble()*0.01);\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n          dir.setRandomIOExceptionRateOnOpen(0.0);\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n                d.add(newTextField(\"content\", \"bbb \" + i, Field.Store.NO));\n                d.add(new NumericDocValuesField(\"dv\", i));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n            try {\n              modifier.close();\n            } catch (IllegalStateException ise) {\n              // ok\n              throw (IOException) ise.getCause();\n            }\n          }\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure index is OK:\n        if (success) {\n          TestUtil.checkIndex(dir);\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = DirectoryReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newMockDirectory();\n    // TODO: find the resource leak that only occurs sometimes here.\n    startDir.setNoDeleteOpenFile(false);\n    // test uses IW unref'ed helper which is unaware of retries\n    startDir.setEnableVirusScanner(false);\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n      d.add(newTextField(\"content\", \"aaa \" + i, Field.Store.NO));\n      d.add(new NumericDocValuesField(\"dv\", i));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), TestUtil.ramCopyOf(startDir));\n      dir.setPreventDoubleWrite(false);\n      dir.setAllowRandomFileNotFoundException(false);\n      // test uses IW unref'ed helper which is unaware of retries\n      dir.setEnableVirusScanner(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMaxBufferedDeleteTerms(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n          dir.setRandomIOExceptionRateOnOpen(random().nextDouble()*0.01);\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n          dir.setRandomIOExceptionRateOnOpen(0.0);\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n                d.add(newTextField(\"content\", \"bbb \" + i, Field.Store.NO));\n                d.add(new NumericDocValuesField(\"dv\", i));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n            try {\n              modifier.close();\n            } catch (IllegalStateException ise) {\n              // ok\n              throw (IOException) ise.getCause();\n            }\n          }\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure index is OK:\n        if (success) {\n          TestUtil.checkIndex(dir);\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = DirectoryReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"11c6df42fb3eba174c3ca0d9a5194eaecd893b77","date":1465931757,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","sourceNew":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newMockDirectory();\n\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n      d.add(newTextField(\"content\", \"aaa \" + i, Field.Store.NO));\n      d.add(new NumericDocValuesField(\"dv\", i));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), TestUtil.ramCopyOf(startDir));\n      dir.setAllowRandomFileNotFoundException(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMaxBufferedDeleteTerms(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n          dir.setRandomIOExceptionRateOnOpen(random().nextDouble()*0.01);\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n          dir.setRandomIOExceptionRateOnOpen(0.0);\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n                d.add(newTextField(\"content\", \"bbb \" + i, Field.Store.NO));\n                d.add(new NumericDocValuesField(\"dv\", i));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n            try {\n              modifier.close();\n            } catch (IllegalStateException ise) {\n              // ok\n              throw (IOException) ise.getCause();\n            }\n          }\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure index is OK:\n        if (success) {\n          TestUtil.checkIndex(dir);\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = DirectoryReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newMockDirectory();\n\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n      d.add(newTextField(\"content\", \"aaa \" + i, Field.Store.NO));\n      d.add(new NumericDocValuesField(\"dv\", i));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), TestUtil.ramCopyOf(startDir));\n      dir.setPreventDoubleWrite(false);\n      dir.setAllowRandomFileNotFoundException(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMaxBufferedDeleteTerms(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n          dir.setRandomIOExceptionRateOnOpen(random().nextDouble()*0.01);\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n          dir.setRandomIOExceptionRateOnOpen(0.0);\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n                d.add(newTextField(\"content\", \"bbb \" + i, Field.Store.NO));\n                d.add(new NumericDocValuesField(\"dv\", i));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n            try {\n              modifier.close();\n            } catch (IllegalStateException ise) {\n              // ok\n              throw (IOException) ise.getCause();\n            }\n          }\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure index is OK:\n        if (success) {\n          TestUtil.checkIndex(dir);\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = DirectoryReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","bugFix":["87c966e9308847938a7c905c2e46a56d8df788b8"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","sourceNew":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newMockDirectory();\n\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n      d.add(newTextField(\"content\", \"aaa \" + i, Field.Store.NO));\n      d.add(new NumericDocValuesField(\"dv\", i));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), TestUtil.ramCopyOf(startDir));\n      dir.setAllowRandomFileNotFoundException(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMaxBufferedDeleteTerms(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n          dir.setRandomIOExceptionRateOnOpen(random().nextDouble()*0.01);\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n          dir.setRandomIOExceptionRateOnOpen(0.0);\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n                d.add(newTextField(\"content\", \"bbb \" + i, Field.Store.NO));\n                d.add(new NumericDocValuesField(\"dv\", i));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n            try {\n              modifier.close();\n            } catch (IllegalStateException ise) {\n              // ok\n              throw (IOException) ise.getCause();\n            }\n          }\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure index is OK:\n        if (success) {\n          TestUtil.checkIndex(dir);\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = DirectoryReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newMockDirectory();\n\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n      d.add(newTextField(\"content\", \"aaa \" + i, Field.Store.NO));\n      d.add(new NumericDocValuesField(\"dv\", i));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), TestUtil.ramCopyOf(startDir));\n      dir.setPreventDoubleWrite(false);\n      dir.setAllowRandomFileNotFoundException(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMaxBufferedDeleteTerms(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n          dir.setRandomIOExceptionRateOnOpen(random().nextDouble()*0.01);\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n          dir.setRandomIOExceptionRateOnOpen(0.0);\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n                d.add(newTextField(\"content\", \"bbb \" + i, Field.Store.NO));\n                d.add(new NumericDocValuesField(\"dv\", i));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n            try {\n              modifier.close();\n            } catch (IllegalStateException ise) {\n              // ok\n              throw (IOException) ise.getCause();\n            }\n          }\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure index is OK:\n        if (success) {\n          TestUtil.checkIndex(dir);\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = DirectoryReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f4363cd33f6eff7fb4753574a441e2d18c1022a4","date":1498067235,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","sourceNew":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newMockDirectory();\n\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n      d.add(newTextField(\"content\", \"aaa \" + i, Field.Store.NO));\n      d.add(new NumericDocValuesField(\"dv\", i));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), TestUtil.ramCopyOf(startDir));\n      dir.setAllowRandomFileNotFoundException(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n          dir.setRandomIOExceptionRateOnOpen(random().nextDouble()*0.01);\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n          dir.setRandomIOExceptionRateOnOpen(0.0);\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n                d.add(newTextField(\"content\", \"bbb \" + i, Field.Store.NO));\n                d.add(new NumericDocValuesField(\"dv\", i));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n            try {\n              modifier.close();\n            } catch (IllegalStateException ise) {\n              // ok\n              throw (IOException) ise.getCause();\n            }\n          }\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure index is OK:\n        if (success) {\n          TestUtil.checkIndex(dir);\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = DirectoryReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newMockDirectory();\n\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n      d.add(newTextField(\"content\", \"aaa \" + i, Field.Store.NO));\n      d.add(new NumericDocValuesField(\"dv\", i));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), TestUtil.ramCopyOf(startDir));\n      dir.setAllowRandomFileNotFoundException(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMaxBufferedDeleteTerms(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n          dir.setRandomIOExceptionRateOnOpen(random().nextDouble()*0.01);\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n          dir.setRandomIOExceptionRateOnOpen(0.0);\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n                d.add(newTextField(\"content\", \"bbb \" + i, Field.Store.NO));\n                d.add(new NumericDocValuesField(\"dv\", i));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n            try {\n              modifier.close();\n            } catch (IllegalStateException ise) {\n              // ok\n              throw (IOException) ise.getCause();\n            }\n          }\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure index is OK:\n        if (success) {\n          TestUtil.checkIndex(dir);\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = DirectoryReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b7dfa64bc2074fb87d0ca70095a644c1ead107e1","date":1498356339,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","sourceNew":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newMockDirectory();\n\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n      d.add(newTextField(\"content\", \"aaa \" + i, Field.Store.NO));\n      d.add(new NumericDocValuesField(\"dv\", i));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), TestUtil.ramCopyOf(startDir));\n      dir.setAllowRandomFileNotFoundException(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n          dir.setRandomIOExceptionRateOnOpen(random().nextDouble()*0.01);\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n          dir.setRandomIOExceptionRateOnOpen(0.0);\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n                d.add(newTextField(\"content\", \"bbb \" + i, Field.Store.NO));\n                d.add(new NumericDocValuesField(\"dv\", i));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n            try {\n              modifier.close();\n            } catch (IllegalStateException ise) {\n              // ok\n              throw (IOException) ise.getCause();\n            }\n          }\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure index is OK:\n        if (success) {\n          TestUtil.checkIndex(dir);\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = DirectoryReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newMockDirectory();\n\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n      d.add(newTextField(\"content\", \"aaa \" + i, Field.Store.NO));\n      d.add(new NumericDocValuesField(\"dv\", i));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), TestUtil.ramCopyOf(startDir));\n      dir.setAllowRandomFileNotFoundException(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMaxBufferedDeleteTerms(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n          dir.setRandomIOExceptionRateOnOpen(random().nextDouble()*0.01);\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n          dir.setRandomIOExceptionRateOnOpen(0.0);\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n                d.add(newTextField(\"content\", \"bbb \" + i, Field.Store.NO));\n                d.add(new NumericDocValuesField(\"dv\", i));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n            try {\n              modifier.close();\n            } catch (IllegalStateException ise) {\n              // ok\n              throw (IOException) ise.getCause();\n            }\n          }\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure index is OK:\n        if (success) {\n          TestUtil.checkIndex(dir);\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = DirectoryReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"28288370235ed02234a64753cdbf0c6ec096304a","date":1498726817,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","sourceNew":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newMockDirectory();\n\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n      d.add(newTextField(\"content\", \"aaa \" + i, Field.Store.NO));\n      d.add(new NumericDocValuesField(\"dv\", i));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), TestUtil.ramCopyOf(startDir));\n      dir.setAllowRandomFileNotFoundException(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n          dir.setRandomIOExceptionRateOnOpen(random().nextDouble()*0.01);\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n          dir.setRandomIOExceptionRateOnOpen(0.0);\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n                d.add(newTextField(\"content\", \"bbb \" + i, Field.Store.NO));\n                d.add(new NumericDocValuesField(\"dv\", i));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n            try {\n              modifier.close();\n            } catch (IllegalStateException ise) {\n              // ok\n              throw (IOException) ise.getCause();\n            }\n          }\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure index is OK:\n        if (success) {\n          TestUtil.checkIndex(dir);\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = DirectoryReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newMockDirectory();\n\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n      d.add(newTextField(\"content\", \"aaa \" + i, Field.Store.NO));\n      d.add(new NumericDocValuesField(\"dv\", i));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), TestUtil.ramCopyOf(startDir));\n      dir.setAllowRandomFileNotFoundException(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMaxBufferedDeleteTerms(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n          dir.setRandomIOExceptionRateOnOpen(random().nextDouble()*0.01);\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n          dir.setRandomIOExceptionRateOnOpen(0.0);\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n                d.add(newTextField(\"content\", \"bbb \" + i, Field.Store.NO));\n                d.add(new NumericDocValuesField(\"dv\", i));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n            try {\n              modifier.close();\n            } catch (IllegalStateException ise) {\n              // ok\n              throw (IOException) ise.getCause();\n            }\n          }\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure index is OK:\n        if (success) {\n          TestUtil.checkIndex(dir);\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = DirectoryReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"45785dfb4e3509986fd9cc11d03052a135477b7b","date":1588319247,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete#doTestOperationsOnDiskFull(boolean).mjava","sourceNew":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newMockDirectory();\n\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n      d.add(newTextField(\"content\", \"aaa \" + i, Field.Store.NO));\n      d.add(new NumericDocValuesField(\"dv\", i));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), TestUtil.ramCopyOf(startDir));\n      dir.setAllowRandomFileNotFoundException(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n          dir.setRandomIOExceptionRateOnOpen(random().nextDouble()*0.01);\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n          dir.setRandomIOExceptionRateOnOpen(0.0);\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n                d.add(newTextField(\"content\", \"bbb \" + i, Field.Store.NO));\n                d.add(new NumericDocValuesField(\"dv\", i));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n            try {\n              modifier.close();\n            } catch (IllegalStateException ise) {\n              // ok\n              throw (IOException) ise.getCause();\n            }\n          }\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure index is OK:\n        if (success) {\n          TestUtil.checkIndex(dir);\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = DirectoryReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n\n      // Try again with more bytes of free space:\n      diskFree += Math.max(10, diskFree >>> 3);\n    }\n    startDir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void doTestOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newMockDirectory();\n\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n      d.add(newTextField(\"content\", \"aaa \" + i, Field.Store.NO));\n      d.add(new NumericDocValuesField(\"dv\", i));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: cycle\");\n      }\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random(), TestUtil.ramCopyOf(startDir));\n      dir.setAllowRandomFileNotFoundException(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false))\n                                             .setMaxBufferedDocs(1000)\n                                             .setMergeScheduler(new ConcurrentMergeScheduler()));\n      ((ConcurrentMergeScheduler) modifier.getConfig().getMergeScheduler()).setSuppressExceptions();\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: x=\" + x);\n        }\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n          dir.setRandomIOExceptionRateOnOpen(random().nextDouble()*0.01);\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n          dir.setRandomIOExceptionRateOnOpen(0.0);\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(newStringField(\"id\", Integer.toString(i), Field.Store.YES));\n                d.add(newTextField(\"content\", \"bbb \" + i, Field.Store.NO));\n                d.add(new NumericDocValuesField(\"dv\", i));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n            try {\n              modifier.close();\n            } catch (IllegalStateException ise) {\n              // ok\n              throw (IOException) ise.getCause();\n            }\n          }\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n        // prevent throwing a random exception here!!\n        final double randomIOExceptionRate = dir.getRandomIOExceptionRate();\n        final long maxSizeInBytes = dir.getMaxSizeInBytes();\n        dir.setRandomIOExceptionRate(0.0);\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        dir.setMaxSizeInBytes(0);\n        if (!success) {\n          // Must force the close else the writer can have\n          // open files which cause exc in MockRAMDir.close\n          if (VERBOSE) {\n            System.out.println(\"TEST: now rollback\");\n          }\n          modifier.rollback();\n        }\n\n        // If the close() succeeded, make sure index is OK:\n        if (success) {\n          TestUtil.checkIndex(dir);\n        }\n        dir.setRandomIOExceptionRate(randomIOExceptionRate);\n        dir.setMaxSizeInBytes(maxSizeInBytes);\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = DirectoryReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        newReader.close();\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n      dir.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n    startDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"5a207d19eac354d649c3f0e2cce070017c78125e":["d9e22bdf0692bfa61e342b04a6ac7078670c1e16","b470f36a9372c97283360b1304eacbde22df6c0d"],"f4363cd33f6eff7fb4753574a441e2d18c1022a4":["11c6df42fb3eba174c3ca0d9a5194eaecd893b77"],"11c6df42fb3eba174c3ca0d9a5194eaecd893b77":["5a207d19eac354d649c3f0e2cce070017c78125e"],"98d2deb8c96c79ebef084a1f8e5a1a6c08608f13":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"fc4053f65ade14b2ce1979911bc398299cc9c9ef":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"04f07771a2a7dd3a395700665ed839c3dae2def2":["e7e8d6f15900ee22ac3cb0a503f15dc952a3580f"],"aba371508186796cc6151d8223a5b4e16d02e26e":["04f07771a2a7dd3a395700665ed839c3dae2def2","d19974432be9aed28ee7dca73bdf01d139e763a9"],"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc":["302be0cc5e6a28ebcebcac98aa81a92be2e94370"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"6bfe104fc023fadc9e709f8d17403d2cc61133fe":["d9e22bdf0692bfa61e342b04a6ac7078670c1e16"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["3b1518fdad7b84b251e9210a29419b2fd0fc7e6a"],"4b51f65902cc2d20ddeb7a5b949aaddf990f31a7":["04f07771a2a7dd3a395700665ed839c3dae2def2","d19974432be9aed28ee7dca73bdf01d139e763a9"],"3b1518fdad7b84b251e9210a29419b2fd0fc7e6a":["6613659748fe4411a7dcf85266e55db1f95f7315"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"6613659748fe4411a7dcf85266e55db1f95f7315":["fc4053f65ade14b2ce1979911bc398299cc9c9ef"],"1e6acbaae7af722f17204ceccf0f7db5753eccf3":["d9e22bdf0692bfa61e342b04a6ac7078670c1e16","b470f36a9372c97283360b1304eacbde22df6c0d"],"45785dfb4e3509986fd9cc11d03052a135477b7b":["28288370235ed02234a64753cdbf0c6ec096304a"],"b7dfa64bc2074fb87d0ca70095a644c1ead107e1":["11c6df42fb3eba174c3ca0d9a5194eaecd893b77","f4363cd33f6eff7fb4753574a441e2d18c1022a4"],"28288370235ed02234a64753cdbf0c6ec096304a":["11c6df42fb3eba174c3ca0d9a5194eaecd893b77","f4363cd33f6eff7fb4753574a441e2d18c1022a4"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["5a207d19eac354d649c3f0e2cce070017c78125e","11c6df42fb3eba174c3ca0d9a5194eaecd893b77"],"d9e22bdf0692bfa61e342b04a6ac7078670c1e16":["f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc"],"d4d69c535930b5cce125cff868d40f6373dc27d4":["d19974432be9aed28ee7dca73bdf01d139e763a9","423d89a2b3cc419b647c07c2b3fdbc54311d07f9"],"d19974432be9aed28ee7dca73bdf01d139e763a9":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"06054bbf4f2aaa2f864ecabac4b0e1db6f3b07eb":["d19974432be9aed28ee7dca73bdf01d139e763a9"],"b470f36a9372c97283360b1304eacbde22df6c0d":["d9e22bdf0692bfa61e342b04a6ac7078670c1e16","6bfe104fc023fadc9e709f8d17403d2cc61133fe"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"9299079153fd7895bf3cf6835cf7019af2ba89b3":["98d2deb8c96c79ebef084a1f8e5a1a6c08608f13"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"423d89a2b3cc419b647c07c2b3fdbc54311d07f9":["06054bbf4f2aaa2f864ecabac4b0e1db6f3b07eb"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["45785dfb4e3509986fd9cc11d03052a135477b7b"],"302be0cc5e6a28ebcebcac98aa81a92be2e94370":["9299079153fd7895bf3cf6835cf7019af2ba89b3"]},"commit2Childs":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"5a207d19eac354d649c3f0e2cce070017c78125e":["11c6df42fb3eba174c3ca0d9a5194eaecd893b77","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"f4363cd33f6eff7fb4753574a441e2d18c1022a4":["b7dfa64bc2074fb87d0ca70095a644c1ead107e1","28288370235ed02234a64753cdbf0c6ec096304a"],"11c6df42fb3eba174c3ca0d9a5194eaecd893b77":["f4363cd33f6eff7fb4753574a441e2d18c1022a4","b7dfa64bc2074fb87d0ca70095a644c1ead107e1","28288370235ed02234a64753cdbf0c6ec096304a","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"98d2deb8c96c79ebef084a1f8e5a1a6c08608f13":["9299079153fd7895bf3cf6835cf7019af2ba89b3"],"fc4053f65ade14b2ce1979911bc398299cc9c9ef":["6613659748fe4411a7dcf85266e55db1f95f7315"],"04f07771a2a7dd3a395700665ed839c3dae2def2":["aba371508186796cc6151d8223a5b4e16d02e26e","4b51f65902cc2d20ddeb7a5b949aaddf990f31a7","d19974432be9aed28ee7dca73bdf01d139e763a9"],"aba371508186796cc6151d8223a5b4e16d02e26e":[],"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc":["d9e22bdf0692bfa61e342b04a6ac7078670c1e16"],"6bfe104fc023fadc9e709f8d17403d2cc61133fe":["b470f36a9372c97283360b1304eacbde22df6c0d"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"4b51f65902cc2d20ddeb7a5b949aaddf990f31a7":[],"3b1518fdad7b84b251e9210a29419b2fd0fc7e6a":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"6613659748fe4411a7dcf85266e55db1f95f7315":["3b1518fdad7b84b251e9210a29419b2fd0fc7e6a"],"1e6acbaae7af722f17204ceccf0f7db5753eccf3":[],"45785dfb4e3509986fd9cc11d03052a135477b7b":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"b7dfa64bc2074fb87d0ca70095a644c1ead107e1":[],"28288370235ed02234a64753cdbf0c6ec096304a":["45785dfb4e3509986fd9cc11d03052a135477b7b"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"d9e22bdf0692bfa61e342b04a6ac7078670c1e16":["5a207d19eac354d649c3f0e2cce070017c78125e","6bfe104fc023fadc9e709f8d17403d2cc61133fe","1e6acbaae7af722f17204ceccf0f7db5753eccf3","b470f36a9372c97283360b1304eacbde22df6c0d"],"d4d69c535930b5cce125cff868d40f6373dc27d4":["fc4053f65ade14b2ce1979911bc398299cc9c9ef"],"d19974432be9aed28ee7dca73bdf01d139e763a9":["aba371508186796cc6151d8223a5b4e16d02e26e","4b51f65902cc2d20ddeb7a5b949aaddf990f31a7","d4d69c535930b5cce125cff868d40f6373dc27d4","06054bbf4f2aaa2f864ecabac4b0e1db6f3b07eb"],"06054bbf4f2aaa2f864ecabac4b0e1db6f3b07eb":["423d89a2b3cc419b647c07c2b3fdbc54311d07f9"],"b470f36a9372c97283360b1304eacbde22df6c0d":["5a207d19eac354d649c3f0e2cce070017c78125e","1e6acbaae7af722f17204ceccf0f7db5753eccf3"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["98d2deb8c96c79ebef084a1f8e5a1a6c08608f13"],"9299079153fd7895bf3cf6835cf7019af2ba89b3":["302be0cc5e6a28ebcebcac98aa81a92be2e94370"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["e7e8d6f15900ee22ac3cb0a503f15dc952a3580f"],"423d89a2b3cc419b647c07c2b3fdbc54311d07f9":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"302be0cc5e6a28ebcebcac98aa81a92be2e94370":["f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["aba371508186796cc6151d8223a5b4e16d02e26e","4b51f65902cc2d20ddeb7a5b949aaddf990f31a7","1e6acbaae7af722f17204ceccf0f7db5753eccf3","b7dfa64bc2074fb87d0ca70095a644c1ead107e1","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}