{"path":"lucene/contrib/demo/src/java/org/apache/lucene/demo/IndexFiles#indexDocs(IndexWriter,File).mjava","commits":[{"id":"790c3f61c9b891d66d919c5d10db9fa5216eb0f1","date":1274818604,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/demo/src/java/org/apache/lucene/demo/IndexFiles#indexDocs(IndexWriter,File).mjava","pathOld":"lucene/src/demo/org/apache/lucene/demo/IndexFiles#indexDocs(IndexWriter,File).mjava","sourceNew":"  static void indexDocs(IndexWriter writer, File file)\n    throws IOException {\n    // do not try to index files that cannot be read\n    if (file.canRead()) {\n      if (file.isDirectory()) {\n        String[] files = file.list();\n        // an IO error could occur\n        if (files != null) {\n          for (int i = 0; i < files.length; i++) {\n            indexDocs(writer, new File(file, files[i]));\n          }\n        }\n      } else {\n        System.out.println(\"adding \" + file);\n        try {\n          writer.addDocument(FileDocument.Document(file));\n        }\n        // at least on windows, some temporary files raise this exception with an \"access denied\" message\n        // checking if the file can be read doesn't help\n        catch (FileNotFoundException fnfe) {\n        }\n      }\n    }\n  }\n\n","sourceOld":"  static void indexDocs(IndexWriter writer, File file)\n    throws IOException {\n    // do not try to index files that cannot be read\n    if (file.canRead()) {\n      if (file.isDirectory()) {\n        String[] files = file.list();\n        // an IO error could occur\n        if (files != null) {\n          for (int i = 0; i < files.length; i++) {\n            indexDocs(writer, new File(file, files[i]));\n          }\n        }\n      } else {\n        System.out.println(\"adding \" + file);\n        try {\n          writer.addDocument(FileDocument.Document(file));\n        }\n        // at least on windows, some temporary files raise this exception with an \"access denied\" message\n        // checking if the file can be read doesn't help\n        catch (FileNotFoundException fnfe) {\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"81ea17596392ebd5d12741eb9e3b2516258b9413","date":1298090976,"type":3,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/contrib/demo/src/java/org/apache/lucene/demo/IndexFiles#indexDocs(IndexWriter,File).mjava","pathOld":"lucene/contrib/demo/src/java/org/apache/lucene/demo/IndexFiles#indexDocs(IndexWriter,File).mjava","sourceNew":"  /**\n   * Indexes the given file using the given writer, or if a directory is given,\n   * recurses over files and directories found under the given directory.\n   * \n   * NOTE: This method indexes one document per input file.  This is slow.  For good\n   * throughput, put multiple documents into your input file(s).  An example of this is\n   * in the benchmark module, which can create \"line doc\" files, one document per line,\n   * using the\n   * <a href=\"../../../../../contrib-benchmark/org/apache/lucene/benchmark/byTask/tasks/WriteLineDocTask.html\"\n   * >WriteLineDocTask</a>.\n   *  \n   * @param writer Writer to the index where the given file/dir info will be stored\n   * @param file The file to index, or the directory to recurse into to find files to index\n   * @throws IOException\n   */\n  static void indexDocs(IndexWriter writer, File file)\n    throws IOException {\n    // do not try to index files that cannot be read\n    if (file.canRead()) {\n      if (file.isDirectory()) {\n        String[] files = file.list();\n        // an IO error could occur\n        if (files != null) {\n          for (int i = 0; i < files.length; i++) {\n            indexDocs(writer, new File(file, files[i]));\n          }\n        }\n      } else {\n\n        FileInputStream fis;\n        try {\n          fis = new FileInputStream(file);\n        } catch (FileNotFoundException fnfe) {\n          // at least on windows, some temporary files raise this exception with an \"access denied\" message\n          // checking if the file can be read doesn't help\n          return;\n        }\n\n        try {\n\n          // make a new, empty document\n          Document doc = new Document();\n\n          // Add the path of the file as a field named \"path\".  Use a\n          // field that is indexed (i.e. searchable), but don't tokenize \n          // the field into separate words and don't index term frequency\n          // or positional information:\n          Field pathField = new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS);\n          pathField.setOmitTermFreqAndPositions(true);\n          doc.add(pathField);\n\n          // Add the last modified date of the file a field named \"modified\".\n          // Use a NumericField that is indexed (i.e. efficiently filterable with\n          // NumericRangeFilter).  This indexes to milli-second resolution, which\n          // is often too fine.  You could instead create a number based on\n          // year/month/day/hour/minutes/seconds, down the resolution you require.\n          // For example the long value 2011021714 would mean\n          // February 17, 2011, 2-3 PM.\n          NumericField modifiedField = new NumericField(\"modified\");\n          modifiedField.setLongValue(file.lastModified());\n          doc.add(modifiedField);\n\n          // Add the contents of the file to a field named \"contents\".  Specify a Reader,\n          // so that the text of the file is tokenized and indexed, but not stored.\n          // Note that FileReader expects the file to be in UTF-8 encoding.\n          // If that's not the case searching for special characters will fail.\n          doc.add(new Field(\"contents\", new BufferedReader(new InputStreamReader(fis, \"UTF-8\"))));\n\n          if (writer.getConfig().getOpenMode() == OpenMode.CREATE) {\n            // New index, so we just add the document (no old document can be there):\n            System.out.println(\"adding \" + file);\n            writer.addDocument(doc);\n          } else {\n            // Existing index (an old copy of this document may have been indexed) so \n            // we use updateDocument instead to replace the old one matching the exact \n            // path, if present:\n            System.out.println(\"updating \" + file);\n            writer.updateDocument(new Term(\"path\", file.getPath()), doc);\n          }\n          \n        } finally {\n          fis.close();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  static void indexDocs(IndexWriter writer, File file)\n    throws IOException {\n    // do not try to index files that cannot be read\n    if (file.canRead()) {\n      if (file.isDirectory()) {\n        String[] files = file.list();\n        // an IO error could occur\n        if (files != null) {\n          for (int i = 0; i < files.length; i++) {\n            indexDocs(writer, new File(file, files[i]));\n          }\n        }\n      } else {\n        System.out.println(\"adding \" + file);\n        try {\n          writer.addDocument(FileDocument.Document(file));\n        }\n        // at least on windows, some temporary files raise this exception with an \"access denied\" message\n        // checking if the file can be read doesn't help\n        catch (FileNotFoundException fnfe) {\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["a78a90fc9701e511308346ea29f4f5e548bb39fe","fa0f44f887719e97183771e977cfc4bfb485b766"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f1bdbf92da222965b46c0a942c3857ba56e5c638","date":1298297608,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/contrib/demo/src/java/org/apache/lucene/demo/IndexFiles#indexDocs(IndexWriter,File).mjava","pathOld":"lucene/contrib/demo/src/java/org/apache/lucene/demo/IndexFiles#indexDocs(IndexWriter,File).mjava","sourceNew":"  /**\n   * Indexes the given file using the given writer, or if a directory is given,\n   * recurses over files and directories found under the given directory.\n   * \n   * NOTE: This method indexes one document per input file.  This is slow.  For good\n   * throughput, put multiple documents into your input file(s).  An example of this is\n   * in the benchmark module, which can create \"line doc\" files, one document per line,\n   * using the\n   * <a href=\"../../../../../contrib-benchmark/org/apache/lucene/benchmark/byTask/tasks/WriteLineDocTask.html\"\n   * >WriteLineDocTask</a>.\n   *  \n   * @param writer Writer to the index where the given file/dir info will be stored\n   * @param file The file to index, or the directory to recurse into to find files to index\n   * @throws IOException\n   */\n  static void indexDocs(IndexWriter writer, File file)\n    throws IOException {\n    // do not try to index files that cannot be read\n    if (file.canRead()) {\n      if (file.isDirectory()) {\n        String[] files = file.list();\n        // an IO error could occur\n        if (files != null) {\n          for (int i = 0; i < files.length; i++) {\n            indexDocs(writer, new File(file, files[i]));\n          }\n        }\n      } else {\n\n        FileInputStream fis;\n        try {\n          fis = new FileInputStream(file);\n        } catch (FileNotFoundException fnfe) {\n          // at least on windows, some temporary files raise this exception with an \"access denied\" message\n          // checking if the file can be read doesn't help\n          return;\n        }\n\n        try {\n\n          // make a new, empty document\n          Document doc = new Document();\n\n          // Add the path of the file as a field named \"path\".  Use a\n          // field that is indexed (i.e. searchable), but don't tokenize \n          // the field into separate words and don't index term frequency\n          // or positional information:\n          Field pathField = new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS);\n          pathField.setOmitTermFreqAndPositions(true);\n          doc.add(pathField);\n\n          // Add the last modified date of the file a field named \"modified\".\n          // Use a NumericField that is indexed (i.e. efficiently filterable with\n          // NumericRangeFilter).  This indexes to milli-second resolution, which\n          // is often too fine.  You could instead create a number based on\n          // year/month/day/hour/minutes/seconds, down the resolution you require.\n          // For example the long value 2011021714 would mean\n          // February 17, 2011, 2-3 PM.\n          NumericField modifiedField = new NumericField(\"modified\");\n          modifiedField.setLongValue(file.lastModified());\n          doc.add(modifiedField);\n\n          // Add the contents of the file to a field named \"contents\".  Specify a Reader,\n          // so that the text of the file is tokenized and indexed, but not stored.\n          // Note that FileReader expects the file to be in UTF-8 encoding.\n          // If that's not the case searching for special characters will fail.\n          doc.add(new Field(\"contents\", new BufferedReader(new InputStreamReader(fis, \"UTF-8\"))));\n\n          if (writer.getConfig().getOpenMode() == OpenMode.CREATE) {\n            // New index, so we just add the document (no old document can be there):\n            System.out.println(\"adding \" + file);\n            writer.addDocument(doc);\n          } else {\n            // Existing index (an old copy of this document may have been indexed) so \n            // we use updateDocument instead to replace the old one matching the exact \n            // path, if present:\n            System.out.println(\"updating \" + file);\n            writer.updateDocument(new Term(\"path\", file.getPath()), doc);\n          }\n          \n        } finally {\n          fis.close();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  static void indexDocs(IndexWriter writer, File file)\n    throws IOException {\n    // do not try to index files that cannot be read\n    if (file.canRead()) {\n      if (file.isDirectory()) {\n        String[] files = file.list();\n        // an IO error could occur\n        if (files != null) {\n          for (int i = 0; i < files.length; i++) {\n            indexDocs(writer, new File(file, files[i]));\n          }\n        }\n      } else {\n        System.out.println(\"adding \" + file);\n        try {\n          writer.addDocument(FileDocument.Document(file));\n        }\n        // at least on windows, some temporary files raise this exception with an \"access denied\" message\n        // checking if the file can be read doesn't help\n        catch (FileNotFoundException fnfe) {\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bde51b089eb7f86171eb3406e38a274743f9b7ac","date":1298336439,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/contrib/demo/src/java/org/apache/lucene/demo/IndexFiles#indexDocs(IndexWriter,File).mjava","pathOld":"lucene/contrib/demo/src/java/org/apache/lucene/demo/IndexFiles#indexDocs(IndexWriter,File).mjava","sourceNew":"  /**\n   * Indexes the given file using the given writer, or if a directory is given,\n   * recurses over files and directories found under the given directory.\n   * \n   * NOTE: This method indexes one document per input file.  This is slow.  For good\n   * throughput, put multiple documents into your input file(s).  An example of this is\n   * in the benchmark module, which can create \"line doc\" files, one document per line,\n   * using the\n   * <a href=\"../../../../../contrib-benchmark/org/apache/lucene/benchmark/byTask/tasks/WriteLineDocTask.html\"\n   * >WriteLineDocTask</a>.\n   *  \n   * @param writer Writer to the index where the given file/dir info will be stored\n   * @param file The file to index, or the directory to recurse into to find files to index\n   * @throws IOException\n   */\n  static void indexDocs(IndexWriter writer, File file)\n    throws IOException {\n    // do not try to index files that cannot be read\n    if (file.canRead()) {\n      if (file.isDirectory()) {\n        String[] files = file.list();\n        // an IO error could occur\n        if (files != null) {\n          for (int i = 0; i < files.length; i++) {\n            indexDocs(writer, new File(file, files[i]));\n          }\n        }\n      } else {\n\n        FileInputStream fis;\n        try {\n          fis = new FileInputStream(file);\n        } catch (FileNotFoundException fnfe) {\n          // at least on windows, some temporary files raise this exception with an \"access denied\" message\n          // checking if the file can be read doesn't help\n          return;\n        }\n\n        try {\n\n          // make a new, empty document\n          Document doc = new Document();\n\n          // Add the path of the file as a field named \"path\".  Use a\n          // field that is indexed (i.e. searchable), but don't tokenize \n          // the field into separate words and don't index term frequency\n          // or positional information:\n          Field pathField = new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS);\n          pathField.setOmitTermFreqAndPositions(true);\n          doc.add(pathField);\n\n          // Add the last modified date of the file a field named \"modified\".\n          // Use a NumericField that is indexed (i.e. efficiently filterable with\n          // NumericRangeFilter).  This indexes to milli-second resolution, which\n          // is often too fine.  You could instead create a number based on\n          // year/month/day/hour/minutes/seconds, down the resolution you require.\n          // For example the long value 2011021714 would mean\n          // February 17, 2011, 2-3 PM.\n          NumericField modifiedField = new NumericField(\"modified\");\n          modifiedField.setLongValue(file.lastModified());\n          doc.add(modifiedField);\n\n          // Add the contents of the file to a field named \"contents\".  Specify a Reader,\n          // so that the text of the file is tokenized and indexed, but not stored.\n          // Note that FileReader expects the file to be in UTF-8 encoding.\n          // If that's not the case searching for special characters will fail.\n          doc.add(new Field(\"contents\", new BufferedReader(new InputStreamReader(fis, \"UTF-8\"))));\n\n          if (writer.getConfig().getOpenMode() == OpenMode.CREATE) {\n            // New index, so we just add the document (no old document can be there):\n            System.out.println(\"adding \" + file);\n            writer.addDocument(doc);\n          } else {\n            // Existing index (an old copy of this document may have been indexed) so \n            // we use updateDocument instead to replace the old one matching the exact \n            // path, if present:\n            System.out.println(\"updating \" + file);\n            writer.updateDocument(new Term(\"path\", file.getPath()), doc);\n          }\n          \n        } finally {\n          fis.close();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  static void indexDocs(IndexWriter writer, File file)\n    throws IOException {\n    // do not try to index files that cannot be read\n    if (file.canRead()) {\n      if (file.isDirectory()) {\n        String[] files = file.list();\n        // an IO error could occur\n        if (files != null) {\n          for (int i = 0; i < files.length; i++) {\n            indexDocs(writer, new File(file, files[i]));\n          }\n        }\n      } else {\n        System.out.println(\"adding \" + file);\n        try {\n          writer.addDocument(FileDocument.Document(file));\n        }\n        // at least on windows, some temporary files raise this exception with an \"access denied\" message\n        // checking if the file can be read doesn't help\n        catch (FileNotFoundException fnfe) {\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2afd23a6f1242190c3409d8d81d5c5912d607fc9","date":1310477482,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/demo/src/java/org/apache/lucene/demo/IndexFiles#indexDocs(IndexWriter,File).mjava","pathOld":"lucene/contrib/demo/src/java/org/apache/lucene/demo/IndexFiles#indexDocs(IndexWriter,File).mjava","sourceNew":"  /**\n   * Indexes the given file using the given writer, or if a directory is given,\n   * recurses over files and directories found under the given directory.\n   * \n   * NOTE: This method indexes one document per input file.  This is slow.  For good\n   * throughput, put multiple documents into your input file(s).  An example of this is\n   * in the benchmark module, which can create \"line doc\" files, one document per line,\n   * using the\n   * <a href=\"../../../../../contrib-benchmark/org/apache/lucene/benchmark/byTask/tasks/WriteLineDocTask.html\"\n   * >WriteLineDocTask</a>.\n   *  \n   * @param writer Writer to the index where the given file/dir info will be stored\n   * @param file The file to index, or the directory to recurse into to find files to index\n   * @throws IOException\n   */\n  static void indexDocs(IndexWriter writer, File file)\n    throws IOException {\n    // do not try to index files that cannot be read\n    if (file.canRead()) {\n      if (file.isDirectory()) {\n        String[] files = file.list();\n        // an IO error could occur\n        if (files != null) {\n          for (int i = 0; i < files.length; i++) {\n            indexDocs(writer, new File(file, files[i]));\n          }\n        }\n      } else {\n\n        FileInputStream fis;\n        try {\n          fis = new FileInputStream(file);\n        } catch (FileNotFoundException fnfe) {\n          // at least on windows, some temporary files raise this exception with an \"access denied\" message\n          // checking if the file can be read doesn't help\n          return;\n        }\n\n        try {\n\n          // make a new, empty document\n          Document doc = new Document();\n\n          // Add the path of the file as a field named \"path\".  Use a\n          // field that is indexed (i.e. searchable), but don't tokenize \n          // the field into separate words and don't index term frequency\n          // or positional information:\n          Field pathField = new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS);\n          pathField.setIndexOptions(IndexOptions.DOCS_ONLY);\n          doc.add(pathField);\n\n          // Add the last modified date of the file a field named \"modified\".\n          // Use a NumericField that is indexed (i.e. efficiently filterable with\n          // NumericRangeFilter).  This indexes to milli-second resolution, which\n          // is often too fine.  You could instead create a number based on\n          // year/month/day/hour/minutes/seconds, down the resolution you require.\n          // For example the long value 2011021714 would mean\n          // February 17, 2011, 2-3 PM.\n          NumericField modifiedField = new NumericField(\"modified\");\n          modifiedField.setLongValue(file.lastModified());\n          doc.add(modifiedField);\n\n          // Add the contents of the file to a field named \"contents\".  Specify a Reader,\n          // so that the text of the file is tokenized and indexed, but not stored.\n          // Note that FileReader expects the file to be in UTF-8 encoding.\n          // If that's not the case searching for special characters will fail.\n          doc.add(new Field(\"contents\", new BufferedReader(new InputStreamReader(fis, \"UTF-8\"))));\n\n          if (writer.getConfig().getOpenMode() == OpenMode.CREATE) {\n            // New index, so we just add the document (no old document can be there):\n            System.out.println(\"adding \" + file);\n            writer.addDocument(doc);\n          } else {\n            // Existing index (an old copy of this document may have been indexed) so \n            // we use updateDocument instead to replace the old one matching the exact \n            // path, if present:\n            System.out.println(\"updating \" + file);\n            writer.updateDocument(new Term(\"path\", file.getPath()), doc);\n          }\n          \n        } finally {\n          fis.close();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Indexes the given file using the given writer, or if a directory is given,\n   * recurses over files and directories found under the given directory.\n   * \n   * NOTE: This method indexes one document per input file.  This is slow.  For good\n   * throughput, put multiple documents into your input file(s).  An example of this is\n   * in the benchmark module, which can create \"line doc\" files, one document per line,\n   * using the\n   * <a href=\"../../../../../contrib-benchmark/org/apache/lucene/benchmark/byTask/tasks/WriteLineDocTask.html\"\n   * >WriteLineDocTask</a>.\n   *  \n   * @param writer Writer to the index where the given file/dir info will be stored\n   * @param file The file to index, or the directory to recurse into to find files to index\n   * @throws IOException\n   */\n  static void indexDocs(IndexWriter writer, File file)\n    throws IOException {\n    // do not try to index files that cannot be read\n    if (file.canRead()) {\n      if (file.isDirectory()) {\n        String[] files = file.list();\n        // an IO error could occur\n        if (files != null) {\n          for (int i = 0; i < files.length; i++) {\n            indexDocs(writer, new File(file, files[i]));\n          }\n        }\n      } else {\n\n        FileInputStream fis;\n        try {\n          fis = new FileInputStream(file);\n        } catch (FileNotFoundException fnfe) {\n          // at least on windows, some temporary files raise this exception with an \"access denied\" message\n          // checking if the file can be read doesn't help\n          return;\n        }\n\n        try {\n\n          // make a new, empty document\n          Document doc = new Document();\n\n          // Add the path of the file as a field named \"path\".  Use a\n          // field that is indexed (i.e. searchable), but don't tokenize \n          // the field into separate words and don't index term frequency\n          // or positional information:\n          Field pathField = new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS);\n          pathField.setOmitTermFreqAndPositions(true);\n          doc.add(pathField);\n\n          // Add the last modified date of the file a field named \"modified\".\n          // Use a NumericField that is indexed (i.e. efficiently filterable with\n          // NumericRangeFilter).  This indexes to milli-second resolution, which\n          // is often too fine.  You could instead create a number based on\n          // year/month/day/hour/minutes/seconds, down the resolution you require.\n          // For example the long value 2011021714 would mean\n          // February 17, 2011, 2-3 PM.\n          NumericField modifiedField = new NumericField(\"modified\");\n          modifiedField.setLongValue(file.lastModified());\n          doc.add(modifiedField);\n\n          // Add the contents of the file to a field named \"contents\".  Specify a Reader,\n          // so that the text of the file is tokenized and indexed, but not stored.\n          // Note that FileReader expects the file to be in UTF-8 encoding.\n          // If that's not the case searching for special characters will fail.\n          doc.add(new Field(\"contents\", new BufferedReader(new InputStreamReader(fis, \"UTF-8\"))));\n\n          if (writer.getConfig().getOpenMode() == OpenMode.CREATE) {\n            // New index, so we just add the document (no old document can be there):\n            System.out.println(\"adding \" + file);\n            writer.addDocument(doc);\n          } else {\n            // Existing index (an old copy of this document may have been indexed) so \n            // we use updateDocument instead to replace the old one matching the exact \n            // path, if present:\n            System.out.println(\"updating \" + file);\n            writer.updateDocument(new Term(\"path\", file.getPath()), doc);\n          }\n          \n        } finally {\n          fis.close();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1509f151d7692d84fae414b2b799ac06ba60fcb4","date":1314451621,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/contrib/demo/src/java/org/apache/lucene/demo/IndexFiles#indexDocs(IndexWriter,File).mjava","pathOld":"lucene/contrib/demo/src/java/org/apache/lucene/demo/IndexFiles#indexDocs(IndexWriter,File).mjava","sourceNew":"  /**\n   * Indexes the given file using the given writer, or if a directory is given,\n   * recurses over files and directories found under the given directory.\n   * \n   * NOTE: This method indexes one document per input file.  This is slow.  For good\n   * throughput, put multiple documents into your input file(s).  An example of this is\n   * in the benchmark module, which can create \"line doc\" files, one document per line,\n   * using the\n   * <a href=\"../../../../../contrib-benchmark/org/apache/lucene/benchmark/byTask/tasks/WriteLineDocTask.html\"\n   * >WriteLineDocTask</a>.\n   *  \n   * @param writer Writer to the index where the given file/dir info will be stored\n   * @param file The file to index, or the directory to recurse into to find files to index\n   * @throws IOException\n   */\n  static void indexDocs(IndexWriter writer, File file)\n    throws IOException {\n    // do not try to index files that cannot be read\n    if (file.canRead()) {\n      if (file.isDirectory()) {\n        String[] files = file.list();\n        // an IO error could occur\n        if (files != null) {\n          for (int i = 0; i < files.length; i++) {\n            indexDocs(writer, new File(file, files[i]));\n          }\n        }\n      } else {\n\n        FileInputStream fis;\n        try {\n          fis = new FileInputStream(file);\n        } catch (FileNotFoundException fnfe) {\n          // at least on windows, some temporary files raise this exception with an \"access denied\" message\n          // checking if the file can be read doesn't help\n          return;\n        }\n\n        try {\n\n          // make a new, empty document\n          Document doc = new Document();\n\n          // Add the path of the file as a field named \"path\".  Use a\n          // field that is indexed (i.e. searchable), but don't tokenize \n          // the field into separate words and don't index term frequency\n          // or positional information:\n          Field pathField = new Field(\"path\", StringField.TYPE_STORED, file.getPath());\n          doc.add(pathField);\n\n          // Add the last modified date of the file a field named \"modified\".\n          // Use a NumericField that is indexed (i.e. efficiently filterable with\n          // NumericRangeFilter).  This indexes to milli-second resolution, which\n          // is often too fine.  You could instead create a number based on\n          // year/month/day/hour/minutes/seconds, down the resolution you require.\n          // For example the long value 2011021714 would mean\n          // February 17, 2011, 2-3 PM.\n          NumericField modifiedField = new NumericField(\"modified\");\n          modifiedField.setLongValue(file.lastModified());\n          doc.add(modifiedField);\n\n          // Add the contents of the file to a field named \"contents\".  Specify a Reader,\n          // so that the text of the file is tokenized and indexed, but not stored.\n          // Note that FileReader expects the file to be in UTF-8 encoding.\n          // If that's not the case searching for special characters will fail.\n          doc.add(new TextField(\"contents\", new BufferedReader(new InputStreamReader(fis, \"UTF-8\"))));\n\n          if (writer.getConfig().getOpenMode() == OpenMode.CREATE) {\n            // New index, so we just add the document (no old document can be there):\n            System.out.println(\"adding \" + file);\n            writer.addDocument(doc);\n          } else {\n            // Existing index (an old copy of this document may have been indexed) so \n            // we use updateDocument instead to replace the old one matching the exact \n            // path, if present:\n            System.out.println(\"updating \" + file);\n            writer.updateDocument(new Term(\"path\", file.getPath()), doc);\n          }\n          \n        } finally {\n          fis.close();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Indexes the given file using the given writer, or if a directory is given,\n   * recurses over files and directories found under the given directory.\n   * \n   * NOTE: This method indexes one document per input file.  This is slow.  For good\n   * throughput, put multiple documents into your input file(s).  An example of this is\n   * in the benchmark module, which can create \"line doc\" files, one document per line,\n   * using the\n   * <a href=\"../../../../../contrib-benchmark/org/apache/lucene/benchmark/byTask/tasks/WriteLineDocTask.html\"\n   * >WriteLineDocTask</a>.\n   *  \n   * @param writer Writer to the index where the given file/dir info will be stored\n   * @param file The file to index, or the directory to recurse into to find files to index\n   * @throws IOException\n   */\n  static void indexDocs(IndexWriter writer, File file)\n    throws IOException {\n    // do not try to index files that cannot be read\n    if (file.canRead()) {\n      if (file.isDirectory()) {\n        String[] files = file.list();\n        // an IO error could occur\n        if (files != null) {\n          for (int i = 0; i < files.length; i++) {\n            indexDocs(writer, new File(file, files[i]));\n          }\n        }\n      } else {\n\n        FileInputStream fis;\n        try {\n          fis = new FileInputStream(file);\n        } catch (FileNotFoundException fnfe) {\n          // at least on windows, some temporary files raise this exception with an \"access denied\" message\n          // checking if the file can be read doesn't help\n          return;\n        }\n\n        try {\n\n          // make a new, empty document\n          Document doc = new Document();\n\n          // Add the path of the file as a field named \"path\".  Use a\n          // field that is indexed (i.e. searchable), but don't tokenize \n          // the field into separate words and don't index term frequency\n          // or positional information:\n          Field pathField = new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS);\n          pathField.setIndexOptions(IndexOptions.DOCS_ONLY);\n          doc.add(pathField);\n\n          // Add the last modified date of the file a field named \"modified\".\n          // Use a NumericField that is indexed (i.e. efficiently filterable with\n          // NumericRangeFilter).  This indexes to milli-second resolution, which\n          // is often too fine.  You could instead create a number based on\n          // year/month/day/hour/minutes/seconds, down the resolution you require.\n          // For example the long value 2011021714 would mean\n          // February 17, 2011, 2-3 PM.\n          NumericField modifiedField = new NumericField(\"modified\");\n          modifiedField.setLongValue(file.lastModified());\n          doc.add(modifiedField);\n\n          // Add the contents of the file to a field named \"contents\".  Specify a Reader,\n          // so that the text of the file is tokenized and indexed, but not stored.\n          // Note that FileReader expects the file to be in UTF-8 encoding.\n          // If that's not the case searching for special characters will fail.\n          doc.add(new Field(\"contents\", new BufferedReader(new InputStreamReader(fis, \"UTF-8\"))));\n\n          if (writer.getConfig().getOpenMode() == OpenMode.CREATE) {\n            // New index, so we just add the document (no old document can be there):\n            System.out.println(\"adding \" + file);\n            writer.addDocument(doc);\n          } else {\n            // Existing index (an old copy of this document may have been indexed) so \n            // we use updateDocument instead to replace the old one matching the exact \n            // path, if present:\n            System.out.println(\"updating \" + file);\n            writer.updateDocument(new Term(\"path\", file.getPath()), doc);\n          }\n          \n        } finally {\n          fis.close();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7e4db59c6b6c10e25322cfb41c4c19d78b4298bd","date":1317197236,"type":3,"author":"Christopher John Male","isMerge":false,"pathNew":"lucene/contrib/demo/src/java/org/apache/lucene/demo/IndexFiles#indexDocs(IndexWriter,File).mjava","pathOld":"lucene/contrib/demo/src/java/org/apache/lucene/demo/IndexFiles#indexDocs(IndexWriter,File).mjava","sourceNew":"  /**\n   * Indexes the given file using the given writer, or if a directory is given,\n   * recurses over files and directories found under the given directory.\n   * \n   * NOTE: This method indexes one document per input file.  This is slow.  For good\n   * throughput, put multiple documents into your input file(s).  An example of this is\n   * in the benchmark module, which can create \"line doc\" files, one document per line,\n   * using the\n   * <a href=\"../../../../../contrib-benchmark/org/apache/lucene/benchmark/byTask/tasks/WriteLineDocTask.html\"\n   * >WriteLineDocTask</a>.\n   *  \n   * @param writer Writer to the index where the given file/dir info will be stored\n   * @param file The file to index, or the directory to recurse into to find files to index\n   * @throws IOException\n   */\n  static void indexDocs(IndexWriter writer, File file)\n    throws IOException {\n    // do not try to index files that cannot be read\n    if (file.canRead()) {\n      if (file.isDirectory()) {\n        String[] files = file.list();\n        // an IO error could occur\n        if (files != null) {\n          for (int i = 0; i < files.length; i++) {\n            indexDocs(writer, new File(file, files[i]));\n          }\n        }\n      } else {\n\n        FileInputStream fis;\n        try {\n          fis = new FileInputStream(file);\n        } catch (FileNotFoundException fnfe) {\n          // at least on windows, some temporary files raise this exception with an \"access denied\" message\n          // checking if the file can be read doesn't help\n          return;\n        }\n\n        try {\n\n          // make a new, empty document\n          Document doc = new Document();\n\n          // Add the path of the file as a field named \"path\".  Use a\n          // field that is indexed (i.e. searchable), but don't tokenize \n          // the field into separate words and don't index term frequency\n          // or positional information:\n          Field pathField = new Field(\"path\", file.getPath(), StringField.TYPE_STORED);\n          doc.add(pathField);\n\n          // Add the last modified date of the file a field named \"modified\".\n          // Use a NumericField that is indexed (i.e. efficiently filterable with\n          // NumericRangeFilter).  This indexes to milli-second resolution, which\n          // is often too fine.  You could instead create a number based on\n          // year/month/day/hour/minutes/seconds, down the resolution you require.\n          // For example the long value 2011021714 would mean\n          // February 17, 2011, 2-3 PM.\n          NumericField modifiedField = new NumericField(\"modified\");\n          modifiedField.setLongValue(file.lastModified());\n          doc.add(modifiedField);\n\n          // Add the contents of the file to a field named \"contents\".  Specify a Reader,\n          // so that the text of the file is tokenized and indexed, but not stored.\n          // Note that FileReader expects the file to be in UTF-8 encoding.\n          // If that's not the case searching for special characters will fail.\n          doc.add(new TextField(\"contents\", new BufferedReader(new InputStreamReader(fis, \"UTF-8\"))));\n\n          if (writer.getConfig().getOpenMode() == OpenMode.CREATE) {\n            // New index, so we just add the document (no old document can be there):\n            System.out.println(\"adding \" + file);\n            writer.addDocument(doc);\n          } else {\n            // Existing index (an old copy of this document may have been indexed) so \n            // we use updateDocument instead to replace the old one matching the exact \n            // path, if present:\n            System.out.println(\"updating \" + file);\n            writer.updateDocument(new Term(\"path\", file.getPath()), doc);\n          }\n          \n        } finally {\n          fis.close();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Indexes the given file using the given writer, or if a directory is given,\n   * recurses over files and directories found under the given directory.\n   * \n   * NOTE: This method indexes one document per input file.  This is slow.  For good\n   * throughput, put multiple documents into your input file(s).  An example of this is\n   * in the benchmark module, which can create \"line doc\" files, one document per line,\n   * using the\n   * <a href=\"../../../../../contrib-benchmark/org/apache/lucene/benchmark/byTask/tasks/WriteLineDocTask.html\"\n   * >WriteLineDocTask</a>.\n   *  \n   * @param writer Writer to the index where the given file/dir info will be stored\n   * @param file The file to index, or the directory to recurse into to find files to index\n   * @throws IOException\n   */\n  static void indexDocs(IndexWriter writer, File file)\n    throws IOException {\n    // do not try to index files that cannot be read\n    if (file.canRead()) {\n      if (file.isDirectory()) {\n        String[] files = file.list();\n        // an IO error could occur\n        if (files != null) {\n          for (int i = 0; i < files.length; i++) {\n            indexDocs(writer, new File(file, files[i]));\n          }\n        }\n      } else {\n\n        FileInputStream fis;\n        try {\n          fis = new FileInputStream(file);\n        } catch (FileNotFoundException fnfe) {\n          // at least on windows, some temporary files raise this exception with an \"access denied\" message\n          // checking if the file can be read doesn't help\n          return;\n        }\n\n        try {\n\n          // make a new, empty document\n          Document doc = new Document();\n\n          // Add the path of the file as a field named \"path\".  Use a\n          // field that is indexed (i.e. searchable), but don't tokenize \n          // the field into separate words and don't index term frequency\n          // or positional information:\n          Field pathField = new Field(\"path\", StringField.TYPE_STORED, file.getPath());\n          doc.add(pathField);\n\n          // Add the last modified date of the file a field named \"modified\".\n          // Use a NumericField that is indexed (i.e. efficiently filterable with\n          // NumericRangeFilter).  This indexes to milli-second resolution, which\n          // is often too fine.  You could instead create a number based on\n          // year/month/day/hour/minutes/seconds, down the resolution you require.\n          // For example the long value 2011021714 would mean\n          // February 17, 2011, 2-3 PM.\n          NumericField modifiedField = new NumericField(\"modified\");\n          modifiedField.setLongValue(file.lastModified());\n          doc.add(modifiedField);\n\n          // Add the contents of the file to a field named \"contents\".  Specify a Reader,\n          // so that the text of the file is tokenized and indexed, but not stored.\n          // Note that FileReader expects the file to be in UTF-8 encoding.\n          // If that's not the case searching for special characters will fail.\n          doc.add(new TextField(\"contents\", new BufferedReader(new InputStreamReader(fis, \"UTF-8\"))));\n\n          if (writer.getConfig().getOpenMode() == OpenMode.CREATE) {\n            // New index, so we just add the document (no old document can be there):\n            System.out.println(\"adding \" + file);\n            writer.addDocument(doc);\n          } else {\n            // Existing index (an old copy of this document may have been indexed) so \n            // we use updateDocument instead to replace the old one matching the exact \n            // path, if present:\n            System.out.println(\"updating \" + file);\n            writer.updateDocument(new Term(\"path\", file.getPath()), doc);\n          }\n          \n        } finally {\n          fis.close();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fa0f44f887719e97183771e977cfc4bfb485b766","date":1326668713,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/contrib/demo/src/java/org/apache/lucene/demo/IndexFiles#indexDocs(IndexWriter,File).mjava","pathOld":"lucene/contrib/demo/src/java/org/apache/lucene/demo/IndexFiles#indexDocs(IndexWriter,File).mjava","sourceNew":"  /**\n   * Indexes the given file using the given writer, or if a directory is given,\n   * recurses over files and directories found under the given directory.\n   * \n   * NOTE: This method indexes one document per input file.  This is slow.  For good\n   * throughput, put multiple documents into your input file(s).  An example of this is\n   * in the benchmark module, which can create \"line doc\" files, one document per line,\n   * using the\n   * <a href=\"../../../../../contrib-benchmark/org/apache/lucene/benchmark/byTask/tasks/WriteLineDocTask.html\"\n   * >WriteLineDocTask</a>.\n   *  \n   * @param writer Writer to the index where the given file/dir info will be stored\n   * @param file The file to index, or the directory to recurse into to find files to index\n   * @throws IOException\n   */\n  static void indexDocs(IndexWriter writer, File file)\n    throws IOException {\n    // do not try to index files that cannot be read\n    if (file.canRead()) {\n      if (file.isDirectory()) {\n        String[] files = file.list();\n        // an IO error could occur\n        if (files != null) {\n          for (int i = 0; i < files.length; i++) {\n            indexDocs(writer, new File(file, files[i]));\n          }\n        }\n      } else {\n\n        FileInputStream fis;\n        try {\n          fis = new FileInputStream(file);\n        } catch (FileNotFoundException fnfe) {\n          // at least on windows, some temporary files raise this exception with an \"access denied\" message\n          // checking if the file can be read doesn't help\n          return;\n        }\n\n        try {\n\n          // make a new, empty document\n          Document doc = new Document();\n\n          // Add the path of the file as a field named \"path\".  Use a\n          // field that is indexed (i.e. searchable), but don't tokenize \n          // the field into separate words and don't index term frequency\n          // or positional information:\n          Field pathField = new Field(\"path\", file.getPath(), StringField.TYPE_STORED);\n          doc.add(pathField);\n\n          // Add the last modified date of the file a field named \"modified\".\n          // Use a NumericField that is indexed (i.e. efficiently filterable with\n          // NumericRangeFilter).  This indexes to milli-second resolution, which\n          // is often too fine.  You could instead create a number based on\n          // year/month/day/hour/minutes/seconds, down the resolution you require.\n          // For example the long value 2011021714 would mean\n          // February 17, 2011, 2-3 PM.\n          doc.add(new NumericField(\"modified\", file.lastModified()));\n\n          // Add the contents of the file to a field named \"contents\".  Specify a Reader,\n          // so that the text of the file is tokenized and indexed, but not stored.\n          // Note that FileReader expects the file to be in UTF-8 encoding.\n          // If that's not the case searching for special characters will fail.\n          doc.add(new TextField(\"contents\", new BufferedReader(new InputStreamReader(fis, \"UTF-8\"))));\n\n          if (writer.getConfig().getOpenMode() == OpenMode.CREATE) {\n            // New index, so we just add the document (no old document can be there):\n            System.out.println(\"adding \" + file);\n            writer.addDocument(doc);\n          } else {\n            // Existing index (an old copy of this document may have been indexed) so \n            // we use updateDocument instead to replace the old one matching the exact \n            // path, if present:\n            System.out.println(\"updating \" + file);\n            writer.updateDocument(new Term(\"path\", file.getPath()), doc);\n          }\n          \n        } finally {\n          fis.close();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Indexes the given file using the given writer, or if a directory is given,\n   * recurses over files and directories found under the given directory.\n   * \n   * NOTE: This method indexes one document per input file.  This is slow.  For good\n   * throughput, put multiple documents into your input file(s).  An example of this is\n   * in the benchmark module, which can create \"line doc\" files, one document per line,\n   * using the\n   * <a href=\"../../../../../contrib-benchmark/org/apache/lucene/benchmark/byTask/tasks/WriteLineDocTask.html\"\n   * >WriteLineDocTask</a>.\n   *  \n   * @param writer Writer to the index where the given file/dir info will be stored\n   * @param file The file to index, or the directory to recurse into to find files to index\n   * @throws IOException\n   */\n  static void indexDocs(IndexWriter writer, File file)\n    throws IOException {\n    // do not try to index files that cannot be read\n    if (file.canRead()) {\n      if (file.isDirectory()) {\n        String[] files = file.list();\n        // an IO error could occur\n        if (files != null) {\n          for (int i = 0; i < files.length; i++) {\n            indexDocs(writer, new File(file, files[i]));\n          }\n        }\n      } else {\n\n        FileInputStream fis;\n        try {\n          fis = new FileInputStream(file);\n        } catch (FileNotFoundException fnfe) {\n          // at least on windows, some temporary files raise this exception with an \"access denied\" message\n          // checking if the file can be read doesn't help\n          return;\n        }\n\n        try {\n\n          // make a new, empty document\n          Document doc = new Document();\n\n          // Add the path of the file as a field named \"path\".  Use a\n          // field that is indexed (i.e. searchable), but don't tokenize \n          // the field into separate words and don't index term frequency\n          // or positional information:\n          Field pathField = new Field(\"path\", file.getPath(), StringField.TYPE_STORED);\n          doc.add(pathField);\n\n          // Add the last modified date of the file a field named \"modified\".\n          // Use a NumericField that is indexed (i.e. efficiently filterable with\n          // NumericRangeFilter).  This indexes to milli-second resolution, which\n          // is often too fine.  You could instead create a number based on\n          // year/month/day/hour/minutes/seconds, down the resolution you require.\n          // For example the long value 2011021714 would mean\n          // February 17, 2011, 2-3 PM.\n          NumericField modifiedField = new NumericField(\"modified\");\n          modifiedField.setLongValue(file.lastModified());\n          doc.add(modifiedField);\n\n          // Add the contents of the file to a field named \"contents\".  Specify a Reader,\n          // so that the text of the file is tokenized and indexed, but not stored.\n          // Note that FileReader expects the file to be in UTF-8 encoding.\n          // If that's not the case searching for special characters will fail.\n          doc.add(new TextField(\"contents\", new BufferedReader(new InputStreamReader(fis, \"UTF-8\"))));\n\n          if (writer.getConfig().getOpenMode() == OpenMode.CREATE) {\n            // New index, so we just add the document (no old document can be there):\n            System.out.println(\"adding \" + file);\n            writer.addDocument(doc);\n          } else {\n            // Existing index (an old copy of this document may have been indexed) so \n            // we use updateDocument instead to replace the old one matching the exact \n            // path, if present:\n            System.out.println(\"updating \" + file);\n            writer.updateDocument(new Term(\"path\", file.getPath()), doc);\n          }\n          \n        } finally {\n          fis.close();\n        }\n      }\n    }\n  }\n\n","bugFix":["81ea17596392ebd5d12741eb9e3b2516258b9413"],"bugIntro":["a78a90fc9701e511308346ea29f4f5e548bb39fe"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a78a90fc9701e511308346ea29f4f5e548bb39fe","date":1329489995,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/contrib/demo/src/java/org/apache/lucene/demo/IndexFiles#indexDocs(IndexWriter,File).mjava","pathOld":"lucene/contrib/demo/src/java/org/apache/lucene/demo/IndexFiles#indexDocs(IndexWriter,File).mjava","sourceNew":"  /**\n   * Indexes the given file using the given writer, or if a directory is given,\n   * recurses over files and directories found under the given directory.\n   * \n   * NOTE: This method indexes one document per input file.  This is slow.  For good\n   * throughput, put multiple documents into your input file(s).  An example of this is\n   * in the benchmark module, which can create \"line doc\" files, one document per line,\n   * using the\n   * <a href=\"../../../../../contrib-benchmark/org/apache/lucene/benchmark/byTask/tasks/WriteLineDocTask.html\"\n   * >WriteLineDocTask</a>.\n   *  \n   * @param writer Writer to the index where the given file/dir info will be stored\n   * @param file The file to index, or the directory to recurse into to find files to index\n   * @throws IOException\n   */\n  static void indexDocs(IndexWriter writer, File file)\n    throws IOException {\n    // do not try to index files that cannot be read\n    if (file.canRead()) {\n      if (file.isDirectory()) {\n        String[] files = file.list();\n        // an IO error could occur\n        if (files != null) {\n          for (int i = 0; i < files.length; i++) {\n            indexDocs(writer, new File(file, files[i]));\n          }\n        }\n      } else {\n\n        FileInputStream fis;\n        try {\n          fis = new FileInputStream(file);\n        } catch (FileNotFoundException fnfe) {\n          // at least on windows, some temporary files raise this exception with an \"access denied\" message\n          // checking if the file can be read doesn't help\n          return;\n        }\n\n        try {\n\n          // make a new, empty document\n          Document doc = new Document();\n\n          // Add the path of the file as a field named \"path\".  Use a\n          // field that is indexed (i.e. searchable), but don't tokenize \n          // the field into separate words and don't index term frequency\n          // or positional information:\n          Field pathField = new Field(\"path\", file.getPath(), StringField.TYPE_STORED);\n          doc.add(pathField);\n\n          // Add the last modified date of the file a field named \"modified\".\n          // Use a LongField that is indexed (i.e. efficiently filterable with\n          // NumericRangeFilter).  This indexes to milli-second resolution, which\n          // is often too fine.  You could instead create a number based on\n          // year/month/day/hour/minutes/seconds, down the resolution you require.\n          // For example the long value 2011021714 would mean\n          // February 17, 2011, 2-3 PM.\n          doc.add(new LongField(\"modified\", file.lastModified()));\n\n          // Add the contents of the file to a field named \"contents\".  Specify a Reader,\n          // so that the text of the file is tokenized and indexed, but not stored.\n          // Note that FileReader expects the file to be in UTF-8 encoding.\n          // If that's not the case searching for special characters will fail.\n          doc.add(new TextField(\"contents\", new BufferedReader(new InputStreamReader(fis, \"UTF-8\"))));\n\n          if (writer.getConfig().getOpenMode() == OpenMode.CREATE) {\n            // New index, so we just add the document (no old document can be there):\n            System.out.println(\"adding \" + file);\n            writer.addDocument(doc);\n          } else {\n            // Existing index (an old copy of this document may have been indexed) so \n            // we use updateDocument instead to replace the old one matching the exact \n            // path, if present:\n            System.out.println(\"updating \" + file);\n            writer.updateDocument(new Term(\"path\", file.getPath()), doc);\n          }\n          \n        } finally {\n          fis.close();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Indexes the given file using the given writer, or if a directory is given,\n   * recurses over files and directories found under the given directory.\n   * \n   * NOTE: This method indexes one document per input file.  This is slow.  For good\n   * throughput, put multiple documents into your input file(s).  An example of this is\n   * in the benchmark module, which can create \"line doc\" files, one document per line,\n   * using the\n   * <a href=\"../../../../../contrib-benchmark/org/apache/lucene/benchmark/byTask/tasks/WriteLineDocTask.html\"\n   * >WriteLineDocTask</a>.\n   *  \n   * @param writer Writer to the index where the given file/dir info will be stored\n   * @param file The file to index, or the directory to recurse into to find files to index\n   * @throws IOException\n   */\n  static void indexDocs(IndexWriter writer, File file)\n    throws IOException {\n    // do not try to index files that cannot be read\n    if (file.canRead()) {\n      if (file.isDirectory()) {\n        String[] files = file.list();\n        // an IO error could occur\n        if (files != null) {\n          for (int i = 0; i < files.length; i++) {\n            indexDocs(writer, new File(file, files[i]));\n          }\n        }\n      } else {\n\n        FileInputStream fis;\n        try {\n          fis = new FileInputStream(file);\n        } catch (FileNotFoundException fnfe) {\n          // at least on windows, some temporary files raise this exception with an \"access denied\" message\n          // checking if the file can be read doesn't help\n          return;\n        }\n\n        try {\n\n          // make a new, empty document\n          Document doc = new Document();\n\n          // Add the path of the file as a field named \"path\".  Use a\n          // field that is indexed (i.e. searchable), but don't tokenize \n          // the field into separate words and don't index term frequency\n          // or positional information:\n          Field pathField = new Field(\"path\", file.getPath(), StringField.TYPE_STORED);\n          doc.add(pathField);\n\n          // Add the last modified date of the file a field named \"modified\".\n          // Use a NumericField that is indexed (i.e. efficiently filterable with\n          // NumericRangeFilter).  This indexes to milli-second resolution, which\n          // is often too fine.  You could instead create a number based on\n          // year/month/day/hour/minutes/seconds, down the resolution you require.\n          // For example the long value 2011021714 would mean\n          // February 17, 2011, 2-3 PM.\n          doc.add(new NumericField(\"modified\", file.lastModified()));\n\n          // Add the contents of the file to a field named \"contents\".  Specify a Reader,\n          // so that the text of the file is tokenized and indexed, but not stored.\n          // Note that FileReader expects the file to be in UTF-8 encoding.\n          // If that's not the case searching for special characters will fail.\n          doc.add(new TextField(\"contents\", new BufferedReader(new InputStreamReader(fis, \"UTF-8\"))));\n\n          if (writer.getConfig().getOpenMode() == OpenMode.CREATE) {\n            // New index, so we just add the document (no old document can be there):\n            System.out.println(\"adding \" + file);\n            writer.addDocument(doc);\n          } else {\n            // Existing index (an old copy of this document may have been indexed) so \n            // we use updateDocument instead to replace the old one matching the exact \n            // path, if present:\n            System.out.println(\"updating \" + file);\n            writer.updateDocument(new Term(\"path\", file.getPath()), doc);\n          }\n          \n        } finally {\n          fis.close();\n        }\n      }\n    }\n  }\n\n","bugFix":["fa0f44f887719e97183771e977cfc4bfb485b766","81ea17596392ebd5d12741eb9e3b2516258b9413"],"bugIntro":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/demo/src/java/org/apache/lucene/demo/IndexFiles#indexDocs(IndexWriter,File).mjava","pathOld":"lucene/contrib/demo/src/java/org/apache/lucene/demo/IndexFiles#indexDocs(IndexWriter,File).mjava","sourceNew":"  /**\n   * Indexes the given file using the given writer, or if a directory is given,\n   * recurses over files and directories found under the given directory.\n   * \n   * NOTE: This method indexes one document per input file.  This is slow.  For good\n   * throughput, put multiple documents into your input file(s).  An example of this is\n   * in the benchmark module, which can create \"line doc\" files, one document per line,\n   * using the\n   * <a href=\"../../../../../contrib-benchmark/org/apache/lucene/benchmark/byTask/tasks/WriteLineDocTask.html\"\n   * >WriteLineDocTask</a>.\n   *  \n   * @param writer Writer to the index where the given file/dir info will be stored\n   * @param file The file to index, or the directory to recurse into to find files to index\n   * @throws IOException\n   */\n  static void indexDocs(IndexWriter writer, File file)\n    throws IOException {\n    // do not try to index files that cannot be read\n    if (file.canRead()) {\n      if (file.isDirectory()) {\n        String[] files = file.list();\n        // an IO error could occur\n        if (files != null) {\n          for (int i = 0; i < files.length; i++) {\n            indexDocs(writer, new File(file, files[i]));\n          }\n        }\n      } else {\n\n        FileInputStream fis;\n        try {\n          fis = new FileInputStream(file);\n        } catch (FileNotFoundException fnfe) {\n          // at least on windows, some temporary files raise this exception with an \"access denied\" message\n          // checking if the file can be read doesn't help\n          return;\n        }\n\n        try {\n\n          // make a new, empty document\n          Document doc = new Document();\n\n          // Add the path of the file as a field named \"path\".  Use a\n          // field that is indexed (i.e. searchable), but don't tokenize \n          // the field into separate words and don't index term frequency\n          // or positional information:\n          Field pathField = new Field(\"path\", file.getPath(), StringField.TYPE_STORED);\n          doc.add(pathField);\n\n          // Add the last modified date of the file a field named \"modified\".\n          // Use a LongField that is indexed (i.e. efficiently filterable with\n          // NumericRangeFilter).  This indexes to milli-second resolution, which\n          // is often too fine.  You could instead create a number based on\n          // year/month/day/hour/minutes/seconds, down the resolution you require.\n          // For example the long value 2011021714 would mean\n          // February 17, 2011, 2-3 PM.\n          doc.add(new LongField(\"modified\", file.lastModified()));\n\n          // Add the contents of the file to a field named \"contents\".  Specify a Reader,\n          // so that the text of the file is tokenized and indexed, but not stored.\n          // Note that FileReader expects the file to be in UTF-8 encoding.\n          // If that's not the case searching for special characters will fail.\n          doc.add(new TextField(\"contents\", new BufferedReader(new InputStreamReader(fis, \"UTF-8\"))));\n\n          if (writer.getConfig().getOpenMode() == OpenMode.CREATE) {\n            // New index, so we just add the document (no old document can be there):\n            System.out.println(\"adding \" + file);\n            writer.addDocument(doc);\n          } else {\n            // Existing index (an old copy of this document may have been indexed) so \n            // we use updateDocument instead to replace the old one matching the exact \n            // path, if present:\n            System.out.println(\"updating \" + file);\n            writer.updateDocument(new Term(\"path\", file.getPath()), doc);\n          }\n          \n        } finally {\n          fis.close();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Indexes the given file using the given writer, or if a directory is given,\n   * recurses over files and directories found under the given directory.\n   * \n   * NOTE: This method indexes one document per input file.  This is slow.  For good\n   * throughput, put multiple documents into your input file(s).  An example of this is\n   * in the benchmark module, which can create \"line doc\" files, one document per line,\n   * using the\n   * <a href=\"../../../../../contrib-benchmark/org/apache/lucene/benchmark/byTask/tasks/WriteLineDocTask.html\"\n   * >WriteLineDocTask</a>.\n   *  \n   * @param writer Writer to the index where the given file/dir info will be stored\n   * @param file The file to index, or the directory to recurse into to find files to index\n   * @throws IOException\n   */\n  static void indexDocs(IndexWriter writer, File file)\n    throws IOException {\n    // do not try to index files that cannot be read\n    if (file.canRead()) {\n      if (file.isDirectory()) {\n        String[] files = file.list();\n        // an IO error could occur\n        if (files != null) {\n          for (int i = 0; i < files.length; i++) {\n            indexDocs(writer, new File(file, files[i]));\n          }\n        }\n      } else {\n\n        FileInputStream fis;\n        try {\n          fis = new FileInputStream(file);\n        } catch (FileNotFoundException fnfe) {\n          // at least on windows, some temporary files raise this exception with an \"access denied\" message\n          // checking if the file can be read doesn't help\n          return;\n        }\n\n        try {\n\n          // make a new, empty document\n          Document doc = new Document();\n\n          // Add the path of the file as a field named \"path\".  Use a\n          // field that is indexed (i.e. searchable), but don't tokenize \n          // the field into separate words and don't index term frequency\n          // or positional information:\n          Field pathField = new Field(\"path\", file.getPath(), StringField.TYPE_STORED);\n          doc.add(pathField);\n\n          // Add the last modified date of the file a field named \"modified\".\n          // Use a LongField that is indexed (i.e. efficiently filterable with\n          // NumericRangeFilter).  This indexes to milli-second resolution, which\n          // is often too fine.  You could instead create a number based on\n          // year/month/day/hour/minutes/seconds, down the resolution you require.\n          // For example the long value 2011021714 would mean\n          // February 17, 2011, 2-3 PM.\n          doc.add(new LongField(\"modified\", file.lastModified()));\n\n          // Add the contents of the file to a field named \"contents\".  Specify a Reader,\n          // so that the text of the file is tokenized and indexed, but not stored.\n          // Note that FileReader expects the file to be in UTF-8 encoding.\n          // If that's not the case searching for special characters will fail.\n          doc.add(new TextField(\"contents\", new BufferedReader(new InputStreamReader(fis, \"UTF-8\"))));\n\n          if (writer.getConfig().getOpenMode() == OpenMode.CREATE) {\n            // New index, so we just add the document (no old document can be there):\n            System.out.println(\"adding \" + file);\n            writer.addDocument(doc);\n          } else {\n            // Existing index (an old copy of this document may have been indexed) so \n            // we use updateDocument instead to replace the old one matching the exact \n            // path, if present:\n            System.out.println(\"updating \" + file);\n            writer.updateDocument(new Term(\"path\", file.getPath()), doc);\n          }\n          \n        } finally {\n          fis.close();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"2afd23a6f1242190c3409d8d81d5c5912d607fc9":["81ea17596392ebd5d12741eb9e3b2516258b9413"],"a78a90fc9701e511308346ea29f4f5e548bb39fe":["fa0f44f887719e97183771e977cfc4bfb485b766"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["a78a90fc9701e511308346ea29f4f5e548bb39fe"],"f1bdbf92da222965b46c0a942c3857ba56e5c638":["790c3f61c9b891d66d919c5d10db9fa5216eb0f1","81ea17596392ebd5d12741eb9e3b2516258b9413"],"81ea17596392ebd5d12741eb9e3b2516258b9413":["790c3f61c9b891d66d919c5d10db9fa5216eb0f1"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"fa0f44f887719e97183771e977cfc4bfb485b766":["7e4db59c6b6c10e25322cfb41c4c19d78b4298bd"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["2afd23a6f1242190c3409d8d81d5c5912d607fc9"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["790c3f61c9b891d66d919c5d10db9fa5216eb0f1","81ea17596392ebd5d12741eb9e3b2516258b9413"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"7e4db59c6b6c10e25322cfb41c4c19d78b4298bd":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"790c3f61c9b891d66d919c5d10db9fa5216eb0f1":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"2afd23a6f1242190c3409d8d81d5c5912d607fc9":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"a78a90fc9701e511308346ea29f4f5e548bb39fe":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"f1bdbf92da222965b46c0a942c3857ba56e5c638":[],"81ea17596392ebd5d12741eb9e3b2516258b9413":["2afd23a6f1242190c3409d8d81d5c5912d607fc9","f1bdbf92da222965b46c0a942c3857ba56e5c638","bde51b089eb7f86171eb3406e38a274743f9b7ac"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["790c3f61c9b891d66d919c5d10db9fa5216eb0f1"],"fa0f44f887719e97183771e977cfc4bfb485b766":["a78a90fc9701e511308346ea29f4f5e548bb39fe"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["7e4db59c6b6c10e25322cfb41c4c19d78b4298bd"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":[],"790c3f61c9b891d66d919c5d10db9fa5216eb0f1":["f1bdbf92da222965b46c0a942c3857ba56e5c638","81ea17596392ebd5d12741eb9e3b2516258b9413","bde51b089eb7f86171eb3406e38a274743f9b7ac"],"7e4db59c6b6c10e25322cfb41c4c19d78b4298bd":["fa0f44f887719e97183771e977cfc4bfb485b766"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["f1bdbf92da222965b46c0a942c3857ba56e5c638","bde51b089eb7f86171eb3406e38a274743f9b7ac","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}