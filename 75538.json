{"path":"lucene/src/java/org/apache/lucene/index/IndexWriter#addIndexesNoOptimize(Directory...).mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#addIndexesNoOptimize(Directory...).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#addIndexesNoOptimize(Directory...).mjava","sourceNew":"  /**\n   * Merges all segments from an array of indexes into this\n   * index.\n   *\n   * <p>This may be used to parallelize batch indexing.  A large document\n   * collection can be broken into sub-collections.  Each sub-collection can be\n   * indexed in parallel, on a different thread, process or machine.  The\n   * complete index can then be created by merging sub-collection indexes\n   * with this method.\n   *\n   * <p><b>NOTE:</b> the index in each Directory must not be\n   * changed (opened by a writer) while this method is\n   * running.  This method does not acquire a write lock in\n   * each input Directory, so it is up to the caller to\n   * enforce this.\n   *\n   * <p><b>NOTE:</b> while this is running, any attempts to\n   * add or delete documents (with another thread) will be\n   * paused until this method completes.\n   *\n   * <p>This method is transactional in how Exceptions are\n   * handled: it does not commit a new segments_N file until\n   * all indexes are added.  This means if an Exception\n   * occurs (for example disk full), then either no indexes\n   * will have been added or they all will have been.</p>\n   *\n   * <p>Note that this requires temporary free space in the\n   * Directory up to 2X the sum of all input indexes\n   * (including the starting index).  If readers/searchers\n   * are open against the starting index, then temporary\n   * free space required will be higher by the size of the\n   * starting index (see {@link #optimize()} for details).\n   * </p>\n   *\n   * <p>Once this completes, the final size of the index\n   * will be less than the sum of all input index sizes\n   * (including the starting index).  It could be quite a\n   * bit smaller (if there were many pending deletes) or\n   * just slightly smaller.</p>\n   * \n   * <p>\n   * This requires this index not be among those to be added.\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void addIndexesNoOptimize(Directory... dirs)\n      throws CorruptIndexException, IOException {\n\n    ensureOpen();\n\n    noDupDirs(dirs);\n\n    // Do not allow add docs or deletes while we are running:\n    docWriter.pauseAllThreads();\n\n    try {\n      if (infoStream != null)\n        message(\"flush at addIndexesNoOptimize\");\n      flush(true, false, true);\n\n      boolean success = false;\n\n      startTransaction(false);\n\n      try {\n\n        int docCount = 0;\n        synchronized(this) {\n          ensureOpen();\n\n          for (int i = 0; i < dirs.length; i++) {\n            if (directory == dirs[i]) {\n              // cannot add this index: segments may be deleted in merge before added\n              throw new IllegalArgumentException(\"Cannot add this index to itself\");\n            }\n\n            SegmentInfos sis = new SegmentInfos(); // read infos from dir\n            sis.read(dirs[i]);\n            for (int j = 0; j < sis.size(); j++) {\n              SegmentInfo info = sis.info(j);\n              assert !segmentInfos.contains(info): \"dup info dir=\" + info.dir + \" name=\" + info.name;\n              docCount += info.docCount;\n              segmentInfos.add(info); // add each info\n            }\n          }\n        }\n\n        // Notify DocumentsWriter that the flushed count just increased\n        docWriter.updateFlushedDocCount(docCount);\n\n        maybeMerge();\n\n        ensureOpen();\n\n        // If after merging there remain segments in the index\n        // that are in a different directory, just copy these\n        // over into our index.  This is necessary (before\n        // finishing the transaction) to avoid leaving the\n        // index in an unusable (inconsistent) state.\n        resolveExternalSegments();\n\n        ensureOpen();\n\n        success = true;\n\n      } finally {\n        if (success) {\n          commitTransaction();\n        } else {\n          rollbackTransaction();\n        }\n      }\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"addIndexesNoOptimize\");\n    } finally {\n      if (docWriter != null) {\n        docWriter.resumeAllThreads();\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Merges all segments from an array of indexes into this\n   * index.\n   *\n   * <p>This may be used to parallelize batch indexing.  A large document\n   * collection can be broken into sub-collections.  Each sub-collection can be\n   * indexed in parallel, on a different thread, process or machine.  The\n   * complete index can then be created by merging sub-collection indexes\n   * with this method.\n   *\n   * <p><b>NOTE:</b> the index in each Directory must not be\n   * changed (opened by a writer) while this method is\n   * running.  This method does not acquire a write lock in\n   * each input Directory, so it is up to the caller to\n   * enforce this.\n   *\n   * <p><b>NOTE:</b> while this is running, any attempts to\n   * add or delete documents (with another thread) will be\n   * paused until this method completes.\n   *\n   * <p>This method is transactional in how Exceptions are\n   * handled: it does not commit a new segments_N file until\n   * all indexes are added.  This means if an Exception\n   * occurs (for example disk full), then either no indexes\n   * will have been added or they all will have been.</p>\n   *\n   * <p>Note that this requires temporary free space in the\n   * Directory up to 2X the sum of all input indexes\n   * (including the starting index).  If readers/searchers\n   * are open against the starting index, then temporary\n   * free space required will be higher by the size of the\n   * starting index (see {@link #optimize()} for details).\n   * </p>\n   *\n   * <p>Once this completes, the final size of the index\n   * will be less than the sum of all input index sizes\n   * (including the starting index).  It could be quite a\n   * bit smaller (if there were many pending deletes) or\n   * just slightly smaller.</p>\n   * \n   * <p>\n   * This requires this index not be among those to be added.\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void addIndexesNoOptimize(Directory... dirs)\n      throws CorruptIndexException, IOException {\n\n    ensureOpen();\n\n    noDupDirs(dirs);\n\n    // Do not allow add docs or deletes while we are running:\n    docWriter.pauseAllThreads();\n\n    try {\n      if (infoStream != null)\n        message(\"flush at addIndexesNoOptimize\");\n      flush(true, false, true);\n\n      boolean success = false;\n\n      startTransaction(false);\n\n      try {\n\n        int docCount = 0;\n        synchronized(this) {\n          ensureOpen();\n\n          for (int i = 0; i < dirs.length; i++) {\n            if (directory == dirs[i]) {\n              // cannot add this index: segments may be deleted in merge before added\n              throw new IllegalArgumentException(\"Cannot add this index to itself\");\n            }\n\n            SegmentInfos sis = new SegmentInfos(); // read infos from dir\n            sis.read(dirs[i]);\n            for (int j = 0; j < sis.size(); j++) {\n              SegmentInfo info = sis.info(j);\n              assert !segmentInfos.contains(info): \"dup info dir=\" + info.dir + \" name=\" + info.name;\n              docCount += info.docCount;\n              segmentInfos.add(info); // add each info\n            }\n          }\n        }\n\n        // Notify DocumentsWriter that the flushed count just increased\n        docWriter.updateFlushedDocCount(docCount);\n\n        maybeMerge();\n\n        ensureOpen();\n\n        // If after merging there remain segments in the index\n        // that are in a different directory, just copy these\n        // over into our index.  This is necessary (before\n        // finishing the transaction) to avoid leaving the\n        // index in an unusable (inconsistent) state.\n        resolveExternalSegments();\n\n        ensureOpen();\n\n        success = true;\n\n      } finally {\n        if (success) {\n          commitTransaction();\n        } else {\n          rollbackTransaction();\n        }\n      }\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"addIndexesNoOptimize\");\n    } finally {\n      if (docWriter != null) {\n        docWriter.resumeAllThreads();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"955c32f886db6f6356c9fcdea6b1f1cb4effda24","date":1270581567,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#addIndexesNoOptimize(Directory...).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#addIndexesNoOptimize(Directory...).mjava","sourceNew":"  /**\n   * Merges all segments from an array of indexes into this\n   * index.\n   *\n   * <p>This may be used to parallelize batch indexing.  A large document\n   * collection can be broken into sub-collections.  Each sub-collection can be\n   * indexed in parallel, on a different thread, process or machine.  The\n   * complete index can then be created by merging sub-collection indexes\n   * with this method.\n   *\n   * <p><b>NOTE:</b> the index in each Directory must not be\n   * changed (opened by a writer) while this method is\n   * running.  This method does not acquire a write lock in\n   * each input Directory, so it is up to the caller to\n   * enforce this.\n   *\n   * <p><b>NOTE:</b> while this is running, any attempts to\n   * add or delete documents (with another thread) will be\n   * paused until this method completes.\n   *\n   * <p>This method is transactional in how Exceptions are\n   * handled: it does not commit a new segments_N file until\n   * all indexes are added.  This means if an Exception\n   * occurs (for example disk full), then either no indexes\n   * will have been added or they all will have been.</p>\n   *\n   * <p>Note that this requires temporary free space in the\n   * Directory up to 2X the sum of all input indexes\n   * (including the starting index).  If readers/searchers\n   * are open against the starting index, then temporary\n   * free space required will be higher by the size of the\n   * starting index (see {@link #optimize()} for details).\n   * </p>\n   *\n   * <p>Once this completes, the final size of the index\n   * will be less than the sum of all input index sizes\n   * (including the starting index).  It could be quite a\n   * bit smaller (if there were many pending deletes) or\n   * just slightly smaller.</p>\n   * \n   * <p>\n   * This requires this index not be among those to be added.\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void addIndexesNoOptimize(Directory... dirs)\n      throws CorruptIndexException, IOException {\n\n    ensureOpen();\n\n    noDupDirs(dirs);\n\n    // Do not allow add docs or deletes while we are running:\n    docWriter.pauseAllThreads();\n\n    try {\n      if (infoStream != null)\n        message(\"flush at addIndexesNoOptimize\");\n      flush(true, false, true);\n\n      boolean success = false;\n\n      startTransaction(false);\n\n      try {\n\n        int docCount = 0;\n        synchronized(this) {\n          ensureOpen();\n\n          for (int i = 0; i < dirs.length; i++) {\n            if (directory == dirs[i]) {\n              // cannot add this index: segments may be deleted in merge before added\n              throw new IllegalArgumentException(\"Cannot add this index to itself\");\n            }\n\n            SegmentInfos sis = new SegmentInfos(); // read infos from dir\n            sis.read(dirs[i], codecs);\n            for (int j = 0; j < sis.size(); j++) {\n              SegmentInfo info = sis.info(j);\n              assert !segmentInfos.contains(info): \"dup info dir=\" + info.dir + \" name=\" + info.name;\n              docCount += info.docCount;\n              segmentInfos.add(info); // add each info\n            }\n          }\n        }\n\n        // Notify DocumentsWriter that the flushed count just increased\n        docWriter.updateFlushedDocCount(docCount);\n\n        maybeMerge();\n\n        ensureOpen();\n\n        // If after merging there remain segments in the index\n        // that are in a different directory, just copy these\n        // over into our index.  This is necessary (before\n        // finishing the transaction) to avoid leaving the\n        // index in an unusable (inconsistent) state.\n        resolveExternalSegments();\n\n        ensureOpen();\n\n        success = true;\n\n      } finally {\n        if (success) {\n          commitTransaction();\n        } else {\n          rollbackTransaction();\n        }\n      }\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"addIndexesNoOptimize\");\n    } finally {\n      if (docWriter != null) {\n        docWriter.resumeAllThreads();\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Merges all segments from an array of indexes into this\n   * index.\n   *\n   * <p>This may be used to parallelize batch indexing.  A large document\n   * collection can be broken into sub-collections.  Each sub-collection can be\n   * indexed in parallel, on a different thread, process or machine.  The\n   * complete index can then be created by merging sub-collection indexes\n   * with this method.\n   *\n   * <p><b>NOTE:</b> the index in each Directory must not be\n   * changed (opened by a writer) while this method is\n   * running.  This method does not acquire a write lock in\n   * each input Directory, so it is up to the caller to\n   * enforce this.\n   *\n   * <p><b>NOTE:</b> while this is running, any attempts to\n   * add or delete documents (with another thread) will be\n   * paused until this method completes.\n   *\n   * <p>This method is transactional in how Exceptions are\n   * handled: it does not commit a new segments_N file until\n   * all indexes are added.  This means if an Exception\n   * occurs (for example disk full), then either no indexes\n   * will have been added or they all will have been.</p>\n   *\n   * <p>Note that this requires temporary free space in the\n   * Directory up to 2X the sum of all input indexes\n   * (including the starting index).  If readers/searchers\n   * are open against the starting index, then temporary\n   * free space required will be higher by the size of the\n   * starting index (see {@link #optimize()} for details).\n   * </p>\n   *\n   * <p>Once this completes, the final size of the index\n   * will be less than the sum of all input index sizes\n   * (including the starting index).  It could be quite a\n   * bit smaller (if there were many pending deletes) or\n   * just slightly smaller.</p>\n   * \n   * <p>\n   * This requires this index not be among those to be added.\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void addIndexesNoOptimize(Directory... dirs)\n      throws CorruptIndexException, IOException {\n\n    ensureOpen();\n\n    noDupDirs(dirs);\n\n    // Do not allow add docs or deletes while we are running:\n    docWriter.pauseAllThreads();\n\n    try {\n      if (infoStream != null)\n        message(\"flush at addIndexesNoOptimize\");\n      flush(true, false, true);\n\n      boolean success = false;\n\n      startTransaction(false);\n\n      try {\n\n        int docCount = 0;\n        synchronized(this) {\n          ensureOpen();\n\n          for (int i = 0; i < dirs.length; i++) {\n            if (directory == dirs[i]) {\n              // cannot add this index: segments may be deleted in merge before added\n              throw new IllegalArgumentException(\"Cannot add this index to itself\");\n            }\n\n            SegmentInfos sis = new SegmentInfos(); // read infos from dir\n            sis.read(dirs[i]);\n            for (int j = 0; j < sis.size(); j++) {\n              SegmentInfo info = sis.info(j);\n              assert !segmentInfos.contains(info): \"dup info dir=\" + info.dir + \" name=\" + info.name;\n              docCount += info.docCount;\n              segmentInfos.add(info); // add each info\n            }\n          }\n        }\n\n        // Notify DocumentsWriter that the flushed count just increased\n        docWriter.updateFlushedDocCount(docCount);\n\n        maybeMerge();\n\n        ensureOpen();\n\n        // If after merging there remain segments in the index\n        // that are in a different directory, just copy these\n        // over into our index.  This is necessary (before\n        // finishing the transaction) to avoid leaving the\n        // index in an unusable (inconsistent) state.\n        resolveExternalSegments();\n\n        ensureOpen();\n\n        success = true;\n\n      } finally {\n        if (success) {\n          commitTransaction();\n        } else {\n          rollbackTransaction();\n        }\n      }\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"addIndexesNoOptimize\");\n    } finally {\n      if (docWriter != null) {\n        docWriter.resumeAllThreads();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fb10b6bcde550b87d8f10e5f010bd8f3021023b6","date":1274974592,"type":4,"author":"Shai Erera","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#addIndexesNoOptimize(Directory...).mjava","sourceNew":null,"sourceOld":"  /**\n   * Merges all segments from an array of indexes into this\n   * index.\n   *\n   * <p>This may be used to parallelize batch indexing.  A large document\n   * collection can be broken into sub-collections.  Each sub-collection can be\n   * indexed in parallel, on a different thread, process or machine.  The\n   * complete index can then be created by merging sub-collection indexes\n   * with this method.\n   *\n   * <p><b>NOTE:</b> the index in each Directory must not be\n   * changed (opened by a writer) while this method is\n   * running.  This method does not acquire a write lock in\n   * each input Directory, so it is up to the caller to\n   * enforce this.\n   *\n   * <p><b>NOTE:</b> while this is running, any attempts to\n   * add or delete documents (with another thread) will be\n   * paused until this method completes.\n   *\n   * <p>This method is transactional in how Exceptions are\n   * handled: it does not commit a new segments_N file until\n   * all indexes are added.  This means if an Exception\n   * occurs (for example disk full), then either no indexes\n   * will have been added or they all will have been.</p>\n   *\n   * <p>Note that this requires temporary free space in the\n   * Directory up to 2X the sum of all input indexes\n   * (including the starting index).  If readers/searchers\n   * are open against the starting index, then temporary\n   * free space required will be higher by the size of the\n   * starting index (see {@link #optimize()} for details).\n   * </p>\n   *\n   * <p>Once this completes, the final size of the index\n   * will be less than the sum of all input index sizes\n   * (including the starting index).  It could be quite a\n   * bit smaller (if there were many pending deletes) or\n   * just slightly smaller.</p>\n   * \n   * <p>\n   * This requires this index not be among those to be added.\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void addIndexesNoOptimize(Directory... dirs)\n      throws CorruptIndexException, IOException {\n\n    ensureOpen();\n\n    noDupDirs(dirs);\n\n    // Do not allow add docs or deletes while we are running:\n    docWriter.pauseAllThreads();\n\n    try {\n      if (infoStream != null)\n        message(\"flush at addIndexesNoOptimize\");\n      flush(true, false, true);\n\n      boolean success = false;\n\n      startTransaction(false);\n\n      try {\n\n        int docCount = 0;\n        synchronized(this) {\n          ensureOpen();\n\n          for (int i = 0; i < dirs.length; i++) {\n            if (directory == dirs[i]) {\n              // cannot add this index: segments may be deleted in merge before added\n              throw new IllegalArgumentException(\"Cannot add this index to itself\");\n            }\n\n            SegmentInfos sis = new SegmentInfos(); // read infos from dir\n            sis.read(dirs[i], codecs);\n            for (int j = 0; j < sis.size(); j++) {\n              SegmentInfo info = sis.info(j);\n              assert !segmentInfos.contains(info): \"dup info dir=\" + info.dir + \" name=\" + info.name;\n              docCount += info.docCount;\n              segmentInfos.add(info); // add each info\n            }\n          }\n        }\n\n        // Notify DocumentsWriter that the flushed count just increased\n        docWriter.updateFlushedDocCount(docCount);\n\n        maybeMerge();\n\n        ensureOpen();\n\n        // If after merging there remain segments in the index\n        // that are in a different directory, just copy these\n        // over into our index.  This is necessary (before\n        // finishing the transaction) to avoid leaving the\n        // index in an unusable (inconsistent) state.\n        resolveExternalSegments();\n\n        ensureOpen();\n\n        success = true;\n\n      } finally {\n        if (success) {\n          commitTransaction();\n        } else {\n          rollbackTransaction();\n        }\n      }\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"addIndexesNoOptimize\");\n    } finally {\n      if (docWriter != null) {\n        docWriter.resumeAllThreads();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"955c32f886db6f6356c9fcdea6b1f1cb4effda24":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["fb10b6bcde550b87d8f10e5f010bd8f3021023b6"],"fb10b6bcde550b87d8f10e5f010bd8f3021023b6":["955c32f886db6f6356c9fcdea6b1f1cb4effda24"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"955c32f886db6f6356c9fcdea6b1f1cb4effda24":["fb10b6bcde550b87d8f10e5f010bd8f3021023b6"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["955c32f886db6f6356c9fcdea6b1f1cb4effda24"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"fb10b6bcde550b87d8f10e5f010bd8f3021023b6":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}