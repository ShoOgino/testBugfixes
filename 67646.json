{"path":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertAnalyzesToReuse(Analyzer,String,String[],int[],int[],String[],int[]).mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertAnalyzesToReuse(Analyzer,String,String[],int[],int[],String[],int[]).mjava","pathOld":"lucene/src/test-framework/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertAnalyzesToReuse(Analyzer,String,String[],int[],int[],String[],int[]).mjava","sourceNew":"  public static void assertAnalyzesToReuse(Analyzer a, String input, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[]) throws IOException {\n    assertTokenStreamContents(a.tokenStream(\"dummy\", new StringReader(input)), output, startOffsets, endOffsets, types, posIncrements, input.length());\n  }\n\n","sourceOld":"  public static void assertAnalyzesToReuse(Analyzer a, String input, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[]) throws IOException {\n    assertTokenStreamContents(a.tokenStream(\"dummy\", new StringReader(input)), output, startOffsets, endOffsets, types, posIncrements, input.length());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0984ad47974c2d5d354519ddb2aa8358973a6271","date":1330868053,"type":3,"author":"Christian Moen","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertAnalyzesToReuse(Analyzer,String,String[],int[],int[],String[],int[]).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertAnalyzesToReuse(Analyzer,String,String[],int[],int[],String[],int[]).mjava","sourceNew":"  public static void assertAnalyzesToReuse(Analyzer a, String input, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[]) throws IOException {\n    assertTokenStreamContents(a.tokenStream(\"dummy\", new StringReader(input)), output, startOffsets, endOffsets, types, posIncrements, null, input.length());\n  }\n\n","sourceOld":"  public static void assertAnalyzesToReuse(Analyzer a, String input, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[]) throws IOException {\n    assertTokenStreamContents(a.tokenStream(\"dummy\", new StringReader(input)), output, startOffsets, endOffsets, types, posIncrements, input.length());\n  }\n\n","bugFix":null,"bugIntro":["c83d6c4335f31cae14f625a222bc842f20073dcd"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","date":1331075828,"type":3,"author":"Ryan McKinley","isMerge":true,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertAnalyzesToReuse(Analyzer,String,String[],int[],int[],String[],int[]).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertAnalyzesToReuse(Analyzer,String,String[],int[],int[],String[],int[]).mjava","sourceNew":"  public static void assertAnalyzesToReuse(Analyzer a, String input, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[]) throws IOException {\n    assertTokenStreamContents(a.tokenStream(\"dummy\", new StringReader(input)), output, startOffsets, endOffsets, types, posIncrements, null, input.length());\n  }\n\n","sourceOld":"  public static void assertAnalyzesToReuse(Analyzer a, String input, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[]) throws IOException {\n    assertTokenStreamContents(a.tokenStream(\"dummy\", new StringReader(input)), output, startOffsets, endOffsets, types, posIncrements, input.length());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c83d6c4335f31cae14f625a222bc842f20073dcd","date":1373306148,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertAnalyzesToReuse(Analyzer,String,String[],int[],int[],String[],int[]).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertAnalyzesToReuse(Analyzer,String,String[],int[],int[],String[],int[]).mjava","sourceNew":"  public static void assertAnalyzesToReuse(Analyzer a, String input, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[]) throws IOException {\n    assertTokenStreamContents(a.tokenStream(\"dummy\", input), output, startOffsets, endOffsets, types, posIncrements, null, input.length());\n  }\n\n","sourceOld":"  public static void assertAnalyzesToReuse(Analyzer a, String input, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[]) throws IOException {\n    assertTokenStreamContents(a.tokenStream(\"dummy\", new StringReader(input)), output, startOffsets, endOffsets, types, posIncrements, null, input.length());\n  }\n\n","bugFix":["0984ad47974c2d5d354519ddb2aa8358973a6271"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"37a0f60745e53927c4c876cfe5b5a58170f0646c","date":1373994005,"type":3,"author":"Han Jiang","isMerge":true,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertAnalyzesToReuse(Analyzer,String,String[],int[],int[],String[],int[]).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertAnalyzesToReuse(Analyzer,String,String[],int[],int[],String[],int[]).mjava","sourceNew":"  public static void assertAnalyzesToReuse(Analyzer a, String input, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[]) throws IOException {\n    assertTokenStreamContents(a.tokenStream(\"dummy\", input), output, startOffsets, endOffsets, types, posIncrements, null, input.length());\n  }\n\n","sourceOld":"  public static void assertAnalyzesToReuse(Analyzer a, String input, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[]) throws IOException {\n    assertTokenStreamContents(a.tokenStream(\"dummy\", new StringReader(input)), output, startOffsets, endOffsets, types, posIncrements, null, input.length());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"df1b735b811bfe6055a98336ee8dfd1e43cf2dc0","date":1379858263,"type":4,"author":"Uwe Schindler","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertAnalyzesToReuse(Analyzer,String,String[],int[],int[],String[],int[]).mjava","sourceNew":null,"sourceOld":"  public static void assertAnalyzesToReuse(Analyzer a, String input, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[]) throws IOException {\n    assertTokenStreamContents(a.tokenStream(\"dummy\", input), output, startOffsets, endOffsets, types, posIncrements, null, input.length());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"df1b735b811bfe6055a98336ee8dfd1e43cf2dc0":["c83d6c4335f31cae14f625a222bc842f20073dcd"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":["0984ad47974c2d5d354519ddb2aa8358973a6271","c83d6c4335f31cae14f625a222bc842f20073dcd"],"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab":["3a119bbc8703c10faa329ec201c654b3a35a1e3e","0984ad47974c2d5d354519ddb2aa8358973a6271"],"c83d6c4335f31cae14f625a222bc842f20073dcd":["0984ad47974c2d5d354519ddb2aa8358973a6271"],"0984ad47974c2d5d354519ddb2aa8358973a6271":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["df1b735b811bfe6055a98336ee8dfd1e43cf2dc0"]},"commit2Childs":{"df1b735b811bfe6055a98336ee8dfd1e43cf2dc0":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":[],"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab":[],"c83d6c4335f31cae14f625a222bc842f20073dcd":["df1b735b811bfe6055a98336ee8dfd1e43cf2dc0","37a0f60745e53927c4c876cfe5b5a58170f0646c"],"0984ad47974c2d5d354519ddb2aa8358973a6271":["37a0f60745e53927c4c876cfe5b5a58170f0646c","9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","c83d6c4335f31cae14f625a222bc842f20073dcd"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","0984ad47974c2d5d354519ddb2aa8358973a6271"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["37a0f60745e53927c4c876cfe5b5a58170f0646c","9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}