{"path":"lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets#testBasic().mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets#testBasic().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestPostingsOffsets#testBasic().mjava","sourceNew":"  public void testBasic() throws Exception {\n    Directory dir = newDirectory();\n    \n    RandomIndexWriter w = new RandomIndexWriter(random, dir, iwc);\n    Document doc = new Document();\n\n    FieldType ft = new FieldType(TextField.TYPE_UNSTORED);\n    ft.setIndexOptions(FieldInfo.IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Token[] tokens = new Token[] {\n      makeToken(\"a\", 1, 0, 6),\n      makeToken(\"b\", 1, 8, 9),\n      makeToken(\"a\", 1, 9, 17),\n      makeToken(\"c\", 1, 19, 50),\n    };\n    doc.add(new Field(\"content\", new CannedAnalyzer.CannedTokenizer(tokens), ft));\n\n    w.addDocument(doc, new CannedAnalyzer(tokens));\n    IndexReader r = w.getReader();\n    w.close();\n\n    DocsAndPositionsEnum dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"a\"), true);\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(2, dp.freq());\n    assertEquals(0, dp.nextPosition());\n    assertEquals(0, dp.startOffset());\n    assertEquals(6, dp.endOffset());\n    assertEquals(2, dp.nextPosition());\n    assertEquals(9, dp.startOffset());\n    assertEquals(17, dp.endOffset());\n    assertEquals(DocsEnum.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"b\"), true);\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(1, dp.nextPosition());\n    assertEquals(8, dp.startOffset());\n    assertEquals(9, dp.endOffset());\n    assertEquals(DocsEnum.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"c\"), true);\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(3, dp.nextPosition());\n    assertEquals(19, dp.startOffset());\n    assertEquals(50, dp.endOffset());\n    assertEquals(DocsEnum.NO_MORE_DOCS, dp.nextDoc());\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testBasic() throws Exception {\n    Directory dir = newDirectory();\n    \n    RandomIndexWriter w = new RandomIndexWriter(random, dir, iwc);\n    Document doc = new Document();\n\n    FieldType ft = new FieldType(TextField.TYPE_UNSTORED);\n    ft.setIndexOptions(FieldInfo.IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Token[] tokens = new Token[] {\n      makeToken(\"a\", 1, 0, 6),\n      makeToken(\"b\", 1, 8, 9),\n      makeToken(\"a\", 1, 9, 17),\n      makeToken(\"c\", 1, 19, 50),\n    };\n    doc.add(new Field(\"content\", new CannedAnalyzer.CannedTokenizer(tokens), ft));\n\n    w.addDocument(doc, new CannedAnalyzer(tokens));\n    IndexReader r = w.getReader();\n    w.close();\n\n    DocsAndPositionsEnum dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"a\"), true);\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(2, dp.freq());\n    assertEquals(0, dp.nextPosition());\n    assertEquals(0, dp.startOffset());\n    assertEquals(6, dp.endOffset());\n    assertEquals(2, dp.nextPosition());\n    assertEquals(9, dp.startOffset());\n    assertEquals(17, dp.endOffset());\n    assertEquals(DocsEnum.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"b\"), true);\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(1, dp.nextPosition());\n    assertEquals(8, dp.startOffset());\n    assertEquals(9, dp.endOffset());\n    assertEquals(DocsEnum.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"c\"), true);\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(3, dp.nextPosition());\n    assertEquals(19, dp.startOffset());\n    assertEquals(50, dp.endOffset());\n    assertEquals(DocsEnum.NO_MORE_DOCS, dp.nextDoc());\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6c2782fe88d18fedf3ef67402c9cb5a41978a8c7","date":1328901155,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets#testBasic().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets#testBasic().mjava","sourceNew":"  public void testBasic() throws Exception {\n    Directory dir = newDirectory();\n    \n    RandomIndexWriter w = new RandomIndexWriter(random, dir, iwc);\n    Document doc = new Document();\n\n    FieldType ft = new FieldType(TextField.TYPE_UNSTORED);\n    ft.setIndexOptions(FieldInfo.IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Token[] tokens = new Token[] {\n      makeToken(\"a\", 1, 0, 6),\n      makeToken(\"b\", 1, 8, 9),\n      makeToken(\"a\", 1, 9, 17),\n      makeToken(\"c\", 1, 19, 50),\n    };\n    doc.add(new Field(\"content\", new CannedTokenStream(tokens), ft));\n\n    w.addDocument(doc);\n    IndexReader r = w.getReader();\n    w.close();\n\n    DocsAndPositionsEnum dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"a\"), true);\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(2, dp.freq());\n    assertEquals(0, dp.nextPosition());\n    assertEquals(0, dp.startOffset());\n    assertEquals(6, dp.endOffset());\n    assertEquals(2, dp.nextPosition());\n    assertEquals(9, dp.startOffset());\n    assertEquals(17, dp.endOffset());\n    assertEquals(DocsEnum.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"b\"), true);\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(1, dp.nextPosition());\n    assertEquals(8, dp.startOffset());\n    assertEquals(9, dp.endOffset());\n    assertEquals(DocsEnum.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"c\"), true);\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(3, dp.nextPosition());\n    assertEquals(19, dp.startOffset());\n    assertEquals(50, dp.endOffset());\n    assertEquals(DocsEnum.NO_MORE_DOCS, dp.nextDoc());\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testBasic() throws Exception {\n    Directory dir = newDirectory();\n    \n    RandomIndexWriter w = new RandomIndexWriter(random, dir, iwc);\n    Document doc = new Document();\n\n    FieldType ft = new FieldType(TextField.TYPE_UNSTORED);\n    ft.setIndexOptions(FieldInfo.IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Token[] tokens = new Token[] {\n      makeToken(\"a\", 1, 0, 6),\n      makeToken(\"b\", 1, 8, 9),\n      makeToken(\"a\", 1, 9, 17),\n      makeToken(\"c\", 1, 19, 50),\n    };\n    doc.add(new Field(\"content\", new CannedAnalyzer.CannedTokenizer(tokens), ft));\n\n    w.addDocument(doc, new CannedAnalyzer(tokens));\n    IndexReader r = w.getReader();\n    w.close();\n\n    DocsAndPositionsEnum dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"a\"), true);\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(2, dp.freq());\n    assertEquals(0, dp.nextPosition());\n    assertEquals(0, dp.startOffset());\n    assertEquals(6, dp.endOffset());\n    assertEquals(2, dp.nextPosition());\n    assertEquals(9, dp.startOffset());\n    assertEquals(17, dp.endOffset());\n    assertEquals(DocsEnum.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"b\"), true);\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(1, dp.nextPosition());\n    assertEquals(8, dp.startOffset());\n    assertEquals(9, dp.endOffset());\n    assertEquals(DocsEnum.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"c\"), true);\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(3, dp.nextPosition());\n    assertEquals(19, dp.startOffset());\n    assertEquals(50, dp.endOffset());\n    assertEquals(DocsEnum.NO_MORE_DOCS, dp.nextDoc());\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f08557cdb6c60ac7b88a9342c983a20cd236e74f","date":1330954480,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets#testBasic().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets#testBasic().mjava","sourceNew":"  public void testBasic() throws Exception {\n    Directory dir = newDirectory();\n    \n    RandomIndexWriter w = new RandomIndexWriter(random, dir, iwc);\n    Document doc = new Document();\n\n    FieldType ft = new FieldType(TextField.TYPE_UNSTORED);\n    ft.setIndexOptions(FieldInfo.IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Token[] tokens = new Token[] {\n      makeToken(\"a\", 1, 0, 6),\n      makeToken(\"b\", 1, 8, 9),\n      makeToken(\"a\", 1, 9, 17),\n      makeToken(\"c\", 1, 19, 50),\n    };\n    doc.add(new Field(\"content\", new CannedTokenStream(tokens), ft));\n\n    w.addDocument(doc);\n    IndexReader r = w.getReader();\n    w.close();\n\n    DocsAndPositionsEnum dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"a\"), true);\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(2, dp.freq());\n    assertEquals(0, dp.nextPosition());\n    assertEquals(0, dp.startOffset());\n    assertEquals(6, dp.endOffset());\n    assertEquals(2, dp.nextPosition());\n    assertEquals(9, dp.startOffset());\n    assertEquals(17, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"b\"), true);\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(1, dp.nextPosition());\n    assertEquals(8, dp.startOffset());\n    assertEquals(9, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"c\"), true);\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(3, dp.nextPosition());\n    assertEquals(19, dp.startOffset());\n    assertEquals(50, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testBasic() throws Exception {\n    Directory dir = newDirectory();\n    \n    RandomIndexWriter w = new RandomIndexWriter(random, dir, iwc);\n    Document doc = new Document();\n\n    FieldType ft = new FieldType(TextField.TYPE_UNSTORED);\n    ft.setIndexOptions(FieldInfo.IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Token[] tokens = new Token[] {\n      makeToken(\"a\", 1, 0, 6),\n      makeToken(\"b\", 1, 8, 9),\n      makeToken(\"a\", 1, 9, 17),\n      makeToken(\"c\", 1, 19, 50),\n    };\n    doc.add(new Field(\"content\", new CannedTokenStream(tokens), ft));\n\n    w.addDocument(doc);\n    IndexReader r = w.getReader();\n    w.close();\n\n    DocsAndPositionsEnum dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"a\"), true);\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(2, dp.freq());\n    assertEquals(0, dp.nextPosition());\n    assertEquals(0, dp.startOffset());\n    assertEquals(6, dp.endOffset());\n    assertEquals(2, dp.nextPosition());\n    assertEquals(9, dp.startOffset());\n    assertEquals(17, dp.endOffset());\n    assertEquals(DocsEnum.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"b\"), true);\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(1, dp.nextPosition());\n    assertEquals(8, dp.startOffset());\n    assertEquals(9, dp.endOffset());\n    assertEquals(DocsEnum.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"c\"), true);\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(3, dp.nextPosition());\n    assertEquals(19, dp.startOffset());\n    assertEquals(50, dp.endOffset());\n    assertEquals(DocsEnum.NO_MORE_DOCS, dp.nextDoc());\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","date":1331075828,"type":3,"author":"Ryan McKinley","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets#testBasic().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets#testBasic().mjava","sourceNew":"  public void testBasic() throws Exception {\n    Directory dir = newDirectory();\n    \n    RandomIndexWriter w = new RandomIndexWriter(random, dir, iwc);\n    Document doc = new Document();\n\n    FieldType ft = new FieldType(TextField.TYPE_UNSTORED);\n    ft.setIndexOptions(FieldInfo.IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Token[] tokens = new Token[] {\n      makeToken(\"a\", 1, 0, 6),\n      makeToken(\"b\", 1, 8, 9),\n      makeToken(\"a\", 1, 9, 17),\n      makeToken(\"c\", 1, 19, 50),\n    };\n    doc.add(new Field(\"content\", new CannedTokenStream(tokens), ft));\n\n    w.addDocument(doc);\n    IndexReader r = w.getReader();\n    w.close();\n\n    DocsAndPositionsEnum dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"a\"), true);\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(2, dp.freq());\n    assertEquals(0, dp.nextPosition());\n    assertEquals(0, dp.startOffset());\n    assertEquals(6, dp.endOffset());\n    assertEquals(2, dp.nextPosition());\n    assertEquals(9, dp.startOffset());\n    assertEquals(17, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"b\"), true);\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(1, dp.nextPosition());\n    assertEquals(8, dp.startOffset());\n    assertEquals(9, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"c\"), true);\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(3, dp.nextPosition());\n    assertEquals(19, dp.startOffset());\n    assertEquals(50, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testBasic() throws Exception {\n    Directory dir = newDirectory();\n    \n    RandomIndexWriter w = new RandomIndexWriter(random, dir, iwc);\n    Document doc = new Document();\n\n    FieldType ft = new FieldType(TextField.TYPE_UNSTORED);\n    ft.setIndexOptions(FieldInfo.IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Token[] tokens = new Token[] {\n      makeToken(\"a\", 1, 0, 6),\n      makeToken(\"b\", 1, 8, 9),\n      makeToken(\"a\", 1, 9, 17),\n      makeToken(\"c\", 1, 19, 50),\n    };\n    doc.add(new Field(\"content\", new CannedTokenStream(tokens), ft));\n\n    w.addDocument(doc);\n    IndexReader r = w.getReader();\n    w.close();\n\n    DocsAndPositionsEnum dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"a\"), true);\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(2, dp.freq());\n    assertEquals(0, dp.nextPosition());\n    assertEquals(0, dp.startOffset());\n    assertEquals(6, dp.endOffset());\n    assertEquals(2, dp.nextPosition());\n    assertEquals(9, dp.startOffset());\n    assertEquals(17, dp.endOffset());\n    assertEquals(DocsEnum.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"b\"), true);\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(1, dp.nextPosition());\n    assertEquals(8, dp.startOffset());\n    assertEquals(9, dp.endOffset());\n    assertEquals(DocsEnum.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"c\"), true);\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(3, dp.nextPosition());\n    assertEquals(19, dp.startOffset());\n    assertEquals(50, dp.endOffset());\n    assertEquals(DocsEnum.NO_MORE_DOCS, dp.nextDoc());\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets#testBasic().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets#testBasic().mjava","sourceNew":"  public void testBasic() throws Exception {\n    Directory dir = newDirectory();\n    \n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n\n    FieldType ft = new FieldType(TextField.TYPE_UNSTORED);\n    ft.setIndexOptions(FieldInfo.IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Token[] tokens = new Token[] {\n      makeToken(\"a\", 1, 0, 6),\n      makeToken(\"b\", 1, 8, 9),\n      makeToken(\"a\", 1, 9, 17),\n      makeToken(\"c\", 1, 19, 50),\n    };\n    doc.add(new Field(\"content\", new CannedTokenStream(tokens), ft));\n\n    w.addDocument(doc);\n    IndexReader r = w.getReader();\n    w.close();\n\n    DocsAndPositionsEnum dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"a\"), true);\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(2, dp.freq());\n    assertEquals(0, dp.nextPosition());\n    assertEquals(0, dp.startOffset());\n    assertEquals(6, dp.endOffset());\n    assertEquals(2, dp.nextPosition());\n    assertEquals(9, dp.startOffset());\n    assertEquals(17, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"b\"), true);\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(1, dp.nextPosition());\n    assertEquals(8, dp.startOffset());\n    assertEquals(9, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"c\"), true);\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(3, dp.nextPosition());\n    assertEquals(19, dp.startOffset());\n    assertEquals(50, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testBasic() throws Exception {\n    Directory dir = newDirectory();\n    \n    RandomIndexWriter w = new RandomIndexWriter(random, dir, iwc);\n    Document doc = new Document();\n\n    FieldType ft = new FieldType(TextField.TYPE_UNSTORED);\n    ft.setIndexOptions(FieldInfo.IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Token[] tokens = new Token[] {\n      makeToken(\"a\", 1, 0, 6),\n      makeToken(\"b\", 1, 8, 9),\n      makeToken(\"a\", 1, 9, 17),\n      makeToken(\"c\", 1, 19, 50),\n    };\n    doc.add(new Field(\"content\", new CannedTokenStream(tokens), ft));\n\n    w.addDocument(doc);\n    IndexReader r = w.getReader();\n    w.close();\n\n    DocsAndPositionsEnum dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"a\"), true);\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(2, dp.freq());\n    assertEquals(0, dp.nextPosition());\n    assertEquals(0, dp.startOffset());\n    assertEquals(6, dp.endOffset());\n    assertEquals(2, dp.nextPosition());\n    assertEquals(9, dp.startOffset());\n    assertEquals(17, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"b\"), true);\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(1, dp.nextPosition());\n    assertEquals(8, dp.startOffset());\n    assertEquals(9, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"c\"), true);\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(3, dp.nextPosition());\n    assertEquals(19, dp.startOffset());\n    assertEquals(50, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7424161ac990ef8f959f09ee516148e4d12c48bc","date":1336236796,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets#testBasic().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets#testBasic().mjava","sourceNew":"  public void testBasic() throws Exception {\n    Directory dir = newDirectory();\n    \n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n\n    FieldType ft = new FieldType(TextField.TYPE_UNSTORED);\n    ft.setIndexOptions(FieldInfo.IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    if (random().nextBoolean()) {\n      ft.setStoreTermVectors(true);\n      ft.setStoreTermVectorPositions(random().nextBoolean());\n      ft.setStoreTermVectorOffsets(random().nextBoolean());\n    }\n    Token[] tokens = new Token[] {\n      makeToken(\"a\", 1, 0, 6),\n      makeToken(\"b\", 1, 8, 9),\n      makeToken(\"a\", 1, 9, 17),\n      makeToken(\"c\", 1, 19, 50),\n    };\n    doc.add(new Field(\"content\", new CannedTokenStream(tokens), ft));\n\n    w.addDocument(doc);\n    IndexReader r = w.getReader();\n    w.close();\n\n    DocsAndPositionsEnum dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"a\"), true);\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(2, dp.freq());\n    assertEquals(0, dp.nextPosition());\n    assertEquals(0, dp.startOffset());\n    assertEquals(6, dp.endOffset());\n    assertEquals(2, dp.nextPosition());\n    assertEquals(9, dp.startOffset());\n    assertEquals(17, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"b\"), true);\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(1, dp.nextPosition());\n    assertEquals(8, dp.startOffset());\n    assertEquals(9, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"c\"), true);\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(3, dp.nextPosition());\n    assertEquals(19, dp.startOffset());\n    assertEquals(50, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testBasic() throws Exception {\n    Directory dir = newDirectory();\n    \n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n\n    FieldType ft = new FieldType(TextField.TYPE_UNSTORED);\n    ft.setIndexOptions(FieldInfo.IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Token[] tokens = new Token[] {\n      makeToken(\"a\", 1, 0, 6),\n      makeToken(\"b\", 1, 8, 9),\n      makeToken(\"a\", 1, 9, 17),\n      makeToken(\"c\", 1, 19, 50),\n    };\n    doc.add(new Field(\"content\", new CannedTokenStream(tokens), ft));\n\n    w.addDocument(doc);\n    IndexReader r = w.getReader();\n    w.close();\n\n    DocsAndPositionsEnum dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"a\"), true);\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(2, dp.freq());\n    assertEquals(0, dp.nextPosition());\n    assertEquals(0, dp.startOffset());\n    assertEquals(6, dp.endOffset());\n    assertEquals(2, dp.nextPosition());\n    assertEquals(9, dp.startOffset());\n    assertEquals(17, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"b\"), true);\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(1, dp.nextPosition());\n    assertEquals(8, dp.startOffset());\n    assertEquals(9, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"c\"), true);\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(3, dp.nextPosition());\n    assertEquals(19, dp.startOffset());\n    assertEquals(50, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"04f07771a2a7dd3a395700665ed839c3dae2def2","date":1339350139,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets#testBasic().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets#testBasic().mjava","sourceNew":"  public void testBasic() throws Exception {\n    Directory dir = newDirectory();\n    \n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n\n    FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n    ft.setIndexOptions(FieldInfo.IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    if (random().nextBoolean()) {\n      ft.setStoreTermVectors(true);\n      ft.setStoreTermVectorPositions(random().nextBoolean());\n      ft.setStoreTermVectorOffsets(random().nextBoolean());\n    }\n    Token[] tokens = new Token[] {\n      makeToken(\"a\", 1, 0, 6),\n      makeToken(\"b\", 1, 8, 9),\n      makeToken(\"a\", 1, 9, 17),\n      makeToken(\"c\", 1, 19, 50),\n    };\n    doc.add(new Field(\"content\", new CannedTokenStream(tokens), ft));\n\n    w.addDocument(doc);\n    IndexReader r = w.getReader();\n    w.close();\n\n    DocsAndPositionsEnum dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"a\"), true);\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(2, dp.freq());\n    assertEquals(0, dp.nextPosition());\n    assertEquals(0, dp.startOffset());\n    assertEquals(6, dp.endOffset());\n    assertEquals(2, dp.nextPosition());\n    assertEquals(9, dp.startOffset());\n    assertEquals(17, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"b\"), true);\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(1, dp.nextPosition());\n    assertEquals(8, dp.startOffset());\n    assertEquals(9, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"c\"), true);\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(3, dp.nextPosition());\n    assertEquals(19, dp.startOffset());\n    assertEquals(50, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testBasic() throws Exception {\n    Directory dir = newDirectory();\n    \n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n\n    FieldType ft = new FieldType(TextField.TYPE_UNSTORED);\n    ft.setIndexOptions(FieldInfo.IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    if (random().nextBoolean()) {\n      ft.setStoreTermVectors(true);\n      ft.setStoreTermVectorPositions(random().nextBoolean());\n      ft.setStoreTermVectorOffsets(random().nextBoolean());\n    }\n    Token[] tokens = new Token[] {\n      makeToken(\"a\", 1, 0, 6),\n      makeToken(\"b\", 1, 8, 9),\n      makeToken(\"a\", 1, 9, 17),\n      makeToken(\"c\", 1, 19, 50),\n    };\n    doc.add(new Field(\"content\", new CannedTokenStream(tokens), ft));\n\n    w.addDocument(doc);\n    IndexReader r = w.getReader();\n    w.close();\n\n    DocsAndPositionsEnum dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"a\"), true);\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(2, dp.freq());\n    assertEquals(0, dp.nextPosition());\n    assertEquals(0, dp.startOffset());\n    assertEquals(6, dp.endOffset());\n    assertEquals(2, dp.nextPosition());\n    assertEquals(9, dp.startOffset());\n    assertEquals(17, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"b\"), true);\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(1, dp.nextPosition());\n    assertEquals(8, dp.startOffset());\n    assertEquals(9, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"c\"), true);\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(3, dp.nextPosition());\n    assertEquals(19, dp.startOffset());\n    assertEquals(50, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":["31f025ae60076ae95274433f3fe8e6ace2857a87"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"322360ac5185a8446d3e0b530b2068bef67cd3d5","date":1343669494,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets#testBasic().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets#testBasic().mjava","sourceNew":"  public void testBasic() throws Exception {\n    Directory dir = newDirectory();\n    \n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n\n    FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n    ft.setIndexOptions(FieldInfo.IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    if (random().nextBoolean()) {\n      ft.setStoreTermVectors(true);\n      ft.setStoreTermVectorPositions(random().nextBoolean());\n      ft.setStoreTermVectorOffsets(random().nextBoolean());\n    }\n    Token[] tokens = new Token[] {\n      makeToken(\"a\", 1, 0, 6),\n      makeToken(\"b\", 1, 8, 9),\n      makeToken(\"a\", 1, 9, 17),\n      makeToken(\"c\", 1, 19, 50),\n    };\n    doc.add(new Field(\"content\", new CannedTokenStream(tokens), ft));\n\n    w.addDocument(doc);\n    IndexReader r = w.getReader();\n    w.close();\n\n    DocsAndPositionsEnum dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"a\"));\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(2, dp.freq());\n    assertEquals(0, dp.nextPosition());\n    assertEquals(0, dp.startOffset());\n    assertEquals(6, dp.endOffset());\n    assertEquals(2, dp.nextPosition());\n    assertEquals(9, dp.startOffset());\n    assertEquals(17, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"b\"));\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(1, dp.nextPosition());\n    assertEquals(8, dp.startOffset());\n    assertEquals(9, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"c\"));\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(3, dp.nextPosition());\n    assertEquals(19, dp.startOffset());\n    assertEquals(50, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testBasic() throws Exception {\n    Directory dir = newDirectory();\n    \n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n\n    FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n    ft.setIndexOptions(FieldInfo.IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    if (random().nextBoolean()) {\n      ft.setStoreTermVectors(true);\n      ft.setStoreTermVectorPositions(random().nextBoolean());\n      ft.setStoreTermVectorOffsets(random().nextBoolean());\n    }\n    Token[] tokens = new Token[] {\n      makeToken(\"a\", 1, 0, 6),\n      makeToken(\"b\", 1, 8, 9),\n      makeToken(\"a\", 1, 9, 17),\n      makeToken(\"c\", 1, 19, 50),\n    };\n    doc.add(new Field(\"content\", new CannedTokenStream(tokens), ft));\n\n    w.addDocument(doc);\n    IndexReader r = w.getReader();\n    w.close();\n\n    DocsAndPositionsEnum dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"a\"), true);\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(2, dp.freq());\n    assertEquals(0, dp.nextPosition());\n    assertEquals(0, dp.startOffset());\n    assertEquals(6, dp.endOffset());\n    assertEquals(2, dp.nextPosition());\n    assertEquals(9, dp.startOffset());\n    assertEquals(17, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"b\"), true);\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(1, dp.nextPosition());\n    assertEquals(8, dp.startOffset());\n    assertEquals(9, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"c\"), true);\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(3, dp.nextPosition());\n    assertEquals(19, dp.startOffset());\n    assertEquals(50, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","date":1343768312,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets#testBasic().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets#testBasic().mjava","sourceNew":"  public void testBasic() throws Exception {\n    Directory dir = newDirectory();\n    \n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n\n    FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n    ft.setIndexOptions(FieldInfo.IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    if (random().nextBoolean()) {\n      ft.setStoreTermVectors(true);\n      ft.setStoreTermVectorPositions(random().nextBoolean());\n      ft.setStoreTermVectorOffsets(random().nextBoolean());\n    }\n    Token[] tokens = new Token[] {\n      makeToken(\"a\", 1, 0, 6),\n      makeToken(\"b\", 1, 8, 9),\n      makeToken(\"a\", 1, 9, 17),\n      makeToken(\"c\", 1, 19, 50),\n    };\n    doc.add(new Field(\"content\", new CannedTokenStream(tokens), ft));\n\n    w.addDocument(doc);\n    IndexReader r = w.getReader();\n    w.close();\n\n    DocsAndPositionsEnum dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"a\"));\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(2, dp.freq());\n    assertEquals(0, dp.nextPosition());\n    assertEquals(0, dp.startOffset());\n    assertEquals(6, dp.endOffset());\n    assertEquals(2, dp.nextPosition());\n    assertEquals(9, dp.startOffset());\n    assertEquals(17, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"b\"));\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(1, dp.nextPosition());\n    assertEquals(8, dp.startOffset());\n    assertEquals(9, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"c\"));\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(3, dp.nextPosition());\n    assertEquals(19, dp.startOffset());\n    assertEquals(50, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testBasic() throws Exception {\n    Directory dir = newDirectory();\n    \n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n\n    FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n    ft.setIndexOptions(FieldInfo.IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    if (random().nextBoolean()) {\n      ft.setStoreTermVectors(true);\n      ft.setStoreTermVectorPositions(random().nextBoolean());\n      ft.setStoreTermVectorOffsets(random().nextBoolean());\n    }\n    Token[] tokens = new Token[] {\n      makeToken(\"a\", 1, 0, 6),\n      makeToken(\"b\", 1, 8, 9),\n      makeToken(\"a\", 1, 9, 17),\n      makeToken(\"c\", 1, 19, 50),\n    };\n    doc.add(new Field(\"content\", new CannedTokenStream(tokens), ft));\n\n    w.addDocument(doc);\n    IndexReader r = w.getReader();\n    w.close();\n\n    DocsAndPositionsEnum dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"a\"), true);\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(2, dp.freq());\n    assertEquals(0, dp.nextPosition());\n    assertEquals(0, dp.startOffset());\n    assertEquals(6, dp.endOffset());\n    assertEquals(2, dp.nextPosition());\n    assertEquals(9, dp.startOffset());\n    assertEquals(17, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"b\"), true);\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(1, dp.nextPosition());\n    assertEquals(8, dp.startOffset());\n    assertEquals(9, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"c\"), true);\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(3, dp.nextPosition());\n    assertEquals(19, dp.startOffset());\n    assertEquals(50, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d6f074e73200c07d54f242d3880a8da5a35ff97b","date":1344507653,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets#testBasic().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets#testBasic().mjava","sourceNew":"  public void testBasic() throws Exception {\n    Directory dir = newDirectory();\n    \n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n\n    FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n    ft.setIndexOptions(FieldInfo.IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    if (random().nextBoolean()) {\n      ft.setStoreTermVectors(true);\n      ft.setStoreTermVectorPositions(random().nextBoolean());\n      ft.setStoreTermVectorOffsets(random().nextBoolean());\n    }\n    Token[] tokens = new Token[] {\n      makeToken(\"a\", 1, 0, 6),\n      makeToken(\"b\", 1, 8, 9),\n      makeToken(\"a\", 1, 9, 17),\n      makeToken(\"c\", 1, 19, 50),\n    };\n    doc.add(new Field(\"content\", new CannedTokenStream(tokens), ft));\n\n    w.addDocument(doc);\n    IndexReader r = w.getReader();\n    w.close();\n\n    DocsAndPositionsEnum dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"a\"));\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(2, dp.freq());\n    assertEquals(0, dp.nextPosition());\n    assertEquals(0, dp.startOffset());\n    assertEquals(6, dp.endOffset());\n    assertEquals(2, dp.nextPosition());\n    assertEquals(9, dp.startOffset());\n    assertEquals(17, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"b\"));\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(1, dp.nextPosition());\n    assertEquals(8, dp.startOffset());\n    assertEquals(9, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"c\"));\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(3, dp.nextPosition());\n    assertEquals(19, dp.startOffset());\n    assertEquals(50, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testBasic() throws Exception {\n    Directory dir = newDirectory();\n    \n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n\n    FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n    ft.setIndexOptions(FieldInfo.IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    if (random().nextBoolean()) {\n      ft.setStoreTermVectors(true);\n      ft.setStoreTermVectorPositions(random().nextBoolean());\n      ft.setStoreTermVectorOffsets(random().nextBoolean());\n    }\n    Token[] tokens = new Token[] {\n      makeToken(\"a\", 1, 0, 6),\n      makeToken(\"b\", 1, 8, 9),\n      makeToken(\"a\", 1, 9, 17),\n      makeToken(\"c\", 1, 19, 50),\n    };\n    doc.add(new Field(\"content\", new CannedTokenStream(tokens), ft));\n\n    w.addDocument(doc);\n    IndexReader r = w.getReader();\n    w.close();\n\n    DocsAndPositionsEnum dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"a\"), true);\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(2, dp.freq());\n    assertEquals(0, dp.nextPosition());\n    assertEquals(0, dp.startOffset());\n    assertEquals(6, dp.endOffset());\n    assertEquals(2, dp.nextPosition());\n    assertEquals(9, dp.startOffset());\n    assertEquals(17, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"b\"), true);\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(1, dp.nextPosition());\n    assertEquals(8, dp.startOffset());\n    assertEquals(9, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"c\"), true);\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(3, dp.nextPosition());\n    assertEquals(19, dp.startOffset());\n    assertEquals(50, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets#testBasic().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets#testBasic().mjava","sourceNew":"  public void testBasic() throws Exception {\n    Directory dir = newDirectory();\n    \n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n\n    FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n    ft.setIndexOptions(FieldInfo.IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    if (random().nextBoolean()) {\n      ft.setStoreTermVectors(true);\n      ft.setStoreTermVectorPositions(random().nextBoolean());\n      ft.setStoreTermVectorOffsets(random().nextBoolean());\n    }\n    Token[] tokens = new Token[] {\n      makeToken(\"a\", 1, 0, 6),\n      makeToken(\"b\", 1, 8, 9),\n      makeToken(\"a\", 1, 9, 17),\n      makeToken(\"c\", 1, 19, 50),\n    };\n    doc.add(new Field(\"content\", new CannedTokenStream(tokens), ft));\n\n    w.addDocument(doc);\n    IndexReader r = w.getReader();\n    w.shutdown();\n\n    DocsAndPositionsEnum dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"a\"));\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(2, dp.freq());\n    assertEquals(0, dp.nextPosition());\n    assertEquals(0, dp.startOffset());\n    assertEquals(6, dp.endOffset());\n    assertEquals(2, dp.nextPosition());\n    assertEquals(9, dp.startOffset());\n    assertEquals(17, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"b\"));\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(1, dp.nextPosition());\n    assertEquals(8, dp.startOffset());\n    assertEquals(9, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"c\"));\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(3, dp.nextPosition());\n    assertEquals(19, dp.startOffset());\n    assertEquals(50, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testBasic() throws Exception {\n    Directory dir = newDirectory();\n    \n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n\n    FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n    ft.setIndexOptions(FieldInfo.IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    if (random().nextBoolean()) {\n      ft.setStoreTermVectors(true);\n      ft.setStoreTermVectorPositions(random().nextBoolean());\n      ft.setStoreTermVectorOffsets(random().nextBoolean());\n    }\n    Token[] tokens = new Token[] {\n      makeToken(\"a\", 1, 0, 6),\n      makeToken(\"b\", 1, 8, 9),\n      makeToken(\"a\", 1, 9, 17),\n      makeToken(\"c\", 1, 19, 50),\n    };\n    doc.add(new Field(\"content\", new CannedTokenStream(tokens), ft));\n\n    w.addDocument(doc);\n    IndexReader r = w.getReader();\n    w.close();\n\n    DocsAndPositionsEnum dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"a\"));\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(2, dp.freq());\n    assertEquals(0, dp.nextPosition());\n    assertEquals(0, dp.startOffset());\n    assertEquals(6, dp.endOffset());\n    assertEquals(2, dp.nextPosition());\n    assertEquals(9, dp.startOffset());\n    assertEquals(17, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"b\"));\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(1, dp.nextPosition());\n    assertEquals(8, dp.startOffset());\n    assertEquals(9, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"c\"));\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(3, dp.nextPosition());\n    assertEquals(19, dp.startOffset());\n    assertEquals(50, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets#testBasic().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets#testBasic().mjava","sourceNew":"  public void testBasic() throws Exception {\n    Directory dir = newDirectory();\n    \n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n\n    FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n    ft.setIndexOptions(FieldInfo.IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    if (random().nextBoolean()) {\n      ft.setStoreTermVectors(true);\n      ft.setStoreTermVectorPositions(random().nextBoolean());\n      ft.setStoreTermVectorOffsets(random().nextBoolean());\n    }\n    Token[] tokens = new Token[] {\n      makeToken(\"a\", 1, 0, 6),\n      makeToken(\"b\", 1, 8, 9),\n      makeToken(\"a\", 1, 9, 17),\n      makeToken(\"c\", 1, 19, 50),\n    };\n    doc.add(new Field(\"content\", new CannedTokenStream(tokens), ft));\n\n    w.addDocument(doc);\n    IndexReader r = w.getReader();\n    w.close();\n\n    DocsAndPositionsEnum dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"a\"));\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(2, dp.freq());\n    assertEquals(0, dp.nextPosition());\n    assertEquals(0, dp.startOffset());\n    assertEquals(6, dp.endOffset());\n    assertEquals(2, dp.nextPosition());\n    assertEquals(9, dp.startOffset());\n    assertEquals(17, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"b\"));\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(1, dp.nextPosition());\n    assertEquals(8, dp.startOffset());\n    assertEquals(9, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"c\"));\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(3, dp.nextPosition());\n    assertEquals(19, dp.startOffset());\n    assertEquals(50, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testBasic() throws Exception {\n    Directory dir = newDirectory();\n    \n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n\n    FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n    ft.setIndexOptions(FieldInfo.IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    if (random().nextBoolean()) {\n      ft.setStoreTermVectors(true);\n      ft.setStoreTermVectorPositions(random().nextBoolean());\n      ft.setStoreTermVectorOffsets(random().nextBoolean());\n    }\n    Token[] tokens = new Token[] {\n      makeToken(\"a\", 1, 0, 6),\n      makeToken(\"b\", 1, 8, 9),\n      makeToken(\"a\", 1, 9, 17),\n      makeToken(\"c\", 1, 19, 50),\n    };\n    doc.add(new Field(\"content\", new CannedTokenStream(tokens), ft));\n\n    w.addDocument(doc);\n    IndexReader r = w.getReader();\n    w.shutdown();\n\n    DocsAndPositionsEnum dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"a\"));\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(2, dp.freq());\n    assertEquals(0, dp.nextPosition());\n    assertEquals(0, dp.startOffset());\n    assertEquals(6, dp.endOffset());\n    assertEquals(2, dp.nextPosition());\n    assertEquals(9, dp.startOffset());\n    assertEquals(17, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"b\"));\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(1, dp.nextPosition());\n    assertEquals(8, dp.startOffset());\n    assertEquals(9, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"c\"));\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(3, dp.nextPosition());\n    assertEquals(19, dp.startOffset());\n    assertEquals(50, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2bb2842e561df4e8e9ad89010605fc86ac265465","date":1414768208,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets#testBasic().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets#testBasic().mjava","sourceNew":"  public void testBasic() throws Exception {\n    Directory dir = newDirectory();\n    \n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n\n    FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n    ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    if (random().nextBoolean()) {\n      ft.setStoreTermVectors(true);\n      ft.setStoreTermVectorPositions(random().nextBoolean());\n      ft.setStoreTermVectorOffsets(random().nextBoolean());\n    }\n    Token[] tokens = new Token[] {\n      makeToken(\"a\", 1, 0, 6),\n      makeToken(\"b\", 1, 8, 9),\n      makeToken(\"a\", 1, 9, 17),\n      makeToken(\"c\", 1, 19, 50),\n    };\n    doc.add(new Field(\"content\", new CannedTokenStream(tokens), ft));\n\n    w.addDocument(doc);\n    IndexReader r = w.getReader();\n    w.close();\n\n    DocsAndPositionsEnum dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"a\"));\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(2, dp.freq());\n    assertEquals(0, dp.nextPosition());\n    assertEquals(0, dp.startOffset());\n    assertEquals(6, dp.endOffset());\n    assertEquals(2, dp.nextPosition());\n    assertEquals(9, dp.startOffset());\n    assertEquals(17, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"b\"));\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(1, dp.nextPosition());\n    assertEquals(8, dp.startOffset());\n    assertEquals(9, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"c\"));\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(3, dp.nextPosition());\n    assertEquals(19, dp.startOffset());\n    assertEquals(50, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testBasic() throws Exception {\n    Directory dir = newDirectory();\n    \n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n\n    FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n    ft.setIndexOptions(FieldInfo.IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    if (random().nextBoolean()) {\n      ft.setStoreTermVectors(true);\n      ft.setStoreTermVectorPositions(random().nextBoolean());\n      ft.setStoreTermVectorOffsets(random().nextBoolean());\n    }\n    Token[] tokens = new Token[] {\n      makeToken(\"a\", 1, 0, 6),\n      makeToken(\"b\", 1, 8, 9),\n      makeToken(\"a\", 1, 9, 17),\n      makeToken(\"c\", 1, 19, 50),\n    };\n    doc.add(new Field(\"content\", new CannedTokenStream(tokens), ft));\n\n    w.addDocument(doc);\n    IndexReader r = w.getReader();\n    w.close();\n\n    DocsAndPositionsEnum dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"a\"));\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(2, dp.freq());\n    assertEquals(0, dp.nextPosition());\n    assertEquals(0, dp.startOffset());\n    assertEquals(6, dp.endOffset());\n    assertEquals(2, dp.nextPosition());\n    assertEquals(9, dp.startOffset());\n    assertEquals(17, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"b\"));\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(1, dp.nextPosition());\n    assertEquals(8, dp.startOffset());\n    assertEquals(9, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"c\"));\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(3, dp.nextPosition());\n    assertEquals(19, dp.startOffset());\n    assertEquals(50, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"51f5280f31484820499077f41fcdfe92d527d9dc","date":1423229122,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets#testBasic().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets#testBasic().mjava","sourceNew":"  public void testBasic() throws Exception {\n    Directory dir = newDirectory();\n    \n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n\n    FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n    ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    if (random().nextBoolean()) {\n      ft.setStoreTermVectors(true);\n      ft.setStoreTermVectorPositions(random().nextBoolean());\n      ft.setStoreTermVectorOffsets(random().nextBoolean());\n    }\n    Token[] tokens = new Token[] {\n      makeToken(\"a\", 1, 0, 6),\n      makeToken(\"b\", 1, 8, 9),\n      makeToken(\"a\", 1, 9, 17),\n      makeToken(\"c\", 1, 19, 50),\n    };\n    doc.add(new Field(\"content\", new CannedTokenStream(tokens), ft));\n\n    w.addDocument(doc);\n    IndexReader r = w.getReader();\n    w.close();\n\n    PostingsEnum dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"a\"));\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(2, dp.freq());\n    assertEquals(0, dp.nextPosition());\n    assertEquals(0, dp.startOffset());\n    assertEquals(6, dp.endOffset());\n    assertEquals(2, dp.nextPosition());\n    assertEquals(9, dp.startOffset());\n    assertEquals(17, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"b\"));\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(1, dp.nextPosition());\n    assertEquals(8, dp.startOffset());\n    assertEquals(9, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"c\"));\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(3, dp.nextPosition());\n    assertEquals(19, dp.startOffset());\n    assertEquals(50, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testBasic() throws Exception {\n    Directory dir = newDirectory();\n    \n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n\n    FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n    ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    if (random().nextBoolean()) {\n      ft.setStoreTermVectors(true);\n      ft.setStoreTermVectorPositions(random().nextBoolean());\n      ft.setStoreTermVectorOffsets(random().nextBoolean());\n    }\n    Token[] tokens = new Token[] {\n      makeToken(\"a\", 1, 0, 6),\n      makeToken(\"b\", 1, 8, 9),\n      makeToken(\"a\", 1, 9, 17),\n      makeToken(\"c\", 1, 19, 50),\n    };\n    doc.add(new Field(\"content\", new CannedTokenStream(tokens), ft));\n\n    w.addDocument(doc);\n    IndexReader r = w.getReader();\n    w.close();\n\n    DocsAndPositionsEnum dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"a\"));\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(2, dp.freq());\n    assertEquals(0, dp.nextPosition());\n    assertEquals(0, dp.startOffset());\n    assertEquals(6, dp.endOffset());\n    assertEquals(2, dp.nextPosition());\n    assertEquals(9, dp.startOffset());\n    assertEquals(17, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"b\"));\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(1, dp.nextPosition());\n    assertEquals(8, dp.startOffset());\n    assertEquals(9, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"c\"));\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(3, dp.nextPosition());\n    assertEquals(19, dp.startOffset());\n    assertEquals(50, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0f4464508ee83288c8c4585b533f9faaa93aa314","date":1435240759,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets#testBasic().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets#testBasic().mjava","sourceNew":"  public void testBasic() throws Exception {\n    Directory dir = newDirectory();\n    \n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n\n    FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n    ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    if (random().nextBoolean()) {\n      ft.setStoreTermVectors(true);\n      ft.setStoreTermVectorPositions(random().nextBoolean());\n      ft.setStoreTermVectorOffsets(random().nextBoolean());\n    }\n    Token[] tokens = new Token[] {\n      makeToken(\"a\", 1, 0, 6),\n      makeToken(\"b\", 1, 8, 9),\n      makeToken(\"a\", 1, 9, 17),\n      makeToken(\"c\", 1, 19, 50),\n    };\n    doc.add(new Field(\"content\", new CannedTokenStream(tokens), ft));\n\n    w.addDocument(doc);\n    IndexReader r = w.getReader();\n    w.close();\n\n    PostingsEnum dp = MultiFields.getTermPositionsEnum(r, \"content\", new BytesRef(\"a\"));\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(2, dp.freq());\n    assertEquals(0, dp.nextPosition());\n    assertEquals(0, dp.startOffset());\n    assertEquals(6, dp.endOffset());\n    assertEquals(2, dp.nextPosition());\n    assertEquals(9, dp.startOffset());\n    assertEquals(17, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, \"content\", new BytesRef(\"b\"));\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(1, dp.nextPosition());\n    assertEquals(8, dp.startOffset());\n    assertEquals(9, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, \"content\", new BytesRef(\"c\"));\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(3, dp.nextPosition());\n    assertEquals(19, dp.startOffset());\n    assertEquals(50, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testBasic() throws Exception {\n    Directory dir = newDirectory();\n    \n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n\n    FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n    ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    if (random().nextBoolean()) {\n      ft.setStoreTermVectors(true);\n      ft.setStoreTermVectorPositions(random().nextBoolean());\n      ft.setStoreTermVectorOffsets(random().nextBoolean());\n    }\n    Token[] tokens = new Token[] {\n      makeToken(\"a\", 1, 0, 6),\n      makeToken(\"b\", 1, 8, 9),\n      makeToken(\"a\", 1, 9, 17),\n      makeToken(\"c\", 1, 19, 50),\n    };\n    doc.add(new Field(\"content\", new CannedTokenStream(tokens), ft));\n\n    w.addDocument(doc);\n    IndexReader r = w.getReader();\n    w.close();\n\n    PostingsEnum dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"a\"));\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(2, dp.freq());\n    assertEquals(0, dp.nextPosition());\n    assertEquals(0, dp.startOffset());\n    assertEquals(6, dp.endOffset());\n    assertEquals(2, dp.nextPosition());\n    assertEquals(9, dp.startOffset());\n    assertEquals(17, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"b\"));\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(1, dp.nextPosition());\n    assertEquals(8, dp.startOffset());\n    assertEquals(9, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, null, \"content\", new BytesRef(\"c\"));\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(3, dp.nextPosition());\n    assertEquals(19, dp.startOffset());\n    assertEquals(50, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"04e775de416dd2d8067b10db1c8af975a1d5017e","date":1539906554,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets#testBasic().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets#testBasic().mjava","sourceNew":"  public void testBasic() throws Exception {\n    Directory dir = newDirectory();\n    \n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n\n    FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n    ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    if (random().nextBoolean()) {\n      ft.setStoreTermVectors(true);\n      ft.setStoreTermVectorPositions(random().nextBoolean());\n      ft.setStoreTermVectorOffsets(random().nextBoolean());\n    }\n    Token[] tokens = new Token[] {\n      makeToken(\"a\", 1, 0, 6),\n      makeToken(\"b\", 1, 8, 9),\n      makeToken(\"a\", 1, 9, 17),\n      makeToken(\"c\", 1, 19, 50),\n    };\n    doc.add(new Field(\"content\", new CannedTokenStream(tokens), ft));\n\n    w.addDocument(doc);\n    IndexReader r = w.getReader();\n    w.close();\n\n    PostingsEnum dp = MultiTerms.getTermPostingsEnum(r, \"content\", new BytesRef(\"a\"));\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(2, dp.freq());\n    assertEquals(0, dp.nextPosition());\n    assertEquals(0, dp.startOffset());\n    assertEquals(6, dp.endOffset());\n    assertEquals(2, dp.nextPosition());\n    assertEquals(9, dp.startOffset());\n    assertEquals(17, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiTerms.getTermPostingsEnum(r, \"content\", new BytesRef(\"b\"));\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(1, dp.nextPosition());\n    assertEquals(8, dp.startOffset());\n    assertEquals(9, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiTerms.getTermPostingsEnum(r, \"content\", new BytesRef(\"c\"));\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(3, dp.nextPosition());\n    assertEquals(19, dp.startOffset());\n    assertEquals(50, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testBasic() throws Exception {\n    Directory dir = newDirectory();\n    \n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n\n    FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n    ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    if (random().nextBoolean()) {\n      ft.setStoreTermVectors(true);\n      ft.setStoreTermVectorPositions(random().nextBoolean());\n      ft.setStoreTermVectorOffsets(random().nextBoolean());\n    }\n    Token[] tokens = new Token[] {\n      makeToken(\"a\", 1, 0, 6),\n      makeToken(\"b\", 1, 8, 9),\n      makeToken(\"a\", 1, 9, 17),\n      makeToken(\"c\", 1, 19, 50),\n    };\n    doc.add(new Field(\"content\", new CannedTokenStream(tokens), ft));\n\n    w.addDocument(doc);\n    IndexReader r = w.getReader();\n    w.close();\n\n    PostingsEnum dp = MultiFields.getTermPositionsEnum(r, \"content\", new BytesRef(\"a\"));\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(2, dp.freq());\n    assertEquals(0, dp.nextPosition());\n    assertEquals(0, dp.startOffset());\n    assertEquals(6, dp.endOffset());\n    assertEquals(2, dp.nextPosition());\n    assertEquals(9, dp.startOffset());\n    assertEquals(17, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, \"content\", new BytesRef(\"b\"));\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(1, dp.nextPosition());\n    assertEquals(8, dp.startOffset());\n    assertEquals(9, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    dp = MultiFields.getTermPositionsEnum(r, \"content\", new BytesRef(\"c\"));\n    assertNotNull(dp);\n    assertEquals(0, dp.nextDoc());\n    assertEquals(1, dp.freq());\n    assertEquals(3, dp.nextPosition());\n    assertEquals(19, dp.startOffset());\n    assertEquals(50, dp.endOffset());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, dp.nextDoc());\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab":["6c2782fe88d18fedf3ef67402c9cb5a41978a8c7","f08557cdb6c60ac7b88a9342c983a20cd236e74f"],"f08557cdb6c60ac7b88a9342c983a20cd236e74f":["6c2782fe88d18fedf3ef67402c9cb5a41978a8c7"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"2bb2842e561df4e8e9ad89010605fc86ac265465":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"51f5280f31484820499077f41fcdfe92d527d9dc":["2bb2842e561df4e8e9ad89010605fc86ac265465"],"6c2782fe88d18fedf3ef67402c9cb5a41978a8c7":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"04f07771a2a7dd3a395700665ed839c3dae2def2":["7424161ac990ef8f959f09ee516148e4d12c48bc"],"0f4464508ee83288c8c4585b533f9faaa93aa314":["51f5280f31484820499077f41fcdfe92d527d9dc"],"7424161ac990ef8f959f09ee516148e4d12c48bc":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f":["04f07771a2a7dd3a395700665ed839c3dae2def2","322360ac5185a8446d3e0b530b2068bef67cd3d5"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":["04f07771a2a7dd3a395700665ed839c3dae2def2","322360ac5185a8446d3e0b530b2068bef67cd3d5"],"04e775de416dd2d8067b10db1c8af975a1d5017e":["0f4464508ee83288c8c4585b533f9faaa93aa314"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["322360ac5185a8446d3e0b530b2068bef67cd3d5"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["f08557cdb6c60ac7b88a9342c983a20cd236e74f"],"322360ac5185a8446d3e0b530b2068bef67cd3d5":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["04e775de416dd2d8067b10db1c8af975a1d5017e"]},"commit2Childs":{"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab":[],"f08557cdb6c60ac7b88a9342c983a20cd236e74f":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["6c2782fe88d18fedf3ef67402c9cb5a41978a8c7"],"2bb2842e561df4e8e9ad89010605fc86ac265465":["51f5280f31484820499077f41fcdfe92d527d9dc"],"51f5280f31484820499077f41fcdfe92d527d9dc":["0f4464508ee83288c8c4585b533f9faaa93aa314"],"6c2782fe88d18fedf3ef67402c9cb5a41978a8c7":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","f08557cdb6c60ac7b88a9342c983a20cd236e74f"],"04f07771a2a7dd3a395700665ed839c3dae2def2":["b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","d6f074e73200c07d54f242d3880a8da5a35ff97b","322360ac5185a8446d3e0b530b2068bef67cd3d5"],"0f4464508ee83288c8c4585b533f9faaa93aa314":["04e775de416dd2d8067b10db1c8af975a1d5017e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"7424161ac990ef8f959f09ee516148e4d12c48bc":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["2bb2842e561df4e8e9ad89010605fc86ac265465"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":[],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"04e775de416dd2d8067b10db1c8af975a1d5017e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["7424161ac990ef8f959f09ee516148e4d12c48bc"],"322360ac5185a8446d3e0b530b2068bef67cd3d5":["b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","d6f074e73200c07d54f242d3880a8da5a35ff97b","ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","d6f074e73200c07d54f242d3880a8da5a35ff97b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}