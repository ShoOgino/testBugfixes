{"path":"solr/src/test/org/apache/solr/analysis/BaseTokenTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[]).mjava","commits":[{"id":"893269407f5c988a4b2ee13c7ffc01ec43136c1d","date":1268598046,"type":0,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/src/test/org/apache/solr/analysis/BaseTokenTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[]).mjava","pathOld":"/dev/null","sourceNew":"  public static void assertTokenStreamContents(TokenStream ts, String[] output,\n      int startOffsets[], int endOffsets[], String types[], int posIncrements[])\n      throws IOException {\n    assertNotNull(output);\n    assertTrue(\"has TermAttribute\", ts.hasAttribute(TermAttribute.class));\n    TermAttribute termAtt = (TermAttribute) ts\n        .getAttribute(TermAttribute.class);\n    \n    OffsetAttribute offsetAtt = null;\n    if (startOffsets != null || endOffsets != null) {\n      assertTrue(\"has OffsetAttribute\", ts.hasAttribute(OffsetAttribute.class));\n      offsetAtt = (OffsetAttribute) ts.getAttribute(OffsetAttribute.class);\n    }\n    \n    TypeAttribute typeAtt = null;\n    if (types != null) {\n      assertTrue(\"has TypeAttribute\", ts.hasAttribute(TypeAttribute.class));\n      typeAtt = (TypeAttribute) ts.getAttribute(TypeAttribute.class);\n    }\n    \n    PositionIncrementAttribute posIncrAtt = null;\n    if (posIncrements != null) {\n      assertTrue(\"has PositionIncrementAttribute\", ts\n          .hasAttribute(PositionIncrementAttribute.class));\n      posIncrAtt = (PositionIncrementAttribute) ts\n          .getAttribute(PositionIncrementAttribute.class);\n    }\n    \n    ts.reset();\n    for (int i = 0; i < output.length; i++) {\n      // extra safety to enforce, that the state is not preserved and also\n      // assign bogus values\n      ts.clearAttributes();\n      termAtt.setTermBuffer(\"bogusTerm\");\n      if (offsetAtt != null) offsetAtt.setOffset(14584724, 24683243);\n      if (typeAtt != null) typeAtt.setType(\"bogusType\");\n      if (posIncrAtt != null) posIncrAtt.setPositionIncrement(45987657);\n      \n      assertTrue(\"token \" + i + \" exists\", ts.incrementToken());\n      assertEquals(\"term \" + i, output[i], termAtt.term());\n      if (startOffsets != null) assertEquals(\"startOffset \" + i,\n          startOffsets[i], offsetAtt.startOffset());\n      if (endOffsets != null) assertEquals(\"endOffset \" + i, endOffsets[i],\n          offsetAtt.endOffset());\n      if (types != null) assertEquals(\"type \" + i, types[i], typeAtt.type());\n      if (posIncrements != null) assertEquals(\"posIncrement \" + i,\n          posIncrements[i], posIncrAtt.getPositionIncrement());\n    }\n    assertFalse(\"end of stream\", ts.incrementToken());\n    ts.end();\n    ts.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8","date":1268599006,"type":4,"author":"Mark Robert Miller","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/src/test/org/apache/solr/analysis/BaseTokenTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[]).mjava","sourceNew":null,"sourceOld":"  public static void assertTokenStreamContents(TokenStream ts, String[] output,\n      int startOffsets[], int endOffsets[], String types[], int posIncrements[])\n      throws IOException {\n    assertNotNull(output);\n    assertTrue(\"has TermAttribute\", ts.hasAttribute(TermAttribute.class));\n    TermAttribute termAtt = (TermAttribute) ts\n        .getAttribute(TermAttribute.class);\n    \n    OffsetAttribute offsetAtt = null;\n    if (startOffsets != null || endOffsets != null) {\n      assertTrue(\"has OffsetAttribute\", ts.hasAttribute(OffsetAttribute.class));\n      offsetAtt = (OffsetAttribute) ts.getAttribute(OffsetAttribute.class);\n    }\n    \n    TypeAttribute typeAtt = null;\n    if (types != null) {\n      assertTrue(\"has TypeAttribute\", ts.hasAttribute(TypeAttribute.class));\n      typeAtt = (TypeAttribute) ts.getAttribute(TypeAttribute.class);\n    }\n    \n    PositionIncrementAttribute posIncrAtt = null;\n    if (posIncrements != null) {\n      assertTrue(\"has PositionIncrementAttribute\", ts\n          .hasAttribute(PositionIncrementAttribute.class));\n      posIncrAtt = (PositionIncrementAttribute) ts\n          .getAttribute(PositionIncrementAttribute.class);\n    }\n    \n    ts.reset();\n    for (int i = 0; i < output.length; i++) {\n      // extra safety to enforce, that the state is not preserved and also\n      // assign bogus values\n      ts.clearAttributes();\n      termAtt.setTermBuffer(\"bogusTerm\");\n      if (offsetAtt != null) offsetAtt.setOffset(14584724, 24683243);\n      if (typeAtt != null) typeAtt.setType(\"bogusType\");\n      if (posIncrAtt != null) posIncrAtt.setPositionIncrement(45987657);\n      \n      assertTrue(\"token \" + i + \" exists\", ts.incrementToken());\n      assertEquals(\"term \" + i, output[i], termAtt.term());\n      if (startOffsets != null) assertEquals(\"startOffset \" + i,\n          startOffsets[i], offsetAtt.startOffset());\n      if (endOffsets != null) assertEquals(\"endOffset \" + i, endOffsets[i],\n          offsetAtt.endOffset());\n      if (types != null) assertEquals(\"type \" + i, types[i], typeAtt.type());\n      if (posIncrements != null) assertEquals(\"posIncrement \" + i,\n          posIncrements[i], posIncrAtt.getPositionIncrement());\n    }\n    assertFalse(\"end of stream\", ts.incrementToken());\n    ts.end();\n    ts.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ad94625fb8d088209f46650c8097196fec67f00c","date":1453508319,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/src/test/org/apache/solr/analysis/BaseTokenTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[]).mjava","pathOld":"src/test/org/apache/solr/analysis/BaseTokenTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[]).mjava","sourceNew":"  public static void assertTokenStreamContents(TokenStream ts, String[] output,\n      int startOffsets[], int endOffsets[], String types[], int posIncrements[])\n      throws IOException {\n    assertNotNull(output);\n    assertTrue(\"has TermAttribute\", ts.hasAttribute(TermAttribute.class));\n    TermAttribute termAtt = (TermAttribute) ts\n        .getAttribute(TermAttribute.class);\n    \n    OffsetAttribute offsetAtt = null;\n    if (startOffsets != null || endOffsets != null) {\n      assertTrue(\"has OffsetAttribute\", ts.hasAttribute(OffsetAttribute.class));\n      offsetAtt = (OffsetAttribute) ts.getAttribute(OffsetAttribute.class);\n    }\n    \n    TypeAttribute typeAtt = null;\n    if (types != null) {\n      assertTrue(\"has TypeAttribute\", ts.hasAttribute(TypeAttribute.class));\n      typeAtt = (TypeAttribute) ts.getAttribute(TypeAttribute.class);\n    }\n    \n    PositionIncrementAttribute posIncrAtt = null;\n    if (posIncrements != null) {\n      assertTrue(\"has PositionIncrementAttribute\", ts\n          .hasAttribute(PositionIncrementAttribute.class));\n      posIncrAtt = (PositionIncrementAttribute) ts\n          .getAttribute(PositionIncrementAttribute.class);\n    }\n    \n    ts.reset();\n    for (int i = 0; i < output.length; i++) {\n      // extra safety to enforce, that the state is not preserved and also\n      // assign bogus values\n      ts.clearAttributes();\n      termAtt.setTermBuffer(\"bogusTerm\");\n      if (offsetAtt != null) offsetAtt.setOffset(14584724, 24683243);\n      if (typeAtt != null) typeAtt.setType(\"bogusType\");\n      if (posIncrAtt != null) posIncrAtt.setPositionIncrement(45987657);\n      \n      assertTrue(\"token \" + i + \" exists\", ts.incrementToken());\n      assertEquals(\"term \" + i, output[i], termAtt.term());\n      if (startOffsets != null) assertEquals(\"startOffset \" + i,\n          startOffsets[i], offsetAtt.startOffset());\n      if (endOffsets != null) assertEquals(\"endOffset \" + i, endOffsets[i],\n          offsetAtt.endOffset());\n      if (types != null) assertEquals(\"type \" + i, types[i], typeAtt.type());\n      if (posIncrements != null) assertEquals(\"posIncrement \" + i,\n          posIncrements[i], posIncrAtt.getPositionIncrement());\n    }\n    assertFalse(\"end of stream\", ts.incrementToken());\n    ts.end();\n    ts.close();\n  }\n\n","sourceOld":"  public static void assertTokenStreamContents(TokenStream ts, String[] output,\n      int startOffsets[], int endOffsets[], String types[], int posIncrements[])\n      throws IOException {\n    assertNotNull(output);\n    assertTrue(\"has TermAttribute\", ts.hasAttribute(TermAttribute.class));\n    TermAttribute termAtt = (TermAttribute) ts\n        .getAttribute(TermAttribute.class);\n    \n    OffsetAttribute offsetAtt = null;\n    if (startOffsets != null || endOffsets != null) {\n      assertTrue(\"has OffsetAttribute\", ts.hasAttribute(OffsetAttribute.class));\n      offsetAtt = (OffsetAttribute) ts.getAttribute(OffsetAttribute.class);\n    }\n    \n    TypeAttribute typeAtt = null;\n    if (types != null) {\n      assertTrue(\"has TypeAttribute\", ts.hasAttribute(TypeAttribute.class));\n      typeAtt = (TypeAttribute) ts.getAttribute(TypeAttribute.class);\n    }\n    \n    PositionIncrementAttribute posIncrAtt = null;\n    if (posIncrements != null) {\n      assertTrue(\"has PositionIncrementAttribute\", ts\n          .hasAttribute(PositionIncrementAttribute.class));\n      posIncrAtt = (PositionIncrementAttribute) ts\n          .getAttribute(PositionIncrementAttribute.class);\n    }\n    \n    ts.reset();\n    for (int i = 0; i < output.length; i++) {\n      // extra safety to enforce, that the state is not preserved and also\n      // assign bogus values\n      ts.clearAttributes();\n      termAtt.setTermBuffer(\"bogusTerm\");\n      if (offsetAtt != null) offsetAtt.setOffset(14584724, 24683243);\n      if (typeAtt != null) typeAtt.setType(\"bogusType\");\n      if (posIncrAtt != null) posIncrAtt.setPositionIncrement(45987657);\n      \n      assertTrue(\"token \" + i + \" exists\", ts.incrementToken());\n      assertEquals(\"term \" + i, output[i], termAtt.term());\n      if (startOffsets != null) assertEquals(\"startOffset \" + i,\n          startOffsets[i], offsetAtt.startOffset());\n      if (endOffsets != null) assertEquals(\"endOffset \" + i, endOffsets[i],\n          offsetAtt.endOffset());\n      if (types != null) assertEquals(\"type \" + i, types[i], typeAtt.type());\n      if (posIncrements != null) assertEquals(\"posIncrement \" + i,\n          posIncrements[i], posIncrAtt.getPositionIncrement());\n    }\n    assertFalse(\"end of stream\", ts.incrementToken());\n    ts.end();\n    ts.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1da8d55113b689b06716246649de6f62430f15c0","date":1453508340,"type":0,"author":"Dawid Weiss","isMerge":true,"pathNew":"solr/src/test/org/apache/solr/analysis/BaseTokenTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[]).mjava","pathOld":"/dev/null","sourceNew":"  public static void assertTokenStreamContents(TokenStream ts, String[] output,\n      int startOffsets[], int endOffsets[], String types[], int posIncrements[])\n      throws IOException {\n    assertNotNull(output);\n    assertTrue(\"has TermAttribute\", ts.hasAttribute(TermAttribute.class));\n    TermAttribute termAtt = (TermAttribute) ts\n        .getAttribute(TermAttribute.class);\n    \n    OffsetAttribute offsetAtt = null;\n    if (startOffsets != null || endOffsets != null) {\n      assertTrue(\"has OffsetAttribute\", ts.hasAttribute(OffsetAttribute.class));\n      offsetAtt = (OffsetAttribute) ts.getAttribute(OffsetAttribute.class);\n    }\n    \n    TypeAttribute typeAtt = null;\n    if (types != null) {\n      assertTrue(\"has TypeAttribute\", ts.hasAttribute(TypeAttribute.class));\n      typeAtt = (TypeAttribute) ts.getAttribute(TypeAttribute.class);\n    }\n    \n    PositionIncrementAttribute posIncrAtt = null;\n    if (posIncrements != null) {\n      assertTrue(\"has PositionIncrementAttribute\", ts\n          .hasAttribute(PositionIncrementAttribute.class));\n      posIncrAtt = (PositionIncrementAttribute) ts\n          .getAttribute(PositionIncrementAttribute.class);\n    }\n    \n    ts.reset();\n    for (int i = 0; i < output.length; i++) {\n      // extra safety to enforce, that the state is not preserved and also\n      // assign bogus values\n      ts.clearAttributes();\n      termAtt.setTermBuffer(\"bogusTerm\");\n      if (offsetAtt != null) offsetAtt.setOffset(14584724, 24683243);\n      if (typeAtt != null) typeAtt.setType(\"bogusType\");\n      if (posIncrAtt != null) posIncrAtt.setPositionIncrement(45987657);\n      \n      assertTrue(\"token \" + i + \" exists\", ts.incrementToken());\n      assertEquals(\"term \" + i, output[i], termAtt.term());\n      if (startOffsets != null) assertEquals(\"startOffset \" + i,\n          startOffsets[i], offsetAtt.startOffset());\n      if (endOffsets != null) assertEquals(\"endOffset \" + i, endOffsets[i],\n          offsetAtt.endOffset());\n      if (types != null) assertEquals(\"type \" + i, types[i], typeAtt.type());\n      if (posIncrements != null) assertEquals(\"posIncrement \" + i,\n          posIncrements[i], posIncrAtt.getPositionIncrement());\n    }\n    assertFalse(\"end of stream\", ts.incrementToken());\n    ts.end();\n    ts.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"531bb2fb94d9781cd3da5dcee4712e5fccd6f214","date":1269118795,"type":4,"author":"Robert Muir","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/src/test/org/apache/solr/analysis/BaseTokenTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[]).mjava","sourceNew":null,"sourceOld":"  public static void assertTokenStreamContents(TokenStream ts, String[] output,\n      int startOffsets[], int endOffsets[], String types[], int posIncrements[])\n      throws IOException {\n    assertNotNull(output);\n    assertTrue(\"has TermAttribute\", ts.hasAttribute(TermAttribute.class));\n    TermAttribute termAtt = (TermAttribute) ts\n        .getAttribute(TermAttribute.class);\n    \n    OffsetAttribute offsetAtt = null;\n    if (startOffsets != null || endOffsets != null) {\n      assertTrue(\"has OffsetAttribute\", ts.hasAttribute(OffsetAttribute.class));\n      offsetAtt = (OffsetAttribute) ts.getAttribute(OffsetAttribute.class);\n    }\n    \n    TypeAttribute typeAtt = null;\n    if (types != null) {\n      assertTrue(\"has TypeAttribute\", ts.hasAttribute(TypeAttribute.class));\n      typeAtt = (TypeAttribute) ts.getAttribute(TypeAttribute.class);\n    }\n    \n    PositionIncrementAttribute posIncrAtt = null;\n    if (posIncrements != null) {\n      assertTrue(\"has PositionIncrementAttribute\", ts\n          .hasAttribute(PositionIncrementAttribute.class));\n      posIncrAtt = (PositionIncrementAttribute) ts\n          .getAttribute(PositionIncrementAttribute.class);\n    }\n    \n    ts.reset();\n    for (int i = 0; i < output.length; i++) {\n      // extra safety to enforce, that the state is not preserved and also\n      // assign bogus values\n      ts.clearAttributes();\n      termAtt.setTermBuffer(\"bogusTerm\");\n      if (offsetAtt != null) offsetAtt.setOffset(14584724, 24683243);\n      if (typeAtt != null) typeAtt.setType(\"bogusType\");\n      if (posIncrAtt != null) posIncrAtt.setPositionIncrement(45987657);\n      \n      assertTrue(\"token \" + i + \" exists\", ts.incrementToken());\n      assertEquals(\"term \" + i, output[i], termAtt.term());\n      if (startOffsets != null) assertEquals(\"startOffset \" + i,\n          startOffsets[i], offsetAtt.startOffset());\n      if (endOffsets != null) assertEquals(\"endOffset \" + i, endOffsets[i],\n          offsetAtt.endOffset());\n      if (types != null) assertEquals(\"type \" + i, types[i], typeAtt.type());\n      if (posIncrements != null) assertEquals(\"posIncrement \" + i,\n          posIncrements[i], posIncrAtt.getPositionIncrement());\n    }\n    assertFalse(\"end of stream\", ts.incrementToken());\n    ts.end();\n    ts.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"1da8d55113b689b06716246649de6f62430f15c0":["a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8","ad94625fb8d088209f46650c8097196fec67f00c"],"893269407f5c988a4b2ee13c7ffc01ec43136c1d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8":["893269407f5c988a4b2ee13c7ffc01ec43136c1d"],"531bb2fb94d9781cd3da5dcee4712e5fccd6f214":["1da8d55113b689b06716246649de6f62430f15c0"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":[],"ad94625fb8d088209f46650c8097196fec67f00c":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["531bb2fb94d9781cd3da5dcee4712e5fccd6f214"]},"commit2Childs":{"1da8d55113b689b06716246649de6f62430f15c0":["531bb2fb94d9781cd3da5dcee4712e5fccd6f214"],"893269407f5c988a4b2ee13c7ffc01ec43136c1d":["a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8"],"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8":["1da8d55113b689b06716246649de6f62430f15c0"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["893269407f5c988a4b2ee13c7ffc01ec43136c1d"],"531bb2fb94d9781cd3da5dcee4712e5fccd6f214":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":["ad94625fb8d088209f46650c8097196fec67f00c"],"ad94625fb8d088209f46650c8097196fec67f00c":["1da8d55113b689b06716246649de6f62430f15c0"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"pathCommit":null}