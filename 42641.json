{"path":"lucene/core/src/java/org/apache/lucene/search/PhraseQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","commits":[{"id":"9fc47cb7b4346802411bb432f501ed0673d7119e","date":1512640179,"type":0,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/PhraseQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    return new PhraseWeight(searcher, scoreMode.needsScores(), boost);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"417142ff08fda9cf0b72d5133e63097a166c6458","date":1512729693,"type":0,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/search/PhraseQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    return new PhraseWeight(searcher, scoreMode.needsScores(), boost);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"33eef98c565ee21b199f04b92acd6e00b842bd1e","date":1514538360,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/PhraseQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/PhraseQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    return new PhraseWeight(searcher, scoreMode, boost);\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    return new PhraseWeight(searcher, scoreMode.needsScores(), boost);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3b11b9d5eaf9707760ca5151530830a825197023","date":1525941319,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/PhraseQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/PhraseQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    return new PhraseWeight(this, field, searcher, scoreMode) {\n\n      private transient TermStates states[];\n\n      @Override\n      protected Similarity.SimScorer getStats(IndexSearcher searcher) throws IOException {\n        final int[] positions = PhraseQuery.this.getPositions();\n        if (positions.length < 2) {\n          throw new IllegalStateException(\"PhraseWeight does not support less than 2 terms, call rewrite first\");\n        } else if (positions[0] != 0) {\n          throw new IllegalStateException(\"PhraseWeight requires that the first position is 0, call rewrite first\");\n        }\n        final IndexReaderContext context = searcher.getTopReaderContext();\n        states = new TermStates[terms.length];\n        TermStatistics termStats[] = new TermStatistics[terms.length];\n        int termUpTo = 0;\n        for (int i = 0; i < terms.length; i++) {\n          final Term term = terms[i];\n          states[i] = TermStates.build(context, term, scoreMode.needsScores());\n          if (scoreMode.needsScores()) {\n            TermStatistics termStatistics = searcher.termStatistics(term, states[i]);\n            if (termStatistics != null) {\n              termStats[termUpTo++] = termStatistics;\n            }\n          }\n        }\n        if (termUpTo > 0) {\n          return similarity.scorer(boost, searcher.collectionStatistics(field), Arrays.copyOf(termStats, termUpTo));\n        } else {\n          return null; // no terms at all, we won't use similarity\n        }\n      }\n\n      @Override\n      protected PhraseMatcher getPhraseMatcher(LeafReaderContext context, boolean exposeOffsets) throws IOException {\n        assert terms.length > 0;\n        final LeafReader reader = context.reader();\n        PostingsAndFreq[] postingsFreqs = new PostingsAndFreq[terms.length];\n\n        final Terms fieldTerms = reader.terms(field);\n        if (fieldTerms == null) {\n          return null;\n        }\n\n        if (fieldTerms.hasPositions() == false) {\n          throw new IllegalStateException(\"field \\\"\" + field + \"\\\" was indexed without position data; cannot run PhraseQuery (phrase=\" + getQuery() + \")\");\n        }\n\n        // Reuse single TermsEnum below:\n        final TermsEnum te = fieldTerms.iterator();\n        float totalMatchCost = 0;\n\n        for (int i = 0; i < terms.length; i++) {\n          final Term t = terms[i];\n          final TermState state = states[i].get(context);\n          if (state == null) { /* term doesnt exist in this segment */\n            assert termNotInReader(reader, t): \"no termstate found but term exists in reader\";\n            return null;\n          }\n          te.seekExact(t.bytes(), state);\n          PostingsEnum postingsEnum = te.postings(null, exposeOffsets ? PostingsEnum.OFFSETS : PostingsEnum.POSITIONS);\n          postingsFreqs[i] = new PostingsAndFreq(postingsEnum, positions[i], t);\n          totalMatchCost += termPositionsCost(te);\n        }\n\n        // sort by increasing docFreq order\n        if (slop == 0) {\n          ArrayUtil.timSort(postingsFreqs);\n          return new ExactPhraseMatcher(postingsFreqs, totalMatchCost);\n        }\n        else {\n          return new SloppyPhraseMatcher(postingsFreqs, slop, totalMatchCost);\n        }\n      }\n\n      @Override\n      public void extractTerms(Set<Term> queryTerms) {\n        Collections.addAll(queryTerms, terms);\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    return new PhraseWeight(searcher, scoreMode, boost);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9798d0818e7a880546802b509792d3f3d57babd2","date":1528358901,"type":3,"author":"Nhat Nguyen","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/PhraseQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/PhraseQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    return new PhraseWeight(this, field, searcher, scoreMode) {\n\n      private transient TermStates states[];\n\n      @Override\n      protected Similarity.SimScorer getStats(IndexSearcher searcher) throws IOException {\n        final int[] positions = PhraseQuery.this.getPositions();\n        if (positions.length < 2) {\n          throw new IllegalStateException(\"PhraseWeight does not support less than 2 terms, call rewrite first\");\n        } else if (positions[0] != 0) {\n          throw new IllegalStateException(\"PhraseWeight requires that the first position is 0, call rewrite first\");\n        }\n        final IndexReaderContext context = searcher.getTopReaderContext();\n        states = new TermStates[terms.length];\n        TermStatistics termStats[] = new TermStatistics[terms.length];\n        int termUpTo = 0;\n        for (int i = 0; i < terms.length; i++) {\n          final Term term = terms[i];\n          states[i] = TermStates.build(context, term, scoreMode.needsScores());\n          if (scoreMode.needsScores()) {\n            TermStatistics termStatistics = searcher.termStatistics(term, states[i]);\n            if (termStatistics != null) {\n              termStats[termUpTo++] = termStatistics;\n            }\n          }\n        }\n        if (termUpTo > 0) {\n          return similarity.scorer(boost, searcher.collectionStatistics(field), ArrayUtil.copyOfSubArray(termStats, 0, termUpTo));\n        } else {\n          return null; // no terms at all, we won't use similarity\n        }\n      }\n\n      @Override\n      protected PhraseMatcher getPhraseMatcher(LeafReaderContext context, boolean exposeOffsets) throws IOException {\n        assert terms.length > 0;\n        final LeafReader reader = context.reader();\n        PostingsAndFreq[] postingsFreqs = new PostingsAndFreq[terms.length];\n\n        final Terms fieldTerms = reader.terms(field);\n        if (fieldTerms == null) {\n          return null;\n        }\n\n        if (fieldTerms.hasPositions() == false) {\n          throw new IllegalStateException(\"field \\\"\" + field + \"\\\" was indexed without position data; cannot run PhraseQuery (phrase=\" + getQuery() + \")\");\n        }\n\n        // Reuse single TermsEnum below:\n        final TermsEnum te = fieldTerms.iterator();\n        float totalMatchCost = 0;\n\n        for (int i = 0; i < terms.length; i++) {\n          final Term t = terms[i];\n          final TermState state = states[i].get(context);\n          if (state == null) { /* term doesnt exist in this segment */\n            assert termNotInReader(reader, t): \"no termstate found but term exists in reader\";\n            return null;\n          }\n          te.seekExact(t.bytes(), state);\n          PostingsEnum postingsEnum = te.postings(null, exposeOffsets ? PostingsEnum.OFFSETS : PostingsEnum.POSITIONS);\n          postingsFreqs[i] = new PostingsAndFreq(postingsEnum, positions[i], t);\n          totalMatchCost += termPositionsCost(te);\n        }\n\n        // sort by increasing docFreq order\n        if (slop == 0) {\n          ArrayUtil.timSort(postingsFreqs);\n          return new ExactPhraseMatcher(postingsFreqs, totalMatchCost);\n        }\n        else {\n          return new SloppyPhraseMatcher(postingsFreqs, slop, totalMatchCost);\n        }\n      }\n\n      @Override\n      public void extractTerms(Set<Term> queryTerms) {\n        Collections.addAll(queryTerms, terms);\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    return new PhraseWeight(this, field, searcher, scoreMode) {\n\n      private transient TermStates states[];\n\n      @Override\n      protected Similarity.SimScorer getStats(IndexSearcher searcher) throws IOException {\n        final int[] positions = PhraseQuery.this.getPositions();\n        if (positions.length < 2) {\n          throw new IllegalStateException(\"PhraseWeight does not support less than 2 terms, call rewrite first\");\n        } else if (positions[0] != 0) {\n          throw new IllegalStateException(\"PhraseWeight requires that the first position is 0, call rewrite first\");\n        }\n        final IndexReaderContext context = searcher.getTopReaderContext();\n        states = new TermStates[terms.length];\n        TermStatistics termStats[] = new TermStatistics[terms.length];\n        int termUpTo = 0;\n        for (int i = 0; i < terms.length; i++) {\n          final Term term = terms[i];\n          states[i] = TermStates.build(context, term, scoreMode.needsScores());\n          if (scoreMode.needsScores()) {\n            TermStatistics termStatistics = searcher.termStatistics(term, states[i]);\n            if (termStatistics != null) {\n              termStats[termUpTo++] = termStatistics;\n            }\n          }\n        }\n        if (termUpTo > 0) {\n          return similarity.scorer(boost, searcher.collectionStatistics(field), Arrays.copyOf(termStats, termUpTo));\n        } else {\n          return null; // no terms at all, we won't use similarity\n        }\n      }\n\n      @Override\n      protected PhraseMatcher getPhraseMatcher(LeafReaderContext context, boolean exposeOffsets) throws IOException {\n        assert terms.length > 0;\n        final LeafReader reader = context.reader();\n        PostingsAndFreq[] postingsFreqs = new PostingsAndFreq[terms.length];\n\n        final Terms fieldTerms = reader.terms(field);\n        if (fieldTerms == null) {\n          return null;\n        }\n\n        if (fieldTerms.hasPositions() == false) {\n          throw new IllegalStateException(\"field \\\"\" + field + \"\\\" was indexed without position data; cannot run PhraseQuery (phrase=\" + getQuery() + \")\");\n        }\n\n        // Reuse single TermsEnum below:\n        final TermsEnum te = fieldTerms.iterator();\n        float totalMatchCost = 0;\n\n        for (int i = 0; i < terms.length; i++) {\n          final Term t = terms[i];\n          final TermState state = states[i].get(context);\n          if (state == null) { /* term doesnt exist in this segment */\n            assert termNotInReader(reader, t): \"no termstate found but term exists in reader\";\n            return null;\n          }\n          te.seekExact(t.bytes(), state);\n          PostingsEnum postingsEnum = te.postings(null, exposeOffsets ? PostingsEnum.OFFSETS : PostingsEnum.POSITIONS);\n          postingsFreqs[i] = new PostingsAndFreq(postingsEnum, positions[i], t);\n          totalMatchCost += termPositionsCost(te);\n        }\n\n        // sort by increasing docFreq order\n        if (slop == 0) {\n          ArrayUtil.timSort(postingsFreqs);\n          return new ExactPhraseMatcher(postingsFreqs, totalMatchCost);\n        }\n        else {\n          return new SloppyPhraseMatcher(postingsFreqs, slop, totalMatchCost);\n        }\n      }\n\n      @Override\n      public void extractTerms(Set<Term> queryTerms) {\n        Collections.addAll(queryTerms, terms);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b70042a8a492f7054d480ccdd2be9796510d4327","date":1528386658,"type":3,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/search/PhraseQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/PhraseQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    return new PhraseWeight(this, field, searcher, scoreMode) {\n\n      private transient TermStates states[];\n\n      @Override\n      protected Similarity.SimScorer getStats(IndexSearcher searcher) throws IOException {\n        final int[] positions = PhraseQuery.this.getPositions();\n        if (positions.length < 2) {\n          throw new IllegalStateException(\"PhraseWeight does not support less than 2 terms, call rewrite first\");\n        } else if (positions[0] != 0) {\n          throw new IllegalStateException(\"PhraseWeight requires that the first position is 0, call rewrite first\");\n        }\n        final IndexReaderContext context = searcher.getTopReaderContext();\n        states = new TermStates[terms.length];\n        TermStatistics termStats[] = new TermStatistics[terms.length];\n        int termUpTo = 0;\n        for (int i = 0; i < terms.length; i++) {\n          final Term term = terms[i];\n          states[i] = TermStates.build(context, term, scoreMode.needsScores());\n          if (scoreMode.needsScores()) {\n            TermStatistics termStatistics = searcher.termStatistics(term, states[i]);\n            if (termStatistics != null) {\n              termStats[termUpTo++] = termStatistics;\n            }\n          }\n        }\n        if (termUpTo > 0) {\n          return similarity.scorer(boost, searcher.collectionStatistics(field), ArrayUtil.copyOfSubArray(termStats, 0, termUpTo));\n        } else {\n          return null; // no terms at all, we won't use similarity\n        }\n      }\n\n      @Override\n      protected PhraseMatcher getPhraseMatcher(LeafReaderContext context, boolean exposeOffsets) throws IOException {\n        assert terms.length > 0;\n        final LeafReader reader = context.reader();\n        PostingsAndFreq[] postingsFreqs = new PostingsAndFreq[terms.length];\n\n        final Terms fieldTerms = reader.terms(field);\n        if (fieldTerms == null) {\n          return null;\n        }\n\n        if (fieldTerms.hasPositions() == false) {\n          throw new IllegalStateException(\"field \\\"\" + field + \"\\\" was indexed without position data; cannot run PhraseQuery (phrase=\" + getQuery() + \")\");\n        }\n\n        // Reuse single TermsEnum below:\n        final TermsEnum te = fieldTerms.iterator();\n        float totalMatchCost = 0;\n\n        for (int i = 0; i < terms.length; i++) {\n          final Term t = terms[i];\n          final TermState state = states[i].get(context);\n          if (state == null) { /* term doesnt exist in this segment */\n            assert termNotInReader(reader, t): \"no termstate found but term exists in reader\";\n            return null;\n          }\n          te.seekExact(t.bytes(), state);\n          PostingsEnum postingsEnum = te.postings(null, exposeOffsets ? PostingsEnum.OFFSETS : PostingsEnum.POSITIONS);\n          postingsFreqs[i] = new PostingsAndFreq(postingsEnum, positions[i], t);\n          totalMatchCost += termPositionsCost(te);\n        }\n\n        // sort by increasing docFreq order\n        if (slop == 0) {\n          ArrayUtil.timSort(postingsFreqs);\n          return new ExactPhraseMatcher(postingsFreqs, totalMatchCost);\n        }\n        else {\n          return new SloppyPhraseMatcher(postingsFreqs, slop, totalMatchCost);\n        }\n      }\n\n      @Override\n      public void extractTerms(Set<Term> queryTerms) {\n        Collections.addAll(queryTerms, terms);\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    return new PhraseWeight(this, field, searcher, scoreMode) {\n\n      private transient TermStates states[];\n\n      @Override\n      protected Similarity.SimScorer getStats(IndexSearcher searcher) throws IOException {\n        final int[] positions = PhraseQuery.this.getPositions();\n        if (positions.length < 2) {\n          throw new IllegalStateException(\"PhraseWeight does not support less than 2 terms, call rewrite first\");\n        } else if (positions[0] != 0) {\n          throw new IllegalStateException(\"PhraseWeight requires that the first position is 0, call rewrite first\");\n        }\n        final IndexReaderContext context = searcher.getTopReaderContext();\n        states = new TermStates[terms.length];\n        TermStatistics termStats[] = new TermStatistics[terms.length];\n        int termUpTo = 0;\n        for (int i = 0; i < terms.length; i++) {\n          final Term term = terms[i];\n          states[i] = TermStates.build(context, term, scoreMode.needsScores());\n          if (scoreMode.needsScores()) {\n            TermStatistics termStatistics = searcher.termStatistics(term, states[i]);\n            if (termStatistics != null) {\n              termStats[termUpTo++] = termStatistics;\n            }\n          }\n        }\n        if (termUpTo > 0) {\n          return similarity.scorer(boost, searcher.collectionStatistics(field), Arrays.copyOf(termStats, termUpTo));\n        } else {\n          return null; // no terms at all, we won't use similarity\n        }\n      }\n\n      @Override\n      protected PhraseMatcher getPhraseMatcher(LeafReaderContext context, boolean exposeOffsets) throws IOException {\n        assert terms.length > 0;\n        final LeafReader reader = context.reader();\n        PostingsAndFreq[] postingsFreqs = new PostingsAndFreq[terms.length];\n\n        final Terms fieldTerms = reader.terms(field);\n        if (fieldTerms == null) {\n          return null;\n        }\n\n        if (fieldTerms.hasPositions() == false) {\n          throw new IllegalStateException(\"field \\\"\" + field + \"\\\" was indexed without position data; cannot run PhraseQuery (phrase=\" + getQuery() + \")\");\n        }\n\n        // Reuse single TermsEnum below:\n        final TermsEnum te = fieldTerms.iterator();\n        float totalMatchCost = 0;\n\n        for (int i = 0; i < terms.length; i++) {\n          final Term t = terms[i];\n          final TermState state = states[i].get(context);\n          if (state == null) { /* term doesnt exist in this segment */\n            assert termNotInReader(reader, t): \"no termstate found but term exists in reader\";\n            return null;\n          }\n          te.seekExact(t.bytes(), state);\n          PostingsEnum postingsEnum = te.postings(null, exposeOffsets ? PostingsEnum.OFFSETS : PostingsEnum.POSITIONS);\n          postingsFreqs[i] = new PostingsAndFreq(postingsEnum, positions[i], t);\n          totalMatchCost += termPositionsCost(te);\n        }\n\n        // sort by increasing docFreq order\n        if (slop == 0) {\n          ArrayUtil.timSort(postingsFreqs);\n          return new ExactPhraseMatcher(postingsFreqs, totalMatchCost);\n        }\n        else {\n          return new SloppyPhraseMatcher(postingsFreqs, slop, totalMatchCost);\n        }\n      }\n\n      @Override\n      public void extractTerms(Set<Term> queryTerms) {\n        Collections.addAll(queryTerms, terms);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26","date":1531589977,"type":3,"author":"Michael Braun","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/search/PhraseQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/PhraseQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    return new PhraseWeight(this, field, searcher, scoreMode) {\n\n      private transient TermStates states[];\n\n      @Override\n      protected Similarity.SimScorer getStats(IndexSearcher searcher) throws IOException {\n        final int[] positions = PhraseQuery.this.getPositions();\n        if (positions.length < 2) {\n          throw new IllegalStateException(\"PhraseWeight does not support less than 2 terms, call rewrite first\");\n        } else if (positions[0] != 0) {\n          throw new IllegalStateException(\"PhraseWeight requires that the first position is 0, call rewrite first\");\n        }\n        final IndexReaderContext context = searcher.getTopReaderContext();\n        states = new TermStates[terms.length];\n        TermStatistics termStats[] = new TermStatistics[terms.length];\n        int termUpTo = 0;\n        for (int i = 0; i < terms.length; i++) {\n          final Term term = terms[i];\n          states[i] = TermStates.build(context, term, scoreMode.needsScores());\n          if (scoreMode.needsScores()) {\n            TermStatistics termStatistics = searcher.termStatistics(term, states[i]);\n            if (termStatistics != null) {\n              termStats[termUpTo++] = termStatistics;\n            }\n          }\n        }\n        if (termUpTo > 0) {\n          return similarity.scorer(boost, searcher.collectionStatistics(field), ArrayUtil.copyOfSubArray(termStats, 0, termUpTo));\n        } else {\n          return null; // no terms at all, we won't use similarity\n        }\n      }\n\n      @Override\n      protected PhraseMatcher getPhraseMatcher(LeafReaderContext context, boolean exposeOffsets) throws IOException {\n        assert terms.length > 0;\n        final LeafReader reader = context.reader();\n        PostingsAndFreq[] postingsFreqs = new PostingsAndFreq[terms.length];\n\n        final Terms fieldTerms = reader.terms(field);\n        if (fieldTerms == null) {\n          return null;\n        }\n\n        if (fieldTerms.hasPositions() == false) {\n          throw new IllegalStateException(\"field \\\"\" + field + \"\\\" was indexed without position data; cannot run PhraseQuery (phrase=\" + getQuery() + \")\");\n        }\n\n        // Reuse single TermsEnum below:\n        final TermsEnum te = fieldTerms.iterator();\n        float totalMatchCost = 0;\n\n        for (int i = 0; i < terms.length; i++) {\n          final Term t = terms[i];\n          final TermState state = states[i].get(context);\n          if (state == null) { /* term doesnt exist in this segment */\n            assert termNotInReader(reader, t): \"no termstate found but term exists in reader\";\n            return null;\n          }\n          te.seekExact(t.bytes(), state);\n          PostingsEnum postingsEnum = te.postings(null, exposeOffsets ? PostingsEnum.OFFSETS : PostingsEnum.POSITIONS);\n          postingsFreqs[i] = new PostingsAndFreq(postingsEnum, positions[i], t);\n          totalMatchCost += termPositionsCost(te);\n        }\n\n        // sort by increasing docFreq order\n        if (slop == 0) {\n          ArrayUtil.timSort(postingsFreqs);\n          return new ExactPhraseMatcher(postingsFreqs, totalMatchCost);\n        }\n        else {\n          return new SloppyPhraseMatcher(postingsFreqs, slop, totalMatchCost);\n        }\n      }\n\n      @Override\n      public void extractTerms(Set<Term> queryTerms) {\n        Collections.addAll(queryTerms, terms);\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    return new PhraseWeight(this, field, searcher, scoreMode) {\n\n      private transient TermStates states[];\n\n      @Override\n      protected Similarity.SimScorer getStats(IndexSearcher searcher) throws IOException {\n        final int[] positions = PhraseQuery.this.getPositions();\n        if (positions.length < 2) {\n          throw new IllegalStateException(\"PhraseWeight does not support less than 2 terms, call rewrite first\");\n        } else if (positions[0] != 0) {\n          throw new IllegalStateException(\"PhraseWeight requires that the first position is 0, call rewrite first\");\n        }\n        final IndexReaderContext context = searcher.getTopReaderContext();\n        states = new TermStates[terms.length];\n        TermStatistics termStats[] = new TermStatistics[terms.length];\n        int termUpTo = 0;\n        for (int i = 0; i < terms.length; i++) {\n          final Term term = terms[i];\n          states[i] = TermStates.build(context, term, scoreMode.needsScores());\n          if (scoreMode.needsScores()) {\n            TermStatistics termStatistics = searcher.termStatistics(term, states[i]);\n            if (termStatistics != null) {\n              termStats[termUpTo++] = termStatistics;\n            }\n          }\n        }\n        if (termUpTo > 0) {\n          return similarity.scorer(boost, searcher.collectionStatistics(field), Arrays.copyOf(termStats, termUpTo));\n        } else {\n          return null; // no terms at all, we won't use similarity\n        }\n      }\n\n      @Override\n      protected PhraseMatcher getPhraseMatcher(LeafReaderContext context, boolean exposeOffsets) throws IOException {\n        assert terms.length > 0;\n        final LeafReader reader = context.reader();\n        PostingsAndFreq[] postingsFreqs = new PostingsAndFreq[terms.length];\n\n        final Terms fieldTerms = reader.terms(field);\n        if (fieldTerms == null) {\n          return null;\n        }\n\n        if (fieldTerms.hasPositions() == false) {\n          throw new IllegalStateException(\"field \\\"\" + field + \"\\\" was indexed without position data; cannot run PhraseQuery (phrase=\" + getQuery() + \")\");\n        }\n\n        // Reuse single TermsEnum below:\n        final TermsEnum te = fieldTerms.iterator();\n        float totalMatchCost = 0;\n\n        for (int i = 0; i < terms.length; i++) {\n          final Term t = terms[i];\n          final TermState state = states[i].get(context);\n          if (state == null) { /* term doesnt exist in this segment */\n            assert termNotInReader(reader, t): \"no termstate found but term exists in reader\";\n            return null;\n          }\n          te.seekExact(t.bytes(), state);\n          PostingsEnum postingsEnum = te.postings(null, exposeOffsets ? PostingsEnum.OFFSETS : PostingsEnum.POSITIONS);\n          postingsFreqs[i] = new PostingsAndFreq(postingsEnum, positions[i], t);\n          totalMatchCost += termPositionsCost(te);\n        }\n\n        // sort by increasing docFreq order\n        if (slop == 0) {\n          ArrayUtil.timSort(postingsFreqs);\n          return new ExactPhraseMatcher(postingsFreqs, totalMatchCost);\n        }\n        else {\n          return new SloppyPhraseMatcher(postingsFreqs, slop, totalMatchCost);\n        }\n      }\n\n      @Override\n      public void extractTerms(Set<Term> queryTerms) {\n        Collections.addAll(queryTerms, terms);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"165c3432cb3c4fcfc8e859af24323bbbd12084af","date":1532292166,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/PhraseQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/PhraseQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    return new PhraseWeight(this, field, searcher, scoreMode) {\n\n      private transient TermStates states[];\n\n      @Override\n      protected Similarity.SimScorer getStats(IndexSearcher searcher) throws IOException {\n        final int[] positions = PhraseQuery.this.getPositions();\n        if (positions.length < 2) {\n          throw new IllegalStateException(\"PhraseWeight does not support less than 2 terms, call rewrite first\");\n        } else if (positions[0] != 0) {\n          throw new IllegalStateException(\"PhraseWeight requires that the first position is 0, call rewrite first\");\n        }\n        final IndexReaderContext context = searcher.getTopReaderContext();\n        states = new TermStates[terms.length];\n        TermStatistics termStats[] = new TermStatistics[terms.length];\n        int termUpTo = 0;\n        for (int i = 0; i < terms.length; i++) {\n          final Term term = terms[i];\n          states[i] = TermStates.build(context, term, scoreMode.needsScores());\n          if (scoreMode.needsScores()) {\n            TermStatistics termStatistics = searcher.termStatistics(term, states[i]);\n            if (termStatistics != null) {\n              termStats[termUpTo++] = termStatistics;\n            }\n          }\n        }\n        if (termUpTo > 0) {\n          return similarity.scorer(boost, searcher.collectionStatistics(field), ArrayUtil.copyOfSubArray(termStats, 0, termUpTo));\n        } else {\n          return null; // no terms at all, we won't use similarity\n        }\n      }\n\n      @Override\n      protected PhraseMatcher getPhraseMatcher(LeafReaderContext context, boolean exposeOffsets) throws IOException {\n        assert terms.length > 0;\n        final LeafReader reader = context.reader();\n        PostingsAndFreq[] postingsFreqs = new PostingsAndFreq[terms.length];\n\n        final Terms fieldTerms = reader.terms(field);\n        if (fieldTerms == null) {\n          return null;\n        }\n\n        if (fieldTerms.hasPositions() == false) {\n          throw new IllegalStateException(\"field \\\"\" + field + \"\\\" was indexed without position data; cannot run PhraseQuery (phrase=\" + getQuery() + \")\");\n        }\n\n        // Reuse single TermsEnum below:\n        final TermsEnum te = fieldTerms.iterator();\n        float totalMatchCost = 0;\n\n        for (int i = 0; i < terms.length; i++) {\n          final Term t = terms[i];\n          final TermState state = states[i].get(context);\n          if (state == null) { /* term doesnt exist in this segment */\n            assert termNotInReader(reader, t): \"no termstate found but term exists in reader\";\n            return null;\n          }\n          te.seekExact(t.bytes(), state);\n          PostingsEnum postingsEnum = te.postings(null, exposeOffsets ? PostingsEnum.ALL : PostingsEnum.POSITIONS);\n          postingsFreqs[i] = new PostingsAndFreq(postingsEnum, positions[i], t);\n          totalMatchCost += termPositionsCost(te);\n        }\n\n        // sort by increasing docFreq order\n        if (slop == 0) {\n          ArrayUtil.timSort(postingsFreqs);\n          return new ExactPhraseMatcher(postingsFreqs, totalMatchCost);\n        }\n        else {\n          return new SloppyPhraseMatcher(postingsFreqs, slop, totalMatchCost, exposeOffsets);\n        }\n      }\n\n      @Override\n      public void extractTerms(Set<Term> queryTerms) {\n        Collections.addAll(queryTerms, terms);\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    return new PhraseWeight(this, field, searcher, scoreMode) {\n\n      private transient TermStates states[];\n\n      @Override\n      protected Similarity.SimScorer getStats(IndexSearcher searcher) throws IOException {\n        final int[] positions = PhraseQuery.this.getPositions();\n        if (positions.length < 2) {\n          throw new IllegalStateException(\"PhraseWeight does not support less than 2 terms, call rewrite first\");\n        } else if (positions[0] != 0) {\n          throw new IllegalStateException(\"PhraseWeight requires that the first position is 0, call rewrite first\");\n        }\n        final IndexReaderContext context = searcher.getTopReaderContext();\n        states = new TermStates[terms.length];\n        TermStatistics termStats[] = new TermStatistics[terms.length];\n        int termUpTo = 0;\n        for (int i = 0; i < terms.length; i++) {\n          final Term term = terms[i];\n          states[i] = TermStates.build(context, term, scoreMode.needsScores());\n          if (scoreMode.needsScores()) {\n            TermStatistics termStatistics = searcher.termStatistics(term, states[i]);\n            if (termStatistics != null) {\n              termStats[termUpTo++] = termStatistics;\n            }\n          }\n        }\n        if (termUpTo > 0) {\n          return similarity.scorer(boost, searcher.collectionStatistics(field), ArrayUtil.copyOfSubArray(termStats, 0, termUpTo));\n        } else {\n          return null; // no terms at all, we won't use similarity\n        }\n      }\n\n      @Override\n      protected PhraseMatcher getPhraseMatcher(LeafReaderContext context, boolean exposeOffsets) throws IOException {\n        assert terms.length > 0;\n        final LeafReader reader = context.reader();\n        PostingsAndFreq[] postingsFreqs = new PostingsAndFreq[terms.length];\n\n        final Terms fieldTerms = reader.terms(field);\n        if (fieldTerms == null) {\n          return null;\n        }\n\n        if (fieldTerms.hasPositions() == false) {\n          throw new IllegalStateException(\"field \\\"\" + field + \"\\\" was indexed without position data; cannot run PhraseQuery (phrase=\" + getQuery() + \")\");\n        }\n\n        // Reuse single TermsEnum below:\n        final TermsEnum te = fieldTerms.iterator();\n        float totalMatchCost = 0;\n\n        for (int i = 0; i < terms.length; i++) {\n          final Term t = terms[i];\n          final TermState state = states[i].get(context);\n          if (state == null) { /* term doesnt exist in this segment */\n            assert termNotInReader(reader, t): \"no termstate found but term exists in reader\";\n            return null;\n          }\n          te.seekExact(t.bytes(), state);\n          PostingsEnum postingsEnum = te.postings(null, exposeOffsets ? PostingsEnum.OFFSETS : PostingsEnum.POSITIONS);\n          postingsFreqs[i] = new PostingsAndFreq(postingsEnum, positions[i], t);\n          totalMatchCost += termPositionsCost(te);\n        }\n\n        // sort by increasing docFreq order\n        if (slop == 0) {\n          ArrayUtil.timSort(postingsFreqs);\n          return new ExactPhraseMatcher(postingsFreqs, totalMatchCost);\n        }\n        else {\n          return new SloppyPhraseMatcher(postingsFreqs, slop, totalMatchCost);\n        }\n      }\n\n      @Override\n      public void extractTerms(Set<Term> queryTerms) {\n        Collections.addAll(queryTerms, terms);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"62ba8124694976baa3b03705351de238ec5d4352","date":1532295406,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/PhraseQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/PhraseQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    return new PhraseWeight(this, field, searcher, scoreMode) {\n\n      private transient TermStates states[];\n\n      @Override\n      protected Similarity.SimScorer getStats(IndexSearcher searcher) throws IOException {\n        final int[] positions = PhraseQuery.this.getPositions();\n        if (positions.length < 2) {\n          throw new IllegalStateException(\"PhraseWeight does not support less than 2 terms, call rewrite first\");\n        } else if (positions[0] != 0) {\n          throw new IllegalStateException(\"PhraseWeight requires that the first position is 0, call rewrite first\");\n        }\n        final IndexReaderContext context = searcher.getTopReaderContext();\n        states = new TermStates[terms.length];\n        TermStatistics termStats[] = new TermStatistics[terms.length];\n        int termUpTo = 0;\n        for (int i = 0; i < terms.length; i++) {\n          final Term term = terms[i];\n          states[i] = TermStates.build(context, term, scoreMode.needsScores());\n          if (scoreMode.needsScores()) {\n            TermStatistics termStatistics = searcher.termStatistics(term, states[i]);\n            if (termStatistics != null) {\n              termStats[termUpTo++] = termStatistics;\n            }\n          }\n        }\n        if (termUpTo > 0) {\n          return similarity.scorer(boost, searcher.collectionStatistics(field), ArrayUtil.copyOfSubArray(termStats, 0, termUpTo));\n        } else {\n          return null; // no terms at all, we won't use similarity\n        }\n      }\n\n      @Override\n      protected PhraseMatcher getPhraseMatcher(LeafReaderContext context, boolean exposeOffsets) throws IOException {\n        assert terms.length > 0;\n        final LeafReader reader = context.reader();\n        PostingsAndFreq[] postingsFreqs = new PostingsAndFreq[terms.length];\n\n        final Terms fieldTerms = reader.terms(field);\n        if (fieldTerms == null) {\n          return null;\n        }\n\n        if (fieldTerms.hasPositions() == false) {\n          throw new IllegalStateException(\"field \\\"\" + field + \"\\\" was indexed without position data; cannot run PhraseQuery (phrase=\" + getQuery() + \")\");\n        }\n\n        // Reuse single TermsEnum below:\n        final TermsEnum te = fieldTerms.iterator();\n        float totalMatchCost = 0;\n\n        for (int i = 0; i < terms.length; i++) {\n          final Term t = terms[i];\n          final TermState state = states[i].get(context);\n          if (state == null) { /* term doesnt exist in this segment */\n            assert termNotInReader(reader, t): \"no termstate found but term exists in reader\";\n            return null;\n          }\n          te.seekExact(t.bytes(), state);\n          PostingsEnum postingsEnum = te.postings(null, exposeOffsets ? PostingsEnum.OFFSETS : PostingsEnum.POSITIONS);\n          postingsFreqs[i] = new PostingsAndFreq(postingsEnum, positions[i], t);\n          totalMatchCost += termPositionsCost(te);\n        }\n\n        // sort by increasing docFreq order\n        if (slop == 0) {\n          ArrayUtil.timSort(postingsFreqs);\n          return new ExactPhraseMatcher(postingsFreqs, totalMatchCost);\n        }\n        else {\n          return new SloppyPhraseMatcher(postingsFreqs, slop, totalMatchCost);\n        }\n      }\n\n      @Override\n      public void extractTerms(Set<Term> queryTerms) {\n        Collections.addAll(queryTerms, terms);\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    return new PhraseWeight(this, field, searcher, scoreMode) {\n\n      private transient TermStates states[];\n\n      @Override\n      protected Similarity.SimScorer getStats(IndexSearcher searcher) throws IOException {\n        final int[] positions = PhraseQuery.this.getPositions();\n        if (positions.length < 2) {\n          throw new IllegalStateException(\"PhraseWeight does not support less than 2 terms, call rewrite first\");\n        } else if (positions[0] != 0) {\n          throw new IllegalStateException(\"PhraseWeight requires that the first position is 0, call rewrite first\");\n        }\n        final IndexReaderContext context = searcher.getTopReaderContext();\n        states = new TermStates[terms.length];\n        TermStatistics termStats[] = new TermStatistics[terms.length];\n        int termUpTo = 0;\n        for (int i = 0; i < terms.length; i++) {\n          final Term term = terms[i];\n          states[i] = TermStates.build(context, term, scoreMode.needsScores());\n          if (scoreMode.needsScores()) {\n            TermStatistics termStatistics = searcher.termStatistics(term, states[i]);\n            if (termStatistics != null) {\n              termStats[termUpTo++] = termStatistics;\n            }\n          }\n        }\n        if (termUpTo > 0) {\n          return similarity.scorer(boost, searcher.collectionStatistics(field), ArrayUtil.copyOfSubArray(termStats, 0, termUpTo));\n        } else {\n          return null; // no terms at all, we won't use similarity\n        }\n      }\n\n      @Override\n      protected PhraseMatcher getPhraseMatcher(LeafReaderContext context, boolean exposeOffsets) throws IOException {\n        assert terms.length > 0;\n        final LeafReader reader = context.reader();\n        PostingsAndFreq[] postingsFreqs = new PostingsAndFreq[terms.length];\n\n        final Terms fieldTerms = reader.terms(field);\n        if (fieldTerms == null) {\n          return null;\n        }\n\n        if (fieldTerms.hasPositions() == false) {\n          throw new IllegalStateException(\"field \\\"\" + field + \"\\\" was indexed without position data; cannot run PhraseQuery (phrase=\" + getQuery() + \")\");\n        }\n\n        // Reuse single TermsEnum below:\n        final TermsEnum te = fieldTerms.iterator();\n        float totalMatchCost = 0;\n\n        for (int i = 0; i < terms.length; i++) {\n          final Term t = terms[i];\n          final TermState state = states[i].get(context);\n          if (state == null) { /* term doesnt exist in this segment */\n            assert termNotInReader(reader, t): \"no termstate found but term exists in reader\";\n            return null;\n          }\n          te.seekExact(t.bytes(), state);\n          PostingsEnum postingsEnum = te.postings(null, exposeOffsets ? PostingsEnum.ALL : PostingsEnum.POSITIONS);\n          postingsFreqs[i] = new PostingsAndFreq(postingsEnum, positions[i], t);\n          totalMatchCost += termPositionsCost(te);\n        }\n\n        // sort by increasing docFreq order\n        if (slop == 0) {\n          ArrayUtil.timSort(postingsFreqs);\n          return new ExactPhraseMatcher(postingsFreqs, totalMatchCost);\n        }\n        else {\n          return new SloppyPhraseMatcher(postingsFreqs, slop, totalMatchCost, exposeOffsets);\n        }\n      }\n\n      @Override\n      public void extractTerms(Set<Term> queryTerms) {\n        Collections.addAll(queryTerms, terms);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"41ebc07bccf12a902ca6a0077910d18ee38b695f","date":1532336521,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/PhraseQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/PhraseQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    return new PhraseWeight(this, field, searcher, scoreMode) {\n\n      private transient TermStates states[];\n\n      @Override\n      protected Similarity.SimScorer getStats(IndexSearcher searcher) throws IOException {\n        final int[] positions = PhraseQuery.this.getPositions();\n        if (positions.length < 2) {\n          throw new IllegalStateException(\"PhraseWeight does not support less than 2 terms, call rewrite first\");\n        } else if (positions[0] != 0) {\n          throw new IllegalStateException(\"PhraseWeight requires that the first position is 0, call rewrite first\");\n        }\n        final IndexReaderContext context = searcher.getTopReaderContext();\n        states = new TermStates[terms.length];\n        TermStatistics termStats[] = new TermStatistics[terms.length];\n        int termUpTo = 0;\n        for (int i = 0; i < terms.length; i++) {\n          final Term term = terms[i];\n          states[i] = TermStates.build(context, term, scoreMode.needsScores());\n          if (scoreMode.needsScores()) {\n            TermStatistics termStatistics = searcher.termStatistics(term, states[i]);\n            if (termStatistics != null) {\n              termStats[termUpTo++] = termStatistics;\n            }\n          }\n        }\n        if (termUpTo > 0) {\n          return similarity.scorer(boost, searcher.collectionStatistics(field), ArrayUtil.copyOfSubArray(termStats, 0, termUpTo));\n        } else {\n          return null; // no terms at all, we won't use similarity\n        }\n      }\n\n      @Override\n      protected PhraseMatcher getPhraseMatcher(LeafReaderContext context, boolean exposeOffsets) throws IOException {\n        assert terms.length > 0;\n        final LeafReader reader = context.reader();\n        PostingsAndFreq[] postingsFreqs = new PostingsAndFreq[terms.length];\n\n        final Terms fieldTerms = reader.terms(field);\n        if (fieldTerms == null) {\n          return null;\n        }\n\n        if (fieldTerms.hasPositions() == false) {\n          throw new IllegalStateException(\"field \\\"\" + field + \"\\\" was indexed without position data; cannot run PhraseQuery (phrase=\" + getQuery() + \")\");\n        }\n\n        // Reuse single TermsEnum below:\n        final TermsEnum te = fieldTerms.iterator();\n        float totalMatchCost = 0;\n\n        for (int i = 0; i < terms.length; i++) {\n          final Term t = terms[i];\n          final TermState state = states[i].get(context);\n          if (state == null) { /* term doesnt exist in this segment */\n            assert termNotInReader(reader, t): \"no termstate found but term exists in reader\";\n            return null;\n          }\n          te.seekExact(t.bytes(), state);\n          PostingsEnum postingsEnum = te.postings(null, exposeOffsets ? PostingsEnum.ALL : PostingsEnum.POSITIONS);\n          postingsFreqs[i] = new PostingsAndFreq(postingsEnum, positions[i], t);\n          totalMatchCost += termPositionsCost(te);\n        }\n\n        // sort by increasing docFreq order\n        if (slop == 0) {\n          ArrayUtil.timSort(postingsFreqs);\n          return new ExactPhraseMatcher(postingsFreqs, totalMatchCost);\n        }\n        else {\n          return new SloppyPhraseMatcher(postingsFreqs, slop, totalMatchCost, exposeOffsets);\n        }\n      }\n\n      @Override\n      public void extractTerms(Set<Term> queryTerms) {\n        Collections.addAll(queryTerms, terms);\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    return new PhraseWeight(this, field, searcher, scoreMode) {\n\n      private transient TermStates states[];\n\n      @Override\n      protected Similarity.SimScorer getStats(IndexSearcher searcher) throws IOException {\n        final int[] positions = PhraseQuery.this.getPositions();\n        if (positions.length < 2) {\n          throw new IllegalStateException(\"PhraseWeight does not support less than 2 terms, call rewrite first\");\n        } else if (positions[0] != 0) {\n          throw new IllegalStateException(\"PhraseWeight requires that the first position is 0, call rewrite first\");\n        }\n        final IndexReaderContext context = searcher.getTopReaderContext();\n        states = new TermStates[terms.length];\n        TermStatistics termStats[] = new TermStatistics[terms.length];\n        int termUpTo = 0;\n        for (int i = 0; i < terms.length; i++) {\n          final Term term = terms[i];\n          states[i] = TermStates.build(context, term, scoreMode.needsScores());\n          if (scoreMode.needsScores()) {\n            TermStatistics termStatistics = searcher.termStatistics(term, states[i]);\n            if (termStatistics != null) {\n              termStats[termUpTo++] = termStatistics;\n            }\n          }\n        }\n        if (termUpTo > 0) {\n          return similarity.scorer(boost, searcher.collectionStatistics(field), ArrayUtil.copyOfSubArray(termStats, 0, termUpTo));\n        } else {\n          return null; // no terms at all, we won't use similarity\n        }\n      }\n\n      @Override\n      protected PhraseMatcher getPhraseMatcher(LeafReaderContext context, boolean exposeOffsets) throws IOException {\n        assert terms.length > 0;\n        final LeafReader reader = context.reader();\n        PostingsAndFreq[] postingsFreqs = new PostingsAndFreq[terms.length];\n\n        final Terms fieldTerms = reader.terms(field);\n        if (fieldTerms == null) {\n          return null;\n        }\n\n        if (fieldTerms.hasPositions() == false) {\n          throw new IllegalStateException(\"field \\\"\" + field + \"\\\" was indexed without position data; cannot run PhraseQuery (phrase=\" + getQuery() + \")\");\n        }\n\n        // Reuse single TermsEnum below:\n        final TermsEnum te = fieldTerms.iterator();\n        float totalMatchCost = 0;\n\n        for (int i = 0; i < terms.length; i++) {\n          final Term t = terms[i];\n          final TermState state = states[i].get(context);\n          if (state == null) { /* term doesnt exist in this segment */\n            assert termNotInReader(reader, t): \"no termstate found but term exists in reader\";\n            return null;\n          }\n          te.seekExact(t.bytes(), state);\n          PostingsEnum postingsEnum = te.postings(null, exposeOffsets ? PostingsEnum.OFFSETS : PostingsEnum.POSITIONS);\n          postingsFreqs[i] = new PostingsAndFreq(postingsEnum, positions[i], t);\n          totalMatchCost += termPositionsCost(te);\n        }\n\n        // sort by increasing docFreq order\n        if (slop == 0) {\n          ArrayUtil.timSort(postingsFreqs);\n          return new ExactPhraseMatcher(postingsFreqs, totalMatchCost);\n        }\n        else {\n          return new SloppyPhraseMatcher(postingsFreqs, slop, totalMatchCost);\n        }\n      }\n\n      @Override\n      public void extractTerms(Set<Term> queryTerms) {\n        Collections.addAll(queryTerms, terms);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5b9ffb60dc4bdc972b1403ad2ab2f5b4d9ce4cf7","date":1552575873,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/PhraseQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/PhraseQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    return new PhraseWeight(this, field, searcher, scoreMode) {\n\n      private transient TermStates states[];\n\n      @Override\n      protected Similarity.SimScorer getStats(IndexSearcher searcher) throws IOException {\n        final int[] positions = PhraseQuery.this.getPositions();\n        if (positions.length < 2) {\n          throw new IllegalStateException(\"PhraseWeight does not support less than 2 terms, call rewrite first\");\n        } else if (positions[0] != 0) {\n          throw new IllegalStateException(\"PhraseWeight requires that the first position is 0, call rewrite first\");\n        }\n        final IndexReaderContext context = searcher.getTopReaderContext();\n        states = new TermStates[terms.length];\n        TermStatistics termStats[] = new TermStatistics[terms.length];\n        int termUpTo = 0;\n        for (int i = 0; i < terms.length; i++) {\n          final Term term = terms[i];\n          states[i] = TermStates.build(context, term, scoreMode.needsScores());\n          if (scoreMode.needsScores()) {\n            TermStatistics termStatistics = searcher.termStatistics(term, states[i]);\n            if (termStatistics != null) {\n              termStats[termUpTo++] = termStatistics;\n            }\n          }\n        }\n        if (termUpTo > 0) {\n          return similarity.scorer(boost, searcher.collectionStatistics(field), ArrayUtil.copyOfSubArray(termStats, 0, termUpTo));\n        } else {\n          return null; // no terms at all, we won't use similarity\n        }\n      }\n\n      @Override\n      protected PhraseMatcher getPhraseMatcher(LeafReaderContext context, boolean exposeOffsets) throws IOException {\n        assert terms.length > 0;\n        final LeafReader reader = context.reader();\n        PostingsAndFreq[] postingsFreqs = new PostingsAndFreq[terms.length];\n\n        final Terms fieldTerms = reader.terms(field);\n        if (fieldTerms == null) {\n          return null;\n        }\n\n        if (fieldTerms.hasPositions() == false) {\n          throw new IllegalStateException(\"field \\\"\" + field + \"\\\" was indexed without position data; cannot run PhraseQuery (phrase=\" + getQuery() + \")\");\n        }\n\n        // Reuse single TermsEnum below:\n        final TermsEnum te = fieldTerms.iterator();\n        float totalMatchCost = 0;\n\n        for (int i = 0; i < terms.length; i++) {\n          final Term t = terms[i];\n          final TermState state = states[i].get(context);\n          if (state == null) { /* term doesnt exist in this segment */\n            assert termNotInReader(reader, t): \"no termstate found but term exists in reader\";\n            return null;\n          }\n          te.seekExact(t.bytes(), state);\n          PostingsEnum postingsEnum = te.postings(null, exposeOffsets ? PostingsEnum.ALL : PostingsEnum.POSITIONS);\n          postingsFreqs[i] = new PostingsAndFreq(postingsEnum, positions[i], t);\n          totalMatchCost += termPositionsCost(te);\n        }\n\n        // sort by increasing docFreq order\n        if (slop == 0) {\n          ArrayUtil.timSort(postingsFreqs);\n          return new ExactPhraseMatcher(postingsFreqs, totalMatchCost);\n        }\n        else {\n          return new SloppyPhraseMatcher(postingsFreqs, slop, totalMatchCost, exposeOffsets);\n        }\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    return new PhraseWeight(this, field, searcher, scoreMode) {\n\n      private transient TermStates states[];\n\n      @Override\n      protected Similarity.SimScorer getStats(IndexSearcher searcher) throws IOException {\n        final int[] positions = PhraseQuery.this.getPositions();\n        if (positions.length < 2) {\n          throw new IllegalStateException(\"PhraseWeight does not support less than 2 terms, call rewrite first\");\n        } else if (positions[0] != 0) {\n          throw new IllegalStateException(\"PhraseWeight requires that the first position is 0, call rewrite first\");\n        }\n        final IndexReaderContext context = searcher.getTopReaderContext();\n        states = new TermStates[terms.length];\n        TermStatistics termStats[] = new TermStatistics[terms.length];\n        int termUpTo = 0;\n        for (int i = 0; i < terms.length; i++) {\n          final Term term = terms[i];\n          states[i] = TermStates.build(context, term, scoreMode.needsScores());\n          if (scoreMode.needsScores()) {\n            TermStatistics termStatistics = searcher.termStatistics(term, states[i]);\n            if (termStatistics != null) {\n              termStats[termUpTo++] = termStatistics;\n            }\n          }\n        }\n        if (termUpTo > 0) {\n          return similarity.scorer(boost, searcher.collectionStatistics(field), ArrayUtil.copyOfSubArray(termStats, 0, termUpTo));\n        } else {\n          return null; // no terms at all, we won't use similarity\n        }\n      }\n\n      @Override\n      protected PhraseMatcher getPhraseMatcher(LeafReaderContext context, boolean exposeOffsets) throws IOException {\n        assert terms.length > 0;\n        final LeafReader reader = context.reader();\n        PostingsAndFreq[] postingsFreqs = new PostingsAndFreq[terms.length];\n\n        final Terms fieldTerms = reader.terms(field);\n        if (fieldTerms == null) {\n          return null;\n        }\n\n        if (fieldTerms.hasPositions() == false) {\n          throw new IllegalStateException(\"field \\\"\" + field + \"\\\" was indexed without position data; cannot run PhraseQuery (phrase=\" + getQuery() + \")\");\n        }\n\n        // Reuse single TermsEnum below:\n        final TermsEnum te = fieldTerms.iterator();\n        float totalMatchCost = 0;\n\n        for (int i = 0; i < terms.length; i++) {\n          final Term t = terms[i];\n          final TermState state = states[i].get(context);\n          if (state == null) { /* term doesnt exist in this segment */\n            assert termNotInReader(reader, t): \"no termstate found but term exists in reader\";\n            return null;\n          }\n          te.seekExact(t.bytes(), state);\n          PostingsEnum postingsEnum = te.postings(null, exposeOffsets ? PostingsEnum.ALL : PostingsEnum.POSITIONS);\n          postingsFreqs[i] = new PostingsAndFreq(postingsEnum, positions[i], t);\n          totalMatchCost += termPositionsCost(te);\n        }\n\n        // sort by increasing docFreq order\n        if (slop == 0) {\n          ArrayUtil.timSort(postingsFreqs);\n          return new ExactPhraseMatcher(postingsFreqs, totalMatchCost);\n        }\n        else {\n          return new SloppyPhraseMatcher(postingsFreqs, slop, totalMatchCost, exposeOffsets);\n        }\n      }\n\n      @Override\n      public void extractTerms(Set<Term> queryTerms) {\n        Collections.addAll(queryTerms, terms);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f8dd25829321d66cd54ea7d40a4130e0d2a29bec","date":1562680889,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/PhraseQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/PhraseQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    return new PhraseWeight(this, field, searcher, scoreMode) {\n\n      private transient TermStates states[];\n\n      @Override\n      protected Similarity.SimScorer getStats(IndexSearcher searcher) throws IOException {\n        final int[] positions = PhraseQuery.this.getPositions();\n        if (positions.length < 2) {\n          throw new IllegalStateException(\"PhraseWeight does not support less than 2 terms, call rewrite first\");\n        } else if (positions[0] != 0) {\n          throw new IllegalStateException(\"PhraseWeight requires that the first position is 0, call rewrite first\");\n        }\n        final IndexReaderContext context = searcher.getTopReaderContext();\n        states = new TermStates[terms.length];\n        TermStatistics termStats[] = new TermStatistics[terms.length];\n        int termUpTo = 0;\n        for (int i = 0; i < terms.length; i++) {\n          final Term term = terms[i];\n          states[i] = TermStates.build(context, term, scoreMode.needsScores());\n          if (scoreMode.needsScores()) {\n            TermStatistics termStatistics = searcher.termStatistics(term, states[i]);\n            if (termStatistics != null) {\n              termStats[termUpTo++] = termStatistics;\n            }\n          }\n        }\n        if (termUpTo > 0) {\n          return similarity.scorer(boost, searcher.collectionStatistics(field), ArrayUtil.copyOfSubArray(termStats, 0, termUpTo));\n        } else {\n          return null; // no terms at all, we won't use similarity\n        }\n      }\n\n      @Override\n      protected PhraseMatcher getPhraseMatcher(LeafReaderContext context, SimScorer scorer, boolean exposeOffsets) throws IOException {\n        assert terms.length > 0;\n        final LeafReader reader = context.reader();\n        PostingsAndFreq[] postingsFreqs = new PostingsAndFreq[terms.length];\n\n        final Terms fieldTerms = reader.terms(field);\n        if (fieldTerms == null) {\n          return null;\n        }\n\n        if (fieldTerms.hasPositions() == false) {\n          throw new IllegalStateException(\"field \\\"\" + field + \"\\\" was indexed without position data; cannot run PhraseQuery (phrase=\" + getQuery() + \")\");\n        }\n\n        // Reuse single TermsEnum below:\n        final TermsEnum te = fieldTerms.iterator();\n        float totalMatchCost = 0;\n\n        for (int i = 0; i < terms.length; i++) {\n          final Term t = terms[i];\n          final TermState state = states[i].get(context);\n          if (state == null) { /* term doesnt exist in this segment */\n            assert termNotInReader(reader, t): \"no termstate found but term exists in reader\";\n            return null;\n          }\n          te.seekExact(t.bytes(), state);\n          PostingsEnum postingsEnum;\n          ImpactsEnum impactsEnum;\n          if (scoreMode == ScoreMode.TOP_SCORES) {\n            postingsEnum = impactsEnum = te.impacts(exposeOffsets ? PostingsEnum.OFFSETS : PostingsEnum.POSITIONS);\n          } else {\n            postingsEnum = te.postings(null, exposeOffsets ? PostingsEnum.OFFSETS : PostingsEnum.POSITIONS);\n            impactsEnum = new SlowImpactsEnum(postingsEnum);\n          }\n          postingsFreqs[i] = new PostingsAndFreq(postingsEnum, impactsEnum, positions[i], t);\n          totalMatchCost += termPositionsCost(te);\n        }\n\n        // sort by increasing docFreq order\n        if (slop == 0) {\n          ArrayUtil.timSort(postingsFreqs);\n          return new ExactPhraseMatcher(postingsFreqs, scoreMode, scorer, totalMatchCost);\n        }\n        else {\n          return new SloppyPhraseMatcher(postingsFreqs, slop, scoreMode, scorer, totalMatchCost, exposeOffsets);\n        }\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    return new PhraseWeight(this, field, searcher, scoreMode) {\n\n      private transient TermStates states[];\n\n      @Override\n      protected Similarity.SimScorer getStats(IndexSearcher searcher) throws IOException {\n        final int[] positions = PhraseQuery.this.getPositions();\n        if (positions.length < 2) {\n          throw new IllegalStateException(\"PhraseWeight does not support less than 2 terms, call rewrite first\");\n        } else if (positions[0] != 0) {\n          throw new IllegalStateException(\"PhraseWeight requires that the first position is 0, call rewrite first\");\n        }\n        final IndexReaderContext context = searcher.getTopReaderContext();\n        states = new TermStates[terms.length];\n        TermStatistics termStats[] = new TermStatistics[terms.length];\n        int termUpTo = 0;\n        for (int i = 0; i < terms.length; i++) {\n          final Term term = terms[i];\n          states[i] = TermStates.build(context, term, scoreMode.needsScores());\n          if (scoreMode.needsScores()) {\n            TermStatistics termStatistics = searcher.termStatistics(term, states[i]);\n            if (termStatistics != null) {\n              termStats[termUpTo++] = termStatistics;\n            }\n          }\n        }\n        if (termUpTo > 0) {\n          return similarity.scorer(boost, searcher.collectionStatistics(field), ArrayUtil.copyOfSubArray(termStats, 0, termUpTo));\n        } else {\n          return null; // no terms at all, we won't use similarity\n        }\n      }\n\n      @Override\n      protected PhraseMatcher getPhraseMatcher(LeafReaderContext context, boolean exposeOffsets) throws IOException {\n        assert terms.length > 0;\n        final LeafReader reader = context.reader();\n        PostingsAndFreq[] postingsFreqs = new PostingsAndFreq[terms.length];\n\n        final Terms fieldTerms = reader.terms(field);\n        if (fieldTerms == null) {\n          return null;\n        }\n\n        if (fieldTerms.hasPositions() == false) {\n          throw new IllegalStateException(\"field \\\"\" + field + \"\\\" was indexed without position data; cannot run PhraseQuery (phrase=\" + getQuery() + \")\");\n        }\n\n        // Reuse single TermsEnum below:\n        final TermsEnum te = fieldTerms.iterator();\n        float totalMatchCost = 0;\n\n        for (int i = 0; i < terms.length; i++) {\n          final Term t = terms[i];\n          final TermState state = states[i].get(context);\n          if (state == null) { /* term doesnt exist in this segment */\n            assert termNotInReader(reader, t): \"no termstate found but term exists in reader\";\n            return null;\n          }\n          te.seekExact(t.bytes(), state);\n          PostingsEnum postingsEnum = te.postings(null, exposeOffsets ? PostingsEnum.ALL : PostingsEnum.POSITIONS);\n          postingsFreqs[i] = new PostingsAndFreq(postingsEnum, positions[i], t);\n          totalMatchCost += termPositionsCost(te);\n        }\n\n        // sort by increasing docFreq order\n        if (slop == 0) {\n          ArrayUtil.timSort(postingsFreqs);\n          return new ExactPhraseMatcher(postingsFreqs, totalMatchCost);\n        }\n        else {\n          return new SloppyPhraseMatcher(postingsFreqs, slop, totalMatchCost, exposeOffsets);\n        }\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"19238c4860c45945f1b1e39032e056ce9e266152","date":1568753304,"type":3,"author":"Bruno Roustant","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/PhraseQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/PhraseQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    return new PhraseWeight(this, field, searcher, scoreMode) {\n\n      private transient TermStates states[];\n\n      @Override\n      protected Similarity.SimScorer getStats(IndexSearcher searcher) throws IOException {\n        final int[] positions = PhraseQuery.this.getPositions();\n        if (positions.length < 2) {\n          throw new IllegalStateException(\"PhraseWeight does not support less than 2 terms, call rewrite first\");\n        } else if (positions[0] != 0) {\n          throw new IllegalStateException(\"PhraseWeight requires that the first position is 0, call rewrite first\");\n        }\n        final IndexReaderContext context = searcher.getTopReaderContext();\n        states = new TermStates[terms.length];\n        TermStatistics termStats[] = new TermStatistics[terms.length];\n        int termUpTo = 0;\n        for (int i = 0; i < terms.length; i++) {\n          final Term term = terms[i];\n          states[i] = TermStates.build(context, term, scoreMode.needsScores());\n          if (scoreMode.needsScores()) {\n            TermStates ts = states[i];\n            if (ts.docFreq() > 0) {\n              termStats[termUpTo++] = searcher.termStatistics(term, ts.docFreq(), ts.totalTermFreq());\n            }\n          }\n        }\n        if (termUpTo > 0) {\n          return similarity.scorer(boost, searcher.collectionStatistics(field), ArrayUtil.copyOfSubArray(termStats, 0, termUpTo));\n        } else {\n          return null; // no terms at all, we won't use similarity\n        }\n      }\n\n      @Override\n      protected PhraseMatcher getPhraseMatcher(LeafReaderContext context, SimScorer scorer, boolean exposeOffsets) throws IOException {\n        assert terms.length > 0;\n        final LeafReader reader = context.reader();\n        PostingsAndFreq[] postingsFreqs = new PostingsAndFreq[terms.length];\n\n        final Terms fieldTerms = reader.terms(field);\n        if (fieldTerms == null) {\n          return null;\n        }\n\n        if (fieldTerms.hasPositions() == false) {\n          throw new IllegalStateException(\"field \\\"\" + field + \"\\\" was indexed without position data; cannot run PhraseQuery (phrase=\" + getQuery() + \")\");\n        }\n\n        // Reuse single TermsEnum below:\n        final TermsEnum te = fieldTerms.iterator();\n        float totalMatchCost = 0;\n\n        for (int i = 0; i < terms.length; i++) {\n          final Term t = terms[i];\n          final TermState state = states[i].get(context);\n          if (state == null) { /* term doesnt exist in this segment */\n            assert termNotInReader(reader, t): \"no termstate found but term exists in reader\";\n            return null;\n          }\n          te.seekExact(t.bytes(), state);\n          PostingsEnum postingsEnum;\n          ImpactsEnum impactsEnum;\n          if (scoreMode == ScoreMode.TOP_SCORES) {\n            postingsEnum = impactsEnum = te.impacts(exposeOffsets ? PostingsEnum.OFFSETS : PostingsEnum.POSITIONS);\n          } else {\n            postingsEnum = te.postings(null, exposeOffsets ? PostingsEnum.OFFSETS : PostingsEnum.POSITIONS);\n            impactsEnum = new SlowImpactsEnum(postingsEnum);\n          }\n          postingsFreqs[i] = new PostingsAndFreq(postingsEnum, impactsEnum, positions[i], t);\n          totalMatchCost += termPositionsCost(te);\n        }\n\n        // sort by increasing docFreq order\n        if (slop == 0) {\n          ArrayUtil.timSort(postingsFreqs);\n          return new ExactPhraseMatcher(postingsFreqs, scoreMode, scorer, totalMatchCost);\n        }\n        else {\n          return new SloppyPhraseMatcher(postingsFreqs, slop, scoreMode, scorer, totalMatchCost, exposeOffsets);\n        }\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    return new PhraseWeight(this, field, searcher, scoreMode) {\n\n      private transient TermStates states[];\n\n      @Override\n      protected Similarity.SimScorer getStats(IndexSearcher searcher) throws IOException {\n        final int[] positions = PhraseQuery.this.getPositions();\n        if (positions.length < 2) {\n          throw new IllegalStateException(\"PhraseWeight does not support less than 2 terms, call rewrite first\");\n        } else if (positions[0] != 0) {\n          throw new IllegalStateException(\"PhraseWeight requires that the first position is 0, call rewrite first\");\n        }\n        final IndexReaderContext context = searcher.getTopReaderContext();\n        states = new TermStates[terms.length];\n        TermStatistics termStats[] = new TermStatistics[terms.length];\n        int termUpTo = 0;\n        for (int i = 0; i < terms.length; i++) {\n          final Term term = terms[i];\n          states[i] = TermStates.build(context, term, scoreMode.needsScores());\n          if (scoreMode.needsScores()) {\n            TermStatistics termStatistics = searcher.termStatistics(term, states[i]);\n            if (termStatistics != null) {\n              termStats[termUpTo++] = termStatistics;\n            }\n          }\n        }\n        if (termUpTo > 0) {\n          return similarity.scorer(boost, searcher.collectionStatistics(field), ArrayUtil.copyOfSubArray(termStats, 0, termUpTo));\n        } else {\n          return null; // no terms at all, we won't use similarity\n        }\n      }\n\n      @Override\n      protected PhraseMatcher getPhraseMatcher(LeafReaderContext context, SimScorer scorer, boolean exposeOffsets) throws IOException {\n        assert terms.length > 0;\n        final LeafReader reader = context.reader();\n        PostingsAndFreq[] postingsFreqs = new PostingsAndFreq[terms.length];\n\n        final Terms fieldTerms = reader.terms(field);\n        if (fieldTerms == null) {\n          return null;\n        }\n\n        if (fieldTerms.hasPositions() == false) {\n          throw new IllegalStateException(\"field \\\"\" + field + \"\\\" was indexed without position data; cannot run PhraseQuery (phrase=\" + getQuery() + \")\");\n        }\n\n        // Reuse single TermsEnum below:\n        final TermsEnum te = fieldTerms.iterator();\n        float totalMatchCost = 0;\n\n        for (int i = 0; i < terms.length; i++) {\n          final Term t = terms[i];\n          final TermState state = states[i].get(context);\n          if (state == null) { /* term doesnt exist in this segment */\n            assert termNotInReader(reader, t): \"no termstate found but term exists in reader\";\n            return null;\n          }\n          te.seekExact(t.bytes(), state);\n          PostingsEnum postingsEnum;\n          ImpactsEnum impactsEnum;\n          if (scoreMode == ScoreMode.TOP_SCORES) {\n            postingsEnum = impactsEnum = te.impacts(exposeOffsets ? PostingsEnum.OFFSETS : PostingsEnum.POSITIONS);\n          } else {\n            postingsEnum = te.postings(null, exposeOffsets ? PostingsEnum.OFFSETS : PostingsEnum.POSITIONS);\n            impactsEnum = new SlowImpactsEnum(postingsEnum);\n          }\n          postingsFreqs[i] = new PostingsAndFreq(postingsEnum, impactsEnum, positions[i], t);\n          totalMatchCost += termPositionsCost(te);\n        }\n\n        // sort by increasing docFreq order\n        if (slop == 0) {\n          ArrayUtil.timSort(postingsFreqs);\n          return new ExactPhraseMatcher(postingsFreqs, scoreMode, scorer, totalMatchCost);\n        }\n        else {\n          return new SloppyPhraseMatcher(postingsFreqs, slop, scoreMode, scorer, totalMatchCost, exposeOffsets);\n        }\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"3b11b9d5eaf9707760ca5151530830a825197023":["33eef98c565ee21b199f04b92acd6e00b842bd1e"],"165c3432cb3c4fcfc8e859af24323bbbd12084af":["9798d0818e7a880546802b509792d3f3d57babd2"],"19238c4860c45945f1b1e39032e056ce9e266152":["f8dd25829321d66cd54ea7d40a4130e0d2a29bec"],"5b9ffb60dc4bdc972b1403ad2ab2f5b4d9ce4cf7":["41ebc07bccf12a902ca6a0077910d18ee38b695f"],"417142ff08fda9cf0b72d5133e63097a166c6458":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","9fc47cb7b4346802411bb432f501ed0673d7119e"],"33eef98c565ee21b199f04b92acd6e00b842bd1e":["417142ff08fda9cf0b72d5133e63097a166c6458"],"f8dd25829321d66cd54ea7d40a4130e0d2a29bec":["5b9ffb60dc4bdc972b1403ad2ab2f5b4d9ce4cf7"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b70042a8a492f7054d480ccdd2be9796510d4327":["3b11b9d5eaf9707760ca5151530830a825197023","9798d0818e7a880546802b509792d3f3d57babd2"],"9fc47cb7b4346802411bb432f501ed0673d7119e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"62ba8124694976baa3b03705351de238ec5d4352":["165c3432cb3c4fcfc8e859af24323bbbd12084af"],"9798d0818e7a880546802b509792d3f3d57babd2":["3b11b9d5eaf9707760ca5151530830a825197023"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["19238c4860c45945f1b1e39032e056ce9e266152"],"41ebc07bccf12a902ca6a0077910d18ee38b695f":["62ba8124694976baa3b03705351de238ec5d4352"],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":["3b11b9d5eaf9707760ca5151530830a825197023","9798d0818e7a880546802b509792d3f3d57babd2"]},"commit2Childs":{"3b11b9d5eaf9707760ca5151530830a825197023":["b70042a8a492f7054d480ccdd2be9796510d4327","9798d0818e7a880546802b509792d3f3d57babd2","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"165c3432cb3c4fcfc8e859af24323bbbd12084af":["62ba8124694976baa3b03705351de238ec5d4352"],"19238c4860c45945f1b1e39032e056ce9e266152":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"5b9ffb60dc4bdc972b1403ad2ab2f5b4d9ce4cf7":["f8dd25829321d66cd54ea7d40a4130e0d2a29bec"],"417142ff08fda9cf0b72d5133e63097a166c6458":["33eef98c565ee21b199f04b92acd6e00b842bd1e"],"33eef98c565ee21b199f04b92acd6e00b842bd1e":["3b11b9d5eaf9707760ca5151530830a825197023"],"f8dd25829321d66cd54ea7d40a4130e0d2a29bec":["19238c4860c45945f1b1e39032e056ce9e266152"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["417142ff08fda9cf0b72d5133e63097a166c6458","9fc47cb7b4346802411bb432f501ed0673d7119e"],"b70042a8a492f7054d480ccdd2be9796510d4327":[],"9fc47cb7b4346802411bb432f501ed0673d7119e":["417142ff08fda9cf0b72d5133e63097a166c6458"],"9798d0818e7a880546802b509792d3f3d57babd2":["165c3432cb3c4fcfc8e859af24323bbbd12084af","b70042a8a492f7054d480ccdd2be9796510d4327","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"62ba8124694976baa3b03705351de238ec5d4352":["41ebc07bccf12a902ca6a0077910d18ee38b695f"],"41ebc07bccf12a902ca6a0077910d18ee38b695f":["5b9ffb60dc4bdc972b1403ad2ab2f5b4d9ce4cf7"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":[]},"heads":["b70042a8a492f7054d480ccdd2be9796510d4327","cd5edd1f2b162a5cfa08efd17851a07373a96817","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}