{"path":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","commits":[{"id":"d528fd7ae22865015b756e0a03832e2051de2a9c","date":1476721105,"type":1,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n      \n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, cloudDesc.getCollectionName(), shardId);\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n      \n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        Replica replica = zkStateReader.getClusterState().getReplica(desc.getCloudDescriptor().getCollectionName(),\n            coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        joinElection(desc, afterExpiration, joinAtHead);\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      \n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        \n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getSlice(collection, shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, core, cc, afterExpiration);\n        if (!didRecovery) {\n          publish(desc, Replica.State.ACTIVE);\n        }\n        \n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores, boolean afterExpiration) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n      \n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, cloudDesc.getCollectionName(), shardId);\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n      \n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        Replica replica = zkStateReader.getClusterState().getReplica(desc.getCloudDescriptor().getCollectionName(),\n            coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        joinElection(desc, afterExpiration, joinAtHead);\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      \n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        \n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getSlice(collection, shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery = checkRecovery(coreName, desc, recoverReloadedCores, isLeader, cloudDesc, collection,\n            coreZkNodeName, shardId, leaderProps, core, cc, afterExpiration);\n        if (!didRecovery) {\n          publish(desc, Replica.State.ACTIVE);\n        }\n        \n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":0,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n      \n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, cloudDesc.getCollectionName(), shardId);\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n      \n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        Replica replica = zkStateReader.getClusterState().getReplica(desc.getCloudDescriptor().getCollectionName(),\n            coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        joinElection(desc, afterExpiration, joinAtHead);\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      \n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        \n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getSlice(collection, shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, core, cc, afterExpiration);\n        if (!didRecovery) {\n          publish(desc, Replica.State.ACTIVE);\n        }\n        \n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"be320990bdc77e643388fa801e75017f19289c42","date":1489477067,"type":3,"author":"Cao Manh Dat","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n      \n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, cloudDesc.getCollectionName(), shardId);\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        Replica replica = zkStateReader.getClusterState().getReplica(desc.getCloudDescriptor().getCollectionName(),\n            coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        joinElection(desc, afterExpiration, joinAtHead);\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      \n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        boolean onlyLeaderIndexes = zkStateReader.getClusterState().getCollection(collection).getRealtimeReplicas() == 1;\n        boolean isReplicaInOnlyLeaderIndexes = onlyLeaderIndexes && !isLeader;\n        if (isReplicaInOnlyLeaderIndexes) {\n          String commitVersion = ReplicateFromLeader.getCommitVersion(core);\n          if (commitVersion != null) {\n            ulog.copyOverOldUpdates(Long.parseLong(commitVersion));\n          }\n        }\n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null && !isReplicaInOnlyLeaderIndexes) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getSlice(collection, shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, core, cc, afterExpiration);\n        if (!didRecovery) {\n          if (isReplicaInOnlyLeaderIndexes) {\n            startReplicationFromLeader(coreName);\n          }\n          publish(desc, Replica.State.ACTIVE);\n        }\n        \n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n      \n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, cloudDesc.getCollectionName(), shardId);\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n      \n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        Replica replica = zkStateReader.getClusterState().getReplica(desc.getCloudDescriptor().getCollectionName(),\n            coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        joinElection(desc, afterExpiration, joinAtHead);\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      \n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        \n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getSlice(collection, shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, core, cc, afterExpiration);\n        if (!didRecovery) {\n          publish(desc, Replica.State.ACTIVE);\n        }\n        \n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f996f8177b9204bdc92f7164460c6cefad9ac99a","date":1489482690,"type":3,"author":"Cao Manh Dat","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n      \n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, cloudDesc.getCollectionName(), shardId);\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        Replica replica = zkStateReader.getClusterState().getReplica(desc.getCloudDescriptor().getCollectionName(),\n            coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        joinElection(desc, afterExpiration, joinAtHead);\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      \n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        boolean onlyLeaderIndexes = zkStateReader.getClusterState().getCollection(collection).getRealtimeReplicas() == 1;\n        boolean isReplicaInOnlyLeaderIndexes = onlyLeaderIndexes && !isLeader;\n        if (isReplicaInOnlyLeaderIndexes) {\n          String commitVersion = ReplicateFromLeader.getCommitVersion(core);\n          if (commitVersion != null) {\n            ulog.copyOverOldUpdates(Long.parseLong(commitVersion));\n          }\n        }\n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null && !isReplicaInOnlyLeaderIndexes) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getSlice(collection, shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, core, cc, afterExpiration);\n        if (!didRecovery) {\n          if (isReplicaInOnlyLeaderIndexes) {\n            startReplicationFromLeader(coreName);\n          }\n          publish(desc, Replica.State.ACTIVE);\n        }\n        \n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n      \n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, cloudDesc.getCollectionName(), shardId);\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n      \n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        Replica replica = zkStateReader.getClusterState().getReplica(desc.getCloudDescriptor().getCollectionName(),\n            coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        joinElection(desc, afterExpiration, joinAtHead);\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      \n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        \n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getSlice(collection, shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, core, cc, afterExpiration);\n        if (!didRecovery) {\n          publish(desc, Replica.State.ACTIVE);\n        }\n        \n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ab68488225b6a6c357dda72ed11dedca9914a192","date":1490013111,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n      \n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, cloudDesc.getCollectionName(), shardId);\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        Replica replica = zkStateReader.getClusterState().getReplica(desc.getCloudDescriptor().getCollectionName(),\n            coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        joinElection(desc, afterExpiration, joinAtHead);\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      \n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        boolean onlyLeaderIndexes = zkStateReader.getClusterState().getCollection(collection).getRealtimeReplicas() == 1;\n        boolean isReplicaInOnlyLeaderIndexes = onlyLeaderIndexes && !isLeader;\n        if (isReplicaInOnlyLeaderIndexes) {\n          String commitVersion = ReplicateFromLeader.getCommitVersion(core);\n          if (commitVersion != null) {\n            ulog.copyOverOldUpdates(Long.parseLong(commitVersion));\n          }\n        }\n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null && !isReplicaInOnlyLeaderIndexes) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getSlice(collection, shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, core, cc, afterExpiration);\n        if (!didRecovery) {\n          if (isReplicaInOnlyLeaderIndexes) {\n            startReplicationFromLeader(coreName);\n          }\n          publish(desc, Replica.State.ACTIVE);\n        }\n        \n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n      \n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, cloudDesc.getCollectionName(), shardId);\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n      \n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        Replica replica = zkStateReader.getClusterState().getReplica(desc.getCloudDescriptor().getCollectionName(),\n            coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        joinElection(desc, afterExpiration, joinAtHead);\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      \n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        \n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getSlice(collection, shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, core, cc, afterExpiration);\n        if (!didRecovery) {\n          publish(desc, Replica.State.ACTIVE);\n        }\n        \n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"61c45e99cf6676da48f19d7511c73712ad39402b","date":1495508331,"type":3,"author":"Tomas Fernandez Lobbe","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n      \n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, cloudDesc.getCollectionName(), shardId);\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        Replica replica = zkStateReader.getClusterState().getReplica(collection, coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        //TODO WHy would replica be null?\n        if (replica == null || replica.getType() != Type.PULL) {\n          joinElection(desc, afterExpiration, joinAtHead);\n        } else if (replica.getType() == Type.PULL) {\n          if (joinAtHead) {\n            log.warn(\"Replica {} was designated as preferred leader but it's type is {}, It won't join election\", coreZkNodeName, Type.PULL);\n          }\n          log.debug(\"Replica {} skipping election because it's type is {}\", coreZkNodeName, Type.PULL);\n          startReplicationFromLeader(coreName, false);\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      Replica.Type replicaType =  zkStateReader.getClusterState().getCollection(collection).getReplica(coreZkNodeName).getType();\n      assert !(isLeader && replicaType == Type.PULL): \"Pull replica became leader!\";\n      \n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        boolean isTlogReplicaAndNotLeader = replicaType == Replica.Type.TLOG && !isLeader;\n        if (isTlogReplicaAndNotLeader) {\n          String commitVersion = ReplicateFromLeader.getCommitVersion(core);\n          if (commitVersion != null) {\n            ulog.copyOverOldUpdates(Long.parseLong(commitVersion));\n          }\n        }\n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null && !isTlogReplicaAndNotLeader) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getSlice(collection, shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, core, cc, afterExpiration);\n        if (!didRecovery) {\n          if (isTlogReplicaAndNotLeader) {\n            startReplicationFromLeader(coreName, true);\n          }\n          publish(desc, Replica.State.ACTIVE);\n        }\n        \n        \n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n      \n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, cloudDesc.getCollectionName(), shardId);\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        Replica replica = zkStateReader.getClusterState().getReplica(desc.getCloudDescriptor().getCollectionName(),\n            coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        joinElection(desc, afterExpiration, joinAtHead);\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      \n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        boolean onlyLeaderIndexes = zkStateReader.getClusterState().getCollection(collection).getRealtimeReplicas() == 1;\n        boolean isReplicaInOnlyLeaderIndexes = onlyLeaderIndexes && !isLeader;\n        if (isReplicaInOnlyLeaderIndexes) {\n          String commitVersion = ReplicateFromLeader.getCommitVersion(core);\n          if (commitVersion != null) {\n            ulog.copyOverOldUpdates(Long.parseLong(commitVersion));\n          }\n        }\n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null && !isReplicaInOnlyLeaderIndexes) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getSlice(collection, shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, core, cc, afterExpiration);\n        if (!didRecovery) {\n          if (isReplicaInOnlyLeaderIndexes) {\n            startReplicationFromLeader(coreName);\n          }\n          publish(desc, Replica.State.ACTIVE);\n        }\n        \n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","bugFix":null,"bugIntro":["344b0840364d990b29b97467bfcc766ff8325d11"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e9017cf144952056066919f1ebc7897ff9bd71b1","date":1496757600,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n      \n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, cloudDesc.getCollectionName(), shardId);\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        Replica replica = zkStateReader.getClusterState().getReplica(collection, coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        //TODO WHy would replica be null?\n        if (replica == null || replica.getType() != Type.PULL) {\n          joinElection(desc, afterExpiration, joinAtHead);\n        } else if (replica.getType() == Type.PULL) {\n          if (joinAtHead) {\n            log.warn(\"Replica {} was designated as preferred leader but it's type is {}, It won't join election\", coreZkNodeName, Type.PULL);\n          }\n          log.debug(\"Replica {} skipping election because it's type is {}\", coreZkNodeName, Type.PULL);\n          startReplicationFromLeader(coreName, false);\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      Replica.Type replicaType =  zkStateReader.getClusterState().getCollection(collection).getReplica(coreZkNodeName).getType();\n      assert !(isLeader && replicaType == Type.PULL): \"Pull replica became leader!\";\n      \n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        boolean isTlogReplicaAndNotLeader = replicaType == Replica.Type.TLOG && !isLeader;\n        if (isTlogReplicaAndNotLeader) {\n          String commitVersion = ReplicateFromLeader.getCommitVersion(core);\n          if (commitVersion != null) {\n            ulog.copyOverOldUpdates(Long.parseLong(commitVersion));\n          }\n        }\n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null && !isTlogReplicaAndNotLeader) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getSlice(collection, shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, core, cc, afterExpiration);\n        if (!didRecovery) {\n          if (isTlogReplicaAndNotLeader) {\n            startReplicationFromLeader(coreName, true);\n          }\n          publish(desc, Replica.State.ACTIVE);\n        }\n        \n        \n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n      \n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, cloudDesc.getCollectionName(), shardId);\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        Replica replica = zkStateReader.getClusterState().getReplica(desc.getCloudDescriptor().getCollectionName(),\n            coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        joinElection(desc, afterExpiration, joinAtHead);\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      \n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        boolean onlyLeaderIndexes = zkStateReader.getClusterState().getCollection(collection).getRealtimeReplicas() == 1;\n        boolean isReplicaInOnlyLeaderIndexes = onlyLeaderIndexes && !isLeader;\n        if (isReplicaInOnlyLeaderIndexes) {\n          String commitVersion = ReplicateFromLeader.getCommitVersion(core);\n          if (commitVersion != null) {\n            ulog.copyOverOldUpdates(Long.parseLong(commitVersion));\n          }\n        }\n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null && !isReplicaInOnlyLeaderIndexes) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getSlice(collection, shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, core, cc, afterExpiration);\n        if (!didRecovery) {\n          if (isReplicaInOnlyLeaderIndexes) {\n            startReplicationFromLeader(coreName);\n          }\n          publish(desc, Replica.State.ACTIVE);\n        }\n        \n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"664ff2b928393480d9655010aa700656b0fcade0","date":1496842764,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n      \n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, cloudDesc.getCollectionName(), shardId);\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        Replica replica = zkStateReader.getClusterState().getReplica(collection, coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        //TODO WHy would replica be null?\n        if (replica == null || replica.getType() != Type.PULL) {\n          joinElection(desc, afterExpiration, joinAtHead);\n        } else if (replica.getType() == Type.PULL) {\n          if (joinAtHead) {\n            log.warn(\"Replica {} was designated as preferred leader but it's type is {}, It won't join election\", coreZkNodeName, Type.PULL);\n          }\n          log.debug(\"Replica {} skipping election because it's type is {}\", coreZkNodeName, Type.PULL);\n          startReplicationFromLeader(coreName, false);\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      Replica.Type replicaType =  zkStateReader.getClusterState().getCollection(collection).getReplica(coreZkNodeName).getType();\n      assert !(isLeader && replicaType == Type.PULL): \"Pull replica became leader!\";\n\n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        boolean isTlogReplicaAndNotLeader = replicaType == Replica.Type.TLOG && !isLeader;\n        if (isTlogReplicaAndNotLeader) {\n          String commitVersion = ReplicateFromLeader.getCommitVersion(core);\n          if (commitVersion != null) {\n            ulog.copyOverOldUpdates(Long.parseLong(commitVersion));\n          }\n        }\n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null && !isTlogReplicaAndNotLeader) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getSlice(collection, shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, core, cc, afterExpiration);\n        if (!didRecovery) {\n          if (isTlogReplicaAndNotLeader) {\n            startReplicationFromLeader(coreName, true);\n          }\n          publish(desc, Replica.State.ACTIVE);\n        }\n        \n\n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n      \n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, cloudDesc.getCollectionName(), shardId);\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        Replica replica = zkStateReader.getClusterState().getReplica(collection, coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        //TODO WHy would replica be null?\n        if (replica == null || replica.getType() != Type.PULL) {\n          joinElection(desc, afterExpiration, joinAtHead);\n        } else if (replica.getType() == Type.PULL) {\n          if (joinAtHead) {\n            log.warn(\"Replica {} was designated as preferred leader but it's type is {}, It won't join election\", coreZkNodeName, Type.PULL);\n          }\n          log.debug(\"Replica {} skipping election because it's type is {}\", coreZkNodeName, Type.PULL);\n          startReplicationFromLeader(coreName, false);\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      Replica.Type replicaType =  zkStateReader.getClusterState().getCollection(collection).getReplica(coreZkNodeName).getType();\n      assert !(isLeader && replicaType == Type.PULL): \"Pull replica became leader!\";\n      \n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        boolean isTlogReplicaAndNotLeader = replicaType == Replica.Type.TLOG && !isLeader;\n        if (isTlogReplicaAndNotLeader) {\n          String commitVersion = ReplicateFromLeader.getCommitVersion(core);\n          if (commitVersion != null) {\n            ulog.copyOverOldUpdates(Long.parseLong(commitVersion));\n          }\n        }\n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null && !isTlogReplicaAndNotLeader) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getSlice(collection, shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, core, cc, afterExpiration);\n        if (!didRecovery) {\n          if (isTlogReplicaAndNotLeader) {\n            startReplicationFromLeader(coreName, true);\n          }\n          publish(desc, Replica.State.ACTIVE);\n        }\n        \n        \n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fbedfa79ef95dc2b5b49f7d54d80e0b47867f9b4","date":1498540685,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n      \n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, cloudDesc.getCollectionName(), shardId);\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        Replica replica = zkStateReader.getClusterState().getReplica(collection, coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        //TODO WHy would replica be null?\n        if (replica == null || replica.getType() != Type.PULL) {\n          joinElection(desc, afterExpiration, joinAtHead);\n        } else if (replica.getType() == Type.PULL) {\n          if (joinAtHead) {\n            log.warn(\"Replica {} was designated as preferred leader but it's type is {}, It won't join election\", coreZkNodeName, Type.PULL);\n          }\n          log.debug(\"Replica {} skipping election because it's type is {}\", coreZkNodeName, Type.PULL);\n          startReplicationFromLeader(coreName, false);\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      Replica.Type replicaType =  zkStateReader.getClusterState().getCollection(collection).getReplica(coreZkNodeName).getType();\n      assert !(isLeader && replicaType == Type.PULL): \"Pull replica became leader!\";\n      \n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        boolean isTlogReplicaAndNotLeader = replicaType == Replica.Type.TLOG && !isLeader;\n        if (isTlogReplicaAndNotLeader) {\n          String commitVersion = ReplicateFromLeader.getCommitVersion(core);\n          if (commitVersion != null) {\n            ulog.copyOverOldUpdates(Long.parseLong(commitVersion));\n          }\n        }\n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null && !isTlogReplicaAndNotLeader) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getSlice(collection, shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, core, cc, afterExpiration);\n        if (!didRecovery) {\n          if (isTlogReplicaAndNotLeader) {\n            startReplicationFromLeader(coreName, true);\n          }\n          publish(desc, Replica.State.ACTIVE);\n        }\n        \n        \n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n      \n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, cloudDesc.getCollectionName(), shardId);\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        Replica replica = zkStateReader.getClusterState().getReplica(collection, coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        //TODO WHy would replica be null?\n        if (replica == null || replica.getType() != Type.PULL) {\n          joinElection(desc, afterExpiration, joinAtHead);\n        } else if (replica.getType() == Type.PULL) {\n          if (joinAtHead) {\n            log.warn(\"Replica {} was designated as preferred leader but it's type is {}, It won't join election\", coreZkNodeName, Type.PULL);\n          }\n          log.debug(\"Replica {} skipping election because it's type is {}\", coreZkNodeName, Type.PULL);\n          startReplicationFromLeader(coreName, false);\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      Replica.Type replicaType =  zkStateReader.getClusterState().getCollection(collection).getReplica(coreZkNodeName).getType();\n      assert !(isLeader && replicaType == Type.PULL): \"Pull replica became leader!\";\n\n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        boolean isTlogReplicaAndNotLeader = replicaType == Replica.Type.TLOG && !isLeader;\n        if (isTlogReplicaAndNotLeader) {\n          String commitVersion = ReplicateFromLeader.getCommitVersion(core);\n          if (commitVersion != null) {\n            ulog.copyOverOldUpdates(Long.parseLong(commitVersion));\n          }\n        }\n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null && !isTlogReplicaAndNotLeader) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getSlice(collection, shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, core, cc, afterExpiration);\n        if (!didRecovery) {\n          if (isTlogReplicaAndNotLeader) {\n            startReplicationFromLeader(coreName, true);\n          }\n          publish(desc, Replica.State.ACTIVE);\n        }\n        \n\n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"344b0840364d990b29b97467bfcc766ff8325d11","date":1501574100,"type":3,"author":"Cao Manh Dat","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n      \n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, cloudDesc.getCollectionName(), shardId);\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        final DocCollection docCollection = zkStateReader.getClusterState().getCollectionOrNull(collection);\n        Replica replica = (docCollection == null) ? null : docCollection.getReplica(coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        //TODO WHy would replica be null?\n        if (replica == null || replica.getType() != Type.PULL) {\n          joinElection(desc, afterExpiration, joinAtHead);\n        } else if (replica.getType() == Type.PULL) {\n          if (joinAtHead) {\n            log.warn(\"Replica {} was designated as preferred leader but it's type is {}, It won't join election\", coreZkNodeName, Type.PULL);\n          }\n          log.debug(\"Replica {} skipping election because it's type is {}\", coreZkNodeName, Type.PULL);\n          startReplicationFromLeader(coreName, false);\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      Replica.Type replicaType =  zkStateReader.getClusterState().getCollection(collection).getReplica(coreZkNodeName).getType();\n      assert !(isLeader && replicaType == Type.PULL): \"Pull replica became leader!\";\n      \n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        boolean isTlogReplicaAndNotLeader = replicaType == Replica.Type.TLOG && !isLeader;\n        if (isTlogReplicaAndNotLeader) {\n          String commitVersion = ReplicateFromLeader.getCommitVersion(core);\n          if (commitVersion != null) {\n            ulog.copyOverOldUpdates(Long.parseLong(commitVersion));\n          }\n        }\n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null && !isTlogReplicaAndNotLeader) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getCollection(collection).getSlice(shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, core, cc, afterExpiration);\n        if (!didRecovery) {\n          if (isTlogReplicaAndNotLeader) {\n            startReplicationFromLeader(coreName, true);\n          }\n          publish(desc, Replica.State.ACTIVE);\n        }\n        \n        \n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n      \n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, cloudDesc.getCollectionName(), shardId);\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        Replica replica = zkStateReader.getClusterState().getReplica(collection, coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        //TODO WHy would replica be null?\n        if (replica == null || replica.getType() != Type.PULL) {\n          joinElection(desc, afterExpiration, joinAtHead);\n        } else if (replica.getType() == Type.PULL) {\n          if (joinAtHead) {\n            log.warn(\"Replica {} was designated as preferred leader but it's type is {}, It won't join election\", coreZkNodeName, Type.PULL);\n          }\n          log.debug(\"Replica {} skipping election because it's type is {}\", coreZkNodeName, Type.PULL);\n          startReplicationFromLeader(coreName, false);\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      Replica.Type replicaType =  zkStateReader.getClusterState().getCollection(collection).getReplica(coreZkNodeName).getType();\n      assert !(isLeader && replicaType == Type.PULL): \"Pull replica became leader!\";\n      \n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        boolean isTlogReplicaAndNotLeader = replicaType == Replica.Type.TLOG && !isLeader;\n        if (isTlogReplicaAndNotLeader) {\n          String commitVersion = ReplicateFromLeader.getCommitVersion(core);\n          if (commitVersion != null) {\n            ulog.copyOverOldUpdates(Long.parseLong(commitVersion));\n          }\n        }\n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null && !isTlogReplicaAndNotLeader) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getSlice(collection, shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, core, cc, afterExpiration);\n        if (!didRecovery) {\n          if (isTlogReplicaAndNotLeader) {\n            startReplicationFromLeader(coreName, true);\n          }\n          publish(desc, Replica.State.ACTIVE);\n        }\n        \n        \n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","bugFix":["dbf528c0e702c5cbd1339b2da1cdc823fd44a925","61c45e99cf6676da48f19d7511c73712ad39402b"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7a23cf16c8fa265dc0a564adcabb55e3f054e0ac","date":1502192746,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n      \n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, cloudDesc.getCollectionName(), shardId);\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        final DocCollection docCollection = zkStateReader.getClusterState().getCollectionOrNull(collection);\n        Replica replica = (docCollection == null) ? null : docCollection.getReplica(coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        //TODO WHy would replica be null?\n        if (replica == null || replica.getType() != Type.PULL) {\n          joinElection(desc, afterExpiration, joinAtHead);\n        } else if (replica.getType() == Type.PULL) {\n          if (joinAtHead) {\n            log.warn(\"Replica {} was designated as preferred leader but it's type is {}, It won't join election\", coreZkNodeName, Type.PULL);\n          }\n          log.debug(\"Replica {} skipping election because it's type is {}\", coreZkNodeName, Type.PULL);\n          startReplicationFromLeader(coreName, false);\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      Replica.Type replicaType =  zkStateReader.getClusterState().getCollection(collection).getReplica(coreZkNodeName).getType();\n      assert !(isLeader && replicaType == Type.PULL): \"Pull replica became leader!\";\n      \n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        boolean isTlogReplicaAndNotLeader = replicaType == Replica.Type.TLOG && !isLeader;\n        if (isTlogReplicaAndNotLeader) {\n          String commitVersion = ReplicateFromLeader.getCommitVersion(core);\n          if (commitVersion != null) {\n            ulog.copyOverOldUpdates(Long.parseLong(commitVersion));\n          }\n        }\n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null && !isTlogReplicaAndNotLeader) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getCollection(collection).getSlice(shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, core, cc, afterExpiration);\n        if (!didRecovery) {\n          if (isTlogReplicaAndNotLeader) {\n            startReplicationFromLeader(coreName, true);\n          }\n          publish(desc, Replica.State.ACTIVE);\n        }\n        \n        \n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n      \n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, cloudDesc.getCollectionName(), shardId);\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        Replica replica = zkStateReader.getClusterState().getReplica(collection, coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        //TODO WHy would replica be null?\n        if (replica == null || replica.getType() != Type.PULL) {\n          joinElection(desc, afterExpiration, joinAtHead);\n        } else if (replica.getType() == Type.PULL) {\n          if (joinAtHead) {\n            log.warn(\"Replica {} was designated as preferred leader but it's type is {}, It won't join election\", coreZkNodeName, Type.PULL);\n          }\n          log.debug(\"Replica {} skipping election because it's type is {}\", coreZkNodeName, Type.PULL);\n          startReplicationFromLeader(coreName, false);\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      Replica.Type replicaType =  zkStateReader.getClusterState().getCollection(collection).getReplica(coreZkNodeName).getType();\n      assert !(isLeader && replicaType == Type.PULL): \"Pull replica became leader!\";\n      \n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        boolean isTlogReplicaAndNotLeader = replicaType == Replica.Type.TLOG && !isLeader;\n        if (isTlogReplicaAndNotLeader) {\n          String commitVersion = ReplicateFromLeader.getCommitVersion(core);\n          if (commitVersion != null) {\n            ulog.copyOverOldUpdates(Long.parseLong(commitVersion));\n          }\n        }\n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null && !isTlogReplicaAndNotLeader) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getSlice(collection, shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, core, cc, afterExpiration);\n        if (!didRecovery) {\n          if (isTlogReplicaAndNotLeader) {\n            startReplicationFromLeader(coreName, true);\n          }\n          publish(desc, Replica.State.ACTIVE);\n        }\n        \n        \n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f09dfe4eae83c6f3ce87c6267cb774e4da0a2d73","date":1504185139,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n      \n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, cloudDesc.getCollectionName(), shardId);\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        final DocCollection docCollection = zkStateReader.getClusterState().getCollectionOrNull(collection);\n        Replica replica = (docCollection == null) ? null : docCollection.getReplica(coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        //TODO WHy would replica be null?\n        if (replica == null || replica.getType() != Type.PULL) {\n          joinElection(desc, afterExpiration, joinAtHead);\n        } else if (replica.getType() == Type.PULL) {\n          if (joinAtHead) {\n            log.warn(\"Replica {} was designated as preferred leader but it's type is {}, It won't join election\", coreZkNodeName, Type.PULL);\n          }\n          log.debug(\"Replica {} skipping election because it's type is {}\", coreZkNodeName, Type.PULL);\n          startReplicationFromLeader(coreName, false);\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      Replica.Type replicaType =  zkStateReader.getClusterState().getCollection(collection).getReplica(coreZkNodeName).getType();\n      assert !(isLeader && replicaType == Type.PULL): \"Pull replica became leader!\";\n      \n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        boolean isTlogReplicaAndNotLeader = replicaType == Replica.Type.TLOG && !isLeader;\n        if (isTlogReplicaAndNotLeader) {\n          String commitVersion = ReplicateFromLeader.getCommitVersion(core);\n          if (commitVersion != null) {\n            ulog.copyOverOldUpdates(Long.parseLong(commitVersion), true);\n          }\n        }\n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null && !isTlogReplicaAndNotLeader) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getCollection(collection).getSlice(shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, core, cc, afterExpiration);\n        if (!didRecovery) {\n          if (isTlogReplicaAndNotLeader) {\n            startReplicationFromLeader(coreName, true);\n          }\n          publish(desc, Replica.State.ACTIVE);\n        }\n        \n        \n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n      \n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, cloudDesc.getCollectionName(), shardId);\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        final DocCollection docCollection = zkStateReader.getClusterState().getCollectionOrNull(collection);\n        Replica replica = (docCollection == null) ? null : docCollection.getReplica(coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        //TODO WHy would replica be null?\n        if (replica == null || replica.getType() != Type.PULL) {\n          joinElection(desc, afterExpiration, joinAtHead);\n        } else if (replica.getType() == Type.PULL) {\n          if (joinAtHead) {\n            log.warn(\"Replica {} was designated as preferred leader but it's type is {}, It won't join election\", coreZkNodeName, Type.PULL);\n          }\n          log.debug(\"Replica {} skipping election because it's type is {}\", coreZkNodeName, Type.PULL);\n          startReplicationFromLeader(coreName, false);\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      Replica.Type replicaType =  zkStateReader.getClusterState().getCollection(collection).getReplica(coreZkNodeName).getType();\n      assert !(isLeader && replicaType == Type.PULL): \"Pull replica became leader!\";\n      \n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        boolean isTlogReplicaAndNotLeader = replicaType == Replica.Type.TLOG && !isLeader;\n        if (isTlogReplicaAndNotLeader) {\n          String commitVersion = ReplicateFromLeader.getCommitVersion(core);\n          if (commitVersion != null) {\n            ulog.copyOverOldUpdates(Long.parseLong(commitVersion));\n          }\n        }\n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null && !isTlogReplicaAndNotLeader) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getCollection(collection).getSlice(shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, core, cc, afterExpiration);\n        if (!didRecovery) {\n          if (isTlogReplicaAndNotLeader) {\n            startReplicationFromLeader(coreName, true);\n          }\n          publish(desc, Replica.State.ACTIVE);\n        }\n        \n        \n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","bugFix":null,"bugIntro":["04ecf884544ff74add5faa452748f160c4af904b"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3a7809d1d753b67f48b1a706e17034bf8b624ea3","date":1504366927,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n      \n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, cloudDesc.getCollectionName(), shardId);\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        final DocCollection docCollection = zkStateReader.getClusterState().getCollectionOrNull(collection);\n        Replica replica = (docCollection == null) ? null : docCollection.getReplica(coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        //TODO WHy would replica be null?\n        if (replica == null || replica.getType() != Type.PULL) {\n          joinElection(desc, afterExpiration, joinAtHead);\n        } else if (replica.getType() == Type.PULL) {\n          if (joinAtHead) {\n            log.warn(\"Replica {} was designated as preferred leader but it's type is {}, It won't join election\", coreZkNodeName, Type.PULL);\n          }\n          log.debug(\"Replica {} skipping election because it's type is {}\", coreZkNodeName, Type.PULL);\n          startReplicationFromLeader(coreName, false);\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      Replica.Type replicaType =  zkStateReader.getClusterState().getCollection(collection).getReplica(coreZkNodeName).getType();\n      assert !(isLeader && replicaType == Type.PULL): \"Pull replica became leader!\";\n      \n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        boolean isTlogReplicaAndNotLeader = replicaType == Replica.Type.TLOG && !isLeader;\n        if (isTlogReplicaAndNotLeader) {\n          String commitVersion = ReplicateFromLeader.getCommitVersion(core);\n          if (commitVersion != null) {\n            ulog.copyOverOldUpdates(Long.parseLong(commitVersion), true);\n          }\n        }\n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null && !isTlogReplicaAndNotLeader) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getCollection(collection).getSlice(shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, core, cc, afterExpiration);\n        if (!didRecovery) {\n          if (isTlogReplicaAndNotLeader) {\n            startReplicationFromLeader(coreName, true);\n          }\n          publish(desc, Replica.State.ACTIVE);\n        }\n        \n        \n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n      \n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, cloudDesc.getCollectionName(), shardId);\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        final DocCollection docCollection = zkStateReader.getClusterState().getCollectionOrNull(collection);\n        Replica replica = (docCollection == null) ? null : docCollection.getReplica(coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        //TODO WHy would replica be null?\n        if (replica == null || replica.getType() != Type.PULL) {\n          joinElection(desc, afterExpiration, joinAtHead);\n        } else if (replica.getType() == Type.PULL) {\n          if (joinAtHead) {\n            log.warn(\"Replica {} was designated as preferred leader but it's type is {}, It won't join election\", coreZkNodeName, Type.PULL);\n          }\n          log.debug(\"Replica {} skipping election because it's type is {}\", coreZkNodeName, Type.PULL);\n          startReplicationFromLeader(coreName, false);\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      Replica.Type replicaType =  zkStateReader.getClusterState().getCollection(collection).getReplica(coreZkNodeName).getType();\n      assert !(isLeader && replicaType == Type.PULL): \"Pull replica became leader!\";\n      \n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        boolean isTlogReplicaAndNotLeader = replicaType == Replica.Type.TLOG && !isLeader;\n        if (isTlogReplicaAndNotLeader) {\n          String commitVersion = ReplicateFromLeader.getCommitVersion(core);\n          if (commitVersion != null) {\n            ulog.copyOverOldUpdates(Long.parseLong(commitVersion));\n          }\n        }\n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null && !isTlogReplicaAndNotLeader) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getCollection(collection).getSlice(shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, core, cc, afterExpiration);\n        if (!didRecovery) {\n          if (isTlogReplicaAndNotLeader) {\n            startReplicationFromLeader(coreName, true);\n          }\n          publish(desc, Replica.State.ACTIVE);\n        }\n        \n        \n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"104a3f62ee393d48b5596de76ed4d9a4e0ea6de7","date":1504848000,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n      \n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, cloudDesc.getCollectionName(), shardId);\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        final DocCollection docCollection = zkStateReader.getClusterState().getCollectionOrNull(collection);\n        Replica replica = (docCollection == null) ? null : docCollection.getReplica(coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        //TODO WHy would replica be null?\n        if (replica == null || replica.getType() != Type.PULL) {\n          joinElection(desc, afterExpiration, joinAtHead);\n        } else if (replica.getType() == Type.PULL) {\n          if (joinAtHead) {\n            log.warn(\"Replica {} was designated as preferred leader but it's type is {}, It won't join election\", coreZkNodeName, Type.PULL);\n          }\n          log.debug(\"Replica {} skipping election because it's type is {}\", coreZkNodeName, Type.PULL);\n          startReplicationFromLeader(coreName, false);\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      Replica.Type replicaType =  zkStateReader.getClusterState().getCollection(collection).getReplica(coreZkNodeName).getType();\n      assert !(isLeader && replicaType == Type.PULL): \"Pull replica became leader!\";\n      \n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        boolean isTlogReplicaAndNotLeader = replicaType == Replica.Type.TLOG && !isLeader;\n        if (isTlogReplicaAndNotLeader) {\n          String commitVersion = ReplicateFromLeader.getCommitVersion(core);\n          if (commitVersion != null) {\n            ulog.copyOverOldUpdates(Long.parseLong(commitVersion), true);\n          }\n        }\n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null && !isTlogReplicaAndNotLeader) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getCollection(collection).getSlice(shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, core, cc, afterExpiration);\n        if (!didRecovery) {\n          if (isTlogReplicaAndNotLeader) {\n            startReplicationFromLeader(coreName, true);\n          }\n          publish(desc, Replica.State.ACTIVE);\n        }\n        \n        \n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n      \n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, cloudDesc.getCollectionName(), shardId);\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        final DocCollection docCollection = zkStateReader.getClusterState().getCollectionOrNull(collection);\n        Replica replica = (docCollection == null) ? null : docCollection.getReplica(coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        //TODO WHy would replica be null?\n        if (replica == null || replica.getType() != Type.PULL) {\n          joinElection(desc, afterExpiration, joinAtHead);\n        } else if (replica.getType() == Type.PULL) {\n          if (joinAtHead) {\n            log.warn(\"Replica {} was designated as preferred leader but it's type is {}, It won't join election\", coreZkNodeName, Type.PULL);\n          }\n          log.debug(\"Replica {} skipping election because it's type is {}\", coreZkNodeName, Type.PULL);\n          startReplicationFromLeader(coreName, false);\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      Replica.Type replicaType =  zkStateReader.getClusterState().getCollection(collection).getReplica(coreZkNodeName).getType();\n      assert !(isLeader && replicaType == Type.PULL): \"Pull replica became leader!\";\n      \n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        boolean isTlogReplicaAndNotLeader = replicaType == Replica.Type.TLOG && !isLeader;\n        if (isTlogReplicaAndNotLeader) {\n          String commitVersion = ReplicateFromLeader.getCommitVersion(core);\n          if (commitVersion != null) {\n            ulog.copyOverOldUpdates(Long.parseLong(commitVersion));\n          }\n        }\n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null && !isTlogReplicaAndNotLeader) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getCollection(collection).getSlice(shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, core, cc, afterExpiration);\n        if (!didRecovery) {\n          if (isTlogReplicaAndNotLeader) {\n            startReplicationFromLeader(coreName, true);\n          }\n          publish(desc, Replica.State.ACTIVE);\n        }\n        \n        \n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"04ecf884544ff74add5faa452748f160c4af904b","date":1506527215,"type":3,"author":"Cao Manh Dat","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n      \n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, cloudDesc.getCollectionName(), shardId);\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        final DocCollection docCollection = zkStateReader.getClusterState().getCollectionOrNull(collection);\n        Replica replica = (docCollection == null) ? null : docCollection.getReplica(coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        //TODO WHy would replica be null?\n        if (replica == null || replica.getType() != Type.PULL) {\n          joinElection(desc, afterExpiration, joinAtHead);\n        } else if (replica.getType() == Type.PULL) {\n          if (joinAtHead) {\n            log.warn(\"Replica {} was designated as preferred leader but it's type is {}, It won't join election\", coreZkNodeName, Type.PULL);\n          }\n          log.debug(\"Replica {} skipping election because it's type is {}\", coreZkNodeName, Type.PULL);\n          startReplicationFromLeader(coreName, false);\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      Replica.Type replicaType =  zkStateReader.getClusterState().getCollection(collection).getReplica(coreZkNodeName).getType();\n      assert !(isLeader && replicaType == Type.PULL): \"Pull replica became leader!\";\n      \n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        boolean isTlogReplicaAndNotLeader = replicaType == Replica.Type.TLOG && !isLeader;\n        if (isTlogReplicaAndNotLeader) {\n          String commitVersion = ReplicateFromLeader.getCommitVersion(core);\n          if (commitVersion != null) {\n            ulog.copyOverOldUpdates(Long.parseLong(commitVersion));\n          }\n        }\n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null && !isTlogReplicaAndNotLeader) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getCollection(collection).getSlice(shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, core, cc, afterExpiration);\n        if (!didRecovery) {\n          if (isTlogReplicaAndNotLeader) {\n            startReplicationFromLeader(coreName, true);\n          }\n          publish(desc, Replica.State.ACTIVE);\n        }\n        \n        \n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n      \n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, cloudDesc.getCollectionName(), shardId);\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        final DocCollection docCollection = zkStateReader.getClusterState().getCollectionOrNull(collection);\n        Replica replica = (docCollection == null) ? null : docCollection.getReplica(coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        //TODO WHy would replica be null?\n        if (replica == null || replica.getType() != Type.PULL) {\n          joinElection(desc, afterExpiration, joinAtHead);\n        } else if (replica.getType() == Type.PULL) {\n          if (joinAtHead) {\n            log.warn(\"Replica {} was designated as preferred leader but it's type is {}, It won't join election\", coreZkNodeName, Type.PULL);\n          }\n          log.debug(\"Replica {} skipping election because it's type is {}\", coreZkNodeName, Type.PULL);\n          startReplicationFromLeader(coreName, false);\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      Replica.Type replicaType =  zkStateReader.getClusterState().getCollection(collection).getReplica(coreZkNodeName).getType();\n      assert !(isLeader && replicaType == Type.PULL): \"Pull replica became leader!\";\n      \n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        boolean isTlogReplicaAndNotLeader = replicaType == Replica.Type.TLOG && !isLeader;\n        if (isTlogReplicaAndNotLeader) {\n          String commitVersion = ReplicateFromLeader.getCommitVersion(core);\n          if (commitVersion != null) {\n            ulog.copyOverOldUpdates(Long.parseLong(commitVersion), true);\n          }\n        }\n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null && !isTlogReplicaAndNotLeader) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getCollection(collection).getSlice(shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, core, cc, afterExpiration);\n        if (!didRecovery) {\n          if (isTlogReplicaAndNotLeader) {\n            startReplicationFromLeader(coreName, true);\n          }\n          publish(desc, Replica.State.ACTIVE);\n        }\n        \n        \n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","bugFix":["f09dfe4eae83c6f3ce87c6267cb774e4da0a2d73"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6240b74b884c5587f2a4062dd27d6c32bf228889","date":1507037235,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n      \n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, cloudDesc.getCollectionName(), shardId);\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        final DocCollection docCollection = zkStateReader.getClusterState().getCollectionOrNull(collection);\n        Replica replica = (docCollection == null) ? null : docCollection.getReplica(coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        //TODO WHy would replica be null?\n        if (replica == null || replica.getType() != Type.PULL) {\n          joinElection(desc, afterExpiration, joinAtHead);\n        } else if (replica.getType() == Type.PULL) {\n          if (joinAtHead) {\n            log.warn(\"Replica {} was designated as preferred leader but it's type is {}, It won't join election\", coreZkNodeName, Type.PULL);\n          }\n          log.debug(\"Replica {} skipping election because it's type is {}\", coreZkNodeName, Type.PULL);\n          startReplicationFromLeader(coreName, false);\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      Replica.Type replicaType =  zkStateReader.getClusterState().getCollection(collection).getReplica(coreZkNodeName).getType();\n      assert !(isLeader && replicaType == Type.PULL): \"Pull replica became leader!\";\n      \n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        boolean isTlogReplicaAndNotLeader = replicaType == Replica.Type.TLOG && !isLeader;\n        if (isTlogReplicaAndNotLeader) {\n          String commitVersion = ReplicateFromLeader.getCommitVersion(core);\n          if (commitVersion != null) {\n            ulog.copyOverOldUpdates(Long.parseLong(commitVersion));\n          }\n        }\n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null && !isTlogReplicaAndNotLeader) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getCollection(collection).getSlice(shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, core, cc, afterExpiration);\n        if (!didRecovery) {\n          if (isTlogReplicaAndNotLeader) {\n            startReplicationFromLeader(coreName, true);\n          }\n          publish(desc, Replica.State.ACTIVE);\n        }\n        \n        \n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n      \n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, cloudDesc.getCollectionName(), shardId);\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        final DocCollection docCollection = zkStateReader.getClusterState().getCollectionOrNull(collection);\n        Replica replica = (docCollection == null) ? null : docCollection.getReplica(coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        //TODO WHy would replica be null?\n        if (replica == null || replica.getType() != Type.PULL) {\n          joinElection(desc, afterExpiration, joinAtHead);\n        } else if (replica.getType() == Type.PULL) {\n          if (joinAtHead) {\n            log.warn(\"Replica {} was designated as preferred leader but it's type is {}, It won't join election\", coreZkNodeName, Type.PULL);\n          }\n          log.debug(\"Replica {} skipping election because it's type is {}\", coreZkNodeName, Type.PULL);\n          startReplicationFromLeader(coreName, false);\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      Replica.Type replicaType =  zkStateReader.getClusterState().getCollection(collection).getReplica(coreZkNodeName).getType();\n      assert !(isLeader && replicaType == Type.PULL): \"Pull replica became leader!\";\n      \n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        boolean isTlogReplicaAndNotLeader = replicaType == Replica.Type.TLOG && !isLeader;\n        if (isTlogReplicaAndNotLeader) {\n          String commitVersion = ReplicateFromLeader.getCommitVersion(core);\n          if (commitVersion != null) {\n            ulog.copyOverOldUpdates(Long.parseLong(commitVersion), true);\n          }\n        }\n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null && !isTlogReplicaAndNotLeader) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getCollection(collection).getSlice(shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, core, cc, afterExpiration);\n        if (!didRecovery) {\n          if (isTlogReplicaAndNotLeader) {\n            startReplicationFromLeader(coreName, true);\n          }\n          publish(desc, Replica.State.ACTIVE);\n        }\n        \n        \n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"84f20f331d8001864545c7021812d8c6509c7593","date":1517216128,"type":3,"author":"Cao Manh Dat","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n\n      ZkShardTerms shardTerms = getShardTerms(collection, cloudDesc.getShardId());\n\n      // This flag is used for testing rolling updates and should be removed in SOLR-11812\n      boolean isRunningInNewLIR = \"new\".equals(desc.getCoreProperty(\"lirVersion\", \"new\"));\n      if (isRunningInNewLIR) {\n        shardTerms.registerTerm(coreZkNodeName);\n      }\n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, cloudDesc.getCollectionName(), shardId);\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        final DocCollection docCollection = zkStateReader.getClusterState().getCollectionOrNull(collection);\n        Replica replica = (docCollection == null) ? null : docCollection.getReplica(coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        //TODO WHy would replica be null?\n        if (replica == null || replica.getType() != Type.PULL) {\n          joinElection(desc, afterExpiration, joinAtHead);\n        } else if (replica.getType() == Type.PULL) {\n          if (joinAtHead) {\n            log.warn(\"Replica {} was designated as preferred leader but it's type is {}, It won't join election\", coreZkNodeName, Type.PULL);\n          }\n          log.debug(\"Replica {} skipping election because it's type is {}\", coreZkNodeName, Type.PULL);\n          startReplicationFromLeader(coreName, false);\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      Replica.Type replicaType =  zkStateReader.getClusterState().getCollection(collection).getReplica(coreZkNodeName).getType();\n      assert !(isLeader && replicaType == Type.PULL): \"Pull replica became leader!\";\n      \n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        boolean isTlogReplicaAndNotLeader = replicaType == Replica.Type.TLOG && !isLeader;\n        if (isTlogReplicaAndNotLeader) {\n          String commitVersion = ReplicateFromLeader.getCommitVersion(core);\n          if (commitVersion != null) {\n            ulog.copyOverOldUpdates(Long.parseLong(commitVersion));\n          }\n        }\n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null && !isTlogReplicaAndNotLeader) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getCollection(collection).getSlice(shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, shardId, core, cc, afterExpiration);\n        if (!didRecovery) {\n          if (isTlogReplicaAndNotLeader) {\n            startReplicationFromLeader(coreName, true);\n          }\n          publish(desc, Replica.State.ACTIVE);\n        }\n\n        if (isRunningInNewLIR && replicaType != Type.PULL) {\n          shardTerms.addListener(new RecoveringCoreTermWatcher(core));\n        }\n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n      \n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, cloudDesc.getCollectionName(), shardId);\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        final DocCollection docCollection = zkStateReader.getClusterState().getCollectionOrNull(collection);\n        Replica replica = (docCollection == null) ? null : docCollection.getReplica(coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        //TODO WHy would replica be null?\n        if (replica == null || replica.getType() != Type.PULL) {\n          joinElection(desc, afterExpiration, joinAtHead);\n        } else if (replica.getType() == Type.PULL) {\n          if (joinAtHead) {\n            log.warn(\"Replica {} was designated as preferred leader but it's type is {}, It won't join election\", coreZkNodeName, Type.PULL);\n          }\n          log.debug(\"Replica {} skipping election because it's type is {}\", coreZkNodeName, Type.PULL);\n          startReplicationFromLeader(coreName, false);\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      Replica.Type replicaType =  zkStateReader.getClusterState().getCollection(collection).getReplica(coreZkNodeName).getType();\n      assert !(isLeader && replicaType == Type.PULL): \"Pull replica became leader!\";\n      \n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        boolean isTlogReplicaAndNotLeader = replicaType == Replica.Type.TLOG && !isLeader;\n        if (isTlogReplicaAndNotLeader) {\n          String commitVersion = ReplicateFromLeader.getCommitVersion(core);\n          if (commitVersion != null) {\n            ulog.copyOverOldUpdates(Long.parseLong(commitVersion));\n          }\n        }\n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null && !isTlogReplicaAndNotLeader) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getCollection(collection).getSlice(shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, core, cc, afterExpiration);\n        if (!didRecovery) {\n          if (isTlogReplicaAndNotLeader) {\n            startReplicationFromLeader(coreName, true);\n          }\n          publish(desc, Replica.State.ACTIVE);\n        }\n        \n        \n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","bugFix":null,"bugIntro":["67144a5cdd5ecbe2f8ca846956214f360fec12f5"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8c30d22eaf1287a88a402fba9d8b7b9d20d6ef94","date":1520143025,"type":3,"author":"Cao Manh Dat","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n\n      ZkShardTerms shardTerms = getShardTerms(collection, cloudDesc.getShardId());\n\n      // This flag is used for testing rolling updates and should be removed in SOLR-11812\n      boolean isRunningInNewLIR = \"new\".equals(desc.getCoreProperty(\"lirVersion\", \"new\"));\n      if (isRunningInNewLIR && cloudDesc.getReplicaType() != Type.PULL) {\n        shardTerms.registerTerm(coreZkNodeName);\n      }\n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, cloudDesc.getCollectionName(), shardId);\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        final DocCollection docCollection = zkStateReader.getClusterState().getCollectionOrNull(collection);\n        Replica replica = (docCollection == null) ? null : docCollection.getReplica(coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        //TODO WHy would replica be null?\n        if (replica == null || replica.getType() != Type.PULL) {\n          joinElection(desc, afterExpiration, joinAtHead);\n        } else if (replica.getType() == Type.PULL) {\n          if (joinAtHead) {\n            log.warn(\"Replica {} was designated as preferred leader but it's type is {}, It won't join election\", coreZkNodeName, Type.PULL);\n          }\n          log.debug(\"Replica {} skipping election because it's type is {}\", coreZkNodeName, Type.PULL);\n          startReplicationFromLeader(coreName, false);\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      Replica.Type replicaType =  zkStateReader.getClusterState().getCollection(collection).getReplica(coreZkNodeName).getType();\n      assert !(isLeader && replicaType == Type.PULL): \"Pull replica became leader!\";\n      \n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        boolean isTlogReplicaAndNotLeader = replicaType == Replica.Type.TLOG && !isLeader;\n        if (isTlogReplicaAndNotLeader) {\n          String commitVersion = ReplicateFromLeader.getCommitVersion(core);\n          if (commitVersion != null) {\n            ulog.copyOverOldUpdates(Long.parseLong(commitVersion));\n          }\n        }\n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null && !isTlogReplicaAndNotLeader) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getCollection(collection).getSlice(shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, shardId, core, cc, afterExpiration);\n        if (!didRecovery) {\n          if (isTlogReplicaAndNotLeader) {\n            startReplicationFromLeader(coreName, true);\n          }\n          publish(desc, Replica.State.ACTIVE);\n        }\n\n        if (isRunningInNewLIR && replicaType != Type.PULL) {\n          shardTerms.addListener(new RecoveringCoreTermWatcher(core));\n        }\n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n\n      ZkShardTerms shardTerms = getShardTerms(collection, cloudDesc.getShardId());\n\n      // This flag is used for testing rolling updates and should be removed in SOLR-11812\n      boolean isRunningInNewLIR = \"new\".equals(desc.getCoreProperty(\"lirVersion\", \"new\"));\n      if (isRunningInNewLIR) {\n        shardTerms.registerTerm(coreZkNodeName);\n      }\n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, cloudDesc.getCollectionName(), shardId);\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        final DocCollection docCollection = zkStateReader.getClusterState().getCollectionOrNull(collection);\n        Replica replica = (docCollection == null) ? null : docCollection.getReplica(coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        //TODO WHy would replica be null?\n        if (replica == null || replica.getType() != Type.PULL) {\n          joinElection(desc, afterExpiration, joinAtHead);\n        } else if (replica.getType() == Type.PULL) {\n          if (joinAtHead) {\n            log.warn(\"Replica {} was designated as preferred leader but it's type is {}, It won't join election\", coreZkNodeName, Type.PULL);\n          }\n          log.debug(\"Replica {} skipping election because it's type is {}\", coreZkNodeName, Type.PULL);\n          startReplicationFromLeader(coreName, false);\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      Replica.Type replicaType =  zkStateReader.getClusterState().getCollection(collection).getReplica(coreZkNodeName).getType();\n      assert !(isLeader && replicaType == Type.PULL): \"Pull replica became leader!\";\n      \n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        boolean isTlogReplicaAndNotLeader = replicaType == Replica.Type.TLOG && !isLeader;\n        if (isTlogReplicaAndNotLeader) {\n          String commitVersion = ReplicateFromLeader.getCommitVersion(core);\n          if (commitVersion != null) {\n            ulog.copyOverOldUpdates(Long.parseLong(commitVersion));\n          }\n        }\n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null && !isTlogReplicaAndNotLeader) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getCollection(collection).getSlice(shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, shardId, core, cc, afterExpiration);\n        if (!didRecovery) {\n          if (isTlogReplicaAndNotLeader) {\n            startReplicationFromLeader(coreName, true);\n          }\n          publish(desc, Replica.State.ACTIVE);\n        }\n\n        if (isRunningInNewLIR && replicaType != Type.PULL) {\n          shardTerms.addListener(new RecoveringCoreTermWatcher(core));\n        }\n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"46df9d682d3407bf67ce2946c9f9267376809bc2","date":1521244495,"type":3,"author":"Cao Manh Dat","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n\n      ZkShardTerms shardTerms = getShardTerms(collection, cloudDesc.getShardId());\n\n      // This flag is used for testing rolling updates and should be removed in SOLR-11812\n      boolean isRunningInNewLIR = \"new\".equals(desc.getCoreProperty(\"lirVersion\", \"new\"));\n      if (isRunningInNewLIR && cloudDesc.getReplicaType() != Type.PULL) {\n        shardTerms.registerTerm(coreZkNodeName);\n      }\n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, cloudDesc.getCollectionName(), shardId);\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        final DocCollection docCollection = zkStateReader.getClusterState().getCollectionOrNull(collection);\n        Replica replica = (docCollection == null) ? null : docCollection.getReplica(coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        //TODO WHy would replica be null?\n        if (replica == null || replica.getType() != Type.PULL) {\n          joinElection(desc, afterExpiration, joinAtHead);\n        } else if (replica.getType() == Type.PULL) {\n          if (joinAtHead) {\n            log.warn(\"Replica {} was designated as preferred leader but it's type is {}, It won't join election\", coreZkNodeName, Type.PULL);\n          }\n          log.debug(\"Replica {} skipping election because it's type is {}\", coreZkNodeName, Type.PULL);\n          startReplicationFromLeader(coreName, false);\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      Replica.Type replicaType =  zkStateReader.getClusterState().getCollection(collection).getReplica(coreZkNodeName).getType();\n      assert !(isLeader && replicaType == Type.PULL): \"Pull replica became leader!\";\n      \n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        boolean isTlogReplicaAndNotLeader = replicaType == Replica.Type.TLOG && !isLeader;\n        if (isTlogReplicaAndNotLeader) {\n          String commitVersion = ReplicateFromLeader.getCommitVersion(core);\n          if (commitVersion != null) {\n            ulog.copyOverOldUpdates(Long.parseLong(commitVersion));\n          }\n        }\n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null && !isTlogReplicaAndNotLeader) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getCollection(collection).getSlice(shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, shardId, core, cc, afterExpiration);\n        if (!didRecovery) {\n          if (isTlogReplicaAndNotLeader) {\n            startReplicationFromLeader(coreName, true);\n          }\n          publish(desc, Replica.State.ACTIVE);\n        }\n\n        if (isRunningInNewLIR && replicaType != Type.PULL) {\n          shardTerms.addListener(new RecoveringCoreTermWatcher(core));\n        }\n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      return shardId;\n    } catch (Exception e) {\n      unregister(coreName, desc, false);\n      throw e;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n\n      ZkShardTerms shardTerms = getShardTerms(collection, cloudDesc.getShardId());\n\n      // This flag is used for testing rolling updates and should be removed in SOLR-11812\n      boolean isRunningInNewLIR = \"new\".equals(desc.getCoreProperty(\"lirVersion\", \"new\"));\n      if (isRunningInNewLIR && cloudDesc.getReplicaType() != Type.PULL) {\n        shardTerms.registerTerm(coreZkNodeName);\n      }\n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, cloudDesc.getCollectionName(), shardId);\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        final DocCollection docCollection = zkStateReader.getClusterState().getCollectionOrNull(collection);\n        Replica replica = (docCollection == null) ? null : docCollection.getReplica(coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        //TODO WHy would replica be null?\n        if (replica == null || replica.getType() != Type.PULL) {\n          joinElection(desc, afterExpiration, joinAtHead);\n        } else if (replica.getType() == Type.PULL) {\n          if (joinAtHead) {\n            log.warn(\"Replica {} was designated as preferred leader but it's type is {}, It won't join election\", coreZkNodeName, Type.PULL);\n          }\n          log.debug(\"Replica {} skipping election because it's type is {}\", coreZkNodeName, Type.PULL);\n          startReplicationFromLeader(coreName, false);\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      Replica.Type replicaType =  zkStateReader.getClusterState().getCollection(collection).getReplica(coreZkNodeName).getType();\n      assert !(isLeader && replicaType == Type.PULL): \"Pull replica became leader!\";\n      \n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        boolean isTlogReplicaAndNotLeader = replicaType == Replica.Type.TLOG && !isLeader;\n        if (isTlogReplicaAndNotLeader) {\n          String commitVersion = ReplicateFromLeader.getCommitVersion(core);\n          if (commitVersion != null) {\n            ulog.copyOverOldUpdates(Long.parseLong(commitVersion));\n          }\n        }\n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null && !isTlogReplicaAndNotLeader) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getCollection(collection).getSlice(shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, shardId, core, cc, afterExpiration);\n        if (!didRecovery) {\n          if (isTlogReplicaAndNotLeader) {\n            startReplicationFromLeader(coreName, true);\n          }\n          publish(desc, Replica.State.ACTIVE);\n        }\n\n        if (isRunningInNewLIR && replicaType != Type.PULL) {\n          shardTerms.addListener(new RecoveringCoreTermWatcher(core));\n        }\n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"203e3fcf513c02ee2c07015f2ce277e26dc60907","date":1521404157,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n\n      ZkShardTerms shardTerms = getShardTerms(collection, cloudDesc.getShardId());\n\n      // This flag is used for testing rolling updates and should be removed in SOLR-11812\n      boolean isRunningInNewLIR = \"new\".equals(desc.getCoreProperty(\"lirVersion\", \"new\"));\n      if (isRunningInNewLIR && cloudDesc.getReplicaType() != Type.PULL) {\n        shardTerms.registerTerm(coreZkNodeName);\n      }\n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, cloudDesc.getCollectionName(), shardId);\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        final DocCollection docCollection = zkStateReader.getClusterState().getCollectionOrNull(collection);\n        Replica replica = (docCollection == null) ? null : docCollection.getReplica(coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        //TODO WHy would replica be null?\n        if (replica == null || replica.getType() != Type.PULL) {\n          joinElection(desc, afterExpiration, joinAtHead);\n        } else if (replica.getType() == Type.PULL) {\n          if (joinAtHead) {\n            log.warn(\"Replica {} was designated as preferred leader but it's type is {}, It won't join election\", coreZkNodeName, Type.PULL);\n          }\n          log.debug(\"Replica {} skipping election because it's type is {}\", coreZkNodeName, Type.PULL);\n          startReplicationFromLeader(coreName, false);\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      Replica.Type replicaType =  zkStateReader.getClusterState().getCollection(collection).getReplica(coreZkNodeName).getType();\n      assert !(isLeader && replicaType == Type.PULL): \"Pull replica became leader!\";\n      \n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        boolean isTlogReplicaAndNotLeader = replicaType == Replica.Type.TLOG && !isLeader;\n        if (isTlogReplicaAndNotLeader) {\n          String commitVersion = ReplicateFromLeader.getCommitVersion(core);\n          if (commitVersion != null) {\n            ulog.copyOverOldUpdates(Long.parseLong(commitVersion));\n          }\n        }\n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null && !isTlogReplicaAndNotLeader) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getCollection(collection).getSlice(shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, shardId, core, cc, afterExpiration);\n        if (!didRecovery) {\n          if (isTlogReplicaAndNotLeader) {\n            startReplicationFromLeader(coreName, true);\n          }\n          publish(desc, Replica.State.ACTIVE);\n        }\n\n        if (isRunningInNewLIR && replicaType != Type.PULL) {\n          shardTerms.addListener(new RecoveringCoreTermWatcher(core));\n        }\n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      return shardId;\n    } catch (Exception e) {\n      unregister(coreName, desc, false);\n      throw e;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n\n      ZkShardTerms shardTerms = getShardTerms(collection, cloudDesc.getShardId());\n\n      // This flag is used for testing rolling updates and should be removed in SOLR-11812\n      boolean isRunningInNewLIR = \"new\".equals(desc.getCoreProperty(\"lirVersion\", \"new\"));\n      if (isRunningInNewLIR && cloudDesc.getReplicaType() != Type.PULL) {\n        shardTerms.registerTerm(coreZkNodeName);\n      }\n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, cloudDesc.getCollectionName(), shardId);\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        final DocCollection docCollection = zkStateReader.getClusterState().getCollectionOrNull(collection);\n        Replica replica = (docCollection == null) ? null : docCollection.getReplica(coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        //TODO WHy would replica be null?\n        if (replica == null || replica.getType() != Type.PULL) {\n          joinElection(desc, afterExpiration, joinAtHead);\n        } else if (replica.getType() == Type.PULL) {\n          if (joinAtHead) {\n            log.warn(\"Replica {} was designated as preferred leader but it's type is {}, It won't join election\", coreZkNodeName, Type.PULL);\n          }\n          log.debug(\"Replica {} skipping election because it's type is {}\", coreZkNodeName, Type.PULL);\n          startReplicationFromLeader(coreName, false);\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      Replica.Type replicaType =  zkStateReader.getClusterState().getCollection(collection).getReplica(coreZkNodeName).getType();\n      assert !(isLeader && replicaType == Type.PULL): \"Pull replica became leader!\";\n      \n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        boolean isTlogReplicaAndNotLeader = replicaType == Replica.Type.TLOG && !isLeader;\n        if (isTlogReplicaAndNotLeader) {\n          String commitVersion = ReplicateFromLeader.getCommitVersion(core);\n          if (commitVersion != null) {\n            ulog.copyOverOldUpdates(Long.parseLong(commitVersion));\n          }\n        }\n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null && !isTlogReplicaAndNotLeader) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getCollection(collection).getSlice(shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, shardId, core, cc, afterExpiration);\n        if (!didRecovery) {\n          if (isTlogReplicaAndNotLeader) {\n            startReplicationFromLeader(coreName, true);\n          }\n          publish(desc, Replica.State.ACTIVE);\n        }\n\n        if (isRunningInNewLIR && replicaType != Type.PULL) {\n          shardTerms.addListener(new RecoveringCoreTermWatcher(core));\n        }\n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"67144a5cdd5ecbe2f8ca846956214f360fec12f5","date":1521599751,"type":3,"author":"Cao Manh Dat","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n\n      ZkShardTerms shardTerms = getShardTerms(collection, cloudDesc.getShardId());\n\n      // This flag is used for testing rolling updates and should be removed in SOLR-11812\n      boolean isRunningInNewLIR = \"new\".equals(desc.getCoreProperty(\"lirVersion\", \"new\"));\n      if (isRunningInNewLIR && cloudDesc.getReplicaType() != Type.PULL) {\n        shardTerms.registerTerm(coreZkNodeName);\n      }\n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, cloudDesc.getCollectionName(), shardId);\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        final DocCollection docCollection = zkStateReader.getClusterState().getCollectionOrNull(collection);\n        Replica replica = (docCollection == null) ? null : docCollection.getReplica(coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        //TODO WHy would replica be null?\n        if (replica == null || replica.getType() != Type.PULL) {\n          joinElection(desc, afterExpiration, joinAtHead);\n        } else if (replica.getType() == Type.PULL) {\n          if (joinAtHead) {\n            log.warn(\"Replica {} was designated as preferred leader but it's type is {}, It won't join election\", coreZkNodeName, Type.PULL);\n          }\n          log.debug(\"Replica {} skipping election because it's type is {}\", coreZkNodeName, Type.PULL);\n          startReplicationFromLeader(coreName, false);\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      Replica.Type replicaType =  zkStateReader.getClusterState().getCollection(collection).getReplica(coreZkNodeName).getType();\n      assert !(isLeader && replicaType == Type.PULL): \"Pull replica became leader!\";\n      \n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        boolean isTlogReplicaAndNotLeader = replicaType == Replica.Type.TLOG && !isLeader;\n        if (isTlogReplicaAndNotLeader) {\n          String commitVersion = ReplicateFromLeader.getCommitVersion(core);\n          if (commitVersion != null) {\n            ulog.copyOverOldUpdates(Long.parseLong(commitVersion));\n          }\n        }\n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null && !isTlogReplicaAndNotLeader) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getCollection(collection).getSlice(shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, shardId, core, cc, afterExpiration);\n        if (!didRecovery) {\n          if (isTlogReplicaAndNotLeader) {\n            startReplicationFromLeader(coreName, true);\n          }\n          publish(desc, Replica.State.ACTIVE);\n        }\n\n        if (isRunningInNewLIR && replicaType != Type.PULL) {\n          shardTerms.addListener(new RecoveringCoreTermWatcher(core.getCoreDescriptor(), getCoreContainer()));\n        }\n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      return shardId;\n    } catch (Exception e) {\n      unregister(coreName, desc, false);\n      throw e;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n\n      ZkShardTerms shardTerms = getShardTerms(collection, cloudDesc.getShardId());\n\n      // This flag is used for testing rolling updates and should be removed in SOLR-11812\n      boolean isRunningInNewLIR = \"new\".equals(desc.getCoreProperty(\"lirVersion\", \"new\"));\n      if (isRunningInNewLIR && cloudDesc.getReplicaType() != Type.PULL) {\n        shardTerms.registerTerm(coreZkNodeName);\n      }\n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, cloudDesc.getCollectionName(), shardId);\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        final DocCollection docCollection = zkStateReader.getClusterState().getCollectionOrNull(collection);\n        Replica replica = (docCollection == null) ? null : docCollection.getReplica(coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        //TODO WHy would replica be null?\n        if (replica == null || replica.getType() != Type.PULL) {\n          joinElection(desc, afterExpiration, joinAtHead);\n        } else if (replica.getType() == Type.PULL) {\n          if (joinAtHead) {\n            log.warn(\"Replica {} was designated as preferred leader but it's type is {}, It won't join election\", coreZkNodeName, Type.PULL);\n          }\n          log.debug(\"Replica {} skipping election because it's type is {}\", coreZkNodeName, Type.PULL);\n          startReplicationFromLeader(coreName, false);\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      Replica.Type replicaType =  zkStateReader.getClusterState().getCollection(collection).getReplica(coreZkNodeName).getType();\n      assert !(isLeader && replicaType == Type.PULL): \"Pull replica became leader!\";\n      \n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        boolean isTlogReplicaAndNotLeader = replicaType == Replica.Type.TLOG && !isLeader;\n        if (isTlogReplicaAndNotLeader) {\n          String commitVersion = ReplicateFromLeader.getCommitVersion(core);\n          if (commitVersion != null) {\n            ulog.copyOverOldUpdates(Long.parseLong(commitVersion));\n          }\n        }\n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null && !isTlogReplicaAndNotLeader) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getCollection(collection).getSlice(shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, shardId, core, cc, afterExpiration);\n        if (!didRecovery) {\n          if (isTlogReplicaAndNotLeader) {\n            startReplicationFromLeader(coreName, true);\n          }\n          publish(desc, Replica.State.ACTIVE);\n        }\n\n        if (isRunningInNewLIR && replicaType != Type.PULL) {\n          shardTerms.addListener(new RecoveringCoreTermWatcher(core));\n        }\n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      return shardId;\n    } catch (Exception e) {\n      unregister(coreName, desc, false);\n      throw e;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","bugFix":["84f20f331d8001864545c7021812d8c6509c7593"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6815b5b5d6334b2245dd7be2f8b6cca949bf7f43","date":1521731438,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n\n      ZkShardTerms shardTerms = getShardTerms(collection, cloudDesc.getShardId());\n\n      // This flag is used for testing rolling updates and should be removed in SOLR-11812\n      boolean isRunningInNewLIR = \"new\".equals(desc.getCoreProperty(\"lirVersion\", \"new\"));\n      if (isRunningInNewLIR && cloudDesc.getReplicaType() != Type.PULL) {\n        shardTerms.registerTerm(coreZkNodeName);\n      }\n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, cloudDesc.getCollectionName(), shardId);\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        final DocCollection docCollection = zkStateReader.getClusterState().getCollectionOrNull(collection);\n        Replica replica = (docCollection == null) ? null : docCollection.getReplica(coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        //TODO WHy would replica be null?\n        if (replica == null || replica.getType() != Type.PULL) {\n          joinElection(desc, afterExpiration, joinAtHead);\n        } else if (replica.getType() == Type.PULL) {\n          if (joinAtHead) {\n            log.warn(\"Replica {} was designated as preferred leader but it's type is {}, It won't join election\", coreZkNodeName, Type.PULL);\n          }\n          log.debug(\"Replica {} skipping election because it's type is {}\", coreZkNodeName, Type.PULL);\n          startReplicationFromLeader(coreName, false);\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      Replica.Type replicaType =  zkStateReader.getClusterState().getCollection(collection).getReplica(coreZkNodeName).getType();\n      assert !(isLeader && replicaType == Type.PULL): \"Pull replica became leader!\";\n      \n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        boolean isTlogReplicaAndNotLeader = replicaType == Replica.Type.TLOG && !isLeader;\n        if (isTlogReplicaAndNotLeader) {\n          String commitVersion = ReplicateFromLeader.getCommitVersion(core);\n          if (commitVersion != null) {\n            ulog.copyOverOldUpdates(Long.parseLong(commitVersion));\n          }\n        }\n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null && !isTlogReplicaAndNotLeader) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getCollection(collection).getSlice(shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, shardId, core, cc, afterExpiration);\n        if (!didRecovery) {\n          if (isTlogReplicaAndNotLeader) {\n            startReplicationFromLeader(coreName, true);\n          }\n          publish(desc, Replica.State.ACTIVE);\n        }\n\n        if (isRunningInNewLIR && replicaType != Type.PULL) {\n          shardTerms.addListener(new RecoveringCoreTermWatcher(core.getCoreDescriptor(), getCoreContainer()));\n        }\n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      return shardId;\n    } catch (Exception e) {\n      unregister(coreName, desc, false);\n      throw e;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n\n      ZkShardTerms shardTerms = getShardTerms(collection, cloudDesc.getShardId());\n\n      // This flag is used for testing rolling updates and should be removed in SOLR-11812\n      boolean isRunningInNewLIR = \"new\".equals(desc.getCoreProperty(\"lirVersion\", \"new\"));\n      if (isRunningInNewLIR && cloudDesc.getReplicaType() != Type.PULL) {\n        shardTerms.registerTerm(coreZkNodeName);\n      }\n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, cloudDesc.getCollectionName(), shardId);\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        final DocCollection docCollection = zkStateReader.getClusterState().getCollectionOrNull(collection);\n        Replica replica = (docCollection == null) ? null : docCollection.getReplica(coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        //TODO WHy would replica be null?\n        if (replica == null || replica.getType() != Type.PULL) {\n          joinElection(desc, afterExpiration, joinAtHead);\n        } else if (replica.getType() == Type.PULL) {\n          if (joinAtHead) {\n            log.warn(\"Replica {} was designated as preferred leader but it's type is {}, It won't join election\", coreZkNodeName, Type.PULL);\n          }\n          log.debug(\"Replica {} skipping election because it's type is {}\", coreZkNodeName, Type.PULL);\n          startReplicationFromLeader(coreName, false);\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      Replica.Type replicaType =  zkStateReader.getClusterState().getCollection(collection).getReplica(coreZkNodeName).getType();\n      assert !(isLeader && replicaType == Type.PULL): \"Pull replica became leader!\";\n      \n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        boolean isTlogReplicaAndNotLeader = replicaType == Replica.Type.TLOG && !isLeader;\n        if (isTlogReplicaAndNotLeader) {\n          String commitVersion = ReplicateFromLeader.getCommitVersion(core);\n          if (commitVersion != null) {\n            ulog.copyOverOldUpdates(Long.parseLong(commitVersion));\n          }\n        }\n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null && !isTlogReplicaAndNotLeader) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getCollection(collection).getSlice(shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, shardId, core, cc, afterExpiration);\n        if (!didRecovery) {\n          if (isTlogReplicaAndNotLeader) {\n            startReplicationFromLeader(coreName, true);\n          }\n          publish(desc, Replica.State.ACTIVE);\n        }\n\n        if (isRunningInNewLIR && replicaType != Type.PULL) {\n          shardTerms.addListener(new RecoveringCoreTermWatcher(core));\n        }\n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      return shardId;\n    } catch (Exception e) {\n      unregister(coreName, desc, false);\n      throw e;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"28ba172425e443e0f08a49de6d73586c418d7251","date":1523970991,"type":3,"author":"Cao Manh Dat","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      final String shardId = cloudDesc.getShardId();\n      final String coreZkNodeName = cloudDesc.getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n\n      // check replica's existence in clusterstate first\n      try {\n        zkStateReader.waitForState(collection, Overseer.isLegacy(zkStateReader) ? 60000 : 100,\n            TimeUnit.MILLISECONDS, (liveNodes, collectionState) -> getReplicaOrNull(collectionState, shardId, coreZkNodeName) != null);\n      } catch (TimeoutException e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Error registering SolrCore, timeout waiting for replica present in clusterstate\");\n      }\n      Replica replica = getReplicaOrNull(zkStateReader.getClusterState().getCollectionOrNull(collection), shardId, coreZkNodeName);\n      if (replica == null) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Error registering SolrCore, replica is removed from clusterstate\");\n      }\n\n      ZkShardTerms shardTerms = getShardTerms(collection, cloudDesc.getShardId());\n\n      // This flag is used for testing rolling updates and should be removed in SOLR-11812\n      boolean isRunningInNewLIR = \"new\".equals(desc.getCoreProperty(\"lirVersion\", \"new\"));\n      if (isRunningInNewLIR && replica.getType() != Type.PULL) {\n        shardTerms.registerTerm(coreZkNodeName);\n      }\n\n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, collection, shardId);\n\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        if (replica.getType() != Type.PULL) {\n          joinElection(desc, afterExpiration, joinAtHead);\n        } else if (replica.getType() == Type.PULL) {\n          if (joinAtHead) {\n            log.warn(\"Replica {} was designated as preferred leader but it's type is {}, It won't join election\", coreZkNodeName, Type.PULL);\n          }\n          log.debug(\"Replica {} skipping election because it's type is {}\", coreZkNodeName, Type.PULL);\n          startReplicationFromLeader(coreName, false);\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      assert !(isLeader && replica.getType() == Type.PULL) : \"Pull replica became leader!\";\n\n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        boolean isTlogReplicaAndNotLeader = replica.getType() == Replica.Type.TLOG && !isLeader;\n        if (isTlogReplicaAndNotLeader) {\n          String commitVersion = ReplicateFromLeader.getCommitVersion(core);\n          if (commitVersion != null) {\n            ulog.copyOverOldUpdates(Long.parseLong(commitVersion));\n          }\n        }\n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null && !isTlogReplicaAndNotLeader) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getCollection(collection).getSlice(shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, shardId, core, cc, afterExpiration);\n        if (!didRecovery) {\n          if (isTlogReplicaAndNotLeader) {\n            startReplicationFromLeader(coreName, true);\n          }\n          publish(desc, Replica.State.ACTIVE);\n        }\n\n        if (isRunningInNewLIR && replica.getType() != Type.PULL) {\n          // the watcher is added to a set so multiple calls of this method will left only one watcher\n          shardTerms.addListener(new RecoveringCoreTermWatcher(core.getCoreDescriptor(), getCoreContainer()));\n        }\n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      } catch (Exception e) {\n        unregister(coreName, desc, false);\n        throw e;\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      // the watcher is added to a set so multiple calls of this method will left only one watcher\n      zkStateReader.registerCollectionStateWatcher(cloudDesc.getCollectionName(),\n          new UnloadCoreOnDeletedWatcher(coreZkNodeName, shardId, desc.getName()));\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      \n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      \n      final String coreZkNodeName = desc.getCloudDescriptor().getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n\n      ZkShardTerms shardTerms = getShardTerms(collection, cloudDesc.getShardId());\n\n      // This flag is used for testing rolling updates and should be removed in SOLR-11812\n      boolean isRunningInNewLIR = \"new\".equals(desc.getCoreProperty(\"lirVersion\", \"new\"));\n      if (isRunningInNewLIR && cloudDesc.getReplicaType() != Type.PULL) {\n        shardTerms.registerTerm(coreZkNodeName);\n      }\n      String shardId = cloudDesc.getShardId();\n      Map<String,Object> props = new HashMap<>();\n      // we only put a subset of props into the leader node\n      props.put(ZkStateReader.BASE_URL_PROP, baseUrl);\n      props.put(ZkStateReader.CORE_NAME_PROP, coreName);\n      props.put(ZkStateReader.NODE_NAME_PROP, getNodeName());\n      \n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, cloudDesc.getCollectionName(), shardId);\n      \n      ZkNodeProps leaderProps = new ZkNodeProps(props);\n\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = false;\n        final DocCollection docCollection = zkStateReader.getClusterState().getCollectionOrNull(collection);\n        Replica replica = (docCollection == null) ? null : docCollection.getReplica(coreZkNodeName);\n        if (replica != null) {\n          joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        }\n        //TODO WHy would replica be null?\n        if (replica == null || replica.getType() != Type.PULL) {\n          joinElection(desc, afterExpiration, joinAtHead);\n        } else if (replica.getType() == Type.PULL) {\n          if (joinAtHead) {\n            log.warn(\"Replica {} was designated as preferred leader but it's type is {}, It won't join election\", coreZkNodeName, Type.PULL);\n          }\n          log.debug(\"Replica {} skipping election because it's type is {}\", coreZkNodeName, Type.PULL);\n          startReplicationFromLeader(coreName, false);\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      Replica.Type replicaType =  zkStateReader.getClusterState().getCollection(collection).getReplica(coreZkNodeName).getType();\n      assert !(isLeader && replicaType == Type.PULL): \"Pull replica became leader!\";\n      \n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        boolean isTlogReplicaAndNotLeader = replicaType == Replica.Type.TLOG && !isLeader;\n        if (isTlogReplicaAndNotLeader) {\n          String commitVersion = ReplicateFromLeader.getCommitVersion(core);\n          if (commitVersion != null) {\n            ulog.copyOverOldUpdates(Long.parseLong(commitVersion));\n          }\n        }\n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null && !isTlogReplicaAndNotLeader) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getCollection(collection).getSlice(shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, shardId, core, cc, afterExpiration);\n        if (!didRecovery) {\n          if (isTlogReplicaAndNotLeader) {\n            startReplicationFromLeader(coreName, true);\n          }\n          publish(desc, Replica.State.ACTIVE);\n        }\n\n        if (isRunningInNewLIR && replicaType != Type.PULL) {\n          shardTerms.addListener(new RecoveringCoreTermWatcher(core.getCoreDescriptor(), getCoreContainer()));\n        }\n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      return shardId;\n    } catch (Exception e) {\n      unregister(coreName, desc, false);\n      throw e;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","bugFix":null,"bugIntro":["5ad9c35f926b4bf8da0336d1300efc709c8d5a56"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b6d72c72ee67b4aa8bc8bdd91bae9069b04fc180","date":1539076849,"type":3,"author":"Cao Manh Dat","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      final String shardId = cloudDesc.getShardId();\n      final String coreZkNodeName = cloudDesc.getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n\n      // check replica's existence in clusterstate first\n      try {\n        zkStateReader.waitForState(collection, Overseer.isLegacy(zkStateReader) ? 60000 : 100,\n            TimeUnit.MILLISECONDS, (liveNodes, collectionState) -> getReplicaOrNull(collectionState, shardId, coreZkNodeName) != null);\n      } catch (TimeoutException e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Error registering SolrCore, timeout waiting for replica present in clusterstate\");\n      }\n      Replica replica = getReplicaOrNull(zkStateReader.getClusterState().getCollectionOrNull(collection), shardId, coreZkNodeName);\n      if (replica == null) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Error registering SolrCore, replica is removed from clusterstate\");\n      }\n\n      ZkShardTerms shardTerms = getShardTerms(collection, cloudDesc.getShardId());\n\n      if (replica.getType() != Type.PULL) {\n        shardTerms.registerTerm(coreZkNodeName);\n      }\n\n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, collection, shardId);\n\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        if (replica.getType() != Type.PULL) {\n          joinElection(desc, afterExpiration, joinAtHead);\n        } else if (replica.getType() == Type.PULL) {\n          if (joinAtHead) {\n            log.warn(\"Replica {} was designated as preferred leader but it's type is {}, It won't join election\", coreZkNodeName, Type.PULL);\n          }\n          log.debug(\"Replica {} skipping election because it's type is {}\", coreZkNodeName, Type.PULL);\n          startReplicationFromLeader(coreName, false);\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      assert !(isLeader && replica.getType() == Type.PULL) : \"Pull replica became leader!\";\n\n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        boolean isTlogReplicaAndNotLeader = replica.getType() == Replica.Type.TLOG && !isLeader;\n        if (isTlogReplicaAndNotLeader) {\n          String commitVersion = ReplicateFromLeader.getCommitVersion(core);\n          if (commitVersion != null) {\n            ulog.copyOverOldUpdates(Long.parseLong(commitVersion));\n          }\n        }\n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null && !isTlogReplicaAndNotLeader) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getCollection(collection).getSlice(shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, shardId, core, cc, afterExpiration);\n        if (!didRecovery) {\n          if (isTlogReplicaAndNotLeader) {\n            startReplicationFromLeader(coreName, true);\n          }\n          publish(desc, Replica.State.ACTIVE);\n        }\n\n        if (replica.getType() != Type.PULL) {\n          // the watcher is added to a set so multiple calls of this method will left only one watcher\n          shardTerms.addListener(new RecoveringCoreTermWatcher(core.getCoreDescriptor(), getCoreContainer()));\n        }\n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      } catch (Exception e) {\n        unregister(coreName, desc, false);\n        throw e;\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      // the watcher is added to a set so multiple calls of this method will left only one watcher\n      zkStateReader.registerCollectionStateWatcher(cloudDesc.getCollectionName(),\n          new UnloadCoreOnDeletedWatcher(coreZkNodeName, shardId, desc.getName()));\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      final String shardId = cloudDesc.getShardId();\n      final String coreZkNodeName = cloudDesc.getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n\n      // check replica's existence in clusterstate first\n      try {\n        zkStateReader.waitForState(collection, Overseer.isLegacy(zkStateReader) ? 60000 : 100,\n            TimeUnit.MILLISECONDS, (liveNodes, collectionState) -> getReplicaOrNull(collectionState, shardId, coreZkNodeName) != null);\n      } catch (TimeoutException e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Error registering SolrCore, timeout waiting for replica present in clusterstate\");\n      }\n      Replica replica = getReplicaOrNull(zkStateReader.getClusterState().getCollectionOrNull(collection), shardId, coreZkNodeName);\n      if (replica == null) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Error registering SolrCore, replica is removed from clusterstate\");\n      }\n\n      ZkShardTerms shardTerms = getShardTerms(collection, cloudDesc.getShardId());\n\n      // This flag is used for testing rolling updates and should be removed in SOLR-11812\n      boolean isRunningInNewLIR = \"new\".equals(desc.getCoreProperty(\"lirVersion\", \"new\"));\n      if (isRunningInNewLIR && replica.getType() != Type.PULL) {\n        shardTerms.registerTerm(coreZkNodeName);\n      }\n\n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, collection, shardId);\n\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        if (replica.getType() != Type.PULL) {\n          joinElection(desc, afterExpiration, joinAtHead);\n        } else if (replica.getType() == Type.PULL) {\n          if (joinAtHead) {\n            log.warn(\"Replica {} was designated as preferred leader but it's type is {}, It won't join election\", coreZkNodeName, Type.PULL);\n          }\n          log.debug(\"Replica {} skipping election because it's type is {}\", coreZkNodeName, Type.PULL);\n          startReplicationFromLeader(coreName, false);\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      assert !(isLeader && replica.getType() == Type.PULL) : \"Pull replica became leader!\";\n\n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        boolean isTlogReplicaAndNotLeader = replica.getType() == Replica.Type.TLOG && !isLeader;\n        if (isTlogReplicaAndNotLeader) {\n          String commitVersion = ReplicateFromLeader.getCommitVersion(core);\n          if (commitVersion != null) {\n            ulog.copyOverOldUpdates(Long.parseLong(commitVersion));\n          }\n        }\n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null && !isTlogReplicaAndNotLeader) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getCollection(collection).getSlice(shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, shardId, core, cc, afterExpiration);\n        if (!didRecovery) {\n          if (isTlogReplicaAndNotLeader) {\n            startReplicationFromLeader(coreName, true);\n          }\n          publish(desc, Replica.State.ACTIVE);\n        }\n\n        if (isRunningInNewLIR && replica.getType() != Type.PULL) {\n          // the watcher is added to a set so multiple calls of this method will left only one watcher\n          shardTerms.addListener(new RecoveringCoreTermWatcher(core.getCoreDescriptor(), getCoreContainer()));\n        }\n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      } catch (Exception e) {\n        unregister(coreName, desc, false);\n        throw e;\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      // the watcher is added to a set so multiple calls of this method will left only one watcher\n      zkStateReader.registerCollectionStateWatcher(cloudDesc.getCollectionName(),\n          new UnloadCoreOnDeletedWatcher(coreZkNodeName, shardId, desc.getName()));\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bb222a3f9d9421d5c95afce73013fbd8de07ea1f","date":1543514331,"type":3,"author":"markrmiller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      final String shardId = cloudDesc.getShardId();\n      final String coreZkNodeName = cloudDesc.getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n\n      // check replica's existence in clusterstate first\n      try {\n        zkStateReader.waitForState(collection, Overseer.isLegacy(zkStateReader) ? 60000 : 100,\n            TimeUnit.MILLISECONDS, (liveNodes, collectionState) -> getReplicaOrNull(collectionState, shardId, coreZkNodeName) != null);\n      } catch (TimeoutException e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Error registering SolrCore, timeout waiting for replica present in clusterstate\");\n      }\n      Replica replica = getReplicaOrNull(zkStateReader.getClusterState().getCollectionOrNull(collection), shardId, coreZkNodeName);\n      if (replica == null) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Error registering SolrCore, replica is removed from clusterstate\");\n      }\n\n      ZkShardTerms shardTerms = getShardTerms(collection, cloudDesc.getShardId());\n\n      if (replica.getType() != Type.PULL) {\n        shardTerms.registerTerm(coreZkNodeName);\n      }\n\n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, collection, shardId);\n\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        if (replica.getType() != Type.PULL) {\n          joinElection(desc, afterExpiration, joinAtHead);\n        } else if (replica.getType() == Type.PULL) {\n          if (joinAtHead) {\n            log.warn(\"Replica {} was designated as preferred leader but it's type is {}, It won't join election\", coreZkNodeName, Type.PULL);\n          }\n          log.debug(\"Replica {} skipping election because it's type is {}\", coreZkNodeName, Type.PULL);\n          startReplicationFromLeader(coreName, false);\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      assert !(isLeader && replica.getType() == Type.PULL) : \"Pull replica became leader!\";\n\n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        if (core == null) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"SolrCore is no longer available to register\");\n        }\n\n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        boolean isTlogReplicaAndNotLeader = replica.getType() == Replica.Type.TLOG && !isLeader;\n        if (isTlogReplicaAndNotLeader) {\n          String commitVersion = ReplicateFromLeader.getCommitVersion(core);\n          if (commitVersion != null) {\n            ulog.copyOverOldUpdates(Long.parseLong(commitVersion));\n          }\n        }\n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null && !isTlogReplicaAndNotLeader) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getCollection(collection).getSlice(shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, shardId, core, cc, afterExpiration);\n        if (!didRecovery) {\n          if (isTlogReplicaAndNotLeader) {\n            startReplicationFromLeader(coreName, true);\n          }\n          publish(desc, Replica.State.ACTIVE);\n        }\n\n        if (replica.getType() != Type.PULL) {\n          // the watcher is added to a set so multiple calls of this method will left only one watcher\n          shardTerms.addListener(new RecoveringCoreTermWatcher(core.getCoreDescriptor(), getCoreContainer()));\n        }\n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      } catch (Exception e) {\n        unregister(coreName, desc, false);\n        throw e;\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      // the watcher is added to a set so multiple calls of this method will left only one watcher\n      zkStateReader.registerCollectionStateWatcher(cloudDesc.getCollectionName(),\n          new UnloadCoreOnDeletedWatcher(coreZkNodeName, shardId, desc.getName()));\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      final String shardId = cloudDesc.getShardId();\n      final String coreZkNodeName = cloudDesc.getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n\n      // check replica's existence in clusterstate first\n      try {\n        zkStateReader.waitForState(collection, Overseer.isLegacy(zkStateReader) ? 60000 : 100,\n            TimeUnit.MILLISECONDS, (liveNodes, collectionState) -> getReplicaOrNull(collectionState, shardId, coreZkNodeName) != null);\n      } catch (TimeoutException e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Error registering SolrCore, timeout waiting for replica present in clusterstate\");\n      }\n      Replica replica = getReplicaOrNull(zkStateReader.getClusterState().getCollectionOrNull(collection), shardId, coreZkNodeName);\n      if (replica == null) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Error registering SolrCore, replica is removed from clusterstate\");\n      }\n\n      ZkShardTerms shardTerms = getShardTerms(collection, cloudDesc.getShardId());\n\n      if (replica.getType() != Type.PULL) {\n        shardTerms.registerTerm(coreZkNodeName);\n      }\n\n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, collection, shardId);\n\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        if (replica.getType() != Type.PULL) {\n          joinElection(desc, afterExpiration, joinAtHead);\n        } else if (replica.getType() == Type.PULL) {\n          if (joinAtHead) {\n            log.warn(\"Replica {} was designated as preferred leader but it's type is {}, It won't join election\", coreZkNodeName, Type.PULL);\n          }\n          log.debug(\"Replica {} skipping election because it's type is {}\", coreZkNodeName, Type.PULL);\n          startReplicationFromLeader(coreName, false);\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      assert !(isLeader && replica.getType() == Type.PULL) : \"Pull replica became leader!\";\n\n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        boolean isTlogReplicaAndNotLeader = replica.getType() == Replica.Type.TLOG && !isLeader;\n        if (isTlogReplicaAndNotLeader) {\n          String commitVersion = ReplicateFromLeader.getCommitVersion(core);\n          if (commitVersion != null) {\n            ulog.copyOverOldUpdates(Long.parseLong(commitVersion));\n          }\n        }\n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null && !isTlogReplicaAndNotLeader) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getCollection(collection).getSlice(shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, shardId, core, cc, afterExpiration);\n        if (!didRecovery) {\n          if (isTlogReplicaAndNotLeader) {\n            startReplicationFromLeader(coreName, true);\n          }\n          publish(desc, Replica.State.ACTIVE);\n        }\n\n        if (replica.getType() != Type.PULL) {\n          // the watcher is added to a set so multiple calls of this method will left only one watcher\n          shardTerms.addListener(new RecoveringCoreTermWatcher(core.getCoreDescriptor(), getCoreContainer()));\n        }\n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      } catch (Exception e) {\n        unregister(coreName, desc, false);\n        throw e;\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      // the watcher is added to a set so multiple calls of this method will left only one watcher\n      zkStateReader.registerCollectionStateWatcher(cloudDesc.getCollectionName(),\n          new UnloadCoreOnDeletedWatcher(coreZkNodeName, shardId, desc.getName()));\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0db83f1bb855a4ac824c9a2a8e1ee9b29a039c15","date":1554259533,"type":3,"author":"Gus Heck","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      final String shardId = cloudDesc.getShardId();\n      final String coreZkNodeName = cloudDesc.getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n\n      // check replica's existence in clusterstate first\n      try {\n        zkStateReader.waitForState(collection, Overseer.isLegacy(zkStateReader) ? 60000 : 100,\n            TimeUnit.MILLISECONDS, (liveNodes, collectionState) -> getReplicaOrNull(collectionState, shardId, coreZkNodeName) != null);\n      } catch (TimeoutException e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Error registering SolrCore, timeout waiting for replica present in clusterstate\");\n      }\n      Replica replica = getReplicaOrNull(zkStateReader.getClusterState().getCollectionOrNull(collection), shardId, coreZkNodeName);\n      if (replica == null) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Error registering SolrCore, replica is removed from clusterstate\");\n      }\n\n      ZkShardTerms shardTerms = getShardTerms(collection, cloudDesc.getShardId());\n\n      if (replica.getType() != Type.PULL) {\n        shardTerms.registerTerm(coreZkNodeName);\n      }\n\n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, collection, shardId);\n\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        if (replica.getType() != Type.PULL) {\n          joinElection(desc, afterExpiration, joinAtHead);\n        } else if (replica.getType() == Type.PULL) {\n          if (joinAtHead) {\n            log.warn(\"Replica {} was designated as preferred leader but it's type is {}, It won't join election\", coreZkNodeName, Type.PULL);\n          }\n          log.debug(\"Replica {} skipping election because it's type is {}\", coreZkNodeName, Type.PULL);\n          startReplicationFromLeader(coreName, false);\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n\n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      assert !(isLeader && replica.getType() == Type.PULL) : \"Pull replica became leader!\";\n\n      try (SolrCore core = cc.getCore(desc.getName())) {\n\n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n\n        if (core == null) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"SolrCore is no longer available to register\");\n        }\n\n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        boolean isTlogReplicaAndNotLeader = replica.getType() == Replica.Type.TLOG && !isLeader;\n        if (isTlogReplicaAndNotLeader) {\n          String commitVersion = ReplicateFromLeader.getCommitVersion(core);\n          if (commitVersion != null) {\n            ulog.copyOverOldUpdates(Long.parseLong(commitVersion));\n          }\n        }\n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null && !isTlogReplicaAndNotLeader) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getCollection(collection).getSlice(shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, shardId, core, cc, afterExpiration);\n        if (!didRecovery) {\n          if (isTlogReplicaAndNotLeader) {\n            startReplicationFromLeader(coreName, true);\n          }\n          publish(desc, Replica.State.ACTIVE);\n        }\n\n        if (replica.getType() != Type.PULL) {\n          // the watcher is added to a set so multiple calls of this method will left only one watcher\n          shardTerms.addListener(new RecoveringCoreTermWatcher(core.getCoreDescriptor(), getCoreContainer()));\n        }\n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      } catch (Exception e) {\n        unregister(coreName, desc, false);\n        throw e;\n      }\n\n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      // the watcher is added to a set so multiple calls of this method will left only one watcher\n      zkStateReader.registerCollectionStateWatcher(cloudDesc.getCollectionName(),\n          new UnloadCoreOnDeletedWatcher(coreZkNodeName, shardId, desc.getName()));\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      final String shardId = cloudDesc.getShardId();\n      final String coreZkNodeName = cloudDesc.getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n\n      // check replica's existence in clusterstate first\n      try {\n        zkStateReader.waitForState(collection, Overseer.isLegacy(zkStateReader) ? 60000 : 100,\n            TimeUnit.MILLISECONDS, (liveNodes, collectionState) -> getReplicaOrNull(collectionState, shardId, coreZkNodeName) != null);\n      } catch (TimeoutException e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Error registering SolrCore, timeout waiting for replica present in clusterstate\");\n      }\n      Replica replica = getReplicaOrNull(zkStateReader.getClusterState().getCollectionOrNull(collection), shardId, coreZkNodeName);\n      if (replica == null) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Error registering SolrCore, replica is removed from clusterstate\");\n      }\n\n      ZkShardTerms shardTerms = getShardTerms(collection, cloudDesc.getShardId());\n\n      if (replica.getType() != Type.PULL) {\n        shardTerms.registerTerm(coreZkNodeName);\n      }\n\n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, collection, shardId);\n\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        if (replica.getType() != Type.PULL) {\n          joinElection(desc, afterExpiration, joinAtHead);\n        } else if (replica.getType() == Type.PULL) {\n          if (joinAtHead) {\n            log.warn(\"Replica {} was designated as preferred leader but it's type is {}, It won't join election\", coreZkNodeName, Type.PULL);\n          }\n          log.debug(\"Replica {} skipping election because it's type is {}\", coreZkNodeName, Type.PULL);\n          startReplicationFromLeader(coreName, false);\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      \n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n      \n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      assert !(isLeader && replica.getType() == Type.PULL) : \"Pull replica became leader!\";\n\n      try (SolrCore core = cc.getCore(desc.getName())) {\n        \n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n        \n        if (core == null) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"SolrCore is no longer available to register\");\n        }\n\n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        boolean isTlogReplicaAndNotLeader = replica.getType() == Replica.Type.TLOG && !isLeader;\n        if (isTlogReplicaAndNotLeader) {\n          String commitVersion = ReplicateFromLeader.getCommitVersion(core);\n          if (commitVersion != null) {\n            ulog.copyOverOldUpdates(Long.parseLong(commitVersion));\n          }\n        }\n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null && !isTlogReplicaAndNotLeader) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getCollection(collection).getSlice(shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, shardId, core, cc, afterExpiration);\n        if (!didRecovery) {\n          if (isTlogReplicaAndNotLeader) {\n            startReplicationFromLeader(coreName, true);\n          }\n          publish(desc, Replica.State.ACTIVE);\n        }\n\n        if (replica.getType() != Type.PULL) {\n          // the watcher is added to a set so multiple calls of this method will left only one watcher\n          shardTerms.addListener(new RecoveringCoreTermWatcher(core.getCoreDescriptor(), getCoreContainer()));\n        }\n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      } catch (Exception e) {\n        unregister(coreName, desc, false);\n        throw e;\n      }\n      \n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      // the watcher is added to a set so multiple calls of this method will left only one watcher\n      zkStateReader.registerCollectionStateWatcher(cloudDesc.getCollectionName(),\n          new UnloadCoreOnDeletedWatcher(coreZkNodeName, shardId, desc.getName()));\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7b366e7dd3172289251a86be96031af4002cd19c","date":1560790783,"type":3,"author":"Chris Hostetter","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      final String shardId = cloudDesc.getShardId();\n      final String coreZkNodeName = cloudDesc.getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n\n      // check replica's existence in clusterstate first\n      try {\n        zkStateReader.waitForState(collection, Overseer.isLegacy(zkStateReader) ? 60000 : 100,\n            TimeUnit.MILLISECONDS, (collectionState) -> getReplicaOrNull(collectionState, shardId, coreZkNodeName) != null);\n      } catch (TimeoutException e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Error registering SolrCore, timeout waiting for replica present in clusterstate\");\n      }\n      Replica replica = getReplicaOrNull(zkStateReader.getClusterState().getCollectionOrNull(collection), shardId, coreZkNodeName);\n      if (replica == null) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Error registering SolrCore, replica is removed from clusterstate\");\n      }\n\n      ZkShardTerms shardTerms = getShardTerms(collection, cloudDesc.getShardId());\n\n      if (replica.getType() != Type.PULL) {\n        shardTerms.registerTerm(coreZkNodeName);\n      }\n\n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, collection, shardId);\n\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        if (replica.getType() != Type.PULL) {\n          joinElection(desc, afterExpiration, joinAtHead);\n        } else if (replica.getType() == Type.PULL) {\n          if (joinAtHead) {\n            log.warn(\"Replica {} was designated as preferred leader but it's type is {}, It won't join election\", coreZkNodeName, Type.PULL);\n          }\n          log.debug(\"Replica {} skipping election because it's type is {}\", coreZkNodeName, Type.PULL);\n          startReplicationFromLeader(coreName, false);\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n\n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      assert !(isLeader && replica.getType() == Type.PULL) : \"Pull replica became leader!\";\n\n      try (SolrCore core = cc.getCore(desc.getName())) {\n\n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n\n        if (core == null) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"SolrCore is no longer available to register\");\n        }\n\n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        boolean isTlogReplicaAndNotLeader = replica.getType() == Replica.Type.TLOG && !isLeader;\n        if (isTlogReplicaAndNotLeader) {\n          String commitVersion = ReplicateFromLeader.getCommitVersion(core);\n          if (commitVersion != null) {\n            ulog.copyOverOldUpdates(Long.parseLong(commitVersion));\n          }\n        }\n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null && !isTlogReplicaAndNotLeader) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getCollection(collection).getSlice(shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, shardId, core, cc, afterExpiration);\n        if (!didRecovery) {\n          if (isTlogReplicaAndNotLeader) {\n            startReplicationFromLeader(coreName, true);\n          }\n          publish(desc, Replica.State.ACTIVE);\n        }\n\n        if (replica.getType() != Type.PULL) {\n          // the watcher is added to a set so multiple calls of this method will left only one watcher\n          shardTerms.addListener(new RecoveringCoreTermWatcher(core.getCoreDescriptor(), getCoreContainer()));\n        }\n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      } catch (Exception e) {\n        unregister(coreName, desc, false);\n        throw e;\n      }\n\n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      // the watcher is added to a set so multiple calls of this method will left only one watcher\n      zkStateReader.registerDocCollectionWatcher(cloudDesc.getCollectionName(),\n          new UnloadCoreOnDeletedWatcher(coreZkNodeName, shardId, desc.getName()));\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      final String shardId = cloudDesc.getShardId();\n      final String coreZkNodeName = cloudDesc.getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n\n      // check replica's existence in clusterstate first\n      try {\n        zkStateReader.waitForState(collection, Overseer.isLegacy(zkStateReader) ? 60000 : 100,\n            TimeUnit.MILLISECONDS, (liveNodes, collectionState) -> getReplicaOrNull(collectionState, shardId, coreZkNodeName) != null);\n      } catch (TimeoutException e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Error registering SolrCore, timeout waiting for replica present in clusterstate\");\n      }\n      Replica replica = getReplicaOrNull(zkStateReader.getClusterState().getCollectionOrNull(collection), shardId, coreZkNodeName);\n      if (replica == null) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Error registering SolrCore, replica is removed from clusterstate\");\n      }\n\n      ZkShardTerms shardTerms = getShardTerms(collection, cloudDesc.getShardId());\n\n      if (replica.getType() != Type.PULL) {\n        shardTerms.registerTerm(coreZkNodeName);\n      }\n\n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, collection, shardId);\n\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        if (replica.getType() != Type.PULL) {\n          joinElection(desc, afterExpiration, joinAtHead);\n        } else if (replica.getType() == Type.PULL) {\n          if (joinAtHead) {\n            log.warn(\"Replica {} was designated as preferred leader but it's type is {}, It won't join election\", coreZkNodeName, Type.PULL);\n          }\n          log.debug(\"Replica {} skipping election because it's type is {}\", coreZkNodeName, Type.PULL);\n          startReplicationFromLeader(coreName, false);\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n\n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      assert !(isLeader && replica.getType() == Type.PULL) : \"Pull replica became leader!\";\n\n      try (SolrCore core = cc.getCore(desc.getName())) {\n\n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n\n        if (core == null) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"SolrCore is no longer available to register\");\n        }\n\n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        boolean isTlogReplicaAndNotLeader = replica.getType() == Replica.Type.TLOG && !isLeader;\n        if (isTlogReplicaAndNotLeader) {\n          String commitVersion = ReplicateFromLeader.getCommitVersion(core);\n          if (commitVersion != null) {\n            ulog.copyOverOldUpdates(Long.parseLong(commitVersion));\n          }\n        }\n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null && !isTlogReplicaAndNotLeader) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getCollection(collection).getSlice(shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, shardId, core, cc, afterExpiration);\n        if (!didRecovery) {\n          if (isTlogReplicaAndNotLeader) {\n            startReplicationFromLeader(coreName, true);\n          }\n          publish(desc, Replica.State.ACTIVE);\n        }\n\n        if (replica.getType() != Type.PULL) {\n          // the watcher is added to a set so multiple calls of this method will left only one watcher\n          shardTerms.addListener(new RecoveringCoreTermWatcher(core.getCoreDescriptor(), getCoreContainer()));\n        }\n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      } catch (Exception e) {\n        unregister(coreName, desc, false);\n        throw e;\n      }\n\n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      // the watcher is added to a set so multiple calls of this method will left only one watcher\n      zkStateReader.registerCollectionStateWatcher(cloudDesc.getCollectionName(),\n          new UnloadCoreOnDeletedWatcher(coreZkNodeName, shardId, desc.getName()));\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","bugFix":null,"bugIntro":["5ad9c35f926b4bf8da0336d1300efc709c8d5a56"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"64b136610bf3772c70e2d86fa4c913425cedbca5","date":1580107100,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      final String shardId = cloudDesc.getShardId();\n      final String coreZkNodeName = cloudDesc.getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n\n      // check replica's existence in clusterstate first\n      try {\n        zkStateReader.waitForState(collection, Overseer.isLegacy(zkStateReader) ? 60000 : 100,\n            TimeUnit.MILLISECONDS, (collectionState) -> getReplicaOrNull(collectionState, shardId, coreZkNodeName) != null);\n      } catch (TimeoutException e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Error registering SolrCore, timeout waiting for replica present in clusterstate\");\n      }\n      Replica replica = getReplicaOrNull(zkStateReader.getClusterState().getCollectionOrNull(collection), shardId, coreZkNodeName);\n      if (replica == null) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Error registering SolrCore, replica is removed from clusterstate\");\n      }\n\n\n      if (replica.getType() != Type.PULL) {\n        getCollectionTerms(collection).register(cloudDesc.getShardId(), coreZkNodeName);\n      }\n\n      ZkShardTerms shardTerms = getShardTerms(collection, cloudDesc.getShardId());\n\n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, collection, shardId);\n\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        if (replica.getType() != Type.PULL) {\n          joinElection(desc, afterExpiration, joinAtHead);\n        } else if (replica.getType() == Type.PULL) {\n          if (joinAtHead) {\n            log.warn(\"Replica {} was designated as preferred leader but it's type is {}, It won't join election\", coreZkNodeName, Type.PULL);\n          }\n          log.debug(\"Replica {} skipping election because it's type is {}\", coreZkNodeName, Type.PULL);\n          startReplicationFromLeader(coreName, false);\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n\n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      assert !(isLeader && replica.getType() == Type.PULL) : \"Pull replica became leader!\";\n\n      try (SolrCore core = cc.getCore(desc.getName())) {\n\n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n\n        if (core == null) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"SolrCore is no longer available to register\");\n        }\n\n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        boolean isTlogReplicaAndNotLeader = replica.getType() == Replica.Type.TLOG && !isLeader;\n        if (isTlogReplicaAndNotLeader) {\n          String commitVersion = ReplicateFromLeader.getCommitVersion(core);\n          if (commitVersion != null) {\n            ulog.copyOverOldUpdates(Long.parseLong(commitVersion));\n          }\n        }\n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null && !isTlogReplicaAndNotLeader) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getCollection(collection).getSlice(shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, shardId, core, cc, afterExpiration);\n        if (!didRecovery) {\n          if (isTlogReplicaAndNotLeader) {\n            startReplicationFromLeader(coreName, true);\n          }\n          publish(desc, Replica.State.ACTIVE);\n        }\n\n        if (replica.getType() != Type.PULL) {\n          // the watcher is added to a set so multiple calls of this method will left only one watcher\n          shardTerms.addListener(new RecoveringCoreTermWatcher(core.getCoreDescriptor(), getCoreContainer()));\n        }\n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      } catch (Exception e) {\n        unregister(coreName, desc, false);\n        throw e;\n      }\n\n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      // the watcher is added to a set so multiple calls of this method will left only one watcher\n      zkStateReader.registerDocCollectionWatcher(cloudDesc.getCollectionName(),\n          new UnloadCoreOnDeletedWatcher(coreZkNodeName, shardId, desc.getName()));\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      final String shardId = cloudDesc.getShardId();\n      final String coreZkNodeName = cloudDesc.getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n\n      // check replica's existence in clusterstate first\n      try {\n        zkStateReader.waitForState(collection, Overseer.isLegacy(zkStateReader) ? 60000 : 100,\n            TimeUnit.MILLISECONDS, (collectionState) -> getReplicaOrNull(collectionState, shardId, coreZkNodeName) != null);\n      } catch (TimeoutException e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Error registering SolrCore, timeout waiting for replica present in clusterstate\");\n      }\n      Replica replica = getReplicaOrNull(zkStateReader.getClusterState().getCollectionOrNull(collection), shardId, coreZkNodeName);\n      if (replica == null) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Error registering SolrCore, replica is removed from clusterstate\");\n      }\n\n      ZkShardTerms shardTerms = getShardTerms(collection, cloudDesc.getShardId());\n\n      if (replica.getType() != Type.PULL) {\n        shardTerms.registerTerm(coreZkNodeName);\n      }\n\n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, collection, shardId);\n\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        if (replica.getType() != Type.PULL) {\n          joinElection(desc, afterExpiration, joinAtHead);\n        } else if (replica.getType() == Type.PULL) {\n          if (joinAtHead) {\n            log.warn(\"Replica {} was designated as preferred leader but it's type is {}, It won't join election\", coreZkNodeName, Type.PULL);\n          }\n          log.debug(\"Replica {} skipping election because it's type is {}\", coreZkNodeName, Type.PULL);\n          startReplicationFromLeader(coreName, false);\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n\n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      assert !(isLeader && replica.getType() == Type.PULL) : \"Pull replica became leader!\";\n\n      try (SolrCore core = cc.getCore(desc.getName())) {\n\n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n\n        if (core == null) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"SolrCore is no longer available to register\");\n        }\n\n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        boolean isTlogReplicaAndNotLeader = replica.getType() == Replica.Type.TLOG && !isLeader;\n        if (isTlogReplicaAndNotLeader) {\n          String commitVersion = ReplicateFromLeader.getCommitVersion(core);\n          if (commitVersion != null) {\n            ulog.copyOverOldUpdates(Long.parseLong(commitVersion));\n          }\n        }\n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null && !isTlogReplicaAndNotLeader) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getCollection(collection).getSlice(shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, shardId, core, cc, afterExpiration);\n        if (!didRecovery) {\n          if (isTlogReplicaAndNotLeader) {\n            startReplicationFromLeader(coreName, true);\n          }\n          publish(desc, Replica.State.ACTIVE);\n        }\n\n        if (replica.getType() != Type.PULL) {\n          // the watcher is added to a set so multiple calls of this method will left only one watcher\n          shardTerms.addListener(new RecoveringCoreTermWatcher(core.getCoreDescriptor(), getCoreContainer()));\n        }\n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      } catch (Exception e) {\n        unregister(coreName, desc, false);\n        throw e;\n      }\n\n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      // the watcher is added to a set so multiple calls of this method will left only one watcher\n      zkStateReader.registerDocCollectionWatcher(cloudDesc.getCollectionName(),\n          new UnloadCoreOnDeletedWatcher(coreZkNodeName, shardId, desc.getName()));\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ed5005b977107bba28c700351216f1595e7abe4f","date":1585964712,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    MDCLoggingContext.setCoreDescriptor(cc, desc);\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      final String shardId = cloudDesc.getShardId();\n      final String coreZkNodeName = cloudDesc.getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n\n      // check replica's existence in clusterstate first\n      try {\n        zkStateReader.waitForState(collection, Overseer.isLegacy(zkStateReader) ? 60000 : 100,\n            TimeUnit.MILLISECONDS, (collectionState) -> getReplicaOrNull(collectionState, shardId, coreZkNodeName) != null);\n      } catch (TimeoutException e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Error registering SolrCore, timeout waiting for replica present in clusterstate\");\n      }\n      Replica replica = getReplicaOrNull(zkStateReader.getClusterState().getCollectionOrNull(collection), shardId, coreZkNodeName);\n      if (replica == null) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Error registering SolrCore, replica is removed from clusterstate\");\n      }\n\n\n      if (replica.getType() != Type.PULL) {\n        getCollectionTerms(collection).register(cloudDesc.getShardId(), coreZkNodeName);\n      }\n\n      ZkShardTerms shardTerms = getShardTerms(collection, cloudDesc.getShardId());\n\n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, collection, shardId);\n\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        if (replica.getType() != Type.PULL) {\n          joinElection(desc, afterExpiration, joinAtHead);\n        } else if (replica.getType() == Type.PULL) {\n          if (joinAtHead) {\n            log.warn(\"Replica {} was designated as preferred leader but it's type is {}, It won't join election\", coreZkNodeName, Type.PULL);\n          }\n          log.debug(\"Replica {} skipping election because it's type is {}\", coreZkNodeName, Type.PULL);\n          startReplicationFromLeader(coreName, false);\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n\n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      assert !(isLeader && replica.getType() == Type.PULL) : \"Pull replica became leader!\";\n\n      try (SolrCore core = cc.getCore(desc.getName())) {\n\n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n\n        if (core == null) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"SolrCore is no longer available to register\");\n        }\n\n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        boolean isTlogReplicaAndNotLeader = replica.getType() == Replica.Type.TLOG && !isLeader;\n        if (isTlogReplicaAndNotLeader) {\n          String commitVersion = ReplicateFromLeader.getCommitVersion(core);\n          if (commitVersion != null) {\n            ulog.copyOverOldUpdates(Long.parseLong(commitVersion));\n          }\n        }\n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null && !isTlogReplicaAndNotLeader) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getCollection(collection).getSlice(shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, shardId, core, cc, afterExpiration);\n        if (!didRecovery) {\n          if (isTlogReplicaAndNotLeader) {\n            startReplicationFromLeader(coreName, true);\n          }\n          publish(desc, Replica.State.ACTIVE);\n        }\n\n        if (replica.getType() != Type.PULL) {\n          // the watcher is added to a set so multiple calls of this method will left only one watcher\n          shardTerms.addListener(new RecoveringCoreTermWatcher(core.getCoreDescriptor(), getCoreContainer()));\n        }\n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      } catch (Exception e) {\n        unregister(coreName, desc, false);\n        throw e;\n      }\n\n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      // the watcher is added to a set so multiple calls of this method will left only one watcher\n      zkStateReader.registerDocCollectionWatcher(cloudDesc.getCollectionName(),\n          new UnloadCoreOnDeletedWatcher(coreZkNodeName, shardId, desc.getName()));\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    try (SolrCore core = cc.getCore(desc.getName())) {\n      MDCLoggingContext.setCore(core);\n    }\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      final String shardId = cloudDesc.getShardId();\n      final String coreZkNodeName = cloudDesc.getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n\n      // check replica's existence in clusterstate first\n      try {\n        zkStateReader.waitForState(collection, Overseer.isLegacy(zkStateReader) ? 60000 : 100,\n            TimeUnit.MILLISECONDS, (collectionState) -> getReplicaOrNull(collectionState, shardId, coreZkNodeName) != null);\n      } catch (TimeoutException e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Error registering SolrCore, timeout waiting for replica present in clusterstate\");\n      }\n      Replica replica = getReplicaOrNull(zkStateReader.getClusterState().getCollectionOrNull(collection), shardId, coreZkNodeName);\n      if (replica == null) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Error registering SolrCore, replica is removed from clusterstate\");\n      }\n\n\n      if (replica.getType() != Type.PULL) {\n        getCollectionTerms(collection).register(cloudDesc.getShardId(), coreZkNodeName);\n      }\n\n      ZkShardTerms shardTerms = getShardTerms(collection, cloudDesc.getShardId());\n\n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, collection, shardId);\n\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        if (replica.getType() != Type.PULL) {\n          joinElection(desc, afterExpiration, joinAtHead);\n        } else if (replica.getType() == Type.PULL) {\n          if (joinAtHead) {\n            log.warn(\"Replica {} was designated as preferred leader but it's type is {}, It won't join election\", coreZkNodeName, Type.PULL);\n          }\n          log.debug(\"Replica {} skipping election because it's type is {}\", coreZkNodeName, Type.PULL);\n          startReplicationFromLeader(coreName, false);\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n\n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      assert !(isLeader && replica.getType() == Type.PULL) : \"Pull replica became leader!\";\n\n      try (SolrCore core = cc.getCore(desc.getName())) {\n\n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n\n        if (core == null) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"SolrCore is no longer available to register\");\n        }\n\n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        boolean isTlogReplicaAndNotLeader = replica.getType() == Replica.Type.TLOG && !isLeader;\n        if (isTlogReplicaAndNotLeader) {\n          String commitVersion = ReplicateFromLeader.getCommitVersion(core);\n          if (commitVersion != null) {\n            ulog.copyOverOldUpdates(Long.parseLong(commitVersion));\n          }\n        }\n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null && !isTlogReplicaAndNotLeader) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getCollection(collection).getSlice(shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, shardId, core, cc, afterExpiration);\n        if (!didRecovery) {\n          if (isTlogReplicaAndNotLeader) {\n            startReplicationFromLeader(coreName, true);\n          }\n          publish(desc, Replica.State.ACTIVE);\n        }\n\n        if (replica.getType() != Type.PULL) {\n          // the watcher is added to a set so multiple calls of this method will left only one watcher\n          shardTerms.addListener(new RecoveringCoreTermWatcher(core.getCoreDescriptor(), getCoreContainer()));\n        }\n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      } catch (Exception e) {\n        unregister(coreName, desc, false);\n        throw e;\n      }\n\n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      // the watcher is added to a set so multiple calls of this method will left only one watcher\n      zkStateReader.registerDocCollectionWatcher(cloudDesc.getCollectionName(),\n          new UnloadCoreOnDeletedWatcher(coreZkNodeName, shardId, desc.getName()));\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ad4957cde742defe6db19689abdc267c5d948066","date":1587990850,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    MDCLoggingContext.setCoreDescriptor(cc, desc);\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      final String shardId = cloudDesc.getShardId();\n      final String coreZkNodeName = cloudDesc.getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n\n      // check replica's existence in clusterstate first\n      try {\n        zkStateReader.waitForState(collection, Overseer.isLegacy(zkStateReader) ? 60000 : 100,\n            TimeUnit.MILLISECONDS, (collectionState) -> getReplicaOrNull(collectionState, shardId, coreZkNodeName) != null);\n      } catch (TimeoutException e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Error registering SolrCore, timeout waiting for replica present in clusterstate\");\n      }\n      Replica replica = getReplicaOrNull(zkStateReader.getClusterState().getCollectionOrNull(collection), shardId, coreZkNodeName);\n      if (replica == null) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Error registering SolrCore, replica is removed from clusterstate\");\n      }\n\n\n      if (replica.getType() != Type.PULL) {\n        getCollectionTerms(collection).register(cloudDesc.getShardId(), coreZkNodeName);\n      }\n\n      ZkShardTerms shardTerms = getShardTerms(collection, cloudDesc.getShardId());\n\n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, collection, shardId);\n\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        if (replica.getType() != Type.PULL) {\n          joinElection(desc, afterExpiration, joinAtHead);\n        } else if (replica.getType() == Type.PULL) {\n          if (joinAtHead) {\n            log.warn(\"Replica {} was designated as preferred leader but it's type is {}, It won't join election\", coreZkNodeName, Type.PULL);\n          }\n          log.debug(\"Replica {} skipping election because it's type is {}\", coreZkNodeName, Type.PULL);\n          startReplicationFromLeader(coreName, false);\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n\n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are {} and leader is {}\", ourUrl, leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      assert !(isLeader && replica.getType() == Type.PULL) : \"Pull replica became leader!\";\n\n      try (SolrCore core = cc.getCore(desc.getName())) {\n\n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n\n        if (core == null) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"SolrCore is no longer available to register\");\n        }\n\n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        boolean isTlogReplicaAndNotLeader = replica.getType() == Replica.Type.TLOG && !isLeader;\n        if (isTlogReplicaAndNotLeader) {\n          String commitVersion = ReplicateFromLeader.getCommitVersion(core);\n          if (commitVersion != null) {\n            ulog.copyOverOldUpdates(Long.parseLong(commitVersion));\n          }\n        }\n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null && !isTlogReplicaAndNotLeader) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getCollection(collection).getSlice(shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for {} during startup... NOTE: This can take a while.\", ourUrl);\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              if (log.isDebugEnabled()) {\n                log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n              }\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, shardId, core, cc, afterExpiration);\n        if (!didRecovery) {\n          if (isTlogReplicaAndNotLeader) {\n            startReplicationFromLeader(coreName, true);\n          }\n          publish(desc, Replica.State.ACTIVE);\n        }\n\n        if (replica.getType() != Type.PULL) {\n          // the watcher is added to a set so multiple calls of this method will left only one watcher\n          shardTerms.addListener(new RecoveringCoreTermWatcher(core.getCoreDescriptor(), getCoreContainer()));\n        }\n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      } catch (Exception e) {\n        unregister(coreName, desc, false);\n        throw e;\n      }\n\n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      // the watcher is added to a set so multiple calls of this method will left only one watcher\n      zkStateReader.registerDocCollectionWatcher(cloudDesc.getCollectionName(),\n          new UnloadCoreOnDeletedWatcher(coreZkNodeName, shardId, desc.getName()));\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    MDCLoggingContext.setCoreDescriptor(cc, desc);\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      final String shardId = cloudDesc.getShardId();\n      final String coreZkNodeName = cloudDesc.getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n\n      // check replica's existence in clusterstate first\n      try {\n        zkStateReader.waitForState(collection, Overseer.isLegacy(zkStateReader) ? 60000 : 100,\n            TimeUnit.MILLISECONDS, (collectionState) -> getReplicaOrNull(collectionState, shardId, coreZkNodeName) != null);\n      } catch (TimeoutException e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Error registering SolrCore, timeout waiting for replica present in clusterstate\");\n      }\n      Replica replica = getReplicaOrNull(zkStateReader.getClusterState().getCollectionOrNull(collection), shardId, coreZkNodeName);\n      if (replica == null) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Error registering SolrCore, replica is removed from clusterstate\");\n      }\n\n\n      if (replica.getType() != Type.PULL) {\n        getCollectionTerms(collection).register(cloudDesc.getShardId(), coreZkNodeName);\n      }\n\n      ZkShardTerms shardTerms = getShardTerms(collection, cloudDesc.getShardId());\n\n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, collection, shardId);\n\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        if (replica.getType() != Type.PULL) {\n          joinElection(desc, afterExpiration, joinAtHead);\n        } else if (replica.getType() == Type.PULL) {\n          if (joinAtHead) {\n            log.warn(\"Replica {} was designated as preferred leader but it's type is {}, It won't join election\", coreZkNodeName, Type.PULL);\n          }\n          log.debug(\"Replica {} skipping election because it's type is {}\", coreZkNodeName, Type.PULL);\n          startReplicationFromLeader(coreName, false);\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n\n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are \" + ourUrl + \" and leader is \" + leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      assert !(isLeader && replica.getType() == Type.PULL) : \"Pull replica became leader!\";\n\n      try (SolrCore core = cc.getCore(desc.getName())) {\n\n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n\n        if (core == null) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"SolrCore is no longer available to register\");\n        }\n\n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        boolean isTlogReplicaAndNotLeader = replica.getType() == Replica.Type.TLOG && !isLeader;\n        if (isTlogReplicaAndNotLeader) {\n          String commitVersion = ReplicateFromLeader.getCommitVersion(core);\n          if (commitVersion != null) {\n            ulog.copyOverOldUpdates(Long.parseLong(commitVersion));\n          }\n        }\n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null && !isTlogReplicaAndNotLeader) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getCollection(collection).getSlice(shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for \" + ourUrl + \" during startup... NOTE: This can take a while.\");\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, shardId, core, cc, afterExpiration);\n        if (!didRecovery) {\n          if (isTlogReplicaAndNotLeader) {\n            startReplicationFromLeader(coreName, true);\n          }\n          publish(desc, Replica.State.ACTIVE);\n        }\n\n        if (replica.getType() != Type.PULL) {\n          // the watcher is added to a set so multiple calls of this method will left only one watcher\n          shardTerms.addListener(new RecoveringCoreTermWatcher(core.getCoreDescriptor(), getCoreContainer()));\n        }\n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      } catch (Exception e) {\n        unregister(coreName, desc, false);\n        throw e;\n      }\n\n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      // the watcher is added to a set so multiple calls of this method will left only one watcher\n      zkStateReader.registerDocCollectionWatcher(cloudDesc.getCollectionName(),\n          new UnloadCoreOnDeletedWatcher(coreZkNodeName, shardId, desc.getName()));\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5ad9c35f926b4bf8da0336d1300efc709c8d5a56","date":1591729157,"type":3,"author":"murblanc","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#register(String,CoreDescriptor,boolean,boolean,boolean).mjava","sourceNew":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    MDCLoggingContext.setCoreDescriptor(cc, desc);\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      final String shardId = cloudDesc.getShardId();\n      final String coreZkNodeName = cloudDesc.getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n\n      // check replica's existence in clusterstate first\n      try {\n        zkStateReader.waitForState(collection, 100, TimeUnit.MILLISECONDS,\n            (collectionState) -> getReplicaOrNull(collectionState, shardId, coreZkNodeName) != null);\n      } catch (TimeoutException e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Error registering SolrCore, timeout waiting for replica present in clusterstate\");\n      }\n      Replica replica = getReplicaOrNull(zkStateReader.getClusterState().getCollectionOrNull(collection), shardId, coreZkNodeName);\n      if (replica == null) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Error registering SolrCore, replica is removed from clusterstate\");\n      }\n\n\n      if (replica.getType() != Type.PULL) {\n        getCollectionTerms(collection).register(cloudDesc.getShardId(), coreZkNodeName);\n      }\n\n      ZkShardTerms shardTerms = getShardTerms(collection, cloudDesc.getShardId());\n\n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, collection, shardId);\n\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        if (replica.getType() != Type.PULL) {\n          joinElection(desc, afterExpiration, joinAtHead);\n        } else if (replica.getType() == Type.PULL) {\n          if (joinAtHead) {\n            log.warn(\"Replica {} was designated as preferred leader but it's type is {}, It won't join election\", coreZkNodeName, Type.PULL);\n          }\n          log.debug(\"Replica {} skipping election because it's type is {}\", coreZkNodeName, Type.PULL);\n          startReplicationFromLeader(coreName, false);\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n\n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are {} and leader is {}\", ourUrl, leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      assert !(isLeader && replica.getType() == Type.PULL) : \"Pull replica became leader!\";\n\n      try (SolrCore core = cc.getCore(desc.getName())) {\n\n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n\n        if (core == null) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"SolrCore is no longer available to register\");\n        }\n\n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        boolean isTlogReplicaAndNotLeader = replica.getType() == Replica.Type.TLOG && !isLeader;\n        if (isTlogReplicaAndNotLeader) {\n          String commitVersion = ReplicateFromLeader.getCommitVersion(core);\n          if (commitVersion != null) {\n            ulog.copyOverOldUpdates(Long.parseLong(commitVersion));\n          }\n        }\n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null && !isTlogReplicaAndNotLeader) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getCollection(collection).getSlice(shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for {} during startup... NOTE: This can take a while.\", ourUrl);\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              if (log.isDebugEnabled()) {\n                log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n              }\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, shardId, core, cc, afterExpiration);\n        if (!didRecovery) {\n          if (isTlogReplicaAndNotLeader) {\n            startReplicationFromLeader(coreName, true);\n          }\n          publish(desc, Replica.State.ACTIVE);\n        }\n\n        if (replica.getType() != Type.PULL) {\n          // the watcher is added to a set so multiple calls of this method will left only one watcher\n          shardTerms.addListener(new RecoveringCoreTermWatcher(core.getCoreDescriptor(), getCoreContainer()));\n        }\n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      } catch (Exception e) {\n        unregister(coreName, desc, false);\n        throw e;\n      }\n\n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      // the watcher is added to a set so multiple calls of this method will left only one watcher\n      zkStateReader.registerDocCollectionWatcher(cloudDesc.getCollectionName(),\n          new UnloadCoreOnDeletedWatcher(coreZkNodeName, shardId, desc.getName()));\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","sourceOld":"  /**\n   * Register shard with ZooKeeper.\n   *\n   * @return the shardId for the SolrCore\n   */\n  public String register(String coreName, final CoreDescriptor desc, boolean recoverReloadedCores,\n                         boolean afterExpiration, boolean skipRecovery) throws Exception {\n    MDCLoggingContext.setCoreDescriptor(cc, desc);\n    try {\n      // pre register has published our down state\n      final String baseUrl = getBaseUrl();\n      final CloudDescriptor cloudDesc = desc.getCloudDescriptor();\n      final String collection = cloudDesc.getCollectionName();\n      final String shardId = cloudDesc.getShardId();\n      final String coreZkNodeName = cloudDesc.getCoreNodeName();\n      assert coreZkNodeName != null : \"we should have a coreNodeName by now\";\n\n      // check replica's existence in clusterstate first\n      try {\n        zkStateReader.waitForState(collection, Overseer.isLegacy(zkStateReader) ? 60000 : 100,\n            TimeUnit.MILLISECONDS, (collectionState) -> getReplicaOrNull(collectionState, shardId, coreZkNodeName) != null);\n      } catch (TimeoutException e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Error registering SolrCore, timeout waiting for replica present in clusterstate\");\n      }\n      Replica replica = getReplicaOrNull(zkStateReader.getClusterState().getCollectionOrNull(collection), shardId, coreZkNodeName);\n      if (replica == null) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Error registering SolrCore, replica is removed from clusterstate\");\n      }\n\n\n      if (replica.getType() != Type.PULL) {\n        getCollectionTerms(collection).register(cloudDesc.getShardId(), coreZkNodeName);\n      }\n\n      ZkShardTerms shardTerms = getShardTerms(collection, cloudDesc.getShardId());\n\n      log.debug(\"Register replica - core:{} address:{} collection:{} shard:{}\",\n          coreName, baseUrl, collection, shardId);\n\n      try {\n        // If we're a preferred leader, insert ourselves at the head of the queue\n        boolean joinAtHead = replica.getBool(SliceMutator.PREFERRED_LEADER_PROP, false);\n        if (replica.getType() != Type.PULL) {\n          joinElection(desc, afterExpiration, joinAtHead);\n        } else if (replica.getType() == Type.PULL) {\n          if (joinAtHead) {\n            log.warn(\"Replica {} was designated as preferred leader but it's type is {}, It won't join election\", coreZkNodeName, Type.PULL);\n          }\n          log.debug(\"Replica {} skipping election because it's type is {}\", coreZkNodeName, Type.PULL);\n          startReplicationFromLeader(coreName, false);\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      } catch (KeeperException | IOException e) {\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      // in this case, we want to wait for the leader as long as the leader might\n      // wait for a vote, at least - but also long enough that a large cluster has\n      // time to get its act together\n      String leaderUrl = getLeader(cloudDesc, leaderVoteWait + 600000);\n\n      String ourUrl = ZkCoreNodeProps.getCoreUrl(baseUrl, coreName);\n      log.debug(\"We are {} and leader is {}\", ourUrl, leaderUrl);\n      boolean isLeader = leaderUrl.equals(ourUrl);\n      assert !(isLeader && replica.getType() == Type.PULL) : \"Pull replica became leader!\";\n\n      try (SolrCore core = cc.getCore(desc.getName())) {\n\n        // recover from local transaction log and wait for it to complete before\n        // going active\n        // TODO: should this be moved to another thread? To recoveryStrat?\n        // TODO: should this actually be done earlier, before (or as part of)\n        // leader election perhaps?\n\n        if (core == null) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"SolrCore is no longer available to register\");\n        }\n\n        UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n        boolean isTlogReplicaAndNotLeader = replica.getType() == Replica.Type.TLOG && !isLeader;\n        if (isTlogReplicaAndNotLeader) {\n          String commitVersion = ReplicateFromLeader.getCommitVersion(core);\n          if (commitVersion != null) {\n            ulog.copyOverOldUpdates(Long.parseLong(commitVersion));\n          }\n        }\n        // we will call register again after zk expiration and on reload\n        if (!afterExpiration && !core.isReloaded() && ulog != null && !isTlogReplicaAndNotLeader) {\n          // disable recovery in case shard is in construction state (for shard splits)\n          Slice slice = getClusterState().getCollection(collection).getSlice(shardId);\n          if (slice.getState() != Slice.State.CONSTRUCTION || !isLeader) {\n            Future<UpdateLog.RecoveryInfo> recoveryFuture = core.getUpdateHandler().getUpdateLog().recoverFromLog();\n            if (recoveryFuture != null) {\n              log.info(\"Replaying tlog for {} during startup... NOTE: This can take a while.\", ourUrl);\n              recoveryFuture.get(); // NOTE: this could potentially block for\n              // minutes or more!\n              // TODO: public as recovering in the mean time?\n              // TODO: in the future we could do peersync in parallel with recoverFromLog\n            } else {\n              if (log.isDebugEnabled()) {\n                log.debug(\"No LogReplay needed for core={} baseURL={}\", core.getName(), baseUrl);\n              }\n            }\n          }\n        }\n        boolean didRecovery\n            = checkRecovery(recoverReloadedCores, isLeader, skipRecovery, collection, coreZkNodeName, shardId, core, cc, afterExpiration);\n        if (!didRecovery) {\n          if (isTlogReplicaAndNotLeader) {\n            startReplicationFromLeader(coreName, true);\n          }\n          publish(desc, Replica.State.ACTIVE);\n        }\n\n        if (replica.getType() != Type.PULL) {\n          // the watcher is added to a set so multiple calls of this method will left only one watcher\n          shardTerms.addListener(new RecoveringCoreTermWatcher(core.getCoreDescriptor(), getCoreContainer()));\n        }\n        core.getCoreDescriptor().getCloudDescriptor().setHasRegistered(true);\n      } catch (Exception e) {\n        unregister(coreName, desc, false);\n        throw e;\n      }\n\n      // make sure we have an update cluster state right away\n      zkStateReader.forceUpdateCollection(collection);\n      // the watcher is added to a set so multiple calls of this method will left only one watcher\n      zkStateReader.registerDocCollectionWatcher(cloudDesc.getCollectionName(),\n          new UnloadCoreOnDeletedWatcher(coreZkNodeName, shardId, desc.getName()));\n      return shardId;\n    } finally {\n      MDCLoggingContext.clear();\n    }\n  }\n\n","bugFix":["28ba172425e443e0f08a49de6d73586c418d7251","7b366e7dd3172289251a86be96031af4002cd19c"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"04ecf884544ff74add5faa452748f160c4af904b":["104a3f62ee393d48b5596de76ed4d9a4e0ea6de7"],"6815b5b5d6334b2245dd7be2f8b6cca949bf7f43":["203e3fcf513c02ee2c07015f2ce277e26dc60907","67144a5cdd5ecbe2f8ca846956214f360fec12f5"],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["b6d72c72ee67b4aa8bc8bdd91bae9069b04fc180"],"344b0840364d990b29b97467bfcc766ff8325d11":["61c45e99cf6676da48f19d7511c73712ad39402b"],"ed5005b977107bba28c700351216f1595e7abe4f":["64b136610bf3772c70e2d86fa4c913425cedbca5"],"ad4957cde742defe6db19689abdc267c5d948066":["ed5005b977107bba28c700351216f1595e7abe4f"],"7b366e7dd3172289251a86be96031af4002cd19c":["0db83f1bb855a4ac824c9a2a8e1ee9b29a039c15"],"84f20f331d8001864545c7021812d8c6509c7593":["04ecf884544ff74add5faa452748f160c4af904b"],"b6d72c72ee67b4aa8bc8bdd91bae9069b04fc180":["28ba172425e443e0f08a49de6d73586c418d7251"],"8c30d22eaf1287a88a402fba9d8b7b9d20d6ef94":["84f20f331d8001864545c7021812d8c6509c7593"],"e9017cf144952056066919f1ebc7897ff9bd71b1":["ab68488225b6a6c357dda72ed11dedca9914a192","61c45e99cf6676da48f19d7511c73712ad39402b"],"104a3f62ee393d48b5596de76ed4d9a4e0ea6de7":["344b0840364d990b29b97467bfcc766ff8325d11","f09dfe4eae83c6f3ce87c6267cb774e4da0a2d73"],"3a7809d1d753b67f48b1a706e17034bf8b624ea3":["7a23cf16c8fa265dc0a564adcabb55e3f054e0ac","f09dfe4eae83c6f3ce87c6267cb774e4da0a2d73"],"f09dfe4eae83c6f3ce87c6267cb774e4da0a2d73":["344b0840364d990b29b97467bfcc766ff8325d11"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"67144a5cdd5ecbe2f8ca846956214f360fec12f5":["203e3fcf513c02ee2c07015f2ce277e26dc60907"],"fbedfa79ef95dc2b5b49f7d54d80e0b47867f9b4":["664ff2b928393480d9655010aa700656b0fcade0","61c45e99cf6676da48f19d7511c73712ad39402b"],"64b136610bf3772c70e2d86fa4c913425cedbca5":["7b366e7dd3172289251a86be96031af4002cd19c"],"be320990bdc77e643388fa801e75017f19289c42":["d528fd7ae22865015b756e0a03832e2051de2a9c"],"ab68488225b6a6c357dda72ed11dedca9914a192":["d528fd7ae22865015b756e0a03832e2051de2a9c","f996f8177b9204bdc92f7164460c6cefad9ac99a"],"46df9d682d3407bf67ce2946c9f9267376809bc2":["8c30d22eaf1287a88a402fba9d8b7b9d20d6ef94"],"664ff2b928393480d9655010aa700656b0fcade0":["e9017cf144952056066919f1ebc7897ff9bd71b1","ab68488225b6a6c357dda72ed11dedca9914a192"],"5ad9c35f926b4bf8da0336d1300efc709c8d5a56":["ad4957cde742defe6db19689abdc267c5d948066"],"61c45e99cf6676da48f19d7511c73712ad39402b":["be320990bdc77e643388fa801e75017f19289c42"],"203e3fcf513c02ee2c07015f2ce277e26dc60907":["8c30d22eaf1287a88a402fba9d8b7b9d20d6ef94","46df9d682d3407bf67ce2946c9f9267376809bc2"],"d528fd7ae22865015b756e0a03832e2051de2a9c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","d528fd7ae22865015b756e0a03832e2051de2a9c"],"7a23cf16c8fa265dc0a564adcabb55e3f054e0ac":["fbedfa79ef95dc2b5b49f7d54d80e0b47867f9b4","344b0840364d990b29b97467bfcc766ff8325d11"],"f996f8177b9204bdc92f7164460c6cefad9ac99a":["d528fd7ae22865015b756e0a03832e2051de2a9c"],"6240b74b884c5587f2a4062dd27d6c32bf228889":["3a7809d1d753b67f48b1a706e17034bf8b624ea3","04ecf884544ff74add5faa452748f160c4af904b"],"0db83f1bb855a4ac824c9a2a8e1ee9b29a039c15":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"28ba172425e443e0f08a49de6d73586c418d7251":["6815b5b5d6334b2245dd7be2f8b6cca949bf7f43"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["5ad9c35f926b4bf8da0336d1300efc709c8d5a56"]},"commit2Childs":{"04ecf884544ff74add5faa452748f160c4af904b":["84f20f331d8001864545c7021812d8c6509c7593","6240b74b884c5587f2a4062dd27d6c32bf228889"],"6815b5b5d6334b2245dd7be2f8b6cca949bf7f43":["28ba172425e443e0f08a49de6d73586c418d7251"],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["0db83f1bb855a4ac824c9a2a8e1ee9b29a039c15"],"344b0840364d990b29b97467bfcc766ff8325d11":["104a3f62ee393d48b5596de76ed4d9a4e0ea6de7","f09dfe4eae83c6f3ce87c6267cb774e4da0a2d73","7a23cf16c8fa265dc0a564adcabb55e3f054e0ac"],"ed5005b977107bba28c700351216f1595e7abe4f":["ad4957cde742defe6db19689abdc267c5d948066"],"ad4957cde742defe6db19689abdc267c5d948066":["5ad9c35f926b4bf8da0336d1300efc709c8d5a56"],"7b366e7dd3172289251a86be96031af4002cd19c":["64b136610bf3772c70e2d86fa4c913425cedbca5"],"84f20f331d8001864545c7021812d8c6509c7593":["8c30d22eaf1287a88a402fba9d8b7b9d20d6ef94"],"b6d72c72ee67b4aa8bc8bdd91bae9069b04fc180":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"8c30d22eaf1287a88a402fba9d8b7b9d20d6ef94":["46df9d682d3407bf67ce2946c9f9267376809bc2","203e3fcf513c02ee2c07015f2ce277e26dc60907"],"e9017cf144952056066919f1ebc7897ff9bd71b1":["664ff2b928393480d9655010aa700656b0fcade0"],"104a3f62ee393d48b5596de76ed4d9a4e0ea6de7":["04ecf884544ff74add5faa452748f160c4af904b"],"3a7809d1d753b67f48b1a706e17034bf8b624ea3":["6240b74b884c5587f2a4062dd27d6c32bf228889"],"f09dfe4eae83c6f3ce87c6267cb774e4da0a2d73":["104a3f62ee393d48b5596de76ed4d9a4e0ea6de7","3a7809d1d753b67f48b1a706e17034bf8b624ea3"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["d528fd7ae22865015b756e0a03832e2051de2a9c","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"67144a5cdd5ecbe2f8ca846956214f360fec12f5":["6815b5b5d6334b2245dd7be2f8b6cca949bf7f43"],"fbedfa79ef95dc2b5b49f7d54d80e0b47867f9b4":["7a23cf16c8fa265dc0a564adcabb55e3f054e0ac"],"64b136610bf3772c70e2d86fa4c913425cedbca5":["ed5005b977107bba28c700351216f1595e7abe4f"],"ab68488225b6a6c357dda72ed11dedca9914a192":["e9017cf144952056066919f1ebc7897ff9bd71b1","664ff2b928393480d9655010aa700656b0fcade0"],"be320990bdc77e643388fa801e75017f19289c42":["61c45e99cf6676da48f19d7511c73712ad39402b"],"46df9d682d3407bf67ce2946c9f9267376809bc2":["203e3fcf513c02ee2c07015f2ce277e26dc60907"],"664ff2b928393480d9655010aa700656b0fcade0":["fbedfa79ef95dc2b5b49f7d54d80e0b47867f9b4"],"5ad9c35f926b4bf8da0336d1300efc709c8d5a56":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"61c45e99cf6676da48f19d7511c73712ad39402b":["344b0840364d990b29b97467bfcc766ff8325d11","e9017cf144952056066919f1ebc7897ff9bd71b1","fbedfa79ef95dc2b5b49f7d54d80e0b47867f9b4"],"203e3fcf513c02ee2c07015f2ce277e26dc60907":["6815b5b5d6334b2245dd7be2f8b6cca949bf7f43","67144a5cdd5ecbe2f8ca846956214f360fec12f5"],"d528fd7ae22865015b756e0a03832e2051de2a9c":["be320990bdc77e643388fa801e75017f19289c42","ab68488225b6a6c357dda72ed11dedca9914a192","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","f996f8177b9204bdc92f7164460c6cefad9ac99a"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"7a23cf16c8fa265dc0a564adcabb55e3f054e0ac":["3a7809d1d753b67f48b1a706e17034bf8b624ea3"],"f996f8177b9204bdc92f7164460c6cefad9ac99a":["ab68488225b6a6c357dda72ed11dedca9914a192"],"6240b74b884c5587f2a4062dd27d6c32bf228889":[],"0db83f1bb855a4ac824c9a2a8e1ee9b29a039c15":["7b366e7dd3172289251a86be96031af4002cd19c"],"28ba172425e443e0f08a49de6d73586c418d7251":["b6d72c72ee67b4aa8bc8bdd91bae9069b04fc180"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","6240b74b884c5587f2a4062dd27d6c32bf228889","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}