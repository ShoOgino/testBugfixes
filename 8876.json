{"path":"lucene/facet/src/java/org/apache/lucene/facet/CachedOrdinalsReader.CachedOrds#CachedOrds(OrdinalsSegmentReader,int).mjava","commits":[{"id":"21d36d0db865f7b84026b447bec653469a6e66df","date":1385495602,"type":1,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/facet/src/java/org/apache/lucene/facet/CachedOrdinalsReader.CachedOrds#CachedOrds(OrdinalsSegmentReader,int).mjava","pathOld":"lucene/facet/src/java/org/apache/lucene/facet/simple/CachedOrdinalsReader.CachedOrds#CachedOrds(OrdinalsSegmentReader,int).mjava","sourceNew":"    /**\n     * Creates a new {@link CachedOrds} from the {@link BinaryDocValues}.\n     * Assumes that the {@link BinaryDocValues} is not {@code null}.\n     */\n    public CachedOrds(OrdinalsSegmentReader source, int maxDoc) throws IOException {\n      final BytesRef buf = new BytesRef();\n\n      offsets = new int[maxDoc + 1];\n      int[] ords = new int[maxDoc]; // let's assume one ordinal per-document as an initial size\n\n      // this aggregator is limited to Integer.MAX_VALUE total ordinals.\n      long totOrds = 0;\n      final IntsRef values = new IntsRef(32);\n      for (int docID = 0; docID < maxDoc; docID++) {\n        offsets[docID] = (int) totOrds;\n        source.get(docID, values);\n        long nextLength = totOrds + values.length;\n        if (nextLength > ords.length) {\n          if (nextLength > ArrayUtil.MAX_ARRAY_LENGTH) {\n            throw new IllegalStateException(\"too many ordinals (>= \" + nextLength + \") to cache\");\n          }\n          ords = ArrayUtil.grow(ords, (int) nextLength);\n        }\n        System.arraycopy(values.ints, 0, ords, (int) totOrds, values.length);\n        totOrds = nextLength;\n      }\n      offsets[maxDoc] = (int) totOrds;\n      \n      // if ords array is bigger by more than 10% of what we really need, shrink it\n      if ((double) totOrds / ords.length < 0.9) { \n        this.ordinals = new int[(int) totOrds];\n        System.arraycopy(ords, 0, this.ordinals, 0, (int) totOrds);\n      } else {\n        this.ordinals = ords;\n      }\n    }\n\n","sourceOld":"    /**\n     * Creates a new {@link CachedOrds} from the {@link BinaryDocValues}.\n     * Assumes that the {@link BinaryDocValues} is not {@code null}.\n     */\n    public CachedOrds(OrdinalsSegmentReader source, int maxDoc) throws IOException {\n      final BytesRef buf = new BytesRef();\n\n      offsets = new int[maxDoc + 1];\n      int[] ords = new int[maxDoc]; // let's assume one ordinal per-document as an initial size\n\n      // this aggregator is limited to Integer.MAX_VALUE total ordinals.\n      long totOrds = 0;\n      final IntsRef values = new IntsRef(32);\n      for (int docID = 0; docID < maxDoc; docID++) {\n        offsets[docID] = (int) totOrds;\n        source.get(docID, values);\n        long nextLength = totOrds + values.length;\n        if (nextLength > ords.length) {\n          if (nextLength > ArrayUtil.MAX_ARRAY_LENGTH) {\n            throw new IllegalStateException(\"too many ordinals (>= \" + nextLength + \") to cache\");\n          }\n          ords = ArrayUtil.grow(ords, (int) nextLength);\n        }\n        System.arraycopy(values.ints, 0, ords, (int) totOrds, values.length);\n        totOrds = nextLength;\n      }\n      offsets[maxDoc] = (int) totOrds;\n      \n      // if ords array is bigger by more than 10% of what we really need, shrink it\n      if ((double) totOrds / ords.length < 0.9) { \n        this.ordinals = new int[(int) totOrds];\n        System.arraycopy(ords, 0, this.ordinals, 0, (int) totOrds);\n      } else {\n        this.ordinals = ords;\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8a6c8fcce6eb5b976a26c9543c230548f7aa13e1","date":1388472624,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/facet/src/java/org/apache/lucene/facet/CachedOrdinalsReader.CachedOrds#CachedOrds(OrdinalsSegmentReader,int).mjava","pathOld":"lucene/facet/src/java/org/apache/lucene/facet/CachedOrdinalsReader.CachedOrds#CachedOrds(OrdinalsSegmentReader,int).mjava","sourceNew":"    /**\n     * Creates a new {@link CachedOrds} from the {@link BinaryDocValues}.\n     * Assumes that the {@link BinaryDocValues} is not {@code null}.\n     */\n    public CachedOrds(OrdinalsSegmentReader source, int maxDoc) throws IOException {\n      offsets = new int[maxDoc + 1];\n      int[] ords = new int[maxDoc]; // let's assume one ordinal per-document as an initial size\n\n      // this aggregator is limited to Integer.MAX_VALUE total ordinals.\n      long totOrds = 0;\n      final IntsRef values = new IntsRef(32);\n      for (int docID = 0; docID < maxDoc; docID++) {\n        offsets[docID] = (int) totOrds;\n        source.get(docID, values);\n        long nextLength = totOrds + values.length;\n        if (nextLength > ords.length) {\n          if (nextLength > ArrayUtil.MAX_ARRAY_LENGTH) {\n            throw new IllegalStateException(\"too many ordinals (>= \" + nextLength + \") to cache\");\n          }\n          ords = ArrayUtil.grow(ords, (int) nextLength);\n        }\n        System.arraycopy(values.ints, 0, ords, (int) totOrds, values.length);\n        totOrds = nextLength;\n      }\n      offsets[maxDoc] = (int) totOrds;\n      \n      // if ords array is bigger by more than 10% of what we really need, shrink it\n      if ((double) totOrds / ords.length < 0.9) { \n        this.ordinals = new int[(int) totOrds];\n        System.arraycopy(ords, 0, this.ordinals, 0, (int) totOrds);\n      } else {\n        this.ordinals = ords;\n      }\n    }\n\n","sourceOld":"    /**\n     * Creates a new {@link CachedOrds} from the {@link BinaryDocValues}.\n     * Assumes that the {@link BinaryDocValues} is not {@code null}.\n     */\n    public CachedOrds(OrdinalsSegmentReader source, int maxDoc) throws IOException {\n      final BytesRef buf = new BytesRef();\n\n      offsets = new int[maxDoc + 1];\n      int[] ords = new int[maxDoc]; // let's assume one ordinal per-document as an initial size\n\n      // this aggregator is limited to Integer.MAX_VALUE total ordinals.\n      long totOrds = 0;\n      final IntsRef values = new IntsRef(32);\n      for (int docID = 0; docID < maxDoc; docID++) {\n        offsets[docID] = (int) totOrds;\n        source.get(docID, values);\n        long nextLength = totOrds + values.length;\n        if (nextLength > ords.length) {\n          if (nextLength > ArrayUtil.MAX_ARRAY_LENGTH) {\n            throw new IllegalStateException(\"too many ordinals (>= \" + nextLength + \") to cache\");\n          }\n          ords = ArrayUtil.grow(ords, (int) nextLength);\n        }\n        System.arraycopy(values.ints, 0, ords, (int) totOrds, values.length);\n        totOrds = nextLength;\n      }\n      offsets[maxDoc] = (int) totOrds;\n      \n      // if ords array is bigger by more than 10% of what we really need, shrink it\n      if ((double) totOrds / ords.length < 0.9) { \n        this.ordinals = new int[(int) totOrds];\n        System.arraycopy(ords, 0, this.ordinals, 0, (int) totOrds);\n      } else {\n        this.ordinals = ords;\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3cc728b07df73b197e6d940d27f9b08b63918f13","date":1388834348,"type":0,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/facet/src/java/org/apache/lucene/facet/CachedOrdinalsReader.CachedOrds#CachedOrds(OrdinalsSegmentReader,int).mjava","pathOld":"/dev/null","sourceNew":"    /**\n     * Creates a new {@link CachedOrds} from the {@link BinaryDocValues}.\n     * Assumes that the {@link BinaryDocValues} is not {@code null}.\n     */\n    public CachedOrds(OrdinalsSegmentReader source, int maxDoc) throws IOException {\n      offsets = new int[maxDoc + 1];\n      int[] ords = new int[maxDoc]; // let's assume one ordinal per-document as an initial size\n\n      // this aggregator is limited to Integer.MAX_VALUE total ordinals.\n      long totOrds = 0;\n      final IntsRef values = new IntsRef(32);\n      for (int docID = 0; docID < maxDoc; docID++) {\n        offsets[docID] = (int) totOrds;\n        source.get(docID, values);\n        long nextLength = totOrds + values.length;\n        if (nextLength > ords.length) {\n          if (nextLength > ArrayUtil.MAX_ARRAY_LENGTH) {\n            throw new IllegalStateException(\"too many ordinals (>= \" + nextLength + \") to cache\");\n          }\n          ords = ArrayUtil.grow(ords, (int) nextLength);\n        }\n        System.arraycopy(values.ints, 0, ords, (int) totOrds, values.length);\n        totOrds = nextLength;\n      }\n      offsets[maxDoc] = (int) totOrds;\n      \n      // if ords array is bigger by more than 10% of what we really need, shrink it\n      if ((double) totOrds / ords.length < 0.9) { \n        this.ordinals = new int[(int) totOrds];\n        System.arraycopy(ords, 0, this.ordinals, 0, (int) totOrds);\n      } else {\n        this.ordinals = ords;\n      }\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9905adab7913dc4e059260c31a65cdfbd94afea9","date":1388944941,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/facet/src/java/org/apache/lucene/facet/taxonomy/CachedOrdinalsReader.CachedOrds#CachedOrds(OrdinalsSegmentReader,int).mjava","pathOld":"lucene/facet/src/java/org/apache/lucene/facet/CachedOrdinalsReader.CachedOrds#CachedOrds(OrdinalsSegmentReader,int).mjava","sourceNew":"    /**\n     * Creates a new {@link CachedOrds} from the {@link BinaryDocValues}.\n     * Assumes that the {@link BinaryDocValues} is not {@code null}.\n     */\n    public CachedOrds(OrdinalsSegmentReader source, int maxDoc) throws IOException {\n      offsets = new int[maxDoc + 1];\n      int[] ords = new int[maxDoc]; // let's assume one ordinal per-document as an initial size\n\n      // this aggregator is limited to Integer.MAX_VALUE total ordinals.\n      long totOrds = 0;\n      final IntsRef values = new IntsRef(32);\n      for (int docID = 0; docID < maxDoc; docID++) {\n        offsets[docID] = (int) totOrds;\n        source.get(docID, values);\n        long nextLength = totOrds + values.length;\n        if (nextLength > ords.length) {\n          if (nextLength > ArrayUtil.MAX_ARRAY_LENGTH) {\n            throw new IllegalStateException(\"too many ordinals (>= \" + nextLength + \") to cache\");\n          }\n          ords = ArrayUtil.grow(ords, (int) nextLength);\n        }\n        System.arraycopy(values.ints, 0, ords, (int) totOrds, values.length);\n        totOrds = nextLength;\n      }\n      offsets[maxDoc] = (int) totOrds;\n      \n      // if ords array is bigger by more than 10% of what we really need, shrink it\n      if ((double) totOrds / ords.length < 0.9) { \n        this.ordinals = new int[(int) totOrds];\n        System.arraycopy(ords, 0, this.ordinals, 0, (int) totOrds);\n      } else {\n        this.ordinals = ords;\n      }\n    }\n\n","sourceOld":"    /**\n     * Creates a new {@link CachedOrds} from the {@link BinaryDocValues}.\n     * Assumes that the {@link BinaryDocValues} is not {@code null}.\n     */\n    public CachedOrds(OrdinalsSegmentReader source, int maxDoc) throws IOException {\n      offsets = new int[maxDoc + 1];\n      int[] ords = new int[maxDoc]; // let's assume one ordinal per-document as an initial size\n\n      // this aggregator is limited to Integer.MAX_VALUE total ordinals.\n      long totOrds = 0;\n      final IntsRef values = new IntsRef(32);\n      for (int docID = 0; docID < maxDoc; docID++) {\n        offsets[docID] = (int) totOrds;\n        source.get(docID, values);\n        long nextLength = totOrds + values.length;\n        if (nextLength > ords.length) {\n          if (nextLength > ArrayUtil.MAX_ARRAY_LENGTH) {\n            throw new IllegalStateException(\"too many ordinals (>= \" + nextLength + \") to cache\");\n          }\n          ords = ArrayUtil.grow(ords, (int) nextLength);\n        }\n        System.arraycopy(values.ints, 0, ords, (int) totOrds, values.length);\n        totOrds = nextLength;\n      }\n      offsets[maxDoc] = (int) totOrds;\n      \n      // if ords array is bigger by more than 10% of what we really need, shrink it\n      if ((double) totOrds / ords.length < 0.9) { \n        this.ordinals = new int[(int) totOrds];\n        System.arraycopy(ords, 0, this.ordinals, 0, (int) totOrds);\n      } else {\n        this.ordinals = ords;\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"9905adab7913dc4e059260c31a65cdfbd94afea9":["3cc728b07df73b197e6d940d27f9b08b63918f13"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"21d36d0db865f7b84026b447bec653469a6e66df":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"3cc728b07df73b197e6d940d27f9b08b63918f13":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","8a6c8fcce6eb5b976a26c9543c230548f7aa13e1"],"8a6c8fcce6eb5b976a26c9543c230548f7aa13e1":["21d36d0db865f7b84026b447bec653469a6e66df"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9905adab7913dc4e059260c31a65cdfbd94afea9"]},"commit2Childs":{"9905adab7913dc4e059260c31a65cdfbd94afea9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["21d36d0db865f7b84026b447bec653469a6e66df","3cc728b07df73b197e6d940d27f9b08b63918f13"],"21d36d0db865f7b84026b447bec653469a6e66df":["8a6c8fcce6eb5b976a26c9543c230548f7aa13e1"],"3cc728b07df73b197e6d940d27f9b08b63918f13":["9905adab7913dc4e059260c31a65cdfbd94afea9"],"8a6c8fcce6eb5b976a26c9543c230548f7aa13e1":["3cc728b07df73b197e6d940d27f9b08b63918f13"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}