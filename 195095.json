{"path":"solr/core/src/test/org/apache/solr/cloud/TestCloudJSONFacetSKG#testRandom().mjava","commits":[{"id":"2c705a0d590cf911e7c942df49563ca2ea176e22","date":1526916174,"type":0,"author":"Chris Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestCloudJSONFacetSKG#testRandom().mjava","pathOld":"/dev/null","sourceNew":"  public void testRandom() throws Exception {\n\n    // since the \"cost\" of verifying the stats for each bucket is so high (see TODO in verifySKGResults())\n    // we put a safety valve in place on the maximum number of buckets that we are willing to verify\n    // across *all* the queries that we do.\n    // that way if the randomized queries we build all have relatively small facets, so be it, but if\n    // we get a really big one early on, we can test as much as possible, skip other iterations.\n    //\n    // (deeply nested facets may contain more buckets then the max, but we won't *check* all of them)\n    final int maxBucketsAllowed = atLeast(2000);\n    final AtomicInteger maxBucketsToCheck = new AtomicInteger(maxBucketsAllowed);\n    \n    final int numIters = atLeast(10);\n    for (int iter = 0; iter < numIters && 0 < maxBucketsToCheck.get(); iter++) {\n      \n      assertFacetSKGsAreCorrect(maxBucketsToCheck, TermFacet.buildRandomFacets(),\n                                buildRandomQuery(), buildRandomQuery(), buildRandomQuery());\n    }\n    assertTrue(\"Didn't check a single bucket???\", maxBucketsToCheck.get() < maxBucketsAllowed);\n           \n\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1bd47e89c87cf4ff6e6c91af7f383ee810968fc3","date":1531457318,"type":3,"author":"Chris Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestCloudJSONFacetSKG#testRandom().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestCloudJSONFacetSKG#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n\n    // since the \"cost\" of verifying the stats for each bucket is so high (see TODO in verifySKGResults())\n    // we put a safety valve in place on the maximum number of buckets that we are willing to verify\n    // across *all* the queries that we do.\n    // that way if the randomized queries we build all have relatively small facets, so be it, but if\n    // we get a really big one early on, we can test as much as possible, skip other iterations.\n    //\n    // (deeply nested facets may contain more buckets then the max, but we won't *check* all of them)\n    final int maxBucketsAllowed = atLeast(2000);\n    final AtomicInteger maxBucketsToCheck = new AtomicInteger(maxBucketsAllowed);\n    \n    final int numIters = atLeast(10);\n    for (int iter = 0; iter < numIters && 0 < maxBucketsToCheck.get(); iter++) {\n      assertFacetSKGsAreCorrect(maxBucketsToCheck, TermFacet.buildRandomFacets(),\n                                buildRandomQuery(), buildRandomQuery(), buildRandomQuery());\n    }\n    assertTrue(\"Didn't check a single bucket???\", maxBucketsToCheck.get() < maxBucketsAllowed);\n           \n\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n\n    // since the \"cost\" of verifying the stats for each bucket is so high (see TODO in verifySKGResults())\n    // we put a safety valve in place on the maximum number of buckets that we are willing to verify\n    // across *all* the queries that we do.\n    // that way if the randomized queries we build all have relatively small facets, so be it, but if\n    // we get a really big one early on, we can test as much as possible, skip other iterations.\n    //\n    // (deeply nested facets may contain more buckets then the max, but we won't *check* all of them)\n    final int maxBucketsAllowed = atLeast(2000);\n    final AtomicInteger maxBucketsToCheck = new AtomicInteger(maxBucketsAllowed);\n    \n    final int numIters = atLeast(10);\n    for (int iter = 0; iter < numIters && 0 < maxBucketsToCheck.get(); iter++) {\n      \n      assertFacetSKGsAreCorrect(maxBucketsToCheck, TermFacet.buildRandomFacets(),\n                                buildRandomQuery(), buildRandomQuery(), buildRandomQuery());\n    }\n    assertTrue(\"Didn't check a single bucket???\", maxBucketsToCheck.get() < maxBucketsAllowed);\n           \n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26","date":1531589977,"type":3,"author":"Michael Braun","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestCloudJSONFacetSKG#testRandom().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestCloudJSONFacetSKG#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n\n    // since the \"cost\" of verifying the stats for each bucket is so high (see TODO in verifySKGResults())\n    // we put a safety valve in place on the maximum number of buckets that we are willing to verify\n    // across *all* the queries that we do.\n    // that way if the randomized queries we build all have relatively small facets, so be it, but if\n    // we get a really big one early on, we can test as much as possible, skip other iterations.\n    //\n    // (deeply nested facets may contain more buckets then the max, but we won't *check* all of them)\n    final int maxBucketsAllowed = atLeast(2000);\n    final AtomicInteger maxBucketsToCheck = new AtomicInteger(maxBucketsAllowed);\n    \n    final int numIters = atLeast(10);\n    for (int iter = 0; iter < numIters && 0 < maxBucketsToCheck.get(); iter++) {\n      assertFacetSKGsAreCorrect(maxBucketsToCheck, TermFacet.buildRandomFacets(),\n                                buildRandomQuery(), buildRandomQuery(), buildRandomQuery());\n    }\n    assertTrue(\"Didn't check a single bucket???\", maxBucketsToCheck.get() < maxBucketsAllowed);\n           \n\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n\n    // since the \"cost\" of verifying the stats for each bucket is so high (see TODO in verifySKGResults())\n    // we put a safety valve in place on the maximum number of buckets that we are willing to verify\n    // across *all* the queries that we do.\n    // that way if the randomized queries we build all have relatively small facets, so be it, but if\n    // we get a really big one early on, we can test as much as possible, skip other iterations.\n    //\n    // (deeply nested facets may contain more buckets then the max, but we won't *check* all of them)\n    final int maxBucketsAllowed = atLeast(2000);\n    final AtomicInteger maxBucketsToCheck = new AtomicInteger(maxBucketsAllowed);\n    \n    final int numIters = atLeast(10);\n    for (int iter = 0; iter < numIters && 0 < maxBucketsToCheck.get(); iter++) {\n      \n      assertFacetSKGsAreCorrect(maxBucketsToCheck, TermFacet.buildRandomFacets(),\n                                buildRandomQuery(), buildRandomQuery(), buildRandomQuery());\n    }\n    assertTrue(\"Didn't check a single bucket???\", maxBucketsToCheck.get() < maxBucketsAllowed);\n           \n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","date":1531905561,"type":3,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestCloudJSONFacetSKG#testRandom().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestCloudJSONFacetSKG#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n\n    // since the \"cost\" of verifying the stats for each bucket is so high (see TODO in verifySKGResults())\n    // we put a safety valve in place on the maximum number of buckets that we are willing to verify\n    // across *all* the queries that we do.\n    // that way if the randomized queries we build all have relatively small facets, so be it, but if\n    // we get a really big one early on, we can test as much as possible, skip other iterations.\n    //\n    // (deeply nested facets may contain more buckets then the max, but we won't *check* all of them)\n    final int maxBucketsAllowed = atLeast(2000);\n    final AtomicInteger maxBucketsToCheck = new AtomicInteger(maxBucketsAllowed);\n    \n    final int numIters = atLeast(10);\n    for (int iter = 0; iter < numIters && 0 < maxBucketsToCheck.get(); iter++) {\n      assertFacetSKGsAreCorrect(maxBucketsToCheck, TermFacet.buildRandomFacets(),\n                                buildRandomQuery(), buildRandomQuery(), buildRandomQuery());\n    }\n    assertTrue(\"Didn't check a single bucket???\", maxBucketsToCheck.get() < maxBucketsAllowed);\n           \n\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n\n    // since the \"cost\" of verifying the stats for each bucket is so high (see TODO in verifySKGResults())\n    // we put a safety valve in place on the maximum number of buckets that we are willing to verify\n    // across *all* the queries that we do.\n    // that way if the randomized queries we build all have relatively small facets, so be it, but if\n    // we get a really big one early on, we can test as much as possible, skip other iterations.\n    //\n    // (deeply nested facets may contain more buckets then the max, but we won't *check* all of them)\n    final int maxBucketsAllowed = atLeast(2000);\n    final AtomicInteger maxBucketsToCheck = new AtomicInteger(maxBucketsAllowed);\n    \n    final int numIters = atLeast(10);\n    for (int iter = 0; iter < numIters && 0 < maxBucketsToCheck.get(); iter++) {\n      \n      assertFacetSKGsAreCorrect(maxBucketsToCheck, TermFacet.buildRandomFacets(),\n                                buildRandomQuery(), buildRandomQuery(), buildRandomQuery());\n    }\n    assertTrue(\"Didn't check a single bucket???\", maxBucketsToCheck.get() < maxBucketsAllowed);\n           \n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"92910727264a23a47b7a6c94b0f75d655537b9ea","date":1540414655,"type":5,"author":"Varun Thacker","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/facet/TestCloudJSONFacetSKG#testRandom().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestCloudJSONFacetSKG#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n\n    // since the \"cost\" of verifying the stats for each bucket is so high (see TODO in verifySKGResults())\n    // we put a safety valve in place on the maximum number of buckets that we are willing to verify\n    // across *all* the queries that we do.\n    // that way if the randomized queries we build all have relatively small facets, so be it, but if\n    // we get a really big one early on, we can test as much as possible, skip other iterations.\n    //\n    // (deeply nested facets may contain more buckets then the max, but we won't *check* all of them)\n    final int maxBucketsAllowed = atLeast(2000);\n    final AtomicInteger maxBucketsToCheck = new AtomicInteger(maxBucketsAllowed);\n    \n    final int numIters = atLeast(10);\n    for (int iter = 0; iter < numIters && 0 < maxBucketsToCheck.get(); iter++) {\n      assertFacetSKGsAreCorrect(maxBucketsToCheck, TermFacet.buildRandomFacets(),\n                                buildRandomQuery(), buildRandomQuery(), buildRandomQuery());\n    }\n    assertTrue(\"Didn't check a single bucket???\", maxBucketsToCheck.get() < maxBucketsAllowed);\n           \n\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n\n    // since the \"cost\" of verifying the stats for each bucket is so high (see TODO in verifySKGResults())\n    // we put a safety valve in place on the maximum number of buckets that we are willing to verify\n    // across *all* the queries that we do.\n    // that way if the randomized queries we build all have relatively small facets, so be it, but if\n    // we get a really big one early on, we can test as much as possible, skip other iterations.\n    //\n    // (deeply nested facets may contain more buckets then the max, but we won't *check* all of them)\n    final int maxBucketsAllowed = atLeast(2000);\n    final AtomicInteger maxBucketsToCheck = new AtomicInteger(maxBucketsAllowed);\n    \n    final int numIters = atLeast(10);\n    for (int iter = 0; iter < numIters && 0 < maxBucketsToCheck.get(); iter++) {\n      assertFacetSKGsAreCorrect(maxBucketsToCheck, TermFacet.buildRandomFacets(),\n                                buildRandomQuery(), buildRandomQuery(), buildRandomQuery());\n    }\n    assertTrue(\"Didn't check a single bucket???\", maxBucketsToCheck.get() < maxBucketsAllowed);\n           \n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"2c705a0d590cf911e7c942df49563ca2ea176e22":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":["2c705a0d590cf911e7c942df49563ca2ea176e22","1bd47e89c87cf4ff6e6c91af7f383ee810968fc3"],"1bd47e89c87cf4ff6e6c91af7f383ee810968fc3":["2c705a0d590cf911e7c942df49563ca2ea176e22"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"92910727264a23a47b7a6c94b0f75d655537b9ea":["1bd47e89c87cf4ff6e6c91af7f383ee810968fc3"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["92910727264a23a47b7a6c94b0f75d655537b9ea"],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":["2c705a0d590cf911e7c942df49563ca2ea176e22","1bd47e89c87cf4ff6e6c91af7f383ee810968fc3"]},"commit2Childs":{"2c705a0d590cf911e7c942df49563ca2ea176e22":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","1bd47e89c87cf4ff6e6c91af7f383ee810968fc3","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":[],"1bd47e89c87cf4ff6e6c91af7f383ee810968fc3":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","92910727264a23a47b7a6c94b0f75d655537b9ea","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["2c705a0d590cf911e7c942df49563ca2ea176e22"],"92910727264a23a47b7a6c94b0f75d655537b9ea":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":[]},"heads":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","cd5edd1f2b162a5cfa08efd17851a07373a96817","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}