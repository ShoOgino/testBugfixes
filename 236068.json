{"path":"lucene/highlighter/src/test/org/apache/lucene/search/uhighlight/TestUnifiedHighlighterRanking.FakePassageFormatter#format(Passage[],String).mjava","commits":[{"id":"1f5ce59aaf4a055cc9ec62c15a89c263a05ff4b2","date":1475611903,"type":0,"author":"David Smiley","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/uhighlight/TestUnifiedHighlighterRanking.FakePassageFormatter#format(Passage[],String).mjava","pathOld":"/dev/null","sourceNew":"    @Override\n    public String format(Passage passages[], String content) {\n      for (Passage p : passages) {\n        // verify some basics about the passage\n        assertTrue(p.getScore() >= 0);\n        assertTrue(p.getNumMatches() > 0);\n        assertTrue(p.getStartOffset() >= 0);\n        assertTrue(p.getStartOffset() <= content.length());\n        assertTrue(p.getEndOffset() >= p.getStartOffset());\n        assertTrue(p.getEndOffset() <= content.length());\n        // we use a very simple analyzer. so we can assert the matches are correct\n        int lastMatchStart = -1;\n        for (int i = 0; i < p.getNumMatches(); i++) {\n          BytesRef term = p.getMatchTerms()[i];\n          int matchStart = p.getMatchStarts()[i];\n          assertTrue(matchStart >= 0);\n          // must at least start within the passage\n          assertTrue(matchStart < p.getEndOffset());\n          int matchEnd = p.getMatchEnds()[i];\n          assertTrue(matchEnd >= 0);\n          // always moving forward\n          assertTrue(matchStart >= lastMatchStart);\n          lastMatchStart = matchStart;\n          // single character terms\n          assertEquals(matchStart + 1, matchEnd);\n          // and the offsets must be correct...\n          assertEquals(1, term.length);\n          assertEquals((char) term.bytes[term.offset], Character.toLowerCase(content.charAt(matchStart)));\n        }\n        // record just the start/end offset for simplicity\n        seen.add(new Pair(p.getStartOffset(), p.getEndOffset()));\n      }\n      return \"bogus!!!!!!\";\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":0,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/uhighlight/TestUnifiedHighlighterRanking.FakePassageFormatter#format(Passage[],String).mjava","pathOld":"/dev/null","sourceNew":"    @Override\n    public String format(Passage passages[], String content) {\n      for (Passage p : passages) {\n        // verify some basics about the passage\n        assertTrue(p.getScore() >= 0);\n        assertTrue(p.getNumMatches() > 0);\n        assertTrue(p.getStartOffset() >= 0);\n        assertTrue(p.getStartOffset() <= content.length());\n        assertTrue(p.getEndOffset() >= p.getStartOffset());\n        assertTrue(p.getEndOffset() <= content.length());\n        // we use a very simple analyzer. so we can assert the matches are correct\n        int lastMatchStart = -1;\n        for (int i = 0; i < p.getNumMatches(); i++) {\n          BytesRef term = p.getMatchTerms()[i];\n          int matchStart = p.getMatchStarts()[i];\n          assertTrue(matchStart >= 0);\n          // must at least start within the passage\n          assertTrue(matchStart < p.getEndOffset());\n          int matchEnd = p.getMatchEnds()[i];\n          assertTrue(matchEnd >= 0);\n          // always moving forward\n          assertTrue(matchStart >= lastMatchStart);\n          lastMatchStart = matchStart;\n          // single character terms\n          assertEquals(matchStart + 1, matchEnd);\n          // and the offsets must be correct...\n          assertEquals(1, term.length);\n          assertEquals((char) term.bytes[term.offset], Character.toLowerCase(content.charAt(matchStart)));\n        }\n        // record just the start/end offset for simplicity\n        seen.add(new Pair(p.getStartOffset(), p.getEndOffset()));\n      }\n      return \"bogus!!!!!!\";\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"1f5ce59aaf4a055cc9ec62c15a89c263a05ff4b2":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","1f5ce59aaf4a055cc9ec62c15a89c263a05ff4b2"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["1f5ce59aaf4a055cc9ec62c15a89c263a05ff4b2"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["1f5ce59aaf4a055cc9ec62c15a89c263a05ff4b2","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"1f5ce59aaf4a055cc9ec62c15a89c263a05ff4b2":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}