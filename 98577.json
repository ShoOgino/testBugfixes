{"path":"modules/analysis/common/src/test/org/apache/lucene/analysis/th/TestThaiAnalyzer#testBuggyTokenType().mjava","commits":[{"id":"0f080986da691a3bba7b757f43ab72cdc82b57ce","date":1273069619,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"modules/analysis/common/src/test/org/apache/lucene/analysis/th/TestThaiAnalyzer#testBuggyTokenType().mjava","pathOld":"lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/th/TestThaiAnalyzer#testBuggyTokenType().mjava","sourceNew":"\t/*\n\t * Thai numeric tokens are typed as <ALPHANUM> instead of <NUM>.\n\t * This is really a problem with the interaction w/ StandardTokenizer, which is used by ThaiAnalyzer.\n\t * \n\t * The issue is this: in StandardTokenizer the entire [:Thai:] block is specified in ALPHANUM (including punctuation, digits, etc)\n\t * Fix is easy: refine this spec to exclude thai punctuation and digits.\n\t * \n\t * A better fix, that would also fix quite a few other languages would be to remove the thai hack.\n\t * Instead, allow the definition of alphanum to include relevant categories like nonspacing marks!\n\t */\n\tpublic void testBuggyTokenType() throws Exception {\n\t\tassertAnalyzesTo(new ThaiAnalyzer(TEST_VERSION_CURRENT), \"เดอะนิวยอร์กไทมส์ ๑๒๓\", \n\t\t\t\tnew String[] { \"เด\", \"อะนิว\", \"ยอ\", \"ร์ก\", \"ไทมส์\", \"๑๒๓\" },\n\t\t\t\tnew String[] { \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\" });\n\t}\n\n","sourceOld":"\t/*\n\t * Thai numeric tokens are typed as <ALPHANUM> instead of <NUM>.\n\t * This is really a problem with the interaction w/ StandardTokenizer, which is used by ThaiAnalyzer.\n\t * \n\t * The issue is this: in StandardTokenizer the entire [:Thai:] block is specified in ALPHANUM (including punctuation, digits, etc)\n\t * Fix is easy: refine this spec to exclude thai punctuation and digits.\n\t * \n\t * A better fix, that would also fix quite a few other languages would be to remove the thai hack.\n\t * Instead, allow the definition of alphanum to include relevant categories like nonspacing marks!\n\t */\n\tpublic void testBuggyTokenType() throws Exception {\n\t\tassertAnalyzesTo(new ThaiAnalyzer(TEST_VERSION_CURRENT), \"เดอะนิวยอร์กไทมส์ ๑๒๓\", \n\t\t\t\tnew String[] { \"เด\", \"อะนิว\", \"ยอ\", \"ร์ก\", \"ไทมส์\", \"๑๒๓\" },\n\t\t\t\tnew String[] { \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\" });\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ac9bb89d6ac5da067733bee436027909ab5f49c6","date":1284521435,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"modules/analysis/common/src/test/org/apache/lucene/analysis/th/TestThaiAnalyzer#testBuggyTokenType().mjava","pathOld":"modules/analysis/common/src/test/org/apache/lucene/analysis/th/TestThaiAnalyzer#testBuggyTokenType().mjava","sourceNew":"\t/*\n\t * Thai numeric tokens are typed as <ALPHANUM> instead of <NUM>.\n\t * This is really a problem with the interaction w/ StandardTokenizer, which is used by ThaiAnalyzer.\n\t * \n\t * The issue is this: in StandardTokenizer the entire [:Thai:] block is specified in ALPHANUM (including punctuation, digits, etc)\n\t * Fix is easy: refine this spec to exclude thai punctuation and digits.\n\t * \n\t * A better fix, that would also fix quite a few other languages would be to remove the thai hack.\n\t * Instead, allow the definition of alphanum to include relevant categories like nonspacing marks!\n\t */\n\tpublic void testBuggyTokenType() throws Exception {\n\t\tassertAnalyzesTo(new ThaiAnalyzer(TEST_VERSION_CURRENT), \"การที่ได้ต้องแสดงว่างานดี ๑๒๓\", \n\t\t    new String[] { \"การ\", \"ที่\", \"ได้\", \"ต้อง\", \"แสดง\", \"ว่า\", \"งาน\", \"ดี\", \"๑๒๓\" },\n\t\t\t\tnew String[] { \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \n\t\t     \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\" });\n\t}\n\n","sourceOld":"\t/*\n\t * Thai numeric tokens are typed as <ALPHANUM> instead of <NUM>.\n\t * This is really a problem with the interaction w/ StandardTokenizer, which is used by ThaiAnalyzer.\n\t * \n\t * The issue is this: in StandardTokenizer the entire [:Thai:] block is specified in ALPHANUM (including punctuation, digits, etc)\n\t * Fix is easy: refine this spec to exclude thai punctuation and digits.\n\t * \n\t * A better fix, that would also fix quite a few other languages would be to remove the thai hack.\n\t * Instead, allow the definition of alphanum to include relevant categories like nonspacing marks!\n\t */\n\tpublic void testBuggyTokenType() throws Exception {\n\t\tassertAnalyzesTo(new ThaiAnalyzer(TEST_VERSION_CURRENT), \"เดอะนิวยอร์กไทมส์ ๑๒๓\", \n\t\t\t\tnew String[] { \"เด\", \"อะนิว\", \"ยอ\", \"ร์ก\", \"ไทมส์\", \"๑๒๓\" },\n\t\t\t\tnew String[] { \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\" });\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3b5d78730ab190ff8c3ec8984b6e7170f7b35de8","date":1284910806,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"modules/analysis/common/src/test/org/apache/lucene/analysis/th/TestThaiAnalyzer#testBuggyTokenType().mjava","pathOld":"modules/analysis/common/src/test/org/apache/lucene/analysis/th/TestThaiAnalyzer#testBuggyTokenType().mjava","sourceNew":"\t/*\n\t * Thai numeric tokens are typed as <ALPHANUM> instead of <NUM>.\n\t * This is really a problem with the interaction w/ StandardTokenizer, which is used by ThaiAnalyzer.\n\t * \n\t * The issue is this: in StandardTokenizer the entire [:Thai:] block is specified in ALPHANUM (including punctuation, digits, etc)\n\t * Fix is easy: refine this spec to exclude thai punctuation and digits.\n\t * \n\t * A better fix, that would also fix quite a few other languages would be to remove the thai hack.\n\t * Instead, allow the definition of alphanum to include relevant categories like nonspacing marks!\n\t */\n\tpublic void testBuggyTokenType() throws Exception {\n\t  Assume.assumeTrue(ThaiWordFilter.DBBI_AVAILABLE);\n\t\tassertAnalyzesTo(new ThaiAnalyzer(TEST_VERSION_CURRENT), \"การที่ได้ต้องแสดงว่างานดี ๑๒๓\", \n\t\t    new String[] { \"การ\", \"ที่\", \"ได้\", \"ต้อง\", \"แสดง\", \"ว่า\", \"งาน\", \"ดี\", \"๑๒๓\" },\n\t\t\t\tnew String[] { \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \n\t\t     \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\" });\n\t}\n\n","sourceOld":"\t/*\n\t * Thai numeric tokens are typed as <ALPHANUM> instead of <NUM>.\n\t * This is really a problem with the interaction w/ StandardTokenizer, which is used by ThaiAnalyzer.\n\t * \n\t * The issue is this: in StandardTokenizer the entire [:Thai:] block is specified in ALPHANUM (including punctuation, digits, etc)\n\t * Fix is easy: refine this spec to exclude thai punctuation and digits.\n\t * \n\t * A better fix, that would also fix quite a few other languages would be to remove the thai hack.\n\t * Instead, allow the definition of alphanum to include relevant categories like nonspacing marks!\n\t */\n\tpublic void testBuggyTokenType() throws Exception {\n\t\tassertAnalyzesTo(new ThaiAnalyzer(TEST_VERSION_CURRENT), \"การที่ได้ต้องแสดงว่างานดี ๑๒๓\", \n\t\t    new String[] { \"การ\", \"ที่\", \"ได้\", \"ต้อง\", \"แสดง\", \"ว่า\", \"งาน\", \"ดี\", \"๑๒๓\" },\n\t\t\t\tnew String[] { \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \n\t\t     \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\" });\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"683d3f90dda2bbb999c3ce855706d74563a53680","date":1285654576,"type":4,"author":"Steven Rowe","isMerge":false,"pathNew":"/dev/null","pathOld":"modules/analysis/common/src/test/org/apache/lucene/analysis/th/TestThaiAnalyzer#testBuggyTokenType().mjava","sourceNew":null,"sourceOld":"\t/*\n\t * Thai numeric tokens are typed as <ALPHANUM> instead of <NUM>.\n\t * This is really a problem with the interaction w/ StandardTokenizer, which is used by ThaiAnalyzer.\n\t * \n\t * The issue is this: in StandardTokenizer the entire [:Thai:] block is specified in ALPHANUM (including punctuation, digits, etc)\n\t * Fix is easy: refine this spec to exclude thai punctuation and digits.\n\t * \n\t * A better fix, that would also fix quite a few other languages would be to remove the thai hack.\n\t * Instead, allow the definition of alphanum to include relevant categories like nonspacing marks!\n\t */\n\tpublic void testBuggyTokenType() throws Exception {\n\t  Assume.assumeTrue(ThaiWordFilter.DBBI_AVAILABLE);\n\t\tassertAnalyzesTo(new ThaiAnalyzer(TEST_VERSION_CURRENT), \"การที่ได้ต้องแสดงว่างานดี ๑๒๓\", \n\t\t    new String[] { \"การ\", \"ที่\", \"ได้\", \"ต้อง\", \"แสดง\", \"ว่า\", \"งาน\", \"ดี\", \"๑๒๓\" },\n\t\t\t\tnew String[] { \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \n\t\t     \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\" });\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":4,"author":"Michael Busch","isMerge":true,"pathNew":"/dev/null","pathOld":"modules/analysis/common/src/test/org/apache/lucene/analysis/th/TestThaiAnalyzer#testBuggyTokenType().mjava","sourceNew":null,"sourceOld":"\t/*\n\t * Thai numeric tokens are typed as <ALPHANUM> instead of <NUM>.\n\t * This is really a problem with the interaction w/ StandardTokenizer, which is used by ThaiAnalyzer.\n\t * \n\t * The issue is this: in StandardTokenizer the entire [:Thai:] block is specified in ALPHANUM (including punctuation, digits, etc)\n\t * Fix is easy: refine this spec to exclude thai punctuation and digits.\n\t * \n\t * A better fix, that would also fix quite a few other languages would be to remove the thai hack.\n\t * Instead, allow the definition of alphanum to include relevant categories like nonspacing marks!\n\t */\n\tpublic void testBuggyTokenType() throws Exception {\n\t\tassertAnalyzesTo(new ThaiAnalyzer(TEST_VERSION_CURRENT), \"เดอะนิวยอร์กไทมส์ ๑๒๓\", \n\t\t\t\tnew String[] { \"เด\", \"อะนิว\", \"ยอ\", \"ร์ก\", \"ไทมส์\", \"๑๒๓\" },\n\t\t\t\tnew String[] { \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\" });\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"683d3f90dda2bbb999c3ce855706d74563a53680":["3b5d78730ab190ff8c3ec8984b6e7170f7b35de8"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"ac9bb89d6ac5da067733bee436027909ab5f49c6":["0f080986da691a3bba7b757f43ab72cdc82b57ce"],"3b5d78730ab190ff8c3ec8984b6e7170f7b35de8":["ac9bb89d6ac5da067733bee436027909ab5f49c6"],"0f080986da691a3bba7b757f43ab72cdc82b57ce":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["0f080986da691a3bba7b757f43ab72cdc82b57ce","683d3f90dda2bbb999c3ce855706d74563a53680"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["683d3f90dda2bbb999c3ce855706d74563a53680"]},"commit2Childs":{"683d3f90dda2bbb999c3ce855706d74563a53680":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["0f080986da691a3bba7b757f43ab72cdc82b57ce"],"ac9bb89d6ac5da067733bee436027909ab5f49c6":["3b5d78730ab190ff8c3ec8984b6e7170f7b35de8"],"3b5d78730ab190ff8c3ec8984b6e7170f7b35de8":["683d3f90dda2bbb999c3ce855706d74563a53680"],"0f080986da691a3bba7b757f43ab72cdc82b57ce":["ac9bb89d6ac5da067733bee436027909ab5f49c6","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}