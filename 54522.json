{"path":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#postingEquals(int).mjava","commits":[{"id":"955c32f886db6f6356c9fcdea6b1f1cb4effda24","date":1270581567,"type":0,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#postingEquals(int).mjava","pathOld":"/dev/null","sourceNew":"  /** Test whether the text for current RawPostingList p equals\n   *  current tokenText in utf8. */\n  private boolean postingEquals(final int termID) {\n    final int textStart = postingsArray.textStarts[termID];\n    final byte[] text = termBytePool.buffers[textStart >> DocumentsWriter.BYTE_BLOCK_SHIFT];\n    assert text != null;\n\n    int pos = textStart & DocumentsWriter.BYTE_BLOCK_MASK;\n    \n    final int len;\n    if ((text[pos] & 0x80) == 0) {\n      // length is 1 byte\n      len = text[pos];\n      pos += 1;\n    } else {\n      // length is 2 bytes\n      len = (text[pos]&0x7f) + ((text[pos+1]&0xff)<<7);\n      pos += 2;\n    }\n\n    if (len == utf8.length) {\n      final byte[] utf8Bytes = utf8.bytes;\n      for(int tokenPos=0;tokenPos<utf8.length;pos++,tokenPos++) {\n        if (utf8Bytes[tokenPos] != text[pos]) {\n          return false;\n        }\n      }\n      return true;\n    } else {\n      return false;\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6c18273ea5b3974d2f30117f46f1ae416c28f727","date":1279708040,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#postingEquals(int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#postingEquals(int).mjava","sourceNew":"  /** Test whether the text for current RawPostingList p equals\n   *  current tokenText in utf8. */\n  private boolean postingEquals(final int termID) {\n    final int textStart = postingsArray.textStarts[termID];\n    final byte[] text = termBytePool.buffers[textStart >> DocumentsWriterRAMAllocator.BYTE_BLOCK_SHIFT];\n    assert text != null;\n\n    int pos = textStart & DocumentsWriterRAMAllocator.BYTE_BLOCK_MASK;\n    \n    final int len;\n    if ((text[pos] & 0x80) == 0) {\n      // length is 1 byte\n      len = text[pos];\n      pos += 1;\n    } else {\n      // length is 2 bytes\n      len = (text[pos]&0x7f) + ((text[pos+1]&0xff)<<7);\n      pos += 2;\n    }\n\n    if (len == utf8.length) {\n      final byte[] utf8Bytes = utf8.bytes;\n      for(int tokenPos=0;tokenPos<utf8.length;pos++,tokenPos++) {\n        if (utf8Bytes[tokenPos] != text[pos]) {\n          return false;\n        }\n      }\n      return true;\n    } else {\n      return false;\n    }\n  }\n\n","sourceOld":"  /** Test whether the text for current RawPostingList p equals\n   *  current tokenText in utf8. */\n  private boolean postingEquals(final int termID) {\n    final int textStart = postingsArray.textStarts[termID];\n    final byte[] text = termBytePool.buffers[textStart >> DocumentsWriter.BYTE_BLOCK_SHIFT];\n    assert text != null;\n\n    int pos = textStart & DocumentsWriter.BYTE_BLOCK_MASK;\n    \n    final int len;\n    if ((text[pos] & 0x80) == 0) {\n      // length is 1 byte\n      len = text[pos];\n      pos += 1;\n    } else {\n      // length is 2 bytes\n      len = (text[pos]&0x7f) + ((text[pos+1]&0xff)<<7);\n      pos += 2;\n    }\n\n    if (len == utf8.length) {\n      final byte[] utf8Bytes = utf8.bytes;\n      for(int tokenPos=0;tokenPos<utf8.length;pos++,tokenPos++) {\n        if (utf8Bytes[tokenPos] != text[pos]) {\n          return false;\n        }\n      }\n      return true;\n    } else {\n      return false;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5d6c52f55ea3ba9a5b1d5a6dd17f79bc7d308392","date":1286023472,"type":4,"author":"Simon Willnauer","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#postingEquals(int).mjava","sourceNew":null,"sourceOld":"  /** Test whether the text for current RawPostingList p equals\n   *  current tokenText in utf8. */\n  private boolean postingEquals(final int termID) {\n    final int textStart = postingsArray.textStarts[termID];\n    final byte[] text = termBytePool.buffers[textStart >> DocumentsWriter.BYTE_BLOCK_SHIFT];\n    assert text != null;\n\n    int pos = textStart & DocumentsWriter.BYTE_BLOCK_MASK;\n    \n    final int len;\n    if ((text[pos] & 0x80) == 0) {\n      // length is 1 byte\n      len = text[pos];\n      pos += 1;\n    } else {\n      // length is 2 bytes\n      len = (text[pos]&0x7f) + ((text[pos+1]&0xff)<<7);\n      pos += 2;\n    }\n\n    if (len == utf8.length) {\n      final byte[] utf8Bytes = utf8.bytes;\n      for(int tokenPos=0;tokenPos<utf8.length;pos++,tokenPos++) {\n        if (utf8Bytes[tokenPos] != text[pos]) {\n          return false;\n        }\n      }\n      return true;\n    } else {\n      return false;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":4,"author":"Michael Busch","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#postingEquals(int).mjava","sourceNew":null,"sourceOld":"  /** Test whether the text for current RawPostingList p equals\n   *  current tokenText in utf8. */\n  private boolean postingEquals(final int termID) {\n    final int textStart = postingsArray.textStarts[termID];\n    final byte[] text = termBytePool.buffers[textStart >> DocumentsWriterRAMAllocator.BYTE_BLOCK_SHIFT];\n    assert text != null;\n\n    int pos = textStart & DocumentsWriterRAMAllocator.BYTE_BLOCK_MASK;\n    \n    final int len;\n    if ((text[pos] & 0x80) == 0) {\n      // length is 1 byte\n      len = text[pos];\n      pos += 1;\n    } else {\n      // length is 2 bytes\n      len = (text[pos]&0x7f) + ((text[pos+1]&0xff)<<7);\n      pos += 2;\n    }\n\n    if (len == utf8.length) {\n      final byte[] utf8Bytes = utf8.bytes;\n      for(int tokenPos=0;tokenPos<utf8.length;pos++,tokenPos++) {\n        if (utf8Bytes[tokenPos] != text[pos]) {\n          return false;\n        }\n      }\n      return true;\n    } else {\n      return false;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"5d6c52f55ea3ba9a5b1d5a6dd17f79bc7d308392":["955c32f886db6f6356c9fcdea6b1f1cb4effda24"],"6c18273ea5b3974d2f30117f46f1ae416c28f727":["955c32f886db6f6356c9fcdea6b1f1cb4effda24"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"955c32f886db6f6356c9fcdea6b1f1cb4effda24":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["6c18273ea5b3974d2f30117f46f1ae416c28f727","5d6c52f55ea3ba9a5b1d5a6dd17f79bc7d308392"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["5d6c52f55ea3ba9a5b1d5a6dd17f79bc7d308392"]},"commit2Childs":{"5d6c52f55ea3ba9a5b1d5a6dd17f79bc7d308392":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"6c18273ea5b3974d2f30117f46f1ae416c28f727":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["955c32f886db6f6356c9fcdea6b1f1cb4effda24"],"955c32f886db6f6356c9fcdea6b1f1cb4effda24":["5d6c52f55ea3ba9a5b1d5a6dd17f79bc7d308392","6c18273ea5b3974d2f30117f46f1ae416c28f727"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}