{"path":"solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","commits":[{"id":"c903c3d15906a3da96b8c0c2fb704491005fdbdb","date":1453508227,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    String fldLst = params.get(TermVectorParams.FIELDS);\n    if (fldLst == null) {\n      fldLst = params.get(CommonParams.FL);\n    }\n\n    //use this to validate our fields\n    IndexSchema schema = rb.req.getSchema();\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    //we have specific fields to retrieve\n    if (fldLst != null) {\n      String [] fields = SolrPluginUtils.split(fldLst);\n      for (String field : fields) {\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions()){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets()){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n    boolean hasWarnings = false;\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n    //Only load the id field to get the uniqueKey of that field\n    SetBasedFieldSelector fieldSelector = new SetBasedFieldSelector(Collections.singleton(uniqFieldName), Collections.<String>emptySet());\n    TVMapper mapper = new TVMapper(reader);\n    mapper.fieldOptions = allFields; //this will only stay set if fieldOptions.isEmpty() (in other words, only if the user didn't set any fields)\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n      mapper.docNL = docNL;\n      termVectors.add(\"doc-\" + docId, docNL);\n\n      if (keyField != null) {\n        Document document = reader.document(docId, fieldSelector);\n        Fieldable uniqId = document.getFieldable(uniqFieldName);\n        String uniqVal = null;\n        if (uniqId != null) {\n          uniqVal = keyField.getType().storedToReadable(uniqId);          \n        }\n        if (uniqVal != null) {\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n        }\n      }\n      if (!fieldOptions.isEmpty()) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          mapper.fieldOptions = entry.getValue();\n          reader.getTermFreqVector(docId, entry.getKey(), mapper);\n        }\n      } else {\n        //deal with all fields by using the allFieldMapper\n        reader.getTermFreqVector(docId, mapper);\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    String fldLst = params.get(TermVectorParams.FIELDS);\n    if (fldLst == null) {\n      fldLst = params.get(CommonParams.FL);\n    }\n\n    //use this to validate our fields\n    IndexSchema schema = rb.req.getSchema();\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    //we have specific fields to retrieve\n    if (fldLst != null) {\n      String [] fields = SolrPluginUtils.split(fldLst);\n      for (String field : fields) {\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions()){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets()){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n    boolean hasWarnings = false;\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n    //Only load the id field to get the uniqueKey of that field\n    SetBasedFieldSelector fieldSelector = new SetBasedFieldSelector(Collections.singleton(uniqFieldName), Collections.<String>emptySet());\n    TVMapper mapper = new TVMapper(reader);\n    mapper.fieldOptions = allFields; //this will only stay set if fieldOptions.isEmpty() (in other words, only if the user didn't set any fields)\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n      mapper.docNL = docNL;\n      termVectors.add(\"doc-\" + docId, docNL);\n\n      if (keyField != null) {\n        Document document = reader.document(docId, fieldSelector);\n        Fieldable uniqId = document.getFieldable(uniqFieldName);\n        String uniqVal = null;\n        if (uniqId != null) {\n          uniqVal = keyField.getType().storedToReadable(uniqId);          \n        }\n        if (uniqVal != null) {\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n        }\n      }\n      if (!fieldOptions.isEmpty()) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          mapper.fieldOptions = entry.getValue();\n          reader.getTermFreqVector(docId, entry.getKey(), mapper);\n        }\n      } else {\n        //deal with all fields by using the allFieldMapper\n        reader.getTermFreqVector(docId, mapper);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a258fbb26824fd104ed795e5d9033d2d040049ee","date":1453508252,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    String fldLst = params.get(TermVectorParams.FIELDS);\n    if (fldLst == null) {\n      fldLst = params.get(CommonParams.FL);\n    }\n\n    //use this to validate our fields\n    IndexSchema schema = rb.req.getSchema();\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    //we have specific fields to retrieve\n    if (fldLst != null) {\n      String [] fields = SolrPluginUtils.split(fldLst);\n      for (String field : fields) {\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions()){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets()){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n    boolean hasWarnings = false;\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n    //Only load the id field to get the uniqueKey of that field\n    SetBasedFieldSelector fieldSelector = new SetBasedFieldSelector(Collections.singleton(uniqFieldName), Collections.<String>emptySet());\n    TVMapper mapper = new TVMapper(reader);\n    mapper.fieldOptions = allFields; //this will only stay set if fieldOptions.isEmpty() (in other words, only if the user didn't set any fields)\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n      mapper.docNL = docNL;\n      termVectors.add(\"doc-\" + docId, docNL);\n\n      if (keyField != null) {\n        Document document = reader.document(docId, fieldSelector);\n        Fieldable uniqId = document.getFieldable(uniqFieldName);\n        String uniqVal = null;\n        if (uniqId != null) {\n          uniqVal = keyField.getType().storedToReadable(uniqId);          \n        }\n        if (uniqVal != null) {\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n        }\n      }\n      if (!fieldOptions.isEmpty()) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          mapper.fieldOptions = entry.getValue();\n          reader.getTermFreqVector(docId, entry.getKey(), mapper);\n        }\n      } else {\n        //deal with all fields by using the allFieldMapper\n        reader.getTermFreqVector(docId, mapper);\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    String fldLst = params.get(TermVectorParams.FIELDS);\n    if (fldLst == null) {\n      fldLst = params.get(CommonParams.FL);\n    }\n\n    //use this to validate our fields\n    IndexSchema schema = rb.req.getSchema();\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    //we have specific fields to retrieve\n    if (fldLst != null) {\n      String [] fields = SolrPluginUtils.split(fldLst);\n      for (String field : fields) {\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions()){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets()){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n    boolean hasWarnings = false;\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n    //Only load the id field to get the uniqueKey of that field\n    SetBasedFieldSelector fieldSelector = new SetBasedFieldSelector(Collections.singleton(uniqFieldName), Collections.<String>emptySet());\n    TVMapper mapper = new TVMapper(reader);\n    mapper.fieldOptions = allFields; //this will only stay set if fieldOptions.isEmpty() (in other words, only if the user didn't set any fields)\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n      mapper.docNL = docNL;\n      termVectors.add(\"doc-\" + docId, docNL);\n\n      if (keyField != null) {\n        Document document = reader.document(docId, fieldSelector);\n        Fieldable uniqId = document.getFieldable(uniqFieldName);\n        String uniqVal = null;\n        if (uniqId != null) {\n          uniqVal = keyField.getType().storedToReadable(uniqId);          \n        }\n        if (uniqVal != null) {\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n        }\n      }\n      if (!fieldOptions.isEmpty()) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          mapper.fieldOptions = entry.getValue();\n          reader.getTermFreqVector(docId, entry.getKey(), mapper);\n        }\n      } else {\n        //deal with all fields by using the allFieldMapper\n        reader.getTermFreqVector(docId, mapper);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c26f00b574427b55127e869b935845554afde1fa","date":1310252513,"type":1,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    String fldLst = params.get(TermVectorParams.FIELDS);\n    if (fldLst == null) {\n      fldLst = params.get(CommonParams.FL);\n    }\n\n    //use this to validate our fields\n    IndexSchema schema = rb.req.getSchema();\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    //we have specific fields to retrieve\n    if (fldLst != null) {\n      String [] fields = SolrPluginUtils.split(fldLst);\n      for (String field : fields) {\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions()){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets()){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n    boolean hasWarnings = false;\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n    //Only load the id field to get the uniqueKey of that field\n    SetBasedFieldSelector fieldSelector = new SetBasedFieldSelector(Collections.singleton(uniqFieldName), Collections.<String>emptySet());\n    TVMapper mapper = new TVMapper(reader);\n    mapper.fieldOptions = allFields; //this will only stay set if fieldOptions.isEmpty() (in other words, only if the user didn't set any fields)\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n      mapper.docNL = docNL;\n      termVectors.add(\"doc-\" + docId, docNL);\n\n      if (keyField != null) {\n        Document document = reader.document(docId, fieldSelector);\n        Fieldable uniqId = document.getFieldable(uniqFieldName);\n        String uniqVal = null;\n        if (uniqId != null) {\n          uniqVal = keyField.getType().storedToReadable(uniqId);          \n        }\n        if (uniqVal != null) {\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n        }\n      }\n      if (!fieldOptions.isEmpty()) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          mapper.fieldOptions = entry.getValue();\n          reader.getTermFreqVector(docId, entry.getKey(), mapper);\n        }\n      } else {\n        //deal with all fields by using the allFieldMapper\n        reader.getTermFreqVector(docId, mapper);\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    String fldLst = params.get(TermVectorParams.FIELDS);\n    if (fldLst == null) {\n      fldLst = params.get(CommonParams.FL);\n    }\n\n    //use this to validate our fields\n    IndexSchema schema = rb.req.getSchema();\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    //we have specific fields to retrieve\n    if (fldLst != null) {\n      String [] fields = SolrPluginUtils.split(fldLst);\n      for (String field : fields) {\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions()){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets()){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n    boolean hasWarnings = false;\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n    //Only load the id field to get the uniqueKey of that field\n    SetBasedFieldSelector fieldSelector = new SetBasedFieldSelector(Collections.singleton(uniqFieldName), Collections.<String>emptySet());\n    TVMapper mapper = new TVMapper(reader);\n    mapper.fieldOptions = allFields; //this will only stay set if fieldOptions.isEmpty() (in other words, only if the user didn't set any fields)\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n      mapper.docNL = docNL;\n      termVectors.add(\"doc-\" + docId, docNL);\n\n      if (keyField != null) {\n        Document document = reader.document(docId, fieldSelector);\n        Fieldable uniqId = document.getFieldable(uniqFieldName);\n        String uniqVal = null;\n        if (uniqId != null) {\n          uniqVal = keyField.getType().storedToReadable(uniqId);          \n        }\n        if (uniqVal != null) {\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n        }\n      }\n      if (!fieldOptions.isEmpty()) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          mapper.fieldOptions = entry.getValue();\n          reader.getTermFreqVector(docId, entry.getKey(), mapper);\n        }\n      } else {\n        //deal with all fields by using the allFieldMapper\n        reader.getTermFreqVector(docId, mapper);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1509f151d7692d84fae414b2b799ac06ba60fcb4","date":1314451621,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    String fldLst = params.get(TermVectorParams.FIELDS);\n    if (fldLst == null) {\n      fldLst = params.get(CommonParams.FL);\n    }\n\n    //use this to validate our fields\n    IndexSchema schema = rb.req.getSchema();\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    //we have specific fields to retrieve\n    if (fldLst != null) {\n      String [] fields = SolrPluginUtils.split(fldLst);\n      for (String field : fields) {\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions()){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets()){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n    boolean hasWarnings = false;\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n    //Only load the id field to get the uniqueKey of that\n    //field\n\n    final String finalUniqFieldName = uniqFieldName;\n\n    final List<String> uniqValues = new ArrayList<String>();\n    final StoredFieldVisitor getUniqValue = new StoredFieldVisitor() {\n      @Override \n      public boolean stringField(FieldInfo fieldInfo, IndexInput in, int numUTF8Bytes) throws IOException {\n        if (fieldInfo.name.equals(finalUniqFieldName)) {\n          final byte[] b = new byte[numUTF8Bytes];\n          in.readBytes(b, 0, b.length);\n          uniqValues.add(new String(b, \"UTF-8\"));\n        } else {\n          in.seek(in.getFilePointer() + numUTF8Bytes);\n        }\n        return false;\n      }\n\n      @Override \n      public boolean intField(FieldInfo fieldInfo, int value) throws IOException {\n        if (fieldInfo.name.equals(finalUniqFieldName)) {\n          uniqValues.add(Integer.toString(value));\n        }\n        return false;\n      }\n\n      @Override \n      public boolean longField(FieldInfo fieldInfo, long value) throws IOException {\n        if (fieldInfo.name.equals(finalUniqFieldName)) {\n          uniqValues.add(Long.toString(value));\n        }\n        return false;\n      }\n    };\n\n    TVMapper mapper = new TVMapper(reader);\n    mapper.fieldOptions = allFields; //this will only stay set if fieldOptions.isEmpty() (in other words, only if the user didn't set any fields)\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n      mapper.docNL = docNL;\n      termVectors.add(\"doc-\" + docId, docNL);\n\n      if (keyField != null) {\n        reader.document(docId, getUniqValue);\n        String uniqVal = null;\n        if (uniqValues.size() != 0) {\n          uniqVal = uniqValues.get(0);\n          uniqValues.clear();\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n        }\n      }\n      if (!fieldOptions.isEmpty()) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          mapper.fieldOptions = entry.getValue();\n          reader.getTermFreqVector(docId, entry.getKey(), mapper);\n        }\n      } else {\n        //deal with all fields by using the allFieldMapper\n        reader.getTermFreqVector(docId, mapper);\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    String fldLst = params.get(TermVectorParams.FIELDS);\n    if (fldLst == null) {\n      fldLst = params.get(CommonParams.FL);\n    }\n\n    //use this to validate our fields\n    IndexSchema schema = rb.req.getSchema();\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    //we have specific fields to retrieve\n    if (fldLst != null) {\n      String [] fields = SolrPluginUtils.split(fldLst);\n      for (String field : fields) {\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions()){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets()){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n    boolean hasWarnings = false;\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n    //Only load the id field to get the uniqueKey of that field\n    SetBasedFieldSelector fieldSelector = new SetBasedFieldSelector(Collections.singleton(uniqFieldName), Collections.<String>emptySet());\n    TVMapper mapper = new TVMapper(reader);\n    mapper.fieldOptions = allFields; //this will only stay set if fieldOptions.isEmpty() (in other words, only if the user didn't set any fields)\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n      mapper.docNL = docNL;\n      termVectors.add(\"doc-\" + docId, docNL);\n\n      if (keyField != null) {\n        Document document = reader.document(docId, fieldSelector);\n        Fieldable uniqId = document.getFieldable(uniqFieldName);\n        String uniqVal = null;\n        if (uniqId != null) {\n          uniqVal = keyField.getType().storedToReadable(uniqId);          \n        }\n        if (uniqVal != null) {\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n        }\n      }\n      if (!fieldOptions.isEmpty()) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          mapper.fieldOptions = entry.getValue();\n          reader.getTermFreqVector(docId, entry.getKey(), mapper);\n        }\n      } else {\n        //deal with all fields by using the allFieldMapper\n        reader.getTermFreqVector(docId, mapper);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"06584e6e98d592b34e1329b384182f368d2025e8","date":1320850353,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    String fldLst = params.get(TermVectorParams.FIELDS);\n    if (fldLst == null) {\n      fldLst = params.get(CommonParams.FL);\n    }\n\n    //use this to validate our fields\n    IndexSchema schema = rb.req.getSchema();\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    //we have specific fields to retrieve\n    if (fldLst != null) {\n      String [] fields = SolrPluginUtils.split(fldLst);\n      for (String field : fields) {\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions()){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets()){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n    boolean hasWarnings = false;\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n    //Only load the id field to get the uniqueKey of that\n    //field\n\n    final String finalUniqFieldName = uniqFieldName;\n\n    final List<String> uniqValues = new ArrayList<String>();\n    \n    // TODO: is this required to be single-valued? if so, we should STOP\n    // once we find it...\n    final StoredFieldVisitor getUniqValue = new StoredFieldVisitor() {\n      @Override \n      public void stringField(FieldInfo fieldInfo, String value) throws IOException {\n        uniqValues.add(value);\n      }\n\n      @Override \n      public void intField(FieldInfo fieldInfo, int value) throws IOException {\n        uniqValues.add(Integer.toString(value));\n      }\n\n      @Override \n      public void longField(FieldInfo fieldInfo, long value) throws IOException {\n        uniqValues.add(Long.toString(value));\n      }\n\n      @Override\n      public Status needsField(FieldInfo fieldInfo) throws IOException {\n        return (fieldInfo.name.equals(finalUniqFieldName)) ? Status.YES : Status.NO;\n      }\n    };\n\n    TVMapper mapper = new TVMapper(reader);\n    mapper.fieldOptions = allFields; //this will only stay set if fieldOptions.isEmpty() (in other words, only if the user didn't set any fields)\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n      mapper.docNL = docNL;\n      termVectors.add(\"doc-\" + docId, docNL);\n\n      if (keyField != null) {\n        reader.document(docId, getUniqValue);\n        String uniqVal = null;\n        if (uniqValues.size() != 0) {\n          uniqVal = uniqValues.get(0);\n          uniqValues.clear();\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n        }\n      }\n      if (!fieldOptions.isEmpty()) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          mapper.fieldOptions = entry.getValue();\n          reader.getTermFreqVector(docId, entry.getKey(), mapper);\n        }\n      } else {\n        //deal with all fields by using the allFieldMapper\n        reader.getTermFreqVector(docId, mapper);\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    String fldLst = params.get(TermVectorParams.FIELDS);\n    if (fldLst == null) {\n      fldLst = params.get(CommonParams.FL);\n    }\n\n    //use this to validate our fields\n    IndexSchema schema = rb.req.getSchema();\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    //we have specific fields to retrieve\n    if (fldLst != null) {\n      String [] fields = SolrPluginUtils.split(fldLst);\n      for (String field : fields) {\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions()){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets()){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n    boolean hasWarnings = false;\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n    //Only load the id field to get the uniqueKey of that\n    //field\n\n    final String finalUniqFieldName = uniqFieldName;\n\n    final List<String> uniqValues = new ArrayList<String>();\n    final StoredFieldVisitor getUniqValue = new StoredFieldVisitor() {\n      @Override \n      public boolean stringField(FieldInfo fieldInfo, IndexInput in, int numUTF8Bytes) throws IOException {\n        if (fieldInfo.name.equals(finalUniqFieldName)) {\n          final byte[] b = new byte[numUTF8Bytes];\n          in.readBytes(b, 0, b.length);\n          uniqValues.add(new String(b, \"UTF-8\"));\n        } else {\n          in.seek(in.getFilePointer() + numUTF8Bytes);\n        }\n        return false;\n      }\n\n      @Override \n      public boolean intField(FieldInfo fieldInfo, int value) throws IOException {\n        if (fieldInfo.name.equals(finalUniqFieldName)) {\n          uniqValues.add(Integer.toString(value));\n        }\n        return false;\n      }\n\n      @Override \n      public boolean longField(FieldInfo fieldInfo, long value) throws IOException {\n        if (fieldInfo.name.equals(finalUniqFieldName)) {\n          uniqValues.add(Long.toString(value));\n        }\n        return false;\n      }\n    };\n\n    TVMapper mapper = new TVMapper(reader);\n    mapper.fieldOptions = allFields; //this will only stay set if fieldOptions.isEmpty() (in other words, only if the user didn't set any fields)\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n      mapper.docNL = docNL;\n      termVectors.add(\"doc-\" + docId, docNL);\n\n      if (keyField != null) {\n        reader.document(docId, getUniqValue);\n        String uniqVal = null;\n        if (uniqValues.size() != 0) {\n          uniqVal = uniqValues.get(0);\n          uniqValues.clear();\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n        }\n      }\n      if (!fieldOptions.isEmpty()) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          mapper.fieldOptions = entry.getValue();\n          reader.getTermFreqVector(docId, entry.getKey(), mapper);\n        }\n      } else {\n        //deal with all fields by using the allFieldMapper\n        reader.getTermFreqVector(docId, mapper);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["4d3e8520fd031bab31fd0e4d480e55958bc45efe"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3cc749c053615f5871f3b95715fe292f34e70a53","date":1321470575,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    String fldLst = params.get(TermVectorParams.FIELDS);\n    if (fldLst == null) {\n      fldLst = params.get(CommonParams.FL);\n    }\n\n    //use this to validate our fields\n    IndexSchema schema = rb.req.getSchema();\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    //we have specific fields to retrieve\n    if (fldLst != null) {\n      String [] fields = SolrPluginUtils.split(fldLst);\n      for (String field : fields) {\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions()){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets()){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n    boolean hasWarnings = false;\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n    //Only load the id field to get the uniqueKey of that\n    //field\n\n    final String finalUniqFieldName = uniqFieldName;\n\n    final List<String> uniqValues = new ArrayList<String>();\n    \n    // TODO: is this required to be single-valued? if so, we should STOP\n    // once we find it...\n    final StoredFieldVisitor getUniqValue = new StoredFieldVisitor() {\n      @Override \n      public void stringField(FieldInfo fieldInfo, String value) throws IOException {\n        uniqValues.add(value);\n      }\n\n      @Override \n      public void intField(FieldInfo fieldInfo, int value) throws IOException {\n        uniqValues.add(Integer.toString(value));\n      }\n\n      @Override \n      public void longField(FieldInfo fieldInfo, long value) throws IOException {\n        uniqValues.add(Long.toString(value));\n      }\n\n      @Override\n      public Status needsField(FieldInfo fieldInfo) throws IOException {\n        return (fieldInfo.name.equals(finalUniqFieldName)) ? Status.YES : Status.NO;\n      }\n    };\n\n    TermsEnum termsEnum = null;\n\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n      termVectors.add(\"doc-\" + docId, docNL);\n\n      if (keyField != null) {\n        reader.document(docId, getUniqValue);\n        String uniqVal = null;\n        if (uniqValues.size() != 0) {\n          uniqVal = uniqValues.get(0);\n          uniqValues.clear();\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n        }\n      }\n      if (!fieldOptions.isEmpty()) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          final String field = entry.getKey();\n          final Terms vector = reader.getTermVector(docId, field);\n          if (vector != null) {\n            termsEnum = vector.iterator(termsEnum);\n            mapOneVector(docNL, entry.getValue(), reader, docId, vector.iterator(termsEnum), field);\n          }\n        }\n      } else {\n        // extract all fields\n        final Fields vectors = reader.getTermVectors(docId);\n        final FieldsEnum fieldsEnum = vectors.iterator();\n        String field;\n        while((field = fieldsEnum.next()) != null) {\n          Terms terms = fieldsEnum.terms();\n          if (terms != null) {\n            termsEnum = terms.iterator(termsEnum);\n            mapOneVector(docNL, allFields, reader, docId, termsEnum, field);\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    String fldLst = params.get(TermVectorParams.FIELDS);\n    if (fldLst == null) {\n      fldLst = params.get(CommonParams.FL);\n    }\n\n    //use this to validate our fields\n    IndexSchema schema = rb.req.getSchema();\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    //we have specific fields to retrieve\n    if (fldLst != null) {\n      String [] fields = SolrPluginUtils.split(fldLst);\n      for (String field : fields) {\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions()){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets()){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n    boolean hasWarnings = false;\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n    //Only load the id field to get the uniqueKey of that\n    //field\n\n    final String finalUniqFieldName = uniqFieldName;\n\n    final List<String> uniqValues = new ArrayList<String>();\n    \n    // TODO: is this required to be single-valued? if so, we should STOP\n    // once we find it...\n    final StoredFieldVisitor getUniqValue = new StoredFieldVisitor() {\n      @Override \n      public void stringField(FieldInfo fieldInfo, String value) throws IOException {\n        uniqValues.add(value);\n      }\n\n      @Override \n      public void intField(FieldInfo fieldInfo, int value) throws IOException {\n        uniqValues.add(Integer.toString(value));\n      }\n\n      @Override \n      public void longField(FieldInfo fieldInfo, long value) throws IOException {\n        uniqValues.add(Long.toString(value));\n      }\n\n      @Override\n      public Status needsField(FieldInfo fieldInfo) throws IOException {\n        return (fieldInfo.name.equals(finalUniqFieldName)) ? Status.YES : Status.NO;\n      }\n    };\n\n    TVMapper mapper = new TVMapper(reader);\n    mapper.fieldOptions = allFields; //this will only stay set if fieldOptions.isEmpty() (in other words, only if the user didn't set any fields)\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n      mapper.docNL = docNL;\n      termVectors.add(\"doc-\" + docId, docNL);\n\n      if (keyField != null) {\n        reader.document(docId, getUniqValue);\n        String uniqVal = null;\n        if (uniqValues.size() != 0) {\n          uniqVal = uniqValues.get(0);\n          uniqValues.clear();\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n        }\n      }\n      if (!fieldOptions.isEmpty()) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          mapper.fieldOptions = entry.getValue();\n          reader.getTermFreqVector(docId, entry.getKey(), mapper);\n        }\n      } else {\n        //deal with all fields by using the allFieldMapper\n        reader.getTermFreqVector(docId, mapper);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d08eba3d52b63561ebf936481ce73e6b6a14aa03","date":1333879759,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    String fldLst = params.get(TermVectorParams.FIELDS);\n    if (fldLst == null) {\n      fldLst = params.get(CommonParams.FL);\n    }\n\n    //use this to validate our fields\n    IndexSchema schema = rb.req.getSchema();\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    //we have specific fields to retrieve\n    if (fldLst != null) {\n      String [] fields = SolrPluginUtils.split(fldLst);\n      for (String field : fields) {\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions()){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets()){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n    boolean hasWarnings = false;\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n    //Only load the id field to get the uniqueKey of that\n    //field\n\n    final String finalUniqFieldName = uniqFieldName;\n\n    final List<String> uniqValues = new ArrayList<String>();\n    \n    // TODO: is this required to be single-valued? if so, we should STOP\n    // once we find it...\n    final StoredFieldVisitor getUniqValue = new StoredFieldVisitor() {\n      @Override \n      public void stringField(FieldInfo fieldInfo, String value) throws IOException {\n        uniqValues.add(value);\n      }\n\n      @Override \n      public void intField(FieldInfo fieldInfo, int value) throws IOException {\n        uniqValues.add(Integer.toString(value));\n      }\n\n      @Override \n      public void longField(FieldInfo fieldInfo, long value) throws IOException {\n        uniqValues.add(Long.toString(value));\n      }\n\n      @Override\n      public Status needsField(FieldInfo fieldInfo) throws IOException {\n        return (fieldInfo.name.equals(finalUniqFieldName)) ? Status.YES : Status.NO;\n      }\n    };\n\n    TermsEnum termsEnum = null;\n\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n      termVectors.add(\"doc-\" + docId, docNL);\n\n      if (keyField != null) {\n        reader.document(docId, getUniqValue);\n        String uniqVal = null;\n        if (uniqValues.size() != 0) {\n          uniqVal = uniqValues.get(0);\n          uniqValues.clear();\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n        }\n      }\n      if (!fieldOptions.isEmpty()) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          final String field = entry.getKey();\n          final Terms vector = reader.getTermVector(docId, field);\n          if (vector != null) {\n            termsEnum = vector.iterator(termsEnum);\n            mapOneVector(docNL, entry.getValue(), reader, docId, vector.iterator(termsEnum), field);\n          }\n        }\n      } else {\n        // extract all fields\n        final InvertedFields vectors = reader.getTermVectors(docId);\n        final FieldsEnum fieldsEnum = vectors.iterator();\n        String field;\n        while((field = fieldsEnum.next()) != null) {\n          Terms terms = fieldsEnum.terms();\n          if (terms != null) {\n            termsEnum = terms.iterator(termsEnum);\n            mapOneVector(docNL, allFields, reader, docId, termsEnum, field);\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    String fldLst = params.get(TermVectorParams.FIELDS);\n    if (fldLst == null) {\n      fldLst = params.get(CommonParams.FL);\n    }\n\n    //use this to validate our fields\n    IndexSchema schema = rb.req.getSchema();\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    //we have specific fields to retrieve\n    if (fldLst != null) {\n      String [] fields = SolrPluginUtils.split(fldLst);\n      for (String field : fields) {\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions()){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets()){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n    boolean hasWarnings = false;\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n    //Only load the id field to get the uniqueKey of that\n    //field\n\n    final String finalUniqFieldName = uniqFieldName;\n\n    final List<String> uniqValues = new ArrayList<String>();\n    \n    // TODO: is this required to be single-valued? if so, we should STOP\n    // once we find it...\n    final StoredFieldVisitor getUniqValue = new StoredFieldVisitor() {\n      @Override \n      public void stringField(FieldInfo fieldInfo, String value) throws IOException {\n        uniqValues.add(value);\n      }\n\n      @Override \n      public void intField(FieldInfo fieldInfo, int value) throws IOException {\n        uniqValues.add(Integer.toString(value));\n      }\n\n      @Override \n      public void longField(FieldInfo fieldInfo, long value) throws IOException {\n        uniqValues.add(Long.toString(value));\n      }\n\n      @Override\n      public Status needsField(FieldInfo fieldInfo) throws IOException {\n        return (fieldInfo.name.equals(finalUniqFieldName)) ? Status.YES : Status.NO;\n      }\n    };\n\n    TermsEnum termsEnum = null;\n\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n      termVectors.add(\"doc-\" + docId, docNL);\n\n      if (keyField != null) {\n        reader.document(docId, getUniqValue);\n        String uniqVal = null;\n        if (uniqValues.size() != 0) {\n          uniqVal = uniqValues.get(0);\n          uniqValues.clear();\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n        }\n      }\n      if (!fieldOptions.isEmpty()) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          final String field = entry.getKey();\n          final Terms vector = reader.getTermVector(docId, field);\n          if (vector != null) {\n            termsEnum = vector.iterator(termsEnum);\n            mapOneVector(docNL, entry.getValue(), reader, docId, vector.iterator(termsEnum), field);\n          }\n        }\n      } else {\n        // extract all fields\n        final Fields vectors = reader.getTermVectors(docId);\n        final FieldsEnum fieldsEnum = vectors.iterator();\n        String field;\n        while((field = fieldsEnum.next()) != null) {\n          Terms terms = fieldsEnum.terms();\n          if (terms != null) {\n            termsEnum = terms.iterator(termsEnum);\n            mapOneVector(docNL, allFields, reader, docId, termsEnum, field);\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf","date":1333892281,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    String fldLst = params.get(TermVectorParams.FIELDS);\n    if (fldLst == null) {\n      fldLst = params.get(CommonParams.FL);\n    }\n\n    //use this to validate our fields\n    IndexSchema schema = rb.req.getSchema();\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    //we have specific fields to retrieve\n    if (fldLst != null) {\n      String [] fields = SolrPluginUtils.split(fldLst);\n      for (String field : fields) {\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions()){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets()){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n    boolean hasWarnings = false;\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n    //Only load the id field to get the uniqueKey of that\n    //field\n\n    final String finalUniqFieldName = uniqFieldName;\n\n    final List<String> uniqValues = new ArrayList<String>();\n    \n    // TODO: is this required to be single-valued? if so, we should STOP\n    // once we find it...\n    final StoredFieldVisitor getUniqValue = new StoredFieldVisitor() {\n      @Override \n      public void stringField(FieldInfo fieldInfo, String value) throws IOException {\n        uniqValues.add(value);\n      }\n\n      @Override \n      public void intField(FieldInfo fieldInfo, int value) throws IOException {\n        uniqValues.add(Integer.toString(value));\n      }\n\n      @Override \n      public void longField(FieldInfo fieldInfo, long value) throws IOException {\n        uniqValues.add(Long.toString(value));\n      }\n\n      @Override\n      public Status needsField(FieldInfo fieldInfo) throws IOException {\n        return (fieldInfo.name.equals(finalUniqFieldName)) ? Status.YES : Status.NO;\n      }\n    };\n\n    TermsEnum termsEnum = null;\n\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n      termVectors.add(\"doc-\" + docId, docNL);\n\n      if (keyField != null) {\n        reader.document(docId, getUniqValue);\n        String uniqVal = null;\n        if (uniqValues.size() != 0) {\n          uniqVal = uniqValues.get(0);\n          uniqValues.clear();\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n        }\n      }\n      if (!fieldOptions.isEmpty()) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          final String field = entry.getKey();\n          final Terms vector = reader.getTermVector(docId, field);\n          if (vector != null) {\n            termsEnum = vector.iterator(termsEnum);\n            mapOneVector(docNL, entry.getValue(), reader, docId, vector.iterator(termsEnum), field);\n          }\n        }\n      } else {\n        // extract all fields\n        final Fields vectors = reader.getTermVectors(docId);\n        final FieldsEnum fieldsEnum = vectors.iterator();\n        String field;\n        while((field = fieldsEnum.next()) != null) {\n          Terms terms = fieldsEnum.terms();\n          if (terms != null) {\n            termsEnum = terms.iterator(termsEnum);\n            mapOneVector(docNL, allFields, reader, docId, termsEnum, field);\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    String fldLst = params.get(TermVectorParams.FIELDS);\n    if (fldLst == null) {\n      fldLst = params.get(CommonParams.FL);\n    }\n\n    //use this to validate our fields\n    IndexSchema schema = rb.req.getSchema();\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    //we have specific fields to retrieve\n    if (fldLst != null) {\n      String [] fields = SolrPluginUtils.split(fldLst);\n      for (String field : fields) {\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions()){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets()){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n    boolean hasWarnings = false;\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n    //Only load the id field to get the uniqueKey of that\n    //field\n\n    final String finalUniqFieldName = uniqFieldName;\n\n    final List<String> uniqValues = new ArrayList<String>();\n    \n    // TODO: is this required to be single-valued? if so, we should STOP\n    // once we find it...\n    final StoredFieldVisitor getUniqValue = new StoredFieldVisitor() {\n      @Override \n      public void stringField(FieldInfo fieldInfo, String value) throws IOException {\n        uniqValues.add(value);\n      }\n\n      @Override \n      public void intField(FieldInfo fieldInfo, int value) throws IOException {\n        uniqValues.add(Integer.toString(value));\n      }\n\n      @Override \n      public void longField(FieldInfo fieldInfo, long value) throws IOException {\n        uniqValues.add(Long.toString(value));\n      }\n\n      @Override\n      public Status needsField(FieldInfo fieldInfo) throws IOException {\n        return (fieldInfo.name.equals(finalUniqFieldName)) ? Status.YES : Status.NO;\n      }\n    };\n\n    TermsEnum termsEnum = null;\n\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n      termVectors.add(\"doc-\" + docId, docNL);\n\n      if (keyField != null) {\n        reader.document(docId, getUniqValue);\n        String uniqVal = null;\n        if (uniqValues.size() != 0) {\n          uniqVal = uniqValues.get(0);\n          uniqValues.clear();\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n        }\n      }\n      if (!fieldOptions.isEmpty()) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          final String field = entry.getKey();\n          final Terms vector = reader.getTermVector(docId, field);\n          if (vector != null) {\n            termsEnum = vector.iterator(termsEnum);\n            mapOneVector(docNL, entry.getValue(), reader, docId, vector.iterator(termsEnum), field);\n          }\n        }\n      } else {\n        // extract all fields\n        final InvertedFields vectors = reader.getTermVectors(docId);\n        final FieldsEnum fieldsEnum = vectors.iterator();\n        String field;\n        while((field = fieldsEnum.next()) != null) {\n          Terms terms = fieldsEnum.terms();\n          if (terms != null) {\n            termsEnum = terms.iterator(termsEnum);\n            mapOneVector(docNL, allFields, reader, docId, termsEnum, field);\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d613b5ee68a090ed0e48d760ff0949da8f2443c4","date":1339448928,"type":3,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    //use this to validate our fields\n    IndexSchema schema = rb.req.getSchema();\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    Set<String> fields = getFields(rb);\n    if ( null != fields ) {\n      //we have specific fields to retrieve, or no fields\n      for (String field : fields) {\n\n        // workarround SOLR-3523\n        if (null == field || \"score\".equals(field)) continue; \n\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions()){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets()){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n    boolean hasWarnings = false;\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n    //Only load the id field to get the uniqueKey of that\n    //field\n\n    final String finalUniqFieldName = uniqFieldName;\n\n    final List<String> uniqValues = new ArrayList<String>();\n    \n    // TODO: is this required to be single-valued? if so, we should STOP\n    // once we find it...\n    final StoredFieldVisitor getUniqValue = new StoredFieldVisitor() {\n      @Override \n      public void stringField(FieldInfo fieldInfo, String value) throws IOException {\n        uniqValues.add(value);\n      }\n\n      @Override \n      public void intField(FieldInfo fieldInfo, int value) throws IOException {\n        uniqValues.add(Integer.toString(value));\n      }\n\n      @Override \n      public void longField(FieldInfo fieldInfo, long value) throws IOException {\n        uniqValues.add(Long.toString(value));\n      }\n\n      @Override\n      public Status needsField(FieldInfo fieldInfo) throws IOException {\n        return (fieldInfo.name.equals(finalUniqFieldName)) ? Status.YES : Status.NO;\n      }\n    };\n\n    TermsEnum termsEnum = null;\n\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n      termVectors.add(\"doc-\" + docId, docNL);\n\n      if (keyField != null) {\n        reader.document(docId, getUniqValue);\n        String uniqVal = null;\n        if (uniqValues.size() != 0) {\n          uniqVal = uniqValues.get(0);\n          uniqValues.clear();\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n        }\n      }\n      if ( null != fields ) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          final String field = entry.getKey();\n          final Terms vector = reader.getTermVector(docId, field);\n          if (vector != null) {\n            termsEnum = vector.iterator(termsEnum);\n            mapOneVector(docNL, entry.getValue(), reader, docId, vector.iterator(termsEnum), field);\n          }\n        }\n      } else {\n        // extract all fields\n        final Fields vectors = reader.getTermVectors(docId);\n        final FieldsEnum fieldsEnum = vectors.iterator();\n        String field;\n        while((field = fieldsEnum.next()) != null) {\n          Terms terms = fieldsEnum.terms();\n          if (terms != null) {\n            termsEnum = terms.iterator(termsEnum);\n            mapOneVector(docNL, allFields, reader, docId, termsEnum, field);\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    String fldLst = params.get(TermVectorParams.FIELDS);\n    if (fldLst == null) {\n      fldLst = params.get(CommonParams.FL);\n    }\n\n    //use this to validate our fields\n    IndexSchema schema = rb.req.getSchema();\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    //we have specific fields to retrieve\n    if (fldLst != null) {\n      String [] fields = SolrPluginUtils.split(fldLst);\n      for (String field : fields) {\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions()){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets()){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n    boolean hasWarnings = false;\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n    //Only load the id field to get the uniqueKey of that\n    //field\n\n    final String finalUniqFieldName = uniqFieldName;\n\n    final List<String> uniqValues = new ArrayList<String>();\n    \n    // TODO: is this required to be single-valued? if so, we should STOP\n    // once we find it...\n    final StoredFieldVisitor getUniqValue = new StoredFieldVisitor() {\n      @Override \n      public void stringField(FieldInfo fieldInfo, String value) throws IOException {\n        uniqValues.add(value);\n      }\n\n      @Override \n      public void intField(FieldInfo fieldInfo, int value) throws IOException {\n        uniqValues.add(Integer.toString(value));\n      }\n\n      @Override \n      public void longField(FieldInfo fieldInfo, long value) throws IOException {\n        uniqValues.add(Long.toString(value));\n      }\n\n      @Override\n      public Status needsField(FieldInfo fieldInfo) throws IOException {\n        return (fieldInfo.name.equals(finalUniqFieldName)) ? Status.YES : Status.NO;\n      }\n    };\n\n    TermsEnum termsEnum = null;\n\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n      termVectors.add(\"doc-\" + docId, docNL);\n\n      if (keyField != null) {\n        reader.document(docId, getUniqValue);\n        String uniqVal = null;\n        if (uniqValues.size() != 0) {\n          uniqVal = uniqValues.get(0);\n          uniqValues.clear();\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n        }\n      }\n      if (!fieldOptions.isEmpty()) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          final String field = entry.getKey();\n          final Terms vector = reader.getTermVector(docId, field);\n          if (vector != null) {\n            termsEnum = vector.iterator(termsEnum);\n            mapOneVector(docNL, entry.getValue(), reader, docId, vector.iterator(termsEnum), field);\n          }\n        }\n      } else {\n        // extract all fields\n        final Fields vectors = reader.getTermVectors(docId);\n        final FieldsEnum fieldsEnum = vectors.iterator();\n        String field;\n        while((field = fieldsEnum.next()) != null) {\n          Terms terms = fieldsEnum.terms();\n          if (terms != null) {\n            termsEnum = terms.iterator(termsEnum);\n            mapOneVector(docNL, allFields, reader, docId, termsEnum, field);\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["4e32cd9d49e5cda7e131c54c05d8e970583b7063"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4d3e8520fd031bab31fd0e4d480e55958bc45efe","date":1340901565,"type":3,"author":"Steven Rowe","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    //use this to validate our fields\n    IndexSchema schema = rb.req.getSchema();\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    Set<String> fields = getFields(rb);\n    if ( null != fields ) {\n      //we have specific fields to retrieve, or no fields\n      for (String field : fields) {\n\n        // workarround SOLR-3523\n        if (null == field || \"score\".equals(field)) continue; \n\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions()){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets()){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n    boolean hasWarnings = false;\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n    //Only load the id field to get the uniqueKey of that\n    //field\n\n    final String finalUniqFieldName = uniqFieldName;\n\n    final List<String> uniqValues = new ArrayList<String>();\n    \n    // TODO: is this required to be single-valued? if so, we should STOP\n    // once we find it...\n    final StoredFieldVisitor getUniqValue = new StoredFieldVisitor() {\n      @Override \n      public void stringField(FieldInfo fieldInfo, String value) {\n        uniqValues.add(value);\n      }\n\n      @Override \n      public void intField(FieldInfo fieldInfo, int value) {\n        uniqValues.add(Integer.toString(value));\n      }\n\n      @Override \n      public void longField(FieldInfo fieldInfo, long value) {\n        uniqValues.add(Long.toString(value));\n      }\n\n      @Override\n      public Status needsField(FieldInfo fieldInfo) {\n        return (fieldInfo.name.equals(finalUniqFieldName)) ? Status.YES : Status.NO;\n      }\n    };\n\n    TermsEnum termsEnum = null;\n\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n      termVectors.add(\"doc-\" + docId, docNL);\n\n      if (keyField != null) {\n        reader.document(docId, getUniqValue);\n        String uniqVal = null;\n        if (uniqValues.size() != 0) {\n          uniqVal = uniqValues.get(0);\n          uniqValues.clear();\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n        }\n      }\n      if ( null != fields ) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          final String field = entry.getKey();\n          final Terms vector = reader.getTermVector(docId, field);\n          if (vector != null) {\n            termsEnum = vector.iterator(termsEnum);\n            mapOneVector(docNL, entry.getValue(), reader, docId, vector.iterator(termsEnum), field);\n          }\n        }\n      } else {\n        // extract all fields\n        final Fields vectors = reader.getTermVectors(docId);\n        final FieldsEnum fieldsEnum = vectors.iterator();\n        String field;\n        while((field = fieldsEnum.next()) != null) {\n          Terms terms = fieldsEnum.terms();\n          if (terms != null) {\n            termsEnum = terms.iterator(termsEnum);\n            mapOneVector(docNL, allFields, reader, docId, termsEnum, field);\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    //use this to validate our fields\n    IndexSchema schema = rb.req.getSchema();\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    Set<String> fields = getFields(rb);\n    if ( null != fields ) {\n      //we have specific fields to retrieve, or no fields\n      for (String field : fields) {\n\n        // workarround SOLR-3523\n        if (null == field || \"score\".equals(field)) continue; \n\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions()){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets()){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n    boolean hasWarnings = false;\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n    //Only load the id field to get the uniqueKey of that\n    //field\n\n    final String finalUniqFieldName = uniqFieldName;\n\n    final List<String> uniqValues = new ArrayList<String>();\n    \n    // TODO: is this required to be single-valued? if so, we should STOP\n    // once we find it...\n    final StoredFieldVisitor getUniqValue = new StoredFieldVisitor() {\n      @Override \n      public void stringField(FieldInfo fieldInfo, String value) throws IOException {\n        uniqValues.add(value);\n      }\n\n      @Override \n      public void intField(FieldInfo fieldInfo, int value) throws IOException {\n        uniqValues.add(Integer.toString(value));\n      }\n\n      @Override \n      public void longField(FieldInfo fieldInfo, long value) throws IOException {\n        uniqValues.add(Long.toString(value));\n      }\n\n      @Override\n      public Status needsField(FieldInfo fieldInfo) throws IOException {\n        return (fieldInfo.name.equals(finalUniqFieldName)) ? Status.YES : Status.NO;\n      }\n    };\n\n    TermsEnum termsEnum = null;\n\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n      termVectors.add(\"doc-\" + docId, docNL);\n\n      if (keyField != null) {\n        reader.document(docId, getUniqValue);\n        String uniqVal = null;\n        if (uniqValues.size() != 0) {\n          uniqVal = uniqValues.get(0);\n          uniqValues.clear();\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n        }\n      }\n      if ( null != fields ) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          final String field = entry.getKey();\n          final Terms vector = reader.getTermVector(docId, field);\n          if (vector != null) {\n            termsEnum = vector.iterator(termsEnum);\n            mapOneVector(docNL, entry.getValue(), reader, docId, vector.iterator(termsEnum), field);\n          }\n        }\n      } else {\n        // extract all fields\n        final Fields vectors = reader.getTermVectors(docId);\n        final FieldsEnum fieldsEnum = vectors.iterator();\n        String field;\n        while((field = fieldsEnum.next()) != null) {\n          Terms terms = fieldsEnum.terms();\n          if (terms != null) {\n            termsEnum = terms.iterator(termsEnum);\n            mapOneVector(docNL, allFields, reader, docId, termsEnum, field);\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":["06584e6e98d592b34e1329b384182f368d2025e8"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fe33227f6805edab2036cbb80645cc4e2d1fa424","date":1342713534,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    //use this to validate our fields\n    IndexSchema schema = rb.req.getSchema();\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    Set<String> fields = getFields(rb);\n    if ( null != fields ) {\n      //we have specific fields to retrieve, or no fields\n      for (String field : fields) {\n\n        // workarround SOLR-3523\n        if (null == field || \"score\".equals(field)) continue; \n\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions()){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets()){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n    boolean hasWarnings = false;\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n    //Only load the id field to get the uniqueKey of that\n    //field\n\n    final String finalUniqFieldName = uniqFieldName;\n\n    final List<String> uniqValues = new ArrayList<String>();\n    \n    // TODO: is this required to be single-valued? if so, we should STOP\n    // once we find it...\n    final StoredFieldVisitor getUniqValue = new StoredFieldVisitor() {\n      @Override \n      public void stringField(FieldInfo fieldInfo, String value) {\n        uniqValues.add(value);\n      }\n\n      @Override \n      public void intField(FieldInfo fieldInfo, int value) {\n        uniqValues.add(Integer.toString(value));\n      }\n\n      @Override \n      public void longField(FieldInfo fieldInfo, long value) {\n        uniqValues.add(Long.toString(value));\n      }\n\n      @Override\n      public Status needsField(FieldInfo fieldInfo) {\n        return (fieldInfo.name.equals(finalUniqFieldName)) ? Status.YES : Status.NO;\n      }\n    };\n\n    TermsEnum termsEnum = null;\n\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n      termVectors.add(\"doc-\" + docId, docNL);\n\n      if (keyField != null) {\n        reader.document(docId, getUniqValue);\n        String uniqVal = null;\n        if (uniqValues.size() != 0) {\n          uniqVal = uniqValues.get(0);\n          uniqValues.clear();\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n        }\n      }\n      if ( null != fields ) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          final String field = entry.getKey();\n          final Terms vector = reader.getTermVector(docId, field);\n          if (vector != null) {\n            termsEnum = vector.iterator(termsEnum);\n            mapOneVector(docNL, entry.getValue(), reader, docId, vector.iterator(termsEnum), field);\n          }\n        }\n      } else {\n        // extract all fields\n        final Fields vectors = reader.getTermVectors(docId);\n        final FieldsEnum fieldsEnum = vectors.iterator();\n        String field;\n        while((field = fieldsEnum.next()) != null) {\n          Terms terms = fieldsEnum.terms();\n          if (terms != null) {\n            termsEnum = terms.iterator(termsEnum);\n            mapOneVector(docNL, allFields, reader, docId, termsEnum, field);\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    //use this to validate our fields\n    IndexSchema schema = rb.req.getSchema();\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    Set<String> fields = getFields(rb);\n    if ( null != fields ) {\n      //we have specific fields to retrieve, or no fields\n      for (String field : fields) {\n\n        // workarround SOLR-3523\n        if (null == field || \"score\".equals(field)) continue; \n\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions()){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets()){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n    boolean hasWarnings = false;\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n    //Only load the id field to get the uniqueKey of that\n    //field\n\n    final String finalUniqFieldName = uniqFieldName;\n\n    final List<String> uniqValues = new ArrayList<String>();\n    \n    // TODO: is this required to be single-valued? if so, we should STOP\n    // once we find it...\n    final StoredFieldVisitor getUniqValue = new StoredFieldVisitor() {\n      @Override \n      public void stringField(FieldInfo fieldInfo, String value) throws IOException {\n        uniqValues.add(value);\n      }\n\n      @Override \n      public void intField(FieldInfo fieldInfo, int value) throws IOException {\n        uniqValues.add(Integer.toString(value));\n      }\n\n      @Override \n      public void longField(FieldInfo fieldInfo, long value) throws IOException {\n        uniqValues.add(Long.toString(value));\n      }\n\n      @Override\n      public Status needsField(FieldInfo fieldInfo) throws IOException {\n        return (fieldInfo.name.equals(finalUniqFieldName)) ? Status.YES : Status.NO;\n      }\n    };\n\n    TermsEnum termsEnum = null;\n\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n      termVectors.add(\"doc-\" + docId, docNL);\n\n      if (keyField != null) {\n        reader.document(docId, getUniqValue);\n        String uniqVal = null;\n        if (uniqValues.size() != 0) {\n          uniqVal = uniqValues.get(0);\n          uniqValues.clear();\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n        }\n      }\n      if ( null != fields ) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          final String field = entry.getKey();\n          final Terms vector = reader.getTermVector(docId, field);\n          if (vector != null) {\n            termsEnum = vector.iterator(termsEnum);\n            mapOneVector(docNL, entry.getValue(), reader, docId, vector.iterator(termsEnum), field);\n          }\n        }\n      } else {\n        // extract all fields\n        final Fields vectors = reader.getTermVectors(docId);\n        final FieldsEnum fieldsEnum = vectors.iterator();\n        String field;\n        while((field = fieldsEnum.next()) != null) {\n          Terms terms = fieldsEnum.terms();\n          if (terms != null) {\n            termsEnum = terms.iterator(termsEnum);\n            mapOneVector(docNL, allFields, reader, docId, termsEnum, field);\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ba3a184cc785359756dd0a77bbdb0e4f06bf727b","date":1344450045,"type":3,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n\n    IndexSchema schema = rb.req.getSchema();\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n      termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n    }\n\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    Set<String> fields = getFields(rb);\n    if ( null != fields ) {\n      //we have specific fields to retrieve, or no fields\n      for (String field : fields) {\n\n        // workarround SOLR-3523\n        if (null == field || \"score\".equals(field)) continue; \n\n        // we don't want to issue warnings about the uniqueKey field\n        // since it can cause lots of confusion in distributed requests\n        // where the uniqueKey field is injected into the fl for merging\n        final boolean fieldIsUniqueKey = field.equals(uniqFieldName);\n\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions() && !fieldIsUniqueKey){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets() && !fieldIsUniqueKey){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            if (!fieldIsUniqueKey) noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n\n    // NOTE: currently all typs of warnings are schema driven, and garunteed\n    // to be consistent across all shards - if additional types of warnings \n    // are added that might be differnet between shards, finishStage() needs \n    // to be changed to account for that.\n    boolean hasWarnings = false;\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n\n    //Only load the id field to get the uniqueKey of that\n    //field\n\n    final String finalUniqFieldName = uniqFieldName;\n\n    final List<String> uniqValues = new ArrayList<String>();\n    \n    // TODO: is this required to be single-valued? if so, we should STOP\n    // once we find it...\n    final StoredFieldVisitor getUniqValue = new StoredFieldVisitor() {\n      @Override \n      public void stringField(FieldInfo fieldInfo, String value) {\n        uniqValues.add(value);\n      }\n\n      @Override \n      public void intField(FieldInfo fieldInfo, int value) {\n        uniqValues.add(Integer.toString(value));\n      }\n\n      @Override \n      public void longField(FieldInfo fieldInfo, long value) {\n        uniqValues.add(Long.toString(value));\n      }\n\n      @Override\n      public Status needsField(FieldInfo fieldInfo) {\n        return (fieldInfo.name.equals(finalUniqFieldName)) ? Status.YES : Status.NO;\n      }\n    };\n\n    TermsEnum termsEnum = null;\n\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n\n      if (keyField != null) {\n        reader.document(docId, getUniqValue);\n        String uniqVal = null;\n        if (uniqValues.size() != 0) {\n          uniqVal = uniqValues.get(0);\n          uniqValues.clear();\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(uniqVal, docNL);\n        }\n      } else {\n        // support for schemas w/o a unique key,\n        termVectors.add(\"doc-\" + docId, docNL);\n      }\n\n      if ( null != fields ) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          final String field = entry.getKey();\n          final Terms vector = reader.getTermVector(docId, field);\n          if (vector != null) {\n            termsEnum = vector.iterator(termsEnum);\n            mapOneVector(docNL, entry.getValue(), reader, docId, vector.iterator(termsEnum), field);\n          }\n        }\n      } else {\n        // extract all fields\n        final Fields vectors = reader.getTermVectors(docId);\n        final FieldsEnum fieldsEnum = vectors.iterator();\n        String field;\n        while((field = fieldsEnum.next()) != null) {\n          Terms terms = fieldsEnum.terms();\n          if (terms != null) {\n            termsEnum = terms.iterator(termsEnum);\n            mapOneVector(docNL, allFields, reader, docId, termsEnum, field);\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    //use this to validate our fields\n    IndexSchema schema = rb.req.getSchema();\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    Set<String> fields = getFields(rb);\n    if ( null != fields ) {\n      //we have specific fields to retrieve, or no fields\n      for (String field : fields) {\n\n        // workarround SOLR-3523\n        if (null == field || \"score\".equals(field)) continue; \n\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions()){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets()){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n    boolean hasWarnings = false;\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n    //Only load the id field to get the uniqueKey of that\n    //field\n\n    final String finalUniqFieldName = uniqFieldName;\n\n    final List<String> uniqValues = new ArrayList<String>();\n    \n    // TODO: is this required to be single-valued? if so, we should STOP\n    // once we find it...\n    final StoredFieldVisitor getUniqValue = new StoredFieldVisitor() {\n      @Override \n      public void stringField(FieldInfo fieldInfo, String value) {\n        uniqValues.add(value);\n      }\n\n      @Override \n      public void intField(FieldInfo fieldInfo, int value) {\n        uniqValues.add(Integer.toString(value));\n      }\n\n      @Override \n      public void longField(FieldInfo fieldInfo, long value) {\n        uniqValues.add(Long.toString(value));\n      }\n\n      @Override\n      public Status needsField(FieldInfo fieldInfo) {\n        return (fieldInfo.name.equals(finalUniqFieldName)) ? Status.YES : Status.NO;\n      }\n    };\n\n    TermsEnum termsEnum = null;\n\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n      termVectors.add(\"doc-\" + docId, docNL);\n\n      if (keyField != null) {\n        reader.document(docId, getUniqValue);\n        String uniqVal = null;\n        if (uniqValues.size() != 0) {\n          uniqVal = uniqValues.get(0);\n          uniqValues.clear();\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n        }\n      }\n      if ( null != fields ) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          final String field = entry.getKey();\n          final Terms vector = reader.getTermVector(docId, field);\n          if (vector != null) {\n            termsEnum = vector.iterator(termsEnum);\n            mapOneVector(docNL, entry.getValue(), reader, docId, vector.iterator(termsEnum), field);\n          }\n        }\n      } else {\n        // extract all fields\n        final Fields vectors = reader.getTermVectors(docId);\n        final FieldsEnum fieldsEnum = vectors.iterator();\n        String field;\n        while((field = fieldsEnum.next()) != null) {\n          Terms terms = fieldsEnum.terms();\n          if (terms != null) {\n            termsEnum = terms.iterator(termsEnum);\n            mapOneVector(docNL, allFields, reader, docId, termsEnum, field);\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["4e32cd9d49e5cda7e131c54c05d8e970583b7063"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d6f074e73200c07d54f242d3880a8da5a35ff97b","date":1344507653,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n\n    IndexSchema schema = rb.req.getSchema();\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n      termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n    }\n\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    Set<String> fields = getFields(rb);\n    if ( null != fields ) {\n      //we have specific fields to retrieve, or no fields\n      for (String field : fields) {\n\n        // workarround SOLR-3523\n        if (null == field || \"score\".equals(field)) continue; \n\n        // we don't want to issue warnings about the uniqueKey field\n        // since it can cause lots of confusion in distributed requests\n        // where the uniqueKey field is injected into the fl for merging\n        final boolean fieldIsUniqueKey = field.equals(uniqFieldName);\n\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions() && !fieldIsUniqueKey){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets() && !fieldIsUniqueKey){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            if (!fieldIsUniqueKey) noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n\n    // NOTE: currently all typs of warnings are schema driven, and garunteed\n    // to be consistent across all shards - if additional types of warnings \n    // are added that might be differnet between shards, finishStage() needs \n    // to be changed to account for that.\n    boolean hasWarnings = false;\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n\n    //Only load the id field to get the uniqueKey of that\n    //field\n\n    final String finalUniqFieldName = uniqFieldName;\n\n    final List<String> uniqValues = new ArrayList<String>();\n    \n    // TODO: is this required to be single-valued? if so, we should STOP\n    // once we find it...\n    final StoredFieldVisitor getUniqValue = new StoredFieldVisitor() {\n      @Override \n      public void stringField(FieldInfo fieldInfo, String value) {\n        uniqValues.add(value);\n      }\n\n      @Override \n      public void intField(FieldInfo fieldInfo, int value) {\n        uniqValues.add(Integer.toString(value));\n      }\n\n      @Override \n      public void longField(FieldInfo fieldInfo, long value) {\n        uniqValues.add(Long.toString(value));\n      }\n\n      @Override\n      public Status needsField(FieldInfo fieldInfo) {\n        return (fieldInfo.name.equals(finalUniqFieldName)) ? Status.YES : Status.NO;\n      }\n    };\n\n    TermsEnum termsEnum = null;\n\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n\n      if (keyField != null) {\n        reader.document(docId, getUniqValue);\n        String uniqVal = null;\n        if (uniqValues.size() != 0) {\n          uniqVal = uniqValues.get(0);\n          uniqValues.clear();\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(uniqVal, docNL);\n        }\n      } else {\n        // support for schemas w/o a unique key,\n        termVectors.add(\"doc-\" + docId, docNL);\n      }\n\n      if ( null != fields ) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          final String field = entry.getKey();\n          final Terms vector = reader.getTermVector(docId, field);\n          if (vector != null) {\n            termsEnum = vector.iterator(termsEnum);\n            mapOneVector(docNL, entry.getValue(), reader, docId, vector.iterator(termsEnum), field);\n          }\n        }\n      } else {\n        // extract all fields\n        final Fields vectors = reader.getTermVectors(docId);\n        final FieldsEnum fieldsEnum = vectors.iterator();\n        String field;\n        while((field = fieldsEnum.next()) != null) {\n          Terms terms = fieldsEnum.terms();\n          if (terms != null) {\n            termsEnum = terms.iterator(termsEnum);\n            mapOneVector(docNL, allFields, reader, docId, termsEnum, field);\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    //use this to validate our fields\n    IndexSchema schema = rb.req.getSchema();\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    Set<String> fields = getFields(rb);\n    if ( null != fields ) {\n      //we have specific fields to retrieve, or no fields\n      for (String field : fields) {\n\n        // workarround SOLR-3523\n        if (null == field || \"score\".equals(field)) continue; \n\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions()){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets()){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n    boolean hasWarnings = false;\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n    //Only load the id field to get the uniqueKey of that\n    //field\n\n    final String finalUniqFieldName = uniqFieldName;\n\n    final List<String> uniqValues = new ArrayList<String>();\n    \n    // TODO: is this required to be single-valued? if so, we should STOP\n    // once we find it...\n    final StoredFieldVisitor getUniqValue = new StoredFieldVisitor() {\n      @Override \n      public void stringField(FieldInfo fieldInfo, String value) {\n        uniqValues.add(value);\n      }\n\n      @Override \n      public void intField(FieldInfo fieldInfo, int value) {\n        uniqValues.add(Integer.toString(value));\n      }\n\n      @Override \n      public void longField(FieldInfo fieldInfo, long value) {\n        uniqValues.add(Long.toString(value));\n      }\n\n      @Override\n      public Status needsField(FieldInfo fieldInfo) {\n        return (fieldInfo.name.equals(finalUniqFieldName)) ? Status.YES : Status.NO;\n      }\n    };\n\n    TermsEnum termsEnum = null;\n\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n      termVectors.add(\"doc-\" + docId, docNL);\n\n      if (keyField != null) {\n        reader.document(docId, getUniqValue);\n        String uniqVal = null;\n        if (uniqValues.size() != 0) {\n          uniqVal = uniqValues.get(0);\n          uniqValues.clear();\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n        }\n      }\n      if ( null != fields ) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          final String field = entry.getKey();\n          final Terms vector = reader.getTermVector(docId, field);\n          if (vector != null) {\n            termsEnum = vector.iterator(termsEnum);\n            mapOneVector(docNL, entry.getValue(), reader, docId, vector.iterator(termsEnum), field);\n          }\n        }\n      } else {\n        // extract all fields\n        final Fields vectors = reader.getTermVectors(docId);\n        final FieldsEnum fieldsEnum = vectors.iterator();\n        String field;\n        while((field = fieldsEnum.next()) != null) {\n          Terms terms = fieldsEnum.terms();\n          if (terms != null) {\n            termsEnum = terms.iterator(termsEnum);\n            mapOneVector(docNL, allFields, reader, docId, termsEnum, field);\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fb07ab105350b80ed9d63ca64b117084ed7391bc","date":1344824719,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n\n    IndexSchema schema = rb.req.getSchema();\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n      termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n    }\n\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    Set<String> fields = getFields(rb);\n    if ( null != fields ) {\n      //we have specific fields to retrieve, or no fields\n      for (String field : fields) {\n\n        // workarround SOLR-3523\n        if (null == field || \"score\".equals(field)) continue; \n\n        // we don't want to issue warnings about the uniqueKey field\n        // since it can cause lots of confusion in distributed requests\n        // where the uniqueKey field is injected into the fl for merging\n        final boolean fieldIsUniqueKey = field.equals(uniqFieldName);\n\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions() && !fieldIsUniqueKey){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets() && !fieldIsUniqueKey){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            if (!fieldIsUniqueKey) noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n\n    // NOTE: currently all typs of warnings are schema driven, and garunteed\n    // to be consistent across all shards - if additional types of warnings \n    // are added that might be differnet between shards, finishStage() needs \n    // to be changed to account for that.\n    boolean hasWarnings = false;\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n\n    //Only load the id field to get the uniqueKey of that\n    //field\n\n    final String finalUniqFieldName = uniqFieldName;\n\n    final List<String> uniqValues = new ArrayList<String>();\n    \n    // TODO: is this required to be single-valued? if so, we should STOP\n    // once we find it...\n    final StoredFieldVisitor getUniqValue = new StoredFieldVisitor() {\n      @Override \n      public void stringField(FieldInfo fieldInfo, String value) {\n        uniqValues.add(value);\n      }\n\n      @Override \n      public void intField(FieldInfo fieldInfo, int value) {\n        uniqValues.add(Integer.toString(value));\n      }\n\n      @Override \n      public void longField(FieldInfo fieldInfo, long value) {\n        uniqValues.add(Long.toString(value));\n      }\n\n      @Override\n      public Status needsField(FieldInfo fieldInfo) {\n        return (fieldInfo.name.equals(finalUniqFieldName)) ? Status.YES : Status.NO;\n      }\n    };\n\n    TermsEnum termsEnum = null;\n\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n\n      if (keyField != null) {\n        reader.document(docId, getUniqValue);\n        String uniqVal = null;\n        if (uniqValues.size() != 0) {\n          uniqVal = uniqValues.get(0);\n          uniqValues.clear();\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(uniqVal, docNL);\n        }\n      } else {\n        // support for schemas w/o a unique key,\n        termVectors.add(\"doc-\" + docId, docNL);\n      }\n\n      if ( null != fields ) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          final String field = entry.getKey();\n          final Terms vector = reader.getTermVector(docId, field);\n          if (vector != null) {\n            termsEnum = vector.iterator(termsEnum);\n            mapOneVector(docNL, entry.getValue(), reader, docId, vector.iterator(termsEnum), field);\n          }\n        }\n      } else {\n        // extract all fields\n        final Fields vectors = reader.getTermVectors(docId);\n        for (String field : vectors) {\n          Terms terms = vectors.terms(field);\n          if (terms != null) {\n            termsEnum = terms.iterator(termsEnum);\n            mapOneVector(docNL, allFields, reader, docId, termsEnum, field);\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n\n    IndexSchema schema = rb.req.getSchema();\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n      termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n    }\n\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    Set<String> fields = getFields(rb);\n    if ( null != fields ) {\n      //we have specific fields to retrieve, or no fields\n      for (String field : fields) {\n\n        // workarround SOLR-3523\n        if (null == field || \"score\".equals(field)) continue; \n\n        // we don't want to issue warnings about the uniqueKey field\n        // since it can cause lots of confusion in distributed requests\n        // where the uniqueKey field is injected into the fl for merging\n        final boolean fieldIsUniqueKey = field.equals(uniqFieldName);\n\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions() && !fieldIsUniqueKey){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets() && !fieldIsUniqueKey){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            if (!fieldIsUniqueKey) noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n\n    // NOTE: currently all typs of warnings are schema driven, and garunteed\n    // to be consistent across all shards - if additional types of warnings \n    // are added that might be differnet between shards, finishStage() needs \n    // to be changed to account for that.\n    boolean hasWarnings = false;\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n\n    //Only load the id field to get the uniqueKey of that\n    //field\n\n    final String finalUniqFieldName = uniqFieldName;\n\n    final List<String> uniqValues = new ArrayList<String>();\n    \n    // TODO: is this required to be single-valued? if so, we should STOP\n    // once we find it...\n    final StoredFieldVisitor getUniqValue = new StoredFieldVisitor() {\n      @Override \n      public void stringField(FieldInfo fieldInfo, String value) {\n        uniqValues.add(value);\n      }\n\n      @Override \n      public void intField(FieldInfo fieldInfo, int value) {\n        uniqValues.add(Integer.toString(value));\n      }\n\n      @Override \n      public void longField(FieldInfo fieldInfo, long value) {\n        uniqValues.add(Long.toString(value));\n      }\n\n      @Override\n      public Status needsField(FieldInfo fieldInfo) {\n        return (fieldInfo.name.equals(finalUniqFieldName)) ? Status.YES : Status.NO;\n      }\n    };\n\n    TermsEnum termsEnum = null;\n\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n\n      if (keyField != null) {\n        reader.document(docId, getUniqValue);\n        String uniqVal = null;\n        if (uniqValues.size() != 0) {\n          uniqVal = uniqValues.get(0);\n          uniqValues.clear();\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(uniqVal, docNL);\n        }\n      } else {\n        // support for schemas w/o a unique key,\n        termVectors.add(\"doc-\" + docId, docNL);\n      }\n\n      if ( null != fields ) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          final String field = entry.getKey();\n          final Terms vector = reader.getTermVector(docId, field);\n          if (vector != null) {\n            termsEnum = vector.iterator(termsEnum);\n            mapOneVector(docNL, entry.getValue(), reader, docId, vector.iterator(termsEnum), field);\n          }\n        }\n      } else {\n        // extract all fields\n        final Fields vectors = reader.getTermVectors(docId);\n        final FieldsEnum fieldsEnum = vectors.iterator();\n        String field;\n        while((field = fieldsEnum.next()) != null) {\n          Terms terms = fieldsEnum.terms();\n          if (terms != null) {\n            termsEnum = terms.iterator(termsEnum);\n            mapOneVector(docNL, allFields, reader, docId, termsEnum, field);\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c7869f64c874ebf7f317d22c00baf2b6857797a6","date":1344856617,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n\n    IndexSchema schema = rb.req.getSchema();\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n      termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n    }\n\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    Set<String> fields = getFields(rb);\n    if ( null != fields ) {\n      //we have specific fields to retrieve, or no fields\n      for (String field : fields) {\n\n        // workarround SOLR-3523\n        if (null == field || \"score\".equals(field)) continue; \n\n        // we don't want to issue warnings about the uniqueKey field\n        // since it can cause lots of confusion in distributed requests\n        // where the uniqueKey field is injected into the fl for merging\n        final boolean fieldIsUniqueKey = field.equals(uniqFieldName);\n\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions() && !fieldIsUniqueKey){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets() && !fieldIsUniqueKey){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            if (!fieldIsUniqueKey) noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n\n    // NOTE: currently all typs of warnings are schema driven, and garunteed\n    // to be consistent across all shards - if additional types of warnings \n    // are added that might be differnet between shards, finishStage() needs \n    // to be changed to account for that.\n    boolean hasWarnings = false;\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n\n    //Only load the id field to get the uniqueKey of that\n    //field\n\n    final String finalUniqFieldName = uniqFieldName;\n\n    final List<String> uniqValues = new ArrayList<String>();\n    \n    // TODO: is this required to be single-valued? if so, we should STOP\n    // once we find it...\n    final StoredFieldVisitor getUniqValue = new StoredFieldVisitor() {\n      @Override \n      public void stringField(FieldInfo fieldInfo, String value) {\n        uniqValues.add(value);\n      }\n\n      @Override \n      public void intField(FieldInfo fieldInfo, int value) {\n        uniqValues.add(Integer.toString(value));\n      }\n\n      @Override \n      public void longField(FieldInfo fieldInfo, long value) {\n        uniqValues.add(Long.toString(value));\n      }\n\n      @Override\n      public Status needsField(FieldInfo fieldInfo) {\n        return (fieldInfo.name.equals(finalUniqFieldName)) ? Status.YES : Status.NO;\n      }\n    };\n\n    TermsEnum termsEnum = null;\n\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n\n      if (keyField != null) {\n        reader.document(docId, getUniqValue);\n        String uniqVal = null;\n        if (uniqValues.size() != 0) {\n          uniqVal = uniqValues.get(0);\n          uniqValues.clear();\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(uniqVal, docNL);\n        }\n      } else {\n        // support for schemas w/o a unique key,\n        termVectors.add(\"doc-\" + docId, docNL);\n      }\n\n      if ( null != fields ) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          final String field = entry.getKey();\n          final Terms vector = reader.getTermVector(docId, field);\n          if (vector != null) {\n            termsEnum = vector.iterator(termsEnum);\n            mapOneVector(docNL, entry.getValue(), reader, docId, vector.iterator(termsEnum), field);\n          }\n        }\n      } else {\n        // extract all fields\n        final Fields vectors = reader.getTermVectors(docId);\n        for (String field : vectors) {\n          Terms terms = vectors.terms(field);\n          if (terms != null) {\n            termsEnum = terms.iterator(termsEnum);\n            mapOneVector(docNL, allFields, reader, docId, termsEnum, field);\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    //use this to validate our fields\n    IndexSchema schema = rb.req.getSchema();\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    Set<String> fields = getFields(rb);\n    if ( null != fields ) {\n      //we have specific fields to retrieve, or no fields\n      for (String field : fields) {\n\n        // workarround SOLR-3523\n        if (null == field || \"score\".equals(field)) continue; \n\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions()){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets()){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n    boolean hasWarnings = false;\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n    //Only load the id field to get the uniqueKey of that\n    //field\n\n    final String finalUniqFieldName = uniqFieldName;\n\n    final List<String> uniqValues = new ArrayList<String>();\n    \n    // TODO: is this required to be single-valued? if so, we should STOP\n    // once we find it...\n    final StoredFieldVisitor getUniqValue = new StoredFieldVisitor() {\n      @Override \n      public void stringField(FieldInfo fieldInfo, String value) {\n        uniqValues.add(value);\n      }\n\n      @Override \n      public void intField(FieldInfo fieldInfo, int value) {\n        uniqValues.add(Integer.toString(value));\n      }\n\n      @Override \n      public void longField(FieldInfo fieldInfo, long value) {\n        uniqValues.add(Long.toString(value));\n      }\n\n      @Override\n      public Status needsField(FieldInfo fieldInfo) {\n        return (fieldInfo.name.equals(finalUniqFieldName)) ? Status.YES : Status.NO;\n      }\n    };\n\n    TermsEnum termsEnum = null;\n\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n      termVectors.add(\"doc-\" + docId, docNL);\n\n      if (keyField != null) {\n        reader.document(docId, getUniqValue);\n        String uniqVal = null;\n        if (uniqValues.size() != 0) {\n          uniqVal = uniqValues.get(0);\n          uniqValues.clear();\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n        }\n      }\n      if ( null != fields ) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          final String field = entry.getKey();\n          final Terms vector = reader.getTermVector(docId, field);\n          if (vector != null) {\n            termsEnum = vector.iterator(termsEnum);\n            mapOneVector(docNL, entry.getValue(), reader, docId, vector.iterator(termsEnum), field);\n          }\n        }\n      } else {\n        // extract all fields\n        final Fields vectors = reader.getTermVectors(docId);\n        final FieldsEnum fieldsEnum = vectors.iterator();\n        String field;\n        while((field = fieldsEnum.next()) != null) {\n          Terms terms = fieldsEnum.terms();\n          if (terms != null) {\n            termsEnum = terms.iterator(termsEnum);\n            mapOneVector(docNL, allFields, reader, docId, termsEnum, field);\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ba34ddeec9e4ab657150c29a5614a7bfbb53c9","date":1344867506,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n\n    IndexSchema schema = rb.req.getSchema();\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n      termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n    }\n\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    Set<String> fields = getFields(rb);\n    if ( null != fields ) {\n      //we have specific fields to retrieve, or no fields\n      for (String field : fields) {\n\n        // workarround SOLR-3523\n        if (null == field || \"score\".equals(field)) continue; \n\n        // we don't want to issue warnings about the uniqueKey field\n        // since it can cause lots of confusion in distributed requests\n        // where the uniqueKey field is injected into the fl for merging\n        final boolean fieldIsUniqueKey = field.equals(uniqFieldName);\n\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions() && !fieldIsUniqueKey){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets() && !fieldIsUniqueKey){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            if (!fieldIsUniqueKey) noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n\n    // NOTE: currently all typs of warnings are schema driven, and garunteed\n    // to be consistent across all shards - if additional types of warnings \n    // are added that might be differnet between shards, finishStage() needs \n    // to be changed to account for that.\n    boolean hasWarnings = false;\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n\n    //Only load the id field to get the uniqueKey of that\n    //field\n\n    final String finalUniqFieldName = uniqFieldName;\n\n    final List<String> uniqValues = new ArrayList<String>();\n    \n    // TODO: is this required to be single-valued? if so, we should STOP\n    // once we find it...\n    final StoredFieldVisitor getUniqValue = new StoredFieldVisitor() {\n      @Override \n      public void stringField(FieldInfo fieldInfo, String value) {\n        uniqValues.add(value);\n      }\n\n      @Override \n      public void intField(FieldInfo fieldInfo, int value) {\n        uniqValues.add(Integer.toString(value));\n      }\n\n      @Override \n      public void longField(FieldInfo fieldInfo, long value) {\n        uniqValues.add(Long.toString(value));\n      }\n\n      @Override\n      public Status needsField(FieldInfo fieldInfo) {\n        return (fieldInfo.name.equals(finalUniqFieldName)) ? Status.YES : Status.NO;\n      }\n    };\n\n    TermsEnum termsEnum = null;\n\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n\n      if (keyField != null) {\n        reader.document(docId, getUniqValue);\n        String uniqVal = null;\n        if (uniqValues.size() != 0) {\n          uniqVal = uniqValues.get(0);\n          uniqValues.clear();\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(uniqVal, docNL);\n        }\n      } else {\n        // support for schemas w/o a unique key,\n        termVectors.add(\"doc-\" + docId, docNL);\n      }\n\n      if ( null != fields ) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          final String field = entry.getKey();\n          final Terms vector = reader.getTermVector(docId, field);\n          if (vector != null) {\n            termsEnum = vector.iterator(termsEnum);\n            mapOneVector(docNL, entry.getValue(), reader, docId, vector.iterator(termsEnum), field);\n          }\n        }\n      } else {\n        // extract all fields\n        final Fields vectors = reader.getTermVectors(docId);\n        for (String field : vectors) {\n          Terms terms = vectors.terms(field);\n          if (terms != null) {\n            termsEnum = terms.iterator(termsEnum);\n            mapOneVector(docNL, allFields, reader, docId, termsEnum, field);\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n\n    IndexSchema schema = rb.req.getSchema();\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n      termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n    }\n\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    Set<String> fields = getFields(rb);\n    if ( null != fields ) {\n      //we have specific fields to retrieve, or no fields\n      for (String field : fields) {\n\n        // workarround SOLR-3523\n        if (null == field || \"score\".equals(field)) continue; \n\n        // we don't want to issue warnings about the uniqueKey field\n        // since it can cause lots of confusion in distributed requests\n        // where the uniqueKey field is injected into the fl for merging\n        final boolean fieldIsUniqueKey = field.equals(uniqFieldName);\n\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions() && !fieldIsUniqueKey){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets() && !fieldIsUniqueKey){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            if (!fieldIsUniqueKey) noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n\n    // NOTE: currently all typs of warnings are schema driven, and garunteed\n    // to be consistent across all shards - if additional types of warnings \n    // are added that might be differnet between shards, finishStage() needs \n    // to be changed to account for that.\n    boolean hasWarnings = false;\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n\n    //Only load the id field to get the uniqueKey of that\n    //field\n\n    final String finalUniqFieldName = uniqFieldName;\n\n    final List<String> uniqValues = new ArrayList<String>();\n    \n    // TODO: is this required to be single-valued? if so, we should STOP\n    // once we find it...\n    final StoredFieldVisitor getUniqValue = new StoredFieldVisitor() {\n      @Override \n      public void stringField(FieldInfo fieldInfo, String value) {\n        uniqValues.add(value);\n      }\n\n      @Override \n      public void intField(FieldInfo fieldInfo, int value) {\n        uniqValues.add(Integer.toString(value));\n      }\n\n      @Override \n      public void longField(FieldInfo fieldInfo, long value) {\n        uniqValues.add(Long.toString(value));\n      }\n\n      @Override\n      public Status needsField(FieldInfo fieldInfo) {\n        return (fieldInfo.name.equals(finalUniqFieldName)) ? Status.YES : Status.NO;\n      }\n    };\n\n    TermsEnum termsEnum = null;\n\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n\n      if (keyField != null) {\n        reader.document(docId, getUniqValue);\n        String uniqVal = null;\n        if (uniqValues.size() != 0) {\n          uniqVal = uniqValues.get(0);\n          uniqValues.clear();\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(uniqVal, docNL);\n        }\n      } else {\n        // support for schemas w/o a unique key,\n        termVectors.add(\"doc-\" + docId, docNL);\n      }\n\n      if ( null != fields ) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          final String field = entry.getKey();\n          final Terms vector = reader.getTermVector(docId, field);\n          if (vector != null) {\n            termsEnum = vector.iterator(termsEnum);\n            mapOneVector(docNL, entry.getValue(), reader, docId, vector.iterator(termsEnum), field);\n          }\n        }\n      } else {\n        // extract all fields\n        final Fields vectors = reader.getTermVectors(docId);\n        final FieldsEnum fieldsEnum = vectors.iterator();\n        String field;\n        while((field = fieldsEnum.next()) != null) {\n          Terms terms = fieldsEnum.terms();\n          if (terms != null) {\n            termsEnum = terms.iterator(termsEnum);\n            mapOneVector(docNL, allFields, reader, docId, termsEnum, field);\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n\n    IndexSchema schema = rb.req.getSchema();\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n      termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n    }\n\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<>();\n    NamedList<List<String>> warnings = new NamedList<>();\n    List<String>  noTV = new ArrayList<>();\n    List<String>  noPos = new ArrayList<>();\n    List<String>  noOff = new ArrayList<>();\n\n    Set<String> fields = getFields(rb);\n    if ( null != fields ) {\n      //we have specific fields to retrieve, or no fields\n      for (String field : fields) {\n\n        // workarround SOLR-3523\n        if (null == field || \"score\".equals(field)) continue; \n\n        // we don't want to issue warnings about the uniqueKey field\n        // since it can cause lots of confusion in distributed requests\n        // where the uniqueKey field is injected into the fl for merging\n        final boolean fieldIsUniqueKey = field.equals(uniqFieldName);\n\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions() && !fieldIsUniqueKey){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets() && !fieldIsUniqueKey){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            if (!fieldIsUniqueKey) noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n\n    // NOTE: currently all typs of warnings are schema driven, and garunteed\n    // to be consistent across all shards - if additional types of warnings \n    // are added that might be differnet between shards, finishStage() needs \n    // to be changed to account for that.\n    boolean hasWarnings = false;\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n\n    //Only load the id field to get the uniqueKey of that\n    //field\n\n    final String finalUniqFieldName = uniqFieldName;\n\n    final List<String> uniqValues = new ArrayList<>();\n    \n    // TODO: is this required to be single-valued? if so, we should STOP\n    // once we find it...\n    final StoredFieldVisitor getUniqValue = new StoredFieldVisitor() {\n      @Override \n      public void stringField(FieldInfo fieldInfo, String value) {\n        uniqValues.add(value);\n      }\n\n      @Override \n      public void intField(FieldInfo fieldInfo, int value) {\n        uniqValues.add(Integer.toString(value));\n      }\n\n      @Override \n      public void longField(FieldInfo fieldInfo, long value) {\n        uniqValues.add(Long.toString(value));\n      }\n\n      @Override\n      public Status needsField(FieldInfo fieldInfo) {\n        return (fieldInfo.name.equals(finalUniqFieldName)) ? Status.YES : Status.NO;\n      }\n    };\n\n    TermsEnum termsEnum = null;\n\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<>();\n\n      if (keyField != null) {\n        reader.document(docId, getUniqValue);\n        String uniqVal = null;\n        if (uniqValues.size() != 0) {\n          uniqVal = uniqValues.get(0);\n          uniqValues.clear();\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(uniqVal, docNL);\n        }\n      } else {\n        // support for schemas w/o a unique key,\n        termVectors.add(\"doc-\" + docId, docNL);\n      }\n\n      if ( null != fields ) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          final String field = entry.getKey();\n          final Terms vector = reader.getTermVector(docId, field);\n          if (vector != null) {\n            termsEnum = vector.iterator(termsEnum);\n            mapOneVector(docNL, entry.getValue(), reader, docId, vector.iterator(termsEnum), field);\n          }\n        }\n      } else {\n        // extract all fields\n        final Fields vectors = reader.getTermVectors(docId);\n        for (String field : vectors) {\n          Terms terms = vectors.terms(field);\n          if (terms != null) {\n            termsEnum = terms.iterator(termsEnum);\n            mapOneVector(docNL, allFields, reader, docId, termsEnum, field);\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n\n    IndexSchema schema = rb.req.getSchema();\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n      termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n    }\n\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    Set<String> fields = getFields(rb);\n    if ( null != fields ) {\n      //we have specific fields to retrieve, or no fields\n      for (String field : fields) {\n\n        // workarround SOLR-3523\n        if (null == field || \"score\".equals(field)) continue; \n\n        // we don't want to issue warnings about the uniqueKey field\n        // since it can cause lots of confusion in distributed requests\n        // where the uniqueKey field is injected into the fl for merging\n        final boolean fieldIsUniqueKey = field.equals(uniqFieldName);\n\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions() && !fieldIsUniqueKey){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets() && !fieldIsUniqueKey){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            if (!fieldIsUniqueKey) noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n\n    // NOTE: currently all typs of warnings are schema driven, and garunteed\n    // to be consistent across all shards - if additional types of warnings \n    // are added that might be differnet between shards, finishStage() needs \n    // to be changed to account for that.\n    boolean hasWarnings = false;\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n\n    //Only load the id field to get the uniqueKey of that\n    //field\n\n    final String finalUniqFieldName = uniqFieldName;\n\n    final List<String> uniqValues = new ArrayList<String>();\n    \n    // TODO: is this required to be single-valued? if so, we should STOP\n    // once we find it...\n    final StoredFieldVisitor getUniqValue = new StoredFieldVisitor() {\n      @Override \n      public void stringField(FieldInfo fieldInfo, String value) {\n        uniqValues.add(value);\n      }\n\n      @Override \n      public void intField(FieldInfo fieldInfo, int value) {\n        uniqValues.add(Integer.toString(value));\n      }\n\n      @Override \n      public void longField(FieldInfo fieldInfo, long value) {\n        uniqValues.add(Long.toString(value));\n      }\n\n      @Override\n      public Status needsField(FieldInfo fieldInfo) {\n        return (fieldInfo.name.equals(finalUniqFieldName)) ? Status.YES : Status.NO;\n      }\n    };\n\n    TermsEnum termsEnum = null;\n\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n\n      if (keyField != null) {\n        reader.document(docId, getUniqValue);\n        String uniqVal = null;\n        if (uniqValues.size() != 0) {\n          uniqVal = uniqValues.get(0);\n          uniqValues.clear();\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(uniqVal, docNL);\n        }\n      } else {\n        // support for schemas w/o a unique key,\n        termVectors.add(\"doc-\" + docId, docNL);\n      }\n\n      if ( null != fields ) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          final String field = entry.getKey();\n          final Terms vector = reader.getTermVector(docId, field);\n          if (vector != null) {\n            termsEnum = vector.iterator(termsEnum);\n            mapOneVector(docNL, entry.getValue(), reader, docId, vector.iterator(termsEnum), field);\n          }\n        }\n      } else {\n        // extract all fields\n        final Fields vectors = reader.getTermVectors(docId);\n        for (String field : vectors) {\n          Terms terms = vectors.terms(field);\n          if (terms != null) {\n            termsEnum = terms.iterator(termsEnum);\n            mapOneVector(docNL, allFields, reader, docId, termsEnum, field);\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a76608e7f735dce831f49f9b0c6bc13f10adc5a6","date":1427421698,"type":3,"author":"David Wayne Smiley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n\n    IndexSchema schema = rb.req.getSchema();\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n      termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n    }\n\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.payloads = params.getBool(TermVectorParams.PAYLOADS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.payloads = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<>();\n    NamedList<List<String>> warnings = new NamedList<>();\n    List<String>  noTV = new ArrayList<>();\n    List<String>  noPos = new ArrayList<>();\n    List<String>  noOff = new ArrayList<>();\n    List<String>  noPay = new ArrayList<>();\n\n    Set<String> fields = getFields(rb);\n    if ( null != fields ) {\n      //we have specific fields to retrieve, or no fields\n      for (String field : fields) {\n\n        // workarround SOLR-3523\n        if (null == field || \"score\".equals(field)) continue; \n\n        // we don't want to issue warnings about the uniqueKey field\n        // since it can cause lots of confusion in distributed requests\n        // where the uniqueKey field is injected into the fl for merging\n        final boolean fieldIsUniqueKey = field.equals(uniqFieldName);\n\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions() && !fieldIsUniqueKey){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets() && !fieldIsUniqueKey){\n              noOff.add(field);\n            }\n            option.payloads = params.getFieldBool(field, TermVectorParams.PAYLOADS, allFields.payloads);\n            if (option.payloads && !sf.storeTermPayloads() && !fieldIsUniqueKey){\n              noPay.add(field);\n            }\n          } else {//field doesn't have term vectors\n            if (!fieldIsUniqueKey) noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n\n    // NOTE: currently all typs of warnings are schema driven, and garunteed\n    // to be consistent across all shards - if additional types of warnings \n    // are added that might be differnet between shards, finishStage() needs \n    // to be changed to account for that.\n    boolean hasWarnings = false;\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (!noPay.isEmpty()) {\n      warnings.add(\"noPayloads\", noPay);\n      hasWarnings = true;\n    }\n    if (hasWarnings) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n\n    //Only load the id field to get the uniqueKey of that\n    //field\n\n    final String finalUniqFieldName = uniqFieldName;\n\n    final List<String> uniqValues = new ArrayList<>();\n    \n    // TODO: is this required to be single-valued? if so, we should STOP\n    // once we find it...\n    final StoredFieldVisitor getUniqValue = new StoredFieldVisitor() {\n      @Override \n      public void stringField(FieldInfo fieldInfo, String value) {\n        uniqValues.add(value);\n      }\n\n      @Override \n      public void intField(FieldInfo fieldInfo, int value) {\n        uniqValues.add(Integer.toString(value));\n      }\n\n      @Override \n      public void longField(FieldInfo fieldInfo, long value) {\n        uniqValues.add(Long.toString(value));\n      }\n\n      @Override\n      public Status needsField(FieldInfo fieldInfo) {\n        return (fieldInfo.name.equals(finalUniqFieldName)) ? Status.YES : Status.NO;\n      }\n    };\n\n    TermsEnum termsEnum = null;\n\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<>();\n\n      if (keyField != null) {\n        reader.document(docId, getUniqValue);\n        String uniqVal = null;\n        if (uniqValues.size() != 0) {\n          uniqVal = uniqValues.get(0);\n          uniqValues.clear();\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(uniqVal, docNL);\n        }\n      } else {\n        // support for schemas w/o a unique key,\n        termVectors.add(\"doc-\" + docId, docNL);\n      }\n\n      if ( null != fields ) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          final String field = entry.getKey();\n          final Terms vector = reader.getTermVector(docId, field);\n          if (vector != null) {\n            termsEnum = vector.iterator(termsEnum);\n            mapOneVector(docNL, entry.getValue(), reader, docId, vector.iterator(termsEnum), field);\n          }\n        }\n      } else {\n        // extract all fields\n        final Fields vectors = reader.getTermVectors(docId);\n        for (String field : vectors) {\n          Terms terms = vectors.terms(field);\n          if (terms != null) {\n            termsEnum = terms.iterator(termsEnum);\n            mapOneVector(docNL, allFields, reader, docId, termsEnum, field);\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n\n    IndexSchema schema = rb.req.getSchema();\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n      termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n    }\n\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<>();\n    NamedList<List<String>> warnings = new NamedList<>();\n    List<String>  noTV = new ArrayList<>();\n    List<String>  noPos = new ArrayList<>();\n    List<String>  noOff = new ArrayList<>();\n\n    Set<String> fields = getFields(rb);\n    if ( null != fields ) {\n      //we have specific fields to retrieve, or no fields\n      for (String field : fields) {\n\n        // workarround SOLR-3523\n        if (null == field || \"score\".equals(field)) continue; \n\n        // we don't want to issue warnings about the uniqueKey field\n        // since it can cause lots of confusion in distributed requests\n        // where the uniqueKey field is injected into the fl for merging\n        final boolean fieldIsUniqueKey = field.equals(uniqFieldName);\n\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions() && !fieldIsUniqueKey){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets() && !fieldIsUniqueKey){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            if (!fieldIsUniqueKey) noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n\n    // NOTE: currently all typs of warnings are schema driven, and garunteed\n    // to be consistent across all shards - if additional types of warnings \n    // are added that might be differnet between shards, finishStage() needs \n    // to be changed to account for that.\n    boolean hasWarnings = false;\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n\n    //Only load the id field to get the uniqueKey of that\n    //field\n\n    final String finalUniqFieldName = uniqFieldName;\n\n    final List<String> uniqValues = new ArrayList<>();\n    \n    // TODO: is this required to be single-valued? if so, we should STOP\n    // once we find it...\n    final StoredFieldVisitor getUniqValue = new StoredFieldVisitor() {\n      @Override \n      public void stringField(FieldInfo fieldInfo, String value) {\n        uniqValues.add(value);\n      }\n\n      @Override \n      public void intField(FieldInfo fieldInfo, int value) {\n        uniqValues.add(Integer.toString(value));\n      }\n\n      @Override \n      public void longField(FieldInfo fieldInfo, long value) {\n        uniqValues.add(Long.toString(value));\n      }\n\n      @Override\n      public Status needsField(FieldInfo fieldInfo) {\n        return (fieldInfo.name.equals(finalUniqFieldName)) ? Status.YES : Status.NO;\n      }\n    };\n\n    TermsEnum termsEnum = null;\n\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<>();\n\n      if (keyField != null) {\n        reader.document(docId, getUniqValue);\n        String uniqVal = null;\n        if (uniqValues.size() != 0) {\n          uniqVal = uniqValues.get(0);\n          uniqValues.clear();\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(uniqVal, docNL);\n        }\n      } else {\n        // support for schemas w/o a unique key,\n        termVectors.add(\"doc-\" + docId, docNL);\n      }\n\n      if ( null != fields ) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          final String field = entry.getKey();\n          final Terms vector = reader.getTermVector(docId, field);\n          if (vector != null) {\n            termsEnum = vector.iterator(termsEnum);\n            mapOneVector(docNL, entry.getValue(), reader, docId, vector.iterator(termsEnum), field);\n          }\n        }\n      } else {\n        // extract all fields\n        final Fields vectors = reader.getTermVectors(docId);\n        for (String field : vectors) {\n          Terms terms = vectors.terms(field);\n          if (terms != null) {\n            termsEnum = terms.iterator(termsEnum);\n            mapOneVector(docNL, allFields, reader, docId, termsEnum, field);\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["4e32cd9d49e5cda7e131c54c05d8e970583b7063"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":3,"author":"Ryan Ernst","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n\n    IndexSchema schema = rb.req.getSchema();\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n      termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n    }\n\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.payloads = params.getBool(TermVectorParams.PAYLOADS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.payloads = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<>();\n    NamedList<List<String>> warnings = new NamedList<>();\n    List<String>  noTV = new ArrayList<>();\n    List<String>  noPos = new ArrayList<>();\n    List<String>  noOff = new ArrayList<>();\n    List<String>  noPay = new ArrayList<>();\n\n    Set<String> fields = getFields(rb);\n    if ( null != fields ) {\n      //we have specific fields to retrieve, or no fields\n      for (String field : fields) {\n\n        // workarround SOLR-3523\n        if (null == field || \"score\".equals(field)) continue; \n\n        // we don't want to issue warnings about the uniqueKey field\n        // since it can cause lots of confusion in distributed requests\n        // where the uniqueKey field is injected into the fl for merging\n        final boolean fieldIsUniqueKey = field.equals(uniqFieldName);\n\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions() && !fieldIsUniqueKey){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets() && !fieldIsUniqueKey){\n              noOff.add(field);\n            }\n            option.payloads = params.getFieldBool(field, TermVectorParams.PAYLOADS, allFields.payloads);\n            if (option.payloads && !sf.storeTermPayloads() && !fieldIsUniqueKey){\n              noPay.add(field);\n            }\n          } else {//field doesn't have term vectors\n            if (!fieldIsUniqueKey) noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n\n    // NOTE: currently all typs of warnings are schema driven, and garunteed\n    // to be consistent across all shards - if additional types of warnings \n    // are added that might be differnet between shards, finishStage() needs \n    // to be changed to account for that.\n    boolean hasWarnings = false;\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (!noPay.isEmpty()) {\n      warnings.add(\"noPayloads\", noPay);\n      hasWarnings = true;\n    }\n    if (hasWarnings) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n\n    //Only load the id field to get the uniqueKey of that\n    //field\n\n    final String finalUniqFieldName = uniqFieldName;\n\n    final List<String> uniqValues = new ArrayList<>();\n    \n    // TODO: is this required to be single-valued? if so, we should STOP\n    // once we find it...\n    final StoredFieldVisitor getUniqValue = new StoredFieldVisitor() {\n      @Override \n      public void stringField(FieldInfo fieldInfo, String value) {\n        uniqValues.add(value);\n      }\n\n      @Override \n      public void intField(FieldInfo fieldInfo, int value) {\n        uniqValues.add(Integer.toString(value));\n      }\n\n      @Override \n      public void longField(FieldInfo fieldInfo, long value) {\n        uniqValues.add(Long.toString(value));\n      }\n\n      @Override\n      public Status needsField(FieldInfo fieldInfo) {\n        return (fieldInfo.name.equals(finalUniqFieldName)) ? Status.YES : Status.NO;\n      }\n    };\n\n    TermsEnum termsEnum = null;\n\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<>();\n\n      if (keyField != null) {\n        reader.document(docId, getUniqValue);\n        String uniqVal = null;\n        if (uniqValues.size() != 0) {\n          uniqVal = uniqValues.get(0);\n          uniqValues.clear();\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(uniqVal, docNL);\n        }\n      } else {\n        // support for schemas w/o a unique key,\n        termVectors.add(\"doc-\" + docId, docNL);\n      }\n\n      if ( null != fields ) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          final String field = entry.getKey();\n          final Terms vector = reader.getTermVector(docId, field);\n          if (vector != null) {\n            termsEnum = vector.iterator(termsEnum);\n            mapOneVector(docNL, entry.getValue(), reader, docId, vector.iterator(termsEnum), field);\n          }\n        }\n      } else {\n        // extract all fields\n        final Fields vectors = reader.getTermVectors(docId);\n        for (String field : vectors) {\n          Terms terms = vectors.terms(field);\n          if (terms != null) {\n            termsEnum = terms.iterator(termsEnum);\n            mapOneVector(docNL, allFields, reader, docId, termsEnum, field);\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n\n    IndexSchema schema = rb.req.getSchema();\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n      termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n    }\n\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<>();\n    NamedList<List<String>> warnings = new NamedList<>();\n    List<String>  noTV = new ArrayList<>();\n    List<String>  noPos = new ArrayList<>();\n    List<String>  noOff = new ArrayList<>();\n\n    Set<String> fields = getFields(rb);\n    if ( null != fields ) {\n      //we have specific fields to retrieve, or no fields\n      for (String field : fields) {\n\n        // workarround SOLR-3523\n        if (null == field || \"score\".equals(field)) continue; \n\n        // we don't want to issue warnings about the uniqueKey field\n        // since it can cause lots of confusion in distributed requests\n        // where the uniqueKey field is injected into the fl for merging\n        final boolean fieldIsUniqueKey = field.equals(uniqFieldName);\n\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions() && !fieldIsUniqueKey){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets() && !fieldIsUniqueKey){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            if (!fieldIsUniqueKey) noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n\n    // NOTE: currently all typs of warnings are schema driven, and garunteed\n    // to be consistent across all shards - if additional types of warnings \n    // are added that might be differnet between shards, finishStage() needs \n    // to be changed to account for that.\n    boolean hasWarnings = false;\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n\n    //Only load the id field to get the uniqueKey of that\n    //field\n\n    final String finalUniqFieldName = uniqFieldName;\n\n    final List<String> uniqValues = new ArrayList<>();\n    \n    // TODO: is this required to be single-valued? if so, we should STOP\n    // once we find it...\n    final StoredFieldVisitor getUniqValue = new StoredFieldVisitor() {\n      @Override \n      public void stringField(FieldInfo fieldInfo, String value) {\n        uniqValues.add(value);\n      }\n\n      @Override \n      public void intField(FieldInfo fieldInfo, int value) {\n        uniqValues.add(Integer.toString(value));\n      }\n\n      @Override \n      public void longField(FieldInfo fieldInfo, long value) {\n        uniqValues.add(Long.toString(value));\n      }\n\n      @Override\n      public Status needsField(FieldInfo fieldInfo) {\n        return (fieldInfo.name.equals(finalUniqFieldName)) ? Status.YES : Status.NO;\n      }\n    };\n\n    TermsEnum termsEnum = null;\n\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<>();\n\n      if (keyField != null) {\n        reader.document(docId, getUniqValue);\n        String uniqVal = null;\n        if (uniqValues.size() != 0) {\n          uniqVal = uniqValues.get(0);\n          uniqValues.clear();\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(uniqVal, docNL);\n        }\n      } else {\n        // support for schemas w/o a unique key,\n        termVectors.add(\"doc-\" + docId, docNL);\n      }\n\n      if ( null != fields ) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          final String field = entry.getKey();\n          final Terms vector = reader.getTermVector(docId, field);\n          if (vector != null) {\n            termsEnum = vector.iterator(termsEnum);\n            mapOneVector(docNL, entry.getValue(), reader, docId, vector.iterator(termsEnum), field);\n          }\n        }\n      } else {\n        // extract all fields\n        final Fields vectors = reader.getTermVectors(docId);\n        for (String field : vectors) {\n          Terms terms = vectors.terms(field);\n          if (terms != null) {\n            termsEnum = terms.iterator(termsEnum);\n            mapOneVector(docNL, allFields, reader, docId, termsEnum, field);\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82","date":1428522487,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n\n    IndexSchema schema = rb.req.getSchema();\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n      termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n    }\n\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.payloads = params.getBool(TermVectorParams.PAYLOADS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.payloads = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<>();\n    NamedList<List<String>> warnings = new NamedList<>();\n    List<String>  noTV = new ArrayList<>();\n    List<String>  noPos = new ArrayList<>();\n    List<String>  noOff = new ArrayList<>();\n    List<String>  noPay = new ArrayList<>();\n\n    Set<String> fields = getFields(rb);\n    if ( null != fields ) {\n      //we have specific fields to retrieve, or no fields\n      for (String field : fields) {\n\n        // workarround SOLR-3523\n        if (null == field || \"score\".equals(field)) continue; \n\n        // we don't want to issue warnings about the uniqueKey field\n        // since it can cause lots of confusion in distributed requests\n        // where the uniqueKey field is injected into the fl for merging\n        final boolean fieldIsUniqueKey = field.equals(uniqFieldName);\n\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions() && !fieldIsUniqueKey){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets() && !fieldIsUniqueKey){\n              noOff.add(field);\n            }\n            option.payloads = params.getFieldBool(field, TermVectorParams.PAYLOADS, allFields.payloads);\n            if (option.payloads && !sf.storeTermPayloads() && !fieldIsUniqueKey){\n              noPay.add(field);\n            }\n          } else {//field doesn't have term vectors\n            if (!fieldIsUniqueKey) noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n\n    // NOTE: currently all typs of warnings are schema driven, and garunteed\n    // to be consistent across all shards - if additional types of warnings \n    // are added that might be differnet between shards, finishStage() needs \n    // to be changed to account for that.\n    boolean hasWarnings = false;\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (!noPay.isEmpty()) {\n      warnings.add(\"noPayloads\", noPay);\n      hasWarnings = true;\n    }\n    if (hasWarnings) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n\n    //Only load the id field to get the uniqueKey of that\n    //field\n\n    final String finalUniqFieldName = uniqFieldName;\n\n    final List<String> uniqValues = new ArrayList<>();\n    \n    // TODO: is this required to be single-valued? if so, we should STOP\n    // once we find it...\n    final StoredFieldVisitor getUniqValue = new StoredFieldVisitor() {\n      @Override \n      public void stringField(FieldInfo fieldInfo, String value) {\n        uniqValues.add(value);\n      }\n\n      @Override \n      public void intField(FieldInfo fieldInfo, int value) {\n        uniqValues.add(Integer.toString(value));\n      }\n\n      @Override \n      public void longField(FieldInfo fieldInfo, long value) {\n        uniqValues.add(Long.toString(value));\n      }\n\n      @Override\n      public Status needsField(FieldInfo fieldInfo) {\n        return (fieldInfo.name.equals(finalUniqFieldName)) ? Status.YES : Status.NO;\n      }\n    };\n\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<>();\n\n      if (keyField != null) {\n        reader.document(docId, getUniqValue);\n        String uniqVal = null;\n        if (uniqValues.size() != 0) {\n          uniqVal = uniqValues.get(0);\n          uniqValues.clear();\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(uniqVal, docNL);\n        }\n      } else {\n        // support for schemas w/o a unique key,\n        termVectors.add(\"doc-\" + docId, docNL);\n      }\n\n      if ( null != fields ) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          final String field = entry.getKey();\n          final Terms vector = reader.getTermVector(docId, field);\n          if (vector != null) {\n            TermsEnum termsEnum = vector.iterator();\n            mapOneVector(docNL, entry.getValue(), reader, docId, termsEnum, field);\n          }\n        }\n      } else {\n        // extract all fields\n        final Fields vectors = reader.getTermVectors(docId);\n        for (String field : vectors) {\n          Terms terms = vectors.terms(field);\n          if (terms != null) {\n            TermsEnum termsEnum = terms.iterator();\n            mapOneVector(docNL, allFields, reader, docId, termsEnum, field);\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n\n    IndexSchema schema = rb.req.getSchema();\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n      termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n    }\n\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.payloads = params.getBool(TermVectorParams.PAYLOADS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.payloads = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<>();\n    NamedList<List<String>> warnings = new NamedList<>();\n    List<String>  noTV = new ArrayList<>();\n    List<String>  noPos = new ArrayList<>();\n    List<String>  noOff = new ArrayList<>();\n    List<String>  noPay = new ArrayList<>();\n\n    Set<String> fields = getFields(rb);\n    if ( null != fields ) {\n      //we have specific fields to retrieve, or no fields\n      for (String field : fields) {\n\n        // workarround SOLR-3523\n        if (null == field || \"score\".equals(field)) continue; \n\n        // we don't want to issue warnings about the uniqueKey field\n        // since it can cause lots of confusion in distributed requests\n        // where the uniqueKey field is injected into the fl for merging\n        final boolean fieldIsUniqueKey = field.equals(uniqFieldName);\n\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions() && !fieldIsUniqueKey){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets() && !fieldIsUniqueKey){\n              noOff.add(field);\n            }\n            option.payloads = params.getFieldBool(field, TermVectorParams.PAYLOADS, allFields.payloads);\n            if (option.payloads && !sf.storeTermPayloads() && !fieldIsUniqueKey){\n              noPay.add(field);\n            }\n          } else {//field doesn't have term vectors\n            if (!fieldIsUniqueKey) noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n\n    // NOTE: currently all typs of warnings are schema driven, and garunteed\n    // to be consistent across all shards - if additional types of warnings \n    // are added that might be differnet between shards, finishStage() needs \n    // to be changed to account for that.\n    boolean hasWarnings = false;\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (!noPay.isEmpty()) {\n      warnings.add(\"noPayloads\", noPay);\n      hasWarnings = true;\n    }\n    if (hasWarnings) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n\n    //Only load the id field to get the uniqueKey of that\n    //field\n\n    final String finalUniqFieldName = uniqFieldName;\n\n    final List<String> uniqValues = new ArrayList<>();\n    \n    // TODO: is this required to be single-valued? if so, we should STOP\n    // once we find it...\n    final StoredFieldVisitor getUniqValue = new StoredFieldVisitor() {\n      @Override \n      public void stringField(FieldInfo fieldInfo, String value) {\n        uniqValues.add(value);\n      }\n\n      @Override \n      public void intField(FieldInfo fieldInfo, int value) {\n        uniqValues.add(Integer.toString(value));\n      }\n\n      @Override \n      public void longField(FieldInfo fieldInfo, long value) {\n        uniqValues.add(Long.toString(value));\n      }\n\n      @Override\n      public Status needsField(FieldInfo fieldInfo) {\n        return (fieldInfo.name.equals(finalUniqFieldName)) ? Status.YES : Status.NO;\n      }\n    };\n\n    TermsEnum termsEnum = null;\n\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<>();\n\n      if (keyField != null) {\n        reader.document(docId, getUniqValue);\n        String uniqVal = null;\n        if (uniqValues.size() != 0) {\n          uniqVal = uniqValues.get(0);\n          uniqValues.clear();\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(uniqVal, docNL);\n        }\n      } else {\n        // support for schemas w/o a unique key,\n        termVectors.add(\"doc-\" + docId, docNL);\n      }\n\n      if ( null != fields ) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          final String field = entry.getKey();\n          final Terms vector = reader.getTermVector(docId, field);\n          if (vector != null) {\n            termsEnum = vector.iterator(termsEnum);\n            mapOneVector(docNL, entry.getValue(), reader, docId, vector.iterator(termsEnum), field);\n          }\n        }\n      } else {\n        // extract all fields\n        final Fields vectors = reader.getTermVectors(docId);\n        for (String field : vectors) {\n          Terms terms = vectors.terms(field);\n          if (terms != null) {\n            termsEnum = terms.iterator(termsEnum);\n            mapOneVector(docNL, allFields, reader, docId, termsEnum, field);\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"399d127639ae13222a8545b50e0ac545a6bcd2d7","date":1428704686,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n\n    IndexSchema schema = rb.req.getSchema();\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n      termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n    }\n\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.payloads = params.getBool(TermVectorParams.PAYLOADS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.payloads = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<>();\n    NamedList<List<String>> warnings = new NamedList<>();\n    List<String>  noTV = new ArrayList<>();\n    List<String>  noPos = new ArrayList<>();\n    List<String>  noOff = new ArrayList<>();\n    List<String>  noPay = new ArrayList<>();\n\n    Set<String> fields = getFields(rb);\n    if ( null != fields ) {\n      //we have specific fields to retrieve, or no fields\n      for (String field : fields) {\n\n        // workarround SOLR-3523\n        if (null == field || \"score\".equals(field)) continue; \n\n        // we don't want to issue warnings about the uniqueKey field\n        // since it can cause lots of confusion in distributed requests\n        // where the uniqueKey field is injected into the fl for merging\n        final boolean fieldIsUniqueKey = field.equals(uniqFieldName);\n\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions() && !fieldIsUniqueKey){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets() && !fieldIsUniqueKey){\n              noOff.add(field);\n            }\n            option.payloads = params.getFieldBool(field, TermVectorParams.PAYLOADS, allFields.payloads);\n            if (option.payloads && !sf.storeTermPayloads() && !fieldIsUniqueKey){\n              noPay.add(field);\n            }\n          } else {//field doesn't have term vectors\n            if (!fieldIsUniqueKey) noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n\n    // NOTE: currently all typs of warnings are schema driven, and garunteed\n    // to be consistent across all shards - if additional types of warnings \n    // are added that might be differnet between shards, finishStage() needs \n    // to be changed to account for that.\n    boolean hasWarnings = false;\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (!noPay.isEmpty()) {\n      warnings.add(\"noPayloads\", noPay);\n      hasWarnings = true;\n    }\n    if (hasWarnings) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n\n    //Only load the id field to get the uniqueKey of that\n    //field\n\n    final String finalUniqFieldName = uniqFieldName;\n\n    final List<String> uniqValues = new ArrayList<>();\n    \n    // TODO: is this required to be single-valued? if so, we should STOP\n    // once we find it...\n    final StoredFieldVisitor getUniqValue = new StoredFieldVisitor() {\n      @Override \n      public void stringField(FieldInfo fieldInfo, byte[] bytes) {\n        uniqValues.add(new String(bytes, StandardCharsets.UTF_8));\n      }\n\n      @Override \n      public void intField(FieldInfo fieldInfo, int value) {\n        uniqValues.add(Integer.toString(value));\n      }\n\n      @Override \n      public void longField(FieldInfo fieldInfo, long value) {\n        uniqValues.add(Long.toString(value));\n      }\n\n      @Override\n      public Status needsField(FieldInfo fieldInfo) {\n        return (fieldInfo.name.equals(finalUniqFieldName)) ? Status.YES : Status.NO;\n      }\n    };\n\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<>();\n\n      if (keyField != null) {\n        reader.document(docId, getUniqValue);\n        String uniqVal = null;\n        if (uniqValues.size() != 0) {\n          uniqVal = uniqValues.get(0);\n          uniqValues.clear();\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(uniqVal, docNL);\n        }\n      } else {\n        // support for schemas w/o a unique key,\n        termVectors.add(\"doc-\" + docId, docNL);\n      }\n\n      if ( null != fields ) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          final String field = entry.getKey();\n          final Terms vector = reader.getTermVector(docId, field);\n          if (vector != null) {\n            TermsEnum termsEnum = vector.iterator();\n            mapOneVector(docNL, entry.getValue(), reader, docId, termsEnum, field);\n          }\n        }\n      } else {\n        // extract all fields\n        final Fields vectors = reader.getTermVectors(docId);\n        for (String field : vectors) {\n          Terms terms = vectors.terms(field);\n          if (terms != null) {\n            TermsEnum termsEnum = terms.iterator();\n            mapOneVector(docNL, allFields, reader, docId, termsEnum, field);\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n\n    IndexSchema schema = rb.req.getSchema();\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n      termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n    }\n\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.payloads = params.getBool(TermVectorParams.PAYLOADS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.payloads = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<>();\n    NamedList<List<String>> warnings = new NamedList<>();\n    List<String>  noTV = new ArrayList<>();\n    List<String>  noPos = new ArrayList<>();\n    List<String>  noOff = new ArrayList<>();\n    List<String>  noPay = new ArrayList<>();\n\n    Set<String> fields = getFields(rb);\n    if ( null != fields ) {\n      //we have specific fields to retrieve, or no fields\n      for (String field : fields) {\n\n        // workarround SOLR-3523\n        if (null == field || \"score\".equals(field)) continue; \n\n        // we don't want to issue warnings about the uniqueKey field\n        // since it can cause lots of confusion in distributed requests\n        // where the uniqueKey field is injected into the fl for merging\n        final boolean fieldIsUniqueKey = field.equals(uniqFieldName);\n\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions() && !fieldIsUniqueKey){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets() && !fieldIsUniqueKey){\n              noOff.add(field);\n            }\n            option.payloads = params.getFieldBool(field, TermVectorParams.PAYLOADS, allFields.payloads);\n            if (option.payloads && !sf.storeTermPayloads() && !fieldIsUniqueKey){\n              noPay.add(field);\n            }\n          } else {//field doesn't have term vectors\n            if (!fieldIsUniqueKey) noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n\n    // NOTE: currently all typs of warnings are schema driven, and garunteed\n    // to be consistent across all shards - if additional types of warnings \n    // are added that might be differnet between shards, finishStage() needs \n    // to be changed to account for that.\n    boolean hasWarnings = false;\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (!noPay.isEmpty()) {\n      warnings.add(\"noPayloads\", noPay);\n      hasWarnings = true;\n    }\n    if (hasWarnings) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n\n    //Only load the id field to get the uniqueKey of that\n    //field\n\n    final String finalUniqFieldName = uniqFieldName;\n\n    final List<String> uniqValues = new ArrayList<>();\n    \n    // TODO: is this required to be single-valued? if so, we should STOP\n    // once we find it...\n    final StoredFieldVisitor getUniqValue = new StoredFieldVisitor() {\n      @Override \n      public void stringField(FieldInfo fieldInfo, String value) {\n        uniqValues.add(value);\n      }\n\n      @Override \n      public void intField(FieldInfo fieldInfo, int value) {\n        uniqValues.add(Integer.toString(value));\n      }\n\n      @Override \n      public void longField(FieldInfo fieldInfo, long value) {\n        uniqValues.add(Long.toString(value));\n      }\n\n      @Override\n      public Status needsField(FieldInfo fieldInfo) {\n        return (fieldInfo.name.equals(finalUniqFieldName)) ? Status.YES : Status.NO;\n      }\n    };\n\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<>();\n\n      if (keyField != null) {\n        reader.document(docId, getUniqValue);\n        String uniqVal = null;\n        if (uniqValues.size() != 0) {\n          uniqVal = uniqValues.get(0);\n          uniqValues.clear();\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(uniqVal, docNL);\n        }\n      } else {\n        // support for schemas w/o a unique key,\n        termVectors.add(\"doc-\" + docId, docNL);\n      }\n\n      if ( null != fields ) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          final String field = entry.getKey();\n          final Terms vector = reader.getTermVector(docId, field);\n          if (vector != null) {\n            TermsEnum termsEnum = vector.iterator();\n            mapOneVector(docNL, entry.getValue(), reader, docId, termsEnum, field);\n          }\n        }\n      } else {\n        // extract all fields\n        final Fields vectors = reader.getTermVectors(docId);\n        for (String field : vectors) {\n          Terms terms = vectors.terms(field);\n          if (terms != null) {\n            TermsEnum termsEnum = terms.iterator();\n            mapOneVector(docNL, allFields, reader, docId, termsEnum, field);\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4e32cd9d49e5cda7e131c54c05d8e970583b7063","date":1450404956,"type":3,"author":"David Wayne Smiley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n\n    IndexSchema schema = rb.req.getSchema();\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.payloads = params.getBool(TermVectorParams.PAYLOADS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.payloads = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<>();\n    NamedList<List<String>> warnings = new NamedList<>();\n    List<String>  noTV = new ArrayList<>();\n    List<String>  noPos = new ArrayList<>();\n    List<String>  noOff = new ArrayList<>();\n    List<String>  noPay = new ArrayList<>();\n\n    Set<String> fields = getFields(rb);\n    if ( null != fields ) {\n      //we have specific fields to retrieve, or no fields\n      for (String field : fields) {\n\n        // workaround SOLR-3523\n        if (null == field || \"score\".equals(field)) continue; \n\n        // we don't want to issue warnings about the uniqueKey field\n        // since it can cause lots of confusion in distributed requests\n        // where the uniqueKey field is injected into the fl for merging\n        final boolean fieldIsUniqueKey = field.equals(uniqFieldName);\n\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions() && !fieldIsUniqueKey){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets() && !fieldIsUniqueKey){\n              noOff.add(field);\n            }\n            option.payloads = params.getFieldBool(field, TermVectorParams.PAYLOADS, allFields.payloads);\n            if (option.payloads && !sf.storeTermPayloads() && !fieldIsUniqueKey){\n              noPay.add(field);\n            }\n          } else {//field doesn't have term vectors\n            if (!fieldIsUniqueKey) noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n\n    // NOTE: currently all types of warnings are schema driven, and guaranteed\n    // to be consistent across all shards - if additional types of warnings \n    // are added that might be different between shards, finishStage() needs\n    // to be changed to account for that.\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n    }\n    if (!noPay.isEmpty()) {\n      warnings.add(\"noPayloads\", noPay);\n    }\n    if (warnings.size() > 0) {\n      termVectors.add(TV_KEY_WARNINGS, warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n\n    //Only load the id field to get the uniqueKey of that\n    //field\n\n    final String finalUniqFieldName = uniqFieldName;\n\n    final List<String> uniqValues = new ArrayList<>();\n    \n    // TODO: is this required to be single-valued? if so, we should STOP\n    // once we find it...\n    final StoredFieldVisitor getUniqValue = new StoredFieldVisitor() {\n      @Override \n      public void stringField(FieldInfo fieldInfo, byte[] bytes) {\n        uniqValues.add(new String(bytes, StandardCharsets.UTF_8));\n      }\n\n      @Override \n      public void intField(FieldInfo fieldInfo, int value) {\n        uniqValues.add(Integer.toString(value));\n      }\n\n      @Override \n      public void longField(FieldInfo fieldInfo, long value) {\n        uniqValues.add(Long.toString(value));\n      }\n\n      @Override\n      public Status needsField(FieldInfo fieldInfo) {\n        return (fieldInfo.name.equals(finalUniqFieldName)) ? Status.YES : Status.NO;\n      }\n    };\n\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<>();\n\n      if (keyField != null) {\n        reader.document(docId, getUniqValue);\n        String uniqVal = null;\n        if (uniqValues.size() != 0) {\n          uniqVal = uniqValues.get(0);\n          uniqValues.clear();\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(uniqVal, docNL);\n        }\n      } else {\n        // support for schemas w/o a unique key,\n        termVectors.add(\"doc-\" + docId, docNL);\n      }\n\n      if ( null != fields ) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          final String field = entry.getKey();\n          final Terms vector = reader.getTermVector(docId, field);\n          if (vector != null) {\n            TermsEnum termsEnum = vector.iterator();\n            mapOneVector(docNL, entry.getValue(), reader, docId, termsEnum, field);\n          }\n        }\n      } else {\n        // extract all fields\n        final Fields vectors = reader.getTermVectors(docId);\n        for (String field : vectors) {\n          Terms terms = vectors.terms(field);\n          if (terms != null) {\n            TermsEnum termsEnum = terms.iterator();\n            mapOneVector(docNL, allFields, reader, docId, termsEnum, field);\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n\n    IndexSchema schema = rb.req.getSchema();\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n      termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n    }\n\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.payloads = params.getBool(TermVectorParams.PAYLOADS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.payloads = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<>();\n    NamedList<List<String>> warnings = new NamedList<>();\n    List<String>  noTV = new ArrayList<>();\n    List<String>  noPos = new ArrayList<>();\n    List<String>  noOff = new ArrayList<>();\n    List<String>  noPay = new ArrayList<>();\n\n    Set<String> fields = getFields(rb);\n    if ( null != fields ) {\n      //we have specific fields to retrieve, or no fields\n      for (String field : fields) {\n\n        // workarround SOLR-3523\n        if (null == field || \"score\".equals(field)) continue; \n\n        // we don't want to issue warnings about the uniqueKey field\n        // since it can cause lots of confusion in distributed requests\n        // where the uniqueKey field is injected into the fl for merging\n        final boolean fieldIsUniqueKey = field.equals(uniqFieldName);\n\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions() && !fieldIsUniqueKey){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets() && !fieldIsUniqueKey){\n              noOff.add(field);\n            }\n            option.payloads = params.getFieldBool(field, TermVectorParams.PAYLOADS, allFields.payloads);\n            if (option.payloads && !sf.storeTermPayloads() && !fieldIsUniqueKey){\n              noPay.add(field);\n            }\n          } else {//field doesn't have term vectors\n            if (!fieldIsUniqueKey) noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n\n    // NOTE: currently all typs of warnings are schema driven, and garunteed\n    // to be consistent across all shards - if additional types of warnings \n    // are added that might be differnet between shards, finishStage() needs \n    // to be changed to account for that.\n    boolean hasWarnings = false;\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (!noPay.isEmpty()) {\n      warnings.add(\"noPayloads\", noPay);\n      hasWarnings = true;\n    }\n    if (hasWarnings) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n\n    //Only load the id field to get the uniqueKey of that\n    //field\n\n    final String finalUniqFieldName = uniqFieldName;\n\n    final List<String> uniqValues = new ArrayList<>();\n    \n    // TODO: is this required to be single-valued? if so, we should STOP\n    // once we find it...\n    final StoredFieldVisitor getUniqValue = new StoredFieldVisitor() {\n      @Override \n      public void stringField(FieldInfo fieldInfo, byte[] bytes) {\n        uniqValues.add(new String(bytes, StandardCharsets.UTF_8));\n      }\n\n      @Override \n      public void intField(FieldInfo fieldInfo, int value) {\n        uniqValues.add(Integer.toString(value));\n      }\n\n      @Override \n      public void longField(FieldInfo fieldInfo, long value) {\n        uniqValues.add(Long.toString(value));\n      }\n\n      @Override\n      public Status needsField(FieldInfo fieldInfo) {\n        return (fieldInfo.name.equals(finalUniqFieldName)) ? Status.YES : Status.NO;\n      }\n    };\n\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<>();\n\n      if (keyField != null) {\n        reader.document(docId, getUniqValue);\n        String uniqVal = null;\n        if (uniqValues.size() != 0) {\n          uniqVal = uniqValues.get(0);\n          uniqValues.clear();\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(uniqVal, docNL);\n        }\n      } else {\n        // support for schemas w/o a unique key,\n        termVectors.add(\"doc-\" + docId, docNL);\n      }\n\n      if ( null != fields ) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          final String field = entry.getKey();\n          final Terms vector = reader.getTermVector(docId, field);\n          if (vector != null) {\n            TermsEnum termsEnum = vector.iterator();\n            mapOneVector(docNL, entry.getValue(), reader, docId, termsEnum, field);\n          }\n        }\n      } else {\n        // extract all fields\n        final Fields vectors = reader.getTermVectors(docId);\n        for (String field : vectors) {\n          Terms terms = vectors.terms(field);\n          if (terms != null) {\n            TermsEnum termsEnum = terms.iterator();\n            mapOneVector(docNL, allFields, reader, docId, termsEnum, field);\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":["df18b2465217a237531d0d944c22ea4a4316411e","ba3a184cc785359756dd0a77bbdb0e4f06bf727b","b48b42b82c149773b4ccb139507e9bd29da91ca2","d613b5ee68a090ed0e48d760ff0949da8f2443c4","a76608e7f735dce831f49f9b0c6bc13f10adc5a6"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fa4d13fa31a8688899168167cbb4449e399b686f","date":1533611099,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n\n    IndexSchema schema = rb.req.getSchema();\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.payloads = params.getBool(TermVectorParams.PAYLOADS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.payloads = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<>();\n    NamedList<List<String>> warnings = new NamedList<>();\n    List<String>  noTV = new ArrayList<>();\n    List<String>  noPos = new ArrayList<>();\n    List<String>  noOff = new ArrayList<>();\n    List<String>  noPay = new ArrayList<>();\n\n    Set<String> fields = getFields(rb);\n    if ( null != fields ) {\n      //we have specific fields to retrieve, or no fields\n      for (String field : fields) {\n\n        // workaround SOLR-3523\n        if (null == field || \"score\".equals(field)) continue; \n\n        // we don't want to issue warnings about the uniqueKey field\n        // since it can cause lots of confusion in distributed requests\n        // where the uniqueKey field is injected into the fl for merging\n        final boolean fieldIsUniqueKey = field.equals(uniqFieldName);\n\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions() && !fieldIsUniqueKey){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets() && !fieldIsUniqueKey){\n              noOff.add(field);\n            }\n            option.payloads = params.getFieldBool(field, TermVectorParams.PAYLOADS, allFields.payloads);\n            if (option.payloads && !sf.storeTermPayloads() && !fieldIsUniqueKey){\n              noPay.add(field);\n            }\n          } else {//field doesn't have term vectors\n            if (!fieldIsUniqueKey) noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n\n    // NOTE: currently all types of warnings are schema driven, and guaranteed\n    // to be consistent across all shards - if additional types of warnings \n    // are added that might be different between shards, finishStage() needs\n    // to be changed to account for that.\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n    }\n    if (!noPay.isEmpty()) {\n      warnings.add(\"noPayloads\", noPay);\n    }\n    if (warnings.size() > 0) {\n      termVectors.add(TV_KEY_WARNINGS, warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n\n    //Only load the id field to get the uniqueKey of that\n    //field\n    SolrDocumentFetcher docFetcher = searcher.getDocFetcher();\n    SolrReturnFields srf = new SolrReturnFields(uniqFieldName, rb.req);\n    RetrieveFieldsOptimizer retrieveFieldsOptimizer = RetrieveFieldsOptimizer.create(docFetcher, srf);\n\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<>();\n\n      if (keyField != null) {\n        SolrDocument sdoc = null;\n        try {\n          if (retrieveFieldsOptimizer.returnStoredFields()) {\n            Document doc = docFetcher.doc(docId, retrieveFieldsOptimizer.getStoredFields());\n            // make sure to use the schema from the searcher and not the request (cross-core)\n            sdoc = DocsStreamer.convertLuceneDocToSolrDoc(doc, searcher.getSchema(), srf);\n          } else {\n            // no need to get stored fields of the document, see SOLR-5968\n            sdoc = new SolrDocument();\n          }\n\n          // decorate the document with non-stored docValues fields\n          if (retrieveFieldsOptimizer.returnDVFields()) {\n            docFetcher.decorateDocValueFields(sdoc, docId, retrieveFieldsOptimizer.getDvFields());\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error reading document with docId \" + docId, e);\n        }\n        Object val = sdoc.getFieldValue(uniqFieldName);\n        String uniqVal = \"\";\n        if (val instanceof StoredField) {\n          uniqVal = ((StoredField) val).stringValue();\n        } else {\n          uniqVal = val.toString();\n        }\n\n        docNL.add(\"uniqueKey\", uniqVal);\n        termVectors.add(uniqVal, docNL);\n      } else {\n        // support for schemas w/o a unique key,\n        termVectors.add(\"doc-\" + docId, docNL);\n      }\n\n      if (null != fields) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          final String field = entry.getKey();\n          final Terms vector = reader.getTermVector(docId, field);\n          if (vector != null) {\n            TermsEnum termsEnum = vector.iterator();\n            mapOneVector(docNL, entry.getValue(), reader, docId, termsEnum, field);\n          }\n        }\n      } else {\n        // extract all fields\n        final Fields vectors = reader.getTermVectors(docId);\n        // There can be no documents with vectors\n        if (vectors != null) {\n          for (String field : vectors) {\n            Terms terms = vectors.terms(field);\n            if (terms != null) {\n              TermsEnum termsEnum = terms.iterator();\n              mapOneVector(docNL, allFields, reader, docId, termsEnum, field);\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n\n    IndexSchema schema = rb.req.getSchema();\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.payloads = params.getBool(TermVectorParams.PAYLOADS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.payloads = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<>();\n    NamedList<List<String>> warnings = new NamedList<>();\n    List<String>  noTV = new ArrayList<>();\n    List<String>  noPos = new ArrayList<>();\n    List<String>  noOff = new ArrayList<>();\n    List<String>  noPay = new ArrayList<>();\n\n    Set<String> fields = getFields(rb);\n    if ( null != fields ) {\n      //we have specific fields to retrieve, or no fields\n      for (String field : fields) {\n\n        // workaround SOLR-3523\n        if (null == field || \"score\".equals(field)) continue; \n\n        // we don't want to issue warnings about the uniqueKey field\n        // since it can cause lots of confusion in distributed requests\n        // where the uniqueKey field is injected into the fl for merging\n        final boolean fieldIsUniqueKey = field.equals(uniqFieldName);\n\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions() && !fieldIsUniqueKey){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets() && !fieldIsUniqueKey){\n              noOff.add(field);\n            }\n            option.payloads = params.getFieldBool(field, TermVectorParams.PAYLOADS, allFields.payloads);\n            if (option.payloads && !sf.storeTermPayloads() && !fieldIsUniqueKey){\n              noPay.add(field);\n            }\n          } else {//field doesn't have term vectors\n            if (!fieldIsUniqueKey) noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n\n    // NOTE: currently all types of warnings are schema driven, and guaranteed\n    // to be consistent across all shards - if additional types of warnings \n    // are added that might be different between shards, finishStage() needs\n    // to be changed to account for that.\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n    }\n    if (!noPay.isEmpty()) {\n      warnings.add(\"noPayloads\", noPay);\n    }\n    if (warnings.size() > 0) {\n      termVectors.add(TV_KEY_WARNINGS, warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n\n    //Only load the id field to get the uniqueKey of that\n    //field\n\n    final String finalUniqFieldName = uniqFieldName;\n\n    final List<String> uniqValues = new ArrayList<>();\n    \n    // TODO: is this required to be single-valued? if so, we should STOP\n    // once we find it...\n    final StoredFieldVisitor getUniqValue = new StoredFieldVisitor() {\n      @Override \n      public void stringField(FieldInfo fieldInfo, byte[] bytes) {\n        uniqValues.add(new String(bytes, StandardCharsets.UTF_8));\n      }\n\n      @Override \n      public void intField(FieldInfo fieldInfo, int value) {\n        uniqValues.add(Integer.toString(value));\n      }\n\n      @Override \n      public void longField(FieldInfo fieldInfo, long value) {\n        uniqValues.add(Long.toString(value));\n      }\n\n      @Override\n      public Status needsField(FieldInfo fieldInfo) {\n        return (fieldInfo.name.equals(finalUniqFieldName)) ? Status.YES : Status.NO;\n      }\n    };\n\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<>();\n\n      if (keyField != null) {\n        reader.document(docId, getUniqValue);\n        String uniqVal = null;\n        if (uniqValues.size() != 0) {\n          uniqVal = uniqValues.get(0);\n          uniqValues.clear();\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(uniqVal, docNL);\n        }\n      } else {\n        // support for schemas w/o a unique key,\n        termVectors.add(\"doc-\" + docId, docNL);\n      }\n\n      if ( null != fields ) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          final String field = entry.getKey();\n          final Terms vector = reader.getTermVector(docId, field);\n          if (vector != null) {\n            TermsEnum termsEnum = vector.iterator();\n            mapOneVector(docNL, entry.getValue(), reader, docId, termsEnum, field);\n          }\n        }\n      } else {\n        // extract all fields\n        final Fields vectors = reader.getTermVectors(docId);\n        for (String field : vectors) {\n          Terms terms = vectors.terms(field);\n          if (terms != null) {\n            TermsEnum termsEnum = terms.iterator();\n            mapOneVector(docNL, allFields, reader, docId, termsEnum, field);\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"96ecd141e96e7a7a65822d7fada5ddc585b21149","date":1534786652,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n\n    IndexSchema schema = rb.req.getSchema();\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.payloads = params.getBool(TermVectorParams.PAYLOADS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.payloads = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<>();\n    NamedList<List<String>> warnings = new NamedList<>();\n    List<String>  noTV = new ArrayList<>();\n    List<String>  noPos = new ArrayList<>();\n    List<String>  noOff = new ArrayList<>();\n    List<String>  noPay = new ArrayList<>();\n\n    Set<String> fields = getFields(rb);\n    if ( null != fields ) {\n      //we have specific fields to retrieve, or no fields\n      for (String field : fields) {\n\n        // workaround SOLR-3523\n        if (null == field || \"score\".equals(field)) continue; \n\n        // we don't want to issue warnings about the uniqueKey field\n        // since it can cause lots of confusion in distributed requests\n        // where the uniqueKey field is injected into the fl for merging\n        final boolean fieldIsUniqueKey = field.equals(uniqFieldName);\n\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions() && !fieldIsUniqueKey){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets() && !fieldIsUniqueKey){\n              noOff.add(field);\n            }\n            option.payloads = params.getFieldBool(field, TermVectorParams.PAYLOADS, allFields.payloads);\n            if (option.payloads && !sf.storeTermPayloads() && !fieldIsUniqueKey){\n              noPay.add(field);\n            }\n          } else {//field doesn't have term vectors\n            if (!fieldIsUniqueKey) noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n\n    // NOTE: currently all types of warnings are schema driven, and guaranteed\n    // to be consistent across all shards - if additional types of warnings \n    // are added that might be different between shards, finishStage() needs\n    // to be changed to account for that.\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n    }\n    if (!noPay.isEmpty()) {\n      warnings.add(\"noPayloads\", noPay);\n    }\n    if (warnings.size() > 0) {\n      termVectors.add(TV_KEY_WARNINGS, warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n\n    //Only load the id field to get the uniqueKey of that\n    //field\n    SolrDocumentFetcher docFetcher = searcher.getDocFetcher();\n    SolrReturnFields srf = new SolrReturnFields(uniqFieldName, rb.req);\n\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<>();\n\n      if (keyField != null) {\n        // guaranteed to be one and only one since this is uniqueKey!\n        SolrDocument solrDoc = docFetcher.solrDoc(docId, srf);\n\n        String uKey = null;\n        Object val = solrDoc.getFieldValue(uniqFieldName);\n        if (val != null) {\n          if (val instanceof StoredField) {\n            uKey = ((StoredField) val).stringValue();\n          } else {\n            uKey = val.toString();\n          }\n        }\n        assert null != uKey;\n        docNL.add(\"uniqueKey\", uKey);\n        termVectors.add(uKey, docNL);\n      } else {\n        // support for schemas w/o a unique key,\n        termVectors.add(\"doc-\" + docId, docNL);\n      }\n\n      if (null != fields) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          final String field = entry.getKey();\n          final Terms vector = reader.getTermVector(docId, field);\n          if (vector != null) {\n            TermsEnum termsEnum = vector.iterator();\n            mapOneVector(docNL, entry.getValue(), reader, docId, termsEnum, field);\n          }\n        }\n      } else {\n        // extract all fields\n        final Fields vectors = reader.getTermVectors(docId);\n        // There can be no documents with vectors\n        if (vectors != null) {\n          for (String field : vectors) {\n            Terms terms = vectors.terms(field);\n            if (terms != null) {\n              TermsEnum termsEnum = terms.iterator();\n              mapOneVector(docNL, allFields, reader, docId, termsEnum, field);\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n\n    IndexSchema schema = rb.req.getSchema();\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.payloads = params.getBool(TermVectorParams.PAYLOADS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.payloads = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<>();\n    NamedList<List<String>> warnings = new NamedList<>();\n    List<String>  noTV = new ArrayList<>();\n    List<String>  noPos = new ArrayList<>();\n    List<String>  noOff = new ArrayList<>();\n    List<String>  noPay = new ArrayList<>();\n\n    Set<String> fields = getFields(rb);\n    if ( null != fields ) {\n      //we have specific fields to retrieve, or no fields\n      for (String field : fields) {\n\n        // workaround SOLR-3523\n        if (null == field || \"score\".equals(field)) continue; \n\n        // we don't want to issue warnings about the uniqueKey field\n        // since it can cause lots of confusion in distributed requests\n        // where the uniqueKey field is injected into the fl for merging\n        final boolean fieldIsUniqueKey = field.equals(uniqFieldName);\n\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions() && !fieldIsUniqueKey){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets() && !fieldIsUniqueKey){\n              noOff.add(field);\n            }\n            option.payloads = params.getFieldBool(field, TermVectorParams.PAYLOADS, allFields.payloads);\n            if (option.payloads && !sf.storeTermPayloads() && !fieldIsUniqueKey){\n              noPay.add(field);\n            }\n          } else {//field doesn't have term vectors\n            if (!fieldIsUniqueKey) noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n\n    // NOTE: currently all types of warnings are schema driven, and guaranteed\n    // to be consistent across all shards - if additional types of warnings \n    // are added that might be different between shards, finishStage() needs\n    // to be changed to account for that.\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n    }\n    if (!noPay.isEmpty()) {\n      warnings.add(\"noPayloads\", noPay);\n    }\n    if (warnings.size() > 0) {\n      termVectors.add(TV_KEY_WARNINGS, warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n\n    //Only load the id field to get the uniqueKey of that\n    //field\n    SolrDocumentFetcher docFetcher = searcher.getDocFetcher();\n    SolrReturnFields srf = new SolrReturnFields(uniqFieldName, rb.req);\n    RetrieveFieldsOptimizer retrieveFieldsOptimizer = RetrieveFieldsOptimizer.create(docFetcher, srf);\n\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<>();\n\n      if (keyField != null) {\n        SolrDocument sdoc = null;\n        try {\n          if (retrieveFieldsOptimizer.returnStoredFields()) {\n            Document doc = docFetcher.doc(docId, retrieveFieldsOptimizer.getStoredFields());\n            // make sure to use the schema from the searcher and not the request (cross-core)\n            sdoc = DocsStreamer.convertLuceneDocToSolrDoc(doc, searcher.getSchema(), srf);\n          } else {\n            // no need to get stored fields of the document, see SOLR-5968\n            sdoc = new SolrDocument();\n          }\n\n          // decorate the document with non-stored docValues fields\n          if (retrieveFieldsOptimizer.returnDVFields()) {\n            docFetcher.decorateDocValueFields(sdoc, docId, retrieveFieldsOptimizer.getDvFields());\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error reading document with docId \" + docId, e);\n        }\n        Object val = sdoc.getFieldValue(uniqFieldName);\n        String uniqVal = \"\";\n        if (val instanceof StoredField) {\n          uniqVal = ((StoredField) val).stringValue();\n        } else {\n          uniqVal = val.toString();\n        }\n\n        docNL.add(\"uniqueKey\", uniqVal);\n        termVectors.add(uniqVal, docNL);\n      } else {\n        // support for schemas w/o a unique key,\n        termVectors.add(\"doc-\" + docId, docNL);\n      }\n\n      if (null != fields) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          final String field = entry.getKey();\n          final Terms vector = reader.getTermVector(docId, field);\n          if (vector != null) {\n            TermsEnum termsEnum = vector.iterator();\n            mapOneVector(docNL, entry.getValue(), reader, docId, termsEnum, field);\n          }\n        }\n      } else {\n        // extract all fields\n        final Fields vectors = reader.getTermVectors(docId);\n        // There can be no documents with vectors\n        if (vectors != null) {\n          for (String field : vectors) {\n            Terms terms = vectors.terms(field);\n            if (terms != null) {\n              TermsEnum termsEnum = terms.iterator();\n              mapOneVector(docNL, allFields, reader, docId, termsEnum, field);\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1a9aeb4a98b03660f065aa31f6b3f2251a12b613","date":1581405488,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n\n    IndexSchema schema = rb.req.getSchema();\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.payloads = params.getBool(TermVectorParams.PAYLOADS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.payloads = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<>();\n    NamedList<List<String>> warnings = new NamedList<>();\n    List<String>  noTV = new ArrayList<>();\n    List<String>  noPos = new ArrayList<>();\n    List<String>  noOff = new ArrayList<>();\n    List<String>  noPay = new ArrayList<>();\n\n    Set<String> fields = getFields(rb);\n    if ( null != fields ) {\n      //we have specific fields to retrieve, or no fields\n      for (String field : fields) {\n\n        // workaround SOLR-3523\n        if (null == field || \"score\".equals(field)) continue; \n\n        // we don't want to issue warnings about the uniqueKey field\n        // since it can cause lots of confusion in distributed requests\n        // where the uniqueKey field is injected into the fl for merging\n        final boolean fieldIsUniqueKey = field.equals(uniqFieldName);\n\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions() && !fieldIsUniqueKey){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets() && !fieldIsUniqueKey){\n              noOff.add(field);\n            }\n            option.payloads = params.getFieldBool(field, TermVectorParams.PAYLOADS, allFields.payloads);\n            if (option.payloads && !sf.storeTermPayloads() && !fieldIsUniqueKey){\n              noPay.add(field);\n            }\n          } else {//field doesn't have term vectors\n            if (!fieldIsUniqueKey) noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n\n    // NOTE: currently all types of warnings are schema driven, and guaranteed\n    // to be consistent across all shards - if additional types of warnings \n    // are added that might be different between shards, finishStage() needs\n    // to be changed to account for that.\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n    }\n    if (!noPay.isEmpty()) {\n      warnings.add(\"noPayloads\", noPay);\n    }\n    if (warnings.size() > 0) {\n      termVectors.add(TV_KEY_WARNINGS, warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n\n    //Only load the id field to get the uniqueKey of that\n    //field\n    SolrDocumentFetcher docFetcher = searcher.getDocFetcher();\n    SolrReturnFields srf = new SolrReturnFields(uniqFieldName, rb.req);\n\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<>();\n\n      if (keyField != null) {\n        // guaranteed to be one and only one since this is uniqueKey!\n        SolrDocument solrDoc = docFetcher.solrDoc(docId, srf);\n        String uKey = schema.printableUniqueKey(solrDoc);\n        assert null != uKey;\n        docNL.add(\"uniqueKey\", uKey);\n        termVectors.add(uKey, docNL);\n      } else {\n        // support for schemas w/o a unique key,\n        termVectors.add(\"doc-\" + docId, docNL);\n      }\n\n      if (null != fields) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          final String field = entry.getKey();\n          final Terms vector = reader.getTermVector(docId, field);\n          if (vector != null) {\n            TermsEnum termsEnum = vector.iterator();\n            mapOneVector(docNL, entry.getValue(), reader, docId, termsEnum, field);\n          }\n        }\n      } else {\n        // extract all fields\n        final Fields vectors = reader.getTermVectors(docId);\n        // There can be no documents with vectors\n        if (vectors != null) {\n          for (String field : vectors) {\n            Terms terms = vectors.terms(field);\n            if (terms != null) {\n              TermsEnum termsEnum = terms.iterator();\n              mapOneVector(docNL, allFields, reader, docId, termsEnum, field);\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n\n    IndexSchema schema = rb.req.getSchema();\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.payloads = params.getBool(TermVectorParams.PAYLOADS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.payloads = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<>();\n    NamedList<List<String>> warnings = new NamedList<>();\n    List<String>  noTV = new ArrayList<>();\n    List<String>  noPos = new ArrayList<>();\n    List<String>  noOff = new ArrayList<>();\n    List<String>  noPay = new ArrayList<>();\n\n    Set<String> fields = getFields(rb);\n    if ( null != fields ) {\n      //we have specific fields to retrieve, or no fields\n      for (String field : fields) {\n\n        // workaround SOLR-3523\n        if (null == field || \"score\".equals(field)) continue; \n\n        // we don't want to issue warnings about the uniqueKey field\n        // since it can cause lots of confusion in distributed requests\n        // where the uniqueKey field is injected into the fl for merging\n        final boolean fieldIsUniqueKey = field.equals(uniqFieldName);\n\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions() && !fieldIsUniqueKey){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets() && !fieldIsUniqueKey){\n              noOff.add(field);\n            }\n            option.payloads = params.getFieldBool(field, TermVectorParams.PAYLOADS, allFields.payloads);\n            if (option.payloads && !sf.storeTermPayloads() && !fieldIsUniqueKey){\n              noPay.add(field);\n            }\n          } else {//field doesn't have term vectors\n            if (!fieldIsUniqueKey) noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n\n    // NOTE: currently all types of warnings are schema driven, and guaranteed\n    // to be consistent across all shards - if additional types of warnings \n    // are added that might be different between shards, finishStage() needs\n    // to be changed to account for that.\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n    }\n    if (!noPay.isEmpty()) {\n      warnings.add(\"noPayloads\", noPay);\n    }\n    if (warnings.size() > 0) {\n      termVectors.add(TV_KEY_WARNINGS, warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n\n    //Only load the id field to get the uniqueKey of that\n    //field\n    SolrDocumentFetcher docFetcher = searcher.getDocFetcher();\n    SolrReturnFields srf = new SolrReturnFields(uniqFieldName, rb.req);\n\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<>();\n\n      if (keyField != null) {\n        // guaranteed to be one and only one since this is uniqueKey!\n        SolrDocument solrDoc = docFetcher.solrDoc(docId, srf);\n\n        String uKey = null;\n        Object val = solrDoc.getFieldValue(uniqFieldName);\n        if (val != null) {\n          if (val instanceof StoredField) {\n            uKey = ((StoredField) val).stringValue();\n          } else {\n            uKey = val.toString();\n          }\n        }\n        assert null != uKey;\n        docNL.add(\"uniqueKey\", uKey);\n        termVectors.add(uKey, docNL);\n      } else {\n        // support for schemas w/o a unique key,\n        termVectors.add(\"doc-\" + docId, docNL);\n      }\n\n      if (null != fields) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          final String field = entry.getKey();\n          final Terms vector = reader.getTermVector(docId, field);\n          if (vector != null) {\n            TermsEnum termsEnum = vector.iterator();\n            mapOneVector(docNL, entry.getValue(), reader, docId, termsEnum, field);\n          }\n        }\n      } else {\n        // extract all fields\n        final Fields vectors = reader.getTermVectors(docId);\n        // There can be no documents with vectors\n        if (vectors != null) {\n          for (String field : vectors) {\n            Terms terms = vectors.terms(field);\n            if (terms != null) {\n              TermsEnum termsEnum = terms.iterator();\n              mapOneVector(docNL, allFields, reader, docId, termsEnum, field);\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82":["a76608e7f735dce831f49f9b0c6bc13f10adc5a6"],"c26f00b574427b55127e869b935845554afde1fa":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","c903c3d15906a3da96b8c0c2fb704491005fdbdb"],"399d127639ae13222a8545b50e0ac545a6bcd2d7":["0a773283ef5eab2e9c7136eeb66574a4b7a2dc82"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["634f330c54fd3f9f491d52036dc3f40b4f4d8934","a76608e7f735dce831f49f9b0c6bc13f10adc5a6"],"ba3a184cc785359756dd0a77bbdb0e4f06bf727b":["4d3e8520fd031bab31fd0e4d480e55958bc45efe"],"c7869f64c874ebf7f317d22c00baf2b6857797a6":["fe33227f6805edab2036cbb80645cc4e2d1fa424","fb07ab105350b80ed9d63ca64b117084ed7391bc"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf":["d08eba3d52b63561ebf936481ce73e6b6a14aa03"],"4d3e8520fd031bab31fd0e4d480e55958bc45efe":["d613b5ee68a090ed0e48d760ff0949da8f2443c4"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["c26f00b574427b55127e869b935845554afde1fa"],"1a9aeb4a98b03660f065aa31f6b3f2251a12b613":["96ecd141e96e7a7a65822d7fada5ddc585b21149"],"d0ba34ddeec9e4ab657150c29a5614a7bfbb53c9":["d6f074e73200c07d54f242d3880a8da5a35ff97b","fb07ab105350b80ed9d63ca64b117084ed7391bc"],"96ecd141e96e7a7a65822d7fada5ddc585b21149":["fa4d13fa31a8688899168167cbb4449e399b686f"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["fb07ab105350b80ed9d63ca64b117084ed7391bc"],"06584e6e98d592b34e1329b384182f368d2025e8":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"fb07ab105350b80ed9d63ca64b117084ed7391bc":["ba3a184cc785359756dd0a77bbdb0e4f06bf727b"],"d613b5ee68a090ed0e48d760ff0949da8f2443c4":["e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf"],"3cc749c053615f5871f3b95715fe292f34e70a53":["06584e6e98d592b34e1329b384182f368d2025e8"],"d08eba3d52b63561ebf936481ce73e6b6a14aa03":["3cc749c053615f5871f3b95715fe292f34e70a53"],"4e32cd9d49e5cda7e131c54c05d8e970583b7063":["399d127639ae13222a8545b50e0ac545a6bcd2d7"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"fa4d13fa31a8688899168167cbb4449e399b686f":["4e32cd9d49e5cda7e131c54c05d8e970583b7063"],"a76608e7f735dce831f49f9b0c6bc13f10adc5a6":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":["d613b5ee68a090ed0e48d760ff0949da8f2443c4","4d3e8520fd031bab31fd0e4d480e55958bc45efe"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":["4d3e8520fd031bab31fd0e4d480e55958bc45efe","ba3a184cc785359756dd0a77bbdb0e4f06bf727b"],"a258fbb26824fd104ed795e5d9033d2d040049ee":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["1a9aeb4a98b03660f065aa31f6b3f2251a12b613"]},"commit2Childs":{"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82":["399d127639ae13222a8545b50e0ac545a6bcd2d7"],"c26f00b574427b55127e869b935845554afde1fa":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"399d127639ae13222a8545b50e0ac545a6bcd2d7":["4e32cd9d49e5cda7e131c54c05d8e970583b7063"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":[],"ba3a184cc785359756dd0a77bbdb0e4f06bf727b":["fb07ab105350b80ed9d63ca64b117084ed7391bc","d6f074e73200c07d54f242d3880a8da5a35ff97b"],"c7869f64c874ebf7f317d22c00baf2b6857797a6":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c26f00b574427b55127e869b935845554afde1fa","c903c3d15906a3da96b8c0c2fb704491005fdbdb","a258fbb26824fd104ed795e5d9033d2d040049ee"],"e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf":["d613b5ee68a090ed0e48d760ff0949da8f2443c4"],"4d3e8520fd031bab31fd0e4d480e55958bc45efe":["ba3a184cc785359756dd0a77bbdb0e4f06bf727b","fe33227f6805edab2036cbb80645cc4e2d1fa424","d6f074e73200c07d54f242d3880a8da5a35ff97b"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["06584e6e98d592b34e1329b384182f368d2025e8"],"1a9aeb4a98b03660f065aa31f6b3f2251a12b613":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"d0ba34ddeec9e4ab657150c29a5614a7bfbb53c9":[],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","a76608e7f735dce831f49f9b0c6bc13f10adc5a6"],"96ecd141e96e7a7a65822d7fada5ddc585b21149":["1a9aeb4a98b03660f065aa31f6b3f2251a12b613"],"06584e6e98d592b34e1329b384182f368d2025e8":["3cc749c053615f5871f3b95715fe292f34e70a53"],"fb07ab105350b80ed9d63ca64b117084ed7391bc":["c7869f64c874ebf7f317d22c00baf2b6857797a6","d0ba34ddeec9e4ab657150c29a5614a7bfbb53c9","634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"d613b5ee68a090ed0e48d760ff0949da8f2443c4":["4d3e8520fd031bab31fd0e4d480e55958bc45efe","fe33227f6805edab2036cbb80645cc4e2d1fa424"],"3cc749c053615f5871f3b95715fe292f34e70a53":["d08eba3d52b63561ebf936481ce73e6b6a14aa03"],"d08eba3d52b63561ebf936481ce73e6b6a14aa03":["e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf"],"4e32cd9d49e5cda7e131c54c05d8e970583b7063":["fa4d13fa31a8688899168167cbb4449e399b686f"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["c26f00b574427b55127e869b935845554afde1fa"],"a76608e7f735dce831f49f9b0c6bc13f10adc5a6":["0a773283ef5eab2e9c7136eeb66574a4b7a2dc82","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":["c7869f64c874ebf7f317d22c00baf2b6857797a6"],"fa4d13fa31a8688899168167cbb4449e399b686f":["96ecd141e96e7a7a65822d7fada5ddc585b21149"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":["d0ba34ddeec9e4ab657150c29a5614a7bfbb53c9"],"a258fbb26824fd104ed795e5d9033d2d040049ee":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","c7869f64c874ebf7f317d22c00baf2b6857797a6","d0ba34ddeec9e4ab657150c29a5614a7bfbb53c9","a258fbb26824fd104ed795e5d9033d2d040049ee","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}