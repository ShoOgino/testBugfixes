{"path":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/EdgeNGramTokenFilter#EdgeNGramTokenFilter(TokenStream,int,int,boolean).mjava","commits":[{"id":"8a255765a5625ff80fba75863de5a16ea392015e","date":1528161860,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/EdgeNGramTokenFilter#EdgeNGramTokenFilter(TokenStream,int,int,boolean).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Creates an EdgeNGramTokenFilter that, for a given input term, produces all\n   * edge n-grams with lengths &gt;= minGram and &lt;= maxGram. Will\n   * optionally preserve the original term when its length is outside of the\n   * defined range.\n   * \n   * @param input {@link TokenStream} holding the input to be tokenized\n   * @param minGram the minimum length of the generated n-grams\n   * @param maxGram the maximum length of the generated n-grams\n   * @param preserveOriginal Whether or not to keep the original term when it\n   * is outside the min/max size range.\n   */\n  public EdgeNGramTokenFilter(\n      TokenStream input, int minGram, int maxGram, boolean preserveOriginal) {\n    super(input);\n\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n    this.preserveOriginal = preserveOriginal;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f592209545c71895260367152601e9200399776d","date":1528238935,"type":1,"author":"Michael Braun","isMerge":true,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/EdgeNGramTokenFilter#EdgeNGramTokenFilter(TokenStream,int,int,boolean).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/EdgeNGramTokenFilter#EdgeNGramTokenFilter(TokenStream,int,int).mjava","sourceNew":"  /**\n   * Creates an EdgeNGramTokenFilter that, for a given input term, produces all\n   * edge n-grams with lengths &gt;= minGram and &lt;= maxGram. Will\n   * optionally preserve the original term when its length is outside of the\n   * defined range.\n   * \n   * @param input {@link TokenStream} holding the input to be tokenized\n   * @param minGram the minimum length of the generated n-grams\n   * @param maxGram the maximum length of the generated n-grams\n   * @param preserveOriginal Whether or not to keep the original term when it\n   * is outside the min/max size range.\n   */\n  public EdgeNGramTokenFilter(\n      TokenStream input, int minGram, int maxGram, boolean preserveOriginal) {\n    super(input);\n\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n    this.preserveOriginal = preserveOriginal;\n  }\n\n","sourceOld":"  /**\n   * Creates EdgeNGramTokenFilter that can generate n-grams in the sizes of the given range\n   *\n   * @param input {@link TokenStream} holding the input to be tokenized\n   * @param minGram the smallest n-gram to generate\n   * @param maxGram the largest n-gram to generate\n   */\n  public EdgeNGramTokenFilter(TokenStream input, int minGram, int maxGram) {\n    super(input);\n\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b70042a8a492f7054d480ccdd2be9796510d4327","date":1528386658,"type":1,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/EdgeNGramTokenFilter#EdgeNGramTokenFilter(TokenStream,int,int,boolean).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/EdgeNGramTokenFilter#EdgeNGramTokenFilter(TokenStream,int,int).mjava","sourceNew":"  /**\n   * Creates an EdgeNGramTokenFilter that, for a given input term, produces all\n   * edge n-grams with lengths &gt;= minGram and &lt;= maxGram. Will\n   * optionally preserve the original term when its length is outside of the\n   * defined range.\n   * \n   * @param input {@link TokenStream} holding the input to be tokenized\n   * @param minGram the minimum length of the generated n-grams\n   * @param maxGram the maximum length of the generated n-grams\n   * @param preserveOriginal Whether or not to keep the original term when it\n   * is outside the min/max size range.\n   */\n  public EdgeNGramTokenFilter(\n      TokenStream input, int minGram, int maxGram, boolean preserveOriginal) {\n    super(input);\n\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n    this.preserveOriginal = preserveOriginal;\n  }\n\n","sourceOld":"  /**\n   * Creates EdgeNGramTokenFilter that can generate n-grams in the sizes of the given range\n   *\n   * @param input {@link TokenStream} holding the input to be tokenized\n   * @param minGram the smallest n-gram to generate\n   * @param maxGram the largest n-gram to generate\n   */\n  public EdgeNGramTokenFilter(TokenStream input, int minGram, int maxGram) {\n    super(input);\n\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"8a255765a5625ff80fba75863de5a16ea392015e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b70042a8a492f7054d480ccdd2be9796510d4327":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","8a255765a5625ff80fba75863de5a16ea392015e"],"f592209545c71895260367152601e9200399776d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","8a255765a5625ff80fba75863de5a16ea392015e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["8a255765a5625ff80fba75863de5a16ea392015e"]},"commit2Childs":{"8a255765a5625ff80fba75863de5a16ea392015e":["b70042a8a492f7054d480ccdd2be9796510d4327","f592209545c71895260367152601e9200399776d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["8a255765a5625ff80fba75863de5a16ea392015e","b70042a8a492f7054d480ccdd2be9796510d4327","f592209545c71895260367152601e9200399776d"],"b70042a8a492f7054d480ccdd2be9796510d4327":[],"f592209545c71895260367152601e9200399776d":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["b70042a8a492f7054d480ccdd2be9796510d4327","f592209545c71895260367152601e9200399776d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}