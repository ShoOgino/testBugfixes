{"path":"lucene/facet/src/test/org/apache/lucene/facet/taxonomy/directory/TestDirectoryTaxonomyReader#testOpenIfChangedNoChangesButSegmentMerges().mjava","commits":[{"id":"8ba2855b999f802c0ae91b92fbeee1ea5557a015","date":1353526984,"type":0,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/taxonomy/directory/TestDirectoryTaxonomyReader#testOpenIfChangedNoChangesButSegmentMerges().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testOpenIfChangedNoChangesButSegmentMerges() throws Exception {\n    // test openIfChanged() when the taxonomy hasn't really changed, but segments\n    // were merged. The NRT reader will be reopened, and ParentArray used to assert\n    // that the new reader contains more ordinals than were given from the old\n    // TaxReader version\n    Directory dir = newDirectory();\n    \n    // hold onto IW to forceMerge\n    // note how we don't close it, since DTW will close it.\n    final IndexWriter iw = new IndexWriter(dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new KeywordAnalyzer())\n            .setMergePolicy(new LogByteSizeMergePolicy()));\n    DirectoryTaxonomyWriter writer = new DirectoryTaxonomyWriter(dir) {\n      @Override\n      protected IndexWriter openIndexWriter(Directory directory,\n          IndexWriterConfig config) throws IOException {\n        return iw;\n      }\n    };\n    \n    // add a category so that the following DTR open will cause a flush and \n    // a new segment will be created\n    writer.addCategory(new CategoryPath(\"a\"));\n    \n    TaxonomyReader reader = new DirectoryTaxonomyReader(writer);\n    assertEquals(2, reader.getSize());\n    assertEquals(2, reader.getParentArray().length);\n\n    // merge all the segments so that NRT reader thinks there's a change \n    iw.forceMerge(1);\n    \n    // now calling openIfChanged should trip on the wrong assert in ParetArray's ctor\n    TaxonomyReader newtr = TaxonomyReader.openIfChanged(reader);\n    assertNotNull(newtr);\n    reader.close();\n    reader = newtr;\n    assertEquals(2, reader.getSize());\n    assertEquals(2, reader.getParentArray().length);\n    \n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3d58d08788c3fd51172ba34474cca42499d6391b","date":1354802133,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/taxonomy/directory/TestDirectoryTaxonomyReader#testOpenIfChangedNoChangesButSegmentMerges().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/taxonomy/directory/TestDirectoryTaxonomyReader#testOpenIfChangedNoChangesButSegmentMerges().mjava","sourceNew":"  @Test\n  public void testOpenIfChangedNoChangesButSegmentMerges() throws Exception {\n    // test openIfChanged() when the taxonomy hasn't really changed, but segments\n    // were merged. The NRT reader will be reopened, and ParentArray used to assert\n    // that the new reader contains more ordinals than were given from the old\n    // TaxReader version\n    Directory dir = newDirectory();\n    \n    // hold onto IW to forceMerge\n    // note how we don't close it, since DTW will close it.\n    final IndexWriter iw = new IndexWriter(dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new KeywordAnalyzer())\n            .setMergePolicy(new LogByteSizeMergePolicy()));\n    DirectoryTaxonomyWriter writer = new DirectoryTaxonomyWriter(dir) {\n      @Override\n      protected IndexWriter openIndexWriter(Directory directory,\n          IndexWriterConfig config) throws IOException {\n        return iw;\n      }\n    };\n    \n    // add a category so that the following DTR open will cause a flush and \n    // a new segment will be created\n    writer.addCategory(new CategoryPath(\"a\"));\n    \n    TaxonomyReader reader = new DirectoryTaxonomyReader(writer);\n    assertEquals(2, reader.getSize());\n    assertEquals(2, reader.getParallelTaxonomyArrays().parents().length);\n\n    // merge all the segments so that NRT reader thinks there's a change \n    iw.forceMerge(1);\n    \n    // now calling openIfChanged should trip on the wrong assert in ParetArray's ctor\n    TaxonomyReader newtr = TaxonomyReader.openIfChanged(reader);\n    assertNotNull(newtr);\n    reader.close();\n    reader = newtr;\n    assertEquals(2, reader.getSize());\n    assertEquals(2, reader.getParallelTaxonomyArrays().parents().length);\n    \n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testOpenIfChangedNoChangesButSegmentMerges() throws Exception {\n    // test openIfChanged() when the taxonomy hasn't really changed, but segments\n    // were merged. The NRT reader will be reopened, and ParentArray used to assert\n    // that the new reader contains more ordinals than were given from the old\n    // TaxReader version\n    Directory dir = newDirectory();\n    \n    // hold onto IW to forceMerge\n    // note how we don't close it, since DTW will close it.\n    final IndexWriter iw = new IndexWriter(dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new KeywordAnalyzer())\n            .setMergePolicy(new LogByteSizeMergePolicy()));\n    DirectoryTaxonomyWriter writer = new DirectoryTaxonomyWriter(dir) {\n      @Override\n      protected IndexWriter openIndexWriter(Directory directory,\n          IndexWriterConfig config) throws IOException {\n        return iw;\n      }\n    };\n    \n    // add a category so that the following DTR open will cause a flush and \n    // a new segment will be created\n    writer.addCategory(new CategoryPath(\"a\"));\n    \n    TaxonomyReader reader = new DirectoryTaxonomyReader(writer);\n    assertEquals(2, reader.getSize());\n    assertEquals(2, reader.getParentArray().length);\n\n    // merge all the segments so that NRT reader thinks there's a change \n    iw.forceMerge(1);\n    \n    // now calling openIfChanged should trip on the wrong assert in ParetArray's ctor\n    TaxonomyReader newtr = TaxonomyReader.openIfChanged(reader);\n    assertNotNull(newtr);\n    reader.close();\n    reader = newtr;\n    assertEquals(2, reader.getSize());\n    assertEquals(2, reader.getParentArray().length);\n    \n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"407687e67faf6e1f02a211ca078d8e3eed631027","date":1355157407,"type":0,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/taxonomy/directory/TestDirectoryTaxonomyReader#testOpenIfChangedNoChangesButSegmentMerges().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testOpenIfChangedNoChangesButSegmentMerges() throws Exception {\n    // test openIfChanged() when the taxonomy hasn't really changed, but segments\n    // were merged. The NRT reader will be reopened, and ParentArray used to assert\n    // that the new reader contains more ordinals than were given from the old\n    // TaxReader version\n    Directory dir = newDirectory();\n    \n    // hold onto IW to forceMerge\n    // note how we don't close it, since DTW will close it.\n    final IndexWriter iw = new IndexWriter(dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new KeywordAnalyzer())\n            .setMergePolicy(new LogByteSizeMergePolicy()));\n    DirectoryTaxonomyWriter writer = new DirectoryTaxonomyWriter(dir) {\n      @Override\n      protected IndexWriter openIndexWriter(Directory directory,\n          IndexWriterConfig config) throws IOException {\n        return iw;\n      }\n    };\n    \n    // add a category so that the following DTR open will cause a flush and \n    // a new segment will be created\n    writer.addCategory(new CategoryPath(\"a\"));\n    \n    TaxonomyReader reader = new DirectoryTaxonomyReader(writer);\n    assertEquals(2, reader.getSize());\n    assertEquals(2, reader.getParallelTaxonomyArrays().parents().length);\n\n    // merge all the segments so that NRT reader thinks there's a change \n    iw.forceMerge(1);\n    \n    // now calling openIfChanged should trip on the wrong assert in ParetArray's ctor\n    TaxonomyReader newtr = TaxonomyReader.openIfChanged(reader);\n    assertNotNull(newtr);\n    reader.close();\n    reader = newtr;\n    assertEquals(2, reader.getSize());\n    assertEquals(2, reader.getParallelTaxonomyArrays().parents().length);\n    \n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1289047c4a6e31121c9d3a8f4c7a3fb30179f0fc","date":1359570667,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/taxonomy/directory/TestDirectoryTaxonomyReader#testOpenIfChangedNoChangesButSegmentMerges().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/taxonomy/directory/TestDirectoryTaxonomyReader#testOpenIfChangedNoChangesButSegmentMerges().mjava","sourceNew":"  @Test\n  public void testOpenIfChangedNoChangesButSegmentMerges() throws Exception {\n    // test openIfChanged() when the taxonomy hasn't really changed, but segments\n    // were merged. The NRT reader will be reopened, and ParentArray used to assert\n    // that the new reader contains more ordinals than were given from the old\n    // TaxReader version\n    Directory dir = newDirectory();\n    \n    // hold onto IW to forceMerge\n    // note how we don't close it, since DTW will close it.\n    final IndexWriter iw = new IndexWriter(dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n            .setMergePolicy(new LogByteSizeMergePolicy()));\n    DirectoryTaxonomyWriter writer = new DirectoryTaxonomyWriter(dir) {\n      @Override\n      protected IndexWriter openIndexWriter(Directory directory,\n          IndexWriterConfig config) throws IOException {\n        return iw;\n      }\n    };\n    \n    // add a category so that the following DTR open will cause a flush and \n    // a new segment will be created\n    writer.addCategory(new CategoryPath(\"a\"));\n    \n    TaxonomyReader reader = new DirectoryTaxonomyReader(writer);\n    assertEquals(2, reader.getSize());\n    assertEquals(2, reader.getParallelTaxonomyArrays().parents().length);\n\n    // merge all the segments so that NRT reader thinks there's a change \n    iw.forceMerge(1);\n    \n    // now calling openIfChanged should trip on the wrong assert in ParetArray's ctor\n    TaxonomyReader newtr = TaxonomyReader.openIfChanged(reader);\n    assertNotNull(newtr);\n    reader.close();\n    reader = newtr;\n    assertEquals(2, reader.getSize());\n    assertEquals(2, reader.getParallelTaxonomyArrays().parents().length);\n    \n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testOpenIfChangedNoChangesButSegmentMerges() throws Exception {\n    // test openIfChanged() when the taxonomy hasn't really changed, but segments\n    // were merged. The NRT reader will be reopened, and ParentArray used to assert\n    // that the new reader contains more ordinals than were given from the old\n    // TaxReader version\n    Directory dir = newDirectory();\n    \n    // hold onto IW to forceMerge\n    // note how we don't close it, since DTW will close it.\n    final IndexWriter iw = new IndexWriter(dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new KeywordAnalyzer())\n            .setMergePolicy(new LogByteSizeMergePolicy()));\n    DirectoryTaxonomyWriter writer = new DirectoryTaxonomyWriter(dir) {\n      @Override\n      protected IndexWriter openIndexWriter(Directory directory,\n          IndexWriterConfig config) throws IOException {\n        return iw;\n      }\n    };\n    \n    // add a category so that the following DTR open will cause a flush and \n    // a new segment will be created\n    writer.addCategory(new CategoryPath(\"a\"));\n    \n    TaxonomyReader reader = new DirectoryTaxonomyReader(writer);\n    assertEquals(2, reader.getSize());\n    assertEquals(2, reader.getParallelTaxonomyArrays().parents().length);\n\n    // merge all the segments so that NRT reader thinks there's a change \n    iw.forceMerge(1);\n    \n    // now calling openIfChanged should trip on the wrong assert in ParetArray's ctor\n    TaxonomyReader newtr = TaxonomyReader.openIfChanged(reader);\n    assertNotNull(newtr);\n    reader.close();\n    reader = newtr;\n    assertEquals(2, reader.getSize());\n    assertEquals(2, reader.getParallelTaxonomyArrays().parents().length);\n    \n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"61d5f95d14e5b9b046998c51e16709a398c15226","date":1359603451,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/taxonomy/directory/TestDirectoryTaxonomyReader#testOpenIfChangedNoChangesButSegmentMerges().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/taxonomy/directory/TestDirectoryTaxonomyReader#testOpenIfChangedNoChangesButSegmentMerges().mjava","sourceNew":"  @Test\n  public void testOpenIfChangedNoChangesButSegmentMerges() throws Exception {\n    // test openIfChanged() when the taxonomy hasn't really changed, but segments\n    // were merged. The NRT reader will be reopened, and ParentArray used to assert\n    // that the new reader contains more ordinals than were given from the old\n    // TaxReader version\n    Directory dir = newDirectory();\n    \n    // hold onto IW to forceMerge\n    // note how we don't close it, since DTW will close it.\n    final IndexWriter iw = new IndexWriter(dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n            .setMergePolicy(new LogByteSizeMergePolicy()));\n    DirectoryTaxonomyWriter writer = new DirectoryTaxonomyWriter(dir) {\n      @Override\n      protected IndexWriter openIndexWriter(Directory directory,\n          IndexWriterConfig config) throws IOException {\n        return iw;\n      }\n    };\n    \n    // add a category so that the following DTR open will cause a flush and \n    // a new segment will be created\n    writer.addCategory(new CategoryPath(\"a\"));\n    \n    TaxonomyReader reader = new DirectoryTaxonomyReader(writer);\n    assertEquals(2, reader.getSize());\n    assertEquals(2, reader.getParallelTaxonomyArrays().parents().length);\n\n    // merge all the segments so that NRT reader thinks there's a change \n    iw.forceMerge(1);\n    \n    // now calling openIfChanged should trip on the wrong assert in ParetArray's ctor\n    TaxonomyReader newtr = TaxonomyReader.openIfChanged(reader);\n    assertNotNull(newtr);\n    reader.close();\n    reader = newtr;\n    assertEquals(2, reader.getSize());\n    assertEquals(2, reader.getParallelTaxonomyArrays().parents().length);\n    \n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testOpenIfChangedNoChangesButSegmentMerges() throws Exception {\n    // test openIfChanged() when the taxonomy hasn't really changed, but segments\n    // were merged. The NRT reader will be reopened, and ParentArray used to assert\n    // that the new reader contains more ordinals than were given from the old\n    // TaxReader version\n    Directory dir = newDirectory();\n    \n    // hold onto IW to forceMerge\n    // note how we don't close it, since DTW will close it.\n    final IndexWriter iw = new IndexWriter(dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new KeywordAnalyzer())\n            .setMergePolicy(new LogByteSizeMergePolicy()));\n    DirectoryTaxonomyWriter writer = new DirectoryTaxonomyWriter(dir) {\n      @Override\n      protected IndexWriter openIndexWriter(Directory directory,\n          IndexWriterConfig config) throws IOException {\n        return iw;\n      }\n    };\n    \n    // add a category so that the following DTR open will cause a flush and \n    // a new segment will be created\n    writer.addCategory(new CategoryPath(\"a\"));\n    \n    TaxonomyReader reader = new DirectoryTaxonomyReader(writer);\n    assertEquals(2, reader.getSize());\n    assertEquals(2, reader.getParallelTaxonomyArrays().parents().length);\n\n    // merge all the segments so that NRT reader thinks there's a change \n    iw.forceMerge(1);\n    \n    // now calling openIfChanged should trip on the wrong assert in ParetArray's ctor\n    TaxonomyReader newtr = TaxonomyReader.openIfChanged(reader);\n    assertNotNull(newtr);\n    reader.close();\n    reader = newtr;\n    assertEquals(2, reader.getSize());\n    assertEquals(2, reader.getParallelTaxonomyArrays().parents().length);\n    \n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c190847801a50f4dd20fd639bdc29b54ea3b288b","date":1384461522,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/taxonomy/directory/TestDirectoryTaxonomyReader#testOpenIfChangedNoChangesButSegmentMerges().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/taxonomy/directory/TestDirectoryTaxonomyReader#testOpenIfChangedNoChangesButSegmentMerges().mjava","sourceNew":"  @Test\n  public void testOpenIfChangedNoChangesButSegmentMerges() throws Exception {\n    // test openIfChanged() when the taxonomy hasn't really changed, but segments\n    // were merged. The NRT reader will be reopened, and ParentArray used to assert\n    // that the new reader contains more ordinals than were given from the old\n    // TaxReader version\n    Directory dir = newDirectory();\n    \n    // hold onto IW to forceMerge\n    // note how we don't close it, since DTW will close it.\n    final IndexWriter iw = new IndexWriter(dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n            .setMergePolicy(new LogByteSizeMergePolicy()));\n    DirectoryTaxonomyWriter writer = new DirectoryTaxonomyWriter(dir) {\n      @Override\n      protected IndexWriter openIndexWriter(Directory directory,\n          IndexWriterConfig config) throws IOException {\n        return iw;\n      }\n    };\n    \n    // add a category so that the following DTR open will cause a flush and \n    // a new segment will be created\n    writer.addCategory(new FacetLabel(\"a\"));\n    \n    TaxonomyReader reader = new DirectoryTaxonomyReader(writer);\n    assertEquals(2, reader.getSize());\n    assertEquals(2, reader.getParallelTaxonomyArrays().parents().length);\n\n    // merge all the segments so that NRT reader thinks there's a change \n    iw.forceMerge(1);\n    \n    // now calling openIfChanged should trip on the wrong assert in ParetArray's ctor\n    TaxonomyReader newtr = TaxonomyReader.openIfChanged(reader);\n    assertNotNull(newtr);\n    reader.close();\n    reader = newtr;\n    assertEquals(2, reader.getSize());\n    assertEquals(2, reader.getParallelTaxonomyArrays().parents().length);\n    \n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testOpenIfChangedNoChangesButSegmentMerges() throws Exception {\n    // test openIfChanged() when the taxonomy hasn't really changed, but segments\n    // were merged. The NRT reader will be reopened, and ParentArray used to assert\n    // that the new reader contains more ordinals than were given from the old\n    // TaxReader version\n    Directory dir = newDirectory();\n    \n    // hold onto IW to forceMerge\n    // note how we don't close it, since DTW will close it.\n    final IndexWriter iw = new IndexWriter(dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n            .setMergePolicy(new LogByteSizeMergePolicy()));\n    DirectoryTaxonomyWriter writer = new DirectoryTaxonomyWriter(dir) {\n      @Override\n      protected IndexWriter openIndexWriter(Directory directory,\n          IndexWriterConfig config) throws IOException {\n        return iw;\n      }\n    };\n    \n    // add a category so that the following DTR open will cause a flush and \n    // a new segment will be created\n    writer.addCategory(new CategoryPath(\"a\"));\n    \n    TaxonomyReader reader = new DirectoryTaxonomyReader(writer);\n    assertEquals(2, reader.getSize());\n    assertEquals(2, reader.getParallelTaxonomyArrays().parents().length);\n\n    // merge all the segments so that NRT reader thinks there's a change \n    iw.forceMerge(1);\n    \n    // now calling openIfChanged should trip on the wrong assert in ParetArray's ctor\n    TaxonomyReader newtr = TaxonomyReader.openIfChanged(reader);\n    assertNotNull(newtr);\n    reader.close();\n    reader = newtr;\n    assertEquals(2, reader.getSize());\n    assertEquals(2, reader.getParallelTaxonomyArrays().parents().length);\n    \n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3cc728b07df73b197e6d940d27f9b08b63918f13","date":1388834348,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/taxonomy/directory/TestDirectoryTaxonomyReader#testOpenIfChangedNoChangesButSegmentMerges().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/taxonomy/directory/TestDirectoryTaxonomyReader#testOpenIfChangedNoChangesButSegmentMerges().mjava","sourceNew":"  @Test\n  public void testOpenIfChangedNoChangesButSegmentMerges() throws Exception {\n    // test openIfChanged() when the taxonomy hasn't really changed, but segments\n    // were merged. The NRT reader will be reopened, and ParentArray used to assert\n    // that the new reader contains more ordinals than were given from the old\n    // TaxReader version\n    Directory dir = newDirectory();\n    \n    // hold onto IW to forceMerge\n    // note how we don't close it, since DTW will close it.\n    final IndexWriter iw = new IndexWriter(dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n            .setMergePolicy(new LogByteSizeMergePolicy()));\n    DirectoryTaxonomyWriter writer = new DirectoryTaxonomyWriter(dir) {\n      @Override\n      protected IndexWriter openIndexWriter(Directory directory,\n          IndexWriterConfig config) throws IOException {\n        return iw;\n      }\n    };\n    \n    // add a category so that the following DTR open will cause a flush and \n    // a new segment will be created\n    writer.addCategory(new FacetLabel(\"a\"));\n    \n    TaxonomyReader reader = new DirectoryTaxonomyReader(writer);\n    assertEquals(2, reader.getSize());\n    assertEquals(2, reader.getParallelTaxonomyArrays().parents().length);\n\n    // merge all the segments so that NRT reader thinks there's a change \n    iw.forceMerge(1);\n    \n    // now calling openIfChanged should trip on the wrong assert in ParetArray's ctor\n    TaxonomyReader newtr = TaxonomyReader.openIfChanged(reader);\n    assertNotNull(newtr);\n    reader.close();\n    reader = newtr;\n    assertEquals(2, reader.getSize());\n    assertEquals(2, reader.getParallelTaxonomyArrays().parents().length);\n    \n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testOpenIfChangedNoChangesButSegmentMerges() throws Exception {\n    // test openIfChanged() when the taxonomy hasn't really changed, but segments\n    // were merged. The NRT reader will be reopened, and ParentArray used to assert\n    // that the new reader contains more ordinals than were given from the old\n    // TaxReader version\n    Directory dir = newDirectory();\n    \n    // hold onto IW to forceMerge\n    // note how we don't close it, since DTW will close it.\n    final IndexWriter iw = new IndexWriter(dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n            .setMergePolicy(new LogByteSizeMergePolicy()));\n    DirectoryTaxonomyWriter writer = new DirectoryTaxonomyWriter(dir) {\n      @Override\n      protected IndexWriter openIndexWriter(Directory directory,\n          IndexWriterConfig config) throws IOException {\n        return iw;\n      }\n    };\n    \n    // add a category so that the following DTR open will cause a flush and \n    // a new segment will be created\n    writer.addCategory(new CategoryPath(\"a\"));\n    \n    TaxonomyReader reader = new DirectoryTaxonomyReader(writer);\n    assertEquals(2, reader.getSize());\n    assertEquals(2, reader.getParallelTaxonomyArrays().parents().length);\n\n    // merge all the segments so that NRT reader thinks there's a change \n    iw.forceMerge(1);\n    \n    // now calling openIfChanged should trip on the wrong assert in ParetArray's ctor\n    TaxonomyReader newtr = TaxonomyReader.openIfChanged(reader);\n    assertNotNull(newtr);\n    reader.close();\n    reader = newtr;\n    assertEquals(2, reader.getSize());\n    assertEquals(2, reader.getParallelTaxonomyArrays().parents().length);\n    \n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/taxonomy/directory/TestDirectoryTaxonomyReader#testOpenIfChangedNoChangesButSegmentMerges().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/taxonomy/directory/TestDirectoryTaxonomyReader#testOpenIfChangedNoChangesButSegmentMerges().mjava","sourceNew":"  @Test\n  public void testOpenIfChangedNoChangesButSegmentMerges() throws Exception {\n    // test openIfChanged() when the taxonomy hasn't really changed, but segments\n    // were merged. The NRT reader will be reopened, and ParentArray used to assert\n    // that the new reader contains more ordinals than were given from the old\n    // TaxReader version\n    Directory dir = newDirectory();\n    \n    // hold onto IW to forceMerge\n    // note how we don't close it, since DTW will close it.\n    final IndexWriter iw = new IndexWriter(dir,\n        new IndexWriterConfig(new MockAnalyzer(random()))\n            .setMergePolicy(new LogByteSizeMergePolicy()));\n    DirectoryTaxonomyWriter writer = new DirectoryTaxonomyWriter(dir) {\n      @Override\n      protected IndexWriter openIndexWriter(Directory directory,\n          IndexWriterConfig config) throws IOException {\n        return iw;\n      }\n    };\n    \n    // add a category so that the following DTR open will cause a flush and \n    // a new segment will be created\n    writer.addCategory(new FacetLabel(\"a\"));\n    \n    TaxonomyReader reader = new DirectoryTaxonomyReader(writer);\n    assertEquals(2, reader.getSize());\n    assertEquals(2, reader.getParallelTaxonomyArrays().parents().length);\n\n    // merge all the segments so that NRT reader thinks there's a change \n    iw.forceMerge(1);\n    \n    // now calling openIfChanged should trip on the wrong assert in ParetArray's ctor\n    TaxonomyReader newtr = TaxonomyReader.openIfChanged(reader);\n    assertNotNull(newtr);\n    reader.close();\n    reader = newtr;\n    assertEquals(2, reader.getSize());\n    assertEquals(2, reader.getParallelTaxonomyArrays().parents().length);\n    \n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testOpenIfChangedNoChangesButSegmentMerges() throws Exception {\n    // test openIfChanged() when the taxonomy hasn't really changed, but segments\n    // were merged. The NRT reader will be reopened, and ParentArray used to assert\n    // that the new reader contains more ordinals than were given from the old\n    // TaxReader version\n    Directory dir = newDirectory();\n    \n    // hold onto IW to forceMerge\n    // note how we don't close it, since DTW will close it.\n    final IndexWriter iw = new IndexWriter(dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n            .setMergePolicy(new LogByteSizeMergePolicy()));\n    DirectoryTaxonomyWriter writer = new DirectoryTaxonomyWriter(dir) {\n      @Override\n      protected IndexWriter openIndexWriter(Directory directory,\n          IndexWriterConfig config) throws IOException {\n        return iw;\n      }\n    };\n    \n    // add a category so that the following DTR open will cause a flush and \n    // a new segment will be created\n    writer.addCategory(new FacetLabel(\"a\"));\n    \n    TaxonomyReader reader = new DirectoryTaxonomyReader(writer);\n    assertEquals(2, reader.getSize());\n    assertEquals(2, reader.getParallelTaxonomyArrays().parents().length);\n\n    // merge all the segments so that NRT reader thinks there's a change \n    iw.forceMerge(1);\n    \n    // now calling openIfChanged should trip on the wrong assert in ParetArray's ctor\n    TaxonomyReader newtr = TaxonomyReader.openIfChanged(reader);\n    assertNotNull(newtr);\n    reader.close();\n    reader = newtr;\n    assertEquals(2, reader.getSize());\n    assertEquals(2, reader.getParallelTaxonomyArrays().parents().length);\n    \n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"61d5f95d14e5b9b046998c51e16709a398c15226":["407687e67faf6e1f02a211ca078d8e3eed631027","1289047c4a6e31121c9d3a8f4c7a3fb30179f0fc"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"407687e67faf6e1f02a211ca078d8e3eed631027":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","3d58d08788c3fd51172ba34474cca42499d6391b"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["3cc728b07df73b197e6d940d27f9b08b63918f13"],"3d58d08788c3fd51172ba34474cca42499d6391b":["8ba2855b999f802c0ae91b92fbeee1ea5557a015"],"3cc728b07df73b197e6d940d27f9b08b63918f13":["1289047c4a6e31121c9d3a8f4c7a3fb30179f0fc","c190847801a50f4dd20fd639bdc29b54ea3b288b"],"1289047c4a6e31121c9d3a8f4c7a3fb30179f0fc":["3d58d08788c3fd51172ba34474cca42499d6391b"],"8ba2855b999f802c0ae91b92fbeee1ea5557a015":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"c190847801a50f4dd20fd639bdc29b54ea3b288b":["1289047c4a6e31121c9d3a8f4c7a3fb30179f0fc"]},"commit2Childs":{"61d5f95d14e5b9b046998c51e16709a398c15226":[],"407687e67faf6e1f02a211ca078d8e3eed631027":["61d5f95d14e5b9b046998c51e16709a398c15226"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["407687e67faf6e1f02a211ca078d8e3eed631027","8ba2855b999f802c0ae91b92fbeee1ea5557a015"],"3d58d08788c3fd51172ba34474cca42499d6391b":["407687e67faf6e1f02a211ca078d8e3eed631027","1289047c4a6e31121c9d3a8f4c7a3fb30179f0fc"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3cc728b07df73b197e6d940d27f9b08b63918f13":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"1289047c4a6e31121c9d3a8f4c7a3fb30179f0fc":["61d5f95d14e5b9b046998c51e16709a398c15226","3cc728b07df73b197e6d940d27f9b08b63918f13","c190847801a50f4dd20fd639bdc29b54ea3b288b"],"8ba2855b999f802c0ae91b92fbeee1ea5557a015":["3d58d08788c3fd51172ba34474cca42499d6391b"],"c190847801a50f4dd20fd639bdc29b54ea3b288b":["3cc728b07df73b197e6d940d27f9b08b63918f13"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["61d5f95d14e5b9b046998c51e16709a398c15226","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}