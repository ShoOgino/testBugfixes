{"path":"lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizer#incrementToken().mjava","commits":[{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizer#incrementToken().mjava","pathOld":"modules/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizer#incrementToken().mjava","sourceNew":"  /*\n   * (non-Javadoc)\n   *\n   * @see org.apache.lucene.analysis.TokenStream#next()\n   */\n  @Override\n  public final boolean incrementToken() throws IOException {\n    clearAttributes();\n    int posIncr = 1;\n\n    while(true) {\n      int tokenType = scanner.getNextToken();\n\n      if (tokenType == StandardTokenizerInterface.YYEOF) {\n        return false;\n      }\n\n      if (scanner.yylength() <= maxTokenLength) {\n        posIncrAtt.setPositionIncrement(posIncr);\n        scanner.getText(termAtt);\n        final int start = scanner.yychar();\n        offsetAtt.setOffset(correctOffset(start), correctOffset(start+termAtt.length()));\n        // This 'if' should be removed in the next release. For now, it converts\n        // invalid acronyms to HOST. When removed, only the 'else' part should\n        // remain.\n        if (tokenType == StandardTokenizer.ACRONYM_DEP) {\n          typeAtt.setType(StandardTokenizer.TOKEN_TYPES[StandardTokenizer.HOST]);\n          termAtt.setLength(termAtt.length() - 1); // remove extra '.'\n        } else {\n          typeAtt.setType(StandardTokenizer.TOKEN_TYPES[tokenType]);\n        }\n        return true;\n      } else\n        // When we skip a too-long term, we still increment the\n        // position increment\n        posIncr++;\n    }\n  }\n\n","sourceOld":"  /*\n   * (non-Javadoc)\n   *\n   * @see org.apache.lucene.analysis.TokenStream#next()\n   */\n  @Override\n  public final boolean incrementToken() throws IOException {\n    clearAttributes();\n    int posIncr = 1;\n\n    while(true) {\n      int tokenType = scanner.getNextToken();\n\n      if (tokenType == StandardTokenizerInterface.YYEOF) {\n        return false;\n      }\n\n      if (scanner.yylength() <= maxTokenLength) {\n        posIncrAtt.setPositionIncrement(posIncr);\n        scanner.getText(termAtt);\n        final int start = scanner.yychar();\n        offsetAtt.setOffset(correctOffset(start), correctOffset(start+termAtt.length()));\n        // This 'if' should be removed in the next release. For now, it converts\n        // invalid acronyms to HOST. When removed, only the 'else' part should\n        // remain.\n        if (tokenType == StandardTokenizer.ACRONYM_DEP) {\n          typeAtt.setType(StandardTokenizer.TOKEN_TYPES[StandardTokenizer.HOST]);\n          termAtt.setLength(termAtt.length() - 1); // remove extra '.'\n        } else {\n          typeAtt.setType(StandardTokenizer.TOKEN_TYPES[tokenType]);\n        }\n        return true;\n      } else\n        // When we skip a too-long term, we still increment the\n        // position increment\n        posIncr++;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f","date":1338430031,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizer#incrementToken().mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizer#incrementToken().mjava","sourceNew":"  /*\n   * (non-Javadoc)\n   *\n   * @see org.apache.lucene.analysis.TokenStream#next()\n   */\n  @Override\n  public final boolean incrementToken() throws IOException {\n    clearAttributes();\n    int posIncr = 1;\n\n    while(true) {\n      int tokenType = scanner.getNextToken();\n\n      if (tokenType == StandardTokenizerInterface.YYEOF) {\n        return false;\n      }\n\n      if (scanner.yylength() <= maxTokenLength) {\n        posIncrAtt.setPositionIncrement(posIncr);\n        scanner.getText(termAtt);\n        final int start = scanner.yychar();\n        offsetAtt.setOffset(correctOffset(start), correctOffset(start+termAtt.length()));\n        typeAtt.setType(StandardTokenizer.TOKEN_TYPES[tokenType]);\n        return true;\n      } else\n        // When we skip a too-long term, we still increment the\n        // position increment\n        posIncr++;\n    }\n  }\n\n","sourceOld":"  /*\n   * (non-Javadoc)\n   *\n   * @see org.apache.lucene.analysis.TokenStream#next()\n   */\n  @Override\n  public final boolean incrementToken() throws IOException {\n    clearAttributes();\n    int posIncr = 1;\n\n    while(true) {\n      int tokenType = scanner.getNextToken();\n\n      if (tokenType == StandardTokenizerInterface.YYEOF) {\n        return false;\n      }\n\n      if (scanner.yylength() <= maxTokenLength) {\n        posIncrAtt.setPositionIncrement(posIncr);\n        scanner.getText(termAtt);\n        final int start = scanner.yychar();\n        offsetAtt.setOffset(correctOffset(start), correctOffset(start+termAtt.length()));\n        // This 'if' should be removed in the next release. For now, it converts\n        // invalid acronyms to HOST. When removed, only the 'else' part should\n        // remain.\n        if (tokenType == StandardTokenizer.ACRONYM_DEP) {\n          typeAtt.setType(StandardTokenizer.TOKEN_TYPES[StandardTokenizer.HOST]);\n          termAtt.setLength(termAtt.length() - 1); // remove extra '.'\n        } else {\n          typeAtt.setType(StandardTokenizer.TOKEN_TYPES[tokenType]);\n        }\n        return true;\n      } else\n        // When we skip a too-long term, we still increment the\n        // position increment\n        posIncr++;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f3f8a0f8bebc057ea4bdf65150b3fdc539db3d03","date":1377018786,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizer#incrementToken().mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizer#incrementToken().mjava","sourceNew":"  /*\n   * (non-Javadoc)\n   *\n   * @see org.apache.lucene.analysis.TokenStream#next()\n   */\n  @Override\n  public final boolean incrementToken() throws IOException {\n    clearAttributes();\n    skippedPositions = 0;\n\n    while(true) {\n      int tokenType = scanner.getNextToken();\n\n      if (tokenType == StandardTokenizerInterface.YYEOF) {\n        return false;\n      }\n\n      if (scanner.yylength() <= maxTokenLength) {\n        posIncrAtt.setPositionIncrement(skippedPositions+1);\n        scanner.getText(termAtt);\n        final int start = scanner.yychar();\n        offsetAtt.setOffset(correctOffset(start), correctOffset(start+termAtt.length()));\n        typeAtt.setType(StandardTokenizer.TOKEN_TYPES[tokenType]);\n        return true;\n      } else\n        // When we skip a too-long term, we still increment the\n        // position increment\n        skippedPositions++;\n    }\n  }\n\n","sourceOld":"  /*\n   * (non-Javadoc)\n   *\n   * @see org.apache.lucene.analysis.TokenStream#next()\n   */\n  @Override\n  public final boolean incrementToken() throws IOException {\n    clearAttributes();\n    int posIncr = 1;\n\n    while(true) {\n      int tokenType = scanner.getNextToken();\n\n      if (tokenType == StandardTokenizerInterface.YYEOF) {\n        return false;\n      }\n\n      if (scanner.yylength() <= maxTokenLength) {\n        posIncrAtt.setPositionIncrement(posIncr);\n        scanner.getText(termAtt);\n        final int start = scanner.yychar();\n        offsetAtt.setOffset(correctOffset(start), correctOffset(start+termAtt.length()));\n        typeAtt.setType(StandardTokenizer.TOKEN_TYPES[tokenType]);\n        return true;\n      } else\n        // When we skip a too-long term, we still increment the\n        // position increment\n        posIncr++;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3dffec77fb8f7d0e9ca4869dddd6af94528b4576","date":1377875202,"type":3,"author":"Han Jiang","isMerge":true,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizer#incrementToken().mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizer#incrementToken().mjava","sourceNew":"  /*\n   * (non-Javadoc)\n   *\n   * @see org.apache.lucene.analysis.TokenStream#next()\n   */\n  @Override\n  public final boolean incrementToken() throws IOException {\n    clearAttributes();\n    skippedPositions = 0;\n\n    while(true) {\n      int tokenType = scanner.getNextToken();\n\n      if (tokenType == StandardTokenizerInterface.YYEOF) {\n        return false;\n      }\n\n      if (scanner.yylength() <= maxTokenLength) {\n        posIncrAtt.setPositionIncrement(skippedPositions+1);\n        scanner.getText(termAtt);\n        final int start = scanner.yychar();\n        offsetAtt.setOffset(correctOffset(start), correctOffset(start+termAtt.length()));\n        typeAtt.setType(StandardTokenizer.TOKEN_TYPES[tokenType]);\n        return true;\n      } else\n        // When we skip a too-long term, we still increment the\n        // position increment\n        skippedPositions++;\n    }\n  }\n\n","sourceOld":"  /*\n   * (non-Javadoc)\n   *\n   * @see org.apache.lucene.analysis.TokenStream#next()\n   */\n  @Override\n  public final boolean incrementToken() throws IOException {\n    clearAttributes();\n    int posIncr = 1;\n\n    while(true) {\n      int tokenType = scanner.getNextToken();\n\n      if (tokenType == StandardTokenizerInterface.YYEOF) {\n        return false;\n      }\n\n      if (scanner.yylength() <= maxTokenLength) {\n        posIncrAtt.setPositionIncrement(posIncr);\n        scanner.getText(termAtt);\n        final int start = scanner.yychar();\n        offsetAtt.setOffset(correctOffset(start), correctOffset(start+termAtt.length()));\n        typeAtt.setType(StandardTokenizer.TOKEN_TYPES[tokenType]);\n        return true;\n      } else\n        // When we skip a too-long term, we still increment the\n        // position increment\n        posIncr++;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c1a1d77f7d47c04c0e559ece71d63fce1d394342","date":1412834287,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizer#incrementToken().mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizer#incrementToken().mjava","sourceNew":"  /*\n   * (non-Javadoc)\n   *\n   * @see org.apache.lucene.analysis.TokenStream#next()\n   */\n  @Override\n  public final boolean incrementToken() throws IOException {\n    clearAttributes();\n    skippedPositions = 0;\n\n    while(true) {\n      int tokenType = scanner.getNextToken();\n\n      if (tokenType == StandardTokenizerImpl.YYEOF) {\n        return false;\n      }\n\n      if (scanner.yylength() <= maxTokenLength) {\n        posIncrAtt.setPositionIncrement(skippedPositions+1);\n        scanner.getText(termAtt);\n        final int start = scanner.yychar();\n        offsetAtt.setOffset(correctOffset(start), correctOffset(start+termAtt.length()));\n        typeAtt.setType(StandardTokenizer.TOKEN_TYPES[tokenType]);\n        return true;\n      } else\n        // When we skip a too-long term, we still increment the\n        // position increment\n        skippedPositions++;\n    }\n  }\n\n","sourceOld":"  /*\n   * (non-Javadoc)\n   *\n   * @see org.apache.lucene.analysis.TokenStream#next()\n   */\n  @Override\n  public final boolean incrementToken() throws IOException {\n    clearAttributes();\n    skippedPositions = 0;\n\n    while(true) {\n      int tokenType = scanner.getNextToken();\n\n      if (tokenType == StandardTokenizerInterface.YYEOF) {\n        return false;\n      }\n\n      if (scanner.yylength() <= maxTokenLength) {\n        posIncrAtt.setPositionIncrement(skippedPositions+1);\n        scanner.getText(termAtt);\n        final int start = scanner.yychar();\n        offsetAtt.setOffset(correctOffset(start), correctOffset(start+termAtt.length()));\n        typeAtt.setType(StandardTokenizer.TOKEN_TYPES[tokenType]);\n        return true;\n      } else\n        // When we skip a too-long term, we still increment the\n        // position increment\n        skippedPositions++;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"55980207f1977bd1463465de1659b821347e2fa8","date":1413336386,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizer#incrementToken().mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizer#incrementToken().mjava","sourceNew":"  /*\n   * (non-Javadoc)\n   *\n   * @see org.apache.lucene.analysis.TokenStream#next()\n   */\n  @Override\n  public final boolean incrementToken() throws IOException {\n    clearAttributes();\n    skippedPositions = 0;\n\n    while(true) {\n      int tokenType = scanner.getNextToken();\n\n      if (tokenType == StandardTokenizerImpl.YYEOF) {\n        return false;\n      }\n\n      if (scanner.yylength() <= maxTokenLength) {\n        posIncrAtt.setPositionIncrement(skippedPositions+1);\n        scanner.getText(termAtt);\n        final int start = scanner.yychar();\n        offsetAtt.setOffset(correctOffset(start), correctOffset(start+termAtt.length()));\n        typeAtt.setType(StandardTokenizer.TOKEN_TYPES[tokenType]);\n        return true;\n      } else\n        // When we skip a too-long term, we still increment the\n        // position increment\n        skippedPositions++;\n    }\n  }\n\n","sourceOld":"  /*\n   * (non-Javadoc)\n   *\n   * @see org.apache.lucene.analysis.TokenStream#next()\n   */\n  @Override\n  public final boolean incrementToken() throws IOException {\n    clearAttributes();\n    skippedPositions = 0;\n\n    while(true) {\n      int tokenType = scanner.getNextToken();\n\n      if (tokenType == StandardTokenizerInterface.YYEOF) {\n        return false;\n      }\n\n      if (scanner.yylength() <= maxTokenLength) {\n        posIncrAtt.setPositionIncrement(skippedPositions+1);\n        scanner.getText(termAtt);\n        final int start = scanner.yychar();\n        offsetAtt.setOffset(correctOffset(start), correctOffset(start+termAtt.length()));\n        typeAtt.setType(StandardTokenizer.TOKEN_TYPES[tokenType]);\n        return true;\n      } else\n        // When we skip a too-long term, we still increment the\n        // position increment\n        skippedPositions++;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b266fe0ac2172d4ad87cff12bd9bf9f8c8247345","date":1465936684,"type":5,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/analysis/standard/StandardTokenizer#incrementToken().mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizer#incrementToken().mjava","sourceNew":"  /*\n   * (non-Javadoc)\n   *\n   * @see org.apache.lucene.analysis.TokenStream#next()\n   */\n  @Override\n  public final boolean incrementToken() throws IOException {\n    clearAttributes();\n    skippedPositions = 0;\n\n    while(true) {\n      int tokenType = scanner.getNextToken();\n\n      if (tokenType == StandardTokenizerImpl.YYEOF) {\n        return false;\n      }\n\n      if (scanner.yylength() <= maxTokenLength) {\n        posIncrAtt.setPositionIncrement(skippedPositions+1);\n        scanner.getText(termAtt);\n        final int start = scanner.yychar();\n        offsetAtt.setOffset(correctOffset(start), correctOffset(start+termAtt.length()));\n        typeAtt.setType(StandardTokenizer.TOKEN_TYPES[tokenType]);\n        return true;\n      } else\n        // When we skip a too-long term, we still increment the\n        // position increment\n        skippedPositions++;\n    }\n  }\n\n","sourceOld":"  /*\n   * (non-Javadoc)\n   *\n   * @see org.apache.lucene.analysis.TokenStream#next()\n   */\n  @Override\n  public final boolean incrementToken() throws IOException {\n    clearAttributes();\n    skippedPositions = 0;\n\n    while(true) {\n      int tokenType = scanner.getNextToken();\n\n      if (tokenType == StandardTokenizerImpl.YYEOF) {\n        return false;\n      }\n\n      if (scanner.yylength() <= maxTokenLength) {\n        posIncrAtt.setPositionIncrement(skippedPositions+1);\n        scanner.getText(termAtt);\n        final int start = scanner.yychar();\n        offsetAtt.setOffset(correctOffset(start), correctOffset(start+termAtt.length()));\n        typeAtt.setType(StandardTokenizer.TOKEN_TYPES[tokenType]);\n        return true;\n      } else\n        // When we skip a too-long term, we still increment the\n        // position increment\n        skippedPositions++;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":5,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/analysis/standard/StandardTokenizer#incrementToken().mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizer#incrementToken().mjava","sourceNew":"  /*\n   * (non-Javadoc)\n   *\n   * @see org.apache.lucene.analysis.TokenStream#next()\n   */\n  @Override\n  public final boolean incrementToken() throws IOException {\n    clearAttributes();\n    skippedPositions = 0;\n\n    while(true) {\n      int tokenType = scanner.getNextToken();\n\n      if (tokenType == StandardTokenizerImpl.YYEOF) {\n        return false;\n      }\n\n      if (scanner.yylength() <= maxTokenLength) {\n        posIncrAtt.setPositionIncrement(skippedPositions+1);\n        scanner.getText(termAtt);\n        final int start = scanner.yychar();\n        offsetAtt.setOffset(correctOffset(start), correctOffset(start+termAtt.length()));\n        typeAtt.setType(StandardTokenizer.TOKEN_TYPES[tokenType]);\n        return true;\n      } else\n        // When we skip a too-long term, we still increment the\n        // position increment\n        skippedPositions++;\n    }\n  }\n\n","sourceOld":"  /*\n   * (non-Javadoc)\n   *\n   * @see org.apache.lucene.analysis.TokenStream#next()\n   */\n  @Override\n  public final boolean incrementToken() throws IOException {\n    clearAttributes();\n    skippedPositions = 0;\n\n    while(true) {\n      int tokenType = scanner.getNextToken();\n\n      if (tokenType == StandardTokenizerImpl.YYEOF) {\n        return false;\n      }\n\n      if (scanner.yylength() <= maxTokenLength) {\n        posIncrAtt.setPositionIncrement(skippedPositions+1);\n        scanner.getText(termAtt);\n        final int start = scanner.yychar();\n        offsetAtt.setOffset(correctOffset(start), correctOffset(start+termAtt.length()));\n        typeAtt.setType(StandardTokenizer.TOKEN_TYPES[tokenType]);\n        return true;\n      } else\n        // When we skip a too-long term, we still increment the\n        // position increment\n        skippedPositions++;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"55980207f1977bd1463465de1659b821347e2fa8":["f3f8a0f8bebc057ea4bdf65150b3fdc539db3d03","c1a1d77f7d47c04c0e559ece71d63fce1d394342"],"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"3dffec77fb8f7d0e9ca4869dddd6af94528b4576":["e7e8d6f15900ee22ac3cb0a503f15dc952a3580f","f3f8a0f8bebc057ea4bdf65150b3fdc539db3d03"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"f3f8a0f8bebc057ea4bdf65150b3fdc539db3d03":["e7e8d6f15900ee22ac3cb0a503f15dc952a3580f"],"b266fe0ac2172d4ad87cff12bd9bf9f8c8247345":["c1a1d77f7d47c04c0e559ece71d63fce1d394342"],"c1a1d77f7d47c04c0e559ece71d63fce1d394342":["f3f8a0f8bebc057ea4bdf65150b3fdc539db3d03"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["c1a1d77f7d47c04c0e559ece71d63fce1d394342","b266fe0ac2172d4ad87cff12bd9bf9f8c8247345"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b266fe0ac2172d4ad87cff12bd9bf9f8c8247345"]},"commit2Childs":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["e7e8d6f15900ee22ac3cb0a503f15dc952a3580f"],"55980207f1977bd1463465de1659b821347e2fa8":[],"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f":["3dffec77fb8f7d0e9ca4869dddd6af94528b4576","f3f8a0f8bebc057ea4bdf65150b3fdc539db3d03"],"3dffec77fb8f7d0e9ca4869dddd6af94528b4576":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"f3f8a0f8bebc057ea4bdf65150b3fdc539db3d03":["55980207f1977bd1463465de1659b821347e2fa8","3dffec77fb8f7d0e9ca4869dddd6af94528b4576","c1a1d77f7d47c04c0e559ece71d63fce1d394342"],"c1a1d77f7d47c04c0e559ece71d63fce1d394342":["55980207f1977bd1463465de1659b821347e2fa8","b266fe0ac2172d4ad87cff12bd9bf9f8c8247345","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"b266fe0ac2172d4ad87cff12bd9bf9f8c8247345":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["55980207f1977bd1463465de1659b821347e2fa8","3dffec77fb8f7d0e9ca4869dddd6af94528b4576","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}