{"path":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestPostingsHighlighterRanking.FakePassageFormatter#format(Passage[],String).mjava","commits":[{"id":"4b3d16cba9355e2e97962eb1c441bbd0b6735c15","date":1357426290,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestPostingsHighlighterRanking.FakePassageFormatter#format(Passage[],String).mjava","pathOld":"lucene/sandbox/src/test/org/apache/lucene/sandbox/postingshighlight/TestPostingsHighlighterRanking.FakePassageFormatter#format(Passage[],String).mjava","sourceNew":"    @Override\n    public String format(Passage passages[], String content) {\n      for (Passage p : passages) {\n        // verify some basics about the passage\n        assertTrue(p.getScore() >= 0);\n        assertTrue(p.getNumMatches() > 0);\n        assertTrue(p.getStartOffset() >= 0);\n        assertTrue(p.getStartOffset() <= content.length());\n        // we use a very simple analyzer. so we can assert the matches are correct\n        for (int i = 0; i < p.getNumMatches(); i++) {\n          Term term = p.getMatchTerms()[i];\n          assertEquals(\"body\", term.field());\n          int matchStart = p.getMatchStarts()[i];\n          assertTrue(matchStart >= 0);\n          int matchEnd = p.getMatchEnds()[i];\n          assertTrue(matchEnd >= 0);\n          // single character terms\n          assertEquals(matchStart+1, matchEnd);\n          // and the offsets must be correct...\n          BytesRef bytes = term.bytes();\n          assertEquals(1, bytes.length);\n          assertEquals((char)bytes.bytes[bytes.offset], Character.toLowerCase(content.charAt(matchStart)));\n        }\n        // record just the start/end offset for simplicity\n        seen.add(new Pair(p.getStartOffset(), p.getEndOffset()));\n      }\n      return \"bogus!!!!!!\";\n    }\n\n","sourceOld":"    @Override\n    public String format(Passage passages[], String content) {\n      for (Passage p : passages) {\n        // verify some basics about the passage\n        assertTrue(p.getScore() >= 0);\n        assertTrue(p.getNumMatches() > 0);\n        assertTrue(p.getStartOffset() >= 0);\n        assertTrue(p.getStartOffset() <= content.length());\n        // we use a very simple analyzer. so we can assert the matches are correct\n        for (int i = 0; i < p.getNumMatches(); i++) {\n          Term term = p.getMatchTerms()[i];\n          assertEquals(\"body\", term.field());\n          int matchStart = p.getMatchStarts()[i];\n          assertTrue(matchStart >= 0);\n          int matchEnd = p.getMatchEnds()[i];\n          assertTrue(matchEnd >= 0);\n          // single character terms\n          assertEquals(matchStart+1, matchEnd);\n          // and the offsets must be correct...\n          BytesRef bytes = term.bytes();\n          assertEquals(1, bytes.length);\n          assertEquals((char)bytes.bytes[bytes.offset], Character.toLowerCase(content.charAt(matchStart)));\n        }\n        // record just the start/end offset for simplicity\n        seen.add(new Pair(p.getStartOffset(), p.getEndOffset()));\n      }\n      return \"bogus!!!!!!\";\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d3fcb70cf561547c7bb1506e0cf32ca7b1287064","date":1357616416,"type":0,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestPostingsHighlighterRanking.FakePassageFormatter#format(Passage[],String).mjava","pathOld":"/dev/null","sourceNew":"    @Override\n    public String format(Passage passages[], String content) {\n      for (Passage p : passages) {\n        // verify some basics about the passage\n        assertTrue(p.getScore() >= 0);\n        assertTrue(p.getNumMatches() > 0);\n        assertTrue(p.getStartOffset() >= 0);\n        assertTrue(p.getStartOffset() <= content.length());\n        // we use a very simple analyzer. so we can assert the matches are correct\n        for (int i = 0; i < p.getNumMatches(); i++) {\n          Term term = p.getMatchTerms()[i];\n          assertEquals(\"body\", term.field());\n          int matchStart = p.getMatchStarts()[i];\n          assertTrue(matchStart >= 0);\n          int matchEnd = p.getMatchEnds()[i];\n          assertTrue(matchEnd >= 0);\n          // single character terms\n          assertEquals(matchStart+1, matchEnd);\n          // and the offsets must be correct...\n          BytesRef bytes = term.bytes();\n          assertEquals(1, bytes.length);\n          assertEquals((char)bytes.bytes[bytes.offset], Character.toLowerCase(content.charAt(matchStart)));\n        }\n        // record just the start/end offset for simplicity\n        seen.add(new Pair(p.getStartOffset(), p.getEndOffset()));\n      }\n      return \"bogus!!!!!!\";\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e4c0b17b8a1d791b23f2f7ee90448d718112841e","date":1361891420,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestPostingsHighlighterRanking.FakePassageFormatter#format(Passage[],String).mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestPostingsHighlighterRanking.FakePassageFormatter#format(Passage[],String).mjava","sourceNew":"    @Override\n    public String format(Passage passages[], String content) {\n      for (Passage p : passages) {\n        // verify some basics about the passage\n        assertTrue(p.getScore() >= 0);\n        assertTrue(p.getNumMatches() > 0);\n        assertTrue(p.getStartOffset() >= 0);\n        assertTrue(p.getStartOffset() <= content.length());\n        // we use a very simple analyzer. so we can assert the matches are correct\n        int lastMatchStart = -1;\n        for (int i = 0; i < p.getNumMatches(); i++) {\n          Term term = p.getMatchTerms()[i];\n          assertEquals(\"body\", term.field());\n          int matchStart = p.getMatchStarts()[i];\n          assertTrue(matchStart >= 0);\n          int matchEnd = p.getMatchEnds()[i];\n          assertTrue(matchEnd >= 0);\n          // always moving forward\n          assertTrue(matchStart >= lastMatchStart);\n          lastMatchStart = matchStart;\n          // single character terms\n          assertEquals(matchStart+1, matchEnd);\n          // and the offsets must be correct...\n          BytesRef bytes = term.bytes();\n          assertEquals(1, bytes.length);\n          assertEquals((char)bytes.bytes[bytes.offset], Character.toLowerCase(content.charAt(matchStart)));\n        }\n        // record just the start/end offset for simplicity\n        seen.add(new Pair(p.getStartOffset(), p.getEndOffset()));\n      }\n      return \"bogus!!!!!!\";\n    }\n\n","sourceOld":"    @Override\n    public String format(Passage passages[], String content) {\n      for (Passage p : passages) {\n        // verify some basics about the passage\n        assertTrue(p.getScore() >= 0);\n        assertTrue(p.getNumMatches() > 0);\n        assertTrue(p.getStartOffset() >= 0);\n        assertTrue(p.getStartOffset() <= content.length());\n        // we use a very simple analyzer. so we can assert the matches are correct\n        for (int i = 0; i < p.getNumMatches(); i++) {\n          Term term = p.getMatchTerms()[i];\n          assertEquals(\"body\", term.field());\n          int matchStart = p.getMatchStarts()[i];\n          assertTrue(matchStart >= 0);\n          int matchEnd = p.getMatchEnds()[i];\n          assertTrue(matchEnd >= 0);\n          // single character terms\n          assertEquals(matchStart+1, matchEnd);\n          // and the offsets must be correct...\n          BytesRef bytes = term.bytes();\n          assertEquals(1, bytes.length);\n          assertEquals((char)bytes.bytes[bytes.offset], Character.toLowerCase(content.charAt(matchStart)));\n        }\n        // record just the start/end offset for simplicity\n        seen.add(new Pair(p.getStartOffset(), p.getEndOffset()));\n      }\n      return \"bogus!!!!!!\";\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"86b90b0ece36c02b9f8b3a26374109d04b76274d","date":1361915620,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestPostingsHighlighterRanking.FakePassageFormatter#format(Passage[],String).mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestPostingsHighlighterRanking.FakePassageFormatter#format(Passage[],String).mjava","sourceNew":"    @Override\n    public String format(Passage passages[], String content) {\n      for (Passage p : passages) {\n        // verify some basics about the passage\n        assertTrue(p.getScore() >= 0);\n        assertTrue(p.getNumMatches() > 0);\n        assertTrue(p.getStartOffset() >= 0);\n        assertTrue(p.getStartOffset() <= content.length());\n        // we use a very simple analyzer. so we can assert the matches are correct\n        int lastMatchStart = -1;\n        for (int i = 0; i < p.getNumMatches(); i++) {\n          Term term = p.getMatchTerms()[i];\n          assertEquals(\"body\", term.field());\n          int matchStart = p.getMatchStarts()[i];\n          assertTrue(matchStart >= 0);\n          // must at least start within the passage\n          assertTrue(matchStart < p.getEndOffset());\n          int matchEnd = p.getMatchEnds()[i];\n          assertTrue(matchEnd >= 0);\n          // always moving forward\n          assertTrue(matchStart >= lastMatchStart);\n          lastMatchStart = matchStart;\n          // single character terms\n          assertEquals(matchStart+1, matchEnd);\n          // and the offsets must be correct...\n          BytesRef bytes = term.bytes();\n          assertEquals(1, bytes.length);\n          assertEquals((char)bytes.bytes[bytes.offset], Character.toLowerCase(content.charAt(matchStart)));\n        }\n        // record just the start/end offset for simplicity\n        seen.add(new Pair(p.getStartOffset(), p.getEndOffset()));\n      }\n      return \"bogus!!!!!!\";\n    }\n\n","sourceOld":"    @Override\n    public String format(Passage passages[], String content) {\n      for (Passage p : passages) {\n        // verify some basics about the passage\n        assertTrue(p.getScore() >= 0);\n        assertTrue(p.getNumMatches() > 0);\n        assertTrue(p.getStartOffset() >= 0);\n        assertTrue(p.getStartOffset() <= content.length());\n        // we use a very simple analyzer. so we can assert the matches are correct\n        int lastMatchStart = -1;\n        for (int i = 0; i < p.getNumMatches(); i++) {\n          Term term = p.getMatchTerms()[i];\n          assertEquals(\"body\", term.field());\n          int matchStart = p.getMatchStarts()[i];\n          assertTrue(matchStart >= 0);\n          int matchEnd = p.getMatchEnds()[i];\n          assertTrue(matchEnd >= 0);\n          // always moving forward\n          assertTrue(matchStart >= lastMatchStart);\n          lastMatchStart = matchStart;\n          // single character terms\n          assertEquals(matchStart+1, matchEnd);\n          // and the offsets must be correct...\n          BytesRef bytes = term.bytes();\n          assertEquals(1, bytes.length);\n          assertEquals((char)bytes.bytes[bytes.offset], Character.toLowerCase(content.charAt(matchStart)));\n        }\n        // record just the start/end offset for simplicity\n        seen.add(new Pair(p.getStartOffset(), p.getEndOffset()));\n      }\n      return \"bogus!!!!!!\";\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4831dd345148fcd7c33877b449ade21fc45459d8","date":1363963811,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestPostingsHighlighterRanking.FakePassageFormatter#format(Passage[],String).mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestPostingsHighlighterRanking.FakePassageFormatter#format(Passage[],String).mjava","sourceNew":"    @Override\n    public String format(Passage passages[], String content) {\n      for (Passage p : passages) {\n        // verify some basics about the passage\n        assertTrue(p.getScore() >= 0);\n        assertTrue(p.getNumMatches() > 0);\n        assertTrue(p.getStartOffset() >= 0);\n        assertTrue(p.getStartOffset() <= content.length());\n        // we use a very simple analyzer. so we can assert the matches are correct\n        int lastMatchStart = -1;\n        for (int i = 0; i < p.getNumMatches(); i++) {\n          BytesRef term = p.getMatchTerms()[i];\n          int matchStart = p.getMatchStarts()[i];\n          assertTrue(matchStart >= 0);\n          // must at least start within the passage\n          assertTrue(matchStart < p.getEndOffset());\n          int matchEnd = p.getMatchEnds()[i];\n          assertTrue(matchEnd >= 0);\n          // always moving forward\n          assertTrue(matchStart >= lastMatchStart);\n          lastMatchStart = matchStart;\n          // single character terms\n          assertEquals(matchStart+1, matchEnd);\n          // and the offsets must be correct...\n          assertEquals(1, term.length);\n          assertEquals((char)term.bytes[term.offset], Character.toLowerCase(content.charAt(matchStart)));\n        }\n        // record just the start/end offset for simplicity\n        seen.add(new Pair(p.getStartOffset(), p.getEndOffset()));\n      }\n      return \"bogus!!!!!!\";\n    }\n\n","sourceOld":"    @Override\n    public String format(Passage passages[], String content) {\n      for (Passage p : passages) {\n        // verify some basics about the passage\n        assertTrue(p.getScore() >= 0);\n        assertTrue(p.getNumMatches() > 0);\n        assertTrue(p.getStartOffset() >= 0);\n        assertTrue(p.getStartOffset() <= content.length());\n        // we use a very simple analyzer. so we can assert the matches are correct\n        int lastMatchStart = -1;\n        for (int i = 0; i < p.getNumMatches(); i++) {\n          Term term = p.getMatchTerms()[i];\n          assertEquals(\"body\", term.field());\n          int matchStart = p.getMatchStarts()[i];\n          assertTrue(matchStart >= 0);\n          // must at least start within the passage\n          assertTrue(matchStart < p.getEndOffset());\n          int matchEnd = p.getMatchEnds()[i];\n          assertTrue(matchEnd >= 0);\n          // always moving forward\n          assertTrue(matchStart >= lastMatchStart);\n          lastMatchStart = matchStart;\n          // single character terms\n          assertEquals(matchStart+1, matchEnd);\n          // and the offsets must be correct...\n          BytesRef bytes = term.bytes();\n          assertEquals(1, bytes.length);\n          assertEquals((char)bytes.bytes[bytes.offset], Character.toLowerCase(content.charAt(matchStart)));\n        }\n        // record just the start/end offset for simplicity\n        seen.add(new Pair(p.getStartOffset(), p.getEndOffset()));\n      }\n      return \"bogus!!!!!!\";\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"71393760b816981b3e59704441c8bd6f32276046","date":1376329629,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestPostingsHighlighterRanking.FakePassageFormatter#format(Passage[],String).mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestPostingsHighlighterRanking.FakePassageFormatter#format(Passage[],String).mjava","sourceNew":"    @Override\n    public String format(Passage passages[], String content) {\n      for (Passage p : passages) {\n        // verify some basics about the passage\n        assertTrue(p.getScore() >= 0);\n        assertTrue(p.getNumMatches() > 0);\n        assertTrue(p.getStartOffset() >= 0);\n        assertTrue(p.getStartOffset() <= content.length());\n        assertTrue(p.getEndOffset() >= p.getStartOffset());\n        assertTrue(p.getEndOffset() <= content.length());\n        // we use a very simple analyzer. so we can assert the matches are correct\n        int lastMatchStart = -1;\n        for (int i = 0; i < p.getNumMatches(); i++) {\n          BytesRef term = p.getMatchTerms()[i];\n          int matchStart = p.getMatchStarts()[i];\n          assertTrue(matchStart >= 0);\n          // must at least start within the passage\n          assertTrue(matchStart < p.getEndOffset());\n          int matchEnd = p.getMatchEnds()[i];\n          assertTrue(matchEnd >= 0);\n          // always moving forward\n          assertTrue(matchStart >= lastMatchStart);\n          lastMatchStart = matchStart;\n          // single character terms\n          assertEquals(matchStart+1, matchEnd);\n          // and the offsets must be correct...\n          assertEquals(1, term.length);\n          assertEquals((char)term.bytes[term.offset], Character.toLowerCase(content.charAt(matchStart)));\n        }\n        // record just the start/end offset for simplicity\n        seen.add(new Pair(p.getStartOffset(), p.getEndOffset()));\n      }\n      return \"bogus!!!!!!\";\n    }\n\n","sourceOld":"    @Override\n    public String format(Passage passages[], String content) {\n      for (Passage p : passages) {\n        // verify some basics about the passage\n        assertTrue(p.getScore() >= 0);\n        assertTrue(p.getNumMatches() > 0);\n        assertTrue(p.getStartOffset() >= 0);\n        assertTrue(p.getStartOffset() <= content.length());\n        // we use a very simple analyzer. so we can assert the matches are correct\n        int lastMatchStart = -1;\n        for (int i = 0; i < p.getNumMatches(); i++) {\n          BytesRef term = p.getMatchTerms()[i];\n          int matchStart = p.getMatchStarts()[i];\n          assertTrue(matchStart >= 0);\n          // must at least start within the passage\n          assertTrue(matchStart < p.getEndOffset());\n          int matchEnd = p.getMatchEnds()[i];\n          assertTrue(matchEnd >= 0);\n          // always moving forward\n          assertTrue(matchStart >= lastMatchStart);\n          lastMatchStart = matchStart;\n          // single character terms\n          assertEquals(matchStart+1, matchEnd);\n          // and the offsets must be correct...\n          assertEquals(1, term.length);\n          assertEquals((char)term.bytes[term.offset], Character.toLowerCase(content.charAt(matchStart)));\n        }\n        // record just the start/end offset for simplicity\n        seen.add(new Pair(p.getStartOffset(), p.getEndOffset()));\n      }\n      return \"bogus!!!!!!\";\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","date":1376366778,"type":3,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestPostingsHighlighterRanking.FakePassageFormatter#format(Passage[],String).mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestPostingsHighlighterRanking.FakePassageFormatter#format(Passage[],String).mjava","sourceNew":"    @Override\n    public String format(Passage passages[], String content) {\n      for (Passage p : passages) {\n        // verify some basics about the passage\n        assertTrue(p.getScore() >= 0);\n        assertTrue(p.getNumMatches() > 0);\n        assertTrue(p.getStartOffset() >= 0);\n        assertTrue(p.getStartOffset() <= content.length());\n        assertTrue(p.getEndOffset() >= p.getStartOffset());\n        assertTrue(p.getEndOffset() <= content.length());\n        // we use a very simple analyzer. so we can assert the matches are correct\n        int lastMatchStart = -1;\n        for (int i = 0; i < p.getNumMatches(); i++) {\n          BytesRef term = p.getMatchTerms()[i];\n          int matchStart = p.getMatchStarts()[i];\n          assertTrue(matchStart >= 0);\n          // must at least start within the passage\n          assertTrue(matchStart < p.getEndOffset());\n          int matchEnd = p.getMatchEnds()[i];\n          assertTrue(matchEnd >= 0);\n          // always moving forward\n          assertTrue(matchStart >= lastMatchStart);\n          lastMatchStart = matchStart;\n          // single character terms\n          assertEquals(matchStart+1, matchEnd);\n          // and the offsets must be correct...\n          assertEquals(1, term.length);\n          assertEquals((char)term.bytes[term.offset], Character.toLowerCase(content.charAt(matchStart)));\n        }\n        // record just the start/end offset for simplicity\n        seen.add(new Pair(p.getStartOffset(), p.getEndOffset()));\n      }\n      return \"bogus!!!!!!\";\n    }\n\n","sourceOld":"    @Override\n    public String format(Passage passages[], String content) {\n      for (Passage p : passages) {\n        // verify some basics about the passage\n        assertTrue(p.getScore() >= 0);\n        assertTrue(p.getNumMatches() > 0);\n        assertTrue(p.getStartOffset() >= 0);\n        assertTrue(p.getStartOffset() <= content.length());\n        // we use a very simple analyzer. so we can assert the matches are correct\n        int lastMatchStart = -1;\n        for (int i = 0; i < p.getNumMatches(); i++) {\n          BytesRef term = p.getMatchTerms()[i];\n          int matchStart = p.getMatchStarts()[i];\n          assertTrue(matchStart >= 0);\n          // must at least start within the passage\n          assertTrue(matchStart < p.getEndOffset());\n          int matchEnd = p.getMatchEnds()[i];\n          assertTrue(matchEnd >= 0);\n          // always moving forward\n          assertTrue(matchStart >= lastMatchStart);\n          lastMatchStart = matchStart;\n          // single character terms\n          assertEquals(matchStart+1, matchEnd);\n          // and the offsets must be correct...\n          assertEquals(1, term.length);\n          assertEquals((char)term.bytes[term.offset], Character.toLowerCase(content.charAt(matchStart)));\n        }\n        // record just the start/end offset for simplicity\n        seen.add(new Pair(p.getStartOffset(), p.getEndOffset()));\n      }\n      return \"bogus!!!!!!\";\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"381618eac2691bb34ab9a3fca76ad55c6274517e","date":1495564791,"type":4,"author":"David Smiley","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestPostingsHighlighterRanking.FakePassageFormatter#format(Passage[],String).mjava","sourceNew":null,"sourceOld":"    @Override\n    public String format(Passage passages[], String content) {\n      for (Passage p : passages) {\n        // verify some basics about the passage\n        assertTrue(p.getScore() >= 0);\n        assertTrue(p.getNumMatches() > 0);\n        assertTrue(p.getStartOffset() >= 0);\n        assertTrue(p.getStartOffset() <= content.length());\n        assertTrue(p.getEndOffset() >= p.getStartOffset());\n        assertTrue(p.getEndOffset() <= content.length());\n        // we use a very simple analyzer. so we can assert the matches are correct\n        int lastMatchStart = -1;\n        for (int i = 0; i < p.getNumMatches(); i++) {\n          BytesRef term = p.getMatchTerms()[i];\n          int matchStart = p.getMatchStarts()[i];\n          assertTrue(matchStart >= 0);\n          // must at least start within the passage\n          assertTrue(matchStart < p.getEndOffset());\n          int matchEnd = p.getMatchEnds()[i];\n          assertTrue(matchEnd >= 0);\n          // always moving forward\n          assertTrue(matchStart >= lastMatchStart);\n          lastMatchStart = matchStart;\n          // single character terms\n          assertEquals(matchStart+1, matchEnd);\n          // and the offsets must be correct...\n          assertEquals(1, term.length);\n          assertEquals((char)term.bytes[term.offset], Character.toLowerCase(content.charAt(matchStart)));\n        }\n        // record just the start/end offset for simplicity\n        seen.add(new Pair(p.getStartOffset(), p.getEndOffset()));\n      }\n      return \"bogus!!!!!!\";\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e9017cf144952056066919f1ebc7897ff9bd71b1","date":1496757600,"type":4,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestPostingsHighlighterRanking.FakePassageFormatter#format(Passage[],String).mjava","sourceNew":null,"sourceOld":"    @Override\n    public String format(Passage passages[], String content) {\n      for (Passage p : passages) {\n        // verify some basics about the passage\n        assertTrue(p.getScore() >= 0);\n        assertTrue(p.getNumMatches() > 0);\n        assertTrue(p.getStartOffset() >= 0);\n        assertTrue(p.getStartOffset() <= content.length());\n        assertTrue(p.getEndOffset() >= p.getStartOffset());\n        assertTrue(p.getEndOffset() <= content.length());\n        // we use a very simple analyzer. so we can assert the matches are correct\n        int lastMatchStart = -1;\n        for (int i = 0; i < p.getNumMatches(); i++) {\n          BytesRef term = p.getMatchTerms()[i];\n          int matchStart = p.getMatchStarts()[i];\n          assertTrue(matchStart >= 0);\n          // must at least start within the passage\n          assertTrue(matchStart < p.getEndOffset());\n          int matchEnd = p.getMatchEnds()[i];\n          assertTrue(matchEnd >= 0);\n          // always moving forward\n          assertTrue(matchStart >= lastMatchStart);\n          lastMatchStart = matchStart;\n          // single character terms\n          assertEquals(matchStart+1, matchEnd);\n          // and the offsets must be correct...\n          assertEquals(1, term.length);\n          assertEquals((char)term.bytes[term.offset], Character.toLowerCase(content.charAt(matchStart)));\n        }\n        // record just the start/end offset for simplicity\n        seen.add(new Pair(p.getStartOffset(), p.getEndOffset()));\n      }\n      return \"bogus!!!!!!\";\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"381618eac2691bb34ab9a3fca76ad55c6274517e":["71393760b816981b3e59704441c8bd6f32276046"],"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","4b3d16cba9355e2e97962eb1c441bbd0b6735c15"],"4b3d16cba9355e2e97962eb1c441bbd0b6735c15":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"e9017cf144952056066919f1ebc7897ff9bd71b1":["71393760b816981b3e59704441c8bd6f32276046","381618eac2691bb34ab9a3fca76ad55c6274517e"],"4831dd345148fcd7c33877b449ade21fc45459d8":["86b90b0ece36c02b9f8b3a26374109d04b76274d"],"e4c0b17b8a1d791b23f2f7ee90448d718112841e":["4b3d16cba9355e2e97962eb1c441bbd0b6735c15"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":["4831dd345148fcd7c33877b449ade21fc45459d8"],"86b90b0ece36c02b9f8b3a26374109d04b76274d":["e4c0b17b8a1d791b23f2f7ee90448d718112841e"],"71393760b816981b3e59704441c8bd6f32276046":["4831dd345148fcd7c33877b449ade21fc45459d8"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["381618eac2691bb34ab9a3fca76ad55c6274517e"]},"commit2Childs":{"381618eac2691bb34ab9a3fca76ad55c6274517e":["e9017cf144952056066919f1ebc7897ff9bd71b1","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":[],"4b3d16cba9355e2e97962eb1c441bbd0b6735c15":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","e4c0b17b8a1d791b23f2f7ee90448d718112841e"],"e9017cf144952056066919f1ebc7897ff9bd71b1":[],"4831dd345148fcd7c33877b449ade21fc45459d8":["8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","71393760b816981b3e59704441c8bd6f32276046"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","4b3d16cba9355e2e97962eb1c441bbd0b6735c15"],"e4c0b17b8a1d791b23f2f7ee90448d718112841e":["86b90b0ece36c02b9f8b3a26374109d04b76274d"],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":[],"86b90b0ece36c02b9f8b3a26374109d04b76274d":["4831dd345148fcd7c33877b449ade21fc45459d8"],"71393760b816981b3e59704441c8bd6f32276046":["381618eac2691bb34ab9a3fca76ad55c6274517e","e9017cf144952056066919f1ebc7897ff9bd71b1"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","e9017cf144952056066919f1ebc7897ff9bd71b1","8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}