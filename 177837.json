{"path":"lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterGraphFilter#bufferWordParts().mjava","commits":[{"id":"098528909bb70948871fd7ed865fafb87ed73964","date":1484667487,"type":0,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterGraphFilter#bufferWordParts().mjava","pathOld":"/dev/null","sourceNew":"  /** Iterates all words parts and concatenations, buffering up the term parts we should return. */\n  private void bufferWordParts() throws IOException {\n\n    saveState();\n\n    // if length by start + end offsets doesn't match the term's text then set offsets for all our word parts/concats to the incoming\n    // offsets.  this can happen if WDGF is applied to an injected synonym, or to a stem'd form, etc:\n    hasIllegalOffsets = (savedEndOffset - savedStartOffset != savedTermLength);\n\n    bufferedLen = 0;\n    lastConcatCount = 0;\n    wordPos = 0;\n\n    if (iterator.isSingleWord()) {\n      buffer(wordPos, wordPos+1, iterator.current, iterator.end);\n      wordPos++;\n      iterator.next();\n    } else {\n\n      // iterate all words parts, possibly buffering them, building up concatenations and possibly buffering them too:\n      while (iterator.end != WordDelimiterIterator.DONE) {\n        int wordType = iterator.type();\n      \n        // do we already have queued up incompatible concatenations?\n        if (concat.isNotEmpty() && (concat.type & wordType) == 0) {\n          flushConcatenation(concat);\n        }\n\n        // add subwords depending upon options\n        if (shouldConcatenate(wordType)) {\n          concatenate(concat);\n        }\n      \n        // add all subwords (catenateAll)\n        if (has(CATENATE_ALL)) {\n          concatenate(concatAll);\n        }\n      \n        // if we should output the word or number part\n        if (shouldGenerateParts(wordType)) {\n          buffer(wordPos, wordPos+1, iterator.current, iterator.end);\n          wordPos++;\n        }\n        iterator.next();\n      }\n\n      if (concat.isNotEmpty()) {\n        // flush final concatenation\n        flushConcatenation(concat);\n      }\n        \n      if (concatAll.isNotEmpty()) {\n        // only if we haven't output this same combo above, e.g. PowerShot with CATENATE_WORDS:\n        if (concatAll.subwordCount > lastConcatCount) {\n          if (wordPos == concatAll.startPos) {\n            // we are not generating parts, so we must advance wordPos now\n            wordPos++;\n          }\n          concatAll.write();\n        }\n        concatAll.clear();\n      }\n    }\n\n    if (has(PRESERVE_ORIGINAL)) {\n      if (wordPos == 0) {\n        // can happen w/ strange flag combos and inputs :)\n        wordPos++;\n      }\n      // add the original token now so that we can set the correct end position\n      buffer(0, wordPos, 0, savedTermLength);\n    }\n            \n    sorter.sort(0, bufferedLen);\n    wordPos = 0;\n\n    // set back to 0 for iterating from the buffer\n    bufferedPos = 0;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"302d34f2c66e8d489ee13078305c330cbf67b226","date":1484754357,"type":0,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterGraphFilter#bufferWordParts().mjava","pathOld":"/dev/null","sourceNew":"  /** Iterates all words parts and concatenations, buffering up the term parts we should return. */\n  private void bufferWordParts() throws IOException {\n\n    saveState();\n\n    // if length by start + end offsets doesn't match the term's text then set offsets for all our word parts/concats to the incoming\n    // offsets.  this can happen if WDGF is applied to an injected synonym, or to a stem'd form, etc:\n    hasIllegalOffsets = (savedEndOffset - savedStartOffset != savedTermLength);\n\n    bufferedLen = 0;\n    lastConcatCount = 0;\n    wordPos = 0;\n\n    if (iterator.isSingleWord()) {\n      buffer(wordPos, wordPos+1, iterator.current, iterator.end);\n      wordPos++;\n      iterator.next();\n    } else {\n\n      // iterate all words parts, possibly buffering them, building up concatenations and possibly buffering them too:\n      while (iterator.end != WordDelimiterIterator.DONE) {\n        int wordType = iterator.type();\n      \n        // do we already have queued up incompatible concatenations?\n        if (concat.isNotEmpty() && (concat.type & wordType) == 0) {\n          flushConcatenation(concat);\n        }\n\n        // add subwords depending upon options\n        if (shouldConcatenate(wordType)) {\n          concatenate(concat);\n        }\n      \n        // add all subwords (catenateAll)\n        if (has(CATENATE_ALL)) {\n          concatenate(concatAll);\n        }\n      \n        // if we should output the word or number part\n        if (shouldGenerateParts(wordType)) {\n          buffer(wordPos, wordPos+1, iterator.current, iterator.end);\n          wordPos++;\n        }\n        iterator.next();\n      }\n\n      if (concat.isNotEmpty()) {\n        // flush final concatenation\n        flushConcatenation(concat);\n      }\n        \n      if (concatAll.isNotEmpty()) {\n        // only if we haven't output this same combo above, e.g. PowerShot with CATENATE_WORDS:\n        if (concatAll.subwordCount > lastConcatCount) {\n          if (wordPos == concatAll.startPos) {\n            // we are not generating parts, so we must advance wordPos now\n            wordPos++;\n          }\n          concatAll.write();\n        }\n        concatAll.clear();\n      }\n    }\n\n    if (has(PRESERVE_ORIGINAL)) {\n      if (wordPos == 0) {\n        // can happen w/ strange flag combos and inputs :)\n        wordPos++;\n      }\n      // add the original token now so that we can set the correct end position\n      buffer(0, wordPos, 0, savedTermLength);\n    }\n            \n    sorter.sort(0, bufferedLen);\n    wordPos = 0;\n\n    // set back to 0 for iterating from the buffer\n    bufferedPos = 0;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"47e241984c8185946746fd8e18cff4200659091e","date":1543916862,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterGraphFilter#bufferWordParts().mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterGraphFilter#bufferWordParts().mjava","sourceNew":"  /** Iterates all words parts and concatenations, buffering up the term parts we should return. */\n  private void bufferWordParts() throws IOException {\n\n    saveState();\n\n    // if length by start + end offsets doesn't match the term's text then set offsets for all our word parts/concats to the incoming\n    // offsets.  this can happen if WDGF is applied to an injected synonym, or to a stem'd form, etc:\n    adjustingOffsets = adjustInternalOffsets && savedEndOffset - savedStartOffset == savedTermLength;\n\n    bufferedLen = 0;\n    lastConcatCount = 0;\n    wordPos = 0;\n\n    if (iterator.isSingleWord()) {\n      buffer(wordPos, wordPos+1, iterator.current, iterator.end);\n      wordPos++;\n      iterator.next();\n    } else {\n\n      // iterate all words parts, possibly buffering them, building up concatenations and possibly buffering them too:\n      while (iterator.end != WordDelimiterIterator.DONE) {\n        int wordType = iterator.type();\n      \n        // do we already have queued up incompatible concatenations?\n        if (concat.isNotEmpty() && (concat.type & wordType) == 0) {\n          flushConcatenation(concat);\n        }\n\n        // add subwords depending upon options\n        if (shouldConcatenate(wordType)) {\n          concatenate(concat);\n        }\n      \n        // add all subwords (catenateAll)\n        if (has(CATENATE_ALL)) {\n          concatenate(concatAll);\n        }\n      \n        // if we should output the word or number part\n        if (shouldGenerateParts(wordType)) {\n          buffer(wordPos, wordPos+1, iterator.current, iterator.end);\n          wordPos++;\n        }\n        iterator.next();\n      }\n\n      if (concat.isNotEmpty()) {\n        // flush final concatenation\n        flushConcatenation(concat);\n      }\n        \n      if (concatAll.isNotEmpty()) {\n        // only if we haven't output this same combo above, e.g. PowerShot with CATENATE_WORDS:\n        if (concatAll.subwordCount > lastConcatCount) {\n          if (wordPos == concatAll.startPos) {\n            // we are not generating parts, so we must advance wordPos now\n            wordPos++;\n          }\n          concatAll.write();\n        }\n        concatAll.clear();\n      }\n    }\n\n    if (has(PRESERVE_ORIGINAL)) {\n      if (wordPos == 0) {\n        // can happen w/ strange flag combos and inputs :)\n        wordPos++;\n      }\n      // add the original token now so that we can set the correct end position\n      buffer(0, wordPos, 0, savedTermLength);\n    }\n            \n    sorter.sort(0, bufferedLen);\n    wordPos = 0;\n\n    // set back to 0 for iterating from the buffer\n    bufferedPos = 0;\n  }\n\n","sourceOld":"  /** Iterates all words parts and concatenations, buffering up the term parts we should return. */\n  private void bufferWordParts() throws IOException {\n\n    saveState();\n\n    // if length by start + end offsets doesn't match the term's text then set offsets for all our word parts/concats to the incoming\n    // offsets.  this can happen if WDGF is applied to an injected synonym, or to a stem'd form, etc:\n    hasIllegalOffsets = (savedEndOffset - savedStartOffset != savedTermLength);\n\n    bufferedLen = 0;\n    lastConcatCount = 0;\n    wordPos = 0;\n\n    if (iterator.isSingleWord()) {\n      buffer(wordPos, wordPos+1, iterator.current, iterator.end);\n      wordPos++;\n      iterator.next();\n    } else {\n\n      // iterate all words parts, possibly buffering them, building up concatenations and possibly buffering them too:\n      while (iterator.end != WordDelimiterIterator.DONE) {\n        int wordType = iterator.type();\n      \n        // do we already have queued up incompatible concatenations?\n        if (concat.isNotEmpty() && (concat.type & wordType) == 0) {\n          flushConcatenation(concat);\n        }\n\n        // add subwords depending upon options\n        if (shouldConcatenate(wordType)) {\n          concatenate(concat);\n        }\n      \n        // add all subwords (catenateAll)\n        if (has(CATENATE_ALL)) {\n          concatenate(concatAll);\n        }\n      \n        // if we should output the word or number part\n        if (shouldGenerateParts(wordType)) {\n          buffer(wordPos, wordPos+1, iterator.current, iterator.end);\n          wordPos++;\n        }\n        iterator.next();\n      }\n\n      if (concat.isNotEmpty()) {\n        // flush final concatenation\n        flushConcatenation(concat);\n      }\n        \n      if (concatAll.isNotEmpty()) {\n        // only if we haven't output this same combo above, e.g. PowerShot with CATENATE_WORDS:\n        if (concatAll.subwordCount > lastConcatCount) {\n          if (wordPos == concatAll.startPos) {\n            // we are not generating parts, so we must advance wordPos now\n            wordPos++;\n          }\n          concatAll.write();\n        }\n        concatAll.clear();\n      }\n    }\n\n    if (has(PRESERVE_ORIGINAL)) {\n      if (wordPos == 0) {\n        // can happen w/ strange flag combos and inputs :)\n        wordPos++;\n      }\n      // add the original token now so that we can set the correct end position\n      buffer(0, wordPos, 0, savedTermLength);\n    }\n            \n    sorter.sort(0, bufferedLen);\n    wordPos = 0;\n\n    // set back to 0 for iterating from the buffer\n    bufferedPos = 0;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9a2e54c3916a617394d9b279fef949760a349a75","date":1554191929,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterGraphFilter#bufferWordParts().mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterGraphFilter#bufferWordParts().mjava","sourceNew":"  /** Iterates all words parts and concatenations, buffering up the term parts we should return. */\n  private void bufferWordParts() throws IOException {\n\n    saveState();\n\n    // if length by start + end offsets doesn't match the term's text then set offsets for all our word parts/concats to the incoming\n    // offsets.  this can happen if WDGF is applied to an injected synonym, or to a stem'd form, etc:\n    adjustingOffsets = adjustInternalOffsets && savedEndOffset - savedStartOffset == savedTermLength;\n\n    bufferedLen = 0;\n    lastConcatCount = 0;\n    wordPos = 0;\n\n    if (has(PRESERVE_ORIGINAL)) {\n      // add the original token now so that it is always emitted first\n      // we will edit the term length after all other parts have been buffered\n      buffer(0, 1, 0, savedTermLength);\n    }\n\n    if (iterator.isSingleWord()) {\n      buffer(wordPos, wordPos+1, iterator.current, iterator.end);\n      wordPos++;\n      iterator.next();\n    } else {\n\n      // iterate all words parts, possibly buffering them, building up concatenations and possibly buffering them too:\n      while (iterator.end != WordDelimiterIterator.DONE) {\n        int wordType = iterator.type();\n      \n        // do we already have queued up incompatible concatenations?\n        if (concat.isNotEmpty() && (concat.type & wordType) == 0) {\n          flushConcatenation(concat);\n        }\n\n        // add subwords depending upon options\n        if (shouldConcatenate(wordType)) {\n          concatenate(concat);\n        }\n      \n        // add all subwords (catenateAll)\n        if (has(CATENATE_ALL)) {\n          concatenate(concatAll);\n        }\n      \n        // if we should output the word or number part\n        if (shouldGenerateParts(wordType)) {\n          buffer(wordPos, wordPos+1, iterator.current, iterator.end);\n          wordPos++;\n        }\n        iterator.next();\n      }\n\n      if (concat.isNotEmpty()) {\n        // flush final concatenation\n        flushConcatenation(concat);\n      }\n        \n      if (concatAll.isNotEmpty()) {\n        // only if we haven't output this same combo above, e.g. PowerShot with CATENATE_WORDS:\n        if (concatAll.subwordCount > lastConcatCount) {\n          if (wordPos == concatAll.startPos) {\n            // we are not generating parts, so we must advance wordPos now\n            wordPos++;\n          }\n          concatAll.write();\n        }\n        concatAll.clear();\n      }\n    }\n\n    if (has(PRESERVE_ORIGINAL)) {\n      // we now know how many tokens need to be injected, so we can set the original\n      // token's position length\n      if (wordPos == 0) {\n        // can happen w/ strange flag combos and inputs :)\n        wordPos++;\n      }\n      bufferedParts[1] = wordPos;\n    }\n            \n    sorter.sort(has(PRESERVE_ORIGINAL) ? 1 : 0, bufferedLen);\n    wordPos = 0;\n\n    // set back to 0 for iterating from the buffer\n    bufferedPos = 0;\n  }\n\n","sourceOld":"  /** Iterates all words parts and concatenations, buffering up the term parts we should return. */\n  private void bufferWordParts() throws IOException {\n\n    saveState();\n\n    // if length by start + end offsets doesn't match the term's text then set offsets for all our word parts/concats to the incoming\n    // offsets.  this can happen if WDGF is applied to an injected synonym, or to a stem'd form, etc:\n    adjustingOffsets = adjustInternalOffsets && savedEndOffset - savedStartOffset == savedTermLength;\n\n    bufferedLen = 0;\n    lastConcatCount = 0;\n    wordPos = 0;\n\n    if (iterator.isSingleWord()) {\n      buffer(wordPos, wordPos+1, iterator.current, iterator.end);\n      wordPos++;\n      iterator.next();\n    } else {\n\n      // iterate all words parts, possibly buffering them, building up concatenations and possibly buffering them too:\n      while (iterator.end != WordDelimiterIterator.DONE) {\n        int wordType = iterator.type();\n      \n        // do we already have queued up incompatible concatenations?\n        if (concat.isNotEmpty() && (concat.type & wordType) == 0) {\n          flushConcatenation(concat);\n        }\n\n        // add subwords depending upon options\n        if (shouldConcatenate(wordType)) {\n          concatenate(concat);\n        }\n      \n        // add all subwords (catenateAll)\n        if (has(CATENATE_ALL)) {\n          concatenate(concatAll);\n        }\n      \n        // if we should output the word or number part\n        if (shouldGenerateParts(wordType)) {\n          buffer(wordPos, wordPos+1, iterator.current, iterator.end);\n          wordPos++;\n        }\n        iterator.next();\n      }\n\n      if (concat.isNotEmpty()) {\n        // flush final concatenation\n        flushConcatenation(concat);\n      }\n        \n      if (concatAll.isNotEmpty()) {\n        // only if we haven't output this same combo above, e.g. PowerShot with CATENATE_WORDS:\n        if (concatAll.subwordCount > lastConcatCount) {\n          if (wordPos == concatAll.startPos) {\n            // we are not generating parts, so we must advance wordPos now\n            wordPos++;\n          }\n          concatAll.write();\n        }\n        concatAll.clear();\n      }\n    }\n\n    if (has(PRESERVE_ORIGINAL)) {\n      if (wordPos == 0) {\n        // can happen w/ strange flag combos and inputs :)\n        wordPos++;\n      }\n      // add the original token now so that we can set the correct end position\n      buffer(0, wordPos, 0, savedTermLength);\n    }\n            \n    sorter.sort(0, bufferedLen);\n    wordPos = 0;\n\n    // set back to 0 for iterating from the buffer\n    bufferedPos = 0;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"098528909bb70948871fd7ed865fafb87ed73964":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"9a2e54c3916a617394d9b279fef949760a349a75":["47e241984c8185946746fd8e18cff4200659091e"],"47e241984c8185946746fd8e18cff4200659091e":["098528909bb70948871fd7ed865fafb87ed73964"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9a2e54c3916a617394d9b279fef949760a349a75"],"302d34f2c66e8d489ee13078305c330cbf67b226":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","098528909bb70948871fd7ed865fafb87ed73964"]},"commit2Childs":{"098528909bb70948871fd7ed865fafb87ed73964":["47e241984c8185946746fd8e18cff4200659091e","302d34f2c66e8d489ee13078305c330cbf67b226"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["098528909bb70948871fd7ed865fafb87ed73964","302d34f2c66e8d489ee13078305c330cbf67b226"],"9a2e54c3916a617394d9b279fef949760a349a75":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"47e241984c8185946746fd8e18cff4200659091e":["9a2e54c3916a617394d9b279fef949760a349a75"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"302d34f2c66e8d489ee13078305c330cbf67b226":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817","302d34f2c66e8d489ee13078305c330cbf67b226"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}