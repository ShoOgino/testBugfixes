{"path":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","commits":[{"id":"fe999fc2d95d6fea71f960bf9556858387ba21f5","date":1363294860,"type":1,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.getCollections().contains(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = msgStrToInt(message, REPLICATION_FACTOR, 1);\n      int numSlices = msgStrToInt(message, NUM_SLICES, 0);\n      int maxShardsPerNode = msgStrToInt(message, MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        SolrException.log(log, REPLICATION_FACTOR + \" must be > 0\");\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n      }\n      \n      if (numSlices < 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      String configName = message.getStr(\"collection.configName\");\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<String>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live (\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      \n      for (int i = 1; i <= numSlices; i++) {\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String sliceName = \"shard\" + i;\n          String shardName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + shardName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n          \n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n          \n          params.set(CoreAdminParams.NAME, shardName);\n          params.set(\"collection.configName\", configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n          \n          ShardRequest sreq = new ShardRequest();\n          sreq.nodeName = nodeName;\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          String replica = zkStateReader.getZkClient()\n            .getBaseUrlForNodeName(nodeName);\n          if (replica.startsWith(\"http://\")) replica = replica.substring(7);\n          sreq.shards = new String[] {replica};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n          \n          shardHandler.submit(sreq, replica, sreq.params);\n          \n        }\n      }\n      \n      ShardResponse srsp;\n      do {\n        srsp = shardHandler.takeCompletedOrError();\n        if (srsp != null) {\n          processResponse(results, srsp);\n        }\n      } while (srsp != null);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private boolean createCollection(ClusterState clusterState, ZkNodeProps message) {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.getCollections().contains(collectionName)) {\n      SolrException.log(log, \"collection already exists: \" + collectionName);\n      return false;\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = msgStrToInt(message, REPLICATION_FACTOR, 1);\n      int numSlices = msgStrToInt(message, NUM_SLICES, 0);\n      int maxShardsPerNode = msgStrToInt(message, MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        SolrException.log(log, REPLICATION_FACTOR + \" must be > 0\");\n        return false;\n      }\n      \n      if (numSlices < 0) {\n        SolrException.log(log, NUM_SLICES + \" must be > 0\");\n        return false;\n      }\n      \n      String configName = message.getStr(\"collection.configName\");\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<String>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        log.error(\"Cannot create collection \" + collectionName\n            + \". No live Solr-instaces\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET:\"\"));\n        return false;\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live (\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        log.error(\"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n        return false;\n      }\n      \n      for (int i = 1; i <= numSlices; i++) {\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String sliceName = \"shard\" + i;\n          String shardName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + shardName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n          \n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n          \n          params.set(CoreAdminParams.NAME, shardName);\n          params.set(\"collection.configName\", configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n          \n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          String replica = zkStateReader.getZkClient()\n            .getBaseUrlForNodeName(nodeName);\n          if (replica.startsWith(\"http://\")) replica = replica.substring(7);\n          sreq.shards = new String[] {replica};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n          \n          shardHandler.submit(sreq, replica, sreq.params);\n          \n        }\n      }\n      \n      int failed = 0;\n      ShardResponse srsp;\n      do {\n        srsp = shardHandler.takeCompletedOrError();\n        if (srsp != null) {\n          Throwable e = srsp.getException();\n          if (e != null) {\n            // should we retry?\n            // TODO: we should return errors to the client\n            // TODO: what if one fails and others succeed?\n            failed++;\n            log.error(\"Error talking to shard: \" + srsp.getShard(), e);\n          }\n        }\n      } while (srsp != null);\n      \n      // if all calls succeeded, return true\n      if (failed > 0) {\n        return false;\n      }\n      log.info(\"Successfully created all shards for collection \"\n          + collectionName);\n      return true;\n    } catch (Exception ex) {\n      // Expecting that the necessary logging has already been performed\n      return false;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"630c3d71b7859a9f17dd985bb82bba51bccee575","date":1363359782,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.getCollections().contains(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = msgStrToInt(message, REPLICATION_FACTOR, 1);\n      Integer numSlices = msgStrToInt(message, NUM_SLICES, null);\n      \n      if (numSlices == null) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n      }\n      \n      int maxShardsPerNode = msgStrToInt(message, MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required paramater\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      String configName = message.getStr(\"collection.configName\");\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<String>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live (\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      \n      for (int i = 1; i <= numSlices; i++) {\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String sliceName = \"shard\" + i;\n          String shardName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + shardName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n          \n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n          \n          params.set(CoreAdminParams.NAME, shardName);\n          params.set(\"collection.configName\", configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n          \n          ShardRequest sreq = new ShardRequest();\n          sreq.nodeName = nodeName;\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          String replica = zkStateReader.getZkClient()\n            .getBaseUrlForNodeName(nodeName);\n          if (replica.startsWith(\"http://\")) replica = replica.substring(7);\n          sreq.shards = new String[] {replica};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n          \n          shardHandler.submit(sreq, replica, sreq.params);\n          \n        }\n      }\n      \n      ShardResponse srsp;\n      do {\n        srsp = shardHandler.takeCompletedOrError();\n        if (srsp != null) {\n          processResponse(results, srsp);\n        }\n      } while (srsp != null);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.getCollections().contains(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = msgStrToInt(message, REPLICATION_FACTOR, 1);\n      int numSlices = msgStrToInt(message, NUM_SLICES, 0);\n      int maxShardsPerNode = msgStrToInt(message, MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        SolrException.log(log, REPLICATION_FACTOR + \" must be > 0\");\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n      }\n      \n      if (numSlices < 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      String configName = message.getStr(\"collection.configName\");\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<String>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live (\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      \n      for (int i = 1; i <= numSlices; i++) {\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String sliceName = \"shard\" + i;\n          String shardName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + shardName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n          \n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n          \n          params.set(CoreAdminParams.NAME, shardName);\n          params.set(\"collection.configName\", configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n          \n          ShardRequest sreq = new ShardRequest();\n          sreq.nodeName = nodeName;\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          String replica = zkStateReader.getZkClient()\n            .getBaseUrlForNodeName(nodeName);\n          if (replica.startsWith(\"http://\")) replica = replica.substring(7);\n          sreq.shards = new String[] {replica};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n          \n          shardHandler.submit(sreq, replica, sreq.params);\n          \n        }\n      }\n      \n      ShardResponse srsp;\n      do {\n        srsp = shardHandler.takeCompletedOrError();\n        if (srsp != null) {\n          processResponse(results, srsp);\n        }\n      } while (srsp != null);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":["4f762b78b5a7fc5814208ae853b54d0041b2e2b1"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6e756785b6f25f3b8f7ee57c7e210c6b67fbfbbf","date":1363562282,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.getCollections().contains(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = msgStrToInt(message, REPLICATION_FACTOR, 1);\n      Integer numSlices = msgStrToInt(message, NUM_SLICES, null);\n      \n      if (numSlices == null) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n      }\n      \n      int maxShardsPerNode = msgStrToInt(message, MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required paramater\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      String configName = message.getStr(\"collection.configName\");\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<String>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      \n      for (int i = 1; i <= numSlices; i++) {\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String sliceName = \"shard\" + i;\n          String shardName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + shardName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n          \n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n          \n          params.set(CoreAdminParams.NAME, shardName);\n          params.set(\"collection.configName\", configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n          \n          ShardRequest sreq = new ShardRequest();\n          sreq.nodeName = nodeName;\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          String replica = zkStateReader.getZkClient()\n            .getBaseUrlForNodeName(nodeName);\n          if (replica.startsWith(\"http://\")) replica = replica.substring(7);\n          sreq.shards = new String[] {replica};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n          \n          shardHandler.submit(sreq, replica, sreq.params);\n          \n        }\n      }\n      \n      ShardResponse srsp;\n      do {\n        srsp = shardHandler.takeCompletedOrError();\n        if (srsp != null) {\n          processResponse(results, srsp);\n        }\n      } while (srsp != null);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.getCollections().contains(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = msgStrToInt(message, REPLICATION_FACTOR, 1);\n      Integer numSlices = msgStrToInt(message, NUM_SLICES, null);\n      \n      if (numSlices == null) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n      }\n      \n      int maxShardsPerNode = msgStrToInt(message, MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required paramater\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      String configName = message.getStr(\"collection.configName\");\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<String>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live (\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      \n      for (int i = 1; i <= numSlices; i++) {\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String sliceName = \"shard\" + i;\n          String shardName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + shardName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n          \n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n          \n          params.set(CoreAdminParams.NAME, shardName);\n          params.set(\"collection.configName\", configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n          \n          ShardRequest sreq = new ShardRequest();\n          sreq.nodeName = nodeName;\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          String replica = zkStateReader.getZkClient()\n            .getBaseUrlForNodeName(nodeName);\n          if (replica.startsWith(\"http://\")) replica = replica.substring(7);\n          sreq.shards = new String[] {replica};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n          \n          shardHandler.submit(sreq, replica, sreq.params);\n          \n        }\n      }\n      \n      ShardResponse srsp;\n      do {\n        srsp = shardHandler.takeCompletedOrError();\n        if (srsp != null) {\n          processResponse(results, srsp);\n        }\n      } while (srsp != null);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0beaed456aa3358e5e4a99ea2aea994ef6c81de3","date":1365434191,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.getCollections().contains(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = msgStrToInt(message, REPLICATION_FACTOR, 1);\n      Integer numSlices = msgStrToInt(message, NUM_SLICES, null);\n      \n      if (numSlices == null) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n      }\n      \n      int maxShardsPerNode = msgStrToInt(message, MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required paramater\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      String configName = message.getStr(\"collection.configName\");\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<String>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      \n      for (int i = 1; i <= numSlices; i++) {\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String sliceName = \"shard\" + i;\n          String shardName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + shardName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n          \n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n          \n          params.set(CoreAdminParams.NAME, shardName);\n          params.set(\"collection.configName\", configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n          \n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          String replica = zkStateReader.getZkClient()\n            .getBaseUrlForNodeName(nodeName);\n          if (replica.startsWith(\"http://\")) replica = replica.substring(7);\n          sreq.shards = new String[] {replica};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n          \n          shardHandler.submit(sreq, replica, sreq.params);\n          \n        }\n      }\n      \n      ShardResponse srsp;\n      do {\n        srsp = shardHandler.takeCompletedOrError();\n        if (srsp != null) {\n          processResponse(results, srsp);\n        }\n      } while (srsp != null);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.getCollections().contains(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = msgStrToInt(message, REPLICATION_FACTOR, 1);\n      Integer numSlices = msgStrToInt(message, NUM_SLICES, null);\n      \n      if (numSlices == null) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n      }\n      \n      int maxShardsPerNode = msgStrToInt(message, MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required paramater\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      String configName = message.getStr(\"collection.configName\");\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<String>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      \n      for (int i = 1; i <= numSlices; i++) {\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String sliceName = \"shard\" + i;\n          String shardName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + shardName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n          \n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n          \n          params.set(CoreAdminParams.NAME, shardName);\n          params.set(\"collection.configName\", configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n          \n          ShardRequest sreq = new ShardRequest();\n          sreq.nodeName = nodeName;\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          String replica = zkStateReader.getZkClient()\n            .getBaseUrlForNodeName(nodeName);\n          if (replica.startsWith(\"http://\")) replica = replica.substring(7);\n          sreq.shards = new String[] {replica};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n          \n          shardHandler.submit(sreq, replica, sreq.params);\n          \n        }\n      }\n      \n      ShardResponse srsp;\n      do {\n        srsp = shardHandler.takeCompletedOrError();\n        if (srsp != null) {\n          processResponse(results, srsp);\n        }\n      } while (srsp != null);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4f762b78b5a7fc5814208ae853b54d0041b2e2b1","date":1366742925,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.getCollections().contains(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = msgStrToInt(message, REPLICATION_FACTOR, 1);\n      Integer numSlices = msgStrToInt(message, NUM_SLICES, null);\n      \n      if (numSlices == null) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param\");\n      }\n      \n      int maxShardsPerNode = msgStrToInt(message, MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than or equal to 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      String configName = message.getStr(\"collection.configName\");\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<String>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      \n      for (int i = 1; i <= numSlices; i++) {\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String sliceName = \"shard\" + i;\n          String shardName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + shardName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n          \n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n          \n          params.set(CoreAdminParams.NAME, shardName);\n          params.set(\"collection.configName\", configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n          \n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          String replica = zkStateReader.getZkClient()\n            .getBaseUrlForNodeName(nodeName);\n          if (replica.startsWith(\"http://\")) replica = replica.substring(7);\n          sreq.shards = new String[] {replica};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n          \n          shardHandler.submit(sreq, replica, sreq.params);\n          \n        }\n      }\n      \n      ShardResponse srsp;\n      do {\n        srsp = shardHandler.takeCompletedOrError();\n        if (srsp != null) {\n          processResponse(results, srsp);\n        }\n      } while (srsp != null);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.getCollections().contains(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = msgStrToInt(message, REPLICATION_FACTOR, 1);\n      Integer numSlices = msgStrToInt(message, NUM_SLICES, null);\n      \n      if (numSlices == null) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n      }\n      \n      int maxShardsPerNode = msgStrToInt(message, MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required paramater\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      String configName = message.getStr(\"collection.configName\");\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<String>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      \n      for (int i = 1; i <= numSlices; i++) {\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String sliceName = \"shard\" + i;\n          String shardName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + shardName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n          \n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n          \n          params.set(CoreAdminParams.NAME, shardName);\n          params.set(\"collection.configName\", configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n          \n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          String replica = zkStateReader.getZkClient()\n            .getBaseUrlForNodeName(nodeName);\n          if (replica.startsWith(\"http://\")) replica = replica.substring(7);\n          sreq.shards = new String[] {replica};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n          \n          shardHandler.submit(sreq, replica, sreq.params);\n          \n        }\n      }\n      \n      ShardResponse srsp;\n      do {\n        srsp = shardHandler.takeCompletedOrError();\n        if (srsp != null) {\n          processResponse(results, srsp);\n        }\n      } while (srsp != null);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":["630c3d71b7859a9f17dd985bb82bba51bccee575"],"bugIntro":["6421b93f31f88ed3e81722f3bf9fabaff15e03a9"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1eeda7e62e149f90eee8895af874c74efa7d4852","date":1375293182,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.getCollections().contains(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt( REPLICATION_FACTOR, 1);\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(ROUTER, DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        Overseer.getShardNames(shardNames, message.getStr(\"shards\",null));\n        numSlices = shardNames.size();\n      } else {\n        Overseer.getShardNames(numSlices,shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param\");\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than or equal to 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<String>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n\n//      ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION,\n//          Overseer.CREATECOLLECTION, \"name\", message.getStr(\"name\"));\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.currentTimeMillis() + 30000;\n      boolean created = false;\n      while (System.currentTimeMillis() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully createcollection: \" + message.getStr(\"name\"));\n\n\n      String configName = message.getStr(COLL_CONF);\n      log.info(\"going to create cores replicas shardNames {} , repFactor : {}\", shardNames, repFactor);\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String shardName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + shardName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, shardName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          String replica = zkStateReader.getZkClient()\n            .getBaseUrlForNodeName(nodeName);\n          if (replica.startsWith(\"http://\")) replica = replica.substring(7);\n          sreq.shards = new String[] {replica};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          shardHandler.submit(sreq, replica, sreq.params);\n\n        }\n      }\n\n      ShardResponse srsp;\n      do {\n        srsp = shardHandler.takeCompletedOrError();\n        if (srsp != null) {\n          processResponse(results, srsp);\n        }\n      } while (srsp != null);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.getCollections().contains(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = msgStrToInt(message, REPLICATION_FACTOR, 1);\n      Integer numSlices = msgStrToInt(message, NUM_SLICES, null);\n      \n      if (numSlices == null) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param\");\n      }\n      \n      int maxShardsPerNode = msgStrToInt(message, MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than or equal to 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      String configName = message.getStr(\"collection.configName\");\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<String>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      \n      for (int i = 1; i <= numSlices; i++) {\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String sliceName = \"shard\" + i;\n          String shardName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + shardName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n          \n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n          \n          params.set(CoreAdminParams.NAME, shardName);\n          params.set(\"collection.configName\", configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n          \n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          String replica = zkStateReader.getZkClient()\n            .getBaseUrlForNodeName(nodeName);\n          if (replica.startsWith(\"http://\")) replica = replica.substring(7);\n          sreq.shards = new String[] {replica};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n          \n          shardHandler.submit(sreq, replica, sreq.params);\n          \n        }\n      }\n      \n      ShardResponse srsp;\n      do {\n        srsp = shardHandler.takeCompletedOrError();\n        if (srsp != null) {\n          processResponse(results, srsp);\n        }\n      } while (srsp != null);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":["eb4db141b31e99d2285436da1428411ed5501f56"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"716d18f3a9b0993bc679d7fa7abdc9bfb03411ec","date":1376375609,"type":3,"author":"Han Jiang","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.getCollections().contains(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt( REPLICATION_FACTOR, 1);\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(ROUTER, DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        Overseer.getShardNames(shardNames, message.getStr(\"shards\",null));\n        numSlices = shardNames.size();\n      } else {\n        Overseer.getShardNames(numSlices,shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param\");\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than or equal to 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<String>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n\n//      ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION,\n//          Overseer.CREATECOLLECTION, \"name\", message.getStr(\"name\"));\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.currentTimeMillis() + 30000;\n      boolean created = false;\n      while (System.currentTimeMillis() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully createcollection: \" + message.getStr(\"name\"));\n\n\n      String configName = message.getStr(COLL_CONF);\n      log.info(\"going to create cores replicas shardNames {} , repFactor : {}\", shardNames, repFactor);\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String shardName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + shardName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, shardName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          String replica = zkStateReader.getZkClient()\n            .getBaseUrlForNodeName(nodeName);\n          if (replica.startsWith(\"http://\")) replica = replica.substring(7);\n          sreq.shards = new String[] {replica};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          shardHandler.submit(sreq, replica, sreq.params);\n\n        }\n      }\n\n      ShardResponse srsp;\n      do {\n        srsp = shardHandler.takeCompletedOrError();\n        if (srsp != null) {\n          processResponse(results, srsp);\n        }\n      } while (srsp != null);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.getCollections().contains(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = msgStrToInt(message, REPLICATION_FACTOR, 1);\n      Integer numSlices = msgStrToInt(message, NUM_SLICES, null);\n      \n      if (numSlices == null) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param\");\n      }\n      \n      int maxShardsPerNode = msgStrToInt(message, MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than or equal to 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      String configName = message.getStr(\"collection.configName\");\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<String>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      \n      for (int i = 1; i <= numSlices; i++) {\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String sliceName = \"shard\" + i;\n          String shardName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + shardName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n          \n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n          \n          params.set(CoreAdminParams.NAME, shardName);\n          params.set(\"collection.configName\", configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n          \n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          String replica = zkStateReader.getZkClient()\n            .getBaseUrlForNodeName(nodeName);\n          if (replica.startsWith(\"http://\")) replica = replica.substring(7);\n          sreq.shards = new String[] {replica};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n          \n          shardHandler.submit(sreq, replica, sreq.params);\n          \n        }\n      }\n      \n      ShardResponse srsp;\n      do {\n        srsp = shardHandler.takeCompletedOrError();\n        if (srsp != null) {\n          processResponse(results, srsp);\n        }\n      } while (srsp != null);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e187a371a1d09379bb452c2c13a7b9221525dff8","date":1379517004,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.getCollections().contains(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt( REPLICATION_FACTOR, 1);\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        Overseer.getShardNames(shardNames, message.getStr(\"shards\",null));\n        numSlices = shardNames.size();\n      } else {\n        Overseer.getShardNames(numSlices,shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param\");\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than or equal to 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<String>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.currentTimeMillis() + 30000;\n      boolean created = false;\n      while (System.currentTimeMillis() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully createcollection: \" + message.getStr(\"name\"));\n\n\n      String configName = message.getStr(COLL_CONF);\n      log.info(\"going to create cores replicas shardNames {} , repFactor : {}\", shardNames, repFactor);\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String shardName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + shardName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, shardName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          String replica = zkStateReader.getZkClient()\n            .getBaseUrlForNodeName(nodeName);\n          if (replica.startsWith(\"http://\")) replica = replica.substring(7);\n          sreq.shards = new String[] {replica};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          shardHandler.submit(sreq, replica, sreq.params);\n\n        }\n      }\n\n      ShardResponse srsp;\n      do {\n        srsp = shardHandler.takeCompletedOrError();\n        if (srsp != null) {\n          processResponse(results, srsp);\n        }\n      } while (srsp != null);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.getCollections().contains(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt( REPLICATION_FACTOR, 1);\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(ROUTER, DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        Overseer.getShardNames(shardNames, message.getStr(\"shards\",null));\n        numSlices = shardNames.size();\n      } else {\n        Overseer.getShardNames(numSlices,shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param\");\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than or equal to 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<String>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n\n//      ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION,\n//          Overseer.CREATECOLLECTION, \"name\", message.getStr(\"name\"));\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.currentTimeMillis() + 30000;\n      boolean created = false;\n      while (System.currentTimeMillis() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully createcollection: \" + message.getStr(\"name\"));\n\n\n      String configName = message.getStr(COLL_CONF);\n      log.info(\"going to create cores replicas shardNames {} , repFactor : {}\", shardNames, repFactor);\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String shardName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + shardName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, shardName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          String replica = zkStateReader.getZkClient()\n            .getBaseUrlForNodeName(nodeName);\n          if (replica.startsWith(\"http://\")) replica = replica.substring(7);\n          sreq.shards = new String[] {replica};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          shardHandler.submit(sreq, replica, sreq.params);\n\n        }\n      }\n\n      ShardResponse srsp;\n      do {\n        srsp = shardHandler.takeCompletedOrError();\n        if (srsp != null) {\n          processResponse(results, srsp);\n        }\n      } while (srsp != null);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b711ca2887ae3fda68611cbb78c1b389fa9833be","date":1384985717,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.getCollections().contains(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt( REPLICATION_FACTOR, 1);\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        Overseer.getShardNames(shardNames, message.getStr(\"shards\",null));\n        numSlices = shardNames.size();\n      } else {\n        Overseer.getShardNames(numSlices,shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param\");\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than or equal to 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<String>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.currentTimeMillis() + 30000;\n      boolean created = false;\n      while (System.currentTimeMillis() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully createcollection: \" + message.getStr(\"name\"));\n\n\n      String configName = message.getStr(COLL_CONF);\n      log.info(\"going to create cores replicas shardNames {} , repFactor : {}\", shardNames, repFactor);\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String shardName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + shardName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, shardName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          String replica = zkStateReader.getZkClient()\n            .getBaseUrlForNodeName(nodeName);\n          if (replica.startsWith(\"http://\")) replica = replica.substring(7);\n          sreq.shards = new String[] {replica};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          shardHandler.submit(sreq, replica, sreq.params);\n\n        }\n      }\n\n      ShardResponse srsp;\n      do {\n        srsp = shardHandler.takeCompletedOrError();\n        if (srsp != null) {\n          processResponse(results, srsp);\n        }\n      } while (srsp != null);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.getCollections().contains(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt( REPLICATION_FACTOR, 1);\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        Overseer.getShardNames(shardNames, message.getStr(\"shards\",null));\n        numSlices = shardNames.size();\n      } else {\n        Overseer.getShardNames(numSlices,shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param\");\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than or equal to 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<String>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.currentTimeMillis() + 30000;\n      boolean created = false;\n      while (System.currentTimeMillis() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully createcollection: \" + message.getStr(\"name\"));\n\n\n      String configName = message.getStr(COLL_CONF);\n      log.info(\"going to create cores replicas shardNames {} , repFactor : {}\", shardNames, repFactor);\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String shardName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + shardName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, shardName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          String replica = zkStateReader.getZkClient()\n            .getBaseUrlForNodeName(nodeName);\n          if (replica.startsWith(\"http://\")) replica = replica.substring(7);\n          sreq.shards = new String[] {replica};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          shardHandler.submit(sreq, replica, sreq.params);\n\n        }\n      }\n\n      ShardResponse srsp;\n      do {\n        srsp = shardHandler.takeCompletedOrError();\n        if (srsp != null) {\n          processResponse(results, srsp);\n        }\n      } while (srsp != null);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6421b93f31f88ed3e81722f3bf9fabaff15e03a9","date":1385018723,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.getCollections().contains(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt( REPLICATION_FACTOR, 1);\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        Overseer.getShardNames(shardNames, message.getStr(\"shards\",null));\n        numSlices = shardNames.size();\n      } else {\n        Overseer.getShardNames(numSlices,shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param\");\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<String>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.currentTimeMillis() + 30000;\n      boolean created = false;\n      while (System.currentTimeMillis() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully createcollection: \" + message.getStr(\"name\"));\n\n\n      String configName = message.getStr(COLL_CONF);\n      log.info(\"going to create cores replicas shardNames {} , repFactor : {}\", shardNames, repFactor);\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String shardName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + shardName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, shardName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          String replica = zkStateReader.getZkClient()\n            .getBaseUrlForNodeName(nodeName);\n          if (replica.startsWith(\"http://\")) replica = replica.substring(7);\n          sreq.shards = new String[] {replica};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          shardHandler.submit(sreq, replica, sreq.params);\n\n        }\n      }\n\n      ShardResponse srsp;\n      do {\n        srsp = shardHandler.takeCompletedOrError();\n        if (srsp != null) {\n          processResponse(results, srsp);\n        }\n      } while (srsp != null);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.getCollections().contains(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt( REPLICATION_FACTOR, 1);\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        Overseer.getShardNames(shardNames, message.getStr(\"shards\",null));\n        numSlices = shardNames.size();\n      } else {\n        Overseer.getShardNames(numSlices,shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param\");\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than or equal to 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<String>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.currentTimeMillis() + 30000;\n      boolean created = false;\n      while (System.currentTimeMillis() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully createcollection: \" + message.getStr(\"name\"));\n\n\n      String configName = message.getStr(COLL_CONF);\n      log.info(\"going to create cores replicas shardNames {} , repFactor : {}\", shardNames, repFactor);\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String shardName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + shardName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, shardName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          String replica = zkStateReader.getZkClient()\n            .getBaseUrlForNodeName(nodeName);\n          if (replica.startsWith(\"http://\")) replica = replica.substring(7);\n          sreq.shards = new String[] {replica};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          shardHandler.submit(sreq, replica, sreq.params);\n\n        }\n      }\n\n      ShardResponse srsp;\n      do {\n        srsp = shardHandler.takeCompletedOrError();\n        if (srsp != null) {\n          processResponse(results, srsp);\n        }\n      } while (srsp != null);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":["4f762b78b5a7fc5814208ae853b54d0041b2e2b1"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3f9f2cd4fc995f484da092b8100a389072ed49ff","date":1386062964,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.getCollections().contains(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt( REPLICATION_FACTOR, 1);\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        Overseer.getShardNames(shardNames, message.getStr(\"shards\",null));\n        numSlices = shardNames.size();\n      } else {\n        Overseer.getShardNames(numSlices,shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param\");\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<String>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      String configName = createConfNode(collectionName, message);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.currentTimeMillis() + 30000;\n      boolean created = false;\n      while (System.currentTimeMillis() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully createcollection: \" + message.getStr(\"name\"));\n\n      log.info(\"going to create cores replicas shardNames {} , repFactor : {}\", shardNames, repFactor);\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String shardName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + shardName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, shardName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          String replica = zkStateReader.getZkClient()\n            .getBaseUrlForNodeName(nodeName);\n          if (replica.startsWith(\"http://\")) replica = replica.substring(7);\n          sreq.shards = new String[] {replica};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          shardHandler.submit(sreq, replica, sreq.params);\n\n        }\n      }\n\n      ShardResponse srsp;\n      do {\n        srsp = shardHandler.takeCompletedOrError();\n        if (srsp != null) {\n          processResponse(results, srsp);\n        }\n      } while (srsp != null);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.getCollections().contains(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt( REPLICATION_FACTOR, 1);\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        Overseer.getShardNames(shardNames, message.getStr(\"shards\",null));\n        numSlices = shardNames.size();\n      } else {\n        Overseer.getShardNames(numSlices,shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param\");\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<String>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.currentTimeMillis() + 30000;\n      boolean created = false;\n      while (System.currentTimeMillis() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully createcollection: \" + message.getStr(\"name\"));\n\n\n      String configName = message.getStr(COLL_CONF);\n      log.info(\"going to create cores replicas shardNames {} , repFactor : {}\", shardNames, repFactor);\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String shardName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + shardName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, shardName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          String replica = zkStateReader.getZkClient()\n            .getBaseUrlForNodeName(nodeName);\n          if (replica.startsWith(\"http://\")) replica = replica.substring(7);\n          sreq.shards = new String[] {replica};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          shardHandler.submit(sreq, replica, sreq.params);\n\n        }\n      }\n\n      ShardResponse srsp;\n      do {\n        srsp = shardHandler.takeCompletedOrError();\n        if (srsp != null) {\n          processResponse(results, srsp);\n        }\n      } while (srsp != null);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"74f45af4339b0daf7a95c820ab88c1aea74fbce0","date":1387475327,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.getCollections().contains(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt( REPLICATION_FACTOR, 1);\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        Overseer.getShardNames(shardNames, message.getStr(\"shards\",null));\n        numSlices = shardNames.size();\n      } else {\n        Overseer.getShardNames(numSlices,shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param\");\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<String>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      String configName = createConfNode(collectionName, message);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.currentTimeMillis() + 30000;\n      boolean created = false;\n      while (System.currentTimeMillis() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully createcollection: \" + message.getStr(\"name\"));\n\n      log.info(\"going to create cores replicas shardNames {} , repFactor : {}\", shardNames, repFactor);\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String shardName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + shardName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, shardName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          String replica = zkStateReader.getZkClient()\n            .getBaseUrlForNodeName(nodeName);\n          if (replica.startsWith(\"http://\")) replica = replica.substring(7);\n          sreq.shards = new String[] {replica};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          shardHandler.submit(sreq, replica, sreq.params);\n\n        }\n      }\n\n      ShardResponse srsp;\n      do {\n        srsp = shardHandler.takeCompletedOrError();\n        if (srsp != null) {\n          processResponse(results, srsp);\n        }\n      } while (srsp != null);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.getCollections().contains(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt( REPLICATION_FACTOR, 1);\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        Overseer.getShardNames(shardNames, message.getStr(\"shards\",null));\n        numSlices = shardNames.size();\n      } else {\n        Overseer.getShardNames(numSlices,shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param\");\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than or equal to 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<String>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.currentTimeMillis() + 30000;\n      boolean created = false;\n      while (System.currentTimeMillis() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully createcollection: \" + message.getStr(\"name\"));\n\n\n      String configName = message.getStr(COLL_CONF);\n      log.info(\"going to create cores replicas shardNames {} , repFactor : {}\", shardNames, repFactor);\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String shardName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + shardName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, shardName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          String replica = zkStateReader.getZkClient()\n            .getBaseUrlForNodeName(nodeName);\n          if (replica.startsWith(\"http://\")) replica = replica.substring(7);\n          sreq.shards = new String[] {replica};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          shardHandler.submit(sreq, replica, sreq.params);\n\n        }\n      }\n\n      ShardResponse srsp;\n      do {\n        srsp = shardHandler.takeCompletedOrError();\n        if (srsp != null) {\n          processResponse(results, srsp);\n        }\n      } while (srsp != null);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b753f4bd40fd8ec5276ceae15e867d2dceeb5552","date":1387799061,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt( REPLICATION_FACTOR, 1);\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        Overseer.getShardNames(shardNames, message.getStr(\"shards\",null));\n        numSlices = shardNames.size();\n      } else {\n        Overseer.getShardNames(numSlices,shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param\");\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<String>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      String configName = createConfNode(collectionName, message);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.currentTimeMillis() + 30000;\n      boolean created = false;\n      while (System.currentTimeMillis() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully createcollection: \" + message.getStr(\"name\"));\n\n      log.info(\"going to create cores replicas shardNames {} , repFactor : {}\", shardNames, repFactor);\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String shardName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + shardName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, shardName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          String replica = zkStateReader.getZkClient()\n            .getBaseUrlForNodeName(nodeName);\n          if (replica.startsWith(\"http://\")) replica = replica.substring(7);\n          sreq.shards = new String[] {replica};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          shardHandler.submit(sreq, replica, sreq.params);\n\n        }\n      }\n\n      ShardResponse srsp;\n      do {\n        srsp = shardHandler.takeCompletedOrError();\n        if (srsp != null) {\n          processResponse(results, srsp);\n        }\n      } while (srsp != null);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.getCollections().contains(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt( REPLICATION_FACTOR, 1);\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        Overseer.getShardNames(shardNames, message.getStr(\"shards\",null));\n        numSlices = shardNames.size();\n      } else {\n        Overseer.getShardNames(numSlices,shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param\");\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<String>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      String configName = createConfNode(collectionName, message);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.currentTimeMillis() + 30000;\n      boolean created = false;\n      while (System.currentTimeMillis() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully createcollection: \" + message.getStr(\"name\"));\n\n      log.info(\"going to create cores replicas shardNames {} , repFactor : {}\", shardNames, repFactor);\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String shardName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + shardName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, shardName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          String replica = zkStateReader.getZkClient()\n            .getBaseUrlForNodeName(nodeName);\n          if (replica.startsWith(\"http://\")) replica = replica.substring(7);\n          sreq.shards = new String[] {replica};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          shardHandler.submit(sreq, replica, sreq.params);\n\n        }\n      }\n\n      ShardResponse srsp;\n      do {\n        srsp = shardHandler.takeCompletedOrError();\n        if (srsp != null) {\n          processResponse(results, srsp);\n        }\n      } while (srsp != null);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"57641b2e9dc6155be493cfb6ae9b8a9c8ceffa72","date":1391985588,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt( REPLICATION_FACTOR, 1);\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        Overseer.getShardNames(shardNames, message.getStr(\"shards\",null));\n        numSlices = shardNames.size();\n      } else {\n        Overseer.getShardNames(numSlices,shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param\");\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<String>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      String configName = createConfNode(collectionName, message);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.currentTimeMillis() + 30000;\n      boolean created = false;\n      while (System.currentTimeMillis() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully createcollection: \" + message.getStr(\"name\"));\n\n      log.info(\"going to create cores replicas shardNames {} , repFactor : {}\", shardNames, repFactor);\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String shardName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + shardName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, shardName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          String replica = zkStateReader.getBaseUrlForNodeName(nodeName);\n          sreq.shards = new String[] {replica};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          shardHandler.submit(sreq, replica, sreq.params);\n\n        }\n      }\n\n      ShardResponse srsp;\n      do {\n        srsp = shardHandler.takeCompletedOrError();\n        if (srsp != null) {\n          processResponse(results, srsp);\n        }\n      } while (srsp != null);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt( REPLICATION_FACTOR, 1);\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        Overseer.getShardNames(shardNames, message.getStr(\"shards\",null));\n        numSlices = shardNames.size();\n      } else {\n        Overseer.getShardNames(numSlices,shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param\");\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<String>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      String configName = createConfNode(collectionName, message);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.currentTimeMillis() + 30000;\n      boolean created = false;\n      while (System.currentTimeMillis() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully createcollection: \" + message.getStr(\"name\"));\n\n      log.info(\"going to create cores replicas shardNames {} , repFactor : {}\", shardNames, repFactor);\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String shardName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + shardName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, shardName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          String replica = zkStateReader.getZkClient()\n            .getBaseUrlForNodeName(nodeName);\n          if (replica.startsWith(\"http://\")) replica = replica.substring(7);\n          sreq.shards = new String[] {replica};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          shardHandler.submit(sreq, replica, sreq.params);\n\n        }\n      }\n\n      ShardResponse srsp;\n      do {\n        srsp = shardHandler.takeCompletedOrError();\n        if (srsp != null) {\n          processResponse(results, srsp);\n        }\n      } while (srsp != null);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8497bb4f9de61b5520423bd9af88ea11a6e109e7","date":1393245090,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt( REPLICATION_FACTOR, 1);\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        Overseer.getShardNames(shardNames, message.getStr(\"shards\",null));\n        numSlices = shardNames.size();\n      } else {\n        Overseer.getShardNames(numSlices,shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param\");\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<String>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      String configName = createConfNode(collectionName, message, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.currentTimeMillis() + 30000;\n      boolean created = false;\n      while (System.currentTimeMillis() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully createcollection: \" + message.getStr(\"name\"));\n\n      log.info(\"going to create cores replicas shardNames {} , repFactor : {}\", shardNames, repFactor);\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String coreName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + coreName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n\n          String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n          //in the new mode, create the replica in clusterstate prior to creating the core.\n          // Otherwise the core creation fails\n          if(!isLegacyCloud){\n            ZkNodeProps props = new ZkNodeProps(\n                Overseer.QUEUE_OPERATION, CollectionParams.CollectionAction.ADDREPLICA.toString(),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.SHARD_ID_PROP, sliceName,\n                ZkStateReader.CORE_NAME_PROP, coreName,\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP,baseUrl);\n                Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n          }\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, coreName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          String replica = zkStateReader.getBaseUrlForNodeName(nodeName);\n          sreq.shards = new String[] {replica};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          shardHandler.submit(sreq, replica, sreq.params);\n\n        }\n      }\n\n      ShardResponse srsp;\n      do {\n        srsp = shardHandler.takeCompletedOrError();\n        if (srsp != null) {\n          processResponse(results, srsp);\n        }\n      } while (srsp != null);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt( REPLICATION_FACTOR, 1);\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        Overseer.getShardNames(shardNames, message.getStr(\"shards\",null));\n        numSlices = shardNames.size();\n      } else {\n        Overseer.getShardNames(numSlices,shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param\");\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<String>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      String configName = createConfNode(collectionName, message);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.currentTimeMillis() + 30000;\n      boolean created = false;\n      while (System.currentTimeMillis() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully createcollection: \" + message.getStr(\"name\"));\n\n      log.info(\"going to create cores replicas shardNames {} , repFactor : {}\", shardNames, repFactor);\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String shardName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + shardName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, shardName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          String replica = zkStateReader.getBaseUrlForNodeName(nodeName);\n          sreq.shards = new String[] {replica};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          shardHandler.submit(sreq, replica, sreq.params);\n\n        }\n      }\n\n      ShardResponse srsp;\n      do {\n        srsp = shardHandler.takeCompletedOrError();\n        if (srsp != null) {\n          processResponse(results, srsp);\n        }\n      } while (srsp != null);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":["707fc23d793376ed98be0bd2f100d32dd5a9c0df"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"840fc95f31a25d020cd825e880018bcfa0bacc71","date":1393483822,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt( REPLICATION_FACTOR, 1);\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        Overseer.getShardNames(shardNames, message.getStr(\"shards\",null));\n        numSlices = shardNames.size();\n      } else {\n        Overseer.getShardNames(numSlices,shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param\");\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<String>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      String configName = createConfNode(collectionName, message, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.currentTimeMillis() + 30000;\n      boolean created = false;\n      while (System.currentTimeMillis() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully createcollection: \" + message.getStr(\"name\"));\n\n      log.info(\"going to create cores replicas shardNames {} , repFactor : {}\", shardNames, repFactor);\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<String, ShardRequest>();\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String coreName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + coreName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n\n          String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n          //in the new mode, create the replica in clusterstate prior to creating the core.\n          // Otherwise the core creation fails\n          if(!isLegacyCloud){\n            ZkNodeProps props = new ZkNodeProps(\n                Overseer.QUEUE_OPERATION, CollectionParams.CollectionAction.ADDREPLICA.toString(),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.SHARD_ID_PROP, sliceName,\n                ZkStateReader.CORE_NAME_PROP, coreName,\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP,baseUrl);\n                Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n          }\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, coreName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          sreq.shards = new String[] {baseUrl};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          if(isLegacyCloud) shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n          else coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        //wait for all replica entries to be created\n        Map<String, Replica> replicas = lookupReplicas(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ShardResponse srsp;\n      do {\n        srsp = shardHandler.takeCompletedOrError();\n        if (srsp != null) {\n          processResponse(results, srsp);\n        }\n      } while (srsp != null);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt( REPLICATION_FACTOR, 1);\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        Overseer.getShardNames(shardNames, message.getStr(\"shards\",null));\n        numSlices = shardNames.size();\n      } else {\n        Overseer.getShardNames(numSlices,shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param\");\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<String>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      String configName = createConfNode(collectionName, message, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.currentTimeMillis() + 30000;\n      boolean created = false;\n      while (System.currentTimeMillis() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully createcollection: \" + message.getStr(\"name\"));\n\n      log.info(\"going to create cores replicas shardNames {} , repFactor : {}\", shardNames, repFactor);\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String coreName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + coreName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n\n          String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n          //in the new mode, create the replica in clusterstate prior to creating the core.\n          // Otherwise the core creation fails\n          if(!isLegacyCloud){\n            ZkNodeProps props = new ZkNodeProps(\n                Overseer.QUEUE_OPERATION, CollectionParams.CollectionAction.ADDREPLICA.toString(),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.SHARD_ID_PROP, sliceName,\n                ZkStateReader.CORE_NAME_PROP, coreName,\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP,baseUrl);\n                Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n          }\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, coreName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          String replica = zkStateReader.getBaseUrlForNodeName(nodeName);\n          sreq.shards = new String[] {replica};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          shardHandler.submit(sreq, replica, sreq.params);\n\n        }\n      }\n\n      ShardResponse srsp;\n      do {\n        srsp = shardHandler.takeCompletedOrError();\n        if (srsp != null) {\n          processResponse(results, srsp);\n        }\n      } while (srsp != null);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":["5ad9c35f926b4bf8da0336d1300efc709c8d5a56","5ad9c35f926b4bf8da0336d1300efc709c8d5a56","5ad9c35f926b4bf8da0336d1300efc709c8d5a56","5ad9c35f926b4bf8da0336d1300efc709c8d5a56","5ad9c35f926b4bf8da0336d1300efc709c8d5a56","5ad9c35f926b4bf8da0336d1300efc709c8d5a56","5ad9c35f926b4bf8da0336d1300efc709c8d5a56","5ad9c35f926b4bf8da0336d1300efc709c8d5a56","eb4db141b31e99d2285436da1428411ed5501f56"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"13f445c5bd6f19fd57d5a3ca0a35244c96f45aa8","date":1393532551,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt( REPLICATION_FACTOR, 1);\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        Overseer.getShardNames(shardNames, message.getStr(\"shards\",null));\n        numSlices = shardNames.size();\n      } else {\n        Overseer.getShardNames(numSlices,shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param\");\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<String>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      String configName = createConfNode(collectionName, message, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.currentTimeMillis() + 30000;\n      boolean created = false;\n      while (System.currentTimeMillis() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully createcollection: \" + message.getStr(\"name\"));\n\n      log.info(\"going to create cores replicas shardNames {} , repFactor : {}\", shardNames, repFactor);\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<String, ShardRequest>();\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String coreName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + coreName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n\n          String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n          //in the new mode, create the replica in clusterstate prior to creating the core.\n          // Otherwise the core creation fails\n          if(!isLegacyCloud){\n            ZkNodeProps props = new ZkNodeProps(\n                Overseer.QUEUE_OPERATION, CollectionParams.CollectionAction.ADDREPLICA.toString(),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.SHARD_ID_PROP, sliceName,\n                ZkStateReader.CORE_NAME_PROP, coreName,\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP,baseUrl);\n                Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n          }\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, coreName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          sreq.shards = new String[] {baseUrl};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          if(isLegacyCloud) shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n          else coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        //wait for all replica entries to be created\n        Map<String, Replica> replicas = lookupReplicas(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ShardResponse srsp;\n      do {\n        srsp = shardHandler.takeCompletedOrError();\n        if (srsp != null) {\n          processResponse(results, srsp);\n        }\n      } while (srsp != null);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt( REPLICATION_FACTOR, 1);\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        Overseer.getShardNames(shardNames, message.getStr(\"shards\",null));\n        numSlices = shardNames.size();\n      } else {\n        Overseer.getShardNames(numSlices,shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param\");\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<String>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      String configName = createConfNode(collectionName, message);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.currentTimeMillis() + 30000;\n      boolean created = false;\n      while (System.currentTimeMillis() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully createcollection: \" + message.getStr(\"name\"));\n\n      log.info(\"going to create cores replicas shardNames {} , repFactor : {}\", shardNames, repFactor);\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String shardName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + shardName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, shardName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          String replica = zkStateReader.getBaseUrlForNodeName(nodeName);\n          sreq.shards = new String[] {replica};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          shardHandler.submit(sreq, replica, sreq.params);\n\n        }\n      }\n\n      ShardResponse srsp;\n      do {\n        srsp = shardHandler.takeCompletedOrError();\n        if (srsp != null) {\n          processResponse(results, srsp);\n        }\n      } while (srsp != null);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fd5bc858b8426d40bbe90b94120ead37c77d7954","date":1393812525,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt( REPLICATION_FACTOR, 1);\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        Overseer.getShardNames(shardNames, message.getStr(\"shards\",null));\n        numSlices = shardNames.size();\n      } else {\n        Overseer.getShardNames(numSlices,shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param\");\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<String>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      String configName = createConfNode(collectionName, message, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully createcollection: \" + message.getStr(\"name\"));\n\n      log.info(\"going to create cores replicas shardNames {} , repFactor : {}\", shardNames, repFactor);\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<String, ShardRequest>();\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String coreName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + coreName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n\n          String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n          //in the new mode, create the replica in clusterstate prior to creating the core.\n          // Otherwise the core creation fails\n          if(!isLegacyCloud){\n            ZkNodeProps props = new ZkNodeProps(\n                Overseer.QUEUE_OPERATION, CollectionParams.CollectionAction.ADDREPLICA.toString(),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.SHARD_ID_PROP, sliceName,\n                ZkStateReader.CORE_NAME_PROP, coreName,\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP,baseUrl);\n                Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n          }\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, coreName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          sreq.shards = new String[] {baseUrl};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          if(isLegacyCloud) shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n          else coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        //wait for all replica entries to be created\n        Map<String, Replica> replicas = lookupReplicas(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ShardResponse srsp;\n      do {\n        srsp = shardHandler.takeCompletedOrError();\n        if (srsp != null) {\n          processResponse(results, srsp);\n        }\n      } while (srsp != null);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt( REPLICATION_FACTOR, 1);\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        Overseer.getShardNames(shardNames, message.getStr(\"shards\",null));\n        numSlices = shardNames.size();\n      } else {\n        Overseer.getShardNames(numSlices,shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param\");\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<String>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      String configName = createConfNode(collectionName, message, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.currentTimeMillis() + 30000;\n      boolean created = false;\n      while (System.currentTimeMillis() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully createcollection: \" + message.getStr(\"name\"));\n\n      log.info(\"going to create cores replicas shardNames {} , repFactor : {}\", shardNames, repFactor);\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<String, ShardRequest>();\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String coreName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + coreName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n\n          String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n          //in the new mode, create the replica in clusterstate prior to creating the core.\n          // Otherwise the core creation fails\n          if(!isLegacyCloud){\n            ZkNodeProps props = new ZkNodeProps(\n                Overseer.QUEUE_OPERATION, CollectionParams.CollectionAction.ADDREPLICA.toString(),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.SHARD_ID_PROP, sliceName,\n                ZkStateReader.CORE_NAME_PROP, coreName,\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP,baseUrl);\n                Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n          }\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, coreName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          sreq.shards = new String[] {baseUrl};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          if(isLegacyCloud) shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n          else coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        //wait for all replica entries to be created\n        Map<String, Replica> replicas = lookupReplicas(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ShardResponse srsp;\n      do {\n        srsp = shardHandler.takeCompletedOrError();\n        if (srsp != null) {\n          processResponse(results, srsp);\n        }\n      } while (srsp != null);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"eb4db141b31e99d2285436da1428411ed5501f56","date":1394114795,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt( REPLICATION_FACTOR, 1);\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        Overseer.getShardNames(shardNames, message.getStr(\"shards\",null));\n        numSlices = shardNames.size();\n      } else {\n        Overseer.getShardNames(numSlices,shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param\");\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<String>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      String configName = createConfNode(collectionName, message, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully createcollection: \" + message.getStr(\"name\"));\n\n      log.info(\"Creating SolrCores for new collection, shardNames {} , replicationFactor : {}\", shardNames, repFactor);\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<String, ShardRequest>();\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String coreName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + coreName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n\n          String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n          //in the new mode, create the replica in clusterstate prior to creating the core.\n          // Otherwise the core creation fails\n          if(!isLegacyCloud){\n            ZkNodeProps props = new ZkNodeProps(\n                Overseer.QUEUE_OPERATION, CollectionParams.CollectionAction.ADDREPLICA.toString(),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.SHARD_ID_PROP, sliceName,\n                ZkStateReader.CORE_NAME_PROP, coreName,\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP,baseUrl);\n                Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n          }\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, coreName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          sreq.shards = new String[] {baseUrl};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          if(isLegacyCloud) {\n            shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n          } else {\n            coresToCreate.put(coreName, sreq);\n          }\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ShardResponse srsp;\n      do {\n        srsp = shardHandler.takeCompletedOrError();\n        if (srsp != null) {\n          processResponse(results, srsp);\n        }\n      } while (srsp != null);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt( REPLICATION_FACTOR, 1);\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        Overseer.getShardNames(shardNames, message.getStr(\"shards\",null));\n        numSlices = shardNames.size();\n      } else {\n        Overseer.getShardNames(numSlices,shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param\");\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<String>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      String configName = createConfNode(collectionName, message, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully createcollection: \" + message.getStr(\"name\"));\n\n      log.info(\"going to create cores replicas shardNames {} , repFactor : {}\", shardNames, repFactor);\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<String, ShardRequest>();\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String coreName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + coreName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n\n          String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n          //in the new mode, create the replica in clusterstate prior to creating the core.\n          // Otherwise the core creation fails\n          if(!isLegacyCloud){\n            ZkNodeProps props = new ZkNodeProps(\n                Overseer.QUEUE_OPERATION, CollectionParams.CollectionAction.ADDREPLICA.toString(),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.SHARD_ID_PROP, sliceName,\n                ZkStateReader.CORE_NAME_PROP, coreName,\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP,baseUrl);\n                Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n          }\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, coreName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          sreq.shards = new String[] {baseUrl};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          if(isLegacyCloud) shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n          else coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        //wait for all replica entries to be created\n        Map<String, Replica> replicas = lookupReplicas(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ShardResponse srsp;\n      do {\n        srsp = shardHandler.takeCompletedOrError();\n        if (srsp != null) {\n          processResponse(results, srsp);\n        }\n      } while (srsp != null);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":["840fc95f31a25d020cd825e880018bcfa0bacc71","1eeda7e62e149f90eee8895af874c74efa7d4852"],"bugIntro":["5ad9c35f926b4bf8da0336d1300efc709c8d5a56","5ad9c35f926b4bf8da0336d1300efc709c8d5a56","5ad9c35f926b4bf8da0336d1300efc709c8d5a56","5ad9c35f926b4bf8da0336d1300efc709c8d5a56","5ad9c35f926b4bf8da0336d1300efc709c8d5a56","5ad9c35f926b4bf8da0336d1300efc709c8d5a56","5ad9c35f926b4bf8da0336d1300efc709c8d5a56","5ad9c35f926b4bf8da0336d1300efc709c8d5a56"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6b51e891605604cf911ab579fb28c49b26749f93","date":1394126258,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt( REPLICATION_FACTOR, 1);\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        Overseer.getShardNames(shardNames, message.getStr(\"shards\",null));\n        numSlices = shardNames.size();\n      } else {\n        Overseer.getShardNames(numSlices,shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param\");\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<String>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      String configName = createConfNode(collectionName, message, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully createcollection: \" + message.getStr(\"name\"));\n\n      log.info(\"Creating SolrCores for new collection, shardNames {} , replicationFactor : {}\", shardNames, repFactor);\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<String, ShardRequest>();\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String coreName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + coreName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n\n          String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n          //in the new mode, create the replica in clusterstate prior to creating the core.\n          // Otherwise the core creation fails\n          if(!isLegacyCloud){\n            ZkNodeProps props = new ZkNodeProps(\n                Overseer.QUEUE_OPERATION, CollectionParams.CollectionAction.ADDREPLICA.toString(),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.SHARD_ID_PROP, sliceName,\n                ZkStateReader.CORE_NAME_PROP, coreName,\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP,baseUrl);\n                Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n          }\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, coreName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          sreq.shards = new String[] {baseUrl};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          if(isLegacyCloud) {\n            shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n          } else {\n            coresToCreate.put(coreName, sreq);\n          }\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ShardResponse srsp;\n      do {\n        srsp = shardHandler.takeCompletedOrError();\n        if (srsp != null) {\n          processResponse(results, srsp);\n        }\n      } while (srsp != null);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt( REPLICATION_FACTOR, 1);\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        Overseer.getShardNames(shardNames, message.getStr(\"shards\",null));\n        numSlices = shardNames.size();\n      } else {\n        Overseer.getShardNames(numSlices,shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param\");\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<String>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      String configName = createConfNode(collectionName, message, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully createcollection: \" + message.getStr(\"name\"));\n\n      log.info(\"going to create cores replicas shardNames {} , repFactor : {}\", shardNames, repFactor);\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<String, ShardRequest>();\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String coreName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + coreName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n\n          String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n          //in the new mode, create the replica in clusterstate prior to creating the core.\n          // Otherwise the core creation fails\n          if(!isLegacyCloud){\n            ZkNodeProps props = new ZkNodeProps(\n                Overseer.QUEUE_OPERATION, CollectionParams.CollectionAction.ADDREPLICA.toString(),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.SHARD_ID_PROP, sliceName,\n                ZkStateReader.CORE_NAME_PROP, coreName,\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP,baseUrl);\n                Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n          }\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, coreName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          sreq.shards = new String[] {baseUrl};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          if(isLegacyCloud) shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n          else coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        //wait for all replica entries to be created\n        Map<String, Replica> replicas = lookupReplicas(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ShardResponse srsp;\n      do {\n        srsp = shardHandler.takeCompletedOrError();\n        if (srsp != null) {\n          processResponse(results, srsp);\n        }\n      } while (srsp != null);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"96ea64d994d340044e0d57aeb6a5871539d10ca5","date":1394225445,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt( REPLICATION_FACTOR, 1);\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        Overseer.getShardNames(shardNames, message.getStr(\"shards\",null));\n        numSlices = shardNames.size();\n      } else {\n        Overseer.getShardNames(numSlices,shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param\");\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<String>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      String configName = createConfNode(collectionName, message, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully createcollection: \" + message.getStr(\"name\"));\n\n      log.info(\"Creating SolrCores for new collection, shardNames {} , replicationFactor : {}\", shardNames, repFactor);\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<String, ShardRequest>();\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String coreName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + coreName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n\n          String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n          //in the new mode, create the replica in clusterstate prior to creating the core.\n          // Otherwise the core creation fails\n          if(!isLegacyCloud){\n            ZkNodeProps props = new ZkNodeProps(\n                Overseer.QUEUE_OPERATION, CollectionParams.CollectionAction.ADDREPLICA.toString(),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.SHARD_ID_PROP, sliceName,\n                ZkStateReader.CORE_NAME_PROP, coreName,\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP,baseUrl);\n                Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n          }\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, coreName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          sreq.shards = new String[] {baseUrl};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          if(isLegacyCloud) {\n            shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n          } else {\n            coresToCreate.put(coreName, sreq);\n          }\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ShardResponse srsp;\n      do {\n        srsp = shardHandler.takeCompletedOrError();\n        if (srsp != null) {\n          processResponse(results, srsp);\n        }\n      } while (srsp != null);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt( REPLICATION_FACTOR, 1);\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        Overseer.getShardNames(shardNames, message.getStr(\"shards\",null));\n        numSlices = shardNames.size();\n      } else {\n        Overseer.getShardNames(numSlices,shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param\");\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<String>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      String configName = createConfNode(collectionName, message, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully createcollection: \" + message.getStr(\"name\"));\n\n      log.info(\"going to create cores replicas shardNames {} , repFactor : {}\", shardNames, repFactor);\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<String, ShardRequest>();\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String coreName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + coreName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n\n          String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n          //in the new mode, create the replica in clusterstate prior to creating the core.\n          // Otherwise the core creation fails\n          if(!isLegacyCloud){\n            ZkNodeProps props = new ZkNodeProps(\n                Overseer.QUEUE_OPERATION, CollectionParams.CollectionAction.ADDREPLICA.toString(),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.SHARD_ID_PROP, sliceName,\n                ZkStateReader.CORE_NAME_PROP, coreName,\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP,baseUrl);\n                Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n          }\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, coreName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          sreq.shards = new String[] {baseUrl};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          if(isLegacyCloud) shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n          else coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        //wait for all replica entries to be created\n        Map<String, Replica> replicas = lookupReplicas(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ShardResponse srsp;\n      do {\n        srsp = shardHandler.takeCompletedOrError();\n        if (srsp != null) {\n          processResponse(results, srsp);\n        }\n      } while (srsp != null);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt( REPLICATION_FACTOR, 1);\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        Overseer.getShardNames(shardNames, message.getStr(\"shards\",null));\n        numSlices = shardNames.size();\n      } else {\n        Overseer.getShardNames(numSlices,shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param\");\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      String configName = createConfNode(collectionName, message, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully createcollection: \" + message.getStr(\"name\"));\n\n      log.info(\"Creating SolrCores for new collection, shardNames {} , replicationFactor : {}\", shardNames, repFactor);\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String coreName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + coreName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n\n          String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n          //in the new mode, create the replica in clusterstate prior to creating the core.\n          // Otherwise the core creation fails\n          if(!isLegacyCloud){\n            ZkNodeProps props = new ZkNodeProps(\n                Overseer.QUEUE_OPERATION, CollectionParams.CollectionAction.ADDREPLICA.toString(),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.SHARD_ID_PROP, sliceName,\n                ZkStateReader.CORE_NAME_PROP, coreName,\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP,baseUrl);\n                Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n          }\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, coreName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          sreq.shards = new String[] {baseUrl};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          if(isLegacyCloud) {\n            shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n          } else {\n            coresToCreate.put(coreName, sreq);\n          }\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ShardResponse srsp;\n      do {\n        srsp = shardHandler.takeCompletedOrError();\n        if (srsp != null) {\n          processResponse(results, srsp);\n        }\n      } while (srsp != null);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt( REPLICATION_FACTOR, 1);\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        Overseer.getShardNames(shardNames, message.getStr(\"shards\",null));\n        numSlices = shardNames.size();\n      } else {\n        Overseer.getShardNames(numSlices,shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param\");\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<String>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      String configName = createConfNode(collectionName, message, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully createcollection: \" + message.getStr(\"name\"));\n\n      log.info(\"Creating SolrCores for new collection, shardNames {} , replicationFactor : {}\", shardNames, repFactor);\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<String, ShardRequest>();\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String coreName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + coreName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n\n          String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n          //in the new mode, create the replica in clusterstate prior to creating the core.\n          // Otherwise the core creation fails\n          if(!isLegacyCloud){\n            ZkNodeProps props = new ZkNodeProps(\n                Overseer.QUEUE_OPERATION, CollectionParams.CollectionAction.ADDREPLICA.toString(),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.SHARD_ID_PROP, sliceName,\n                ZkStateReader.CORE_NAME_PROP, coreName,\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP,baseUrl);\n                Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n          }\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, coreName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          sreq.shards = new String[] {baseUrl};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          if(isLegacyCloud) {\n            shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n          } else {\n            coresToCreate.put(coreName, sreq);\n          }\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ShardResponse srsp;\n      do {\n        srsp = shardHandler.takeCompletedOrError();\n        if (srsp != null) {\n          processResponse(results, srsp);\n        }\n      } while (srsp != null);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":["b1197d6f54676973038ad402280d80a139dfd27b"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"058f5a3debcfa0ea477da3eabb4cbe2ec0fac211","date":1394784078,"type":3,"author":"Anshum Gupta","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt( REPLICATION_FACTOR, 1);\n\n      String async = null;\n      if (message.containsKey(\"async\"))\n        async = message.getStr(\"async\");\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        Overseer.getShardNames(shardNames, message.getStr(\"shards\",null));\n        numSlices = shardNames.size();\n      } else {\n        Overseer.getShardNames(numSlices,shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param\");\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      String configName = createConfNode(collectionName, message, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully createcollection: \" + message.getStr(\"name\"));\n\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n      log.info(\"Creating SolrCores for new collection, shardNames {} , replicationFactor : {}\", shardNames, repFactor);\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String coreName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + coreName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n\n          String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n          //in the new mode, create the replica in clusterstate prior to creating the core.\n          // Otherwise the core creation fails\n          if(!isLegacyCloud){\n            ZkNodeProps props = new ZkNodeProps(\n                Overseer.QUEUE_OPERATION, CollectionParams.CollectionAction.ADDREPLICA.toString(),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.SHARD_ID_PROP, sliceName,\n                ZkStateReader.CORE_NAME_PROP, coreName,\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP,baseUrl);\n                Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n          }\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, coreName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n          String replica = zkStateReader.getBaseUrlForNodeName(nodeName);\n          if (replica.startsWith(\"http://\")) replica = replica.substring(7);\n\n          setupAsyncRequest(async, requestMap, params, nodeName);\n\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          sreq.shards = new String[] {baseUrl};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          if(isLegacyCloud) {\n            shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n          } else {\n            coresToCreate.put(coreName, sreq);\n          }\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt( REPLICATION_FACTOR, 1);\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        Overseer.getShardNames(shardNames, message.getStr(\"shards\",null));\n        numSlices = shardNames.size();\n      } else {\n        Overseer.getShardNames(numSlices,shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param\");\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      String configName = createConfNode(collectionName, message, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully createcollection: \" + message.getStr(\"name\"));\n\n      log.info(\"Creating SolrCores for new collection, shardNames {} , replicationFactor : {}\", shardNames, repFactor);\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String coreName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + coreName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n\n          String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n          //in the new mode, create the replica in clusterstate prior to creating the core.\n          // Otherwise the core creation fails\n          if(!isLegacyCloud){\n            ZkNodeProps props = new ZkNodeProps(\n                Overseer.QUEUE_OPERATION, CollectionParams.CollectionAction.ADDREPLICA.toString(),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.SHARD_ID_PROP, sliceName,\n                ZkStateReader.CORE_NAME_PROP, coreName,\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP,baseUrl);\n                Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n          }\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, coreName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          sreq.shards = new String[] {baseUrl};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          if(isLegacyCloud) {\n            shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n          } else {\n            coresToCreate.put(coreName, sreq);\n          }\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      ShardResponse srsp;\n      do {\n        srsp = shardHandler.takeCompletedOrError();\n        if (srsp != null) {\n          processResponse(results, srsp);\n        }\n      } while (srsp != null);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":["69e6520a21709190413a63084ed135271aab1a7c","69e6520a21709190413a63084ed135271aab1a7c","69e6520a21709190413a63084ed135271aab1a7c","69e6520a21709190413a63084ed135271aab1a7c","69e6520a21709190413a63084ed135271aab1a7c","69e6520a21709190413a63084ed135271aab1a7c","69e6520a21709190413a63084ed135271aab1a7c","69e6520a21709190413a63084ed135271aab1a7c","efefd19367eebaa6d911ba8f441a30b7b7564e26","ee31282189f924712ed9ad83e3073e0c207a1a53"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ec81a59b3b8e480b084a4bfab0d55b2519b271ae","date":1394870972,"type":3,"author":"Anshum Gupta","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt( REPLICATION_FACTOR, 1);\n\n      String async = null;\n      if (message.containsKey(\"async\"))\n        async = message.getStr(\"async\");\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        Overseer.getShardNames(shardNames, message.getStr(\"shards\",null));\n        numSlices = shardNames.size();\n      } else {\n        Overseer.getShardNames(numSlices,shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param\");\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      String configName = createConfNode(collectionName, message, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully createcollection: \" + message.getStr(\"name\"));\n\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n      log.info(\"Creating SolrCores for new collection, shardNames {} , replicationFactor : {}\", shardNames, repFactor);\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String coreName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + coreName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n\n          String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n          //in the new mode, create the replica in clusterstate prior to creating the core.\n          // Otherwise the core creation fails\n          if(!isLegacyCloud){\n            ZkNodeProps props = new ZkNodeProps(\n                Overseer.QUEUE_OPERATION, CollectionParams.CollectionAction.ADDREPLICA.toString(),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.SHARD_ID_PROP, sliceName,\n                ZkStateReader.CORE_NAME_PROP, coreName,\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP,baseUrl);\n                Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n          }\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, coreName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n          String replica = zkStateReader.getBaseUrlForNodeName(nodeName);\n\n          setupAsyncRequest(async, requestMap, params, nodeName);\n\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          sreq.shards = new String[] {baseUrl};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          if(isLegacyCloud) {\n            shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n          } else {\n            coresToCreate.put(coreName, sreq);\n          }\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt( REPLICATION_FACTOR, 1);\n\n      String async = null;\n      if (message.containsKey(\"async\"))\n        async = message.getStr(\"async\");\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        Overseer.getShardNames(shardNames, message.getStr(\"shards\",null));\n        numSlices = shardNames.size();\n      } else {\n        Overseer.getShardNames(numSlices,shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param\");\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      String configName = createConfNode(collectionName, message, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully createcollection: \" + message.getStr(\"name\"));\n\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n      log.info(\"Creating SolrCores for new collection, shardNames {} , replicationFactor : {}\", shardNames, repFactor);\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String coreName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + coreName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n\n          String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n          //in the new mode, create the replica in clusterstate prior to creating the core.\n          // Otherwise the core creation fails\n          if(!isLegacyCloud){\n            ZkNodeProps props = new ZkNodeProps(\n                Overseer.QUEUE_OPERATION, CollectionParams.CollectionAction.ADDREPLICA.toString(),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.SHARD_ID_PROP, sliceName,\n                ZkStateReader.CORE_NAME_PROP, coreName,\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP,baseUrl);\n                Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n          }\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, coreName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n          String replica = zkStateReader.getBaseUrlForNodeName(nodeName);\n          if (replica.startsWith(\"http://\")) replica = replica.substring(7);\n\n          setupAsyncRequest(async, requestMap, params, nodeName);\n\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          sreq.shards = new String[] {baseUrl};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          if(isLegacyCloud) {\n            shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n          } else {\n            coresToCreate.put(coreName, sreq);\n          }\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f3695669e45bdf702e0bc9176428b884bd24cdfd","date":1394936868,"type":3,"author":"Anshum Gupta","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt( REPLICATION_FACTOR, 1);\n\n      String async = null;\n      if (message.containsKey(\"async\"))\n        async = message.getStr(\"async\");\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        Overseer.getShardNames(shardNames, message.getStr(\"shards\",null));\n        numSlices = shardNames.size();\n      } else {\n        Overseer.getShardNames(numSlices,shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param\");\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      String configName = createConfNode(collectionName, message, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully createcollection: \" + message.getStr(\"name\"));\n\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n      log.info(\"Creating SolrCores for new collection, shardNames {} , replicationFactor : {}\", shardNames, repFactor);\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String coreName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + coreName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n\n          String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n          //in the new mode, create the replica in clusterstate prior to creating the core.\n          // Otherwise the core creation fails\n          if(!isLegacyCloud){\n            ZkNodeProps props = new ZkNodeProps(\n                Overseer.QUEUE_OPERATION, CollectionParams.CollectionAction.ADDREPLICA.toString(),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.SHARD_ID_PROP, sliceName,\n                ZkStateReader.CORE_NAME_PROP, coreName,\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP,baseUrl);\n                Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n          }\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, coreName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n          setupAsyncRequest(async, requestMap, params, nodeName);\n\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          sreq.shards = new String[] {baseUrl};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          if(isLegacyCloud) {\n            shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n          } else {\n            coresToCreate.put(coreName, sreq);\n          }\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt( REPLICATION_FACTOR, 1);\n\n      String async = null;\n      if (message.containsKey(\"async\"))\n        async = message.getStr(\"async\");\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        Overseer.getShardNames(shardNames, message.getStr(\"shards\",null));\n        numSlices = shardNames.size();\n      } else {\n        Overseer.getShardNames(numSlices,shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param\");\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      String configName = createConfNode(collectionName, message, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully createcollection: \" + message.getStr(\"name\"));\n\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n      log.info(\"Creating SolrCores for new collection, shardNames {} , replicationFactor : {}\", shardNames, repFactor);\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String coreName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + coreName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n\n          String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n          //in the new mode, create the replica in clusterstate prior to creating the core.\n          // Otherwise the core creation fails\n          if(!isLegacyCloud){\n            ZkNodeProps props = new ZkNodeProps(\n                Overseer.QUEUE_OPERATION, CollectionParams.CollectionAction.ADDREPLICA.toString(),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.SHARD_ID_PROP, sliceName,\n                ZkStateReader.CORE_NAME_PROP, coreName,\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP,baseUrl);\n                Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n          }\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, coreName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n          String replica = zkStateReader.getBaseUrlForNodeName(nodeName);\n\n          setupAsyncRequest(async, requestMap, params, nodeName);\n\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          sreq.shards = new String[] {baseUrl};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          if(isLegacyCloud) {\n            shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n          } else {\n            coresToCreate.put(coreName, sreq);\n          }\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6f26f74e4969851a019d28f10315cb1c77786f22","date":1400539241,"type":3,"author":"Anshum Gupta","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt( REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      String async = null;\n      async = message.getStr(\"async\");\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        Overseer.getShardNames(shardNames, message.getStr(\"shards\",null));\n        numSlices = shardNames.size();\n      } else {\n        Overseer.getShardNames(numSlices,shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param\");\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      String configName = createConfNode(collectionName, message, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully createcollection: \" + message.getStr(\"name\"));\n\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n      log.info(\"Creating SolrCores for new collection {}, shardNames {} , replicationFactor : {}\",\n          collectionName, shardNames, repFactor);\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String coreName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + coreName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n\n          String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n          //in the new mode, create the replica in clusterstate prior to creating the core.\n          // Otherwise the core creation fails\n          if(!isLegacyCloud){\n            ZkNodeProps props = new ZkNodeProps(\n                Overseer.QUEUE_OPERATION, CollectionParams.CollectionAction.ADDREPLICA.toString(),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.SHARD_ID_PROP, sliceName,\n                ZkStateReader.CORE_NAME_PROP, coreName,\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP,baseUrl);\n                Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n          }\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, coreName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n          setupAsyncRequest(async, requestMap, params, nodeName);\n\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          sreq.shards = new String[] {baseUrl};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          if(isLegacyCloud) {\n            shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n          } else {\n            coresToCreate.put(coreName, sreq);\n          }\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt( REPLICATION_FACTOR, 1);\n\n      String async = null;\n      if (message.containsKey(\"async\"))\n        async = message.getStr(\"async\");\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        Overseer.getShardNames(shardNames, message.getStr(\"shards\",null));\n        numSlices = shardNames.size();\n      } else {\n        Overseer.getShardNames(numSlices,shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param\");\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      String configName = createConfNode(collectionName, message, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully createcollection: \" + message.getStr(\"name\"));\n\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n      log.info(\"Creating SolrCores for new collection, shardNames {} , replicationFactor : {}\", shardNames, repFactor);\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String coreName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + coreName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n\n          String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n          //in the new mode, create the replica in clusterstate prior to creating the core.\n          // Otherwise the core creation fails\n          if(!isLegacyCloud){\n            ZkNodeProps props = new ZkNodeProps(\n                Overseer.QUEUE_OPERATION, CollectionParams.CollectionAction.ADDREPLICA.toString(),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.SHARD_ID_PROP, sliceName,\n                ZkStateReader.CORE_NAME_PROP, coreName,\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP,baseUrl);\n                Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n          }\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, coreName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n          setupAsyncRequest(async, requestMap, params, nodeName);\n\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          sreq.shards = new String[] {baseUrl};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          if(isLegacyCloud) {\n            shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n          } else {\n            coresToCreate.put(coreName, sreq);\n          }\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b7605579001505896d48b07160075a5c8b8e128e","date":1400758727,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt( REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      String async = null;\n      async = message.getStr(\"async\");\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        Overseer.getShardNames(shardNames, message.getStr(\"shards\",null));\n        numSlices = shardNames.size();\n      } else {\n        Overseer.getShardNames(numSlices,shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param\");\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      String configName = createConfNode(collectionName, message, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully createcollection: \" + message.getStr(\"name\"));\n\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n      log.info(\"Creating SolrCores for new collection {}, shardNames {} , replicationFactor : {}\",\n          collectionName, shardNames, repFactor);\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String coreName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + coreName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n\n          String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n          //in the new mode, create the replica in clusterstate prior to creating the core.\n          // Otherwise the core creation fails\n          if(!isLegacyCloud){\n            ZkNodeProps props = new ZkNodeProps(\n                Overseer.QUEUE_OPERATION, CollectionParams.CollectionAction.ADDREPLICA.toString(),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.SHARD_ID_PROP, sliceName,\n                ZkStateReader.CORE_NAME_PROP, coreName,\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP,baseUrl);\n                Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n          }\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, coreName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n          setupAsyncRequest(async, requestMap, params, nodeName);\n\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          sreq.shards = new String[] {baseUrl};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          if(isLegacyCloud) {\n            shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n          } else {\n            coresToCreate.put(coreName, sreq);\n          }\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt( REPLICATION_FACTOR, 1);\n\n      String async = null;\n      if (message.containsKey(\"async\"))\n        async = message.getStr(\"async\");\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        Overseer.getShardNames(shardNames, message.getStr(\"shards\",null));\n        numSlices = shardNames.size();\n      } else {\n        Overseer.getShardNames(numSlices,shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param\");\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      String configName = createConfNode(collectionName, message, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully createcollection: \" + message.getStr(\"name\"));\n\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n      log.info(\"Creating SolrCores for new collection, shardNames {} , replicationFactor : {}\", shardNames, repFactor);\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String coreName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + coreName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n\n          String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n          //in the new mode, create the replica in clusterstate prior to creating the core.\n          // Otherwise the core creation fails\n          if(!isLegacyCloud){\n            ZkNodeProps props = new ZkNodeProps(\n                Overseer.QUEUE_OPERATION, CollectionParams.CollectionAction.ADDREPLICA.toString(),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.SHARD_ID_PROP, sliceName,\n                ZkStateReader.CORE_NAME_PROP, coreName,\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP,baseUrl);\n                Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n          }\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, coreName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n          setupAsyncRequest(async, requestMap, params, nodeName);\n\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          sreq.shards = new String[] {baseUrl};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          if(isLegacyCloud) {\n            shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n          } else {\n            coresToCreate.put(coreName, sreq);\n          }\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0ad7bdba3e91cf3373cda2e52239cb761fc0b452","date":1408019547,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt(ZkStateReader.REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      String async = null;\n      async = message.getStr(\"async\");\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        Overseer.getShardNames(shardNames, message.getStr(\"shards\",null));\n        numSlices = shardNames.size();\n      } else {\n        Overseer.getShardNames(numSlices,shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param\");\n      }\n\n      int maxShardsPerNode = message.getInt(ZkStateReader.MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, ZkStateReader.REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + ZkStateReader.REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + ZkStateReader.MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + ZkStateReader.REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      String configName = createConfNode(collectionName, message, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully createcollection: \" + message.getStr(\"name\"));\n\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n      log.info(\"Creating SolrCores for new collection {}, shardNames {} , replicationFactor : {}\",\n          collectionName, shardNames, repFactor);\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String coreName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + coreName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n\n          String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n          //in the new mode, create the replica in clusterstate prior to creating the core.\n          // Otherwise the core creation fails\n          if(!isLegacyCloud){\n            ZkNodeProps props = new ZkNodeProps(\n                Overseer.QUEUE_OPERATION, CollectionParams.CollectionAction.ADDREPLICA.toString(),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.SHARD_ID_PROP, sliceName,\n                ZkStateReader.CORE_NAME_PROP, coreName,\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP,baseUrl);\n                Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n          }\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, coreName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n          setupAsyncRequest(async, requestMap, params, nodeName);\n\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          sreq.shards = new String[] {baseUrl};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          if(isLegacyCloud) {\n            shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n          } else {\n            coresToCreate.put(coreName, sreq);\n          }\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt( REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      String async = null;\n      async = message.getStr(\"async\");\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        Overseer.getShardNames(shardNames, message.getStr(\"shards\",null));\n        numSlices = shardNames.size();\n      } else {\n        Overseer.getShardNames(numSlices,shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param\");\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      String configName = createConfNode(collectionName, message, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully createcollection: \" + message.getStr(\"name\"));\n\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n      log.info(\"Creating SolrCores for new collection {}, shardNames {} , replicationFactor : {}\",\n          collectionName, shardNames, repFactor);\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String coreName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + coreName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n\n          String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n          //in the new mode, create the replica in clusterstate prior to creating the core.\n          // Otherwise the core creation fails\n          if(!isLegacyCloud){\n            ZkNodeProps props = new ZkNodeProps(\n                Overseer.QUEUE_OPERATION, CollectionParams.CollectionAction.ADDREPLICA.toString(),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.SHARD_ID_PROP, sliceName,\n                ZkStateReader.CORE_NAME_PROP, coreName,\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP,baseUrl);\n                Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n          }\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, coreName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n          setupAsyncRequest(async, requestMap, params, nodeName);\n\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          sreq.shards = new String[] {baseUrl};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          if(isLegacyCloud) {\n            shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n          } else {\n            coresToCreate.put(coreName, sreq);\n          }\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"989ba56f08f1aa5d58405eed8411bf40e4150deb","date":1408576828,"type":3,"author":"Anshum Gupta","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt(ZkStateReader.REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      String async = null;\n      async = message.getStr(\"async\");\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        Overseer.getShardNames(shardNames, message.getStr(\"shards\",null));\n        numSlices = shardNames.size();\n      } else {\n        Overseer.getShardNames(numSlices,shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n      }\n\n      int maxShardsPerNode = message.getInt(ZkStateReader.MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, ZkStateReader.REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + ZkStateReader.REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + ZkStateReader.MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + ZkStateReader.REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      String configName = createConfNode(collectionName, message, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully createcollection: \" + message.getStr(\"name\"));\n\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n      log.info(\"Creating SolrCores for new collection {}, shardNames {} , replicationFactor : {}\",\n          collectionName, shardNames, repFactor);\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String coreName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + coreName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n\n          String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n          //in the new mode, create the replica in clusterstate prior to creating the core.\n          // Otherwise the core creation fails\n          if(!isLegacyCloud){\n            ZkNodeProps props = new ZkNodeProps(\n                Overseer.QUEUE_OPERATION, CollectionParams.CollectionAction.ADDREPLICA.toString(),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.SHARD_ID_PROP, sliceName,\n                ZkStateReader.CORE_NAME_PROP, coreName,\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP,baseUrl);\n                Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n          }\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, coreName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n          setupAsyncRequest(async, requestMap, params, nodeName);\n\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          sreq.shards = new String[] {baseUrl};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          if(isLegacyCloud) {\n            shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n          } else {\n            coresToCreate.put(coreName, sreq);\n          }\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt(ZkStateReader.REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      String async = null;\n      async = message.getStr(\"async\");\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        Overseer.getShardNames(shardNames, message.getStr(\"shards\",null));\n        numSlices = shardNames.size();\n      } else {\n        Overseer.getShardNames(numSlices,shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param\");\n      }\n\n      int maxShardsPerNode = message.getInt(ZkStateReader.MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, ZkStateReader.REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + ZkStateReader.REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + ZkStateReader.MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + ZkStateReader.REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      String configName = createConfNode(collectionName, message, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully createcollection: \" + message.getStr(\"name\"));\n\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n      log.info(\"Creating SolrCores for new collection {}, shardNames {} , replicationFactor : {}\",\n          collectionName, shardNames, repFactor);\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String coreName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + coreName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n\n          String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n          //in the new mode, create the replica in clusterstate prior to creating the core.\n          // Otherwise the core creation fails\n          if(!isLegacyCloud){\n            ZkNodeProps props = new ZkNodeProps(\n                Overseer.QUEUE_OPERATION, CollectionParams.CollectionAction.ADDREPLICA.toString(),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.SHARD_ID_PROP, sliceName,\n                ZkStateReader.CORE_NAME_PROP, coreName,\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP,baseUrl);\n                Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n          }\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, coreName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n          setupAsyncRequest(async, requestMap, params, nodeName);\n\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          sreq.shards = new String[] {baseUrl};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          if(isLegacyCloud) {\n            shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n          } else {\n            coresToCreate.put(coreName, sreq);\n          }\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"30c688f7052130cef7bd419c85e3c5be214f7b9e","date":1411018984,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt(ZkStateReader.REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      String async = null;\n      async = message.getStr(\"async\");\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        Overseer.getShardNames(shardNames, message.getStr(\"shards\",null));\n        numSlices = shardNames.size();\n      } else {\n        Overseer.getShardNames(numSlices,shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n      }\n\n      int maxShardsPerNode = message.getInt(ZkStateReader.MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, ZkStateReader.REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + ZkStateReader.REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + ZkStateReader.MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + ZkStateReader.REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      String configName = createConfNode(collectionName, message, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + message.getStr(\"name\"));\n\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n      log.info(\"Creating SolrCores for new collection {}, shardNames {} , replicationFactor : {}\",\n          collectionName, shardNames, repFactor);\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String coreName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + coreName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n\n          String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n          //in the new mode, create the replica in clusterstate prior to creating the core.\n          // Otherwise the core creation fails\n          if(!isLegacyCloud){\n            ZkNodeProps props = new ZkNodeProps(\n                Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.SHARD_ID_PROP, sliceName,\n                ZkStateReader.CORE_NAME_PROP, coreName,\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP,baseUrl);\n                Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n          }\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, coreName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n          setupAsyncRequest(async, requestMap, params, nodeName);\n\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          sreq.shards = new String[] {baseUrl};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          if(isLegacyCloud) {\n            shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n          } else {\n            coresToCreate.put(coreName, sreq);\n          }\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt(ZkStateReader.REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      String async = null;\n      async = message.getStr(\"async\");\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        Overseer.getShardNames(shardNames, message.getStr(\"shards\",null));\n        numSlices = shardNames.size();\n      } else {\n        Overseer.getShardNames(numSlices,shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n      }\n\n      int maxShardsPerNode = message.getInt(ZkStateReader.MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, ZkStateReader.REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + ZkStateReader.REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + ZkStateReader.MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + ZkStateReader.REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      String configName = createConfNode(collectionName, message, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully createcollection: \" + message.getStr(\"name\"));\n\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n      log.info(\"Creating SolrCores for new collection {}, shardNames {} , replicationFactor : {}\",\n          collectionName, shardNames, repFactor);\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String coreName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + coreName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n\n          String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n          //in the new mode, create the replica in clusterstate prior to creating the core.\n          // Otherwise the core creation fails\n          if(!isLegacyCloud){\n            ZkNodeProps props = new ZkNodeProps(\n                Overseer.QUEUE_OPERATION, CollectionParams.CollectionAction.ADDREPLICA.toString(),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.SHARD_ID_PROP, sliceName,\n                ZkStateReader.CORE_NAME_PROP, coreName,\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP,baseUrl);\n                Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n          }\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, coreName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n          setupAsyncRequest(async, requestMap, params, nodeName);\n\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          sreq.shards = new String[] {baseUrl};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          if(isLegacyCloud) {\n            shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n          } else {\n            coresToCreate.put(coreName, sreq);\n          }\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"103857ec20f79f31c7a00310a91ed001b9a6ef17","date":1412698959,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt(ZkStateReader.REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      String async = null;\n      async = message.getStr(\"async\");\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        Overseer.getShardNames(shardNames, message.getStr(\"shards\",null));\n        numSlices = shardNames.size();\n      } else {\n        Overseer.getShardNames(numSlices,shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n      }\n\n      int maxShardsPerNode = message.getInt(ZkStateReader.MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, ZkStateReader.REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList, RANDOM);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + ZkStateReader.REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + ZkStateReader.MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + ZkStateReader.REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      String configName = createConfNode(collectionName, message, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + message.getStr(\"name\"));\n\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n      log.info(\"Creating SolrCores for new collection {}, shardNames {} , replicationFactor : {}\",\n          collectionName, shardNames, repFactor);\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String coreName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + coreName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n\n          String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n          //in the new mode, create the replica in clusterstate prior to creating the core.\n          // Otherwise the core creation fails\n          if(!isLegacyCloud){\n            ZkNodeProps props = new ZkNodeProps(\n                Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.SHARD_ID_PROP, sliceName,\n                ZkStateReader.CORE_NAME_PROP, coreName,\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP,baseUrl);\n                Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n          }\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, coreName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n          setupAsyncRequest(async, requestMap, params, nodeName);\n\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          sreq.shards = new String[] {baseUrl};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          if(isLegacyCloud) {\n            shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n          } else {\n            coresToCreate.put(coreName, sreq);\n          }\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt(ZkStateReader.REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      String async = null;\n      async = message.getStr(\"async\");\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        Overseer.getShardNames(shardNames, message.getStr(\"shards\",null));\n        numSlices = shardNames.size();\n      } else {\n        Overseer.getShardNames(numSlices,shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n      }\n\n      int maxShardsPerNode = message.getInt(ZkStateReader.MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, ZkStateReader.REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + ZkStateReader.REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + ZkStateReader.MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + ZkStateReader.REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      String configName = createConfNode(collectionName, message, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + message.getStr(\"name\"));\n\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n      log.info(\"Creating SolrCores for new collection {}, shardNames {} , replicationFactor : {}\",\n          collectionName, shardNames, repFactor);\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String coreName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + coreName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n\n          String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n          //in the new mode, create the replica in clusterstate prior to creating the core.\n          // Otherwise the core creation fails\n          if(!isLegacyCloud){\n            ZkNodeProps props = new ZkNodeProps(\n                Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.SHARD_ID_PROP, sliceName,\n                ZkStateReader.CORE_NAME_PROP, coreName,\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP,baseUrl);\n                Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n          }\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, coreName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n          setupAsyncRequest(async, requestMap, params, nodeName);\n\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          sreq.shards = new String[] {baseUrl};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          if(isLegacyCloud) {\n            shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n          } else {\n            coresToCreate.put(coreName, sreq);\n          }\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":["c215736a9e29403edd2132d9f0829a287b428df4"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"55980207f1977bd1463465de1659b821347e2fa8","date":1413336386,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt(ZkStateReader.REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      String async = null;\n      async = message.getStr(\"async\");\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        Overseer.getShardNames(shardNames, message.getStr(\"shards\",null));\n        numSlices = shardNames.size();\n      } else {\n        Overseer.getShardNames(numSlices,shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n      }\n\n      int maxShardsPerNode = message.getInt(ZkStateReader.MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, ZkStateReader.REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList, RANDOM);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + ZkStateReader.REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + ZkStateReader.MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + ZkStateReader.REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      String configName = createConfNode(collectionName, message, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + message.getStr(\"name\"));\n\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n      log.info(\"Creating SolrCores for new collection {}, shardNames {} , replicationFactor : {}\",\n          collectionName, shardNames, repFactor);\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String coreName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + coreName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n\n          String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n          //in the new mode, create the replica in clusterstate prior to creating the core.\n          // Otherwise the core creation fails\n          if(!isLegacyCloud){\n            ZkNodeProps props = new ZkNodeProps(\n                Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.SHARD_ID_PROP, sliceName,\n                ZkStateReader.CORE_NAME_PROP, coreName,\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP,baseUrl);\n                Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n          }\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, coreName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n          setupAsyncRequest(async, requestMap, params, nodeName);\n\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          sreq.shards = new String[] {baseUrl};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          if(isLegacyCloud) {\n            shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n          } else {\n            coresToCreate.put(coreName, sreq);\n          }\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt(ZkStateReader.REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      String async = null;\n      async = message.getStr(\"async\");\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        Overseer.getShardNames(shardNames, message.getStr(\"shards\",null));\n        numSlices = shardNames.size();\n      } else {\n        Overseer.getShardNames(numSlices,shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n      }\n\n      int maxShardsPerNode = message.getInt(ZkStateReader.MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, ZkStateReader.REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + ZkStateReader.REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + ZkStateReader.MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + ZkStateReader.REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      String configName = createConfNode(collectionName, message, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + message.getStr(\"name\"));\n\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n      log.info(\"Creating SolrCores for new collection {}, shardNames {} , replicationFactor : {}\",\n          collectionName, shardNames, repFactor);\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String coreName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + coreName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n\n          String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n          //in the new mode, create the replica in clusterstate prior to creating the core.\n          // Otherwise the core creation fails\n          if(!isLegacyCloud){\n            ZkNodeProps props = new ZkNodeProps(\n                Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.SHARD_ID_PROP, sliceName,\n                ZkStateReader.CORE_NAME_PROP, coreName,\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP,baseUrl);\n                Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n          }\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, coreName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n          setupAsyncRequest(async, requestMap, params, nodeName);\n\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          sreq.shards = new String[] {baseUrl};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          if(isLegacyCloud) {\n            shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n          } else {\n            coresToCreate.put(coreName, sreq);\n          }\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"24a5da2a0d397ff29f3de8f6cf451d3412c2509a","date":1417276391,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt(ZkStateReader.REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      String async = null;\n      async = message.getStr(\"async\");\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n      }\n\n      int maxShardsPerNode = message.getInt(ZkStateReader.MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, ZkStateReader.REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList, RANDOM);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + ZkStateReader.REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + ZkStateReader.MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + ZkStateReader.REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      String configName = createConfNode(collectionName, message, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + message.getStr(\"name\"));\n\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n      log.info(\"Creating SolrCores for new collection {}, shardNames {} , replicationFactor : {}\",\n          collectionName, shardNames, repFactor);\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String coreName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + coreName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n\n          String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n          //in the new mode, create the replica in clusterstate prior to creating the core.\n          // Otherwise the core creation fails\n          if(!isLegacyCloud){\n            ZkNodeProps props = new ZkNodeProps(\n                Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.SHARD_ID_PROP, sliceName,\n                ZkStateReader.CORE_NAME_PROP, coreName,\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP,baseUrl);\n                Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n          }\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, coreName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n          setupAsyncRequest(async, requestMap, params, nodeName);\n\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          sreq.shards = new String[] {baseUrl};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          if(isLegacyCloud) {\n            shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n          } else {\n            coresToCreate.put(coreName, sreq);\n          }\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt(ZkStateReader.REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      String async = null;\n      async = message.getStr(\"async\");\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        Overseer.getShardNames(shardNames, message.getStr(\"shards\",null));\n        numSlices = shardNames.size();\n      } else {\n        Overseer.getShardNames(numSlices,shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n      }\n\n      int maxShardsPerNode = message.getInt(ZkStateReader.MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, ZkStateReader.REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList, RANDOM);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + ZkStateReader.REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + ZkStateReader.MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + ZkStateReader.REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      String configName = createConfNode(collectionName, message, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + message.getStr(\"name\"));\n\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n      log.info(\"Creating SolrCores for new collection {}, shardNames {} , replicationFactor : {}\",\n          collectionName, shardNames, repFactor);\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String coreName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + coreName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n\n          String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n          //in the new mode, create the replica in clusterstate prior to creating the core.\n          // Otherwise the core creation fails\n          if(!isLegacyCloud){\n            ZkNodeProps props = new ZkNodeProps(\n                Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.SHARD_ID_PROP, sliceName,\n                ZkStateReader.CORE_NAME_PROP, coreName,\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP,baseUrl);\n                Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n          }\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, coreName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n          setupAsyncRequest(async, requestMap, params, nodeName);\n\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          sreq.shards = new String[] {baseUrl};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          if(isLegacyCloud) {\n            shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n          } else {\n            coresToCreate.put(coreName, sreq);\n          }\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"08b22329006608bd6b95aeba7a59f28092cd7a5e","date":1419362789,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt(ZkStateReader.REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      String async = null;\n      async = message.getStr(\"async\");\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n      }\n\n      int maxShardsPerNode = message.getInt(ZkStateReader.MAX_SHARDS_PER_NODE, 1);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, ZkStateReader.REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + ZkStateReader.REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + ZkStateReader.MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + ZkStateReader.REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      String configName = createConfNode(collectionName, message, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + message.getStr(\"name\"));\n\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n      log.info(\"Creating SolrCores for new collection {}, shardNames {} , replicationFactor : {}\",\n          collectionName, shardNames, repFactor);\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String coreName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + coreName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n\n          String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n          //in the new mode, create the replica in clusterstate prior to creating the core.\n          // Otherwise the core creation fails\n          if(!isLegacyCloud){\n            ZkNodeProps props = new ZkNodeProps(\n                Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.SHARD_ID_PROP, sliceName,\n                ZkStateReader.CORE_NAME_PROP, coreName,\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP,baseUrl);\n                Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n          }\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, coreName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n          setupAsyncRequest(async, requestMap, params, nodeName);\n\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          sreq.shards = new String[] {baseUrl};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          if(isLegacyCloud) {\n            shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n          } else {\n            coresToCreate.put(coreName, sreq);\n          }\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt(ZkStateReader.REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      String async = null;\n      async = message.getStr(\"async\");\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n      }\n\n      int maxShardsPerNode = message.getInt(ZkStateReader.MAX_SHARDS_PER_NODE, 1);\n      String createNodeSetStr; \n      List<String> createNodeList = ((createNodeSetStr = message.getStr(CREATE_NODE_SET)) == null)?null:StrUtils.splitSmart(createNodeSetStr, \",\", true);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, ZkStateReader.REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      // TODO: add smarter options that look at the current number of cores per\n      // node?\n      // for now we just go random\n      Set<String> nodes = clusterState.getLiveNodes();\n      List<String> nodeList = new ArrayList<>(nodes.size());\n      nodeList.addAll(nodes);\n      if (createNodeList != null) nodeList.retainAll(createNodeList);\n      Collections.shuffle(nodeList, RANDOM);\n      \n      if (nodeList.size() <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n            + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n      }\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + ZkStateReader.REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + ZkStateReader.MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of live nodes is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + ZkStateReader.REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      String configName = createConfNode(collectionName, message, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + message.getStr(\"name\"));\n\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n      log.info(\"Creating SolrCores for new collection {}, shardNames {} , replicationFactor : {}\",\n          collectionName, shardNames, repFactor);\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String coreName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + coreName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n\n          String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n          //in the new mode, create the replica in clusterstate prior to creating the core.\n          // Otherwise the core creation fails\n          if(!isLegacyCloud){\n            ZkNodeProps props = new ZkNodeProps(\n                Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.SHARD_ID_PROP, sliceName,\n                ZkStateReader.CORE_NAME_PROP, coreName,\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP,baseUrl);\n                Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n          }\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, coreName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n          setupAsyncRequest(async, requestMap, params, nodeName);\n\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          sreq.shards = new String[] {baseUrl};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          if(isLegacyCloud) {\n            shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n          } else {\n            coresToCreate.put(coreName, sreq);\n          }\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8aa2bb13f56a3ad540fd2dc5e882e1ed4bf799d1","date":1419400138,"type":3,"author":"Steven Rowe","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt(ZkStateReader.REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      String async = null;\n      async = message.getStr(\"async\");\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n      }\n\n      int maxShardsPerNode = message.getInt(ZkStateReader.MAX_SHARDS_PER_NODE, 1);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, ZkStateReader.REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + ZkStateReader.REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + ZkStateReader.MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + ZkStateReader.REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      String configName = createConfNode(collectionName, message, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + message.getStr(\"name\"));\n\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n      log.info(\"Creating SolrCores for new collection {}, shardNames {} , replicationFactor : {}\",\n          collectionName, shardNames, repFactor);\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String coreName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + coreName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n\n          String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n          //in the new mode, create the replica in clusterstate prior to creating the core.\n          // Otherwise the core creation fails\n          if(!isLegacyCloud){\n            ZkNodeProps props = new ZkNodeProps(\n                Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.SHARD_ID_PROP, sliceName,\n                ZkStateReader.CORE_NAME_PROP, coreName,\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP,baseUrl);\n                Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n          }\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, coreName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n          setupAsyncRequest(async, requestMap, params, nodeName);\n\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          sreq.shards = new String[] {baseUrl};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          if(isLegacyCloud) {\n            shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n          } else {\n            coresToCreate.put(coreName, sreq);\n          }\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt(ZkStateReader.REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      String async = null;\n      async = message.getStr(\"async\");\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n      }\n\n      int maxShardsPerNode = message.getInt(ZkStateReader.MAX_SHARDS_PER_NODE, 1);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, ZkStateReader.REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + ZkStateReader.REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). Its unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + ZkStateReader.MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + ZkStateReader.REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      String configName = createConfNode(collectionName, message, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + message.getStr(\"name\"));\n\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n      log.info(\"Creating SolrCores for new collection {}, shardNames {} , replicationFactor : {}\",\n          collectionName, shardNames, repFactor);\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String coreName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + coreName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n\n          String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n          //in the new mode, create the replica in clusterstate prior to creating the core.\n          // Otherwise the core creation fails\n          if(!isLegacyCloud){\n            ZkNodeProps props = new ZkNodeProps(\n                Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.SHARD_ID_PROP, sliceName,\n                ZkStateReader.CORE_NAME_PROP, coreName,\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP,baseUrl);\n                Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n          }\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, coreName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n          setupAsyncRequest(async, requestMap, params, nodeName);\n\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          sreq.shards = new String[] {baseUrl};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          if(isLegacyCloud) {\n            shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n          } else {\n            coresToCreate.put(coreName, sreq);\n          }\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"707fc23d793376ed98be0bd2f100d32dd5a9c0df","date":1422324604,"type":3,"author":"Anshum Gupta","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    } else if (!validateConfig(configName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Can not find the specified config set: \" + configName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt(ZkStateReader.REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      String async = null;\n      async = message.getStr(\"async\");\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n      }\n\n      int maxShardsPerNode = message.getInt(ZkStateReader.MAX_SHARDS_PER_NODE, 1);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, ZkStateReader.REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + ZkStateReader.REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + ZkStateReader.MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + ZkStateReader.REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + message.getStr(\"name\"));\n\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n      log.info(\"Creating SolrCores for new collection {}, shardNames {} , replicationFactor : {}\",\n          collectionName, shardNames, repFactor);\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String coreName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + coreName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n\n          String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n          //in the new mode, create the replica in clusterstate prior to creating the core.\n          // Otherwise the core creation fails\n          if(!isLegacyCloud){\n            ZkNodeProps props = new ZkNodeProps(\n                Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.SHARD_ID_PROP, sliceName,\n                ZkStateReader.CORE_NAME_PROP, coreName,\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP,baseUrl);\n                Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n          }\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, coreName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n          setupAsyncRequest(async, requestMap, params, nodeName);\n\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          sreq.shards = new String[] {baseUrl};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          if(isLegacyCloud) {\n            shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n          } else {\n            coresToCreate.put(coreName, sreq);\n          }\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt(ZkStateReader.REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      String async = null;\n      async = message.getStr(\"async\");\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n      }\n\n      int maxShardsPerNode = message.getInt(ZkStateReader.MAX_SHARDS_PER_NODE, 1);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, ZkStateReader.REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + ZkStateReader.REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + ZkStateReader.MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + ZkStateReader.REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      String configName = createConfNode(collectionName, message, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + message.getStr(\"name\"));\n\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n      log.info(\"Creating SolrCores for new collection {}, shardNames {} , replicationFactor : {}\",\n          collectionName, shardNames, repFactor);\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String coreName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + coreName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n\n          String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n          //in the new mode, create the replica in clusterstate prior to creating the core.\n          // Otherwise the core creation fails\n          if(!isLegacyCloud){\n            ZkNodeProps props = new ZkNodeProps(\n                Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.SHARD_ID_PROP, sliceName,\n                ZkStateReader.CORE_NAME_PROP, coreName,\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP,baseUrl);\n                Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n          }\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, coreName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n          setupAsyncRequest(async, requestMap, params, nodeName);\n\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          sreq.shards = new String[] {baseUrl};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          if(isLegacyCloud) {\n            shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n          } else {\n            coresToCreate.put(coreName, sreq);\n          }\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":["8497bb4f9de61b5520423bd9af88ea11a6e109e7"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3b90bc78bc6662319cd8bad5213f992fd4807bb2","date":1425997311,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    } else if (!validateConfig(configName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Can not find the specified config set: \" + configName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt(ZkStateReader.REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      String async = null;\n      async = message.getStr(\"async\");\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(ZkStateReader.MAX_SHARDS_PER_NODE, 1);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, ZkStateReader.REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + ZkStateReader.REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + ZkStateReader.MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + ZkStateReader.REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + message.getStr(\"name\"));\n\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n      log.info(\"Creating SolrCores for new collection {}, shardNames {} , replicationFactor : {}\",\n          collectionName, shardNames, repFactor);\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String coreName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + coreName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n\n          String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n          //in the new mode, create the replica in clusterstate prior to creating the core.\n          // Otherwise the core creation fails\n          if(!isLegacyCloud){\n            ZkNodeProps props = new ZkNodeProps(\n                Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.SHARD_ID_PROP, sliceName,\n                ZkStateReader.CORE_NAME_PROP, coreName,\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP,baseUrl);\n                Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n          }\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, coreName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n          setupAsyncRequest(async, requestMap, params, nodeName);\n\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          sreq.shards = new String[] {baseUrl};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          if(isLegacyCloud) {\n            shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n          } else {\n            coresToCreate.put(coreName, sreq);\n          }\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    } else if (!validateConfig(configName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Can not find the specified config set: \" + configName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt(ZkStateReader.REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      String async = null;\n      async = message.getStr(\"async\");\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n      }\n\n      int maxShardsPerNode = message.getInt(ZkStateReader.MAX_SHARDS_PER_NODE, 1);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, ZkStateReader.REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + ZkStateReader.REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + ZkStateReader.MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + ZkStateReader.REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + message.getStr(\"name\"));\n\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n      log.info(\"Creating SolrCores for new collection {}, shardNames {} , replicationFactor : {}\",\n          collectionName, shardNames, repFactor);\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String coreName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + coreName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n\n          String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n          //in the new mode, create the replica in clusterstate prior to creating the core.\n          // Otherwise the core creation fails\n          if(!isLegacyCloud){\n            ZkNodeProps props = new ZkNodeProps(\n                Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.SHARD_ID_PROP, sliceName,\n                ZkStateReader.CORE_NAME_PROP, coreName,\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP,baseUrl);\n                Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n          }\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, coreName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n          setupAsyncRequest(async, requestMap, params, nodeName);\n\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          sreq.shards = new String[] {baseUrl};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          if(isLegacyCloud) {\n            shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n          } else {\n            coresToCreate.put(coreName, sreq);\n          }\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ee31282189f924712ed9ad83e3073e0c207a1a53","date":1427223880,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    } else if (!validateConfig(configName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Can not find the specified config set: \" + configName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt(ZkStateReader.REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      String async = null;\n      async = message.getStr(\"async\");\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(ZkStateReader.MAX_SHARDS_PER_NODE, 1);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, ZkStateReader.REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + ZkStateReader.REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + ZkStateReader.MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + ZkStateReader.REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + message.getStr(\"name\"));\n\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n      log.info(\"Creating SolrCores for new collection {}, shardNames {} , replicationFactor : {}\",\n          collectionName, shardNames, repFactor);\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String coreName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + coreName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n\n          String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n          //in the new mode, create the replica in clusterstate prior to creating the core.\n          // Otherwise the core creation fails\n          if(!isLegacyCloud){\n            ZkNodeProps props = new ZkNodeProps(\n                Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.SHARD_ID_PROP, sliceName,\n                ZkStateReader.CORE_NAME_PROP, coreName,\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP,baseUrl);\n                Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n          }\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, coreName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n          if (async != null)  {\n            String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n            params.add(ASYNC, coreAdminAsyncId);\n            requestMap.put(nodeName, coreAdminAsyncId);\n          }\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          sreq.shards = new String[] {baseUrl};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          if(isLegacyCloud) {\n            shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n          } else {\n            coresToCreate.put(coreName, sreq);\n          }\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    } else if (!validateConfig(configName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Can not find the specified config set: \" + configName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt(ZkStateReader.REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      String async = null;\n      async = message.getStr(\"async\");\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(ZkStateReader.MAX_SHARDS_PER_NODE, 1);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, ZkStateReader.REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + ZkStateReader.REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + ZkStateReader.MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + ZkStateReader.REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + message.getStr(\"name\"));\n\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n      log.info(\"Creating SolrCores for new collection {}, shardNames {} , replicationFactor : {}\",\n          collectionName, shardNames, repFactor);\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String coreName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + coreName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n\n          String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n          //in the new mode, create the replica in clusterstate prior to creating the core.\n          // Otherwise the core creation fails\n          if(!isLegacyCloud){\n            ZkNodeProps props = new ZkNodeProps(\n                Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.SHARD_ID_PROP, sliceName,\n                ZkStateReader.CORE_NAME_PROP, coreName,\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP,baseUrl);\n                Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n          }\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, coreName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n          setupAsyncRequest(async, requestMap, params, nodeName);\n\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          sreq.shards = new String[] {baseUrl};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          if(isLegacyCloud) {\n            shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n          } else {\n            coresToCreate.put(coreName, sreq);\n          }\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":["058f5a3debcfa0ea477da3eabb4cbe2ec0fac211"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":3,"author":"Ryan Ernst","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    } else if (!validateConfig(configName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Can not find the specified config set: \" + configName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt(ZkStateReader.REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      String async = null;\n      async = message.getStr(\"async\");\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(ZkStateReader.MAX_SHARDS_PER_NODE, 1);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, ZkStateReader.REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + ZkStateReader.REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + ZkStateReader.MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + ZkStateReader.REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + message.getStr(\"name\"));\n\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n      log.info(\"Creating SolrCores for new collection {}, shardNames {} , replicationFactor : {}\",\n          collectionName, shardNames, repFactor);\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String coreName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + coreName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n\n          String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n          //in the new mode, create the replica in clusterstate prior to creating the core.\n          // Otherwise the core creation fails\n          if(!isLegacyCloud){\n            ZkNodeProps props = new ZkNodeProps(\n                Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.SHARD_ID_PROP, sliceName,\n                ZkStateReader.CORE_NAME_PROP, coreName,\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP,baseUrl);\n                Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n          }\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, coreName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n          if (async != null)  {\n            String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n            params.add(ASYNC, coreAdminAsyncId);\n            requestMap.put(nodeName, coreAdminAsyncId);\n          }\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          sreq.shards = new String[] {baseUrl};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          if(isLegacyCloud) {\n            shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n          } else {\n            coresToCreate.put(coreName, sreq);\n          }\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    } else if (!validateConfig(configName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Can not find the specified config set: \" + configName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt(ZkStateReader.REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      String async = null;\n      async = message.getStr(\"async\");\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      if (numSlices == null ) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n      }\n\n      int maxShardsPerNode = message.getInt(ZkStateReader.MAX_SHARDS_PER_NODE, 1);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, ZkStateReader.REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + ZkStateReader.REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + ZkStateReader.MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + ZkStateReader.REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + message.getStr(\"name\"));\n\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n      log.info(\"Creating SolrCores for new collection {}, shardNames {} , replicationFactor : {}\",\n          collectionName, shardNames, repFactor);\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String coreName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + coreName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n\n          String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n          //in the new mode, create the replica in clusterstate prior to creating the core.\n          // Otherwise the core creation fails\n          if(!isLegacyCloud){\n            ZkNodeProps props = new ZkNodeProps(\n                Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.SHARD_ID_PROP, sliceName,\n                ZkStateReader.CORE_NAME_PROP, coreName,\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP,baseUrl);\n                Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n          }\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, coreName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n          setupAsyncRequest(async, requestMap, params, nodeName);\n\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          sreq.shards = new String[] {baseUrl};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          if(isLegacyCloud) {\n            shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n          } else {\n            coresToCreate.put(coreName, sreq);\n          }\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1390137e395d2f07f9ba5b8c43d293befe84d563","date":1427947685,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(NAME);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    } else if (!validateConfig(configName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Can not find the specified config set: \" + configName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt(ZkStateReader.REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      String async = null;\n      async = message.getStr(\"async\");\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(ZkStateReader.MAX_SHARDS_PER_NODE, 1);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, ZkStateReader.REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + ZkStateReader.REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + ZkStateReader.MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + ZkStateReader.REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(NAME));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + message.getStr(NAME));\n\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n      log.info(\"Creating SolrCores for new collection {}, shardNames {} , replicationFactor : {}\",\n          collectionName, shardNames, repFactor);\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String coreName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + coreName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n\n          String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n          //in the new mode, create the replica in clusterstate prior to creating the core.\n          // Otherwise the core creation fails\n          if(!isLegacyCloud){\n            ZkNodeProps props = new ZkNodeProps(\n                Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.SHARD_ID_PROP, sliceName,\n                ZkStateReader.CORE_NAME_PROP, coreName,\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP,baseUrl);\n                Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n          }\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, coreName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n          if (async != null)  {\n            String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n            params.add(ASYNC, coreAdminAsyncId);\n            requestMap.put(nodeName, coreAdminAsyncId);\n          }\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          sreq.shards = new String[] {baseUrl};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          if(isLegacyCloud) {\n            shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n          } else {\n            coresToCreate.put(coreName, sreq);\n          }\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    } else if (!validateConfig(configName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Can not find the specified config set: \" + configName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt(ZkStateReader.REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      String async = null;\n      async = message.getStr(\"async\");\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(ZkStateReader.MAX_SHARDS_PER_NODE, 1);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, ZkStateReader.REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + ZkStateReader.REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + ZkStateReader.MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + ZkStateReader.REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + message.getStr(\"name\"));\n\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n      log.info(\"Creating SolrCores for new collection {}, shardNames {} , replicationFactor : {}\",\n          collectionName, shardNames, repFactor);\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String coreName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + coreName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n\n          String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n          //in the new mode, create the replica in clusterstate prior to creating the core.\n          // Otherwise the core creation fails\n          if(!isLegacyCloud){\n            ZkNodeProps props = new ZkNodeProps(\n                Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.SHARD_ID_PROP, sliceName,\n                ZkStateReader.CORE_NAME_PROP, coreName,\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP,baseUrl);\n                Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n          }\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, coreName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n          if (async != null)  {\n            String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n            params.add(ASYNC, coreAdminAsyncId);\n            requestMap.put(nodeName, coreAdminAsyncId);\n          }\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          sreq.shards = new String[] {baseUrl};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          if(isLegacyCloud) {\n            shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n          } else {\n            coresToCreate.put(coreName, sreq);\n          }\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d2638f781be724518ff6c2263d14a48cf6e68017","date":1427989059,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(NAME);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    } else if (!validateConfig(configName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Can not find the specified config set: \" + configName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt(ZkStateReader.REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      String async = null;\n      async = message.getStr(\"async\");\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(ZkStateReader.MAX_SHARDS_PER_NODE, 1);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, ZkStateReader.REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + ZkStateReader.REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + ZkStateReader.MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + ZkStateReader.REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(NAME));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + message.getStr(NAME));\n\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n      log.info(\"Creating SolrCores for new collection {}, shardNames {} , replicationFactor : {}\",\n          collectionName, shardNames, repFactor);\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String coreName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + coreName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n\n          String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n          //in the new mode, create the replica in clusterstate prior to creating the core.\n          // Otherwise the core creation fails\n          if(!isLegacyCloud){\n            ZkNodeProps props = new ZkNodeProps(\n                Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.SHARD_ID_PROP, sliceName,\n                ZkStateReader.CORE_NAME_PROP, coreName,\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP,baseUrl);\n                Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n          }\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, coreName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n          if (async != null)  {\n            String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n            params.add(ASYNC, coreAdminAsyncId);\n            requestMap.put(nodeName, coreAdminAsyncId);\n          }\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          sreq.shards = new String[] {baseUrl};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          if(isLegacyCloud) {\n            shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n          } else {\n            coresToCreate.put(coreName, sreq);\n          }\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(\"name\");\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    } else if (!validateConfig(configName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Can not find the specified config set: \" + configName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt(ZkStateReader.REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      String async = null;\n      async = message.getStr(\"async\");\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(ZkStateReader.MAX_SHARDS_PER_NODE, 1);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, ZkStateReader.REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + ZkStateReader.REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + ZkStateReader.MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + ZkStateReader.REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(\"name\"));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + message.getStr(\"name\"));\n\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n      log.info(\"Creating SolrCores for new collection {}, shardNames {} , replicationFactor : {}\",\n          collectionName, shardNames, repFactor);\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String coreName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + coreName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n\n          String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n          //in the new mode, create the replica in clusterstate prior to creating the core.\n          // Otherwise the core creation fails\n          if(!isLegacyCloud){\n            ZkNodeProps props = new ZkNodeProps(\n                Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.SHARD_ID_PROP, sliceName,\n                ZkStateReader.CORE_NAME_PROP, coreName,\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP,baseUrl);\n                Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n          }\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, coreName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n          if (async != null)  {\n            String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n            params.add(ASYNC, coreAdminAsyncId);\n            requestMap.put(nodeName, coreAdminAsyncId);\n          }\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          sreq.shards = new String[] {baseUrl};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          if(isLegacyCloud) {\n            shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n          } else {\n            coresToCreate.put(coreName, sreq);\n          }\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a219f1dcad1700e84807666bdbd2b573e8de7021","date":1428130940,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(NAME);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    } else if (!validateConfig(configName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Can not find the specified config set: \" + configName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt(ZkStateReader.REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      String async = null;\n      async = message.getStr(\"async\");\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(ZkStateReader.MAX_SHARDS_PER_NODE, 1);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, ZkStateReader.REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + ZkStateReader.REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + ZkStateReader.MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + ZkStateReader.REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(NAME));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + message.getStr(NAME));\n\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n      log.info(\"Creating SolrCores for new collection {}, shardNames {} , replicationFactor : {}\",\n          collectionName, shardNames, repFactor);\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String coreName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + coreName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n\n          String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n          //in the new mode, create the replica in clusterstate prior to creating the core.\n          // Otherwise the core creation fails\n          if(!isLegacyCloud){\n            ZkNodeProps props = new ZkNodeProps(\n                Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.SHARD_ID_PROP, sliceName,\n                ZkStateReader.CORE_NAME_PROP, coreName,\n                ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n                ZkStateReader.BASE_URL_PROP,baseUrl);\n                Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n          }\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, coreName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n          if (async != null)  {\n            String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n            params.add(ASYNC, coreAdminAsyncId);\n            requestMap.put(nodeName, coreAdminAsyncId);\n          }\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          sreq.shards = new String[] {baseUrl};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          if(isLegacyCloud) {\n            shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n          } else {\n            coresToCreate.put(coreName, sreq);\n          }\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(NAME);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    } else if (!validateConfig(configName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Can not find the specified config set: \" + configName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt(ZkStateReader.REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      String async = null;\n      async = message.getStr(\"async\");\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(ZkStateReader.MAX_SHARDS_PER_NODE, 1);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, ZkStateReader.REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + ZkStateReader.REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + ZkStateReader.MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + ZkStateReader.REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(NAME));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + message.getStr(NAME));\n\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n      log.info(\"Creating SolrCores for new collection {}, shardNames {} , replicationFactor : {}\",\n          collectionName, shardNames, repFactor);\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String coreName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + coreName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n\n          String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n          //in the new mode, create the replica in clusterstate prior to creating the core.\n          // Otherwise the core creation fails\n          if(!isLegacyCloud){\n            ZkNodeProps props = new ZkNodeProps(\n                Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.SHARD_ID_PROP, sliceName,\n                ZkStateReader.CORE_NAME_PROP, coreName,\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP,baseUrl);\n                Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n          }\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, coreName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n          if (async != null)  {\n            String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n            params.add(ASYNC, coreAdminAsyncId);\n            requestMap.put(nodeName, coreAdminAsyncId);\n          }\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          sreq.shards = new String[] {baseUrl};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          if(isLegacyCloud) {\n            shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n          } else {\n            coresToCreate.put(coreName, sreq);\n          }\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8c7a6584aa35e033d783e02c6f4eefa6ad21c7fe","date":1430750405,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(NAME);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    } else if (!validateConfig(configName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Can not find the specified config set: \" + configName);\n    }\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(ZkStateReader.REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      String async = null;\n      async = message.getStr(\"async\");\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(ZkStateReader.MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, ZkStateReader.REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n\n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + ZkStateReader.REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n\n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + ZkStateReader.MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + ZkStateReader.REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n\n      Map<Position, String> positionVsNodes = identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(NAME));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + message.getStr(NAME));\n\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n\n      log.info(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<Position, String> e : positionVsNodes.entrySet()) {\n        Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.info(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        params.set(\"qt\", adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(NAME);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    } else if (!validateConfig(configName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Can not find the specified config set: \" + configName);\n    }\n    \n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n      \n      int repFactor = message.getInt(ZkStateReader.REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      String async = null;\n      async = message.getStr(\"async\");\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(ZkStateReader.MAX_SHARDS_PER_NODE, 1);\n      \n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, ZkStateReader.REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n      \n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n      \n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n      \n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      \n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + ZkStateReader.REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n      \n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + ZkStateReader.MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + ZkStateReader.REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(NAME));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + message.getStr(NAME));\n\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n      log.info(\"Creating SolrCores for new collection {}, shardNames {} , replicationFactor : {}\",\n          collectionName, shardNames, repFactor);\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (int i = 1; i <= shardNames.size(); i++) {\n        String sliceName = shardNames.get(i-1);\n        for (int j = 1; j <= repFactor; j++) {\n          String nodeName = nodeList.get((repFactor * (i - 1) + (j - 1)) % nodeList.size());\n          String coreName = collectionName + \"_\" + sliceName + \"_replica\" + j;\n          log.info(\"Creating shard \" + coreName + \" as part of slice \"\n              + sliceName + \" of collection \" + collectionName + \" on \"\n              + nodeName);\n\n\n          String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n          //in the new mode, create the replica in clusterstate prior to creating the core.\n          // Otherwise the core creation fails\n          if(!isLegacyCloud){\n            ZkNodeProps props = new ZkNodeProps(\n                Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.SHARD_ID_PROP, sliceName,\n                ZkStateReader.CORE_NAME_PROP, coreName,\n                ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n                ZkStateReader.BASE_URL_PROP,baseUrl);\n                Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n          }\n\n          // Need to create new params for each request\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n          params.set(CoreAdminParams.NAME, coreName);\n          params.set(COLL_CONF, configName);\n          params.set(CoreAdminParams.COLLECTION, collectionName);\n          params.set(CoreAdminParams.SHARD, sliceName);\n          params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n          if (async != null)  {\n            String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n            params.add(ASYNC, coreAdminAsyncId);\n            requestMap.put(nodeName, coreAdminAsyncId);\n          }\n          addPropertyParams(message, params);\n\n          ShardRequest sreq = new ShardRequest();\n          params.set(\"qt\", adminPath);\n          sreq.purpose = 1;\n          sreq.shards = new String[] {baseUrl};\n          sreq.actualShards = sreq.shards;\n          sreq.params = params;\n\n          if(isLegacyCloud) {\n            shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n          } else {\n            coresToCreate.put(coreName, sreq);\n          }\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":["5ad9c35f926b4bf8da0336d1300efc709c8d5a56","5ad9c35f926b4bf8da0336d1300efc709c8d5a56","5ad9c35f926b4bf8da0336d1300efc709c8d5a56","5ad9c35f926b4bf8da0336d1300efc709c8d5a56","5ad9c35f926b4bf8da0336d1300efc709c8d5a56","5ad9c35f926b4bf8da0336d1300efc709c8d5a56","5ad9c35f926b4bf8da0336d1300efc709c8d5a56","5ad9c35f926b4bf8da0336d1300efc709c8d5a56","69e6520a21709190413a63084ed135271aab1a7c","69e6520a21709190413a63084ed135271aab1a7c","69e6520a21709190413a63084ed135271aab1a7c","69e6520a21709190413a63084ed135271aab1a7c","69e6520a21709190413a63084ed135271aab1a7c","69e6520a21709190413a63084ed135271aab1a7c","69e6520a21709190413a63084ed135271aab1a7c","69e6520a21709190413a63084ed135271aab1a7c","f291d2d430e8149d24fdd06b0bcdab0941ec9144","f291d2d430e8149d24fdd06b0bcdab0941ec9144","c0ee0c7f6bcf49646748d46aee9383b68eb55c80","c0ee0c7f6bcf49646748d46aee9383b68eb55c80"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"07dbf37ea1062f6f3f4fc7deb3ae385ab837ebc8","date":1431966199,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(NAME);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    } else if (!validateConfig(configName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Can not find the specified config set: \" + configName);\n    }\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      String async = null;\n      async = message.getStr(\"async\");\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n\n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n\n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n\n      Map<Position, String> positionVsNodes = identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(NAME));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + message.getStr(NAME));\n\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n\n      log.info(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<Position, String> e : positionVsNodes.entrySet()) {\n        Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.info(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        params.set(\"qt\", adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(NAME);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    } else if (!validateConfig(configName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Can not find the specified config set: \" + configName);\n    }\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(ZkStateReader.REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      String async = null;\n      async = message.getStr(\"async\");\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(ZkStateReader.MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, ZkStateReader.REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n\n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + ZkStateReader.REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n\n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + ZkStateReader.MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + ZkStateReader.REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n\n      Map<Position, String> positionVsNodes = identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(NAME));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + message.getStr(NAME));\n\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n\n      log.info(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<Position, String> e : positionVsNodes.entrySet()) {\n        Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.info(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        params.set(\"qt\", adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f222f4f2bda21ffd6b39b3362b2412e98e4d5e31","date":1435517625,"type":3,"author":"Ramkumar Aiyengar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(NAME);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    } else if (!validateConfig(configName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Can not find the specified config set: \" + configName);\n    }\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n\n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n\n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n\n      Map<Position, String> positionVsNodes = identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(NAME));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + message.getStr(NAME));\n\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n\n      log.info(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<Position, String> e : positionVsNodes.entrySet()) {\n        Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.info(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        params.set(\"qt\", adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(NAME);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    } else if (!validateConfig(configName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Can not find the specified config set: \" + configName);\n    }\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      String async = null;\n      async = message.getStr(\"async\");\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n\n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n\n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n\n      Map<Position, String> positionVsNodes = identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(NAME));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + message.getStr(NAME));\n\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n\n      log.info(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<Position, String> e : positionVsNodes.entrySet()) {\n        Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.info(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        params.set(\"qt\", adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b693a83132c9e45afcd564fd65a25b60ed80388b","date":1436882146,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(NAME);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    } else if (!validateConfig(configName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Can not find the specified config set: \" + configName);\n    }\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n\n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n\n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n\n      Map<Position, String> positionVsNodes = identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(NAME));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + message.getStr(NAME));\n\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n\n      log.info(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<Position, String> e : positionVsNodes.entrySet()) {\n        Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.info(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getInQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        params.set(\"qt\", adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(NAME);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    } else if (!validateConfig(configName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Can not find the specified config set: \" + configName);\n    }\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n\n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n\n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n\n      Map<Position, String> positionVsNodes = identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(NAME));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + message.getStr(NAME));\n\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n\n      log.info(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<Position, String> e : positionVsNodes.entrySet()) {\n        Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.info(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        params.set(\"qt\", adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2c0d0643efdcc41b0c814bf27a381e4dc2ff472b","date":1438774486,"type":3,"author":"Christine Poerschke","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    final String collectionName = message.getStr(NAME);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    } else if (!validateConfig(configName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Can not find the specified config set: \" + configName);\n    }\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        if (repFactor > nodeList.size()) {\n          log.warn(\"Specified \"\n              + REPLICATION_FACTOR\n              + \" of \"\n              + repFactor\n              + \" on collection \"\n              + collectionName\n              + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n        \n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * repFactor;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      }\n\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we do see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.info(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n\n      log.info(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<Position, String> e : positionVsNodes.entrySet()) {\n        Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.info(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getInQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        params.set(\"qt\", adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    String collectionName = message.getStr(NAME);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    } else if (!validateConfig(configName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Can not find the specified config set: \" + configName);\n    }\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n\n      if (repFactor > nodeList.size()) {\n        log.warn(\"Specified \"\n            + REPLICATION_FACTOR\n            + \" of \"\n            + repFactor\n            + \" on collection \"\n            + collectionName\n            + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n            + nodeList.size()\n            + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n      }\n\n      int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n      int requestedShardsToCreate = numSlices * repFactor;\n      if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n            + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n            + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n            + \". This allows a maximum of \" + maxShardsAllowedToCreate\n            + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n            + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n            + \". This requires \" + requestedShardsToCreate\n            + \" shards to be created (higher than the allowed number)\");\n      }\n\n      Map<Position, String> positionVsNodes = identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(message.getStr(NAME));\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + message.getStr(NAME));\n\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n\n      log.info(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<Position, String> e : positionVsNodes.entrySet()) {\n        Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.info(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getInQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        params.set(\"qt\", adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":["c0ee0c7f6bcf49646748d46aee9383b68eb55c80","c0ee0c7f6bcf49646748d46aee9383b68eb55c80"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e31e6ce5848e5040d4c9ecbb25bc6ccf5d0894ac","date":1438841252,"type":5,"author":"Gregory Chanan","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#createCollection(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    final String collectionName = message.getStr(NAME);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    } else if (!validateConfig(configName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Can not find the specified config set: \" + configName);\n    }\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        if (repFactor > nodeList.size()) {\n          log.warn(\"Specified \"\n              + REPLICATION_FACTOR\n              + \" of \"\n              + repFactor\n              + \" on collection \"\n              + collectionName\n              + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n        \n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * repFactor;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      }\n\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we don't see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.info(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n\n      log.info(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<Position, String> e : positionVsNodes.entrySet()) {\n        Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.info(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getInQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        params.set(\"qt\", adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","sourceOld":"  private void createCollection(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {\n    final String collectionName = message.getStr(NAME);\n    if (clusterState.hasCollection(collectionName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n    }\n\n    String configName = getConfigName(collectionName, message);\n    if (configName == null) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n    } else if (!validateConfig(configName)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Can not find the specified config set: \" + configName);\n    }\n\n    try {\n      // look at the replication factor and see if it matches reality\n      // if it does not, find best nodes to create more cores\n\n      int repFactor = message.getInt(REPLICATION_FACTOR, 1);\n\n      ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n      final String async = message.getStr(ASYNC);\n\n      Integer numSlices = message.getInt(NUM_SLICES, null);\n      String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n      List<String> shardNames = new ArrayList<>();\n      if(ImplicitDocRouter.NAME.equals(router)){\n        ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n        numSlices = shardNames.size();\n      } else {\n        if (numSlices == null ) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" is a required param (when using CompositeId router).\");\n        }\n        ClusterStateMutator.getShardNames(numSlices, shardNames);\n      }\n\n      int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n\n      if (repFactor <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, REPLICATION_FACTOR + \" must be greater than 0\");\n      }\n\n      if (numSlices <= 0) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, NUM_SLICES + \" must be > 0\");\n      }\n\n      // we need to look at every node and see how many cores it serves\n      // add our new cores to existing nodes serving the least number of cores\n      // but (for now) require that each core goes on a distinct node.\n\n      final List<String> nodeList = getLiveOrLiveAndCreateNodeSetList(clusterState.getLiveNodes(), message, RANDOM);\n      Map<Position, String> positionVsNodes;\n      if (nodeList.isEmpty()) {\n        log.warn(\"It is unusual to create a collection (\"+collectionName+\") without cores.\");\n\n        positionVsNodes = new HashMap<>();\n      } else {\n        if (repFactor > nodeList.size()) {\n          log.warn(\"Specified \"\n              + REPLICATION_FACTOR\n              + \" of \"\n              + repFactor\n              + \" on collection \"\n              + collectionName\n              + \" is higher than or equal to the number of Solr instances currently live or live and part of your \" + CREATE_NODE_SET + \"(\"\n              + nodeList.size()\n              + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n        }\n        \n        int maxShardsAllowedToCreate = maxShardsPerNode * nodeList.size();\n        int requestedShardsToCreate = numSlices * repFactor;\n        if (maxShardsAllowedToCreate < requestedShardsToCreate) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName + \". Value of \"\n              + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n              + \", and the number of nodes currently live or live and part of your \"+CREATE_NODE_SET+\" is \" + nodeList.size()\n              + \". This allows a maximum of \" + maxShardsAllowedToCreate\n              + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n              + \" and value of \" + REPLICATION_FACTOR + \" is \" + repFactor\n              + \". This requires \" + requestedShardsToCreate\n              + \" shards to be created (higher than the allowed number)\");\n        }\n\n        positionVsNodes = identifyNodes(clusterState, nodeList, message, shardNames, repFactor);\n      }\n\n      boolean isLegacyCloud =  Overseer.isLegacy(zkStateReader.getClusterProps());\n\n      createConfNode(configName, collectionName, isLegacyCloud);\n\n      Overseer.getInQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n\n      // wait for a while until we do see the collection\n      long waitUntil = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n      boolean created = false;\n      while (System.nanoTime() < waitUntil) {\n        Thread.sleep(100);\n        created = zkStateReader.getClusterState().getCollections().contains(collectionName);\n        if(created) break;\n      }\n      if (!created)\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n\n      if (nodeList.isEmpty()) {\n        log.info(\"Finished create command for collection: {}\", collectionName);\n        return;\n      }\n      // For tracking async calls.\n      HashMap<String, String> requestMap = new HashMap<String, String>();\n\n\n      log.info(formatString(\"Creating SolrCores for new collection {0}, shardNames {1} , replicationFactor : {2}\",\n          collectionName, shardNames, repFactor));\n      Map<String ,ShardRequest> coresToCreate = new LinkedHashMap<>();\n      for (Map.Entry<Position, String> e : positionVsNodes.entrySet()) {\n        Position position = e.getKey();\n        String nodeName = e.getValue();\n        String coreName = collectionName + \"_\" + position.shard + \"_replica\" + (position.index + 1);\n        log.info(formatString(\"Creating core {0} as part of shard {1} of collection {2} on {3}\"\n            , coreName, position.shard, collectionName, nodeName));\n\n\n        String baseUrl = zkStateReader.getBaseUrlForNodeName(nodeName);\n        //in the new mode, create the replica in clusterstate prior to creating the core.\n        // Otherwise the core creation fails\n        if (!isLegacyCloud) {\n          ZkNodeProps props = new ZkNodeProps(\n              Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n              ZkStateReader.COLLECTION_PROP, collectionName,\n              ZkStateReader.SHARD_ID_PROP, position.shard,\n              ZkStateReader.CORE_NAME_PROP, coreName,\n              ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n              ZkStateReader.BASE_URL_PROP, baseUrl);\n          Overseer.getInQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n        }\n\n        // Need to create new params for each request\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminAction.CREATE.toString());\n\n        params.set(CoreAdminParams.NAME, coreName);\n        params.set(COLL_CONF, configName);\n        params.set(CoreAdminParams.COLLECTION, collectionName);\n        params.set(CoreAdminParams.SHARD, position.shard);\n        params.set(ZkStateReader.NUM_SHARDS_PROP, numSlices);\n\n        if (async != null) {\n          String coreAdminAsyncId = async + Math.abs(System.nanoTime());\n          params.add(ASYNC, coreAdminAsyncId);\n          requestMap.put(nodeName, coreAdminAsyncId);\n        }\n        addPropertyParams(message, params);\n\n        ShardRequest sreq = new ShardRequest();\n        params.set(\"qt\", adminPath);\n        sreq.purpose = 1;\n        sreq.shards = new String[]{baseUrl};\n        sreq.actualShards = sreq.shards;\n        sreq.params = params;\n\n        if (isLegacyCloud) {\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        } else {\n          coresToCreate.put(coreName, sreq);\n        }\n      }\n\n      if(!isLegacyCloud) {\n        // wait for all replica entries to be created\n        Map<String, Replica> replicas = waitToSeeReplicasInState(collectionName, coresToCreate.keySet());\n        for (Map.Entry<String, ShardRequest> e : coresToCreate.entrySet()) {\n          ShardRequest sreq = e.getValue();\n          sreq.params.set(CoreAdminParams.CORE_NODE_NAME, replicas.get(e.getKey()).getName());\n          shardHandler.submit(sreq, sreq.shards[0], sreq.params);\n        }\n      }\n\n      processResponses(results, shardHandler);\n\n      completeAsyncRequest(async, requestMap, results);\n\n      log.info(\"Finished create command on all shards for collection: \"\n          + collectionName);\n\n    } catch (SolrException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, null, ex);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"f222f4f2bda21ffd6b39b3362b2412e98e4d5e31":["07dbf37ea1062f6f3f4fc7deb3ae385ab837ebc8"],"96ea64d994d340044e0d57aeb6a5871539d10ca5":["fd5bc858b8426d40bbe90b94120ead37c77d7954","eb4db141b31e99d2285436da1428411ed5501f56"],"3b90bc78bc6662319cd8bad5213f992fd4807bb2":["707fc23d793376ed98be0bd2f100d32dd5a9c0df"],"6421b93f31f88ed3e81722f3bf9fabaff15e03a9":["b711ca2887ae3fda68611cbb78c1b389fa9833be"],"058f5a3debcfa0ea477da3eabb4cbe2ec0fac211":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"30c688f7052130cef7bd419c85e3c5be214f7b9e":["989ba56f08f1aa5d58405eed8411bf40e4150deb"],"1eeda7e62e149f90eee8895af874c74efa7d4852":["4f762b78b5a7fc5814208ae853b54d0041b2e2b1"],"fd5bc858b8426d40bbe90b94120ead37c77d7954":["840fc95f31a25d020cd825e880018bcfa0bacc71"],"a219f1dcad1700e84807666bdbd2b573e8de7021":["1390137e395d2f07f9ba5b8c43d293befe84d563"],"24a5da2a0d397ff29f3de8f6cf451d3412c2509a":["103857ec20f79f31c7a00310a91ed001b9a6ef17"],"d2638f781be724518ff6c2263d14a48cf6e68017":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","1390137e395d2f07f9ba5b8c43d293befe84d563"],"ee31282189f924712ed9ad83e3073e0c207a1a53":["3b90bc78bc6662319cd8bad5213f992fd4807bb2"],"6f26f74e4969851a019d28f10315cb1c77786f22":["f3695669e45bdf702e0bc9176428b884bd24cdfd"],"4f762b78b5a7fc5814208ae853b54d0041b2e2b1":["0beaed456aa3358e5e4a99ea2aea994ef6c81de3"],"08b22329006608bd6b95aeba7a59f28092cd7a5e":["24a5da2a0d397ff29f3de8f6cf451d3412c2509a"],"8c7a6584aa35e033d783e02c6f4eefa6ad21c7fe":["a219f1dcad1700e84807666bdbd2b573e8de7021"],"b711ca2887ae3fda68611cbb78c1b389fa9833be":["e187a371a1d09379bb452c2c13a7b9221525dff8"],"2c0d0643efdcc41b0c814bf27a381e4dc2ff472b":["b693a83132c9e45afcd564fd65a25b60ed80388b"],"fe999fc2d95d6fea71f960bf9556858387ba21f5":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"57641b2e9dc6155be493cfb6ae9b8a9c8ceffa72":["b753f4bd40fd8ec5276ceae15e867d2dceeb5552"],"ec81a59b3b8e480b084a4bfab0d55b2519b271ae":["058f5a3debcfa0ea477da3eabb4cbe2ec0fac211"],"74f45af4339b0daf7a95c820ab88c1aea74fbce0":["e187a371a1d09379bb452c2c13a7b9221525dff8","3f9f2cd4fc995f484da092b8100a389072ed49ff"],"8497bb4f9de61b5520423bd9af88ea11a6e109e7":["57641b2e9dc6155be493cfb6ae9b8a9c8ceffa72"],"3f9f2cd4fc995f484da092b8100a389072ed49ff":["6421b93f31f88ed3e81722f3bf9fabaff15e03a9"],"6b51e891605604cf911ab579fb28c49b26749f93":["fd5bc858b8426d40bbe90b94120ead37c77d7954","eb4db141b31e99d2285436da1428411ed5501f56"],"b753f4bd40fd8ec5276ceae15e867d2dceeb5552":["3f9f2cd4fc995f484da092b8100a389072ed49ff"],"989ba56f08f1aa5d58405eed8411bf40e4150deb":["0ad7bdba3e91cf3373cda2e52239cb761fc0b452"],"630c3d71b7859a9f17dd985bb82bba51bccee575":["fe999fc2d95d6fea71f960bf9556858387ba21f5"],"b7605579001505896d48b07160075a5c8b8e128e":["f3695669e45bdf702e0bc9176428b884bd24cdfd","6f26f74e4969851a019d28f10315cb1c77786f22"],"13f445c5bd6f19fd57d5a3ca0a35244c96f45aa8":["57641b2e9dc6155be493cfb6ae9b8a9c8ceffa72","840fc95f31a25d020cd825e880018bcfa0bacc71"],"e31e6ce5848e5040d4c9ecbb25bc6ccf5d0894ac":["2c0d0643efdcc41b0c814bf27a381e4dc2ff472b"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["707fc23d793376ed98be0bd2f100d32dd5a9c0df","ee31282189f924712ed9ad83e3073e0c207a1a53"],"8aa2bb13f56a3ad540fd2dc5e882e1ed4bf799d1":["08b22329006608bd6b95aeba7a59f28092cd7a5e"],"f3695669e45bdf702e0bc9176428b884bd24cdfd":["ec81a59b3b8e480b084a4bfab0d55b2519b271ae"],"6e756785b6f25f3b8f7ee57c7e210c6b67fbfbbf":["630c3d71b7859a9f17dd985bb82bba51bccee575"],"07dbf37ea1062f6f3f4fc7deb3ae385ab837ebc8":["8c7a6584aa35e033d783e02c6f4eefa6ad21c7fe"],"1390137e395d2f07f9ba5b8c43d293befe84d563":["ee31282189f924712ed9ad83e3073e0c207a1a53"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["eb4db141b31e99d2285436da1428411ed5501f56"],"55980207f1977bd1463465de1659b821347e2fa8":["30c688f7052130cef7bd419c85e3c5be214f7b9e","103857ec20f79f31c7a00310a91ed001b9a6ef17"],"716d18f3a9b0993bc679d7fa7abdc9bfb03411ec":["4f762b78b5a7fc5814208ae853b54d0041b2e2b1","1eeda7e62e149f90eee8895af874c74efa7d4852"],"eb4db141b31e99d2285436da1428411ed5501f56":["fd5bc858b8426d40bbe90b94120ead37c77d7954"],"b693a83132c9e45afcd564fd65a25b60ed80388b":["f222f4f2bda21ffd6b39b3362b2412e98e4d5e31"],"0beaed456aa3358e5e4a99ea2aea994ef6c81de3":["6e756785b6f25f3b8f7ee57c7e210c6b67fbfbbf"],"840fc95f31a25d020cd825e880018bcfa0bacc71":["8497bb4f9de61b5520423bd9af88ea11a6e109e7"],"0ad7bdba3e91cf3373cda2e52239cb761fc0b452":["6f26f74e4969851a019d28f10315cb1c77786f22"],"707fc23d793376ed98be0bd2f100d32dd5a9c0df":["8aa2bb13f56a3ad540fd2dc5e882e1ed4bf799d1"],"103857ec20f79f31c7a00310a91ed001b9a6ef17":["30c688f7052130cef7bd419c85e3c5be214f7b9e"],"e187a371a1d09379bb452c2c13a7b9221525dff8":["1eeda7e62e149f90eee8895af874c74efa7d4852"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["e31e6ce5848e5040d4c9ecbb25bc6ccf5d0894ac"]},"commit2Childs":{"f222f4f2bda21ffd6b39b3362b2412e98e4d5e31":["b693a83132c9e45afcd564fd65a25b60ed80388b"],"96ea64d994d340044e0d57aeb6a5871539d10ca5":[],"3b90bc78bc6662319cd8bad5213f992fd4807bb2":["ee31282189f924712ed9ad83e3073e0c207a1a53"],"6421b93f31f88ed3e81722f3bf9fabaff15e03a9":["3f9f2cd4fc995f484da092b8100a389072ed49ff"],"058f5a3debcfa0ea477da3eabb4cbe2ec0fac211":["ec81a59b3b8e480b084a4bfab0d55b2519b271ae"],"30c688f7052130cef7bd419c85e3c5be214f7b9e":["55980207f1977bd1463465de1659b821347e2fa8","103857ec20f79f31c7a00310a91ed001b9a6ef17"],"1eeda7e62e149f90eee8895af874c74efa7d4852":["716d18f3a9b0993bc679d7fa7abdc9bfb03411ec","e187a371a1d09379bb452c2c13a7b9221525dff8"],"fd5bc858b8426d40bbe90b94120ead37c77d7954":["96ea64d994d340044e0d57aeb6a5871539d10ca5","6b51e891605604cf911ab579fb28c49b26749f93","eb4db141b31e99d2285436da1428411ed5501f56"],"a219f1dcad1700e84807666bdbd2b573e8de7021":["8c7a6584aa35e033d783e02c6f4eefa6ad21c7fe"],"24a5da2a0d397ff29f3de8f6cf451d3412c2509a":["08b22329006608bd6b95aeba7a59f28092cd7a5e"],"d2638f781be724518ff6c2263d14a48cf6e68017":[],"ee31282189f924712ed9ad83e3073e0c207a1a53":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","1390137e395d2f07f9ba5b8c43d293befe84d563"],"4f762b78b5a7fc5814208ae853b54d0041b2e2b1":["1eeda7e62e149f90eee8895af874c74efa7d4852","716d18f3a9b0993bc679d7fa7abdc9bfb03411ec"],"6f26f74e4969851a019d28f10315cb1c77786f22":["b7605579001505896d48b07160075a5c8b8e128e","0ad7bdba3e91cf3373cda2e52239cb761fc0b452"],"08b22329006608bd6b95aeba7a59f28092cd7a5e":["8aa2bb13f56a3ad540fd2dc5e882e1ed4bf799d1"],"8c7a6584aa35e033d783e02c6f4eefa6ad21c7fe":["07dbf37ea1062f6f3f4fc7deb3ae385ab837ebc8"],"b711ca2887ae3fda68611cbb78c1b389fa9833be":["6421b93f31f88ed3e81722f3bf9fabaff15e03a9"],"2c0d0643efdcc41b0c814bf27a381e4dc2ff472b":["e31e6ce5848e5040d4c9ecbb25bc6ccf5d0894ac"],"fe999fc2d95d6fea71f960bf9556858387ba21f5":["630c3d71b7859a9f17dd985bb82bba51bccee575"],"57641b2e9dc6155be493cfb6ae9b8a9c8ceffa72":["8497bb4f9de61b5520423bd9af88ea11a6e109e7","13f445c5bd6f19fd57d5a3ca0a35244c96f45aa8"],"ec81a59b3b8e480b084a4bfab0d55b2519b271ae":["f3695669e45bdf702e0bc9176428b884bd24cdfd"],"74f45af4339b0daf7a95c820ab88c1aea74fbce0":[],"8497bb4f9de61b5520423bd9af88ea11a6e109e7":["840fc95f31a25d020cd825e880018bcfa0bacc71"],"3f9f2cd4fc995f484da092b8100a389072ed49ff":["74f45af4339b0daf7a95c820ab88c1aea74fbce0","b753f4bd40fd8ec5276ceae15e867d2dceeb5552"],"6b51e891605604cf911ab579fb28c49b26749f93":[],"b753f4bd40fd8ec5276ceae15e867d2dceeb5552":["57641b2e9dc6155be493cfb6ae9b8a9c8ceffa72"],"989ba56f08f1aa5d58405eed8411bf40e4150deb":["30c688f7052130cef7bd419c85e3c5be214f7b9e"],"630c3d71b7859a9f17dd985bb82bba51bccee575":["6e756785b6f25f3b8f7ee57c7e210c6b67fbfbbf"],"b7605579001505896d48b07160075a5c8b8e128e":[],"13f445c5bd6f19fd57d5a3ca0a35244c96f45aa8":[],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["d2638f781be724518ff6c2263d14a48cf6e68017"],"e31e6ce5848e5040d4c9ecbb25bc6ccf5d0894ac":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"8aa2bb13f56a3ad540fd2dc5e882e1ed4bf799d1":["707fc23d793376ed98be0bd2f100d32dd5a9c0df"],"f3695669e45bdf702e0bc9176428b884bd24cdfd":["6f26f74e4969851a019d28f10315cb1c77786f22","b7605579001505896d48b07160075a5c8b8e128e"],"6e756785b6f25f3b8f7ee57c7e210c6b67fbfbbf":["0beaed456aa3358e5e4a99ea2aea994ef6c81de3"],"07dbf37ea1062f6f3f4fc7deb3ae385ab837ebc8":["f222f4f2bda21ffd6b39b3362b2412e98e4d5e31"],"1390137e395d2f07f9ba5b8c43d293befe84d563":["a219f1dcad1700e84807666bdbd2b573e8de7021","d2638f781be724518ff6c2263d14a48cf6e68017"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["fe999fc2d95d6fea71f960bf9556858387ba21f5"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["058f5a3debcfa0ea477da3eabb4cbe2ec0fac211"],"55980207f1977bd1463465de1659b821347e2fa8":[],"716d18f3a9b0993bc679d7fa7abdc9bfb03411ec":[],"eb4db141b31e99d2285436da1428411ed5501f56":["96ea64d994d340044e0d57aeb6a5871539d10ca5","6b51e891605604cf911ab579fb28c49b26749f93","634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"b693a83132c9e45afcd564fd65a25b60ed80388b":["2c0d0643efdcc41b0c814bf27a381e4dc2ff472b"],"0beaed456aa3358e5e4a99ea2aea994ef6c81de3":["4f762b78b5a7fc5814208ae853b54d0041b2e2b1"],"840fc95f31a25d020cd825e880018bcfa0bacc71":["fd5bc858b8426d40bbe90b94120ead37c77d7954","13f445c5bd6f19fd57d5a3ca0a35244c96f45aa8"],"0ad7bdba3e91cf3373cda2e52239cb761fc0b452":["989ba56f08f1aa5d58405eed8411bf40e4150deb"],"707fc23d793376ed98be0bd2f100d32dd5a9c0df":["3b90bc78bc6662319cd8bad5213f992fd4807bb2","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae"],"103857ec20f79f31c7a00310a91ed001b9a6ef17":["24a5da2a0d397ff29f3de8f6cf451d3412c2509a","55980207f1977bd1463465de1659b821347e2fa8"],"e187a371a1d09379bb452c2c13a7b9221525dff8":["b711ca2887ae3fda68611cbb78c1b389fa9833be","74f45af4339b0daf7a95c820ab88c1aea74fbce0"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["96ea64d994d340044e0d57aeb6a5871539d10ca5","d2638f781be724518ff6c2263d14a48cf6e68017","74f45af4339b0daf7a95c820ab88c1aea74fbce0","6b51e891605604cf911ab579fb28c49b26749f93","b7605579001505896d48b07160075a5c8b8e128e","13f445c5bd6f19fd57d5a3ca0a35244c96f45aa8","55980207f1977bd1463465de1659b821347e2fa8","716d18f3a9b0993bc679d7fa7abdc9bfb03411ec","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}