{"path":"lucene/codecs/src/test/org/apache/lucene/codecs/autoprefix/TestAutoPrefixTerms#testBinaryNumericRanges().mjava","commits":[{"id":"3e8715d826e588419327562287d5d6a8040d63d6","date":1427987148,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/codecs/src/test/org/apache/lucene/codecs/autoprefix/TestAutoPrefixTerms#testBinaryNumericRanges().mjava","pathOld":"/dev/null","sourceNew":"  // Numbers are encoded in full binary (4 byte ints):\n  public void testBinaryNumericRanges() throws Exception {\n    if (VERBOSE) {\n      System.out.println(\"TEST: minItemsPerBlock=\" + minItemsPerBlock);\n      System.out.println(\"TEST: maxItemsPerBlock=\" + maxItemsPerBlock);\n      System.out.println(\"TEST: minTermsAutoPrefix=\" + minTermsAutoPrefix);\n      System.out.println(\"TEST: maxTermsAutoPrefix=\" + maxTermsAutoPrefix);\n    }\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setCodec(codec);\n    IndexWriter w = new IndexWriter(dir, iwc);\n    int numTerms = TestUtil.nextInt(random(), 3000, 50000);\n    Set<Integer> terms = new HashSet<>();\n    while (terms.size() < numTerms) {\n      terms.add(random().nextInt());\n    }\n\n    for(Integer term : terms) {\n      Document doc = new Document();\n      doc.add(new BinaryField(\"field\", intToBytes(term)));\n      doc.add(new NumericDocValuesField(\"field\", term));\n      w.addDocument(doc);\n    }\n\n    if (random().nextBoolean()) {\n      if (VERBOSE) System.out.println(\"TEST: now force merge\");\n      w.forceMerge(1);\n    }\n\n    IndexReader r = DirectoryReader.open(w, true);\n\n    List<Integer> sortedTerms = new ArrayList<>(terms);\n    Collections.sort(sortedTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: sorted terms:\");\n      int idx = 0;\n      for(Integer term : sortedTerms) {\n        System.out.println(idx + \": \" + term);\n        idx++;\n      }\n    }\n\n    int iters = atLeast(100);\n    for(int iter=0;iter<iters;iter++) {\n\n      int min, max;\n      while (true) {\n        min = random().nextInt();\n        max = random().nextInt();\n        if (min == max) {\n          continue;\n        } else if (min > max) {\n          int x = min;\n          min = max;\n          max = x;\n        }\n        break;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" min=\" + min + \" (\" + intToBytes(min) + \") max=\" + max + \" (\" + intToBytes(max) + \")\");\n      }\n      \n      boolean minInclusive = random().nextBoolean();\n      BytesRef minTerm = intToBytes(min);\n      boolean maxInclusive = random().nextBoolean();\n      BytesRef maxTerm = intToBytes(max);\n      CompiledAutomaton ca = new CompiledAutomaton(Automata.makeBinaryInterval(minTerm, minInclusive, maxTerm, maxInclusive),\n                                                   true, false, Integer.MAX_VALUE, true);\n\n      TermsEnum te = ca.getTermsEnum(MultiFields.getTerms(r, \"field\"));\n      NumericDocValues docValues = MultiDocValues.getNumericValues(r, \"field\");\n      PostingsEnum postingsEnum = null;\n      VerifyAutoPrefixTerms verifier = new VerifyAutoPrefixTerms(r.maxDoc(), minTerm, maxTerm);\n      while (te.next() != null) {\n        if (VERBOSE) {\n          System.out.println(\"  got term=\" + te.term() + \" docFreq=\" + te.docFreq());\n        }\n        verifier.sawTerm(te.term());        \n        postingsEnum = te.postings(null, postingsEnum);\n        int docID;\n        while ((docID = postingsEnum.nextDoc()) != PostingsEnum.NO_MORE_DOCS) {\n          long v = docValues.get(docID);\n          assert v >= min && v <= max: \"docID=\" + docID + \" v=\" + v;\n          verifier.sawDoc(docID);\n        }\n      }\n      \n      int startLoc = Collections.binarySearch(sortedTerms, min);\n      if (startLoc < 0) {\n        startLoc = -startLoc-1;\n      } else if (minInclusive == false) {\n        startLoc++;\n      }\n      int endLoc = Collections.binarySearch(sortedTerms, max);\n      if (endLoc < 0) {\n        endLoc = -endLoc-2;\n      } else if (maxInclusive == false) {\n        endLoc--;\n      }\n      int expectedHits = endLoc-startLoc+1;\n      try {\n        verifier.finish(expectedHits, maxTermsAutoPrefix);\n      } catch (AssertionError ae) {\n        for(int i=0;i<numTerms;i++) {\n          if (verifier.allHits.get(i) == false) {\n            int v = (int) docValues.get(i);\n            boolean accept = (v > min || (v == min && minInclusive)) &&\n              (v < max || (v == max && maxInclusive));\n            if (accept) {\n              System.out.println(\"MISSING: docID=\" + i + \" v=\" + v + \" term=\" + intToBytes(v));\n            }\n          }\n        }\n\n        throw ae;\n      }\n    }\n\n    r.close();\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d2638f781be724518ff6c2263d14a48cf6e68017","date":1427989059,"type":0,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/codecs/src/test/org/apache/lucene/codecs/autoprefix/TestAutoPrefixTerms#testBinaryNumericRanges().mjava","pathOld":"/dev/null","sourceNew":"  // Numbers are encoded in full binary (4 byte ints):\n  public void testBinaryNumericRanges() throws Exception {\n    if (VERBOSE) {\n      System.out.println(\"TEST: minItemsPerBlock=\" + minItemsPerBlock);\n      System.out.println(\"TEST: maxItemsPerBlock=\" + maxItemsPerBlock);\n      System.out.println(\"TEST: minTermsAutoPrefix=\" + minTermsAutoPrefix);\n      System.out.println(\"TEST: maxTermsAutoPrefix=\" + maxTermsAutoPrefix);\n    }\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setCodec(codec);\n    IndexWriter w = new IndexWriter(dir, iwc);\n    int numTerms = TestUtil.nextInt(random(), 3000, 50000);\n    Set<Integer> terms = new HashSet<>();\n    while (terms.size() < numTerms) {\n      terms.add(random().nextInt());\n    }\n\n    for(Integer term : terms) {\n      Document doc = new Document();\n      doc.add(new BinaryField(\"field\", intToBytes(term)));\n      doc.add(new NumericDocValuesField(\"field\", term));\n      w.addDocument(doc);\n    }\n\n    if (random().nextBoolean()) {\n      if (VERBOSE) System.out.println(\"TEST: now force merge\");\n      w.forceMerge(1);\n    }\n\n    IndexReader r = DirectoryReader.open(w, true);\n\n    List<Integer> sortedTerms = new ArrayList<>(terms);\n    Collections.sort(sortedTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: sorted terms:\");\n      int idx = 0;\n      for(Integer term : sortedTerms) {\n        System.out.println(idx + \": \" + term);\n        idx++;\n      }\n    }\n\n    int iters = atLeast(100);\n    for(int iter=0;iter<iters;iter++) {\n\n      int min, max;\n      while (true) {\n        min = random().nextInt();\n        max = random().nextInt();\n        if (min == max) {\n          continue;\n        } else if (min > max) {\n          int x = min;\n          min = max;\n          max = x;\n        }\n        break;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" min=\" + min + \" (\" + intToBytes(min) + \") max=\" + max + \" (\" + intToBytes(max) + \")\");\n      }\n      \n      boolean minInclusive = random().nextBoolean();\n      BytesRef minTerm = intToBytes(min);\n      boolean maxInclusive = random().nextBoolean();\n      BytesRef maxTerm = intToBytes(max);\n      CompiledAutomaton ca = new CompiledAutomaton(Automata.makeBinaryInterval(minTerm, minInclusive, maxTerm, maxInclusive),\n                                                   true, false, Integer.MAX_VALUE, true);\n\n      TermsEnum te = ca.getTermsEnum(MultiFields.getTerms(r, \"field\"));\n      NumericDocValues docValues = MultiDocValues.getNumericValues(r, \"field\");\n      PostingsEnum postingsEnum = null;\n      VerifyAutoPrefixTerms verifier = new VerifyAutoPrefixTerms(r.maxDoc(), minTerm, maxTerm);\n      while (te.next() != null) {\n        if (VERBOSE) {\n          System.out.println(\"  got term=\" + te.term() + \" docFreq=\" + te.docFreq());\n        }\n        verifier.sawTerm(te.term());        \n        postingsEnum = te.postings(null, postingsEnum);\n        int docID;\n        while ((docID = postingsEnum.nextDoc()) != PostingsEnum.NO_MORE_DOCS) {\n          long v = docValues.get(docID);\n          assert v >= min && v <= max: \"docID=\" + docID + \" v=\" + v;\n          verifier.sawDoc(docID);\n        }\n      }\n      \n      int startLoc = Collections.binarySearch(sortedTerms, min);\n      if (startLoc < 0) {\n        startLoc = -startLoc-1;\n      } else if (minInclusive == false) {\n        startLoc++;\n      }\n      int endLoc = Collections.binarySearch(sortedTerms, max);\n      if (endLoc < 0) {\n        endLoc = -endLoc-2;\n      } else if (maxInclusive == false) {\n        endLoc--;\n      }\n      int expectedHits = endLoc-startLoc+1;\n      try {\n        verifier.finish(expectedHits, maxTermsAutoPrefix);\n      } catch (AssertionError ae) {\n        for(int i=0;i<numTerms;i++) {\n          if (verifier.allHits.get(i) == false) {\n            int v = (int) docValues.get(i);\n            boolean accept = (v > min || (v == min && minInclusive)) &&\n              (v < max || (v == max && maxInclusive));\n            if (accept) {\n              System.out.println(\"MISSING: docID=\" + i + \" v=\" + v + \" term=\" + intToBytes(v));\n            }\n          }\n        }\n\n        throw ae;\n      }\n    }\n\n    r.close();\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0f4464508ee83288c8c4585b533f9faaa93aa314","date":1435240759,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/codecs/src/test/org/apache/lucene/codecs/autoprefix/TestAutoPrefixTerms#testBinaryNumericRanges().mjava","pathOld":"lucene/codecs/src/test/org/apache/lucene/codecs/autoprefix/TestAutoPrefixTerms#testBinaryNumericRanges().mjava","sourceNew":"  // Numbers are encoded in full binary (4 byte ints):\n  public void testBinaryNumericRanges() throws Exception {\n    if (VERBOSE) {\n      System.out.println(\"TEST: minItemsPerBlock=\" + minItemsPerBlock);\n      System.out.println(\"TEST: maxItemsPerBlock=\" + maxItemsPerBlock);\n      System.out.println(\"TEST: minTermsAutoPrefix=\" + minTermsAutoPrefix);\n      System.out.println(\"TEST: maxTermsAutoPrefix=\" + maxTermsAutoPrefix);\n    }\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setCodec(codec);\n    IndexWriter w = new IndexWriter(dir, iwc);\n    int numTerms = TestUtil.nextInt(random(), 3000, 50000);\n    Set<Integer> terms = new HashSet<>();\n    while (terms.size() < numTerms) {\n      terms.add(random().nextInt());\n    }\n\n    for(Integer term : terms) {\n      Document doc = new Document();\n      doc.add(new BinaryField(\"field\", intToBytes(term)));\n      doc.add(new NumericDocValuesField(\"field\", term));\n      w.addDocument(doc);\n    }\n\n    if (random().nextBoolean()) {\n      if (VERBOSE) System.out.println(\"TEST: now force merge\");\n      w.forceMerge(1);\n    }\n\n    IndexReader r = DirectoryReader.open(w, true);\n\n    List<Integer> sortedTerms = new ArrayList<>(terms);\n    Collections.sort(sortedTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: sorted terms:\");\n      int idx = 0;\n      for(Integer term : sortedTerms) {\n        System.out.println(idx + \": \" + term);\n        idx++;\n      }\n    }\n\n    int iters = atLeast(100);\n    for(int iter=0;iter<iters;iter++) {\n\n      int min, max;\n      while (true) {\n        min = random().nextInt();\n        max = random().nextInt();\n        if (min == max) {\n          continue;\n        } else if (min > max) {\n          int x = min;\n          min = max;\n          max = x;\n        }\n        break;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" min=\" + min + \" (\" + intToBytes(min) + \") max=\" + max + \" (\" + intToBytes(max) + \")\");\n      }\n      \n      boolean minInclusive = random().nextBoolean();\n      BytesRef minTerm = intToBytes(min);\n      boolean maxInclusive = random().nextBoolean();\n      BytesRef maxTerm = intToBytes(max);\n      CompiledAutomaton ca = new CompiledAutomaton(Automata.makeBinaryInterval(minTerm, minInclusive, maxTerm, maxInclusive),\n                                                   true, false, Integer.MAX_VALUE, true);\n\n      TermsEnum te = ca.getTermsEnum(MultiFields.getTerms(r, \"field\"));\n      NumericDocValues docValues = MultiDocValues.getNumericValues(r, \"field\");\n      PostingsEnum postingsEnum = null;\n      VerifyAutoPrefixTerms verifier = new VerifyAutoPrefixTerms(r.maxDoc(), minTerm, maxTerm);\n      while (te.next() != null) {\n        if (VERBOSE) {\n          System.out.println(\"  got term=\" + te.term() + \" docFreq=\" + te.docFreq());\n        }\n        verifier.sawTerm(te.term());        \n        postingsEnum = te.postings(postingsEnum);\n        int docID;\n        while ((docID = postingsEnum.nextDoc()) != PostingsEnum.NO_MORE_DOCS) {\n          long v = docValues.get(docID);\n          assert v >= min && v <= max: \"docID=\" + docID + \" v=\" + v;\n          verifier.sawDoc(docID);\n        }\n      }\n      \n      int startLoc = Collections.binarySearch(sortedTerms, min);\n      if (startLoc < 0) {\n        startLoc = -startLoc-1;\n      } else if (minInclusive == false) {\n        startLoc++;\n      }\n      int endLoc = Collections.binarySearch(sortedTerms, max);\n      if (endLoc < 0) {\n        endLoc = -endLoc-2;\n      } else if (maxInclusive == false) {\n        endLoc--;\n      }\n      int expectedHits = endLoc-startLoc+1;\n      try {\n        verifier.finish(expectedHits, maxTermsAutoPrefix);\n      } catch (AssertionError ae) {\n        for(int i=0;i<numTerms;i++) {\n          if (verifier.allHits.get(i) == false) {\n            int v = (int) docValues.get(i);\n            boolean accept = (v > min || (v == min && minInclusive)) &&\n              (v < max || (v == max && maxInclusive));\n            if (accept) {\n              System.out.println(\"MISSING: docID=\" + i + \" v=\" + v + \" term=\" + intToBytes(v));\n            }\n          }\n        }\n\n        throw ae;\n      }\n    }\n\n    r.close();\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Numbers are encoded in full binary (4 byte ints):\n  public void testBinaryNumericRanges() throws Exception {\n    if (VERBOSE) {\n      System.out.println(\"TEST: minItemsPerBlock=\" + minItemsPerBlock);\n      System.out.println(\"TEST: maxItemsPerBlock=\" + maxItemsPerBlock);\n      System.out.println(\"TEST: minTermsAutoPrefix=\" + minTermsAutoPrefix);\n      System.out.println(\"TEST: maxTermsAutoPrefix=\" + maxTermsAutoPrefix);\n    }\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setCodec(codec);\n    IndexWriter w = new IndexWriter(dir, iwc);\n    int numTerms = TestUtil.nextInt(random(), 3000, 50000);\n    Set<Integer> terms = new HashSet<>();\n    while (terms.size() < numTerms) {\n      terms.add(random().nextInt());\n    }\n\n    for(Integer term : terms) {\n      Document doc = new Document();\n      doc.add(new BinaryField(\"field\", intToBytes(term)));\n      doc.add(new NumericDocValuesField(\"field\", term));\n      w.addDocument(doc);\n    }\n\n    if (random().nextBoolean()) {\n      if (VERBOSE) System.out.println(\"TEST: now force merge\");\n      w.forceMerge(1);\n    }\n\n    IndexReader r = DirectoryReader.open(w, true);\n\n    List<Integer> sortedTerms = new ArrayList<>(terms);\n    Collections.sort(sortedTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: sorted terms:\");\n      int idx = 0;\n      for(Integer term : sortedTerms) {\n        System.out.println(idx + \": \" + term);\n        idx++;\n      }\n    }\n\n    int iters = atLeast(100);\n    for(int iter=0;iter<iters;iter++) {\n\n      int min, max;\n      while (true) {\n        min = random().nextInt();\n        max = random().nextInt();\n        if (min == max) {\n          continue;\n        } else if (min > max) {\n          int x = min;\n          min = max;\n          max = x;\n        }\n        break;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" min=\" + min + \" (\" + intToBytes(min) + \") max=\" + max + \" (\" + intToBytes(max) + \")\");\n      }\n      \n      boolean minInclusive = random().nextBoolean();\n      BytesRef minTerm = intToBytes(min);\n      boolean maxInclusive = random().nextBoolean();\n      BytesRef maxTerm = intToBytes(max);\n      CompiledAutomaton ca = new CompiledAutomaton(Automata.makeBinaryInterval(minTerm, minInclusive, maxTerm, maxInclusive),\n                                                   true, false, Integer.MAX_VALUE, true);\n\n      TermsEnum te = ca.getTermsEnum(MultiFields.getTerms(r, \"field\"));\n      NumericDocValues docValues = MultiDocValues.getNumericValues(r, \"field\");\n      PostingsEnum postingsEnum = null;\n      VerifyAutoPrefixTerms verifier = new VerifyAutoPrefixTerms(r.maxDoc(), minTerm, maxTerm);\n      while (te.next() != null) {\n        if (VERBOSE) {\n          System.out.println(\"  got term=\" + te.term() + \" docFreq=\" + te.docFreq());\n        }\n        verifier.sawTerm(te.term());        \n        postingsEnum = te.postings(null, postingsEnum);\n        int docID;\n        while ((docID = postingsEnum.nextDoc()) != PostingsEnum.NO_MORE_DOCS) {\n          long v = docValues.get(docID);\n          assert v >= min && v <= max: \"docID=\" + docID + \" v=\" + v;\n          verifier.sawDoc(docID);\n        }\n      }\n      \n      int startLoc = Collections.binarySearch(sortedTerms, min);\n      if (startLoc < 0) {\n        startLoc = -startLoc-1;\n      } else if (minInclusive == false) {\n        startLoc++;\n      }\n      int endLoc = Collections.binarySearch(sortedTerms, max);\n      if (endLoc < 0) {\n        endLoc = -endLoc-2;\n      } else if (maxInclusive == false) {\n        endLoc--;\n      }\n      int expectedHits = endLoc-startLoc+1;\n      try {\n        verifier.finish(expectedHits, maxTermsAutoPrefix);\n      } catch (AssertionError ae) {\n        for(int i=0;i<numTerms;i++) {\n          if (verifier.allHits.get(i) == false) {\n            int v = (int) docValues.get(i);\n            boolean accept = (v > min || (v == min && minInclusive)) &&\n              (v < max || (v == max && maxInclusive));\n            if (accept) {\n              System.out.println(\"MISSING: docID=\" + i + \" v=\" + v + \" term=\" + intToBytes(v));\n            }\n          }\n        }\n\n        throw ae;\n      }\n    }\n\n    r.close();\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"804b857d1066ab5185b3b9101bde41b0b71426ec","date":1435846169,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/codecs/src/test/org/apache/lucene/codecs/autoprefix/TestAutoPrefixTerms#testBinaryNumericRanges().mjava","pathOld":"lucene/codecs/src/test/org/apache/lucene/codecs/autoprefix/TestAutoPrefixTerms#testBinaryNumericRanges().mjava","sourceNew":"  // Numbers are encoded in full binary (4 byte ints):\n  public void testBinaryNumericRanges() throws Exception {\n    if (VERBOSE) {\n      System.out.println(\"TEST: minItemsPerBlock=\" + minItemsPerBlock);\n      System.out.println(\"TEST: maxItemsPerBlock=\" + maxItemsPerBlock);\n      System.out.println(\"TEST: minTermsAutoPrefix=\" + minTermsAutoPrefix);\n      System.out.println(\"TEST: maxTermsAutoPrefix=\" + maxTermsAutoPrefix);\n    }\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setCodec(codec);\n    IndexWriter w = new IndexWriter(dir, iwc);\n    int numTerms = TestUtil.nextInt(random(), 3000, 50000);\n    Set<Integer> terms = new HashSet<>();\n    while (terms.size() < numTerms) {\n      terms.add(random().nextInt());\n    }\n\n    for(Integer term : terms) {\n      Document doc = new Document();\n      doc.add(newStringField(\"field\", intToBytes(term), Field.Store.NO));\n      doc.add(new NumericDocValuesField(\"field\", term));\n      w.addDocument(doc);\n    }\n\n    if (random().nextBoolean()) {\n      if (VERBOSE) System.out.println(\"TEST: now force merge\");\n      w.forceMerge(1);\n    }\n\n    IndexReader r = DirectoryReader.open(w, true);\n\n    List<Integer> sortedTerms = new ArrayList<>(terms);\n    Collections.sort(sortedTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: sorted terms:\");\n      int idx = 0;\n      for(Integer term : sortedTerms) {\n        System.out.println(idx + \": \" + term);\n        idx++;\n      }\n    }\n\n    int iters = atLeast(100);\n    for(int iter=0;iter<iters;iter++) {\n\n      int min, max;\n      while (true) {\n        min = random().nextInt();\n        max = random().nextInt();\n        if (min == max) {\n          continue;\n        } else if (min > max) {\n          int x = min;\n          min = max;\n          max = x;\n        }\n        break;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" min=\" + min + \" (\" + intToBytes(min) + \") max=\" + max + \" (\" + intToBytes(max) + \")\");\n      }\n      \n      boolean minInclusive = random().nextBoolean();\n      BytesRef minTerm = intToBytes(min);\n      boolean maxInclusive = random().nextBoolean();\n      BytesRef maxTerm = intToBytes(max);\n      CompiledAutomaton ca = new CompiledAutomaton(Automata.makeBinaryInterval(minTerm, minInclusive, maxTerm, maxInclusive),\n                                                   true, false, Integer.MAX_VALUE, true);\n\n      TermsEnum te = ca.getTermsEnum(MultiFields.getTerms(r, \"field\"));\n      NumericDocValues docValues = MultiDocValues.getNumericValues(r, \"field\");\n      PostingsEnum postingsEnum = null;\n      VerifyAutoPrefixTerms verifier = new VerifyAutoPrefixTerms(r.maxDoc(), minTerm, maxTerm);\n      while (te.next() != null) {\n        if (VERBOSE) {\n          System.out.println(\"  got term=\" + te.term() + \" docFreq=\" + te.docFreq());\n        }\n        verifier.sawTerm(te.term());        \n        postingsEnum = te.postings(postingsEnum);\n        int docID;\n        while ((docID = postingsEnum.nextDoc()) != PostingsEnum.NO_MORE_DOCS) {\n          long v = docValues.get(docID);\n          assert v >= min && v <= max: \"docID=\" + docID + \" v=\" + v;\n          verifier.sawDoc(docID);\n        }\n      }\n      \n      int startLoc = Collections.binarySearch(sortedTerms, min);\n      if (startLoc < 0) {\n        startLoc = -startLoc-1;\n      } else if (minInclusive == false) {\n        startLoc++;\n      }\n      int endLoc = Collections.binarySearch(sortedTerms, max);\n      if (endLoc < 0) {\n        endLoc = -endLoc-2;\n      } else if (maxInclusive == false) {\n        endLoc--;\n      }\n      int expectedHits = endLoc-startLoc+1;\n      try {\n        verifier.finish(expectedHits, maxTermsAutoPrefix);\n      } catch (AssertionError ae) {\n        for(int i=0;i<numTerms;i++) {\n          if (verifier.allHits.get(i) == false) {\n            int v = (int) docValues.get(i);\n            boolean accept = (v > min || (v == min && minInclusive)) &&\n              (v < max || (v == max && maxInclusive));\n            if (accept) {\n              System.out.println(\"MISSING: docID=\" + i + \" v=\" + v + \" term=\" + intToBytes(v));\n            }\n          }\n        }\n\n        throw ae;\n      }\n    }\n\n    r.close();\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Numbers are encoded in full binary (4 byte ints):\n  public void testBinaryNumericRanges() throws Exception {\n    if (VERBOSE) {\n      System.out.println(\"TEST: minItemsPerBlock=\" + minItemsPerBlock);\n      System.out.println(\"TEST: maxItemsPerBlock=\" + maxItemsPerBlock);\n      System.out.println(\"TEST: minTermsAutoPrefix=\" + minTermsAutoPrefix);\n      System.out.println(\"TEST: maxTermsAutoPrefix=\" + maxTermsAutoPrefix);\n    }\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setCodec(codec);\n    IndexWriter w = new IndexWriter(dir, iwc);\n    int numTerms = TestUtil.nextInt(random(), 3000, 50000);\n    Set<Integer> terms = new HashSet<>();\n    while (terms.size() < numTerms) {\n      terms.add(random().nextInt());\n    }\n\n    for(Integer term : terms) {\n      Document doc = new Document();\n      doc.add(new BinaryField(\"field\", intToBytes(term)));\n      doc.add(new NumericDocValuesField(\"field\", term));\n      w.addDocument(doc);\n    }\n\n    if (random().nextBoolean()) {\n      if (VERBOSE) System.out.println(\"TEST: now force merge\");\n      w.forceMerge(1);\n    }\n\n    IndexReader r = DirectoryReader.open(w, true);\n\n    List<Integer> sortedTerms = new ArrayList<>(terms);\n    Collections.sort(sortedTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: sorted terms:\");\n      int idx = 0;\n      for(Integer term : sortedTerms) {\n        System.out.println(idx + \": \" + term);\n        idx++;\n      }\n    }\n\n    int iters = atLeast(100);\n    for(int iter=0;iter<iters;iter++) {\n\n      int min, max;\n      while (true) {\n        min = random().nextInt();\n        max = random().nextInt();\n        if (min == max) {\n          continue;\n        } else if (min > max) {\n          int x = min;\n          min = max;\n          max = x;\n        }\n        break;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" min=\" + min + \" (\" + intToBytes(min) + \") max=\" + max + \" (\" + intToBytes(max) + \")\");\n      }\n      \n      boolean minInclusive = random().nextBoolean();\n      BytesRef minTerm = intToBytes(min);\n      boolean maxInclusive = random().nextBoolean();\n      BytesRef maxTerm = intToBytes(max);\n      CompiledAutomaton ca = new CompiledAutomaton(Automata.makeBinaryInterval(minTerm, minInclusive, maxTerm, maxInclusive),\n                                                   true, false, Integer.MAX_VALUE, true);\n\n      TermsEnum te = ca.getTermsEnum(MultiFields.getTerms(r, \"field\"));\n      NumericDocValues docValues = MultiDocValues.getNumericValues(r, \"field\");\n      PostingsEnum postingsEnum = null;\n      VerifyAutoPrefixTerms verifier = new VerifyAutoPrefixTerms(r.maxDoc(), minTerm, maxTerm);\n      while (te.next() != null) {\n        if (VERBOSE) {\n          System.out.println(\"  got term=\" + te.term() + \" docFreq=\" + te.docFreq());\n        }\n        verifier.sawTerm(te.term());        \n        postingsEnum = te.postings(postingsEnum);\n        int docID;\n        while ((docID = postingsEnum.nextDoc()) != PostingsEnum.NO_MORE_DOCS) {\n          long v = docValues.get(docID);\n          assert v >= min && v <= max: \"docID=\" + docID + \" v=\" + v;\n          verifier.sawDoc(docID);\n        }\n      }\n      \n      int startLoc = Collections.binarySearch(sortedTerms, min);\n      if (startLoc < 0) {\n        startLoc = -startLoc-1;\n      } else if (minInclusive == false) {\n        startLoc++;\n      }\n      int endLoc = Collections.binarySearch(sortedTerms, max);\n      if (endLoc < 0) {\n        endLoc = -endLoc-2;\n      } else if (maxInclusive == false) {\n        endLoc--;\n      }\n      int expectedHits = endLoc-startLoc+1;\n      try {\n        verifier.finish(expectedHits, maxTermsAutoPrefix);\n      } catch (AssertionError ae) {\n        for(int i=0;i<numTerms;i++) {\n          if (verifier.allHits.get(i) == false) {\n            int v = (int) docValues.get(i);\n            boolean accept = (v > min || (v == min && minInclusive)) &&\n              (v < max || (v == max && maxInclusive));\n            if (accept) {\n              System.out.println(\"MISSING: docID=\" + i + \" v=\" + v + \" term=\" + intToBytes(v));\n            }\n          }\n        }\n\n        throw ae;\n      }\n    }\n\n    r.close();\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2a1862266772deb28cdcb7d996b64d2177022687","date":1453077824,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/codecs/src/test/org/apache/lucene/codecs/autoprefix/TestAutoPrefixTerms#testBinaryNumericRanges().mjava","pathOld":"lucene/codecs/src/test/org/apache/lucene/codecs/autoprefix/TestAutoPrefixTerms#testBinaryNumericRanges().mjava","sourceNew":"  // Numbers are encoded in full binary (4 byte ints):\n  public void testBinaryNumericRanges() throws Exception {\n    if (VERBOSE) {\n      System.out.println(\"TEST: minItemsPerBlock=\" + minItemsPerBlock);\n      System.out.println(\"TEST: maxItemsPerBlock=\" + maxItemsPerBlock);\n      System.out.println(\"TEST: minTermsAutoPrefix=\" + minTermsAutoPrefix);\n      System.out.println(\"TEST: maxTermsAutoPrefix=\" + maxTermsAutoPrefix);\n    }\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setCodec(codec);\n    IndexWriter w = new IndexWriter(dir, iwc);\n    int numTerms = TestUtil.nextInt(random(), 3000, 50000);\n    Set<Integer> terms = new HashSet<>();\n    while (terms.size() < numTerms) {\n      terms.add(random().nextInt());\n    }\n\n    for(Integer term : terms) {\n      Document doc = new Document();\n      doc.add(newStringField(\"field\", intToBytes(term), Field.Store.NO));\n      doc.add(new NumericDocValuesField(\"field\", term));\n      w.addDocument(doc);\n    }\n\n    if (random().nextBoolean()) {\n      if (VERBOSE) System.out.println(\"TEST: now force merge\");\n      w.forceMerge(1);\n    }\n\n    IndexReader r = DirectoryReader.open(w);\n\n    List<Integer> sortedTerms = new ArrayList<>(terms);\n    Collections.sort(sortedTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: sorted terms:\");\n      int idx = 0;\n      for(Integer term : sortedTerms) {\n        System.out.println(idx + \": \" + term);\n        idx++;\n      }\n    }\n\n    int iters = atLeast(100);\n    for(int iter=0;iter<iters;iter++) {\n\n      int min, max;\n      while (true) {\n        min = random().nextInt();\n        max = random().nextInt();\n        if (min == max) {\n          continue;\n        } else if (min > max) {\n          int x = min;\n          min = max;\n          max = x;\n        }\n        break;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" min=\" + min + \" (\" + intToBytes(min) + \") max=\" + max + \" (\" + intToBytes(max) + \")\");\n      }\n      \n      boolean minInclusive = random().nextBoolean();\n      BytesRef minTerm = intToBytes(min);\n      boolean maxInclusive = random().nextBoolean();\n      BytesRef maxTerm = intToBytes(max);\n      CompiledAutomaton ca = new CompiledAutomaton(Automata.makeBinaryInterval(minTerm, minInclusive, maxTerm, maxInclusive),\n                                                   true, false, Integer.MAX_VALUE, true);\n\n      TermsEnum te = ca.getTermsEnum(MultiFields.getTerms(r, \"field\"));\n      NumericDocValues docValues = MultiDocValues.getNumericValues(r, \"field\");\n      PostingsEnum postingsEnum = null;\n      VerifyAutoPrefixTerms verifier = new VerifyAutoPrefixTerms(r.maxDoc(), minTerm, maxTerm);\n      while (te.next() != null) {\n        if (VERBOSE) {\n          System.out.println(\"  got term=\" + te.term() + \" docFreq=\" + te.docFreq());\n        }\n        verifier.sawTerm(te.term());        \n        postingsEnum = te.postings(postingsEnum);\n        int docID;\n        while ((docID = postingsEnum.nextDoc()) != PostingsEnum.NO_MORE_DOCS) {\n          long v = docValues.get(docID);\n          assert v >= min && v <= max: \"docID=\" + docID + \" v=\" + v;\n          verifier.sawDoc(docID);\n        }\n      }\n      \n      int startLoc = Collections.binarySearch(sortedTerms, min);\n      if (startLoc < 0) {\n        startLoc = -startLoc-1;\n      } else if (minInclusive == false) {\n        startLoc++;\n      }\n      int endLoc = Collections.binarySearch(sortedTerms, max);\n      if (endLoc < 0) {\n        endLoc = -endLoc-2;\n      } else if (maxInclusive == false) {\n        endLoc--;\n      }\n      int expectedHits = endLoc-startLoc+1;\n      try {\n        verifier.finish(expectedHits, maxTermsAutoPrefix);\n      } catch (AssertionError ae) {\n        for(int i=0;i<numTerms;i++) {\n          if (verifier.allHits.get(i) == false) {\n            int v = (int) docValues.get(i);\n            boolean accept = (v > min || (v == min && minInclusive)) &&\n              (v < max || (v == max && maxInclusive));\n            if (accept) {\n              System.out.println(\"MISSING: docID=\" + i + \" v=\" + v + \" term=\" + intToBytes(v));\n            }\n          }\n        }\n\n        throw ae;\n      }\n    }\n\n    r.close();\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Numbers are encoded in full binary (4 byte ints):\n  public void testBinaryNumericRanges() throws Exception {\n    if (VERBOSE) {\n      System.out.println(\"TEST: minItemsPerBlock=\" + minItemsPerBlock);\n      System.out.println(\"TEST: maxItemsPerBlock=\" + maxItemsPerBlock);\n      System.out.println(\"TEST: minTermsAutoPrefix=\" + minTermsAutoPrefix);\n      System.out.println(\"TEST: maxTermsAutoPrefix=\" + maxTermsAutoPrefix);\n    }\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setCodec(codec);\n    IndexWriter w = new IndexWriter(dir, iwc);\n    int numTerms = TestUtil.nextInt(random(), 3000, 50000);\n    Set<Integer> terms = new HashSet<>();\n    while (terms.size() < numTerms) {\n      terms.add(random().nextInt());\n    }\n\n    for(Integer term : terms) {\n      Document doc = new Document();\n      doc.add(newStringField(\"field\", intToBytes(term), Field.Store.NO));\n      doc.add(new NumericDocValuesField(\"field\", term));\n      w.addDocument(doc);\n    }\n\n    if (random().nextBoolean()) {\n      if (VERBOSE) System.out.println(\"TEST: now force merge\");\n      w.forceMerge(1);\n    }\n\n    IndexReader r = DirectoryReader.open(w, true);\n\n    List<Integer> sortedTerms = new ArrayList<>(terms);\n    Collections.sort(sortedTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: sorted terms:\");\n      int idx = 0;\n      for(Integer term : sortedTerms) {\n        System.out.println(idx + \": \" + term);\n        idx++;\n      }\n    }\n\n    int iters = atLeast(100);\n    for(int iter=0;iter<iters;iter++) {\n\n      int min, max;\n      while (true) {\n        min = random().nextInt();\n        max = random().nextInt();\n        if (min == max) {\n          continue;\n        } else if (min > max) {\n          int x = min;\n          min = max;\n          max = x;\n        }\n        break;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" min=\" + min + \" (\" + intToBytes(min) + \") max=\" + max + \" (\" + intToBytes(max) + \")\");\n      }\n      \n      boolean minInclusive = random().nextBoolean();\n      BytesRef minTerm = intToBytes(min);\n      boolean maxInclusive = random().nextBoolean();\n      BytesRef maxTerm = intToBytes(max);\n      CompiledAutomaton ca = new CompiledAutomaton(Automata.makeBinaryInterval(minTerm, minInclusive, maxTerm, maxInclusive),\n                                                   true, false, Integer.MAX_VALUE, true);\n\n      TermsEnum te = ca.getTermsEnum(MultiFields.getTerms(r, \"field\"));\n      NumericDocValues docValues = MultiDocValues.getNumericValues(r, \"field\");\n      PostingsEnum postingsEnum = null;\n      VerifyAutoPrefixTerms verifier = new VerifyAutoPrefixTerms(r.maxDoc(), minTerm, maxTerm);\n      while (te.next() != null) {\n        if (VERBOSE) {\n          System.out.println(\"  got term=\" + te.term() + \" docFreq=\" + te.docFreq());\n        }\n        verifier.sawTerm(te.term());        \n        postingsEnum = te.postings(postingsEnum);\n        int docID;\n        while ((docID = postingsEnum.nextDoc()) != PostingsEnum.NO_MORE_DOCS) {\n          long v = docValues.get(docID);\n          assert v >= min && v <= max: \"docID=\" + docID + \" v=\" + v;\n          verifier.sawDoc(docID);\n        }\n      }\n      \n      int startLoc = Collections.binarySearch(sortedTerms, min);\n      if (startLoc < 0) {\n        startLoc = -startLoc-1;\n      } else if (minInclusive == false) {\n        startLoc++;\n      }\n      int endLoc = Collections.binarySearch(sortedTerms, max);\n      if (endLoc < 0) {\n        endLoc = -endLoc-2;\n      } else if (maxInclusive == false) {\n        endLoc--;\n      }\n      int expectedHits = endLoc-startLoc+1;\n      try {\n        verifier.finish(expectedHits, maxTermsAutoPrefix);\n      } catch (AssertionError ae) {\n        for(int i=0;i<numTerms;i++) {\n          if (verifier.allHits.get(i) == false) {\n            int v = (int) docValues.get(i);\n            boolean accept = (v > min || (v == min && minInclusive)) &&\n              (v < max || (v == max && maxInclusive));\n            if (accept) {\n              System.out.println(\"MISSING: docID=\" + i + \" v=\" + v + \" term=\" + intToBytes(v));\n            }\n          }\n        }\n\n        throw ae;\n      }\n    }\n\n    r.close();\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"25b8a027ba57951e63075a2ae9647c5c4a8c5c5f","date":1466407389,"type":4,"author":"Adrien Grand","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/codecs/src/test/org/apache/lucene/codecs/autoprefix/TestAutoPrefixTerms#testBinaryNumericRanges().mjava","sourceNew":null,"sourceOld":"  // Numbers are encoded in full binary (4 byte ints):\n  public void testBinaryNumericRanges() throws Exception {\n    if (VERBOSE) {\n      System.out.println(\"TEST: minItemsPerBlock=\" + minItemsPerBlock);\n      System.out.println(\"TEST: maxItemsPerBlock=\" + maxItemsPerBlock);\n      System.out.println(\"TEST: minTermsAutoPrefix=\" + minTermsAutoPrefix);\n      System.out.println(\"TEST: maxTermsAutoPrefix=\" + maxTermsAutoPrefix);\n    }\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setCodec(codec);\n    IndexWriter w = new IndexWriter(dir, iwc);\n    int numTerms = TestUtil.nextInt(random(), 3000, 50000);\n    Set<Integer> terms = new HashSet<>();\n    while (terms.size() < numTerms) {\n      terms.add(random().nextInt());\n    }\n\n    for(Integer term : terms) {\n      Document doc = new Document();\n      doc.add(newStringField(\"field\", intToBytes(term), Field.Store.NO));\n      doc.add(new NumericDocValuesField(\"field\", term));\n      w.addDocument(doc);\n    }\n\n    if (random().nextBoolean()) {\n      if (VERBOSE) System.out.println(\"TEST: now force merge\");\n      w.forceMerge(1);\n    }\n\n    IndexReader r = DirectoryReader.open(w);\n\n    List<Integer> sortedTerms = new ArrayList<>(terms);\n    Collections.sort(sortedTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: sorted terms:\");\n      int idx = 0;\n      for(Integer term : sortedTerms) {\n        System.out.println(idx + \": \" + term);\n        idx++;\n      }\n    }\n\n    int iters = atLeast(100);\n    for(int iter=0;iter<iters;iter++) {\n\n      int min, max;\n      while (true) {\n        min = random().nextInt();\n        max = random().nextInt();\n        if (min == max) {\n          continue;\n        } else if (min > max) {\n          int x = min;\n          min = max;\n          max = x;\n        }\n        break;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" min=\" + min + \" (\" + intToBytes(min) + \") max=\" + max + \" (\" + intToBytes(max) + \")\");\n      }\n      \n      boolean minInclusive = random().nextBoolean();\n      BytesRef minTerm = intToBytes(min);\n      boolean maxInclusive = random().nextBoolean();\n      BytesRef maxTerm = intToBytes(max);\n      CompiledAutomaton ca = new CompiledAutomaton(Automata.makeBinaryInterval(minTerm, minInclusive, maxTerm, maxInclusive),\n                                                   true, false, Integer.MAX_VALUE, true);\n\n      TermsEnum te = ca.getTermsEnum(MultiFields.getTerms(r, \"field\"));\n      NumericDocValues docValues = MultiDocValues.getNumericValues(r, \"field\");\n      PostingsEnum postingsEnum = null;\n      VerifyAutoPrefixTerms verifier = new VerifyAutoPrefixTerms(r.maxDoc(), minTerm, maxTerm);\n      while (te.next() != null) {\n        if (VERBOSE) {\n          System.out.println(\"  got term=\" + te.term() + \" docFreq=\" + te.docFreq());\n        }\n        verifier.sawTerm(te.term());        \n        postingsEnum = te.postings(postingsEnum);\n        int docID;\n        while ((docID = postingsEnum.nextDoc()) != PostingsEnum.NO_MORE_DOCS) {\n          long v = docValues.get(docID);\n          assert v >= min && v <= max: \"docID=\" + docID + \" v=\" + v;\n          verifier.sawDoc(docID);\n        }\n      }\n      \n      int startLoc = Collections.binarySearch(sortedTerms, min);\n      if (startLoc < 0) {\n        startLoc = -startLoc-1;\n      } else if (minInclusive == false) {\n        startLoc++;\n      }\n      int endLoc = Collections.binarySearch(sortedTerms, max);\n      if (endLoc < 0) {\n        endLoc = -endLoc-2;\n      } else if (maxInclusive == false) {\n        endLoc--;\n      }\n      int expectedHits = endLoc-startLoc+1;\n      try {\n        verifier.finish(expectedHits, maxTermsAutoPrefix);\n      } catch (AssertionError ae) {\n        for(int i=0;i<numTerms;i++) {\n          if (verifier.allHits.get(i) == false) {\n            int v = (int) docValues.get(i);\n            boolean accept = (v > min || (v == min && minInclusive)) &&\n              (v < max || (v == max && maxInclusive));\n            if (accept) {\n              System.out.println(\"MISSING: docID=\" + i + \" v=\" + v + \" term=\" + intToBytes(v));\n            }\n          }\n        }\n\n        throw ae;\n      }\n    }\n\n    r.close();\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6aaba221b22442bdf0ef28770c25fe259dfb3f55","date":1466496193,"type":4,"author":"Noble Paul","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/codecs/src/test/org/apache/lucene/codecs/autoprefix/TestAutoPrefixTerms#testBinaryNumericRanges().mjava","sourceNew":null,"sourceOld":"  // Numbers are encoded in full binary (4 byte ints):\n  public void testBinaryNumericRanges() throws Exception {\n    if (VERBOSE) {\n      System.out.println(\"TEST: minItemsPerBlock=\" + minItemsPerBlock);\n      System.out.println(\"TEST: maxItemsPerBlock=\" + maxItemsPerBlock);\n      System.out.println(\"TEST: minTermsAutoPrefix=\" + minTermsAutoPrefix);\n      System.out.println(\"TEST: maxTermsAutoPrefix=\" + maxTermsAutoPrefix);\n    }\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setCodec(codec);\n    IndexWriter w = new IndexWriter(dir, iwc);\n    int numTerms = TestUtil.nextInt(random(), 3000, 50000);\n    Set<Integer> terms = new HashSet<>();\n    while (terms.size() < numTerms) {\n      terms.add(random().nextInt());\n    }\n\n    for(Integer term : terms) {\n      Document doc = new Document();\n      doc.add(newStringField(\"field\", intToBytes(term), Field.Store.NO));\n      doc.add(new NumericDocValuesField(\"field\", term));\n      w.addDocument(doc);\n    }\n\n    if (random().nextBoolean()) {\n      if (VERBOSE) System.out.println(\"TEST: now force merge\");\n      w.forceMerge(1);\n    }\n\n    IndexReader r = DirectoryReader.open(w);\n\n    List<Integer> sortedTerms = new ArrayList<>(terms);\n    Collections.sort(sortedTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: sorted terms:\");\n      int idx = 0;\n      for(Integer term : sortedTerms) {\n        System.out.println(idx + \": \" + term);\n        idx++;\n      }\n    }\n\n    int iters = atLeast(100);\n    for(int iter=0;iter<iters;iter++) {\n\n      int min, max;\n      while (true) {\n        min = random().nextInt();\n        max = random().nextInt();\n        if (min == max) {\n          continue;\n        } else if (min > max) {\n          int x = min;\n          min = max;\n          max = x;\n        }\n        break;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" min=\" + min + \" (\" + intToBytes(min) + \") max=\" + max + \" (\" + intToBytes(max) + \")\");\n      }\n      \n      boolean minInclusive = random().nextBoolean();\n      BytesRef minTerm = intToBytes(min);\n      boolean maxInclusive = random().nextBoolean();\n      BytesRef maxTerm = intToBytes(max);\n      CompiledAutomaton ca = new CompiledAutomaton(Automata.makeBinaryInterval(minTerm, minInclusive, maxTerm, maxInclusive),\n                                                   true, false, Integer.MAX_VALUE, true);\n\n      TermsEnum te = ca.getTermsEnum(MultiFields.getTerms(r, \"field\"));\n      NumericDocValues docValues = MultiDocValues.getNumericValues(r, \"field\");\n      PostingsEnum postingsEnum = null;\n      VerifyAutoPrefixTerms verifier = new VerifyAutoPrefixTerms(r.maxDoc(), minTerm, maxTerm);\n      while (te.next() != null) {\n        if (VERBOSE) {\n          System.out.println(\"  got term=\" + te.term() + \" docFreq=\" + te.docFreq());\n        }\n        verifier.sawTerm(te.term());        \n        postingsEnum = te.postings(postingsEnum);\n        int docID;\n        while ((docID = postingsEnum.nextDoc()) != PostingsEnum.NO_MORE_DOCS) {\n          long v = docValues.get(docID);\n          assert v >= min && v <= max: \"docID=\" + docID + \" v=\" + v;\n          verifier.sawDoc(docID);\n        }\n      }\n      \n      int startLoc = Collections.binarySearch(sortedTerms, min);\n      if (startLoc < 0) {\n        startLoc = -startLoc-1;\n      } else if (minInclusive == false) {\n        startLoc++;\n      }\n      int endLoc = Collections.binarySearch(sortedTerms, max);\n      if (endLoc < 0) {\n        endLoc = -endLoc-2;\n      } else if (maxInclusive == false) {\n        endLoc--;\n      }\n      int expectedHits = endLoc-startLoc+1;\n      try {\n        verifier.finish(expectedHits, maxTermsAutoPrefix);\n      } catch (AssertionError ae) {\n        for(int i=0;i<numTerms;i++) {\n          if (verifier.allHits.get(i) == false) {\n            int v = (int) docValues.get(i);\n            boolean accept = (v > min || (v == min && minInclusive)) &&\n              (v < max || (v == max && maxInclusive));\n            if (accept) {\n              System.out.println(\"MISSING: docID=\" + i + \" v=\" + v + \" term=\" + intToBytes(v));\n            }\n          }\n        }\n\n        throw ae;\n      }\n    }\n\n    r.close();\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":4,"author":"Kevin Risden","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/codecs/src/test/org/apache/lucene/codecs/autoprefix/TestAutoPrefixTerms#testBinaryNumericRanges().mjava","sourceNew":null,"sourceOld":"  // Numbers are encoded in full binary (4 byte ints):\n  public void testBinaryNumericRanges() throws Exception {\n    if (VERBOSE) {\n      System.out.println(\"TEST: minItemsPerBlock=\" + minItemsPerBlock);\n      System.out.println(\"TEST: maxItemsPerBlock=\" + maxItemsPerBlock);\n      System.out.println(\"TEST: minTermsAutoPrefix=\" + minTermsAutoPrefix);\n      System.out.println(\"TEST: maxTermsAutoPrefix=\" + maxTermsAutoPrefix);\n    }\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setCodec(codec);\n    IndexWriter w = new IndexWriter(dir, iwc);\n    int numTerms = TestUtil.nextInt(random(), 3000, 50000);\n    Set<Integer> terms = new HashSet<>();\n    while (terms.size() < numTerms) {\n      terms.add(random().nextInt());\n    }\n\n    for(Integer term : terms) {\n      Document doc = new Document();\n      doc.add(newStringField(\"field\", intToBytes(term), Field.Store.NO));\n      doc.add(new NumericDocValuesField(\"field\", term));\n      w.addDocument(doc);\n    }\n\n    if (random().nextBoolean()) {\n      if (VERBOSE) System.out.println(\"TEST: now force merge\");\n      w.forceMerge(1);\n    }\n\n    IndexReader r = DirectoryReader.open(w);\n\n    List<Integer> sortedTerms = new ArrayList<>(terms);\n    Collections.sort(sortedTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: sorted terms:\");\n      int idx = 0;\n      for(Integer term : sortedTerms) {\n        System.out.println(idx + \": \" + term);\n        idx++;\n      }\n    }\n\n    int iters = atLeast(100);\n    for(int iter=0;iter<iters;iter++) {\n\n      int min, max;\n      while (true) {\n        min = random().nextInt();\n        max = random().nextInt();\n        if (min == max) {\n          continue;\n        } else if (min > max) {\n          int x = min;\n          min = max;\n          max = x;\n        }\n        break;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" min=\" + min + \" (\" + intToBytes(min) + \") max=\" + max + \" (\" + intToBytes(max) + \")\");\n      }\n      \n      boolean minInclusive = random().nextBoolean();\n      BytesRef minTerm = intToBytes(min);\n      boolean maxInclusive = random().nextBoolean();\n      BytesRef maxTerm = intToBytes(max);\n      CompiledAutomaton ca = new CompiledAutomaton(Automata.makeBinaryInterval(minTerm, minInclusive, maxTerm, maxInclusive),\n                                                   true, false, Integer.MAX_VALUE, true);\n\n      TermsEnum te = ca.getTermsEnum(MultiFields.getTerms(r, \"field\"));\n      NumericDocValues docValues = MultiDocValues.getNumericValues(r, \"field\");\n      PostingsEnum postingsEnum = null;\n      VerifyAutoPrefixTerms verifier = new VerifyAutoPrefixTerms(r.maxDoc(), minTerm, maxTerm);\n      while (te.next() != null) {\n        if (VERBOSE) {\n          System.out.println(\"  got term=\" + te.term() + \" docFreq=\" + te.docFreq());\n        }\n        verifier.sawTerm(te.term());        \n        postingsEnum = te.postings(postingsEnum);\n        int docID;\n        while ((docID = postingsEnum.nextDoc()) != PostingsEnum.NO_MORE_DOCS) {\n          long v = docValues.get(docID);\n          assert v >= min && v <= max: \"docID=\" + docID + \" v=\" + v;\n          verifier.sawDoc(docID);\n        }\n      }\n      \n      int startLoc = Collections.binarySearch(sortedTerms, min);\n      if (startLoc < 0) {\n        startLoc = -startLoc-1;\n      } else if (minInclusive == false) {\n        startLoc++;\n      }\n      int endLoc = Collections.binarySearch(sortedTerms, max);\n      if (endLoc < 0) {\n        endLoc = -endLoc-2;\n      } else if (maxInclusive == false) {\n        endLoc--;\n      }\n      int expectedHits = endLoc-startLoc+1;\n      try {\n        verifier.finish(expectedHits, maxTermsAutoPrefix);\n      } catch (AssertionError ae) {\n        for(int i=0;i<numTerms;i++) {\n          if (verifier.allHits.get(i) == false) {\n            int v = (int) docValues.get(i);\n            boolean accept = (v > min || (v == min && minInclusive)) &&\n              (v < max || (v == max && maxInclusive));\n            if (accept) {\n              System.out.println(\"MISSING: docID=\" + i + \" v=\" + v + \" term=\" + intToBytes(v));\n            }\n          }\n        }\n\n        throw ae;\n      }\n    }\n\n    r.close();\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"804b857d1066ab5185b3b9101bde41b0b71426ec":["0f4464508ee83288c8c4585b533f9faaa93aa314"],"0f4464508ee83288c8c4585b533f9faaa93aa314":["3e8715d826e588419327562287d5d6a8040d63d6"],"2a1862266772deb28cdcb7d996b64d2177022687":["804b857d1066ab5185b3b9101bde41b0b71426ec"],"6aaba221b22442bdf0ef28770c25fe259dfb3f55":["2a1862266772deb28cdcb7d996b64d2177022687","25b8a027ba57951e63075a2ae9647c5c4a8c5c5f"],"25b8a027ba57951e63075a2ae9647c5c4a8c5c5f":["2a1862266772deb28cdcb7d996b64d2177022687"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d2638f781be724518ff6c2263d14a48cf6e68017":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","3e8715d826e588419327562287d5d6a8040d63d6"],"3e8715d826e588419327562287d5d6a8040d63d6":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["2a1862266772deb28cdcb7d996b64d2177022687","6aaba221b22442bdf0ef28770c25fe259dfb3f55"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["6aaba221b22442bdf0ef28770c25fe259dfb3f55"]},"commit2Childs":{"804b857d1066ab5185b3b9101bde41b0b71426ec":["2a1862266772deb28cdcb7d996b64d2177022687"],"0f4464508ee83288c8c4585b533f9faaa93aa314":["804b857d1066ab5185b3b9101bde41b0b71426ec"],"2a1862266772deb28cdcb7d996b64d2177022687":["6aaba221b22442bdf0ef28770c25fe259dfb3f55","25b8a027ba57951e63075a2ae9647c5c4a8c5c5f","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"6aaba221b22442bdf0ef28770c25fe259dfb3f55":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"25b8a027ba57951e63075a2ae9647c5c4a8c5c5f":["6aaba221b22442bdf0ef28770c25fe259dfb3f55"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["d2638f781be724518ff6c2263d14a48cf6e68017","3e8715d826e588419327562287d5d6a8040d63d6"],"d2638f781be724518ff6c2263d14a48cf6e68017":[],"3e8715d826e588419327562287d5d6a8040d63d6":["0f4464508ee83288c8c4585b533f9faaa93aa314","d2638f781be724518ff6c2263d14a48cf6e68017"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["d2638f781be724518ff6c2263d14a48cf6e68017","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}