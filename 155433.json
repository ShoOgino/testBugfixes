{"path":"solr/core/src/test/org/apache/solr/cloud/MoveReplicaHDFSFailoverTest#testDataDirAndUlogAreMaintained().mjava","commits":[{"id":"717e5ceb2acae36d422ec75e5a4ce9fac40506e1","date":1501239603,"type":1,"author":"Cao Manh Dat","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/MoveReplicaHDFSFailoverTest#testDataDirAndUlogAreMaintained().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/MoveReplicaHDFSUlogDirTest#testDataDirAndUlogAreMaintained().mjava","sourceNew":"  @Test\n  public void testDataDirAndUlogAreMaintained() throws Exception {\n    String coll = \"movereplicatest_coll2\";\n    CollectionAdminRequest.createCollection(coll, \"conf1\", 1, 1)\n        .setCreateNodeSet(\"\")\n        .process(cluster.getSolrClient());\n    String hdfsUri = HdfsTestUtil.getURI(dfsCluster);\n    String dataDir = hdfsUri + \"/dummyFolder/dataDir\";\n    String ulogDir = hdfsUri + \"/dummyFolder2/ulogDir\";\n    CollectionAdminResponse res = CollectionAdminRequest\n        .addReplicaToShard(coll, \"shard1\")\n        .setDataDir(dataDir)\n        .setUlogDir(ulogDir)\n        .setNode(cluster.getJettySolrRunner(0).getNodeName())\n        .process(cluster.getSolrClient());\n\n    ulogDir += \"/tlog\";\n    ZkStateReader zkStateReader = cluster.getSolrClient().getZkStateReader();\n    assertTrue(ClusterStateUtil.waitForAllActiveAndLiveReplicas(zkStateReader, 120000));\n\n    DocCollection docCollection = zkStateReader.getClusterState().getCollection(coll);\n    Replica replica = docCollection.getReplicas().iterator().next();\n    assertTrue(replica.getStr(\"ulogDir\"), replica.getStr(\"ulogDir\").equals(ulogDir) || replica.getStr(\"ulogDir\").equals(ulogDir+'/'));\n    assertTrue(replica.getStr(\"dataDir\"),replica.getStr(\"dataDir\").equals(dataDir) || replica.getStr(\"dataDir\").equals(dataDir+'/'));\n\n    new CollectionAdminRequest.MoveReplica(coll, replica.getName(), cluster.getJettySolrRunner(1).getNodeName())\n        .process(cluster.getSolrClient());\n    assertTrue(ClusterStateUtil.waitForAllActiveAndLiveReplicas(zkStateReader, 120000));\n    docCollection = zkStateReader.getClusterState().getCollection(coll);\n    assertEquals(1, docCollection.getSlice(\"shard1\").getReplicas().size());\n    Replica newReplica = docCollection.getReplicas().iterator().next();\n    assertEquals(newReplica.getNodeName(), cluster.getJettySolrRunner(1).getNodeName());\n    assertTrue(newReplica.getStr(\"ulogDir\"), newReplica.getStr(\"ulogDir\").equals(ulogDir) || newReplica.getStr(\"ulogDir\").equals(ulogDir+'/'));\n    assertTrue(newReplica.getStr(\"dataDir\"),newReplica.getStr(\"dataDir\").equals(dataDir) || newReplica.getStr(\"dataDir\").equals(dataDir+'/'));\n\n    assertEquals(replica.getName(), newReplica.getName());\n    assertEquals(replica.getCoreName(), newReplica.getCoreName());\n    assertFalse(replica.getNodeName().equals(newReplica.getNodeName()));\n    final int numDocs = 100;\n    addDocs(coll, numDocs);  // indexed but not committed\n\n    cluster.getJettySolrRunner(1).stop();\n    Thread.sleep(5000);\n    new CollectionAdminRequest.MoveReplica(coll, newReplica.getName(), cluster.getJettySolrRunner(0).getNodeName())\n        .process(cluster.getSolrClient());\n    assertTrue(ClusterStateUtil.waitForAllActiveAndLiveReplicas(zkStateReader, 120000));\n\n    // assert that the old core will be removed on startup\n    cluster.getJettySolrRunner(1).start();\n    assertTrue(ClusterStateUtil.waitForAllActiveAndLiveReplicas(zkStateReader, 120000));\n    docCollection = zkStateReader.getClusterState().getCollection(coll);\n    assertEquals(1, docCollection.getReplicas().size());\n    newReplica = docCollection.getReplicas().iterator().next();\n    assertEquals(newReplica.getNodeName(), cluster.getJettySolrRunner(0).getNodeName());\n    assertTrue(newReplica.getStr(\"ulogDir\"), newReplica.getStr(\"ulogDir\").equals(ulogDir) || newReplica.getStr(\"ulogDir\").equals(ulogDir+'/'));\n    assertTrue(newReplica.getStr(\"dataDir\"),newReplica.getStr(\"dataDir\").equals(dataDir) || newReplica.getStr(\"dataDir\").equals(dataDir+'/'));\n\n    assertEquals(0, cluster.getJettySolrRunner(1).getCoreContainer().getCores().size());\n\n    cluster.getSolrClient().commit(coll);\n    assertEquals(numDocs, cluster.getSolrClient().query(coll, new SolrQuery(\"*:*\")).getResults().getNumFound());\n    CollectionAdminRequest.deleteCollection(coll).process(cluster.getSolrClient());\n  }\n\n","sourceOld":"  @Test\n  public void testDataDirAndUlogAreMaintained() throws Exception {\n    String coll = \"movereplicatest_coll2\";\n    CollectionAdminRequest.createCollection(coll, \"conf1\", 1, 1)\n        .setCreateNodeSet(\"\")\n        .process(cluster.getSolrClient());\n    String hdfsUri = HdfsTestUtil.getURI(dfsCluster);\n    String dataDir = hdfsUri + \"/dummyFolder/dataDir\";\n    String ulogDir = hdfsUri + \"/dummyFolder2/ulogDir\";\n    CollectionAdminResponse res = CollectionAdminRequest\n        .addReplicaToShard(coll, \"shard1\")\n        .setDataDir(dataDir)\n        .setUlogDir(ulogDir)\n        .setNode(cluster.getJettySolrRunner(0).getNodeName())\n        .process(cluster.getSolrClient());\n\n    ulogDir += \"/tlog\";\n    ZkStateReader zkStateReader = cluster.getSolrClient().getZkStateReader();\n    assertTrue(ClusterStateUtil.waitForAllActiveAndLiveReplicas(zkStateReader, 120000));\n\n    DocCollection docCollection = zkStateReader.getClusterState().getCollection(coll);\n    Replica replica = docCollection.getReplicas().iterator().next();\n    assertTrue(replica.getStr(\"ulogDir\"), replica.getStr(\"ulogDir\").equals(ulogDir) || replica.getStr(\"ulogDir\").equals(ulogDir+'/'));\n    assertTrue(replica.getStr(\"dataDir\"),replica.getStr(\"dataDir\").equals(dataDir) || replica.getStr(\"dataDir\").equals(dataDir+'/'));\n\n    new CollectionAdminRequest.MoveReplica(coll, replica.getName(), cluster.getJettySolrRunner(1).getNodeName())\n        .process(cluster.getSolrClient());\n    assertTrue(ClusterStateUtil.waitForAllActiveAndLiveReplicas(zkStateReader, 120000));\n    docCollection = zkStateReader.getClusterState().getCollection(coll);\n    assertEquals(1, docCollection.getSlice(\"shard1\").getReplicas().size());\n    Replica newReplica = docCollection.getReplicas().iterator().next();\n    assertEquals(newReplica.getNodeName(), cluster.getJettySolrRunner(1).getNodeName());\n    assertTrue(newReplica.getStr(\"ulogDir\"), newReplica.getStr(\"ulogDir\").equals(ulogDir) || newReplica.getStr(\"ulogDir\").equals(ulogDir+'/'));\n    assertTrue(newReplica.getStr(\"dataDir\"),newReplica.getStr(\"dataDir\").equals(dataDir) || newReplica.getStr(\"dataDir\").equals(dataDir+'/'));\n\n    assertEquals(replica.getName(), newReplica.getName());\n    assertEquals(replica.getCoreName(), newReplica.getCoreName());\n    assertFalse(replica.getNodeName().equals(newReplica.getNodeName()));\n    final int numDocs = 100;\n    addDocs(coll, numDocs);  // indexed but not committed\n\n    cluster.getJettySolrRunner(1).stop();\n    Thread.sleep(5000);\n    new CollectionAdminRequest.MoveReplica(coll, newReplica.getName(), cluster.getJettySolrRunner(0).getNodeName())\n        .process(cluster.getSolrClient());\n    assertTrue(ClusterStateUtil.waitForAllActiveAndLiveReplicas(zkStateReader, 120000));\n\n    // assert that the old core will be removed on startup\n    cluster.getJettySolrRunner(1).start();\n    assertTrue(ClusterStateUtil.waitForAllActiveAndLiveReplicas(zkStateReader, 120000));\n    docCollection = zkStateReader.getClusterState().getCollection(coll);\n    assertEquals(1, docCollection.getReplicas().size());\n    newReplica = docCollection.getReplicas().iterator().next();\n    assertEquals(newReplica.getNodeName(), cluster.getJettySolrRunner(0).getNodeName());\n    assertTrue(newReplica.getStr(\"ulogDir\"), newReplica.getStr(\"ulogDir\").equals(ulogDir) || newReplica.getStr(\"ulogDir\").equals(ulogDir+'/'));\n    assertTrue(newReplica.getStr(\"dataDir\"),newReplica.getStr(\"dataDir\").equals(dataDir) || newReplica.getStr(\"dataDir\").equals(dataDir+'/'));\n\n    assertEquals(0, cluster.getJettySolrRunner(1).getCoreContainer().getCores().size());\n\n    cluster.getSolrClient().commit(coll);\n    assertEquals(numDocs, cluster.getSolrClient().query(coll, new SolrQuery(\"*:*\")).getResults().getNumFound());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c304e97e7c1d472bc70e801b35ee78583916c6cd","date":1507105431,"type":0,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/MoveReplicaHDFSFailoverTest#testDataDirAndUlogAreMaintained().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testDataDirAndUlogAreMaintained() throws Exception {\n    String coll = \"movereplicatest_coll2\";\n    CollectionAdminRequest.createCollection(coll, \"conf1\", 1, 1)\n        .setCreateNodeSet(\"\")\n        .process(cluster.getSolrClient());\n    String hdfsUri = HdfsTestUtil.getURI(dfsCluster);\n    String dataDir = hdfsUri + \"/dummyFolder/dataDir\";\n    String ulogDir = hdfsUri + \"/dummyFolder2/ulogDir\";\n    CollectionAdminResponse res = CollectionAdminRequest\n        .addReplicaToShard(coll, \"shard1\")\n        .setDataDir(dataDir)\n        .setUlogDir(ulogDir)\n        .setNode(cluster.getJettySolrRunner(0).getNodeName())\n        .process(cluster.getSolrClient());\n\n    ulogDir += \"/tlog\";\n    ZkStateReader zkStateReader = cluster.getSolrClient().getZkStateReader();\n    assertTrue(ClusterStateUtil.waitForAllActiveAndLiveReplicas(zkStateReader, 120000));\n\n    DocCollection docCollection = zkStateReader.getClusterState().getCollection(coll);\n    Replica replica = docCollection.getReplicas().iterator().next();\n    assertTrue(replica.getStr(\"ulogDir\"), replica.getStr(\"ulogDir\").equals(ulogDir) || replica.getStr(\"ulogDir\").equals(ulogDir+'/'));\n    assertTrue(replica.getStr(\"dataDir\"),replica.getStr(\"dataDir\").equals(dataDir) || replica.getStr(\"dataDir\").equals(dataDir+'/'));\n\n    new CollectionAdminRequest.MoveReplica(coll, replica.getName(), cluster.getJettySolrRunner(1).getNodeName())\n        .process(cluster.getSolrClient());\n    assertTrue(ClusterStateUtil.waitForAllActiveAndLiveReplicas(zkStateReader, 120000));\n    docCollection = zkStateReader.getClusterState().getCollection(coll);\n    assertEquals(1, docCollection.getSlice(\"shard1\").getReplicas().size());\n    Replica newReplica = docCollection.getReplicas().iterator().next();\n    assertEquals(newReplica.getNodeName(), cluster.getJettySolrRunner(1).getNodeName());\n    assertTrue(newReplica.getStr(\"ulogDir\"), newReplica.getStr(\"ulogDir\").equals(ulogDir) || newReplica.getStr(\"ulogDir\").equals(ulogDir+'/'));\n    assertTrue(newReplica.getStr(\"dataDir\"),newReplica.getStr(\"dataDir\").equals(dataDir) || newReplica.getStr(\"dataDir\").equals(dataDir+'/'));\n\n    assertEquals(replica.getName(), newReplica.getName());\n    assertEquals(replica.getCoreName(), newReplica.getCoreName());\n    assertFalse(replica.getNodeName().equals(newReplica.getNodeName()));\n    final int numDocs = 100;\n    addDocs(coll, numDocs);  // indexed but not committed\n\n    cluster.getJettySolrRunner(1).stop();\n    Thread.sleep(5000);\n    new CollectionAdminRequest.MoveReplica(coll, newReplica.getName(), cluster.getJettySolrRunner(0).getNodeName())\n        .process(cluster.getSolrClient());\n    assertTrue(ClusterStateUtil.waitForAllActiveAndLiveReplicas(zkStateReader, 120000));\n\n    // assert that the old core will be removed on startup\n    cluster.getJettySolrRunner(1).start();\n    assertTrue(ClusterStateUtil.waitForAllActiveAndLiveReplicas(zkStateReader, 120000));\n    docCollection = zkStateReader.getClusterState().getCollection(coll);\n    assertEquals(1, docCollection.getReplicas().size());\n    newReplica = docCollection.getReplicas().iterator().next();\n    assertEquals(newReplica.getNodeName(), cluster.getJettySolrRunner(0).getNodeName());\n    assertTrue(newReplica.getStr(\"ulogDir\"), newReplica.getStr(\"ulogDir\").equals(ulogDir) || newReplica.getStr(\"ulogDir\").equals(ulogDir+'/'));\n    assertTrue(newReplica.getStr(\"dataDir\"),newReplica.getStr(\"dataDir\").equals(dataDir) || newReplica.getStr(\"dataDir\").equals(dataDir+'/'));\n\n    assertEquals(0, cluster.getJettySolrRunner(1).getCoreContainer().getCores().size());\n\n    cluster.getSolrClient().commit(coll);\n    assertEquals(numDocs, cluster.getSolrClient().query(coll, new SolrQuery(\"*:*\")).getResults().getNumFound());\n    CollectionAdminRequest.deleteCollection(coll).process(cluster.getSolrClient());\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"560c18d71dad43d675158783c3840f8c80d6d39c","date":1507105532,"type":0,"author":"Cao Manh Dat","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/MoveReplicaHDFSFailoverTest#testDataDirAndUlogAreMaintained().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testDataDirAndUlogAreMaintained() throws Exception {\n    String coll = \"movereplicatest_coll2\";\n    CollectionAdminRequest.createCollection(coll, \"conf1\", 1, 1)\n        .setCreateNodeSet(\"\")\n        .process(cluster.getSolrClient());\n    String hdfsUri = HdfsTestUtil.getURI(dfsCluster);\n    String dataDir = hdfsUri + \"/dummyFolder/dataDir\";\n    String ulogDir = hdfsUri + \"/dummyFolder2/ulogDir\";\n    CollectionAdminResponse res = CollectionAdminRequest\n        .addReplicaToShard(coll, \"shard1\")\n        .setDataDir(dataDir)\n        .setUlogDir(ulogDir)\n        .setNode(cluster.getJettySolrRunner(0).getNodeName())\n        .process(cluster.getSolrClient());\n\n    ulogDir += \"/tlog\";\n    ZkStateReader zkStateReader = cluster.getSolrClient().getZkStateReader();\n    assertTrue(ClusterStateUtil.waitForAllActiveAndLiveReplicas(zkStateReader, 120000));\n\n    DocCollection docCollection = zkStateReader.getClusterState().getCollection(coll);\n    Replica replica = docCollection.getReplicas().iterator().next();\n    assertTrue(replica.getStr(\"ulogDir\"), replica.getStr(\"ulogDir\").equals(ulogDir) || replica.getStr(\"ulogDir\").equals(ulogDir+'/'));\n    assertTrue(replica.getStr(\"dataDir\"),replica.getStr(\"dataDir\").equals(dataDir) || replica.getStr(\"dataDir\").equals(dataDir+'/'));\n\n    new CollectionAdminRequest.MoveReplica(coll, replica.getName(), cluster.getJettySolrRunner(1).getNodeName())\n        .process(cluster.getSolrClient());\n    assertTrue(ClusterStateUtil.waitForAllActiveAndLiveReplicas(zkStateReader, 120000));\n    docCollection = zkStateReader.getClusterState().getCollection(coll);\n    assertEquals(1, docCollection.getSlice(\"shard1\").getReplicas().size());\n    Replica newReplica = docCollection.getReplicas().iterator().next();\n    assertEquals(newReplica.getNodeName(), cluster.getJettySolrRunner(1).getNodeName());\n    assertTrue(newReplica.getStr(\"ulogDir\"), newReplica.getStr(\"ulogDir\").equals(ulogDir) || newReplica.getStr(\"ulogDir\").equals(ulogDir+'/'));\n    assertTrue(newReplica.getStr(\"dataDir\"),newReplica.getStr(\"dataDir\").equals(dataDir) || newReplica.getStr(\"dataDir\").equals(dataDir+'/'));\n\n    assertEquals(replica.getName(), newReplica.getName());\n    assertEquals(replica.getCoreName(), newReplica.getCoreName());\n    assertFalse(replica.getNodeName().equals(newReplica.getNodeName()));\n    final int numDocs = 100;\n    addDocs(coll, numDocs);  // indexed but not committed\n\n    cluster.getJettySolrRunner(1).stop();\n    Thread.sleep(5000);\n    new CollectionAdminRequest.MoveReplica(coll, newReplica.getName(), cluster.getJettySolrRunner(0).getNodeName())\n        .process(cluster.getSolrClient());\n    assertTrue(ClusterStateUtil.waitForAllActiveAndLiveReplicas(zkStateReader, 120000));\n\n    // assert that the old core will be removed on startup\n    cluster.getJettySolrRunner(1).start();\n    assertTrue(ClusterStateUtil.waitForAllActiveAndLiveReplicas(zkStateReader, 120000));\n    docCollection = zkStateReader.getClusterState().getCollection(coll);\n    assertEquals(1, docCollection.getReplicas().size());\n    newReplica = docCollection.getReplicas().iterator().next();\n    assertEquals(newReplica.getNodeName(), cluster.getJettySolrRunner(0).getNodeName());\n    assertTrue(newReplica.getStr(\"ulogDir\"), newReplica.getStr(\"ulogDir\").equals(ulogDir) || newReplica.getStr(\"ulogDir\").equals(ulogDir+'/'));\n    assertTrue(newReplica.getStr(\"dataDir\"),newReplica.getStr(\"dataDir\").equals(dataDir) || newReplica.getStr(\"dataDir\").equals(dataDir+'/'));\n\n    assertEquals(0, cluster.getJettySolrRunner(1).getCoreContainer().getCores().size());\n\n    cluster.getSolrClient().commit(coll);\n    assertEquals(numDocs, cluster.getSolrClient().query(coll, new SolrQuery(\"*:*\")).getResults().getNumFound());\n    CollectionAdminRequest.deleteCollection(coll).process(cluster.getSolrClient());\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"c304e97e7c1d472bc70e801b35ee78583916c6cd":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","717e5ceb2acae36d422ec75e5a4ce9fac40506e1"],"717e5ceb2acae36d422ec75e5a4ce9fac40506e1":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"560c18d71dad43d675158783c3840f8c80d6d39c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","c304e97e7c1d472bc70e801b35ee78583916c6cd"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["560c18d71dad43d675158783c3840f8c80d6d39c"]},"commit2Childs":{"c304e97e7c1d472bc70e801b35ee78583916c6cd":["560c18d71dad43d675158783c3840f8c80d6d39c"],"717e5ceb2acae36d422ec75e5a4ce9fac40506e1":["c304e97e7c1d472bc70e801b35ee78583916c6cd"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c304e97e7c1d472bc70e801b35ee78583916c6cd","717e5ceb2acae36d422ec75e5a4ce9fac40506e1","560c18d71dad43d675158783c3840f8c80d6d39c"],"560c18d71dad43d675158783c3840f8c80d6d39c":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}