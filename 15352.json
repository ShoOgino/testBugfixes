{"path":"lucene/src/java/org/apache/lucene/index/SegmentMerger#merge().mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#merge().mjava","pathOld":"src/java/org/apache/lucene/index/SegmentMerger#merge().mjava","sourceNew":"  /**\n   * Merges the readers specified by the {@link #add} method into the directory passed to the constructor\n   * @return The number of documents that were merged\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  final int merge() throws CorruptIndexException, IOException {\n    return merge(true);\n  }\n\n","sourceOld":"  /**\n   * Merges the readers specified by the {@link #add} method into the directory passed to the constructor\n   * @return The number of documents that were merged\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  final int merge() throws CorruptIndexException, IOException {\n    return merge(true);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"833a7987bc1c94455fde83e3311f72bddedcfb93","date":1279951470,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#merge().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentMerger#merge().mjava","sourceNew":"  /**\n   * Merges the readers specified by the {@link #add} method into the directory passed to the constructor\n   * @return The number of documents that were merged\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  final int merge() throws CorruptIndexException, IOException {\n    // NOTE: it's important to add calls to\n    // checkAbort.work(...) if you make any changes to this\n    // method that will spend alot of time.  The frequency\n    // of this check impacts how long\n    // IndexWriter.close(false) takes to actually stop the\n    // threads.\n\n    mergedDocs = mergeFields();\n    mergeTerms();\n    mergeNorms();\n\n    if (fieldInfos.hasVectors())\n      mergeVectors();\n\n    return mergedDocs;\n  }\n\n","sourceOld":"  /**\n   * Merges the readers specified by the {@link #add} method into the directory passed to the constructor\n   * @return The number of documents that were merged\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  final int merge() throws CorruptIndexException, IOException {\n    return merge(true);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4948bc5d29211f0c9b5ccc31b2632cdd27066ea5","date":1292695408,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#merge().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentMerger#merge().mjava","sourceNew":"  /**\n   * Merges the readers specified by the {@link #add} method into the directory passed to the constructor\n   * @return The number of documents that were merged\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  final int merge() throws CorruptIndexException, IOException {\n    // NOTE: it's important to add calls to\n    // checkAbort.work(...) if you make any changes to this\n    // method that will spend alot of time.  The frequency\n    // of this check impacts how long\n    // IndexWriter.close(false) takes to actually stop the\n    // threads.\n\n    mergedDocs = mergeFields();\n    mergeTerms();\n    mergeNorms();\n\n    if (fieldInfos.hasVectors())\n      mergeVectors();\n\n    return mergedDocs;\n  }\n\n","sourceOld":"  /**\n   * Merges the readers specified by the {@link #add} method into the directory passed to the constructor\n   * @return The number of documents that were merged\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  final int merge() throws CorruptIndexException, IOException {\n    return merge(true);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ab5cb6a74aefb78aa0569857970b9151dfe2e787","date":1292842407,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#merge().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentMerger#merge().mjava","sourceNew":"  /**\n   * Merges the readers specified by the {@link #add} method into the directory passed to the constructor\n   * @return The number of documents that were merged\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  final int merge() throws CorruptIndexException, IOException {\n    // NOTE: it's important to add calls to\n    // checkAbort.work(...) if you make any changes to this\n    // method that will spend alot of time.  The frequency\n    // of this check impacts how long\n    // IndexWriter.close(false) takes to actually stop the\n    // threads.\n\n    mergedDocs = mergeFields();\n    mergeTerms();\n    mergeNorms();\n\n    if (fieldInfos.hasVectors())\n      mergeVectors();\n    return mergedDocs;\n  }\n\n","sourceOld":"  /**\n   * Merges the readers specified by the {@link #add} method into the directory passed to the constructor\n   * @return The number of documents that were merged\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  final int merge() throws CorruptIndexException, IOException {\n    return merge(true);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2e8d7ba2175f47e280231533f7d3016249cea88b","date":1307711934,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#merge().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentMerger#merge().mjava","sourceNew":"  /**\n   * Merges the readers specified by the {@link #add} method into the directory passed to the constructor\n   * @return The number of documents that were merged\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  final int merge() throws CorruptIndexException, IOException {\n    // NOTE: it's important to add calls to\n    // checkAbort.work(...) if you make any changes to this\n    // method that will spend alot of time.  The frequency\n    // of this check impacts how long\n    // IndexWriter.close(false) takes to actually stop the\n    // threads.\n\n    mergedDocs = mergeFields();\n    mergeTerms();\n    mergeNorms();\n\n    if (fieldInfos.hasVectors())\n      mergeVectors();\n    return mergedDocs;\n  }\n\n","sourceOld":"  /**\n   * Merges the readers specified by the {@link #add} method into the directory passed to the constructor\n   * @return The number of documents that were merged\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  final int merge() throws CorruptIndexException, IOException {\n    // NOTE: it's important to add calls to\n    // checkAbort.work(...) if you make any changes to this\n    // method that will spend alot of time.  The frequency\n    // of this check impacts how long\n    // IndexWriter.close(false) takes to actually stop the\n    // threads.\n\n    mergedDocs = mergeFields();\n    mergeTerms();\n    mergeNorms();\n\n    if (fieldInfos.hasVectors())\n      mergeVectors();\n\n    return mergedDocs;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a02058e0eaba4bbd5d05e6b06b9522c0acfd1655","date":1307729864,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#merge().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentMerger#merge().mjava","sourceNew":"  /**\n   * Merges the readers specified by the {@link #add} method into the directory passed to the constructor\n   * @return The number of documents that were merged\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  final int merge() throws CorruptIndexException, IOException {\n    // NOTE: it's important to add calls to\n    // checkAbort.work(...) if you make any changes to this\n    // method that will spend alot of time.  The frequency\n    // of this check impacts how long\n    // IndexWriter.close(false) takes to actually stop the\n    // threads.\n\n    mergedDocs = mergeFields();\n    mergeTerms();\n    mergeNorms();\n\n    if (fieldInfos.hasVectors())\n      mergeVectors();\n    return mergedDocs;\n  }\n\n","sourceOld":"  /**\n   * Merges the readers specified by the {@link #add} method into the directory passed to the constructor\n   * @return The number of documents that were merged\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  final int merge() throws CorruptIndexException, IOException {\n    // NOTE: it's important to add calls to\n    // checkAbort.work(...) if you make any changes to this\n    // method that will spend alot of time.  The frequency\n    // of this check impacts how long\n    // IndexWriter.close(false) takes to actually stop the\n    // threads.\n\n    mergedDocs = mergeFields();\n    mergeTerms();\n    mergeNorms();\n\n    if (fieldInfos.hasVectors())\n      mergeVectors();\n\n    return mergedDocs;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5a07ca455ec3f405a6078602f3f3dcf2d4fa8679","date":1310042027,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#merge().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentMerger#merge().mjava","sourceNew":"  /**\n   * Merges the readers specified by the {@link #add} method into the directory passed to the constructor\n   * @return The number of documents that were merged\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  final int merge() throws CorruptIndexException, IOException {\n    // NOTE: it's important to add calls to\n    // checkAbort.work(...) if you make any changes to this\n    // method that will spend alot of time.  The frequency\n    // of this check impacts how long\n    // IndexWriter.close(false) takes to actually stop the\n    // threads.\n\n    mergedDocs = mergeFields();\n    mergeTerms();\n    mergePerDoc();\n    mergeNorms();\n\n    if (fieldInfos.hasVectors())\n      mergeVectors();\n    return mergedDocs;\n  }\n\n","sourceOld":"  /**\n   * Merges the readers specified by the {@link #add} method into the directory passed to the constructor\n   * @return The number of documents that were merged\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  final int merge() throws CorruptIndexException, IOException {\n    // NOTE: it's important to add calls to\n    // checkAbort.work(...) if you make any changes to this\n    // method that will spend alot of time.  The frequency\n    // of this check impacts how long\n    // IndexWriter.close(false) takes to actually stop the\n    // threads.\n\n    mergedDocs = mergeFields();\n    mergeTerms();\n    mergeNorms();\n\n    if (fieldInfos.hasVectors())\n      mergeVectors();\n    return mergedDocs;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f0b9507caf22f292ac0e5e59f62db4275adf4511","date":1310107283,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#merge().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentMerger#merge().mjava","sourceNew":"  /**\n   * Merges the readers specified by the {@link #add} method into the directory passed to the constructor\n   * @return The number of documents that were merged\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  final int merge() throws CorruptIndexException, IOException {\n    // NOTE: it's important to add calls to\n    // checkAbort.work(...) if you make any changes to this\n    // method that will spend alot of time.  The frequency\n    // of this check impacts how long\n    // IndexWriter.close(false) takes to actually stop the\n    // threads.\n\n    mergedDocs = mergeFields();\n    mergeTerms();\n    mergePerDoc();\n    mergeNorms();\n\n    if (fieldInfos.hasVectors())\n      mergeVectors();\n    return mergedDocs;\n  }\n\n","sourceOld":"  /**\n   * Merges the readers specified by the {@link #add} method into the directory passed to the constructor\n   * @return The number of documents that were merged\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  final int merge() throws CorruptIndexException, IOException {\n    // NOTE: it's important to add calls to\n    // checkAbort.work(...) if you make any changes to this\n    // method that will spend alot of time.  The frequency\n    // of this check impacts how long\n    // IndexWriter.close(false) takes to actually stop the\n    // threads.\n\n    mergedDocs = mergeFields();\n    mergeTerms();\n    mergeNorms();\n\n    if (fieldInfos.hasVectors())\n      mergeVectors();\n    return mergedDocs;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1291e4568eb7d9463d751627596ef14baf4c1603","date":1310112572,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#merge().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentMerger#merge().mjava","sourceNew":"  /**\n   * Merges the readers specified by the {@link #add} method into the directory passed to the constructor\n   * @return The number of documents that were merged\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  final int merge() throws CorruptIndexException, IOException {\n    // NOTE: it's important to add calls to\n    // checkAbort.work(...) if you make any changes to this\n    // method that will spend alot of time.  The frequency\n    // of this check impacts how long\n    // IndexWriter.close(false) takes to actually stop the\n    // threads.\n\n    mergedDocs = mergeFields();\n    mergeTerms();\n    mergePerDoc();\n    mergeNorms();\n\n    if (fieldInfos.hasVectors())\n      mergeVectors();\n    return mergedDocs;\n  }\n\n","sourceOld":"  /**\n   * Merges the readers specified by the {@link #add} method into the directory passed to the constructor\n   * @return The number of documents that were merged\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  final int merge() throws CorruptIndexException, IOException {\n    // NOTE: it's important to add calls to\n    // checkAbort.work(...) if you make any changes to this\n    // method that will spend alot of time.  The frequency\n    // of this check impacts how long\n    // IndexWriter.close(false) takes to actually stop the\n    // threads.\n\n    mergedDocs = mergeFields();\n    mergeTerms();\n    mergeNorms();\n\n    if (fieldInfos.hasVectors())\n      mergeVectors();\n    return mergedDocs;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0061262413ecc163d6eebba1b5c43ab91a0c2dc5","date":1311195279,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#merge().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentMerger#merge().mjava","sourceNew":"  /**\n   * Merges the readers specified by the {@link #add} method into the directory passed to the constructor\n   * @return The number of documents that were merged\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  final int merge() throws CorruptIndexException, IOException {\n    // NOTE: it's important to add calls to\n    // checkAbort.work(...) if you make any changes to this\n    // method that will spend alot of time.  The frequency\n    // of this check impacts how long\n    // IndexWriter.close(false) takes to actually stop the\n    // threads.\n\n    mergedDocs = mergeFields();\n    mergeTerms();\n    mergePerDoc();\n    mergeNorms();\n\n    if (fieldInfos.hasVectors()) {\n      mergeVectors();\n    }\n    return mergedDocs;\n  }\n\n","sourceOld":"  /**\n   * Merges the readers specified by the {@link #add} method into the directory passed to the constructor\n   * @return The number of documents that were merged\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  final int merge() throws CorruptIndexException, IOException {\n    // NOTE: it's important to add calls to\n    // checkAbort.work(...) if you make any changes to this\n    // method that will spend alot of time.  The frequency\n    // of this check impacts how long\n    // IndexWriter.close(false) takes to actually stop the\n    // threads.\n\n    mergedDocs = mergeFields();\n    mergeTerms();\n    mergePerDoc();\n    mergeNorms();\n\n    if (fieldInfos.hasVectors())\n      mergeVectors();\n    return mergedDocs;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"32aca6bb0a6aa0a1813e7d035ac0e039f54269f4","date":1318260487,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#merge().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentMerger#merge().mjava","sourceNew":"  /**\n   * Merges the readers specified by the {@link #add} method into the directory passed to the constructor\n   * @return The number of documents that were merged\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  final int merge() throws CorruptIndexException, IOException {\n    // NOTE: it's important to add calls to\n    // checkAbort.work(...) if you make any changes to this\n    // method that will spend alot of time.  The frequency\n    // of this check impacts how long\n    // IndexWriter.close(false) takes to actually stop the\n    // threads.\n\n    mergedDocs = mergeFields();\n    mergeTerms();\n    mergePerDoc();\n    mergeNorms();\n\n    if (fieldInfos.hasVectors()) {\n      mergeVectors();\n    }\n    // write FIS once merge is done. IDV might change types or drops fields\n    fieldInfos.write(directory, segment + \".\" + IndexFileNames.FIELD_INFOS_EXTENSION);\n    return mergedDocs;\n  }\n\n","sourceOld":"  /**\n   * Merges the readers specified by the {@link #add} method into the directory passed to the constructor\n   * @return The number of documents that were merged\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  final int merge() throws CorruptIndexException, IOException {\n    // NOTE: it's important to add calls to\n    // checkAbort.work(...) if you make any changes to this\n    // method that will spend alot of time.  The frequency\n    // of this check impacts how long\n    // IndexWriter.close(false) takes to actually stop the\n    // threads.\n\n    mergedDocs = mergeFields();\n    mergeTerms();\n    mergePerDoc();\n    mergeNorms();\n\n    if (fieldInfos.hasVectors()) {\n      mergeVectors();\n    }\n    return mergedDocs;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"06584e6e98d592b34e1329b384182f368d2025e8","date":1320850353,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#merge().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentMerger#merge().mjava","sourceNew":"  /**\n   * Merges the readers specified by the {@link #add} method into the directory passed to the constructor\n   * @return The number of documents that were merged\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  final MergeState merge() throws CorruptIndexException, IOException {\n    // NOTE: it's important to add calls to\n    // checkAbort.work(...) if you make any changes to this\n    // method that will spend alot of time.  The frequency\n    // of this check impacts how long\n    // IndexWriter.close(false) takes to actually stop the\n    // threads.\n    \n    final int numReaders = mergeState.readers.size();\n    // Remap docIDs\n    mergeState.docMaps = new int[numReaders][];\n    mergeState.docBase = new int[numReaders];\n    mergeState.dirPayloadProcessor = new PayloadProcessorProvider.DirPayloadProcessor[numReaders];\n    mergeState.currentPayloadProcessor = new PayloadProcessorProvider.PayloadProcessor[numReaders];\n\n    mergeFieldInfos();\n    setMatchingSegmentReaders();\n    mergeState.mergedDocCount = mergeFields();\n\n    final SegmentWriteState segmentWriteState = new SegmentWriteState(mergeState.infoStream, directory, segment, mergeState.fieldInfos, mergeState.mergedDocCount, termIndexInterval, codec, null, context);\n    mergeTerms(segmentWriteState);\n    mergePerDoc(segmentWriteState);\n    mergeNorms();\n\n    if (mergeState.fieldInfos.hasVectors()) {\n      mergeVectors(segmentWriteState);\n    }\n    // write FIS once merge is done. IDV might change types or drops fields\n    mergeState.fieldInfos.write(directory, segment + \".\" + IndexFileNames.FIELD_INFOS_EXTENSION);\n    return mergeState;\n  }\n\n","sourceOld":"  /**\n   * Merges the readers specified by the {@link #add} method into the directory passed to the constructor\n   * @return The number of documents that were merged\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  final int merge() throws CorruptIndexException, IOException {\n    // NOTE: it's important to add calls to\n    // checkAbort.work(...) if you make any changes to this\n    // method that will spend alot of time.  The frequency\n    // of this check impacts how long\n    // IndexWriter.close(false) takes to actually stop the\n    // threads.\n\n    mergedDocs = mergeFields();\n    mergeTerms();\n    mergePerDoc();\n    mergeNorms();\n\n    if (fieldInfos.hasVectors()) {\n      mergeVectors();\n    }\n    // write FIS once merge is done. IDV might change types or drops fields\n    fieldInfos.write(directory, segment + \".\" + IndexFileNames.FIELD_INFOS_EXTENSION);\n    return mergedDocs;\n  }\n\n","bugFix":null,"bugIntro":["0859dec0aa7a485aa0081147f533c5987b4b47ac","d4d69c535930b5cce125cff868d40f6373dc27d4","4d3e8520fd031bab31fd0e4d480e55958bc45efe"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3cc749c053615f5871f3b95715fe292f34e70a53","date":1321470575,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#merge().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentMerger#merge().mjava","sourceNew":"  /**\n   * Merges the readers specified by the {@link #add} method into the directory passed to the constructor\n   * @return The number of documents that were merged\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  final MergeState merge() throws CorruptIndexException, IOException {\n    // NOTE: it's important to add calls to\n    // checkAbort.work(...) if you make any changes to this\n    // method that will spend alot of time.  The frequency\n    // of this check impacts how long\n    // IndexWriter.close(false) takes to actually stop the\n    // threads.\n    \n    final int numReaders = mergeState.readers.size();\n    // Remap docIDs\n    mergeState.docMaps = new int[numReaders][];\n    mergeState.docBase = new int[numReaders];\n    mergeState.dirPayloadProcessor = new PayloadProcessorProvider.DirPayloadProcessor[numReaders];\n    mergeState.currentPayloadProcessor = new PayloadProcessorProvider.PayloadProcessor[numReaders];\n\n    mergeFieldInfos();\n    setMatchingSegmentReaders();\n    mergeState.mergedDocCount = mergeFields();\n\n    final SegmentWriteState segmentWriteState = new SegmentWriteState(mergeState.infoStream, directory, segment, mergeState.fieldInfos, mergeState.mergedDocCount, termIndexInterval, codec, null, context);\n    mergeTerms(segmentWriteState);\n    mergePerDoc(segmentWriteState);\n    mergeNorms();\n\n    if (mergeState.fieldInfos.hasVectors()) {\n      int numMerged = mergeVectors();\n      assert numMerged == mergeState.mergedDocCount;\n    }\n    // write FIS once merge is done. IDV might change types or drops fields\n    FieldInfosWriter fieldInfosWriter = codec.fieldInfosFormat().getFieldInfosWriter();\n    fieldInfosWriter.write(directory, segment, mergeState.fieldInfos, context);\n    return mergeState;\n  }\n\n","sourceOld":"  /**\n   * Merges the readers specified by the {@link #add} method into the directory passed to the constructor\n   * @return The number of documents that were merged\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  final MergeState merge() throws CorruptIndexException, IOException {\n    // NOTE: it's important to add calls to\n    // checkAbort.work(...) if you make any changes to this\n    // method that will spend alot of time.  The frequency\n    // of this check impacts how long\n    // IndexWriter.close(false) takes to actually stop the\n    // threads.\n    \n    final int numReaders = mergeState.readers.size();\n    // Remap docIDs\n    mergeState.docMaps = new int[numReaders][];\n    mergeState.docBase = new int[numReaders];\n    mergeState.dirPayloadProcessor = new PayloadProcessorProvider.DirPayloadProcessor[numReaders];\n    mergeState.currentPayloadProcessor = new PayloadProcessorProvider.PayloadProcessor[numReaders];\n\n    mergeFieldInfos();\n    setMatchingSegmentReaders();\n    mergeState.mergedDocCount = mergeFields();\n\n    final SegmentWriteState segmentWriteState = new SegmentWriteState(mergeState.infoStream, directory, segment, mergeState.fieldInfos, mergeState.mergedDocCount, termIndexInterval, codec, null, context);\n    mergeTerms(segmentWriteState);\n    mergePerDoc(segmentWriteState);\n    mergeNorms();\n\n    if (mergeState.fieldInfos.hasVectors()) {\n      mergeVectors(segmentWriteState);\n    }\n    // write FIS once merge is done. IDV might change types or drops fields\n    mergeState.fieldInfos.write(directory, segment + \".\" + IndexFileNames.FIELD_INFOS_EXTENSION);\n    return mergeState;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f6ee314d4978b896d2a804ee60ba6e830624d990","date":1323044870,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#merge().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentMerger#merge().mjava","sourceNew":"  /**\n   * Merges the readers specified by the {@link #add} method into the directory passed to the constructor\n   * @return The number of documents that were merged\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  final MergeState merge() throws CorruptIndexException, IOException {\n    // NOTE: it's important to add calls to\n    // checkAbort.work(...) if you make any changes to this\n    // method that will spend alot of time.  The frequency\n    // of this check impacts how long\n    // IndexWriter.close(false) takes to actually stop the\n    // threads.\n    \n    final int numReaders = mergeState.readers.size();\n    // Remap docIDs\n    mergeState.docMaps = new int[numReaders][];\n    mergeState.docBase = new int[numReaders];\n    mergeState.dirPayloadProcessor = new PayloadProcessorProvider.DirPayloadProcessor[numReaders];\n    mergeState.currentPayloadProcessor = new PayloadProcessorProvider.PayloadProcessor[numReaders];\n\n    mergeFieldInfos();\n    setMatchingSegmentReaders();\n    mergeState.mergedDocCount = mergeFields();\n\n    final SegmentWriteState segmentWriteState = new SegmentWriteState(mergeState.infoStream, directory, segment, mergeState.fieldInfos, mergeState.mergedDocCount, termIndexInterval, codec, null, context);\n    mergeTerms(segmentWriteState);\n    mergePerDoc(segmentWriteState);\n    \n    if (mergeState.fieldInfos.hasNorms()) {\n      int numMerged = mergeNorms(segmentWriteState);\n      assert numMerged == mergeState.mergedDocCount;\n    }\n\n    if (mergeState.fieldInfos.hasVectors()) {\n      int numMerged = mergeVectors();\n      assert numMerged == mergeState.mergedDocCount;\n    }\n    // write FIS once merge is done. IDV might change types or drops fields\n    FieldInfosWriter fieldInfosWriter = codec.fieldInfosFormat().getFieldInfosWriter();\n    fieldInfosWriter.write(directory, segment, mergeState.fieldInfos, context);\n    return mergeState;\n  }\n\n","sourceOld":"  /**\n   * Merges the readers specified by the {@link #add} method into the directory passed to the constructor\n   * @return The number of documents that were merged\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  final MergeState merge() throws CorruptIndexException, IOException {\n    // NOTE: it's important to add calls to\n    // checkAbort.work(...) if you make any changes to this\n    // method that will spend alot of time.  The frequency\n    // of this check impacts how long\n    // IndexWriter.close(false) takes to actually stop the\n    // threads.\n    \n    final int numReaders = mergeState.readers.size();\n    // Remap docIDs\n    mergeState.docMaps = new int[numReaders][];\n    mergeState.docBase = new int[numReaders];\n    mergeState.dirPayloadProcessor = new PayloadProcessorProvider.DirPayloadProcessor[numReaders];\n    mergeState.currentPayloadProcessor = new PayloadProcessorProvider.PayloadProcessor[numReaders];\n\n    mergeFieldInfos();\n    setMatchingSegmentReaders();\n    mergeState.mergedDocCount = mergeFields();\n\n    final SegmentWriteState segmentWriteState = new SegmentWriteState(mergeState.infoStream, directory, segment, mergeState.fieldInfos, mergeState.mergedDocCount, termIndexInterval, codec, null, context);\n    mergeTerms(segmentWriteState);\n    mergePerDoc(segmentWriteState);\n    mergeNorms();\n\n    if (mergeState.fieldInfos.hasVectors()) {\n      int numMerged = mergeVectors();\n      assert numMerged == mergeState.mergedDocCount;\n    }\n    // write FIS once merge is done. IDV might change types or drops fields\n    FieldInfosWriter fieldInfosWriter = codec.fieldInfosFormat().getFieldInfosWriter();\n    fieldInfosWriter.write(directory, segment, mergeState.fieldInfos, context);\n    return mergeState;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"23c3a6c2ecb0c99396936e72e8998df877ea9ad5","date":1323268151,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#merge().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentMerger#merge().mjava","sourceNew":"  /**\n   * Merges the readers specified by the {@link #add} method into the directory passed to the constructor\n   * @return The number of documents that were merged\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  final MergeState merge() throws CorruptIndexException, IOException {\n    // NOTE: it's important to add calls to\n    // checkAbort.work(...) if you make any changes to this\n    // method that will spend alot of time.  The frequency\n    // of this check impacts how long\n    // IndexWriter.close(false) takes to actually stop the\n    // threads.\n    \n    final int numReaders = mergeState.readers.size();\n    // Remap docIDs\n    mergeState.docMaps = new int[numReaders][];\n    mergeState.docBase = new int[numReaders];\n    mergeState.dirPayloadProcessor = new PayloadProcessorProvider.DirPayloadProcessor[numReaders];\n    mergeState.currentPayloadProcessor = new PayloadProcessorProvider.PayloadProcessor[numReaders];\n\n    mergeFieldInfos();\n    setMatchingSegmentReaders();\n    mergeState.mergedDocCount = mergeFields();\n\n    final SegmentWriteState segmentWriteState = new SegmentWriteState(mergeState.infoStream, directory, segment, mergeState.fieldInfos, mergeState.mergedDocCount, termIndexInterval, codec, null, context);\n    mergeTerms(segmentWriteState);\n    mergePerDoc(segmentWriteState);\n    mergeNorms();\n\n    if (mergeState.fieldInfos.hasVectors()) {\n      int numMerged = mergeVectors();\n      assert numMerged == mergeState.mergedDocCount;\n    }\n\n    return mergeState;\n  }\n\n","sourceOld":"  /**\n   * Merges the readers specified by the {@link #add} method into the directory passed to the constructor\n   * @return The number of documents that were merged\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  final MergeState merge() throws CorruptIndexException, IOException {\n    // NOTE: it's important to add calls to\n    // checkAbort.work(...) if you make any changes to this\n    // method that will spend alot of time.  The frequency\n    // of this check impacts how long\n    // IndexWriter.close(false) takes to actually stop the\n    // threads.\n    \n    final int numReaders = mergeState.readers.size();\n    // Remap docIDs\n    mergeState.docMaps = new int[numReaders][];\n    mergeState.docBase = new int[numReaders];\n    mergeState.dirPayloadProcessor = new PayloadProcessorProvider.DirPayloadProcessor[numReaders];\n    mergeState.currentPayloadProcessor = new PayloadProcessorProvider.PayloadProcessor[numReaders];\n\n    mergeFieldInfos();\n    setMatchingSegmentReaders();\n    mergeState.mergedDocCount = mergeFields();\n\n    final SegmentWriteState segmentWriteState = new SegmentWriteState(mergeState.infoStream, directory, segment, mergeState.fieldInfos, mergeState.mergedDocCount, termIndexInterval, codec, null, context);\n    mergeTerms(segmentWriteState);\n    mergePerDoc(segmentWriteState);\n    mergeNorms();\n\n    if (mergeState.fieldInfos.hasVectors()) {\n      int numMerged = mergeVectors();\n      assert numMerged == mergeState.mergedDocCount;\n    }\n    // write FIS once merge is done. IDV might change types or drops fields\n    FieldInfosWriter fieldInfosWriter = codec.fieldInfosFormat().getFieldInfosWriter();\n    fieldInfosWriter.write(directory, segment, mergeState.fieldInfos, context);\n    return mergeState;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3615ce4a1f785ae1b779244de52c6a7d99227e60","date":1323422019,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#merge().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentMerger#merge().mjava","sourceNew":"  /**\n   * Merges the readers specified by the {@link #add} method into the directory passed to the constructor\n   * @return The number of documents that were merged\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  final MergeState merge() throws CorruptIndexException, IOException {\n    // NOTE: it's important to add calls to\n    // checkAbort.work(...) if you make any changes to this\n    // method that will spend alot of time.  The frequency\n    // of this check impacts how long\n    // IndexWriter.close(false) takes to actually stop the\n    // threads.\n    \n    final int numReaders = mergeState.readers.size();\n    // Remap docIDs\n    mergeState.docMaps = new int[numReaders][];\n    mergeState.docBase = new int[numReaders];\n    mergeState.dirPayloadProcessor = new PayloadProcessorProvider.DirPayloadProcessor[numReaders];\n    mergeState.currentPayloadProcessor = new PayloadProcessorProvider.PayloadProcessor[numReaders];\n\n    mergeFieldInfos();\n    setMatchingSegmentReaders();\n    mergeState.mergedDocCount = mergeFields();\n\n    final SegmentWriteState segmentWriteState = new SegmentWriteState(mergeState.infoStream, directory, segment, mergeState.fieldInfos, mergeState.mergedDocCount, termIndexInterval, codec, null, context);\n    mergeTerms(segmentWriteState);\n    mergePerDoc(segmentWriteState);\n    \n    if (mergeState.fieldInfos.hasNorms()) {\n      int numMerged = mergeNorms(segmentWriteState);\n      assert numMerged == mergeState.mergedDocCount;\n    }\n\n    if (mergeState.fieldInfos.hasVectors()) {\n      int numMerged = mergeVectors();\n      assert numMerged == mergeState.mergedDocCount;\n    }\n    // write FIS once merge is done. IDV might change types or drops fields\n    FieldInfosWriter fieldInfosWriter = codec.fieldInfosFormat().getFieldInfosWriter();\n    fieldInfosWriter.write(directory, segment, mergeState.fieldInfos, context);\n    return mergeState;\n  }\n\n","sourceOld":"  /**\n   * Merges the readers specified by the {@link #add} method into the directory passed to the constructor\n   * @return The number of documents that were merged\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  final MergeState merge() throws CorruptIndexException, IOException {\n    // NOTE: it's important to add calls to\n    // checkAbort.work(...) if you make any changes to this\n    // method that will spend alot of time.  The frequency\n    // of this check impacts how long\n    // IndexWriter.close(false) takes to actually stop the\n    // threads.\n    \n    final int numReaders = mergeState.readers.size();\n    // Remap docIDs\n    mergeState.docMaps = new int[numReaders][];\n    mergeState.docBase = new int[numReaders];\n    mergeState.dirPayloadProcessor = new PayloadProcessorProvider.DirPayloadProcessor[numReaders];\n    mergeState.currentPayloadProcessor = new PayloadProcessorProvider.PayloadProcessor[numReaders];\n\n    mergeFieldInfos();\n    setMatchingSegmentReaders();\n    mergeState.mergedDocCount = mergeFields();\n\n    final SegmentWriteState segmentWriteState = new SegmentWriteState(mergeState.infoStream, directory, segment, mergeState.fieldInfos, mergeState.mergedDocCount, termIndexInterval, codec, null, context);\n    mergeTerms(segmentWriteState);\n    mergePerDoc(segmentWriteState);\n    mergeNorms();\n\n    if (mergeState.fieldInfos.hasVectors()) {\n      int numMerged = mergeVectors();\n      assert numMerged == mergeState.mergedDocCount;\n    }\n    // write FIS once merge is done. IDV might change types or drops fields\n    FieldInfosWriter fieldInfosWriter = codec.fieldInfosFormat().getFieldInfosWriter();\n    fieldInfosWriter.write(directory, segment, mergeState.fieldInfos, context);\n    return mergeState;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","date":1323437438,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#merge().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentMerger#merge().mjava","sourceNew":"  /**\n   * Merges the readers specified by the {@link #add} method into the directory passed to the constructor\n   * @return The number of documents that were merged\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  final MergeState merge() throws CorruptIndexException, IOException {\n    // NOTE: it's important to add calls to\n    // checkAbort.work(...) if you make any changes to this\n    // method that will spend alot of time.  The frequency\n    // of this check impacts how long\n    // IndexWriter.close(false) takes to actually stop the\n    // threads.\n    \n    final int numReaders = mergeState.readers.size();\n    // Remap docIDs\n    mergeState.docMaps = new int[numReaders][];\n    mergeState.docBase = new int[numReaders];\n    mergeState.dirPayloadProcessor = new PayloadProcessorProvider.DirPayloadProcessor[numReaders];\n    mergeState.currentPayloadProcessor = new PayloadProcessorProvider.PayloadProcessor[numReaders];\n\n    mergeFieldInfos();\n    setMatchingSegmentReaders();\n    mergeState.mergedDocCount = mergeFields();\n\n    final SegmentWriteState segmentWriteState = new SegmentWriteState(mergeState.infoStream, directory, segment, mergeState.fieldInfos, mergeState.mergedDocCount, termIndexInterval, codec, null, context);\n    mergeTerms(segmentWriteState);\n    mergePerDoc(segmentWriteState);\n    \n    if (mergeState.fieldInfos.hasNorms()) {\n      int numMerged = mergeNorms(segmentWriteState);\n      assert numMerged == mergeState.mergedDocCount;\n    }\n\n    if (mergeState.fieldInfos.hasVectors()) {\n      int numMerged = mergeVectors();\n      assert numMerged == mergeState.mergedDocCount;\n    }\n\n    return mergeState;\n  }\n\n","sourceOld":"  /**\n   * Merges the readers specified by the {@link #add} method into the directory passed to the constructor\n   * @return The number of documents that were merged\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  final MergeState merge() throws CorruptIndexException, IOException {\n    // NOTE: it's important to add calls to\n    // checkAbort.work(...) if you make any changes to this\n    // method that will spend alot of time.  The frequency\n    // of this check impacts how long\n    // IndexWriter.close(false) takes to actually stop the\n    // threads.\n    \n    final int numReaders = mergeState.readers.size();\n    // Remap docIDs\n    mergeState.docMaps = new int[numReaders][];\n    mergeState.docBase = new int[numReaders];\n    mergeState.dirPayloadProcessor = new PayloadProcessorProvider.DirPayloadProcessor[numReaders];\n    mergeState.currentPayloadProcessor = new PayloadProcessorProvider.PayloadProcessor[numReaders];\n\n    mergeFieldInfos();\n    setMatchingSegmentReaders();\n    mergeState.mergedDocCount = mergeFields();\n\n    final SegmentWriteState segmentWriteState = new SegmentWriteState(mergeState.infoStream, directory, segment, mergeState.fieldInfos, mergeState.mergedDocCount, termIndexInterval, codec, null, context);\n    mergeTerms(segmentWriteState);\n    mergePerDoc(segmentWriteState);\n    mergeNorms();\n\n    if (mergeState.fieldInfos.hasVectors()) {\n      int numMerged = mergeVectors();\n      assert numMerged == mergeState.mergedDocCount;\n    }\n\n    return mergeState;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d638301ad1cfcae567b681b893bc8781f0ee48a5","date":1323801546,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#merge().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentMerger#merge().mjava","sourceNew":"  /**\n   * Merges the readers specified by the {@link #add} method into the directory passed to the constructor\n   * @return The number of documents that were merged\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  final MergeState merge() throws CorruptIndexException, IOException {\n    // NOTE: it's important to add calls to\n    // checkAbort.work(...) if you make any changes to this\n    // method that will spend alot of time.  The frequency\n    // of this check impacts how long\n    // IndexWriter.close(false) takes to actually stop the\n    // threads.\n    \n    final int numReaders = mergeState.readers.size();\n    // Remap docIDs\n    mergeState.docMaps = new int[numReaders][];\n    mergeState.docBase = new int[numReaders];\n    mergeState.dirPayloadProcessor = new PayloadProcessorProvider.DirPayloadProcessor[numReaders];\n    mergeState.currentPayloadProcessor = new PayloadProcessorProvider.PayloadProcessor[numReaders];\n\n    mergeFieldInfos();\n    setMatchingSegmentReaders();\n    mergeState.mergedDocCount = mergeFields();\n\n    final SegmentWriteState segmentWriteState = new SegmentWriteState(mergeState.infoStream, directory, segment, mergeState.fieldInfos, mergeState.mergedDocCount, termIndexInterval, codec, null, context);\n    mergeTerms(segmentWriteState);\n    mergePerDoc(segmentWriteState);\n    \n    if (mergeState.fieldInfos.hasNorms()) {\n      int numMerged = mergeNorms(segmentWriteState);\n      assert numMerged == mergeState.mergedDocCount;\n    }\n\n    if (mergeState.fieldInfos.hasVectors()) {\n      int numMerged = mergeVectors();\n      assert numMerged == mergeState.mergedDocCount;\n    }\n\n    return mergeState;\n  }\n\n","sourceOld":"  /**\n   * Merges the readers specified by the {@link #add} method into the directory passed to the constructor\n   * @return The number of documents that were merged\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  final MergeState merge() throws CorruptIndexException, IOException {\n    // NOTE: it's important to add calls to\n    // checkAbort.work(...) if you make any changes to this\n    // method that will spend alot of time.  The frequency\n    // of this check impacts how long\n    // IndexWriter.close(false) takes to actually stop the\n    // threads.\n    \n    final int numReaders = mergeState.readers.size();\n    // Remap docIDs\n    mergeState.docMaps = new int[numReaders][];\n    mergeState.docBase = new int[numReaders];\n    mergeState.dirPayloadProcessor = new PayloadProcessorProvider.DirPayloadProcessor[numReaders];\n    mergeState.currentPayloadProcessor = new PayloadProcessorProvider.PayloadProcessor[numReaders];\n\n    mergeFieldInfos();\n    setMatchingSegmentReaders();\n    mergeState.mergedDocCount = mergeFields();\n\n    final SegmentWriteState segmentWriteState = new SegmentWriteState(mergeState.infoStream, directory, segment, mergeState.fieldInfos, mergeState.mergedDocCount, termIndexInterval, codec, null, context);\n    mergeTerms(segmentWriteState);\n    mergePerDoc(segmentWriteState);\n    \n    if (mergeState.fieldInfos.hasNorms()) {\n      int numMerged = mergeNorms(segmentWriteState);\n      assert numMerged == mergeState.mergedDocCount;\n    }\n\n    if (mergeState.fieldInfos.hasVectors()) {\n      int numMerged = mergeVectors();\n      assert numMerged == mergeState.mergedDocCount;\n    }\n    // write FIS once merge is done. IDV might change types or drops fields\n    FieldInfosWriter fieldInfosWriter = codec.fieldInfosFormat().getFieldInfosWriter();\n    fieldInfosWriter.write(directory, segment, mergeState.fieldInfos, context);\n    return mergeState;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f6e3376a314fcc2b31bc46d399c2ff23552b78d6","date":1325780477,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#merge().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentMerger#merge().mjava","sourceNew":"  /**\n   * Merges the readers specified by the {@link #add} method into the directory passed to the constructor\n   * @return The number of documents that were merged\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  final MergeState merge() throws CorruptIndexException, IOException {\n    // NOTE: it's important to add calls to\n    // checkAbort.work(...) if you make any changes to this\n    // method that will spend alot of time.  The frequency\n    // of this check impacts how long\n    // IndexWriter.close(false) takes to actually stop the\n    // threads.\n    \n    final int numReaders = mergeState.readers.size();\n    // Remap docIDs\n    mergeState.docMaps = new int[numReaders][];\n    mergeState.docBase = new int[numReaders];\n    mergeState.dirPayloadProcessor = new PayloadProcessorProvider.DirPayloadProcessor[numReaders];\n    mergeState.currentPayloadProcessor = new PayloadProcessorProvider.PayloadProcessor[numReaders];\n\n    mergeFieldInfos();\n    setMatchingSegmentReaders();\n    mergeState.mergedDocCount = mergeFields();\n\n    final SegmentWriteState segmentWriteState = new SegmentWriteState(mergeState.infoStream, directory, segment, mergeState.fieldInfos, mergeState.mergedDocCount, termIndexInterval, codec, null, context);\n    mergeTerms(segmentWriteState);\n    mergePerDoc(segmentWriteState);\n    \n    if (mergeState.fieldInfos.hasNorms()) {\n      mergeNorms(segmentWriteState);\n    }\n\n    if (mergeState.fieldInfos.hasVectors()) {\n      int numMerged = mergeVectors();\n      assert numMerged == mergeState.mergedDocCount;\n    }\n\n    return mergeState;\n  }\n\n","sourceOld":"  /**\n   * Merges the readers specified by the {@link #add} method into the directory passed to the constructor\n   * @return The number of documents that were merged\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  final MergeState merge() throws CorruptIndexException, IOException {\n    // NOTE: it's important to add calls to\n    // checkAbort.work(...) if you make any changes to this\n    // method that will spend alot of time.  The frequency\n    // of this check impacts how long\n    // IndexWriter.close(false) takes to actually stop the\n    // threads.\n    \n    final int numReaders = mergeState.readers.size();\n    // Remap docIDs\n    mergeState.docMaps = new int[numReaders][];\n    mergeState.docBase = new int[numReaders];\n    mergeState.dirPayloadProcessor = new PayloadProcessorProvider.DirPayloadProcessor[numReaders];\n    mergeState.currentPayloadProcessor = new PayloadProcessorProvider.PayloadProcessor[numReaders];\n\n    mergeFieldInfos();\n    setMatchingSegmentReaders();\n    mergeState.mergedDocCount = mergeFields();\n\n    final SegmentWriteState segmentWriteState = new SegmentWriteState(mergeState.infoStream, directory, segment, mergeState.fieldInfos, mergeState.mergedDocCount, termIndexInterval, codec, null, context);\n    mergeTerms(segmentWriteState);\n    mergePerDoc(segmentWriteState);\n    \n    if (mergeState.fieldInfos.hasNorms()) {\n      int numMerged = mergeNorms(segmentWriteState);\n      assert numMerged == mergeState.mergedDocCount;\n    }\n\n    if (mergeState.fieldInfos.hasVectors()) {\n      int numMerged = mergeVectors();\n      assert numMerged == mergeState.mergedDocCount;\n    }\n\n    return mergeState;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ccad4bab070f323ce610caa0040346d4a87213dc","date":1327747432,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#merge().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentMerger#merge().mjava","sourceNew":"  /**\n   * Merges the readers specified by the {@link #add} method into the directory passed to the constructor\n   * @return The number of documents that were merged\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  final MergeState merge() throws CorruptIndexException, IOException {\n    // NOTE: it's important to add calls to\n    // checkAbort.work(...) if you make any changes to this\n    // method that will spend alot of time.  The frequency\n    // of this check impacts how long\n    // IndexWriter.close(false) takes to actually stop the\n    // threads.\n    \n    setDocMaps();\n\n    mergeFieldInfos();\n    setMatchingSegmentReaders();\n    mergeState.mergedDocCount = mergeFields();\n\n    final SegmentWriteState segmentWriteState = new SegmentWriteState(mergeState.infoStream, directory, segment, mergeState.fieldInfos, mergeState.mergedDocCount, termIndexInterval, codec, null, context);\n    mergeTerms(segmentWriteState);\n    mergePerDoc(segmentWriteState);\n    \n    if (mergeState.fieldInfos.hasNorms()) {\n      mergeNorms(segmentWriteState);\n    }\n\n    if (mergeState.fieldInfos.hasVectors()) {\n      int numMerged = mergeVectors();\n      assert numMerged == mergeState.mergedDocCount;\n    }\n\n    return mergeState;\n  }\n\n","sourceOld":"  /**\n   * Merges the readers specified by the {@link #add} method into the directory passed to the constructor\n   * @return The number of documents that were merged\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  final MergeState merge() throws CorruptIndexException, IOException {\n    // NOTE: it's important to add calls to\n    // checkAbort.work(...) if you make any changes to this\n    // method that will spend alot of time.  The frequency\n    // of this check impacts how long\n    // IndexWriter.close(false) takes to actually stop the\n    // threads.\n    \n    final int numReaders = mergeState.readers.size();\n    // Remap docIDs\n    mergeState.docMaps = new int[numReaders][];\n    mergeState.docBase = new int[numReaders];\n    mergeState.dirPayloadProcessor = new PayloadProcessorProvider.DirPayloadProcessor[numReaders];\n    mergeState.currentPayloadProcessor = new PayloadProcessorProvider.PayloadProcessor[numReaders];\n\n    mergeFieldInfos();\n    setMatchingSegmentReaders();\n    mergeState.mergedDocCount = mergeFields();\n\n    final SegmentWriteState segmentWriteState = new SegmentWriteState(mergeState.infoStream, directory, segment, mergeState.fieldInfos, mergeState.mergedDocCount, termIndexInterval, codec, null, context);\n    mergeTerms(segmentWriteState);\n    mergePerDoc(segmentWriteState);\n    \n    if (mergeState.fieldInfos.hasNorms()) {\n      mergeNorms(segmentWriteState);\n    }\n\n    if (mergeState.fieldInfos.hasVectors()) {\n      int numMerged = mergeVectors();\n      assert numMerged == mergeState.mergedDocCount;\n    }\n\n    return mergeState;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5a6eeb3bd5b45df414522e8c152b36db43eb18bf","date":1327761784,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#merge().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentMerger#merge().mjava","sourceNew":"  /**\n   * Merges the readers specified by the {@link #add} method into the directory passed to the constructor\n   * @return The number of documents that were merged\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  final MergeState merge() throws CorruptIndexException, IOException {\n    // NOTE: it's important to add calls to\n    // checkAbort.work(...) if you make any changes to this\n    // method that will spend alot of time.  The frequency\n    // of this check impacts how long\n    // IndexWriter.close(false) takes to actually stop the\n    // threads.\n    \n    mergeState.mergedDocCount = setDocMaps();\n\n    mergeFieldInfos();\n    setMatchingSegmentReaders();\n    int numMerged = mergeFields();\n    assert numMerged == mergeState.mergedDocCount;\n\n    final SegmentWriteState segmentWriteState = new SegmentWriteState(mergeState.infoStream, directory, segment, mergeState.fieldInfos, mergeState.mergedDocCount, termIndexInterval, codec, null, context);\n    mergeTerms(segmentWriteState);\n    mergePerDoc(segmentWriteState);\n    \n    if (mergeState.fieldInfos.hasNorms()) {\n      mergeNorms(segmentWriteState);\n    }\n\n    if (mergeState.fieldInfos.hasVectors()) {\n      numMerged = mergeVectors();\n      assert numMerged == mergeState.mergedDocCount;\n    }\n\n    return mergeState;\n  }\n\n","sourceOld":"  /**\n   * Merges the readers specified by the {@link #add} method into the directory passed to the constructor\n   * @return The number of documents that were merged\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  final MergeState merge() throws CorruptIndexException, IOException {\n    // NOTE: it's important to add calls to\n    // checkAbort.work(...) if you make any changes to this\n    // method that will spend alot of time.  The frequency\n    // of this check impacts how long\n    // IndexWriter.close(false) takes to actually stop the\n    // threads.\n    \n    setDocMaps();\n\n    mergeFieldInfos();\n    setMatchingSegmentReaders();\n    mergeState.mergedDocCount = mergeFields();\n\n    final SegmentWriteState segmentWriteState = new SegmentWriteState(mergeState.infoStream, directory, segment, mergeState.fieldInfos, mergeState.mergedDocCount, termIndexInterval, codec, null, context);\n    mergeTerms(segmentWriteState);\n    mergePerDoc(segmentWriteState);\n    \n    if (mergeState.fieldInfos.hasNorms()) {\n      mergeNorms(segmentWriteState);\n    }\n\n    if (mergeState.fieldInfos.hasVectors()) {\n      int numMerged = mergeVectors();\n      assert numMerged == mergeState.mergedDocCount;\n    }\n\n    return mergeState;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c9f2d6bb11ccaac366d9b7652b2feb0c715d9c31","date":1327836826,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#merge().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentMerger#merge().mjava","sourceNew":"  /**\n   * Merges the readers specified by the {@link #add} method into the directory passed to the constructor\n   * @return The number of documents that were merged\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  final MergeState merge() throws CorruptIndexException, IOException {\n    // NOTE: it's important to add calls to\n    // checkAbort.work(...) if you make any changes to this\n    // method that will spend alot of time.  The frequency\n    // of this check impacts how long\n    // IndexWriter.close(false) takes to actually stop the\n    // threads.\n    \n    mergeState.mergedDocCount = setDocMaps();\n\n    mergeFieldInfos();\n    setMatchingSegmentReaders();\n    int numMerged = mergeFields();\n    assert numMerged == mergeState.mergedDocCount;\n\n    final SegmentWriteState segmentWriteState = new SegmentWriteState(mergeState.infoStream, directory, segment, mergeState.fieldInfos, mergeState.mergedDocCount, termIndexInterval, codec, null, context);\n    mergeTerms(segmentWriteState);\n    mergePerDoc(segmentWriteState);\n    \n    if (mergeState.fieldInfos.hasNorms()) {\n      mergeNorms(segmentWriteState);\n    }\n\n    if (mergeState.fieldInfos.hasVectors()) {\n      numMerged = mergeVectors();\n      assert numMerged == mergeState.mergedDocCount;\n    }\n\n    return mergeState;\n  }\n\n","sourceOld":"  /**\n   * Merges the readers specified by the {@link #add} method into the directory passed to the constructor\n   * @return The number of documents that were merged\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  final MergeState merge() throws CorruptIndexException, IOException {\n    // NOTE: it's important to add calls to\n    // checkAbort.work(...) if you make any changes to this\n    // method that will spend alot of time.  The frequency\n    // of this check impacts how long\n    // IndexWriter.close(false) takes to actually stop the\n    // threads.\n    \n    final int numReaders = mergeState.readers.size();\n    // Remap docIDs\n    mergeState.docMaps = new int[numReaders][];\n    mergeState.docBase = new int[numReaders];\n    mergeState.dirPayloadProcessor = new PayloadProcessorProvider.DirPayloadProcessor[numReaders];\n    mergeState.currentPayloadProcessor = new PayloadProcessorProvider.PayloadProcessor[numReaders];\n\n    mergeFieldInfos();\n    setMatchingSegmentReaders();\n    mergeState.mergedDocCount = mergeFields();\n\n    final SegmentWriteState segmentWriteState = new SegmentWriteState(mergeState.infoStream, directory, segment, mergeState.fieldInfos, mergeState.mergedDocCount, termIndexInterval, codec, null, context);\n    mergeTerms(segmentWriteState);\n    mergePerDoc(segmentWriteState);\n    \n    if (mergeState.fieldInfos.hasNorms()) {\n      mergeNorms(segmentWriteState);\n    }\n\n    if (mergeState.fieldInfos.hasVectors()) {\n      int numMerged = mergeVectors();\n      assert numMerged == mergeState.mergedDocCount;\n    }\n\n    return mergeState;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fd92b8bcc88e969302510acf77bd6970da3994c4","date":1327839530,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#merge().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentMerger#merge().mjava","sourceNew":"  /**\n   * Merges the readers specified by the {@link #add} method into the directory passed to the constructor\n   * @return The number of documents that were merged\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  final MergeState merge() throws CorruptIndexException, IOException {\n    // NOTE: it's important to add calls to\n    // checkAbort.work(...) if you make any changes to this\n    // method that will spend alot of time.  The frequency\n    // of this check impacts how long\n    // IndexWriter.close(false) takes to actually stop the\n    // threads.\n    \n    mergeState.mergedDocCount = setDocMaps();\n\n    mergeFieldInfos();\n    setMatchingSegmentReaders();\n    int numMerged = mergeFields();\n    assert numMerged == mergeState.mergedDocCount;\n\n    final SegmentWriteState segmentWriteState = new SegmentWriteState(mergeState.infoStream, directory, segment, mergeState.fieldInfos, mergeState.mergedDocCount, termIndexInterval, codec, null, context);\n    mergeTerms(segmentWriteState);\n    mergePerDoc(segmentWriteState);\n    \n    if (mergeState.fieldInfos.hasNorms()) {\n      mergeNorms(segmentWriteState);\n    }\n\n    if (mergeState.fieldInfos.hasVectors()) {\n      numMerged = mergeVectors();\n      assert numMerged == mergeState.mergedDocCount;\n    }\n\n    return mergeState;\n  }\n\n","sourceOld":"  /**\n   * Merges the readers specified by the {@link #add} method into the directory passed to the constructor\n   * @return The number of documents that were merged\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  final MergeState merge() throws CorruptIndexException, IOException {\n    // NOTE: it's important to add calls to\n    // checkAbort.work(...) if you make any changes to this\n    // method that will spend alot of time.  The frequency\n    // of this check impacts how long\n    // IndexWriter.close(false) takes to actually stop the\n    // threads.\n    \n    final int numReaders = mergeState.readers.size();\n    // Remap docIDs\n    mergeState.docMaps = new int[numReaders][];\n    mergeState.docBase = new int[numReaders];\n    mergeState.dirPayloadProcessor = new PayloadProcessorProvider.DirPayloadProcessor[numReaders];\n    mergeState.currentPayloadProcessor = new PayloadProcessorProvider.PayloadProcessor[numReaders];\n\n    mergeFieldInfos();\n    setMatchingSegmentReaders();\n    mergeState.mergedDocCount = mergeFields();\n\n    final SegmentWriteState segmentWriteState = new SegmentWriteState(mergeState.infoStream, directory, segment, mergeState.fieldInfos, mergeState.mergedDocCount, termIndexInterval, codec, null, context);\n    mergeTerms(segmentWriteState);\n    mergePerDoc(segmentWriteState);\n    \n    if (mergeState.fieldInfos.hasNorms()) {\n      mergeNorms(segmentWriteState);\n    }\n\n    if (mergeState.fieldInfos.hasVectors()) {\n      int numMerged = mergeVectors();\n      assert numMerged == mergeState.mergedDocCount;\n    }\n\n    return mergeState;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentMerger#merge().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentMerger#merge().mjava","sourceNew":"  /**\n   * Merges the readers specified by the {@link #add} method into the directory passed to the constructor\n   * @return The number of documents that were merged\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  final MergeState merge() throws CorruptIndexException, IOException {\n    // NOTE: it's important to add calls to\n    // checkAbort.work(...) if you make any changes to this\n    // method that will spend alot of time.  The frequency\n    // of this check impacts how long\n    // IndexWriter.close(false) takes to actually stop the\n    // threads.\n    \n    mergeState.mergedDocCount = setDocMaps();\n\n    mergeFieldInfos();\n    setMatchingSegmentReaders();\n    int numMerged = mergeFields();\n    assert numMerged == mergeState.mergedDocCount;\n\n    final SegmentWriteState segmentWriteState = new SegmentWriteState(mergeState.infoStream, directory, segment, mergeState.fieldInfos, mergeState.mergedDocCount, termIndexInterval, codec, null, context);\n    mergeTerms(segmentWriteState);\n    mergePerDoc(segmentWriteState);\n    \n    if (mergeState.fieldInfos.hasNorms()) {\n      mergeNorms(segmentWriteState);\n    }\n\n    if (mergeState.fieldInfos.hasVectors()) {\n      numMerged = mergeVectors();\n      assert numMerged == mergeState.mergedDocCount;\n    }\n\n    return mergeState;\n  }\n\n","sourceOld":"  /**\n   * Merges the readers specified by the {@link #add} method into the directory passed to the constructor\n   * @return The number of documents that were merged\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  final MergeState merge() throws CorruptIndexException, IOException {\n    // NOTE: it's important to add calls to\n    // checkAbort.work(...) if you make any changes to this\n    // method that will spend alot of time.  The frequency\n    // of this check impacts how long\n    // IndexWriter.close(false) takes to actually stop the\n    // threads.\n    \n    mergeState.mergedDocCount = setDocMaps();\n\n    mergeFieldInfos();\n    setMatchingSegmentReaders();\n    int numMerged = mergeFields();\n    assert numMerged == mergeState.mergedDocCount;\n\n    final SegmentWriteState segmentWriteState = new SegmentWriteState(mergeState.infoStream, directory, segment, mergeState.fieldInfos, mergeState.mergedDocCount, termIndexInterval, codec, null, context);\n    mergeTerms(segmentWriteState);\n    mergePerDoc(segmentWriteState);\n    \n    if (mergeState.fieldInfos.hasNorms()) {\n      mergeNorms(segmentWriteState);\n    }\n\n    if (mergeState.fieldInfos.hasVectors()) {\n      numMerged = mergeVectors();\n      assert numMerged == mergeState.mergedDocCount;\n    }\n\n    return mergeState;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"0061262413ecc163d6eebba1b5c43ab91a0c2dc5":["5a07ca455ec3f405a6078602f3f3dcf2d4fa8679"],"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00":["23c3a6c2ecb0c99396936e72e8998df877ea9ad5","3615ce4a1f785ae1b779244de52c6a7d99227e60"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["c9f2d6bb11ccaac366d9b7652b2feb0c715d9c31"],"fd92b8bcc88e969302510acf77bd6970da3994c4":["f6e3376a314fcc2b31bc46d399c2ff23552b78d6","c9f2d6bb11ccaac366d9b7652b2feb0c715d9c31"],"d638301ad1cfcae567b681b893bc8781f0ee48a5":["3615ce4a1f785ae1b779244de52c6a7d99227e60","ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00"],"2e8d7ba2175f47e280231533f7d3016249cea88b":["4948bc5d29211f0c9b5ccc31b2632cdd27066ea5","ab5cb6a74aefb78aa0569857970b9151dfe2e787"],"f0b9507caf22f292ac0e5e59f62db4275adf4511":["a02058e0eaba4bbd5d05e6b06b9522c0acfd1655","5a07ca455ec3f405a6078602f3f3dcf2d4fa8679"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"ccad4bab070f323ce610caa0040346d4a87213dc":["f6e3376a314fcc2b31bc46d399c2ff23552b78d6"],"f6e3376a314fcc2b31bc46d399c2ff23552b78d6":["d638301ad1cfcae567b681b893bc8781f0ee48a5"],"4948bc5d29211f0c9b5ccc31b2632cdd27066ea5":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"23c3a6c2ecb0c99396936e72e8998df877ea9ad5":["3cc749c053615f5871f3b95715fe292f34e70a53"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"833a7987bc1c94455fde83e3311f72bddedcfb93":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"a02058e0eaba4bbd5d05e6b06b9522c0acfd1655":["4948bc5d29211f0c9b5ccc31b2632cdd27066ea5","2e8d7ba2175f47e280231533f7d3016249cea88b"],"5a6eeb3bd5b45df414522e8c152b36db43eb18bf":["ccad4bab070f323ce610caa0040346d4a87213dc"],"06584e6e98d592b34e1329b384182f368d2025e8":["32aca6bb0a6aa0a1813e7d035ac0e039f54269f4"],"3cc749c053615f5871f3b95715fe292f34e70a53":["06584e6e98d592b34e1329b384182f368d2025e8"],"ab5cb6a74aefb78aa0569857970b9151dfe2e787":["9454a6510e2db155fb01faa5c049b06ece95fab9","4948bc5d29211f0c9b5ccc31b2632cdd27066ea5"],"f6ee314d4978b896d2a804ee60ba6e830624d990":["3cc749c053615f5871f3b95715fe292f34e70a53"],"1291e4568eb7d9463d751627596ef14baf4c1603":["2e8d7ba2175f47e280231533f7d3016249cea88b","5a07ca455ec3f405a6078602f3f3dcf2d4fa8679"],"3615ce4a1f785ae1b779244de52c6a7d99227e60":["3cc749c053615f5871f3b95715fe292f34e70a53","f6ee314d4978b896d2a804ee60ba6e830624d990"],"5a07ca455ec3f405a6078602f3f3dcf2d4fa8679":["2e8d7ba2175f47e280231533f7d3016249cea88b"],"c9f2d6bb11ccaac366d9b7652b2feb0c715d9c31":["f6e3376a314fcc2b31bc46d399c2ff23552b78d6","5a6eeb3bd5b45df414522e8c152b36db43eb18bf"],"32aca6bb0a6aa0a1813e7d035ac0e039f54269f4":["0061262413ecc163d6eebba1b5c43ab91a0c2dc5"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"]},"commit2Childs":{"0061262413ecc163d6eebba1b5c43ab91a0c2dc5":["32aca6bb0a6aa0a1813e7d035ac0e039f54269f4"],"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00":["d638301ad1cfcae567b681b893bc8781f0ee48a5"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"fd92b8bcc88e969302510acf77bd6970da3994c4":[],"d638301ad1cfcae567b681b893bc8781f0ee48a5":["f6e3376a314fcc2b31bc46d399c2ff23552b78d6"],"2e8d7ba2175f47e280231533f7d3016249cea88b":["a02058e0eaba4bbd5d05e6b06b9522c0acfd1655","1291e4568eb7d9463d751627596ef14baf4c1603","5a07ca455ec3f405a6078602f3f3dcf2d4fa8679"],"f0b9507caf22f292ac0e5e59f62db4275adf4511":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"ccad4bab070f323ce610caa0040346d4a87213dc":["5a6eeb3bd5b45df414522e8c152b36db43eb18bf"],"f6e3376a314fcc2b31bc46d399c2ff23552b78d6":["fd92b8bcc88e969302510acf77bd6970da3994c4","ccad4bab070f323ce610caa0040346d4a87213dc","c9f2d6bb11ccaac366d9b7652b2feb0c715d9c31"],"4948bc5d29211f0c9b5ccc31b2632cdd27066ea5":["2e8d7ba2175f47e280231533f7d3016249cea88b","a02058e0eaba4bbd5d05e6b06b9522c0acfd1655","ab5cb6a74aefb78aa0569857970b9151dfe2e787"],"23c3a6c2ecb0c99396936e72e8998df877ea9ad5":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["4948bc5d29211f0c9b5ccc31b2632cdd27066ea5","833a7987bc1c94455fde83e3311f72bddedcfb93","ab5cb6a74aefb78aa0569857970b9151dfe2e787"],"833a7987bc1c94455fde83e3311f72bddedcfb93":[],"a02058e0eaba4bbd5d05e6b06b9522c0acfd1655":["f0b9507caf22f292ac0e5e59f62db4275adf4511"],"5a6eeb3bd5b45df414522e8c152b36db43eb18bf":["c9f2d6bb11ccaac366d9b7652b2feb0c715d9c31"],"06584e6e98d592b34e1329b384182f368d2025e8":["3cc749c053615f5871f3b95715fe292f34e70a53"],"ab5cb6a74aefb78aa0569857970b9151dfe2e787":["2e8d7ba2175f47e280231533f7d3016249cea88b"],"3cc749c053615f5871f3b95715fe292f34e70a53":["23c3a6c2ecb0c99396936e72e8998df877ea9ad5","f6ee314d4978b896d2a804ee60ba6e830624d990","3615ce4a1f785ae1b779244de52c6a7d99227e60"],"f6ee314d4978b896d2a804ee60ba6e830624d990":["3615ce4a1f785ae1b779244de52c6a7d99227e60"],"1291e4568eb7d9463d751627596ef14baf4c1603":[],"3615ce4a1f785ae1b779244de52c6a7d99227e60":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","d638301ad1cfcae567b681b893bc8781f0ee48a5"],"5a07ca455ec3f405a6078602f3f3dcf2d4fa8679":["0061262413ecc163d6eebba1b5c43ab91a0c2dc5","f0b9507caf22f292ac0e5e59f62db4275adf4511","1291e4568eb7d9463d751627596ef14baf4c1603"],"c9f2d6bb11ccaac366d9b7652b2feb0c715d9c31":["3a119bbc8703c10faa329ec201c654b3a35a1e3e","fd92b8bcc88e969302510acf77bd6970da3994c4"],"32aca6bb0a6aa0a1813e7d035ac0e039f54269f4":["06584e6e98d592b34e1329b384182f368d2025e8"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["fd92b8bcc88e969302510acf77bd6970da3994c4","f0b9507caf22f292ac0e5e59f62db4275adf4511","833a7987bc1c94455fde83e3311f72bddedcfb93","1291e4568eb7d9463d751627596ef14baf4c1603","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}