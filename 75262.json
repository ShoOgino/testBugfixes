{"path":"lucene/src/java/org/apache/lucene/index/BufferedDeletesStream#applyTermDeletes(Iterable[Term],SegmentReader).mjava","commits":[{"id":"69a6d2d525aeab53c867ed26934185e5bb627d0e","date":1296516902,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/BufferedDeletesStream#applyTermDeletes(Iterable[Term],SegmentReader).mjava","pathOld":"/dev/null","sourceNew":"  // Delete by Term\n  private synchronized long applyTermDeletes(Iterable<Term> termsIter, SegmentReader reader) throws IOException {\n    long delCount = 0;\n    Fields fields = reader.fields();\n    if (fields == null) {\n      // This reader has no postings\n      return 0;\n    }\n\n    TermsEnum termsEnum = null;\n        \n    String currentField = null;\n    DocsEnum docs = null;\n        \n    assert checkDeleteTerm(null);\n\n    for (Term term : termsIter) {\n      // Since we visit terms sorted, we gain performance\n      // by re-using the same TermsEnum and seeking only\n      // forwards\n      if (term.field() != currentField) {\n        assert currentField == null || currentField.compareTo(term.field()) < 0;\n        currentField = term.field();\n        Terms terms = fields.terms(currentField);\n        if (terms != null) {\n          termsEnum = terms.iterator();\n        } else {\n          termsEnum = null;\n        }\n      }\n\n      if (termsEnum == null) {\n        continue;\n      }\n      assert checkDeleteTerm(term);\n\n      // System.out.println(\"  term=\" + term);\n          \n      if (termsEnum.seek(term.bytes(), false) == TermsEnum.SeekStatus.FOUND) {\n        DocsEnum docsEnum = termsEnum.docs(reader.getDeletedDocs(), docs);\n            \n        if (docsEnum != null) {\n          while (true) {\n            final int docID = docsEnum.nextDoc();\n            if (docID == DocsEnum.NO_MORE_DOCS) {\n              break;\n            }\n            reader.deleteDocument(docID);\n            // TODO: we could/should change\n            // reader.deleteDocument to return boolean\n            // true if it did in fact delete, because here\n            // we could be deleting an already-deleted doc\n            // which makes this an upper bound:\n            delCount++;\n          }\n        }\n      }\n    }\n\n    return delCount;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["c00afe74a80796ed1f30a9509b150ff104746a1f","8028ab7a24273833d53d35eb160dba5b57283cf5","8028ab7a24273833d53d35eb160dba5b57283cf5"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"29ef99d61cda9641b6250bf9567329a6e65f901d","date":1297244127,"type":0,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/BufferedDeletesStream#applyTermDeletes(Iterable[Term],SegmentReader).mjava","pathOld":"/dev/null","sourceNew":"  // Delete by Term\n  private synchronized long applyTermDeletes(Iterable<Term> termsIter, SegmentReader reader) throws IOException {\n    long delCount = 0;\n    Fields fields = reader.fields();\n    if (fields == null) {\n      // This reader has no postings\n      return 0;\n    }\n\n    TermsEnum termsEnum = null;\n        \n    String currentField = null;\n    DocsEnum docs = null;\n        \n    assert checkDeleteTerm(null);\n\n    for (Term term : termsIter) {\n      // Since we visit terms sorted, we gain performance\n      // by re-using the same TermsEnum and seeking only\n      // forwards\n      if (term.field() != currentField) {\n        assert currentField == null || currentField.compareTo(term.field()) < 0;\n        currentField = term.field();\n        Terms terms = fields.terms(currentField);\n        if (terms != null) {\n          termsEnum = terms.iterator();\n        } else {\n          termsEnum = null;\n        }\n      }\n\n      if (termsEnum == null) {\n        continue;\n      }\n      assert checkDeleteTerm(term);\n\n      // System.out.println(\"  term=\" + term);\n          \n      if (termsEnum.seek(term.bytes(), false) == TermsEnum.SeekStatus.FOUND) {\n        DocsEnum docsEnum = termsEnum.docs(reader.getDeletedDocs(), docs);\n            \n        if (docsEnum != null) {\n          while (true) {\n            final int docID = docsEnum.nextDoc();\n            if (docID == DocsEnum.NO_MORE_DOCS) {\n              break;\n            }\n            reader.deleteDocument(docID);\n            // TODO: we could/should change\n            // reader.deleteDocument to return boolean\n            // true if it did in fact delete, because here\n            // we could be deleting an already-deleted doc\n            // which makes this an upper bound:\n            delCount++;\n          }\n        }\n      }\n    }\n\n    return delCount;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bde51b089eb7f86171eb3406e38a274743f9b7ac","date":1298336439,"type":0,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/BufferedDeletesStream#applyTermDeletes(Iterable[Term],SegmentReader).mjava","pathOld":"/dev/null","sourceNew":"  // Delete by Term\n  private synchronized long applyTermDeletes(Iterable<Term> termsIter, SegmentReader reader) throws IOException {\n    long delCount = 0;\n    Fields fields = reader.fields();\n    if (fields == null) {\n      // This reader has no postings\n      return 0;\n    }\n\n    TermsEnum termsEnum = null;\n\n    String currentField = null;\n    DocsEnum docs = null;\n\n    assert checkDeleteTerm(null);\n\n    for (Term term : termsIter) {\n      // Since we visit terms sorted, we gain performance\n      // by re-using the same TermsEnum and seeking only\n      // forwards\n      if (term.field() != currentField) {\n        assert currentField == null || currentField.compareTo(term.field()) < 0;\n        currentField = term.field();\n        Terms terms = fields.terms(currentField);\n        if (terms != null) {\n          termsEnum = terms.iterator();\n        } else {\n          termsEnum = null;\n        }\n      }\n\n      if (termsEnum == null) {\n        continue;\n      }\n      assert checkDeleteTerm(term);\n\n      // System.out.println(\"  term=\" + term);\n\n      if (termsEnum.seek(term.bytes(), false) == TermsEnum.SeekStatus.FOUND) {\n        DocsEnum docsEnum = termsEnum.docs(reader.getDeletedDocs(), docs);\n\n        if (docsEnum != null) {\n          while (true) {\n            final int docID = docsEnum.nextDoc();\n            if (docID == DocsEnum.NO_MORE_DOCS) {\n              break;\n            }\n            reader.deleteDocument(docID);\n            // TODO: we could/should change\n            // reader.deleteDocument to return boolean\n            // true if it did in fact delete, because here\n            // we could be deleting an already-deleted doc\n            // which makes this an upper bound:\n            delCount++;\n          }\n        }\n      }\n    }\n\n    return delCount;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b3e06be49006ecac364d39d12b9c9f74882f9b9f","date":1304289513,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/BufferedDeletesStream#applyTermDeletes(Iterable[Term],SegmentReader).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/BufferedDeletesStream#applyTermDeletes(Iterable[Term],SegmentReader).mjava","sourceNew":"  // Delete by Term\n  private synchronized long applyTermDeletes(Iterable<Term> termsIter, SegmentReader reader) throws IOException {\n    long delCount = 0;\n    Fields fields = reader.fields();\n    if (fields == null) {\n      // This reader has no postings\n      return 0;\n    }\n\n    TermsEnum termsEnum = null;\n\n    String currentField = null;\n    DocsEnum docs = null;\n\n    assert checkDeleteTerm(null);\n\n    for (Term term : termsIter) {\n      // Since we visit terms sorted, we gain performance\n      // by re-using the same TermsEnum and seeking only\n      // forwards\n      if (term.field() != currentField) {\n        assert currentField == null || currentField.compareTo(term.field()) < 0;\n        currentField = term.field();\n        Terms terms = fields.terms(currentField);\n        if (terms != null) {\n          termsEnum = terms.iterator();\n        } else {\n          termsEnum = null;\n        }\n      }\n\n      if (termsEnum == null) {\n        continue;\n      }\n      assert checkDeleteTerm(term);\n\n      // System.out.println(\"  term=\" + term);\n\n      if (termsEnum.seek(term.bytes(), false) == TermsEnum.SeekStatus.FOUND) {\n        DocsEnum docsEnum = termsEnum.docs(reader.getDeletedDocs(), docs);\n\n        if (docsEnum != null) {\n          while (true) {\n            final int docID = docsEnum.nextDoc();\n            if (docID == DocsEnum.NO_MORE_DOCS) {\n              break;\n            }\n            reader.deleteDocument(docID);\n            // TODO: we could/should change\n            // reader.deleteDocument to return boolean\n            // true if it did in fact delete, because here\n            // we could be deleting an already-deleted doc\n            // which makes this an upper bound:\n            delCount++;\n          }\n        }\n      }\n    }\n\n    return delCount;\n  }\n\n","sourceOld":"  // Delete by Term\n  private synchronized long applyTermDeletes(Iterable<Term> termsIter, SegmentReader reader) throws IOException {\n    long delCount = 0;\n    Fields fields = reader.fields();\n    if (fields == null) {\n      // This reader has no postings\n      return 0;\n    }\n\n    TermsEnum termsEnum = null;\n        \n    String currentField = null;\n    DocsEnum docs = null;\n        \n    assert checkDeleteTerm(null);\n\n    for (Term term : termsIter) {\n      // Since we visit terms sorted, we gain performance\n      // by re-using the same TermsEnum and seeking only\n      // forwards\n      if (term.field() != currentField) {\n        assert currentField == null || currentField.compareTo(term.field()) < 0;\n        currentField = term.field();\n        Terms terms = fields.terms(currentField);\n        if (terms != null) {\n          termsEnum = terms.iterator();\n        } else {\n          termsEnum = null;\n        }\n      }\n\n      if (termsEnum == null) {\n        continue;\n      }\n      assert checkDeleteTerm(term);\n\n      // System.out.println(\"  term=\" + term);\n          \n      if (termsEnum.seek(term.bytes(), false) == TermsEnum.SeekStatus.FOUND) {\n        DocsEnum docsEnum = termsEnum.docs(reader.getDeletedDocs(), docs);\n            \n        if (docsEnum != null) {\n          while (true) {\n            final int docID = docsEnum.nextDoc();\n            if (docID == DocsEnum.NO_MORE_DOCS) {\n              break;\n            }\n            reader.deleteDocument(docID);\n            // TODO: we could/should change\n            // reader.deleteDocument to return boolean\n            // true if it did in fact delete, because here\n            // we could be deleting an already-deleted doc\n            // which makes this an upper bound:\n            delCount++;\n          }\n        }\n      }\n    }\n\n    return delCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"135621f3a0670a9394eb563224a3b76cc4dddc0f","date":1304344257,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/BufferedDeletesStream#applyTermDeletes(Iterable[Term],SegmentReader).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/BufferedDeletesStream#applyTermDeletes(Iterable[Term],SegmentReader).mjava","sourceNew":"  // Delete by Term\n  private synchronized long applyTermDeletes(Iterable<Term> termsIter, SegmentReader reader) throws IOException {\n    long delCount = 0;\n    Fields fields = reader.fields();\n    if (fields == null) {\n      // This reader has no postings\n      return 0;\n    }\n\n    TermsEnum termsEnum = null;\n\n    String currentField = null;\n    DocsEnum docs = null;\n\n    assert checkDeleteTerm(null);\n\n    for (Term term : termsIter) {\n      // Since we visit terms sorted, we gain performance\n      // by re-using the same TermsEnum and seeking only\n      // forwards\n      if (term.field() != currentField) {\n        assert currentField == null || currentField.compareTo(term.field()) < 0;\n        currentField = term.field();\n        Terms terms = fields.terms(currentField);\n        if (terms != null) {\n          termsEnum = terms.iterator();\n        } else {\n          termsEnum = null;\n        }\n      }\n\n      if (termsEnum == null) {\n        continue;\n      }\n      assert checkDeleteTerm(term);\n\n      // System.out.println(\"  term=\" + term);\n\n      if (termsEnum.seek(term.bytes(), false) == TermsEnum.SeekStatus.FOUND) {\n        DocsEnum docsEnum = termsEnum.docs(reader.getDeletedDocs(), docs);\n\n        if (docsEnum != null) {\n          while (true) {\n            final int docID = docsEnum.nextDoc();\n            if (docID == DocsEnum.NO_MORE_DOCS) {\n              break;\n            }\n            reader.deleteDocument(docID);\n            // TODO: we could/should change\n            // reader.deleteDocument to return boolean\n            // true if it did in fact delete, because here\n            // we could be deleting an already-deleted doc\n            // which makes this an upper bound:\n            delCount++;\n          }\n        }\n      }\n    }\n\n    return delCount;\n  }\n\n","sourceOld":"  // Delete by Term\n  private synchronized long applyTermDeletes(Iterable<Term> termsIter, SegmentReader reader) throws IOException {\n    long delCount = 0;\n    Fields fields = reader.fields();\n    if (fields == null) {\n      // This reader has no postings\n      return 0;\n    }\n\n    TermsEnum termsEnum = null;\n        \n    String currentField = null;\n    DocsEnum docs = null;\n        \n    assert checkDeleteTerm(null);\n\n    for (Term term : termsIter) {\n      // Since we visit terms sorted, we gain performance\n      // by re-using the same TermsEnum and seeking only\n      // forwards\n      if (term.field() != currentField) {\n        assert currentField == null || currentField.compareTo(term.field()) < 0;\n        currentField = term.field();\n        Terms terms = fields.terms(currentField);\n        if (terms != null) {\n          termsEnum = terms.iterator();\n        } else {\n          termsEnum = null;\n        }\n      }\n\n      if (termsEnum == null) {\n        continue;\n      }\n      assert checkDeleteTerm(term);\n\n      // System.out.println(\"  term=\" + term);\n          \n      if (termsEnum.seek(term.bytes(), false) == TermsEnum.SeekStatus.FOUND) {\n        DocsEnum docsEnum = termsEnum.docs(reader.getDeletedDocs(), docs);\n            \n        if (docsEnum != null) {\n          while (true) {\n            final int docID = docsEnum.nextDoc();\n            if (docID == DocsEnum.NO_MORE_DOCS) {\n              break;\n            }\n            reader.deleteDocument(docID);\n            // TODO: we could/should change\n            // reader.deleteDocument to return boolean\n            // true if it did in fact delete, because here\n            // we could be deleting an already-deleted doc\n            // which makes this an upper bound:\n            delCount++;\n          }\n        }\n      }\n    }\n\n    return delCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/BufferedDeletesStream#applyTermDeletes(Iterable[Term],SegmentReader).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/BufferedDeletesStream#applyTermDeletes(Iterable[Term],SegmentReader).mjava","sourceNew":"  // Delete by Term\n  private synchronized long applyTermDeletes(Iterable<Term> termsIter, SegmentReader reader) throws IOException {\n    long delCount = 0;\n    Fields fields = reader.fields();\n    if (fields == null) {\n      // This reader has no postings\n      return 0;\n    }\n\n    TermsEnum termsEnum = null;\n\n    String currentField = null;\n    DocsEnum docs = null;\n\n    assert checkDeleteTerm(null);\n\n    for (Term term : termsIter) {\n      // Since we visit terms sorted, we gain performance\n      // by re-using the same TermsEnum and seeking only\n      // forwards\n      if (term.field() != currentField) {\n        assert currentField == null || currentField.compareTo(term.field()) < 0;\n        currentField = term.field();\n        Terms terms = fields.terms(currentField);\n        if (terms != null) {\n          termsEnum = terms.iterator();\n        } else {\n          termsEnum = null;\n        }\n      }\n\n      if (termsEnum == null) {\n        continue;\n      }\n      assert checkDeleteTerm(term);\n\n      // System.out.println(\"  term=\" + term);\n\n      if (termsEnum.seek(term.bytes(), false) == TermsEnum.SeekStatus.FOUND) {\n        DocsEnum docsEnum = termsEnum.docs(reader.getDeletedDocs(), docs);\n\n        if (docsEnum != null) {\n          while (true) {\n            final int docID = docsEnum.nextDoc();\n            if (docID == DocsEnum.NO_MORE_DOCS) {\n              break;\n            }\n            reader.deleteDocument(docID);\n            // TODO: we could/should change\n            // reader.deleteDocument to return boolean\n            // true if it did in fact delete, because here\n            // we could be deleting an already-deleted doc\n            // which makes this an upper bound:\n            delCount++;\n          }\n        }\n      }\n    }\n\n    return delCount;\n  }\n\n","sourceOld":"  // Delete by Term\n  private synchronized long applyTermDeletes(Iterable<Term> termsIter, SegmentReader reader) throws IOException {\n    long delCount = 0;\n    Fields fields = reader.fields();\n    if (fields == null) {\n      // This reader has no postings\n      return 0;\n    }\n\n    TermsEnum termsEnum = null;\n        \n    String currentField = null;\n    DocsEnum docs = null;\n        \n    assert checkDeleteTerm(null);\n\n    for (Term term : termsIter) {\n      // Since we visit terms sorted, we gain performance\n      // by re-using the same TermsEnum and seeking only\n      // forwards\n      if (term.field() != currentField) {\n        assert currentField == null || currentField.compareTo(term.field()) < 0;\n        currentField = term.field();\n        Terms terms = fields.terms(currentField);\n        if (terms != null) {\n          termsEnum = terms.iterator();\n        } else {\n          termsEnum = null;\n        }\n      }\n\n      if (termsEnum == null) {\n        continue;\n      }\n      assert checkDeleteTerm(term);\n\n      // System.out.println(\"  term=\" + term);\n          \n      if (termsEnum.seek(term.bytes(), false) == TermsEnum.SeekStatus.FOUND) {\n        DocsEnum docsEnum = termsEnum.docs(reader.getDeletedDocs(), docs);\n            \n        if (docsEnum != null) {\n          while (true) {\n            final int docID = docsEnum.nextDoc();\n            if (docID == DocsEnum.NO_MORE_DOCS) {\n              break;\n            }\n            reader.deleteDocument(docID);\n            // TODO: we could/should change\n            // reader.deleteDocument to return boolean\n            // true if it did in fact delete, because here\n            // we could be deleting an already-deleted doc\n            // which makes this an upper bound:\n            delCount++;\n          }\n        }\n      }\n    }\n\n    return delCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fafef7c83fe8e0b3ca9298d5d75d6b943dc28153","date":1308670974,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/BufferedDeletesStream#applyTermDeletes(Iterable[Term],SegmentReader).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/BufferedDeletesStream#applyTermDeletes(Iterable[Term],SegmentReader).mjava","sourceNew":"  // Delete by Term\n  private synchronized long applyTermDeletes(Iterable<Term> termsIter, SegmentReader reader) throws IOException {\n    long delCount = 0;\n    Fields fields = reader.fields();\n    if (fields == null) {\n      // This reader has no postings\n      return 0;\n    }\n\n    TermsEnum termsEnum = null;\n\n    String currentField = null;\n    DocsEnum docs = null;\n\n    assert checkDeleteTerm(null);\n\n    for (Term term : termsIter) {\n      // Since we visit terms sorted, we gain performance\n      // by re-using the same TermsEnum and seeking only\n      // forwards\n      if (!term.field().equals(currentField)) {\n        assert currentField == null || currentField.compareTo(term.field()) < 0;\n        currentField = term.field();\n        Terms terms = fields.terms(currentField);\n        if (terms != null) {\n          termsEnum = terms.iterator();\n        } else {\n          termsEnum = null;\n        }\n      }\n\n      if (termsEnum == null) {\n        continue;\n      }\n      assert checkDeleteTerm(term);\n\n      // System.out.println(\"  term=\" + term);\n\n      if (termsEnum.seek(term.bytes(), false) == TermsEnum.SeekStatus.FOUND) {\n        DocsEnum docsEnum = termsEnum.docs(reader.getDeletedDocs(), docs);\n\n        if (docsEnum != null) {\n          while (true) {\n            final int docID = docsEnum.nextDoc();\n            if (docID == DocsEnum.NO_MORE_DOCS) {\n              break;\n            }\n            reader.deleteDocument(docID);\n            // TODO: we could/should change\n            // reader.deleteDocument to return boolean\n            // true if it did in fact delete, because here\n            // we could be deleting an already-deleted doc\n            // which makes this an upper bound:\n            delCount++;\n          }\n        }\n      }\n    }\n\n    return delCount;\n  }\n\n","sourceOld":"  // Delete by Term\n  private synchronized long applyTermDeletes(Iterable<Term> termsIter, SegmentReader reader) throws IOException {\n    long delCount = 0;\n    Fields fields = reader.fields();\n    if (fields == null) {\n      // This reader has no postings\n      return 0;\n    }\n\n    TermsEnum termsEnum = null;\n\n    String currentField = null;\n    DocsEnum docs = null;\n\n    assert checkDeleteTerm(null);\n\n    for (Term term : termsIter) {\n      // Since we visit terms sorted, we gain performance\n      // by re-using the same TermsEnum and seeking only\n      // forwards\n      if (term.field() != currentField) {\n        assert currentField == null || currentField.compareTo(term.field()) < 0;\n        currentField = term.field();\n        Terms terms = fields.terms(currentField);\n        if (terms != null) {\n          termsEnum = terms.iterator();\n        } else {\n          termsEnum = null;\n        }\n      }\n\n      if (termsEnum == null) {\n        continue;\n      }\n      assert checkDeleteTerm(term);\n\n      // System.out.println(\"  term=\" + term);\n\n      if (termsEnum.seek(term.bytes(), false) == TermsEnum.SeekStatus.FOUND) {\n        DocsEnum docsEnum = termsEnum.docs(reader.getDeletedDocs(), docs);\n\n        if (docsEnum != null) {\n          while (true) {\n            final int docID = docsEnum.nextDoc();\n            if (docID == DocsEnum.NO_MORE_DOCS) {\n              break;\n            }\n            reader.deleteDocument(docID);\n            // TODO: we could/should change\n            // reader.deleteDocument to return boolean\n            // true if it did in fact delete, because here\n            // we could be deleting an already-deleted doc\n            // which makes this an upper bound:\n            delCount++;\n          }\n        }\n      }\n    }\n\n    return delCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fd9cc9d77712aba3662f24632df7539ab75e3667","date":1309095238,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/BufferedDeletesStream#applyTermDeletes(Iterable[Term],SegmentReader).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/BufferedDeletesStream#applyTermDeletes(Iterable[Term],SegmentReader).mjava","sourceNew":"  // Delete by Term\n  private synchronized long applyTermDeletes(Iterable<Term> termsIter, SegmentReader reader) throws IOException {\n    long delCount = 0;\n    Fields fields = reader.fields();\n    if (fields == null) {\n      // This reader has no postings\n      return 0;\n    }\n\n    TermsEnum termsEnum = null;\n\n    String currentField = null;\n    DocsEnum docs = null;\n\n    assert checkDeleteTerm(null);\n\n    for (Term term : termsIter) {\n      // Since we visit terms sorted, we gain performance\n      // by re-using the same TermsEnum and seeking only\n      // forwards\n      if (!term.field().equals(currentField)) {\n        assert currentField == null || currentField.compareTo(term.field()) < 0;\n        currentField = term.field();\n        Terms terms = fields.terms(currentField);\n        if (terms != null) {\n          termsEnum = terms.iterator();\n        } else {\n          termsEnum = null;\n        }\n      }\n\n      if (termsEnum == null) {\n        continue;\n      }\n      assert checkDeleteTerm(term);\n\n      // System.out.println(\"  term=\" + term);\n\n      if (termsEnum.seekExact(term.bytes(), false)) {\n        DocsEnum docsEnum = termsEnum.docs(reader.getDeletedDocs(), docs);\n\n        if (docsEnum != null) {\n          while (true) {\n            final int docID = docsEnum.nextDoc();\n            if (docID == DocsEnum.NO_MORE_DOCS) {\n              break;\n            }\n            reader.deleteDocument(docID);\n            // TODO: we could/should change\n            // reader.deleteDocument to return boolean\n            // true if it did in fact delete, because here\n            // we could be deleting an already-deleted doc\n            // which makes this an upper bound:\n            delCount++;\n          }\n        }\n      }\n    }\n\n    return delCount;\n  }\n\n","sourceOld":"  // Delete by Term\n  private synchronized long applyTermDeletes(Iterable<Term> termsIter, SegmentReader reader) throws IOException {\n    long delCount = 0;\n    Fields fields = reader.fields();\n    if (fields == null) {\n      // This reader has no postings\n      return 0;\n    }\n\n    TermsEnum termsEnum = null;\n\n    String currentField = null;\n    DocsEnum docs = null;\n\n    assert checkDeleteTerm(null);\n\n    for (Term term : termsIter) {\n      // Since we visit terms sorted, we gain performance\n      // by re-using the same TermsEnum and seeking only\n      // forwards\n      if (!term.field().equals(currentField)) {\n        assert currentField == null || currentField.compareTo(term.field()) < 0;\n        currentField = term.field();\n        Terms terms = fields.terms(currentField);\n        if (terms != null) {\n          termsEnum = terms.iterator();\n        } else {\n          termsEnum = null;\n        }\n      }\n\n      if (termsEnum == null) {\n        continue;\n      }\n      assert checkDeleteTerm(term);\n\n      // System.out.println(\"  term=\" + term);\n\n      if (termsEnum.seek(term.bytes(), false) == TermsEnum.SeekStatus.FOUND) {\n        DocsEnum docsEnum = termsEnum.docs(reader.getDeletedDocs(), docs);\n\n        if (docsEnum != null) {\n          while (true) {\n            final int docID = docsEnum.nextDoc();\n            if (docID == DocsEnum.NO_MORE_DOCS) {\n              break;\n            }\n            reader.deleteDocument(docID);\n            // TODO: we could/should change\n            // reader.deleteDocument to return boolean\n            // true if it did in fact delete, because here\n            // we could be deleting an already-deleted doc\n            // which makes this an upper bound:\n            delCount++;\n          }\n        }\n      }\n    }\n\n    return delCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2553b00f699380c64959ccb27991289aae87be2e","date":1309290151,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/BufferedDeletesStream#applyTermDeletes(Iterable[Term],SegmentReader).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/BufferedDeletesStream#applyTermDeletes(Iterable[Term],SegmentReader).mjava","sourceNew":"  // Delete by Term\n  private synchronized long applyTermDeletes(Iterable<Term> termsIter, SegmentReader reader) throws IOException {\n    long delCount = 0;\n    Fields fields = reader.fields();\n    if (fields == null) {\n      // This reader has no postings\n      return 0;\n    }\n\n    TermsEnum termsEnum = null;\n\n    String currentField = null;\n    DocsEnum docs = null;\n\n    assert checkDeleteTerm(null);\n\n    for (Term term : termsIter) {\n      // Since we visit terms sorted, we gain performance\n      // by re-using the same TermsEnum and seeking only\n      // forwards\n      if (!term.field().equals(currentField)) {\n        assert currentField == null || currentField.compareTo(term.field()) < 0;\n        currentField = term.field();\n        Terms terms = fields.terms(currentField);\n        if (terms != null) {\n          termsEnum = terms.iterator();\n        } else {\n          termsEnum = null;\n        }\n      }\n\n      if (termsEnum == null) {\n        continue;\n      }\n      assert checkDeleteTerm(term);\n\n      // System.out.println(\"  term=\" + term);\n\n      if (termsEnum.seekExact(term.bytes(), false)) {\n        DocsEnum docsEnum = termsEnum.docs(reader.getDeletedDocs(), docs);\n\n        if (docsEnum != null) {\n          while (true) {\n            final int docID = docsEnum.nextDoc();\n            if (docID == DocsEnum.NO_MORE_DOCS) {\n              break;\n            }\n            reader.deleteDocument(docID);\n            // TODO: we could/should change\n            // reader.deleteDocument to return boolean\n            // true if it did in fact delete, because here\n            // we could be deleting an already-deleted doc\n            // which makes this an upper bound:\n            delCount++;\n          }\n        }\n      }\n    }\n\n    return delCount;\n  }\n\n","sourceOld":"  // Delete by Term\n  private synchronized long applyTermDeletes(Iterable<Term> termsIter, SegmentReader reader) throws IOException {\n    long delCount = 0;\n    Fields fields = reader.fields();\n    if (fields == null) {\n      // This reader has no postings\n      return 0;\n    }\n\n    TermsEnum termsEnum = null;\n\n    String currentField = null;\n    DocsEnum docs = null;\n\n    assert checkDeleteTerm(null);\n\n    for (Term term : termsIter) {\n      // Since we visit terms sorted, we gain performance\n      // by re-using the same TermsEnum and seeking only\n      // forwards\n      if (term.field() != currentField) {\n        assert currentField == null || currentField.compareTo(term.field()) < 0;\n        currentField = term.field();\n        Terms terms = fields.terms(currentField);\n        if (terms != null) {\n          termsEnum = terms.iterator();\n        } else {\n          termsEnum = null;\n        }\n      }\n\n      if (termsEnum == null) {\n        continue;\n      }\n      assert checkDeleteTerm(term);\n\n      // System.out.println(\"  term=\" + term);\n\n      if (termsEnum.seek(term.bytes(), false) == TermsEnum.SeekStatus.FOUND) {\n        DocsEnum docsEnum = termsEnum.docs(reader.getDeletedDocs(), docs);\n\n        if (docsEnum != null) {\n          while (true) {\n            final int docID = docsEnum.nextDoc();\n            if (docID == DocsEnum.NO_MORE_DOCS) {\n              break;\n            }\n            reader.deleteDocument(docID);\n            // TODO: we could/should change\n            // reader.deleteDocument to return boolean\n            // true if it did in fact delete, because here\n            // we could be deleting an already-deleted doc\n            // which makes this an upper bound:\n            delCount++;\n          }\n        }\n      }\n    }\n\n    return delCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e7bd246bb7bc35ac22edfee9157e034dfc4e65eb","date":1309960478,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/BufferedDeletesStream#applyTermDeletes(Iterable[Term],SegmentReader).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/BufferedDeletesStream#applyTermDeletes(Iterable[Term],SegmentReader).mjava","sourceNew":"  // Delete by Term\n  private synchronized long applyTermDeletes(Iterable<Term> termsIter, SegmentReader reader) throws IOException {\n    long delCount = 0;\n    Fields fields = reader.fields();\n    if (fields == null) {\n      // This reader has no postings\n      return 0;\n    }\n\n    TermsEnum termsEnum = null;\n\n    String currentField = null;\n    DocsEnum docs = null;\n\n    assert checkDeleteTerm(null);\n\n    for (Term term : termsIter) {\n      // Since we visit terms sorted, we gain performance\n      // by re-using the same TermsEnum and seeking only\n      // forwards\n      if (!term.field().equals(currentField)) {\n        assert currentField == null || currentField.compareTo(term.field()) < 0;\n        currentField = term.field();\n        Terms terms = fields.terms(currentField);\n        if (terms != null) {\n          termsEnum = terms.iterator();\n        } else {\n          termsEnum = null;\n        }\n      }\n\n      if (termsEnum == null) {\n        continue;\n      }\n      assert checkDeleteTerm(term);\n\n      // System.out.println(\"  term=\" + term);\n\n      if (termsEnum.seekExact(term.bytes(), false)) {\n        DocsEnum docsEnum = termsEnum.docs(reader.getLiveDocs(), docs);\n\n        if (docsEnum != null) {\n          while (true) {\n            final int docID = docsEnum.nextDoc();\n            if (docID == DocsEnum.NO_MORE_DOCS) {\n              break;\n            }\n            reader.deleteDocument(docID);\n            // TODO: we could/should change\n            // reader.deleteDocument to return boolean\n            // true if it did in fact delete, because here\n            // we could be deleting an already-deleted doc\n            // which makes this an upper bound:\n            delCount++;\n          }\n        }\n      }\n    }\n\n    return delCount;\n  }\n\n","sourceOld":"  // Delete by Term\n  private synchronized long applyTermDeletes(Iterable<Term> termsIter, SegmentReader reader) throws IOException {\n    long delCount = 0;\n    Fields fields = reader.fields();\n    if (fields == null) {\n      // This reader has no postings\n      return 0;\n    }\n\n    TermsEnum termsEnum = null;\n\n    String currentField = null;\n    DocsEnum docs = null;\n\n    assert checkDeleteTerm(null);\n\n    for (Term term : termsIter) {\n      // Since we visit terms sorted, we gain performance\n      // by re-using the same TermsEnum and seeking only\n      // forwards\n      if (!term.field().equals(currentField)) {\n        assert currentField == null || currentField.compareTo(term.field()) < 0;\n        currentField = term.field();\n        Terms terms = fields.terms(currentField);\n        if (terms != null) {\n          termsEnum = terms.iterator();\n        } else {\n          termsEnum = null;\n        }\n      }\n\n      if (termsEnum == null) {\n        continue;\n      }\n      assert checkDeleteTerm(term);\n\n      // System.out.println(\"  term=\" + term);\n\n      if (termsEnum.seekExact(term.bytes(), false)) {\n        DocsEnum docsEnum = termsEnum.docs(reader.getDeletedDocs(), docs);\n\n        if (docsEnum != null) {\n          while (true) {\n            final int docID = docsEnum.nextDoc();\n            if (docID == DocsEnum.NO_MORE_DOCS) {\n              break;\n            }\n            reader.deleteDocument(docID);\n            // TODO: we could/should change\n            // reader.deleteDocument to return boolean\n            // true if it did in fact delete, because here\n            // we could be deleting an already-deleted doc\n            // which makes this an upper bound:\n            delCount++;\n          }\n        }\n      }\n    }\n\n    return delCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"817d8435e9135b756f08ce6710ab0baac51bdf88","date":1309986993,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/BufferedDeletesStream#applyTermDeletes(Iterable[Term],SegmentReader).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/BufferedDeletesStream#applyTermDeletes(Iterable[Term],SegmentReader).mjava","sourceNew":"  // Delete by Term\n  private synchronized long applyTermDeletes(Iterable<Term> termsIter, SegmentReader reader) throws IOException {\n    long delCount = 0;\n    Fields fields = reader.fields();\n    if (fields == null) {\n      // This reader has no postings\n      return 0;\n    }\n\n    TermsEnum termsEnum = null;\n\n    String currentField = null;\n    DocsEnum docs = null;\n\n    assert checkDeleteTerm(null);\n\n    for (Term term : termsIter) {\n      // Since we visit terms sorted, we gain performance\n      // by re-using the same TermsEnum and seeking only\n      // forwards\n      if (!term.field().equals(currentField)) {\n        assert currentField == null || currentField.compareTo(term.field()) < 0;\n        currentField = term.field();\n        Terms terms = fields.terms(currentField);\n        if (terms != null) {\n          termsEnum = terms.iterator();\n        } else {\n          termsEnum = null;\n        }\n      }\n\n      if (termsEnum == null) {\n        continue;\n      }\n      assert checkDeleteTerm(term);\n\n      // System.out.println(\"  term=\" + term);\n\n      if (termsEnum.seekExact(term.bytes(), false)) {\n        DocsEnum docsEnum = termsEnum.docs(reader.getLiveDocs(), docs);\n\n        if (docsEnum != null) {\n          while (true) {\n            final int docID = docsEnum.nextDoc();\n            if (docID == DocsEnum.NO_MORE_DOCS) {\n              break;\n            }\n            reader.deleteDocument(docID);\n            // TODO: we could/should change\n            // reader.deleteDocument to return boolean\n            // true if it did in fact delete, because here\n            // we could be deleting an already-deleted doc\n            // which makes this an upper bound:\n            delCount++;\n          }\n        }\n      }\n    }\n\n    return delCount;\n  }\n\n","sourceOld":"  // Delete by Term\n  private synchronized long applyTermDeletes(Iterable<Term> termsIter, SegmentReader reader) throws IOException {\n    long delCount = 0;\n    Fields fields = reader.fields();\n    if (fields == null) {\n      // This reader has no postings\n      return 0;\n    }\n\n    TermsEnum termsEnum = null;\n\n    String currentField = null;\n    DocsEnum docs = null;\n\n    assert checkDeleteTerm(null);\n\n    for (Term term : termsIter) {\n      // Since we visit terms sorted, we gain performance\n      // by re-using the same TermsEnum and seeking only\n      // forwards\n      if (!term.field().equals(currentField)) {\n        assert currentField == null || currentField.compareTo(term.field()) < 0;\n        currentField = term.field();\n        Terms terms = fields.terms(currentField);\n        if (terms != null) {\n          termsEnum = terms.iterator();\n        } else {\n          termsEnum = null;\n        }\n      }\n\n      if (termsEnum == null) {\n        continue;\n      }\n      assert checkDeleteTerm(term);\n\n      // System.out.println(\"  term=\" + term);\n\n      if (termsEnum.seekExact(term.bytes(), false)) {\n        DocsEnum docsEnum = termsEnum.docs(reader.getDeletedDocs(), docs);\n\n        if (docsEnum != null) {\n          while (true) {\n            final int docID = docsEnum.nextDoc();\n            if (docID == DocsEnum.NO_MORE_DOCS) {\n              break;\n            }\n            reader.deleteDocument(docID);\n            // TODO: we could/should change\n            // reader.deleteDocument to return boolean\n            // true if it did in fact delete, because here\n            // we could be deleting an already-deleted doc\n            // which makes this an upper bound:\n            delCount++;\n          }\n        }\n      }\n    }\n\n    return delCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d083e83f225b11e5fdd900e83d26ddb385b6955c","date":1310029438,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/BufferedDeletesStream#applyTermDeletes(Iterable[Term],SegmentReader).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/BufferedDeletesStream#applyTermDeletes(Iterable[Term],SegmentReader).mjava","sourceNew":"  // Delete by Term\n  private synchronized long applyTermDeletes(Iterable<Term> termsIter, SegmentReader reader) throws IOException {\n    long delCount = 0;\n    Fields fields = reader.fields();\n    if (fields == null) {\n      // This reader has no postings\n      return 0;\n    }\n\n    TermsEnum termsEnum = null;\n\n    String currentField = null;\n    DocsEnum docs = null;\n\n    assert checkDeleteTerm(null);\n\n    for (Term term : termsIter) {\n      // Since we visit terms sorted, we gain performance\n      // by re-using the same TermsEnum and seeking only\n      // forwards\n      if (!term.field().equals(currentField)) {\n        assert currentField == null || currentField.compareTo(term.field()) < 0;\n        currentField = term.field();\n        Terms terms = fields.terms(currentField);\n        if (terms != null) {\n          termsEnum = terms.iterator();\n        } else {\n          termsEnum = null;\n        }\n      }\n\n      if (termsEnum == null) {\n        continue;\n      }\n      assert checkDeleteTerm(term);\n\n      // System.out.println(\"  term=\" + term);\n\n      if (termsEnum.seekExact(term.bytes(), false)) {\n        DocsEnum docsEnum = termsEnum.docs(reader.getLiveDocs(), docs);\n\n        if (docsEnum != null) {\n          while (true) {\n            final int docID = docsEnum.nextDoc();\n            if (docID == DocsEnum.NO_MORE_DOCS) {\n              break;\n            }\n            reader.deleteDocument(docID);\n            // TODO: we could/should change\n            // reader.deleteDocument to return boolean\n            // true if it did in fact delete, because here\n            // we could be deleting an already-deleted doc\n            // which makes this an upper bound:\n            delCount++;\n          }\n        }\n      }\n    }\n\n    return delCount;\n  }\n\n","sourceOld":"  // Delete by Term\n  private synchronized long applyTermDeletes(Iterable<Term> termsIter, SegmentReader reader) throws IOException {\n    long delCount = 0;\n    Fields fields = reader.fields();\n    if (fields == null) {\n      // This reader has no postings\n      return 0;\n    }\n\n    TermsEnum termsEnum = null;\n\n    String currentField = null;\n    DocsEnum docs = null;\n\n    assert checkDeleteTerm(null);\n\n    for (Term term : termsIter) {\n      // Since we visit terms sorted, we gain performance\n      // by re-using the same TermsEnum and seeking only\n      // forwards\n      if (term.field() != currentField) {\n        assert currentField == null || currentField.compareTo(term.field()) < 0;\n        currentField = term.field();\n        Terms terms = fields.terms(currentField);\n        if (terms != null) {\n          termsEnum = terms.iterator();\n        } else {\n          termsEnum = null;\n        }\n      }\n\n      if (termsEnum == null) {\n        continue;\n      }\n      assert checkDeleteTerm(term);\n\n      // System.out.println(\"  term=\" + term);\n\n      if (termsEnum.seek(term.bytes(), false) == TermsEnum.SeekStatus.FOUND) {\n        DocsEnum docsEnum = termsEnum.docs(reader.getDeletedDocs(), docs);\n\n        if (docsEnum != null) {\n          while (true) {\n            final int docID = docsEnum.nextDoc();\n            if (docID == DocsEnum.NO_MORE_DOCS) {\n              break;\n            }\n            reader.deleteDocument(docID);\n            // TODO: we could/should change\n            // reader.deleteDocument to return boolean\n            // true if it did in fact delete, because here\n            // we could be deleting an already-deleted doc\n            // which makes this an upper bound:\n            delCount++;\n          }\n        }\n      }\n    }\n\n    return delCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c00afe74a80796ed1f30a9509b150ff104746a1f","date":1312881735,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/BufferedDeletesStream#applyTermDeletes(Iterable[Term],SegmentReader).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/BufferedDeletesStream#applyTermDeletes(Iterable[Term],SegmentReader).mjava","sourceNew":"  // Delete by Term\n  private synchronized long applyTermDeletes(Iterable<Term> termsIter, SegmentReader reader) throws IOException {\n    long delCount = 0;\n    Fields fields = reader.fields();\n    if (fields == null) {\n      // This reader has no postings\n      return 0;\n    }\n\n    TermsEnum termsEnum = null;\n\n    String currentField = null;\n    DocsEnum docs = null;\n\n    assert checkDeleteTerm(null);\n    \n    //System.out.println(Thread.currentThread().getName() + \" del terms reader=\" + reader);\n    for (Term term : termsIter) {\n      // Since we visit terms sorted, we gain performance\n      // by re-using the same TermsEnum and seeking only\n      // forwards\n      if (!term.field().equals(currentField)) {\n        assert currentField == null || currentField.compareTo(term.field()) < 0;\n        currentField = term.field();\n        Terms terms = fields.terms(currentField);\n        if (terms != null) {\n          termsEnum = terms.iterator();\n        } else {\n          termsEnum = null;\n        }\n      }\n\n      if (termsEnum == null) {\n        continue;\n      }\n      assert checkDeleteTerm(term);\n\n      // System.out.println(\"  term=\" + term);\n\n      if (termsEnum.seekExact(term.bytes(), false)) {\n        DocsEnum docsEnum = termsEnum.docs(reader.getLiveDocs(), docs);\n\n        if (docsEnum != null) {\n          while (true) {\n            final int docID = docsEnum.nextDoc();\n            //System.out.println(Thread.currentThread().getName() + \" del term=\" + term + \" doc=\" + docID);\n            if (docID == DocsEnum.NO_MORE_DOCS) {\n              break;\n            }\n            reader.deleteDocument(docID);\n            // TODO: we could/should change\n            // reader.deleteDocument to return boolean\n            // true if it did in fact delete, because here\n            // we could be deleting an already-deleted doc\n            // which makes this an upper bound:\n            delCount++;\n          }\n        }\n      }\n    }\n\n    return delCount;\n  }\n\n","sourceOld":"  // Delete by Term\n  private synchronized long applyTermDeletes(Iterable<Term> termsIter, SegmentReader reader) throws IOException {\n    long delCount = 0;\n    Fields fields = reader.fields();\n    if (fields == null) {\n      // This reader has no postings\n      return 0;\n    }\n\n    TermsEnum termsEnum = null;\n\n    String currentField = null;\n    DocsEnum docs = null;\n\n    assert checkDeleteTerm(null);\n\n    for (Term term : termsIter) {\n      // Since we visit terms sorted, we gain performance\n      // by re-using the same TermsEnum and seeking only\n      // forwards\n      if (!term.field().equals(currentField)) {\n        assert currentField == null || currentField.compareTo(term.field()) < 0;\n        currentField = term.field();\n        Terms terms = fields.terms(currentField);\n        if (terms != null) {\n          termsEnum = terms.iterator();\n        } else {\n          termsEnum = null;\n        }\n      }\n\n      if (termsEnum == null) {\n        continue;\n      }\n      assert checkDeleteTerm(term);\n\n      // System.out.println(\"  term=\" + term);\n\n      if (termsEnum.seekExact(term.bytes(), false)) {\n        DocsEnum docsEnum = termsEnum.docs(reader.getLiveDocs(), docs);\n\n        if (docsEnum != null) {\n          while (true) {\n            final int docID = docsEnum.nextDoc();\n            if (docID == DocsEnum.NO_MORE_DOCS) {\n              break;\n            }\n            reader.deleteDocument(docID);\n            // TODO: we could/should change\n            // reader.deleteDocument to return boolean\n            // true if it did in fact delete, because here\n            // we could be deleting an already-deleted doc\n            // which makes this an upper bound:\n            delCount++;\n          }\n        }\n      }\n    }\n\n    return delCount;\n  }\n\n","bugFix":["69a6d2d525aeab53c867ed26934185e5bb627d0e"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"60ba444201d2570214b6fcf1d15600dc1a01f548","date":1313868045,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/BufferedDeletesStream#applyTermDeletes(Iterable[Term],SegmentReader).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/BufferedDeletesStream#applyTermDeletes(Iterable[Term],SegmentReader).mjava","sourceNew":"  // Delete by Term\n  private synchronized long applyTermDeletes(Iterable<Term> termsIter, SegmentReader reader) throws IOException {\n    long delCount = 0;\n    Fields fields = reader.fields();\n    if (fields == null) {\n      // This reader has no postings\n      return 0;\n    }\n\n    TermsEnum termsEnum = null;\n\n    String currentField = null;\n    DocsEnum docs = null;\n\n    assert checkDeleteTerm(null);\n    \n    //System.out.println(Thread.currentThread().getName() + \" del terms reader=\" + reader);\n    for (Term term : termsIter) {\n      // Since we visit terms sorted, we gain performance\n      // by re-using the same TermsEnum and seeking only\n      // forwards\n      if (!term.field().equals(currentField)) {\n        assert currentField == null || currentField.compareTo(term.field()) < 0;\n        currentField = term.field();\n        Terms terms = fields.terms(currentField);\n        if (terms != null) {\n          termsEnum = terms.iterator();\n        } else {\n          termsEnum = null;\n        }\n      }\n\n      if (termsEnum == null) {\n        continue;\n      }\n      assert checkDeleteTerm(term);\n\n      // System.out.println(\"  term=\" + term);\n\n      if (termsEnum.seekExact(term.bytes(), false)) {\n        DocsEnum docsEnum = termsEnum.docs(reader.getLiveDocs(), docs);\n        //System.out.println(\"BDS: got docsEnum=\" + docsEnum);\n\n        if (docsEnum != null) {\n          while (true) {\n            final int docID = docsEnum.nextDoc();\n            //System.out.println(Thread.currentThread().getName() + \" del term=\" + term + \" doc=\" + docID);\n            if (docID == DocsEnum.NO_MORE_DOCS) {\n              break;\n            }\n            reader.deleteDocument(docID);\n            // TODO: we could/should change\n            // reader.deleteDocument to return boolean\n            // true if it did in fact delete, because here\n            // we could be deleting an already-deleted doc\n            // which makes this an upper bound:\n            delCount++;\n          }\n        }\n      }\n    }\n\n    return delCount;\n  }\n\n","sourceOld":"  // Delete by Term\n  private synchronized long applyTermDeletes(Iterable<Term> termsIter, SegmentReader reader) throws IOException {\n    long delCount = 0;\n    Fields fields = reader.fields();\n    if (fields == null) {\n      // This reader has no postings\n      return 0;\n    }\n\n    TermsEnum termsEnum = null;\n\n    String currentField = null;\n    DocsEnum docs = null;\n\n    assert checkDeleteTerm(null);\n    \n    //System.out.println(Thread.currentThread().getName() + \" del terms reader=\" + reader);\n    for (Term term : termsIter) {\n      // Since we visit terms sorted, we gain performance\n      // by re-using the same TermsEnum and seeking only\n      // forwards\n      if (!term.field().equals(currentField)) {\n        assert currentField == null || currentField.compareTo(term.field()) < 0;\n        currentField = term.field();\n        Terms terms = fields.terms(currentField);\n        if (terms != null) {\n          termsEnum = terms.iterator();\n        } else {\n          termsEnum = null;\n        }\n      }\n\n      if (termsEnum == null) {\n        continue;\n      }\n      assert checkDeleteTerm(term);\n\n      // System.out.println(\"  term=\" + term);\n\n      if (termsEnum.seekExact(term.bytes(), false)) {\n        DocsEnum docsEnum = termsEnum.docs(reader.getLiveDocs(), docs);\n\n        if (docsEnum != null) {\n          while (true) {\n            final int docID = docsEnum.nextDoc();\n            //System.out.println(Thread.currentThread().getName() + \" del term=\" + term + \" doc=\" + docID);\n            if (docID == DocsEnum.NO_MORE_DOCS) {\n              break;\n            }\n            reader.deleteDocument(docID);\n            // TODO: we could/should change\n            // reader.deleteDocument to return boolean\n            // true if it did in fact delete, because here\n            // we could be deleting an already-deleted doc\n            // which makes this an upper bound:\n            delCount++;\n          }\n        }\n      }\n    }\n\n    return delCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3cc749c053615f5871f3b95715fe292f34e70a53","date":1321470575,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/BufferedDeletesStream#applyTermDeletes(Iterable[Term],SegmentReader).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/BufferedDeletesStream#applyTermDeletes(Iterable[Term],SegmentReader).mjava","sourceNew":"  // Delete by Term\n  private synchronized long applyTermDeletes(Iterable<Term> termsIter, SegmentReader reader) throws IOException {\n    long delCount = 0;\n    Fields fields = reader.fields();\n    if (fields == null) {\n      // This reader has no postings\n      return 0;\n    }\n\n    TermsEnum termsEnum = null;\n\n    String currentField = null;\n    DocsEnum docs = null;\n\n    assert checkDeleteTerm(null);\n    \n    //System.out.println(Thread.currentThread().getName() + \" del terms reader=\" + reader);\n    for (Term term : termsIter) {\n      // Since we visit terms sorted, we gain performance\n      // by re-using the same TermsEnum and seeking only\n      // forwards\n      if (!term.field().equals(currentField)) {\n        assert currentField == null || currentField.compareTo(term.field()) < 0;\n        currentField = term.field();\n        Terms terms = fields.terms(currentField);\n        if (terms != null) {\n          termsEnum = terms.iterator(null);\n        } else {\n          termsEnum = null;\n        }\n      }\n\n      if (termsEnum == null) {\n        continue;\n      }\n      assert checkDeleteTerm(term);\n\n      // System.out.println(\"  term=\" + term);\n\n      if (termsEnum.seekExact(term.bytes(), false)) {\n        DocsEnum docsEnum = termsEnum.docs(reader.getLiveDocs(), docs);\n        //System.out.println(\"BDS: got docsEnum=\" + docsEnum);\n\n        if (docsEnum != null) {\n          while (true) {\n            final int docID = docsEnum.nextDoc();\n            //System.out.println(Thread.currentThread().getName() + \" del term=\" + term + \" doc=\" + docID);\n            if (docID == DocsEnum.NO_MORE_DOCS) {\n              break;\n            }\n            reader.deleteDocument(docID);\n            // TODO: we could/should change\n            // reader.deleteDocument to return boolean\n            // true if it did in fact delete, because here\n            // we could be deleting an already-deleted doc\n            // which makes this an upper bound:\n            delCount++;\n          }\n        }\n      }\n    }\n\n    return delCount;\n  }\n\n","sourceOld":"  // Delete by Term\n  private synchronized long applyTermDeletes(Iterable<Term> termsIter, SegmentReader reader) throws IOException {\n    long delCount = 0;\n    Fields fields = reader.fields();\n    if (fields == null) {\n      // This reader has no postings\n      return 0;\n    }\n\n    TermsEnum termsEnum = null;\n\n    String currentField = null;\n    DocsEnum docs = null;\n\n    assert checkDeleteTerm(null);\n    \n    //System.out.println(Thread.currentThread().getName() + \" del terms reader=\" + reader);\n    for (Term term : termsIter) {\n      // Since we visit terms sorted, we gain performance\n      // by re-using the same TermsEnum and seeking only\n      // forwards\n      if (!term.field().equals(currentField)) {\n        assert currentField == null || currentField.compareTo(term.field()) < 0;\n        currentField = term.field();\n        Terms terms = fields.terms(currentField);\n        if (terms != null) {\n          termsEnum = terms.iterator();\n        } else {\n          termsEnum = null;\n        }\n      }\n\n      if (termsEnum == null) {\n        continue;\n      }\n      assert checkDeleteTerm(term);\n\n      // System.out.println(\"  term=\" + term);\n\n      if (termsEnum.seekExact(term.bytes(), false)) {\n        DocsEnum docsEnum = termsEnum.docs(reader.getLiveDocs(), docs);\n        //System.out.println(\"BDS: got docsEnum=\" + docsEnum);\n\n        if (docsEnum != null) {\n          while (true) {\n            final int docID = docsEnum.nextDoc();\n            //System.out.println(Thread.currentThread().getName() + \" del term=\" + term + \" doc=\" + docID);\n            if (docID == DocsEnum.NO_MORE_DOCS) {\n              break;\n            }\n            reader.deleteDocument(docID);\n            // TODO: we could/should change\n            // reader.deleteDocument to return boolean\n            // true if it did in fact delete, because here\n            // we could be deleting an already-deleted doc\n            // which makes this an upper bound:\n            delCount++;\n          }\n        }\n      }\n    }\n\n    return delCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"872cff1d3a554e0cd64014cd97f88d3002b0f491","date":1323024658,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/BufferedDeletesStream#applyTermDeletes(Iterable[Term],SegmentReader).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/BufferedDeletesStream#applyTermDeletes(Iterable[Term],SegmentReader).mjava","sourceNew":"  // Delete by Term\n  private synchronized long applyTermDeletes(Iterable<Term> termsIter, SegmentReader reader) throws IOException {\n    long delCount = 0;\n    Fields fields = reader.fields();\n    if (fields == null) {\n      // This reader has no postings\n      return 0;\n    }\n\n    TermsEnum termsEnum = null;\n\n    String currentField = null;\n    DocsEnum docs = null;\n\n    assert checkDeleteTerm(null);\n    \n    //System.out.println(Thread.currentThread().getName() + \" del terms reader=\" + reader);\n    for (Term term : termsIter) {\n      // Since we visit terms sorted, we gain performance\n      // by re-using the same TermsEnum and seeking only\n      // forwards\n      if (!term.field().equals(currentField)) {\n        assert currentField == null || currentField.compareTo(term.field()) < 0;\n        currentField = term.field();\n        Terms terms = fields.terms(currentField);\n        if (terms != null) {\n          termsEnum = terms.iterator(null);\n        } else {\n          termsEnum = null;\n        }\n      }\n\n      if (termsEnum == null) {\n        continue;\n      }\n      assert checkDeleteTerm(term);\n\n      // System.out.println(\"  term=\" + term);\n\n      if (termsEnum.seekExact(term.bytes(), false)) {\n        DocsEnum docsEnum = termsEnum.docs(reader.getLiveDocs(), docs, false);\n        //System.out.println(\"BDS: got docsEnum=\" + docsEnum);\n\n        if (docsEnum != null) {\n          while (true) {\n            final int docID = docsEnum.nextDoc();\n            //System.out.println(Thread.currentThread().getName() + \" del term=\" + term + \" doc=\" + docID);\n            if (docID == DocsEnum.NO_MORE_DOCS) {\n              break;\n            }\n            reader.deleteDocument(docID);\n            // TODO: we could/should change\n            // reader.deleteDocument to return boolean\n            // true if it did in fact delete, because here\n            // we could be deleting an already-deleted doc\n            // which makes this an upper bound:\n            delCount++;\n          }\n        }\n      }\n    }\n\n    return delCount;\n  }\n\n","sourceOld":"  // Delete by Term\n  private synchronized long applyTermDeletes(Iterable<Term> termsIter, SegmentReader reader) throws IOException {\n    long delCount = 0;\n    Fields fields = reader.fields();\n    if (fields == null) {\n      // This reader has no postings\n      return 0;\n    }\n\n    TermsEnum termsEnum = null;\n\n    String currentField = null;\n    DocsEnum docs = null;\n\n    assert checkDeleteTerm(null);\n    \n    //System.out.println(Thread.currentThread().getName() + \" del terms reader=\" + reader);\n    for (Term term : termsIter) {\n      // Since we visit terms sorted, we gain performance\n      // by re-using the same TermsEnum and seeking only\n      // forwards\n      if (!term.field().equals(currentField)) {\n        assert currentField == null || currentField.compareTo(term.field()) < 0;\n        currentField = term.field();\n        Terms terms = fields.terms(currentField);\n        if (terms != null) {\n          termsEnum = terms.iterator(null);\n        } else {\n          termsEnum = null;\n        }\n      }\n\n      if (termsEnum == null) {\n        continue;\n      }\n      assert checkDeleteTerm(term);\n\n      // System.out.println(\"  term=\" + term);\n\n      if (termsEnum.seekExact(term.bytes(), false)) {\n        DocsEnum docsEnum = termsEnum.docs(reader.getLiveDocs(), docs);\n        //System.out.println(\"BDS: got docsEnum=\" + docsEnum);\n\n        if (docsEnum != null) {\n          while (true) {\n            final int docID = docsEnum.nextDoc();\n            //System.out.println(Thread.currentThread().getName() + \" del term=\" + term + \" doc=\" + docID);\n            if (docID == DocsEnum.NO_MORE_DOCS) {\n              break;\n            }\n            reader.deleteDocument(docID);\n            // TODO: we could/should change\n            // reader.deleteDocument to return boolean\n            // true if it did in fact delete, because here\n            // we could be deleting an already-deleted doc\n            // which makes this an upper bound:\n            delCount++;\n          }\n        }\n      }\n    }\n\n    return delCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b65b350ca9588f9fc76ce7d6804160d06c45ff42","date":1323026297,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/BufferedDeletesStream#applyTermDeletes(Iterable[Term],SegmentReader).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/BufferedDeletesStream#applyTermDeletes(Iterable[Term],SegmentReader).mjava","sourceNew":"  // Delete by Term\n  private synchronized long applyTermDeletes(Iterable<Term> termsIter, SegmentReader reader) throws IOException {\n    long delCount = 0;\n    Fields fields = reader.fields();\n    if (fields == null) {\n      // This reader has no postings\n      return 0;\n    }\n\n    TermsEnum termsEnum = null;\n\n    String currentField = null;\n    DocsEnum docs = null;\n\n    assert checkDeleteTerm(null);\n    \n    //System.out.println(Thread.currentThread().getName() + \" del terms reader=\" + reader);\n    for (Term term : termsIter) {\n      // Since we visit terms sorted, we gain performance\n      // by re-using the same TermsEnum and seeking only\n      // forwards\n      if (!term.field().equals(currentField)) {\n        assert currentField == null || currentField.compareTo(term.field()) < 0;\n        currentField = term.field();\n        Terms terms = fields.terms(currentField);\n        if (terms != null) {\n          termsEnum = terms.iterator(null);\n        } else {\n          termsEnum = null;\n        }\n      }\n\n      if (termsEnum == null) {\n        continue;\n      }\n      assert checkDeleteTerm(term);\n\n      // System.out.println(\"  term=\" + term);\n\n      if (termsEnum.seekExact(term.bytes(), false)) {\n        DocsEnum docsEnum = termsEnum.docs(reader.getLiveDocs(), docs, false);\n        //System.out.println(\"BDS: got docsEnum=\" + docsEnum);\n\n        if (docsEnum != null) {\n          while (true) {\n            final int docID = docsEnum.nextDoc();\n            //System.out.println(Thread.currentThread().getName() + \" del term=\" + term + \" doc=\" + docID);\n            if (docID == DocsEnum.NO_MORE_DOCS) {\n              break;\n            }\n            reader.deleteDocument(docID);\n            // TODO: we could/should change\n            // reader.deleteDocument to return boolean\n            // true if it did in fact delete, because here\n            // we could be deleting an already-deleted doc\n            // which makes this an upper bound:\n            delCount++;\n          }\n        }\n      }\n    }\n\n    return delCount;\n  }\n\n","sourceOld":"  // Delete by Term\n  private synchronized long applyTermDeletes(Iterable<Term> termsIter, SegmentReader reader) throws IOException {\n    long delCount = 0;\n    Fields fields = reader.fields();\n    if (fields == null) {\n      // This reader has no postings\n      return 0;\n    }\n\n    TermsEnum termsEnum = null;\n\n    String currentField = null;\n    DocsEnum docs = null;\n\n    assert checkDeleteTerm(null);\n    \n    //System.out.println(Thread.currentThread().getName() + \" del terms reader=\" + reader);\n    for (Term term : termsIter) {\n      // Since we visit terms sorted, we gain performance\n      // by re-using the same TermsEnum and seeking only\n      // forwards\n      if (!term.field().equals(currentField)) {\n        assert currentField == null || currentField.compareTo(term.field()) < 0;\n        currentField = term.field();\n        Terms terms = fields.terms(currentField);\n        if (terms != null) {\n          termsEnum = terms.iterator(null);\n        } else {\n          termsEnum = null;\n        }\n      }\n\n      if (termsEnum == null) {\n        continue;\n      }\n      assert checkDeleteTerm(term);\n\n      // System.out.println(\"  term=\" + term);\n\n      if (termsEnum.seekExact(term.bytes(), false)) {\n        DocsEnum docsEnum = termsEnum.docs(reader.getLiveDocs(), docs);\n        //System.out.println(\"BDS: got docsEnum=\" + docsEnum);\n\n        if (docsEnum != null) {\n          while (true) {\n            final int docID = docsEnum.nextDoc();\n            //System.out.println(Thread.currentThread().getName() + \" del term=\" + term + \" doc=\" + docID);\n            if (docID == DocsEnum.NO_MORE_DOCS) {\n              break;\n            }\n            reader.deleteDocument(docID);\n            // TODO: we could/should change\n            // reader.deleteDocument to return boolean\n            // true if it did in fact delete, because here\n            // we could be deleting an already-deleted doc\n            // which makes this an upper bound:\n            delCount++;\n          }\n        }\n      }\n    }\n\n    return delCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9ce667c6d3400b22523701c549c0d35e26da8b46","date":1324405053,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/BufferedDeletesStream#applyTermDeletes(Iterable[Term],IndexWriter.ReadersAndLiveDocs,SegmentReader).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/BufferedDeletesStream#applyTermDeletes(Iterable[Term],SegmentReader).mjava","sourceNew":"  // Delete by Term\n  private synchronized long applyTermDeletes(Iterable<Term> termsIter, IndexWriter.ReadersAndLiveDocs rld, SegmentReader reader) throws IOException {\n    long delCount = 0;\n    Fields fields = reader.fields();\n    if (fields == null) {\n      // This reader has no postings\n      return 0;\n    }\n\n    TermsEnum termsEnum = null;\n\n    String currentField = null;\n    DocsEnum docs = null;\n\n    assert checkDeleteTerm(null);\n\n    boolean any = false;\n\n    //System.out.println(Thread.currentThread().getName() + \" del terms reader=\" + reader);\n    for (Term term : termsIter) {\n      // Since we visit terms sorted, we gain performance\n      // by re-using the same TermsEnum and seeking only\n      // forwards\n      if (!term.field().equals(currentField)) {\n        assert currentField == null || currentField.compareTo(term.field()) < 0;\n        currentField = term.field();\n        Terms terms = fields.terms(currentField);\n        if (terms != null) {\n          termsEnum = terms.iterator(null);\n        } else {\n          termsEnum = null;\n        }\n      }\n\n      if (termsEnum == null) {\n        continue;\n      }\n      assert checkDeleteTerm(term);\n\n      // System.out.println(\"  term=\" + term);\n\n      if (termsEnum.seekExact(term.bytes(), false)) {\n        DocsEnum docsEnum = termsEnum.docs(rld.liveDocs, docs, false);\n        //System.out.println(\"BDS: got docsEnum=\" + docsEnum);\n\n        if (docsEnum != null) {\n          while (true) {\n            final int docID = docsEnum.nextDoc();\n            //System.out.println(Thread.currentThread().getName() + \" del term=\" + term + \" doc=\" + docID);\n            if (docID == DocsEnum.NO_MORE_DOCS) {\n              break;\n            }   \n            // NOTE: there is no limit check on the docID\n            // when deleting by Term (unlike by Query)\n            // because on flush we apply all Term deletes to\n            // each segment.  So all Term deleting here is\n            // against prior segments:\n            if (!any) {\n              rld.initWritableLiveDocs();\n              any = true;\n            }\n            if (rld.delete(docID)) {\n              delCount++;\n            }\n          }\n        }\n      }\n    }\n\n    return delCount;\n  }\n\n","sourceOld":"  // Delete by Term\n  private synchronized long applyTermDeletes(Iterable<Term> termsIter, SegmentReader reader) throws IOException {\n    long delCount = 0;\n    Fields fields = reader.fields();\n    if (fields == null) {\n      // This reader has no postings\n      return 0;\n    }\n\n    TermsEnum termsEnum = null;\n\n    String currentField = null;\n    DocsEnum docs = null;\n\n    assert checkDeleteTerm(null);\n    \n    //System.out.println(Thread.currentThread().getName() + \" del terms reader=\" + reader);\n    for (Term term : termsIter) {\n      // Since we visit terms sorted, we gain performance\n      // by re-using the same TermsEnum and seeking only\n      // forwards\n      if (!term.field().equals(currentField)) {\n        assert currentField == null || currentField.compareTo(term.field()) < 0;\n        currentField = term.field();\n        Terms terms = fields.terms(currentField);\n        if (terms != null) {\n          termsEnum = terms.iterator(null);\n        } else {\n          termsEnum = null;\n        }\n      }\n\n      if (termsEnum == null) {\n        continue;\n      }\n      assert checkDeleteTerm(term);\n\n      // System.out.println(\"  term=\" + term);\n\n      if (termsEnum.seekExact(term.bytes(), false)) {\n        DocsEnum docsEnum = termsEnum.docs(reader.getLiveDocs(), docs, false);\n        //System.out.println(\"BDS: got docsEnum=\" + docsEnum);\n\n        if (docsEnum != null) {\n          while (true) {\n            final int docID = docsEnum.nextDoc();\n            //System.out.println(Thread.currentThread().getName() + \" del term=\" + term + \" doc=\" + docID);\n            if (docID == DocsEnum.NO_MORE_DOCS) {\n              break;\n            }\n            reader.deleteDocument(docID);\n            // TODO: we could/should change\n            // reader.deleteDocument to return boolean\n            // true if it did in fact delete, because here\n            // we could be deleting an already-deleted doc\n            // which makes this an upper bound:\n            delCount++;\n          }\n        }\n      }\n    }\n\n    return delCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"fafef7c83fe8e0b3ca9298d5d75d6b943dc28153":["b3e06be49006ecac364d39d12b9c9f74882f9b9f"],"e7bd246bb7bc35ac22edfee9157e034dfc4e65eb":["fd9cc9d77712aba3662f24632df7539ab75e3667"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["29ef99d61cda9641b6250bf9567329a6e65f901d","b3e06be49006ecac364d39d12b9c9f74882f9b9f"],"3cc749c053615f5871f3b95715fe292f34e70a53":["60ba444201d2570214b6fcf1d15600dc1a01f548"],"b3e06be49006ecac364d39d12b9c9f74882f9b9f":["69a6d2d525aeab53c867ed26934185e5bb627d0e","bde51b089eb7f86171eb3406e38a274743f9b7ac"],"872cff1d3a554e0cd64014cd97f88d3002b0f491":["3cc749c053615f5871f3b95715fe292f34e70a53"],"2553b00f699380c64959ccb27991289aae87be2e":["a3776dccca01c11e7046323cfad46a3b4a471233","fd9cc9d77712aba3662f24632df7539ab75e3667"],"c00afe74a80796ed1f30a9509b150ff104746a1f":["e7bd246bb7bc35ac22edfee9157e034dfc4e65eb"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":["b3e06be49006ecac364d39d12b9c9f74882f9b9f","e7bd246bb7bc35ac22edfee9157e034dfc4e65eb"],"817d8435e9135b756f08ce6710ab0baac51bdf88":["2553b00f699380c64959ccb27991289aae87be2e","e7bd246bb7bc35ac22edfee9157e034dfc4e65eb"],"60ba444201d2570214b6fcf1d15600dc1a01f548":["c00afe74a80796ed1f30a9509b150ff104746a1f"],"b65b350ca9588f9fc76ce7d6804160d06c45ff42":["3cc749c053615f5871f3b95715fe292f34e70a53","872cff1d3a554e0cd64014cd97f88d3002b0f491"],"a3776dccca01c11e7046323cfad46a3b4a471233":["69a6d2d525aeab53c867ed26934185e5bb627d0e","b3e06be49006ecac364d39d12b9c9f74882f9b9f"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","69a6d2d525aeab53c867ed26934185e5bb627d0e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"69a6d2d525aeab53c867ed26934185e5bb627d0e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"9ce667c6d3400b22523701c549c0d35e26da8b46":["872cff1d3a554e0cd64014cd97f88d3002b0f491"],"fd9cc9d77712aba3662f24632df7539ab75e3667":["fafef7c83fe8e0b3ca9298d5d75d6b943dc28153"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","69a6d2d525aeab53c867ed26934185e5bb627d0e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9ce667c6d3400b22523701c549c0d35e26da8b46"]},"commit2Childs":{"fafef7c83fe8e0b3ca9298d5d75d6b943dc28153":["fd9cc9d77712aba3662f24632df7539ab75e3667"],"e7bd246bb7bc35ac22edfee9157e034dfc4e65eb":["c00afe74a80796ed1f30a9509b150ff104746a1f","d083e83f225b11e5fdd900e83d26ddb385b6955c","817d8435e9135b756f08ce6710ab0baac51bdf88"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":[],"b3e06be49006ecac364d39d12b9c9f74882f9b9f":["fafef7c83fe8e0b3ca9298d5d75d6b943dc28153","135621f3a0670a9394eb563224a3b76cc4dddc0f","d083e83f225b11e5fdd900e83d26ddb385b6955c","a3776dccca01c11e7046323cfad46a3b4a471233"],"3cc749c053615f5871f3b95715fe292f34e70a53":["872cff1d3a554e0cd64014cd97f88d3002b0f491","b65b350ca9588f9fc76ce7d6804160d06c45ff42"],"872cff1d3a554e0cd64014cd97f88d3002b0f491":["b65b350ca9588f9fc76ce7d6804160d06c45ff42","9ce667c6d3400b22523701c549c0d35e26da8b46"],"2553b00f699380c64959ccb27991289aae87be2e":["817d8435e9135b756f08ce6710ab0baac51bdf88"],"c00afe74a80796ed1f30a9509b150ff104746a1f":["60ba444201d2570214b6fcf1d15600dc1a01f548"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":[],"817d8435e9135b756f08ce6710ab0baac51bdf88":[],"60ba444201d2570214b6fcf1d15600dc1a01f548":["3cc749c053615f5871f3b95715fe292f34e70a53"],"b65b350ca9588f9fc76ce7d6804160d06c45ff42":[],"29ef99d61cda9641b6250bf9567329a6e65f901d":["135621f3a0670a9394eb563224a3b76cc4dddc0f"],"a3776dccca01c11e7046323cfad46a3b4a471233":["2553b00f699380c64959ccb27991289aae87be2e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["29ef99d61cda9641b6250bf9567329a6e65f901d","69a6d2d525aeab53c867ed26934185e5bb627d0e","bde51b089eb7f86171eb3406e38a274743f9b7ac"],"69a6d2d525aeab53c867ed26934185e5bb627d0e":["b3e06be49006ecac364d39d12b9c9f74882f9b9f","a3776dccca01c11e7046323cfad46a3b4a471233","29ef99d61cda9641b6250bf9567329a6e65f901d","bde51b089eb7f86171eb3406e38a274743f9b7ac"],"9ce667c6d3400b22523701c549c0d35e26da8b46":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"fd9cc9d77712aba3662f24632df7539ab75e3667":["e7bd246bb7bc35ac22edfee9157e034dfc4e65eb","2553b00f699380c64959ccb27991289aae87be2e"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["b3e06be49006ecac364d39d12b9c9f74882f9b9f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["135621f3a0670a9394eb563224a3b76cc4dddc0f","d083e83f225b11e5fdd900e83d26ddb385b6955c","817d8435e9135b756f08ce6710ab0baac51bdf88","b65b350ca9588f9fc76ce7d6804160d06c45ff42","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}