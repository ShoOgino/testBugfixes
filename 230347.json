{"path":"lucene/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xSegmentInfosReader#readSegmentInfo(Directory,int,ChecksumIndexInput).mjava","commits":[{"id":"7e0127a0bf2a1895ba6109cbbd451359b9c0653d","date":1326981970,"type":0,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xSegmentInfosReader#readSegmentInfo(Directory,int,ChecksumIndexInput).mjava","pathOld":"/dev/null","sourceNew":"  // if we make a preflex impl we can remove a lot of this hair...\n  public SegmentInfo readSegmentInfo(Directory dir, int format, ChecksumIndexInput input) throws IOException {\n    final String version;\n    if (format <= SegmentInfos.FORMAT_3_1) {\n      version = input.readString();\n    } else {\n      version = null;\n    }\n    final String name = input.readString();\n    final int docCount = input.readInt();\n    final long delGen = input.readLong();\n    final int docStoreOffset = input.readInt();\n    final String docStoreSegment;\n    final boolean docStoreIsCompoundFile;\n    if (docStoreOffset != -1) {\n      docStoreSegment = input.readString();\n      docStoreIsCompoundFile = input.readByte() == SegmentInfo.YES;\n    } else {\n      docStoreSegment = name;\n      docStoreIsCompoundFile = false;\n    }\n\n    // pre-4.0 indexes write a byte if there is a single norms file\n    byte b = input.readByte();\n    assert 1 == b : \"expected 1 but was: \"+ b + \" format: \" + format;\n\n    final int numNormGen = input.readInt();\n    final Map<Integer,Long> normGen;\n    if (numNormGen == SegmentInfo.NO) {\n      normGen = null;\n    } else {\n      normGen = new HashMap<Integer, Long>();\n      for(int j=0;j<numNormGen;j++) {\n        normGen.put(j, input.readLong());\n      }\n    }\n    final boolean isCompoundFile = input.readByte() == SegmentInfo.YES;\n\n    final int delCount = input.readInt();\n    assert delCount <= docCount;\n\n    final int hasProx = input.readByte();\n\n    final Codec codec = Codec.forName(\"Lucene3x\");\n    final Map<String,String> diagnostics = input.readStringStringMap();\n\n    final int hasVectors;\n    if (format <= SegmentInfos.FORMAT_HAS_VECTORS) {\n      hasVectors = input.readByte();\n    } else {\n      final String storesSegment;\n      final String ext;\n      final boolean storeIsCompoundFile;\n      if (docStoreOffset != -1) {\n        storesSegment = docStoreSegment;\n        storeIsCompoundFile = docStoreIsCompoundFile;\n        ext = IndexFileNames.COMPOUND_FILE_STORE_EXTENSION;\n      } else {\n        storesSegment = name;\n        storeIsCompoundFile = isCompoundFile;\n        ext = IndexFileNames.COMPOUND_FILE_EXTENSION;\n      }\n      final Directory dirToTest;\n      if (storeIsCompoundFile) {\n        dirToTest = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(storesSegment, \"\", ext), IOContext.READONCE, false);\n      } else {\n        dirToTest = dir;\n      }\n      try {\n        hasVectors = dirToTest.fileExists(IndexFileNames.segmentFileName(storesSegment, \"\", Lucene3xTermVectorsReader.VECTORS_INDEX_EXTENSION)) ? SegmentInfo.YES : SegmentInfo.NO;\n      } finally {\n        if (isCompoundFile) {\n          dirToTest.close();\n        }\n      }\n    }\n    \n    return new SegmentInfo(dir, version, name, docCount, delGen, docStoreOffset,\n      docStoreSegment, docStoreIsCompoundFile, normGen, isCompoundFile,\n      delCount, hasProx, codec, diagnostics, hasVectors);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"be9e3e7d2fc880996ffcfe9a8fc47057b647e9e3","date":1327944832,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xSegmentInfosReader#readSegmentInfo(Directory,int,ChecksumIndexInput).mjava","pathOld":"lucene/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xSegmentInfosReader#readSegmentInfo(Directory,int,ChecksumIndexInput).mjava","sourceNew":"  // if we make a preflex impl we can remove a lot of this hair...\n  public SegmentInfo readSegmentInfo(Directory dir, int format, ChecksumIndexInput input) throws IOException {\n    final String version;\n    if (format <= SegmentInfos.FORMAT_3_1) {\n      version = input.readString();\n    } else {\n      version = null;\n    }\n    final String name = input.readString();\n    final int docCount = input.readInt();\n    final long delGen = input.readLong();\n    final int docStoreOffset = input.readInt();\n    final String docStoreSegment;\n    final boolean docStoreIsCompoundFile;\n    if (docStoreOffset != -1) {\n      docStoreSegment = input.readString();\n      docStoreIsCompoundFile = input.readByte() == SegmentInfo.YES;\n    } else {\n      docStoreSegment = name;\n      docStoreIsCompoundFile = false;\n    }\n\n    // pre-4.0 indexes write a byte if there is a single norms file\n    byte b = input.readByte();\n    assert 1 == b : \"expected 1 but was: \"+ b + \" format: \" + format;\n\n    final int numNormGen = input.readInt();\n    final Map<Integer,Long> normGen;\n    if (numNormGen == SegmentInfo.NO) {\n      normGen = null;\n    } else {\n      normGen = new HashMap<Integer, Long>();\n      for(int j=0;j<numNormGen;j++) {\n        normGen.put(j, input.readLong());\n      }\n    }\n    final boolean isCompoundFile = input.readByte() == SegmentInfo.YES;\n\n    final int delCount = input.readInt();\n    assert delCount <= docCount;\n\n    final int hasProx = input.readByte();\n\n    final Codec codec = Codec.forName(\"Lucene3x\");\n    final Map<String,String> diagnostics = input.readStringStringMap();\n\n    final int hasVectors;\n    if (format <= SegmentInfos.FORMAT_HAS_VECTORS) {\n      hasVectors = input.readByte();\n    } else {\n      final String storesSegment;\n      final String ext;\n      final boolean storeIsCompoundFile;\n      if (docStoreOffset != -1) {\n        storesSegment = docStoreSegment;\n        storeIsCompoundFile = docStoreIsCompoundFile;\n        ext = Lucene3xCodec.COMPOUND_FILE_STORE_EXTENSION;\n      } else {\n        storesSegment = name;\n        storeIsCompoundFile = isCompoundFile;\n        ext = IndexFileNames.COMPOUND_FILE_EXTENSION;\n      }\n      final Directory dirToTest;\n      if (storeIsCompoundFile) {\n        dirToTest = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(storesSegment, \"\", ext), IOContext.READONCE, false);\n      } else {\n        dirToTest = dir;\n      }\n      try {\n        hasVectors = dirToTest.fileExists(IndexFileNames.segmentFileName(storesSegment, \"\", Lucene3xTermVectorsReader.VECTORS_INDEX_EXTENSION)) ? SegmentInfo.YES : SegmentInfo.NO;\n      } finally {\n        if (isCompoundFile) {\n          dirToTest.close();\n        }\n      }\n    }\n    \n    return new SegmentInfo(dir, version, name, docCount, delGen, docStoreOffset,\n      docStoreSegment, docStoreIsCompoundFile, normGen, isCompoundFile,\n      delCount, hasProx, codec, diagnostics, hasVectors);\n  }\n\n","sourceOld":"  // if we make a preflex impl we can remove a lot of this hair...\n  public SegmentInfo readSegmentInfo(Directory dir, int format, ChecksumIndexInput input) throws IOException {\n    final String version;\n    if (format <= SegmentInfos.FORMAT_3_1) {\n      version = input.readString();\n    } else {\n      version = null;\n    }\n    final String name = input.readString();\n    final int docCount = input.readInt();\n    final long delGen = input.readLong();\n    final int docStoreOffset = input.readInt();\n    final String docStoreSegment;\n    final boolean docStoreIsCompoundFile;\n    if (docStoreOffset != -1) {\n      docStoreSegment = input.readString();\n      docStoreIsCompoundFile = input.readByte() == SegmentInfo.YES;\n    } else {\n      docStoreSegment = name;\n      docStoreIsCompoundFile = false;\n    }\n\n    // pre-4.0 indexes write a byte if there is a single norms file\n    byte b = input.readByte();\n    assert 1 == b : \"expected 1 but was: \"+ b + \" format: \" + format;\n\n    final int numNormGen = input.readInt();\n    final Map<Integer,Long> normGen;\n    if (numNormGen == SegmentInfo.NO) {\n      normGen = null;\n    } else {\n      normGen = new HashMap<Integer, Long>();\n      for(int j=0;j<numNormGen;j++) {\n        normGen.put(j, input.readLong());\n      }\n    }\n    final boolean isCompoundFile = input.readByte() == SegmentInfo.YES;\n\n    final int delCount = input.readInt();\n    assert delCount <= docCount;\n\n    final int hasProx = input.readByte();\n\n    final Codec codec = Codec.forName(\"Lucene3x\");\n    final Map<String,String> diagnostics = input.readStringStringMap();\n\n    final int hasVectors;\n    if (format <= SegmentInfos.FORMAT_HAS_VECTORS) {\n      hasVectors = input.readByte();\n    } else {\n      final String storesSegment;\n      final String ext;\n      final boolean storeIsCompoundFile;\n      if (docStoreOffset != -1) {\n        storesSegment = docStoreSegment;\n        storeIsCompoundFile = docStoreIsCompoundFile;\n        ext = IndexFileNames.COMPOUND_FILE_STORE_EXTENSION;\n      } else {\n        storesSegment = name;\n        storeIsCompoundFile = isCompoundFile;\n        ext = IndexFileNames.COMPOUND_FILE_EXTENSION;\n      }\n      final Directory dirToTest;\n      if (storeIsCompoundFile) {\n        dirToTest = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(storesSegment, \"\", ext), IOContext.READONCE, false);\n      } else {\n        dirToTest = dir;\n      }\n      try {\n        hasVectors = dirToTest.fileExists(IndexFileNames.segmentFileName(storesSegment, \"\", Lucene3xTermVectorsReader.VECTORS_INDEX_EXTENSION)) ? SegmentInfo.YES : SegmentInfo.NO;\n      } finally {\n        if (isCompoundFile) {\n          dirToTest.close();\n        }\n      }\n    }\n    \n    return new SegmentInfo(dir, version, name, docCount, delGen, docStoreOffset,\n      docStoreSegment, docStoreIsCompoundFile, normGen, isCompoundFile,\n      delCount, hasProx, codec, diagnostics, hasVectors);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"296df632fd63421ea20756fa11ad36fbc6f4c8a9","date":1327957998,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xSegmentInfosReader#readSegmentInfo(Directory,int,ChecksumIndexInput).mjava","pathOld":"lucene/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xSegmentInfosReader#readSegmentInfo(Directory,int,ChecksumIndexInput).mjava","sourceNew":"  // if we make a preflex impl we can remove a lot of this hair...\n  public SegmentInfo readSegmentInfo(Directory dir, int format, ChecksumIndexInput input) throws IOException {\n    final String version;\n    if (format <= SegmentInfos.FORMAT_3_1) {\n      version = input.readString();\n    } else {\n      version = null;\n    }\n    final String name = input.readString();\n    final int docCount = input.readInt();\n    final long delGen = input.readLong();\n    final int docStoreOffset = input.readInt();\n    final String docStoreSegment;\n    final boolean docStoreIsCompoundFile;\n    if (docStoreOffset != -1) {\n      docStoreSegment = input.readString();\n      docStoreIsCompoundFile = input.readByte() == SegmentInfo.YES;\n    } else {\n      docStoreSegment = name;\n      docStoreIsCompoundFile = false;\n    }\n\n    // pre-4.0 indexes write a byte if there is a single norms file\n    byte b = input.readByte();\n    assert 1 == b : \"expected 1 but was: \"+ b + \" format: \" + format;\n\n    final int numNormGen = input.readInt();\n    final Map<Integer,Long> normGen;\n    if (numNormGen == SegmentInfo.NO) {\n      normGen = null;\n    } else {\n      normGen = new HashMap<Integer, Long>();\n      for(int j=0;j<numNormGen;j++) {\n        normGen.put(j, input.readLong());\n      }\n    }\n    final boolean isCompoundFile = input.readByte() == SegmentInfo.YES;\n\n    final int delCount = input.readInt();\n    assert delCount <= docCount;\n\n    final int hasProx = input.readByte();\n\n    final Codec codec = Codec.forName(\"Lucene3x\");\n    final Map<String,String> diagnostics = input.readStringStringMap();\n\n    final int hasVectors;\n    if (format <= SegmentInfos.FORMAT_HAS_VECTORS) {\n      hasVectors = input.readByte();\n    } else {\n      final String storesSegment;\n      final String ext;\n      final boolean storeIsCompoundFile;\n      if (docStoreOffset != -1) {\n        storesSegment = docStoreSegment;\n        storeIsCompoundFile = docStoreIsCompoundFile;\n        ext = Lucene3xCodec.COMPOUND_FILE_STORE_EXTENSION;\n      } else {\n        storesSegment = name;\n        storeIsCompoundFile = isCompoundFile;\n        ext = IndexFileNames.COMPOUND_FILE_EXTENSION;\n      }\n      final Directory dirToTest;\n      if (storeIsCompoundFile) {\n        dirToTest = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(storesSegment, \"\", ext), IOContext.READONCE, false);\n      } else {\n        dirToTest = dir;\n      }\n      try {\n        hasVectors = dirToTest.fileExists(IndexFileNames.segmentFileName(storesSegment, \"\", Lucene3xTermVectorsReader.VECTORS_INDEX_EXTENSION)) ? SegmentInfo.YES : SegmentInfo.NO;\n      } finally {\n        if (isCompoundFile) {\n          dirToTest.close();\n        }\n      }\n    }\n    \n    return new SegmentInfo(dir, version, name, docCount, delGen, docStoreOffset,\n      docStoreSegment, docStoreIsCompoundFile, normGen, isCompoundFile,\n      delCount, hasProx, codec, diagnostics, hasVectors);\n  }\n\n","sourceOld":"  // if we make a preflex impl we can remove a lot of this hair...\n  public SegmentInfo readSegmentInfo(Directory dir, int format, ChecksumIndexInput input) throws IOException {\n    final String version;\n    if (format <= SegmentInfos.FORMAT_3_1) {\n      version = input.readString();\n    } else {\n      version = null;\n    }\n    final String name = input.readString();\n    final int docCount = input.readInt();\n    final long delGen = input.readLong();\n    final int docStoreOffset = input.readInt();\n    final String docStoreSegment;\n    final boolean docStoreIsCompoundFile;\n    if (docStoreOffset != -1) {\n      docStoreSegment = input.readString();\n      docStoreIsCompoundFile = input.readByte() == SegmentInfo.YES;\n    } else {\n      docStoreSegment = name;\n      docStoreIsCompoundFile = false;\n    }\n\n    // pre-4.0 indexes write a byte if there is a single norms file\n    byte b = input.readByte();\n    assert 1 == b : \"expected 1 but was: \"+ b + \" format: \" + format;\n\n    final int numNormGen = input.readInt();\n    final Map<Integer,Long> normGen;\n    if (numNormGen == SegmentInfo.NO) {\n      normGen = null;\n    } else {\n      normGen = new HashMap<Integer, Long>();\n      for(int j=0;j<numNormGen;j++) {\n        normGen.put(j, input.readLong());\n      }\n    }\n    final boolean isCompoundFile = input.readByte() == SegmentInfo.YES;\n\n    final int delCount = input.readInt();\n    assert delCount <= docCount;\n\n    final int hasProx = input.readByte();\n\n    final Codec codec = Codec.forName(\"Lucene3x\");\n    final Map<String,String> diagnostics = input.readStringStringMap();\n\n    final int hasVectors;\n    if (format <= SegmentInfos.FORMAT_HAS_VECTORS) {\n      hasVectors = input.readByte();\n    } else {\n      final String storesSegment;\n      final String ext;\n      final boolean storeIsCompoundFile;\n      if (docStoreOffset != -1) {\n        storesSegment = docStoreSegment;\n        storeIsCompoundFile = docStoreIsCompoundFile;\n        ext = IndexFileNames.COMPOUND_FILE_STORE_EXTENSION;\n      } else {\n        storesSegment = name;\n        storeIsCompoundFile = isCompoundFile;\n        ext = IndexFileNames.COMPOUND_FILE_EXTENSION;\n      }\n      final Directory dirToTest;\n      if (storeIsCompoundFile) {\n        dirToTest = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(storesSegment, \"\", ext), IOContext.READONCE, false);\n      } else {\n        dirToTest = dir;\n      }\n      try {\n        hasVectors = dirToTest.fileExists(IndexFileNames.segmentFileName(storesSegment, \"\", Lucene3xTermVectorsReader.VECTORS_INDEX_EXTENSION)) ? SegmentInfo.YES : SegmentInfo.NO;\n      } finally {\n        if (isCompoundFile) {\n          dirToTest.close();\n        }\n      }\n    }\n    \n    return new SegmentInfo(dir, version, name, docCount, delGen, docStoreOffset,\n      docStoreSegment, docStoreIsCompoundFile, normGen, isCompoundFile,\n      delCount, hasProx, codec, diagnostics, hasVectors);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"410e066f093e407222d9681429d209084e783149","date":1327958394,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xSegmentInfosReader#readSegmentInfo(Directory,int,ChecksumIndexInput).mjava","pathOld":"lucene/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xSegmentInfosReader#readSegmentInfo(Directory,int,ChecksumIndexInput).mjava","sourceNew":"  // if we make a preflex impl we can remove a lot of this hair...\n  public SegmentInfo readSegmentInfo(Directory dir, int format, ChecksumIndexInput input) throws IOException {\n    final String version;\n    if (format <= SegmentInfos.FORMAT_3_1) {\n      version = input.readString();\n    } else {\n      version = null;\n    }\n    final String name = input.readString();\n    final int docCount = input.readInt();\n    final long delGen = input.readLong();\n    final int docStoreOffset = input.readInt();\n    final String docStoreSegment;\n    final boolean docStoreIsCompoundFile;\n    if (docStoreOffset != -1) {\n      docStoreSegment = input.readString();\n      docStoreIsCompoundFile = input.readByte() == SegmentInfo.YES;\n    } else {\n      docStoreSegment = name;\n      docStoreIsCompoundFile = false;\n    }\n\n    // pre-4.0 indexes write a byte if there is a single norms file\n    byte b = input.readByte();\n    assert 1 == b : \"expected 1 but was: \"+ b + \" format: \" + format;\n\n    final int numNormGen = input.readInt();\n    final Map<Integer,Long> normGen;\n    if (numNormGen == SegmentInfo.NO) {\n      normGen = null;\n    } else {\n      normGen = new HashMap<Integer, Long>();\n      for(int j=0;j<numNormGen;j++) {\n        normGen.put(j, input.readLong());\n      }\n    }\n    final boolean isCompoundFile = input.readByte() == SegmentInfo.YES;\n\n    final int delCount = input.readInt();\n    assert delCount <= docCount;\n\n    final int hasProx = input.readByte();\n\n    final Codec codec = Codec.forName(\"Lucene3x\");\n    final Map<String,String> diagnostics = input.readStringStringMap();\n\n    final int hasVectors;\n    if (format <= SegmentInfos.FORMAT_HAS_VECTORS) {\n      hasVectors = input.readByte();\n    } else {\n      final String storesSegment;\n      final String ext;\n      final boolean storeIsCompoundFile;\n      if (docStoreOffset != -1) {\n        storesSegment = docStoreSegment;\n        storeIsCompoundFile = docStoreIsCompoundFile;\n        ext = Lucene3xCodec.COMPOUND_FILE_STORE_EXTENSION;\n      } else {\n        storesSegment = name;\n        storeIsCompoundFile = isCompoundFile;\n        ext = IndexFileNames.COMPOUND_FILE_EXTENSION;\n      }\n      final Directory dirToTest;\n      if (storeIsCompoundFile) {\n        dirToTest = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(storesSegment, \"\", ext), IOContext.READONCE, false);\n      } else {\n        dirToTest = dir;\n      }\n      try {\n        hasVectors = dirToTest.fileExists(IndexFileNames.segmentFileName(storesSegment, \"\", Lucene3xTermVectorsReader.VECTORS_INDEX_EXTENSION)) ? SegmentInfo.YES : SegmentInfo.NO;\n      } finally {\n        if (isCompoundFile) {\n          dirToTest.close();\n        }\n      }\n    }\n    \n    return new SegmentInfo(dir, version, name, docCount, delGen, docStoreOffset,\n      docStoreSegment, docStoreIsCompoundFile, normGen, isCompoundFile,\n      delCount, hasProx, codec, diagnostics, hasVectors);\n  }\n\n","sourceOld":"  // if we make a preflex impl we can remove a lot of this hair...\n  public SegmentInfo readSegmentInfo(Directory dir, int format, ChecksumIndexInput input) throws IOException {\n    final String version;\n    if (format <= SegmentInfos.FORMAT_3_1) {\n      version = input.readString();\n    } else {\n      version = null;\n    }\n    final String name = input.readString();\n    final int docCount = input.readInt();\n    final long delGen = input.readLong();\n    final int docStoreOffset = input.readInt();\n    final String docStoreSegment;\n    final boolean docStoreIsCompoundFile;\n    if (docStoreOffset != -1) {\n      docStoreSegment = input.readString();\n      docStoreIsCompoundFile = input.readByte() == SegmentInfo.YES;\n    } else {\n      docStoreSegment = name;\n      docStoreIsCompoundFile = false;\n    }\n\n    // pre-4.0 indexes write a byte if there is a single norms file\n    byte b = input.readByte();\n    assert 1 == b : \"expected 1 but was: \"+ b + \" format: \" + format;\n\n    final int numNormGen = input.readInt();\n    final Map<Integer,Long> normGen;\n    if (numNormGen == SegmentInfo.NO) {\n      normGen = null;\n    } else {\n      normGen = new HashMap<Integer, Long>();\n      for(int j=0;j<numNormGen;j++) {\n        normGen.put(j, input.readLong());\n      }\n    }\n    final boolean isCompoundFile = input.readByte() == SegmentInfo.YES;\n\n    final int delCount = input.readInt();\n    assert delCount <= docCount;\n\n    final int hasProx = input.readByte();\n\n    final Codec codec = Codec.forName(\"Lucene3x\");\n    final Map<String,String> diagnostics = input.readStringStringMap();\n\n    final int hasVectors;\n    if (format <= SegmentInfos.FORMAT_HAS_VECTORS) {\n      hasVectors = input.readByte();\n    } else {\n      final String storesSegment;\n      final String ext;\n      final boolean storeIsCompoundFile;\n      if (docStoreOffset != -1) {\n        storesSegment = docStoreSegment;\n        storeIsCompoundFile = docStoreIsCompoundFile;\n        ext = IndexFileNames.COMPOUND_FILE_STORE_EXTENSION;\n      } else {\n        storesSegment = name;\n        storeIsCompoundFile = isCompoundFile;\n        ext = IndexFileNames.COMPOUND_FILE_EXTENSION;\n      }\n      final Directory dirToTest;\n      if (storeIsCompoundFile) {\n        dirToTest = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(storesSegment, \"\", ext), IOContext.READONCE, false);\n      } else {\n        dirToTest = dir;\n      }\n      try {\n        hasVectors = dirToTest.fileExists(IndexFileNames.segmentFileName(storesSegment, \"\", Lucene3xTermVectorsReader.VECTORS_INDEX_EXTENSION)) ? SegmentInfo.YES : SegmentInfo.NO;\n      } finally {\n        if (isCompoundFile) {\n          dirToTest.close();\n        }\n      }\n    }\n    \n    return new SegmentInfo(dir, version, name, docCount, delGen, docStoreOffset,\n      docStoreSegment, docStoreIsCompoundFile, normGen, isCompoundFile,\n      delCount, hasProx, codec, diagnostics, hasVectors);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xSegmentInfosReader#readSegmentInfo(Directory,int,ChecksumIndexInput).mjava","pathOld":"lucene/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xSegmentInfosReader#readSegmentInfo(Directory,int,ChecksumIndexInput).mjava","sourceNew":"  // if we make a preflex impl we can remove a lot of this hair...\n  public SegmentInfo readSegmentInfo(Directory dir, int format, ChecksumIndexInput input) throws IOException {\n    final String version;\n    if (format <= SegmentInfos.FORMAT_3_1) {\n      version = input.readString();\n    } else {\n      version = null;\n    }\n    final String name = input.readString();\n    final int docCount = input.readInt();\n    final long delGen = input.readLong();\n    final int docStoreOffset = input.readInt();\n    final String docStoreSegment;\n    final boolean docStoreIsCompoundFile;\n    if (docStoreOffset != -1) {\n      docStoreSegment = input.readString();\n      docStoreIsCompoundFile = input.readByte() == SegmentInfo.YES;\n    } else {\n      docStoreSegment = name;\n      docStoreIsCompoundFile = false;\n    }\n\n    // pre-4.0 indexes write a byte if there is a single norms file\n    byte b = input.readByte();\n    assert 1 == b : \"expected 1 but was: \"+ b + \" format: \" + format;\n\n    final int numNormGen = input.readInt();\n    final Map<Integer,Long> normGen;\n    if (numNormGen == SegmentInfo.NO) {\n      normGen = null;\n    } else {\n      normGen = new HashMap<Integer, Long>();\n      for(int j=0;j<numNormGen;j++) {\n        normGen.put(j, input.readLong());\n      }\n    }\n    final boolean isCompoundFile = input.readByte() == SegmentInfo.YES;\n\n    final int delCount = input.readInt();\n    assert delCount <= docCount;\n\n    final int hasProx = input.readByte();\n\n    final Codec codec = Codec.forName(\"Lucene3x\");\n    final Map<String,String> diagnostics = input.readStringStringMap();\n\n    final int hasVectors;\n    if (format <= SegmentInfos.FORMAT_HAS_VECTORS) {\n      hasVectors = input.readByte();\n    } else {\n      final String storesSegment;\n      final String ext;\n      final boolean storeIsCompoundFile;\n      if (docStoreOffset != -1) {\n        storesSegment = docStoreSegment;\n        storeIsCompoundFile = docStoreIsCompoundFile;\n        ext = Lucene3xCodec.COMPOUND_FILE_STORE_EXTENSION;\n      } else {\n        storesSegment = name;\n        storeIsCompoundFile = isCompoundFile;\n        ext = IndexFileNames.COMPOUND_FILE_EXTENSION;\n      }\n      final Directory dirToTest;\n      if (storeIsCompoundFile) {\n        dirToTest = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(storesSegment, \"\", ext), IOContext.READONCE, false);\n      } else {\n        dirToTest = dir;\n      }\n      try {\n        hasVectors = dirToTest.fileExists(IndexFileNames.segmentFileName(storesSegment, \"\", Lucene3xTermVectorsReader.VECTORS_INDEX_EXTENSION)) ? SegmentInfo.YES : SegmentInfo.NO;\n      } finally {\n        if (isCompoundFile) {\n          dirToTest.close();\n        }\n      }\n    }\n    \n    return new SegmentInfo(dir, version, name, docCount, delGen, docStoreOffset,\n      docStoreSegment, docStoreIsCompoundFile, normGen, isCompoundFile,\n      delCount, hasProx, codec, diagnostics, hasVectors);\n  }\n\n","sourceOld":"  // if we make a preflex impl we can remove a lot of this hair...\n  public SegmentInfo readSegmentInfo(Directory dir, int format, ChecksumIndexInput input) throws IOException {\n    final String version;\n    if (format <= SegmentInfos.FORMAT_3_1) {\n      version = input.readString();\n    } else {\n      version = null;\n    }\n    final String name = input.readString();\n    final int docCount = input.readInt();\n    final long delGen = input.readLong();\n    final int docStoreOffset = input.readInt();\n    final String docStoreSegment;\n    final boolean docStoreIsCompoundFile;\n    if (docStoreOffset != -1) {\n      docStoreSegment = input.readString();\n      docStoreIsCompoundFile = input.readByte() == SegmentInfo.YES;\n    } else {\n      docStoreSegment = name;\n      docStoreIsCompoundFile = false;\n    }\n\n    // pre-4.0 indexes write a byte if there is a single norms file\n    byte b = input.readByte();\n    assert 1 == b : \"expected 1 but was: \"+ b + \" format: \" + format;\n\n    final int numNormGen = input.readInt();\n    final Map<Integer,Long> normGen;\n    if (numNormGen == SegmentInfo.NO) {\n      normGen = null;\n    } else {\n      normGen = new HashMap<Integer, Long>();\n      for(int j=0;j<numNormGen;j++) {\n        normGen.put(j, input.readLong());\n      }\n    }\n    final boolean isCompoundFile = input.readByte() == SegmentInfo.YES;\n\n    final int delCount = input.readInt();\n    assert delCount <= docCount;\n\n    final int hasProx = input.readByte();\n\n    final Codec codec = Codec.forName(\"Lucene3x\");\n    final Map<String,String> diagnostics = input.readStringStringMap();\n\n    final int hasVectors;\n    if (format <= SegmentInfos.FORMAT_HAS_VECTORS) {\n      hasVectors = input.readByte();\n    } else {\n      final String storesSegment;\n      final String ext;\n      final boolean storeIsCompoundFile;\n      if (docStoreOffset != -1) {\n        storesSegment = docStoreSegment;\n        storeIsCompoundFile = docStoreIsCompoundFile;\n        ext = Lucene3xCodec.COMPOUND_FILE_STORE_EXTENSION;\n      } else {\n        storesSegment = name;\n        storeIsCompoundFile = isCompoundFile;\n        ext = IndexFileNames.COMPOUND_FILE_EXTENSION;\n      }\n      final Directory dirToTest;\n      if (storeIsCompoundFile) {\n        dirToTest = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(storesSegment, \"\", ext), IOContext.READONCE, false);\n      } else {\n        dirToTest = dir;\n      }\n      try {\n        hasVectors = dirToTest.fileExists(IndexFileNames.segmentFileName(storesSegment, \"\", Lucene3xTermVectorsReader.VECTORS_INDEX_EXTENSION)) ? SegmentInfo.YES : SegmentInfo.NO;\n      } finally {\n        if (isCompoundFile) {\n          dirToTest.close();\n        }\n      }\n    }\n    \n    return new SegmentInfo(dir, version, name, docCount, delGen, docStoreOffset,\n      docStoreSegment, docStoreIsCompoundFile, normGen, isCompoundFile,\n      delCount, hasProx, codec, diagnostics, hasVectors);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"410e066f093e407222d9681429d209084e783149":["7e0127a0bf2a1895ba6109cbbd451359b9c0653d","296df632fd63421ea20756fa11ad36fbc6f4c8a9"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["296df632fd63421ea20756fa11ad36fbc6f4c8a9"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"296df632fd63421ea20756fa11ad36fbc6f4c8a9":["7e0127a0bf2a1895ba6109cbbd451359b9c0653d","be9e3e7d2fc880996ffcfe9a8fc47057b647e9e3"],"7e0127a0bf2a1895ba6109cbbd451359b9c0653d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"be9e3e7d2fc880996ffcfe9a8fc47057b647e9e3":["7e0127a0bf2a1895ba6109cbbd451359b9c0653d"]},"commit2Childs":{"410e066f093e407222d9681429d209084e783149":[],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["7e0127a0bf2a1895ba6109cbbd451359b9c0653d"],"296df632fd63421ea20756fa11ad36fbc6f4c8a9":["410e066f093e407222d9681429d209084e783149","3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"7e0127a0bf2a1895ba6109cbbd451359b9c0653d":["410e066f093e407222d9681429d209084e783149","296df632fd63421ea20756fa11ad36fbc6f4c8a9","be9e3e7d2fc880996ffcfe9a8fc47057b647e9e3"],"be9e3e7d2fc880996ffcfe9a8fc47057b647e9e3":["296df632fd63421ea20756fa11ad36fbc6f4c8a9"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["410e066f093e407222d9681429d209084e783149","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}