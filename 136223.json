{"path":"contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/DocMaker#createDocument(DocData,int,int).mjava","commits":[{"id":"6944b9fa6d8ef96b83ae2d3a4332d03b3857355b","date":1245355139,"type":0,"author":"Mark Robert Miller","isMerge":false,"pathNew":"contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/DocMaker#createDocument(DocData,int,int).mjava","pathOld":"/dev/null","sourceNew":"  // create a doc\n  // use only part of the body, modify it to keep the rest (or use all if size==0).\n  // reset the docdata properties so they are not added more than once.\n  private Document createDocument(DocData docData, int size, int cnt) throws UnsupportedEncodingException {\n    int docid = incrNumDocsCreated();\n    DocState ds = reuseFields ? getDocState() : localDocState;\n    Document doc = reuseFields ? ds.doc : new Document();\n    doc.getFields().clear();\n    \n    // Set ID_FIELD\n    Field idField = ds.getField(ID_FIELD, storeVal, indexVal, termVecVal);\n    idField.setValue(\"doc\" + docid);\n    doc.add(idField);\n    \n    // Set NAME_FIELD\n    String name = docData.getName();\n    if (name == null) name = \"\";\n    name = cnt < 0 ? name : name + \"_\" + cnt;\n    Field nameField = ds.getField(NAME_FIELD, storeVal, indexVal, termVecVal);\n    nameField.setValue(name);\n    doc.add(nameField);\n    \n    // Set DATE_FIELD\n    String date = docData.getDate();\n    if (date == null) {\n      date = \"\";\n    }\n    Field dateField = ds.getField(DATE_FIELD, storeVal, indexVal, termVecVal);\n    dateField.setValue(date);\n    doc.add(dateField);\n    \n    // Set TITLE_FIELD\n    String title = docData.getTitle();\n    Field titleField = ds.getField(TITLE_FIELD, storeVal, indexVal, termVecVal);\n    titleField.setValue(title == null ? \"\" : title);\n    doc.add(titleField);\n    \n    String body = docData.getBody();\n    if (body != null && body.length() > 0) {\n      String bdy;\n      if (size <= 0 || size >= body.length()) {\n        bdy = body; // use all\n        docData.setBody(\"\"); // nothing left\n      } else {\n        // attempt not to break words - if whitespace found within next 20 chars...\n        for (int n = size - 1; n < size + 20 && n < body.length(); n++) {\n          if (Character.isWhitespace(body.charAt(n))) {\n            size = n;\n            break;\n          }\n        }\n        bdy = body.substring(0, size); // use part\n        docData.setBody(body.substring(size)); // some left\n      }\n      Field bodyField = ds.getField(BODY_FIELD, storeVal, indexVal, termVecVal);\n      bodyField.setValue(bdy);\n      doc.add(bodyField);\n      \n      if (storeBytes) {\n        Field bytesField = ds.getField(BYTES_FIELD, Store.YES, Index.NOT_ANALYZED_NO_NORMS, TermVector.NO);\n        bytesField.setValue(bdy.getBytes(\"UTF-8\"));\n        doc.add(bytesField);\n      }\n    }\n\n    Properties props = docData.getProps();\n    if (props != null) {\n      for (Iterator iterator = props.entrySet().iterator(); iterator.hasNext();) {\n        Entry entry = (Entry) iterator.next();\n        Field f = ds.getField((String) entry.getKey(), storeVal, indexVal, termVecVal);\n        f.setValue((String) entry.getValue());\n        doc.add(f);\n      }\n      docData.setProps(null);\n    }\n    //System.out.println(\"============== Created doc \"+numDocsCreated+\" :\\n\"+doc+\"\\n==========\");\n    return doc;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["a78a90fc9701e511308346ea29f4f5e548bb39fe","a78a90fc9701e511308346ea29f4f5e548bb39fe"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"edbc02bad7b5b2634d0cf080d93d96fc03b901f8","date":1246037214,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/DocMaker#createDocument(DocData,int,int).mjava","pathOld":"contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/DocMaker#createDocument(DocData,int,int).mjava","sourceNew":"  // create a doc\n  // use only part of the body, modify it to keep the rest (or use all if size==0).\n  // reset the docdata properties so they are not added more than once.\n  private Document createDocument(DocData docData, int size, int cnt) throws UnsupportedEncodingException {\n    int docid = incrNumDocsCreated();\n    DocState ds = reuseFields ? getDocState() : localDocState;\n    Document doc = reuseFields ? ds.doc : new Document();\n    doc.getFields().clear();\n    \n    // Set ID_FIELD\n    Field idField = ds.getField(ID_FIELD, storeVal, Index.NOT_ANALYZED_NO_NORMS, termVecVal);\n    idField.setValue(\"doc\" + docid);\n    doc.add(idField);\n    \n    // Set NAME_FIELD\n    String name = docData.getName();\n    if (name == null) name = \"\";\n    name = cnt < 0 ? name : name + \"_\" + cnt;\n    Field nameField = ds.getField(NAME_FIELD, storeVal, indexVal, termVecVal);\n    nameField.setValue(name);\n    doc.add(nameField);\n    \n    // Set DATE_FIELD\n    String date = docData.getDate();\n    if (date == null) {\n      date = \"\";\n    }\n    Field dateField = ds.getField(DATE_FIELD, storeVal, indexVal, termVecVal);\n    dateField.setValue(date);\n    doc.add(dateField);\n    \n    // Set TITLE_FIELD\n    String title = docData.getTitle();\n    Field titleField = ds.getField(TITLE_FIELD, storeVal, indexVal, termVecVal);\n    titleField.setValue(title == null ? \"\" : title);\n    doc.add(titleField);\n    \n    String body = docData.getBody();\n    if (body != null && body.length() > 0) {\n      String bdy;\n      if (size <= 0 || size >= body.length()) {\n        bdy = body; // use all\n        docData.setBody(\"\"); // nothing left\n      } else {\n        // attempt not to break words - if whitespace found within next 20 chars...\n        for (int n = size - 1; n < size + 20 && n < body.length(); n++) {\n          if (Character.isWhitespace(body.charAt(n))) {\n            size = n;\n            break;\n          }\n        }\n        bdy = body.substring(0, size); // use part\n        docData.setBody(body.substring(size)); // some left\n      }\n      Field bodyField = ds.getField(BODY_FIELD, storeVal, bodyIndexVal, termVecVal);\n      bodyField.setValue(bdy);\n      doc.add(bodyField);\n      \n      if (storeBytes) {\n        Field bytesField = ds.getField(BYTES_FIELD, Store.YES, Index.NOT_ANALYZED_NO_NORMS, TermVector.NO);\n        bytesField.setValue(bdy.getBytes(\"UTF-8\"));\n        doc.add(bytesField);\n      }\n    }\n\n    if (indexProperties) {\n      Properties props = docData.getProps();\n      if (props != null) {\n        for (Iterator iterator = props.entrySet().iterator(); iterator.hasNext();) {\n          Entry entry = (Entry) iterator.next();\n          Field f = ds.getField((String) entry.getKey(), storeVal, indexVal, termVecVal);\n          f.setValue((String) entry.getValue());\n          doc.add(f);\n        }\n        docData.setProps(null);\n      }\n    }\n    \n    //System.out.println(\"============== Created doc \"+numDocsCreated+\" :\\n\"+doc+\"\\n==========\");\n    return doc;\n  }\n\n","sourceOld":"  // create a doc\n  // use only part of the body, modify it to keep the rest (or use all if size==0).\n  // reset the docdata properties so they are not added more than once.\n  private Document createDocument(DocData docData, int size, int cnt) throws UnsupportedEncodingException {\n    int docid = incrNumDocsCreated();\n    DocState ds = reuseFields ? getDocState() : localDocState;\n    Document doc = reuseFields ? ds.doc : new Document();\n    doc.getFields().clear();\n    \n    // Set ID_FIELD\n    Field idField = ds.getField(ID_FIELD, storeVal, indexVal, termVecVal);\n    idField.setValue(\"doc\" + docid);\n    doc.add(idField);\n    \n    // Set NAME_FIELD\n    String name = docData.getName();\n    if (name == null) name = \"\";\n    name = cnt < 0 ? name : name + \"_\" + cnt;\n    Field nameField = ds.getField(NAME_FIELD, storeVal, indexVal, termVecVal);\n    nameField.setValue(name);\n    doc.add(nameField);\n    \n    // Set DATE_FIELD\n    String date = docData.getDate();\n    if (date == null) {\n      date = \"\";\n    }\n    Field dateField = ds.getField(DATE_FIELD, storeVal, indexVal, termVecVal);\n    dateField.setValue(date);\n    doc.add(dateField);\n    \n    // Set TITLE_FIELD\n    String title = docData.getTitle();\n    Field titleField = ds.getField(TITLE_FIELD, storeVal, indexVal, termVecVal);\n    titleField.setValue(title == null ? \"\" : title);\n    doc.add(titleField);\n    \n    String body = docData.getBody();\n    if (body != null && body.length() > 0) {\n      String bdy;\n      if (size <= 0 || size >= body.length()) {\n        bdy = body; // use all\n        docData.setBody(\"\"); // nothing left\n      } else {\n        // attempt not to break words - if whitespace found within next 20 chars...\n        for (int n = size - 1; n < size + 20 && n < body.length(); n++) {\n          if (Character.isWhitespace(body.charAt(n))) {\n            size = n;\n            break;\n          }\n        }\n        bdy = body.substring(0, size); // use part\n        docData.setBody(body.substring(size)); // some left\n      }\n      Field bodyField = ds.getField(BODY_FIELD, storeVal, indexVal, termVecVal);\n      bodyField.setValue(bdy);\n      doc.add(bodyField);\n      \n      if (storeBytes) {\n        Field bytesField = ds.getField(BYTES_FIELD, Store.YES, Index.NOT_ANALYZED_NO_NORMS, TermVector.NO);\n        bytesField.setValue(bdy.getBytes(\"UTF-8\"));\n        doc.add(bytesField);\n      }\n    }\n\n    Properties props = docData.getProps();\n    if (props != null) {\n      for (Iterator iterator = props.entrySet().iterator(); iterator.hasNext();) {\n        Entry entry = (Entry) iterator.next();\n        Field f = ds.getField((String) entry.getKey(), storeVal, indexVal, termVecVal);\n        f.setValue((String) entry.getValue());\n        doc.add(f);\n      }\n      docData.setProps(null);\n    }\n    //System.out.println(\"============== Created doc \"+numDocsCreated+\" :\\n\"+doc+\"\\n==========\");\n    return doc;\n  }\n\n","bugFix":null,"bugIntro":["a78a90fc9701e511308346ea29f4f5e548bb39fe","a78a90fc9701e511308346ea29f4f5e548bb39fe"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1bc1076e669ef72f6939198a862b40a0ffd1fc70","date":1248689703,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/DocMaker#createDocument(DocData,int,int).mjava","pathOld":"contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/DocMaker#createDocument(DocData,int,int).mjava","sourceNew":"  // create a doc\n  // use only part of the body, modify it to keep the rest (or use all if size==0).\n  // reset the docdata properties so they are not added more than once.\n  private Document createDocument(DocData docData, int size, int cnt) throws UnsupportedEncodingException {\n\n    final DocState ds = reuseFields ? getDocState() : localDocState;\n    final Document doc = reuseFields ? ds.doc : new Document();\n    doc.getFields().clear();\n    \n    // Set ID_FIELD\n    Field idField = ds.getField(ID_FIELD, storeVal, Index.NOT_ANALYZED_NO_NORMS, termVecVal);\n    idField.setValue(\"doc\" + (r != null ? r.nextInt(updateDocIDLimit) : incrNumDocsCreated()));\n    doc.add(idField);\n    \n    // Set NAME_FIELD\n    String name = docData.getName();\n    if (name == null) name = \"\";\n    name = cnt < 0 ? name : name + \"_\" + cnt;\n    Field nameField = ds.getField(NAME_FIELD, storeVal, indexVal, termVecVal);\n    nameField.setValue(name);\n    doc.add(nameField);\n    \n    // Set DATE_FIELD\n    String date = docData.getDate();\n    if (date == null) {\n      date = \"\";\n    }\n    Field dateField = ds.getField(DATE_FIELD, storeVal, indexVal, termVecVal);\n    dateField.setValue(date);\n    doc.add(dateField);\n    \n    // Set TITLE_FIELD\n    String title = docData.getTitle();\n    Field titleField = ds.getField(TITLE_FIELD, storeVal, indexVal, termVecVal);\n    titleField.setValue(title == null ? \"\" : title);\n    doc.add(titleField);\n    \n    String body = docData.getBody();\n    if (body != null && body.length() > 0) {\n      String bdy;\n      if (size <= 0 || size >= body.length()) {\n        bdy = body; // use all\n        docData.setBody(\"\"); // nothing left\n      } else {\n        // attempt not to break words - if whitespace found within next 20 chars...\n        for (int n = size - 1; n < size + 20 && n < body.length(); n++) {\n          if (Character.isWhitespace(body.charAt(n))) {\n            size = n;\n            break;\n          }\n        }\n        bdy = body.substring(0, size); // use part\n        docData.setBody(body.substring(size)); // some left\n      }\n      Field bodyField = ds.getField(BODY_FIELD, storeVal, bodyIndexVal, termVecVal);\n      bodyField.setValue(bdy);\n      doc.add(bodyField);\n      \n      if (storeBytes) {\n        Field bytesField = ds.getField(BYTES_FIELD, Store.YES, Index.NOT_ANALYZED_NO_NORMS, TermVector.NO);\n        bytesField.setValue(bdy.getBytes(\"UTF-8\"));\n        doc.add(bytesField);\n      }\n    }\n\n    if (indexProperties) {\n      Properties props = docData.getProps();\n      if (props != null) {\n        for (Iterator iterator = props.entrySet().iterator(); iterator.hasNext();) {\n          Entry entry = (Entry) iterator.next();\n          Field f = ds.getField((String) entry.getKey(), storeVal, indexVal, termVecVal);\n          f.setValue((String) entry.getValue());\n          doc.add(f);\n        }\n        docData.setProps(null);\n      }\n    }\n    \n    //System.out.println(\"============== Created doc \"+numDocsCreated+\" :\\n\"+doc+\"\\n==========\");\n    return doc;\n  }\n\n","sourceOld":"  // create a doc\n  // use only part of the body, modify it to keep the rest (or use all if size==0).\n  // reset the docdata properties so they are not added more than once.\n  private Document createDocument(DocData docData, int size, int cnt) throws UnsupportedEncodingException {\n    int docid = incrNumDocsCreated();\n    DocState ds = reuseFields ? getDocState() : localDocState;\n    Document doc = reuseFields ? ds.doc : new Document();\n    doc.getFields().clear();\n    \n    // Set ID_FIELD\n    Field idField = ds.getField(ID_FIELD, storeVal, Index.NOT_ANALYZED_NO_NORMS, termVecVal);\n    idField.setValue(\"doc\" + docid);\n    doc.add(idField);\n    \n    // Set NAME_FIELD\n    String name = docData.getName();\n    if (name == null) name = \"\";\n    name = cnt < 0 ? name : name + \"_\" + cnt;\n    Field nameField = ds.getField(NAME_FIELD, storeVal, indexVal, termVecVal);\n    nameField.setValue(name);\n    doc.add(nameField);\n    \n    // Set DATE_FIELD\n    String date = docData.getDate();\n    if (date == null) {\n      date = \"\";\n    }\n    Field dateField = ds.getField(DATE_FIELD, storeVal, indexVal, termVecVal);\n    dateField.setValue(date);\n    doc.add(dateField);\n    \n    // Set TITLE_FIELD\n    String title = docData.getTitle();\n    Field titleField = ds.getField(TITLE_FIELD, storeVal, indexVal, termVecVal);\n    titleField.setValue(title == null ? \"\" : title);\n    doc.add(titleField);\n    \n    String body = docData.getBody();\n    if (body != null && body.length() > 0) {\n      String bdy;\n      if (size <= 0 || size >= body.length()) {\n        bdy = body; // use all\n        docData.setBody(\"\"); // nothing left\n      } else {\n        // attempt not to break words - if whitespace found within next 20 chars...\n        for (int n = size - 1; n < size + 20 && n < body.length(); n++) {\n          if (Character.isWhitespace(body.charAt(n))) {\n            size = n;\n            break;\n          }\n        }\n        bdy = body.substring(0, size); // use part\n        docData.setBody(body.substring(size)); // some left\n      }\n      Field bodyField = ds.getField(BODY_FIELD, storeVal, bodyIndexVal, termVecVal);\n      bodyField.setValue(bdy);\n      doc.add(bodyField);\n      \n      if (storeBytes) {\n        Field bytesField = ds.getField(BYTES_FIELD, Store.YES, Index.NOT_ANALYZED_NO_NORMS, TermVector.NO);\n        bytesField.setValue(bdy.getBytes(\"UTF-8\"));\n        doc.add(bytesField);\n      }\n    }\n\n    if (indexProperties) {\n      Properties props = docData.getProps();\n      if (props != null) {\n        for (Iterator iterator = props.entrySet().iterator(); iterator.hasNext();) {\n          Entry entry = (Entry) iterator.next();\n          Field f = ds.getField((String) entry.getKey(), storeVal, indexVal, termVecVal);\n          f.setValue((String) entry.getValue());\n          doc.add(f);\n        }\n        docData.setProps(null);\n      }\n    }\n    \n    //System.out.println(\"============== Created doc \"+numDocsCreated+\" :\\n\"+doc+\"\\n==========\");\n    return doc;\n  }\n\n","bugFix":null,"bugIntro":["1c001b73abaf2c7481f219514cc5e9e953c760b4"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ffdf794cee8d43eb612df752c592cef2dc3e75ae","date":1256465578,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/DocMaker#createDocument(DocData,int,int).mjava","pathOld":"contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/DocMaker#createDocument(DocData,int,int).mjava","sourceNew":"  // create a doc\n  // use only part of the body, modify it to keep the rest (or use all if size==0).\n  // reset the docdata properties so they are not added more than once.\n  private Document createDocument(DocData docData, int size, int cnt) throws UnsupportedEncodingException {\n\n    final DocState ds = reuseFields ? getDocState() : localDocState;\n    final Document doc = reuseFields ? ds.doc : new Document();\n    doc.getFields().clear();\n    \n    // Set ID_FIELD\n    Field idField = ds.getField(ID_FIELD, storeVal, Index.NOT_ANALYZED_NO_NORMS, termVecVal);\n    idField.setValue(\"doc\" + (r != null ? r.nextInt(updateDocIDLimit) : incrNumDocsCreated()));\n    doc.add(idField);\n    \n    // Set NAME_FIELD\n    String name = docData.getName();\n    if (name == null) name = \"\";\n    name = cnt < 0 ? name : name + \"_\" + cnt;\n    Field nameField = ds.getField(NAME_FIELD, storeVal, indexVal, termVecVal);\n    nameField.setValue(name);\n    doc.add(nameField);\n    \n    // Set DATE_FIELD\n    String date = docData.getDate();\n    if (date == null) {\n      date = \"\";\n    }\n    Field dateField = ds.getField(DATE_FIELD, storeVal, indexVal, termVecVal);\n    dateField.setValue(date);\n    doc.add(dateField);\n    \n    // Set TITLE_FIELD\n    String title = docData.getTitle();\n    Field titleField = ds.getField(TITLE_FIELD, storeVal, indexVal, termVecVal);\n    titleField.setValue(title == null ? \"\" : title);\n    doc.add(titleField);\n    \n    String body = docData.getBody();\n    if (body != null && body.length() > 0) {\n      String bdy;\n      if (size <= 0 || size >= body.length()) {\n        bdy = body; // use all\n        docData.setBody(\"\"); // nothing left\n      } else {\n        // attempt not to break words - if whitespace found within next 20 chars...\n        for (int n = size - 1; n < size + 20 && n < body.length(); n++) {\n          if (Character.isWhitespace(body.charAt(n))) {\n            size = n;\n            break;\n          }\n        }\n        bdy = body.substring(0, size); // use part\n        docData.setBody(body.substring(size)); // some left\n      }\n      Field bodyField = ds.getField(BODY_FIELD, storeVal, bodyIndexVal, termVecVal);\n      bodyField.setValue(bdy);\n      doc.add(bodyField);\n      \n      if (storeBytes) {\n        Field bytesField = ds.getField(BYTES_FIELD, Store.YES, Index.NOT_ANALYZED_NO_NORMS, TermVector.NO);\n        bytesField.setValue(bdy.getBytes(\"UTF-8\"));\n        doc.add(bytesField);\n      }\n    }\n\n    if (indexProperties) {\n      Properties props = docData.getProps();\n      if (props != null) {\n        for (final Map.Entry<Object,Object> entry : props.entrySet()) {\n          Field f = ds.getField((String) entry.getKey(), storeVal, indexVal, termVecVal);\n          f.setValue((String) entry.getValue());\n          doc.add(f);\n        }\n        docData.setProps(null);\n      }\n    }\n    \n    //System.out.println(\"============== Created doc \"+numDocsCreated+\" :\\n\"+doc+\"\\n==========\");\n    return doc;\n  }\n\n","sourceOld":"  // create a doc\n  // use only part of the body, modify it to keep the rest (or use all if size==0).\n  // reset the docdata properties so they are not added more than once.\n  private Document createDocument(DocData docData, int size, int cnt) throws UnsupportedEncodingException {\n\n    final DocState ds = reuseFields ? getDocState() : localDocState;\n    final Document doc = reuseFields ? ds.doc : new Document();\n    doc.getFields().clear();\n    \n    // Set ID_FIELD\n    Field idField = ds.getField(ID_FIELD, storeVal, Index.NOT_ANALYZED_NO_NORMS, termVecVal);\n    idField.setValue(\"doc\" + (r != null ? r.nextInt(updateDocIDLimit) : incrNumDocsCreated()));\n    doc.add(idField);\n    \n    // Set NAME_FIELD\n    String name = docData.getName();\n    if (name == null) name = \"\";\n    name = cnt < 0 ? name : name + \"_\" + cnt;\n    Field nameField = ds.getField(NAME_FIELD, storeVal, indexVal, termVecVal);\n    nameField.setValue(name);\n    doc.add(nameField);\n    \n    // Set DATE_FIELD\n    String date = docData.getDate();\n    if (date == null) {\n      date = \"\";\n    }\n    Field dateField = ds.getField(DATE_FIELD, storeVal, indexVal, termVecVal);\n    dateField.setValue(date);\n    doc.add(dateField);\n    \n    // Set TITLE_FIELD\n    String title = docData.getTitle();\n    Field titleField = ds.getField(TITLE_FIELD, storeVal, indexVal, termVecVal);\n    titleField.setValue(title == null ? \"\" : title);\n    doc.add(titleField);\n    \n    String body = docData.getBody();\n    if (body != null && body.length() > 0) {\n      String bdy;\n      if (size <= 0 || size >= body.length()) {\n        bdy = body; // use all\n        docData.setBody(\"\"); // nothing left\n      } else {\n        // attempt not to break words - if whitespace found within next 20 chars...\n        for (int n = size - 1; n < size + 20 && n < body.length(); n++) {\n          if (Character.isWhitespace(body.charAt(n))) {\n            size = n;\n            break;\n          }\n        }\n        bdy = body.substring(0, size); // use part\n        docData.setBody(body.substring(size)); // some left\n      }\n      Field bodyField = ds.getField(BODY_FIELD, storeVal, bodyIndexVal, termVecVal);\n      bodyField.setValue(bdy);\n      doc.add(bodyField);\n      \n      if (storeBytes) {\n        Field bytesField = ds.getField(BYTES_FIELD, Store.YES, Index.NOT_ANALYZED_NO_NORMS, TermVector.NO);\n        bytesField.setValue(bdy.getBytes(\"UTF-8\"));\n        doc.add(bytesField);\n      }\n    }\n\n    if (indexProperties) {\n      Properties props = docData.getProps();\n      if (props != null) {\n        for (Iterator iterator = props.entrySet().iterator(); iterator.hasNext();) {\n          Entry entry = (Entry) iterator.next();\n          Field f = ds.getField((String) entry.getKey(), storeVal, indexVal, termVecVal);\n          f.setValue((String) entry.getValue());\n          doc.add(f);\n        }\n        docData.setProps(null);\n      }\n    }\n    \n    //System.out.println(\"============== Created doc \"+numDocsCreated+\" :\\n\"+doc+\"\\n==========\");\n    return doc;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1c001b73abaf2c7481f219514cc5e9e953c760b4","date":1256724383,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/DocMaker#createDocument(DocData,int,int).mjava","pathOld":"contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/DocMaker#createDocument(DocData,int,int).mjava","sourceNew":"  // create a doc\n  // use only part of the body, modify it to keep the rest (or use all if size==0).\n  // reset the docdata properties so they are not added more than once.\n  private Document createDocument(DocData docData, int size, int cnt) throws UnsupportedEncodingException {\n\n    final DocState ds = getDocState();\n    final Document doc = reuseFields ? ds.doc : new Document();\n    doc.getFields().clear();\n    \n    // Set ID_FIELD\n    Field idField = ds.getField(ID_FIELD, storeVal, Index.NOT_ANALYZED_NO_NORMS, termVecVal);\n    idField.setValue(\"doc\" + (r != null ? r.nextInt(updateDocIDLimit) : incrNumDocsCreated()));\n    doc.add(idField);\n    \n    // Set NAME_FIELD\n    String name = docData.getName();\n    if (name == null) name = \"\";\n    name = cnt < 0 ? name : name + \"_\" + cnt;\n    Field nameField = ds.getField(NAME_FIELD, storeVal, indexVal, termVecVal);\n    nameField.setValue(name);\n    doc.add(nameField);\n    \n    // Set DATE_FIELD\n    String date = docData.getDate();\n    if (date == null) {\n      date = \"\";\n    }\n    Field dateField = ds.getField(DATE_FIELD, storeVal, indexVal, termVecVal);\n    dateField.setValue(date);\n    doc.add(dateField);\n    \n    // Set TITLE_FIELD\n    String title = docData.getTitle();\n    Field titleField = ds.getField(TITLE_FIELD, storeVal, indexVal, termVecVal);\n    titleField.setValue(title == null ? \"\" : title);\n    doc.add(titleField);\n    \n    String body = docData.getBody();\n    if (body != null && body.length() > 0) {\n      String bdy;\n      if (size <= 0 || size >= body.length()) {\n        bdy = body; // use all\n        docData.setBody(\"\"); // nothing left\n      } else {\n        // attempt not to break words - if whitespace found within next 20 chars...\n        for (int n = size - 1; n < size + 20 && n < body.length(); n++) {\n          if (Character.isWhitespace(body.charAt(n))) {\n            size = n;\n            break;\n          }\n        }\n        bdy = body.substring(0, size); // use part\n        docData.setBody(body.substring(size)); // some left\n      }\n      Field bodyField = ds.getField(BODY_FIELD, storeVal, bodyIndexVal, termVecVal);\n      bodyField.setValue(bdy);\n      doc.add(bodyField);\n      \n      if (storeBytes) {\n        Field bytesField = ds.getField(BYTES_FIELD, Store.YES, Index.NOT_ANALYZED_NO_NORMS, TermVector.NO);\n        bytesField.setValue(bdy.getBytes(\"UTF-8\"));\n        doc.add(bytesField);\n      }\n    }\n\n    if (indexProperties) {\n      Properties props = docData.getProps();\n      if (props != null) {\n        for (final Map.Entry<Object,Object> entry : props.entrySet()) {\n          Field f = ds.getField((String) entry.getKey(), storeVal, indexVal, termVecVal);\n          f.setValue((String) entry.getValue());\n          doc.add(f);\n        }\n        docData.setProps(null);\n      }\n    }\n    \n    //System.out.println(\"============== Created doc \"+numDocsCreated+\" :\\n\"+doc+\"\\n==========\");\n    return doc;\n  }\n\n","sourceOld":"  // create a doc\n  // use only part of the body, modify it to keep the rest (or use all if size==0).\n  // reset the docdata properties so they are not added more than once.\n  private Document createDocument(DocData docData, int size, int cnt) throws UnsupportedEncodingException {\n\n    final DocState ds = reuseFields ? getDocState() : localDocState;\n    final Document doc = reuseFields ? ds.doc : new Document();\n    doc.getFields().clear();\n    \n    // Set ID_FIELD\n    Field idField = ds.getField(ID_FIELD, storeVal, Index.NOT_ANALYZED_NO_NORMS, termVecVal);\n    idField.setValue(\"doc\" + (r != null ? r.nextInt(updateDocIDLimit) : incrNumDocsCreated()));\n    doc.add(idField);\n    \n    // Set NAME_FIELD\n    String name = docData.getName();\n    if (name == null) name = \"\";\n    name = cnt < 0 ? name : name + \"_\" + cnt;\n    Field nameField = ds.getField(NAME_FIELD, storeVal, indexVal, termVecVal);\n    nameField.setValue(name);\n    doc.add(nameField);\n    \n    // Set DATE_FIELD\n    String date = docData.getDate();\n    if (date == null) {\n      date = \"\";\n    }\n    Field dateField = ds.getField(DATE_FIELD, storeVal, indexVal, termVecVal);\n    dateField.setValue(date);\n    doc.add(dateField);\n    \n    // Set TITLE_FIELD\n    String title = docData.getTitle();\n    Field titleField = ds.getField(TITLE_FIELD, storeVal, indexVal, termVecVal);\n    titleField.setValue(title == null ? \"\" : title);\n    doc.add(titleField);\n    \n    String body = docData.getBody();\n    if (body != null && body.length() > 0) {\n      String bdy;\n      if (size <= 0 || size >= body.length()) {\n        bdy = body; // use all\n        docData.setBody(\"\"); // nothing left\n      } else {\n        // attempt not to break words - if whitespace found within next 20 chars...\n        for (int n = size - 1; n < size + 20 && n < body.length(); n++) {\n          if (Character.isWhitespace(body.charAt(n))) {\n            size = n;\n            break;\n          }\n        }\n        bdy = body.substring(0, size); // use part\n        docData.setBody(body.substring(size)); // some left\n      }\n      Field bodyField = ds.getField(BODY_FIELD, storeVal, bodyIndexVal, termVecVal);\n      bodyField.setValue(bdy);\n      doc.add(bodyField);\n      \n      if (storeBytes) {\n        Field bytesField = ds.getField(BYTES_FIELD, Store.YES, Index.NOT_ANALYZED_NO_NORMS, TermVector.NO);\n        bytesField.setValue(bdy.getBytes(\"UTF-8\"));\n        doc.add(bytesField);\n      }\n    }\n\n    if (indexProperties) {\n      Properties props = docData.getProps();\n      if (props != null) {\n        for (final Map.Entry<Object,Object> entry : props.entrySet()) {\n          Field f = ds.getField((String) entry.getKey(), storeVal, indexVal, termVecVal);\n          f.setValue((String) entry.getValue());\n          doc.add(f);\n        }\n        docData.setProps(null);\n      }\n    }\n    \n    //System.out.println(\"============== Created doc \"+numDocsCreated+\" :\\n\"+doc+\"\\n==========\");\n    return doc;\n  }\n\n","bugFix":["1bc1076e669ef72f6939198a862b40a0ffd1fc70"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6db0ffb3c24c39faecaf89e17fe056cbb484ae5e","date":1257551050,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/DocMaker#createDocument(DocData,int,int).mjava","pathOld":"contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/DocMaker#createDocument(DocData,int,int).mjava","sourceNew":"  // create a doc\n  // use only part of the body, modify it to keep the rest (or use all if size==0).\n  // reset the docdata properties so they are not added more than once.\n  private Document createDocument(DocData docData, int size, int cnt) throws UnsupportedEncodingException {\n\n    final DocState ds = getDocState();\n    final Document doc = reuseFields ? ds.doc : new Document();\n    doc.getFields().clear();\n    \n    // Set ID_FIELD\n    Field idField = ds.getField(ID_FIELD, storeVal, Index.NOT_ANALYZED_NO_NORMS, termVecVal);\n    idField.setValue(\"doc\" + (r != null ? r.nextInt(updateDocIDLimit) : incrNumDocsCreated()));\n    doc.add(idField);\n    \n    // Set NAME_FIELD\n    String name = docData.getName();\n    if (name == null) name = \"\";\n    name = cnt < 0 ? name : name + \"_\" + cnt;\n    Field nameField = ds.getField(NAME_FIELD, storeVal, indexVal, termVecVal);\n    nameField.setValue(name);\n    doc.add(nameField);\n    \n    // Set DATE_FIELD\n    String date = docData.getDate();\n    if (date == null) {\n      date = \"\";\n    }\n    Field dateField = ds.getField(DATE_FIELD, storeVal, indexVal, termVecVal);\n    dateField.setValue(date);\n    doc.add(dateField);\n    \n    // Set TITLE_FIELD\n    String title = docData.getTitle();\n    Field titleField = ds.getField(TITLE_FIELD, storeVal, indexVal, termVecVal);\n    titleField.setValue(title == null ? \"\" : title);\n    doc.add(titleField);\n    \n    String body = docData.getBody();\n    if (body != null && body.length() > 0) {\n      String bdy;\n      if (size <= 0 || size >= body.length()) {\n        bdy = body; // use all\n        docData.setBody(\"\"); // nothing left\n      } else {\n        // attempt not to break words - if whitespace found within next 20 chars...\n        for (int n = size - 1; n < size + 20 && n < body.length(); n++) {\n          if (Character.isWhitespace(body.charAt(n))) {\n            size = n;\n            break;\n          }\n        }\n        bdy = body.substring(0, size); // use part\n        docData.setBody(body.substring(size)); // some left\n      }\n      Field bodyField = ds.getField(BODY_FIELD, bodyStoreVal, bodyIndexVal, termVecVal);\n      bodyField.setValue(bdy);\n      doc.add(bodyField);\n      \n      if (storeBytes) {\n        Field bytesField = ds.getField(BYTES_FIELD, Store.YES, Index.NOT_ANALYZED_NO_NORMS, TermVector.NO);\n        bytesField.setValue(bdy.getBytes(\"UTF-8\"));\n        doc.add(bytesField);\n      }\n    }\n\n    if (indexProperties) {\n      Properties props = docData.getProps();\n      if (props != null) {\n        for (final Map.Entry<Object,Object> entry : props.entrySet()) {\n          Field f = ds.getField((String) entry.getKey(), storeVal, indexVal, termVecVal);\n          f.setValue((String) entry.getValue());\n          doc.add(f);\n        }\n        docData.setProps(null);\n      }\n    }\n    \n    //System.out.println(\"============== Created doc \"+numDocsCreated+\" :\\n\"+doc+\"\\n==========\");\n    return doc;\n  }\n\n","sourceOld":"  // create a doc\n  // use only part of the body, modify it to keep the rest (or use all if size==0).\n  // reset the docdata properties so they are not added more than once.\n  private Document createDocument(DocData docData, int size, int cnt) throws UnsupportedEncodingException {\n\n    final DocState ds = getDocState();\n    final Document doc = reuseFields ? ds.doc : new Document();\n    doc.getFields().clear();\n    \n    // Set ID_FIELD\n    Field idField = ds.getField(ID_FIELD, storeVal, Index.NOT_ANALYZED_NO_NORMS, termVecVal);\n    idField.setValue(\"doc\" + (r != null ? r.nextInt(updateDocIDLimit) : incrNumDocsCreated()));\n    doc.add(idField);\n    \n    // Set NAME_FIELD\n    String name = docData.getName();\n    if (name == null) name = \"\";\n    name = cnt < 0 ? name : name + \"_\" + cnt;\n    Field nameField = ds.getField(NAME_FIELD, storeVal, indexVal, termVecVal);\n    nameField.setValue(name);\n    doc.add(nameField);\n    \n    // Set DATE_FIELD\n    String date = docData.getDate();\n    if (date == null) {\n      date = \"\";\n    }\n    Field dateField = ds.getField(DATE_FIELD, storeVal, indexVal, termVecVal);\n    dateField.setValue(date);\n    doc.add(dateField);\n    \n    // Set TITLE_FIELD\n    String title = docData.getTitle();\n    Field titleField = ds.getField(TITLE_FIELD, storeVal, indexVal, termVecVal);\n    titleField.setValue(title == null ? \"\" : title);\n    doc.add(titleField);\n    \n    String body = docData.getBody();\n    if (body != null && body.length() > 0) {\n      String bdy;\n      if (size <= 0 || size >= body.length()) {\n        bdy = body; // use all\n        docData.setBody(\"\"); // nothing left\n      } else {\n        // attempt not to break words - if whitespace found within next 20 chars...\n        for (int n = size - 1; n < size + 20 && n < body.length(); n++) {\n          if (Character.isWhitespace(body.charAt(n))) {\n            size = n;\n            break;\n          }\n        }\n        bdy = body.substring(0, size); // use part\n        docData.setBody(body.substring(size)); // some left\n      }\n      Field bodyField = ds.getField(BODY_FIELD, storeVal, bodyIndexVal, termVecVal);\n      bodyField.setValue(bdy);\n      doc.add(bodyField);\n      \n      if (storeBytes) {\n        Field bytesField = ds.getField(BYTES_FIELD, Store.YES, Index.NOT_ANALYZED_NO_NORMS, TermVector.NO);\n        bytesField.setValue(bdy.getBytes(\"UTF-8\"));\n        doc.add(bytesField);\n      }\n    }\n\n    if (indexProperties) {\n      Properties props = docData.getProps();\n      if (props != null) {\n        for (final Map.Entry<Object,Object> entry : props.entrySet()) {\n          Field f = ds.getField((String) entry.getKey(), storeVal, indexVal, termVecVal);\n          f.setValue((String) entry.getValue());\n          doc.add(f);\n        }\n        docData.setProps(null);\n      }\n    }\n    \n    //System.out.println(\"============== Created doc \"+numDocsCreated+\" :\\n\"+doc+\"\\n==========\");\n    return doc;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/DocMaker#createDocument(DocData,int,int).mjava","pathOld":"contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/DocMaker#createDocument(DocData,int,int).mjava","sourceNew":"  // create a doc\n  // use only part of the body, modify it to keep the rest (or use all if size==0).\n  // reset the docdata properties so they are not added more than once.\n  private Document createDocument(DocData docData, int size, int cnt) throws UnsupportedEncodingException {\n\n    final DocState ds = getDocState();\n    final Document doc = reuseFields ? ds.doc : new Document();\n    doc.getFields().clear();\n    \n    // Set ID_FIELD\n    Field idField = ds.getField(ID_FIELD, storeVal, Index.NOT_ANALYZED_NO_NORMS, termVecVal);\n    idField.setValue(\"doc\" + (r != null ? r.nextInt(updateDocIDLimit) : incrNumDocsCreated()));\n    doc.add(idField);\n    \n    // Set NAME_FIELD\n    String name = docData.getName();\n    if (name == null) name = \"\";\n    name = cnt < 0 ? name : name + \"_\" + cnt;\n    Field nameField = ds.getField(NAME_FIELD, storeVal, indexVal, termVecVal);\n    nameField.setValue(name);\n    doc.add(nameField);\n    \n    // Set DATE_FIELD\n    String date = docData.getDate();\n    if (date == null) {\n      date = \"\";\n    }\n    Field dateField = ds.getField(DATE_FIELD, storeVal, indexVal, termVecVal);\n    dateField.setValue(date);\n    doc.add(dateField);\n    \n    // Set TITLE_FIELD\n    String title = docData.getTitle();\n    Field titleField = ds.getField(TITLE_FIELD, storeVal, indexVal, termVecVal);\n    titleField.setValue(title == null ? \"\" : title);\n    doc.add(titleField);\n    \n    String body = docData.getBody();\n    if (body != null && body.length() > 0) {\n      String bdy;\n      if (size <= 0 || size >= body.length()) {\n        bdy = body; // use all\n        docData.setBody(\"\"); // nothing left\n      } else {\n        // attempt not to break words - if whitespace found within next 20 chars...\n        for (int n = size - 1; n < size + 20 && n < body.length(); n++) {\n          if (Character.isWhitespace(body.charAt(n))) {\n            size = n;\n            break;\n          }\n        }\n        bdy = body.substring(0, size); // use part\n        docData.setBody(body.substring(size)); // some left\n      }\n      Field bodyField = ds.getField(BODY_FIELD, bodyStoreVal, bodyIndexVal, termVecVal);\n      bodyField.setValue(bdy);\n      doc.add(bodyField);\n      \n      if (storeBytes) {\n        Field bytesField = ds.getField(BYTES_FIELD, Store.YES, Index.NOT_ANALYZED_NO_NORMS, TermVector.NO);\n        bytesField.setValue(bdy.getBytes(\"UTF-8\"));\n        doc.add(bytesField);\n      }\n    }\n\n    if (indexProperties) {\n      Properties props = docData.getProps();\n      if (props != null) {\n        for (final Map.Entry<Object,Object> entry : props.entrySet()) {\n          Field f = ds.getField((String) entry.getKey(), storeVal, indexVal, termVecVal);\n          f.setValue((String) entry.getValue());\n          doc.add(f);\n        }\n        docData.setProps(null);\n      }\n    }\n    \n    //System.out.println(\"============== Created doc \"+numDocsCreated+\" :\\n\"+doc+\"\\n==========\");\n    return doc;\n  }\n\n","sourceOld":"  // create a doc\n  // use only part of the body, modify it to keep the rest (or use all if size==0).\n  // reset the docdata properties so they are not added more than once.\n  private Document createDocument(DocData docData, int size, int cnt) throws UnsupportedEncodingException {\n\n    final DocState ds = getDocState();\n    final Document doc = reuseFields ? ds.doc : new Document();\n    doc.getFields().clear();\n    \n    // Set ID_FIELD\n    Field idField = ds.getField(ID_FIELD, storeVal, Index.NOT_ANALYZED_NO_NORMS, termVecVal);\n    idField.setValue(\"doc\" + (r != null ? r.nextInt(updateDocIDLimit) : incrNumDocsCreated()));\n    doc.add(idField);\n    \n    // Set NAME_FIELD\n    String name = docData.getName();\n    if (name == null) name = \"\";\n    name = cnt < 0 ? name : name + \"_\" + cnt;\n    Field nameField = ds.getField(NAME_FIELD, storeVal, indexVal, termVecVal);\n    nameField.setValue(name);\n    doc.add(nameField);\n    \n    // Set DATE_FIELD\n    String date = docData.getDate();\n    if (date == null) {\n      date = \"\";\n    }\n    Field dateField = ds.getField(DATE_FIELD, storeVal, indexVal, termVecVal);\n    dateField.setValue(date);\n    doc.add(dateField);\n    \n    // Set TITLE_FIELD\n    String title = docData.getTitle();\n    Field titleField = ds.getField(TITLE_FIELD, storeVal, indexVal, termVecVal);\n    titleField.setValue(title == null ? \"\" : title);\n    doc.add(titleField);\n    \n    String body = docData.getBody();\n    if (body != null && body.length() > 0) {\n      String bdy;\n      if (size <= 0 || size >= body.length()) {\n        bdy = body; // use all\n        docData.setBody(\"\"); // nothing left\n      } else {\n        // attempt not to break words - if whitespace found within next 20 chars...\n        for (int n = size - 1; n < size + 20 && n < body.length(); n++) {\n          if (Character.isWhitespace(body.charAt(n))) {\n            size = n;\n            break;\n          }\n        }\n        bdy = body.substring(0, size); // use part\n        docData.setBody(body.substring(size)); // some left\n      }\n      Field bodyField = ds.getField(BODY_FIELD, bodyStoreVal, bodyIndexVal, termVecVal);\n      bodyField.setValue(bdy);\n      doc.add(bodyField);\n      \n      if (storeBytes) {\n        Field bytesField = ds.getField(BYTES_FIELD, Store.YES, Index.NOT_ANALYZED_NO_NORMS, TermVector.NO);\n        bytesField.setValue(bdy.getBytes(\"UTF-8\"));\n        doc.add(bytesField);\n      }\n    }\n\n    if (indexProperties) {\n      Properties props = docData.getProps();\n      if (props != null) {\n        for (final Map.Entry<Object,Object> entry : props.entrySet()) {\n          Field f = ds.getField((String) entry.getKey(), storeVal, indexVal, termVecVal);\n          f.setValue((String) entry.getValue());\n          doc.add(f);\n        }\n        docData.setProps(null);\n      }\n    }\n    \n    //System.out.println(\"============== Created doc \"+numDocsCreated+\" :\\n\"+doc+\"\\n==========\");\n    return doc;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"ffdf794cee8d43eb612df752c592cef2dc3e75ae":["1bc1076e669ef72f6939198a862b40a0ffd1fc70"],"6db0ffb3c24c39faecaf89e17fe056cbb484ae5e":["1c001b73abaf2c7481f219514cc5e9e953c760b4"],"6944b9fa6d8ef96b83ae2d3a4332d03b3857355b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"edbc02bad7b5b2634d0cf080d93d96fc03b901f8":["6944b9fa6d8ef96b83ae2d3a4332d03b3857355b"],"1c001b73abaf2c7481f219514cc5e9e953c760b4":["ffdf794cee8d43eb612df752c592cef2dc3e75ae"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["6db0ffb3c24c39faecaf89e17fe056cbb484ae5e"],"1bc1076e669ef72f6939198a862b40a0ffd1fc70":["edbc02bad7b5b2634d0cf080d93d96fc03b901f8"]},"commit2Childs":{"ffdf794cee8d43eb612df752c592cef2dc3e75ae":["1c001b73abaf2c7481f219514cc5e9e953c760b4"],"6db0ffb3c24c39faecaf89e17fe056cbb484ae5e":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"6944b9fa6d8ef96b83ae2d3a4332d03b3857355b":["edbc02bad7b5b2634d0cf080d93d96fc03b901f8"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["6944b9fa6d8ef96b83ae2d3a4332d03b3857355b"],"edbc02bad7b5b2634d0cf080d93d96fc03b901f8":["1bc1076e669ef72f6939198a862b40a0ffd1fc70"],"1c001b73abaf2c7481f219514cc5e9e953c760b4":["6db0ffb3c24c39faecaf89e17fe056cbb484ae5e"],"1bc1076e669ef72f6939198a862b40a0ffd1fc70":["ffdf794cee8d43eb612df752c592cef2dc3e75ae"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}