{"path":"lucene/src/test/org/apache/lucene/search/TestShardSearching#testSimple().mjava","commits":[{"id":"226aae72c0326f4299c16280195bade4530de537","date":1324221898,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestShardSearching#testSimple().mjava","pathOld":"/dev/null","sourceNew":"  public void testSimple() throws Exception {\n    final int numNodes = _TestUtil.nextInt(random, 1, 10);\n\n    final double runTimeSec = atLeast(5) * RANDOM_MULTIPLIER;\n\n    final int minDocsToMakeTerms = _TestUtil.nextInt(random, 5, 20);\n\n    final int maxSearcherAgeSeconds = _TestUtil.nextInt(random, 1, 4);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: numNodes=\" + numNodes + \" runTimeSec=\" + runTimeSec + \" maxSearcherAgeSeconds=\" + maxSearcherAgeSeconds);\n    }\n\n    start(_TestUtil.getTempDir(\"TestShardSearching\").toString(),\n          numNodes,\n          runTimeSec,\n          maxSearcherAgeSeconds\n          );\n\n    final List<PreviousSearchState> priorSearches = new ArrayList<PreviousSearchState>();\n    List<BytesRef> terms = null;\n    while (System.nanoTime() < endTimeNanos) {\n\n      final boolean doFollowon = priorSearches.size() > 0 && random.nextInt(7) == 1;\n\n      // Pick a random node; we will run the query on this node:\n      final int myNodeID = random.nextInt(numNodes);\n\n      final NodeState.ShardIndexSearcher localShardSearcher;\n\n      final PreviousSearchState prevSearchState;\n\n      if (doFollowon) {\n        // Pretend user issued a followon query:\n        prevSearchState = priorSearches.get(random.nextInt(priorSearches.size()));\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: follow-on query age=\" + ((System.nanoTime() - prevSearchState.searchTimeNanos)/1000000000.0));\n        }\n\n        try {\n          localShardSearcher = nodes[myNodeID].acquire(prevSearchState.versions);\n        } catch (SearcherExpiredException see) {\n          // Expected, sometimes; in a \"real\" app we would\n          // either forward this error to the user (\"too\n          // much time has passed; please re-run your\n          // search\") or sneakily just switch to newest\n          // searcher w/o telling them...\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during local shard searcher init: \" + see);\n          }\n          priorSearches.remove(prevSearchState);\n          continue;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: fresh query\");\n        }\n        // Do fresh query:\n        localShardSearcher = nodes[myNodeID].acquire();\n        prevSearchState = null;\n      }\n\n      final IndexReader[] subs = new IndexReader[numNodes];\n\n      PreviousSearchState searchState = null;\n\n      try {\n\n        // Mock: now make a single reader (MultiReader) from all node\n        // searchers.  In a real shard env you can't do this... we\n        // do it to confirm results from the shard searcher\n        // are correct:\n        int docCount = 0;\n        try {\n          for(int nodeID=0;nodeID<numNodes;nodeID++) {\n            final long subVersion = localShardSearcher.nodeVersions[nodeID];\n            final IndexSearcher sub = nodes[nodeID].searchers.acquire(subVersion);\n            if (sub == null) {\n              nodeID--;\n              while(nodeID >= 0) {\n                subs[nodeID].decRef();\n                subs[nodeID] = null;\n                nodeID--;\n              }\n              throw new SearcherExpiredException(\"nodeID=\" + nodeID + \" version=\" + subVersion);\n            }\n            subs[nodeID] = sub.getIndexReader();\n            docCount += subs[nodeID].maxDoc();\n          }\n        } catch (SearcherExpiredException see) {\n          // Expected\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during mock reader init: \" + see);\n          }\n          continue;\n        }\n\n        final IndexReader mockReader = new MultiReader(subs);\n        final IndexSearcher mockSearcher = new IndexSearcher(mockReader);\n\n        Query query;\n        Sort sort;\n\n        if (prevSearchState != null) {\n          query = prevSearchState.query;\n          sort = prevSearchState.sort;\n        } else {\n          if (terms == null && docCount > minDocsToMakeTerms) {\n            // TODO: try to \"focus\" on high freq terms sometimes too\n            // TODO: maybe also periodically reset the terms...?\n            final TermsEnum termsEnum = MultiFields.getTerms(mockReader, \"body\").iterator(null);\n            terms = new ArrayList<BytesRef>();\n            while(termsEnum.next() != null) {\n              terms.add(BytesRef.deepCopyOf(termsEnum.term()));\n            }\n            if (VERBOSE) {\n              System.out.println(\"TEST: init terms: \" + terms.size() + \" terms\");\n            }\n            if (terms.size() == 0) {\n              terms = null;\n            }\n          }\n\n          if (VERBOSE) {\n            System.out.println(\"  maxDoc=\" + mockReader.maxDoc());\n          }\n\n          if (terms != null) {\n            if (random.nextBoolean()) {\n              query = new TermQuery(new Term(\"body\", terms.get(random.nextInt(terms.size()))));\n            } else {\n              final String t = terms.get(random.nextInt(terms.size())).utf8ToString();\n              final String prefix;\n              if (t.length() <= 1) {\n                prefix = t;\n              } else {\n                prefix = t.substring(0, _TestUtil.nextInt(random, 1, 2));\n              }\n              query = new PrefixQuery(new Term(\"body\", prefix));\n            }\n            \n            if (random.nextBoolean()) {\n              sort = null;\n            } else {\n              // TODO: sort by more than 1 field\n              final int what = random.nextInt(3);\n              if (what == 0) {\n                sort = new Sort(SortField.FIELD_SCORE);\n              } else if (what == 1) {\n                // TODO: this sort doesn't merge\n                // correctly... it's tricky because you\n                // could have > 2.1B docs across all shards: \n                //sort = new Sort(SortField.FIELD_DOC);\n                sort = null;\n              } else if (what == 2) {\n                sort = new Sort(new SortField[] {new SortField(\"docid\", SortField.Type.INT, random.nextBoolean())});\n              } else {\n                sort = new Sort(new SortField[] {new SortField(\"title\", SortField.Type.STRING, random.nextBoolean())});\n              }\n            }\n          } else {\n            query = null;\n            sort = null;\n          }\n        }\n\n        if (query != null) {\n\n          try {\n            searchState = assertSame(mockSearcher, localShardSearcher, query, sort, prevSearchState);\n          } catch (SearcherExpiredException see) {\n            // Expected; in a \"real\" app we would\n            // either forward this error to the user (\"too\n            // much time has passed; please re-run your\n            // search\") or sneakily just switch to newest\n            // searcher w/o telling them...\n            if (VERBOSE) {\n              System.out.println(\"  searcher expired during search: \" + see);\n              see.printStackTrace(System.out);\n            }\n            assert prevSearchState != null;\n            priorSearches.remove(prevSearchState);\n          }\n        }\n      } finally {\n        nodes[myNodeID].release(localShardSearcher);\n        for(IndexReader sub : subs) {\n          if (sub != null) {\n            sub.decRef();\n          }\n        }\n      }\n\n      if (searchState != null && searchState.searchAfterLocal != null && random.nextInt(5) == 3) {\n        priorSearches.add(searchState);\n        if (priorSearches.size() > 200) {\n          Collections.shuffle(priorSearches, random);\n          priorSearches.subList(100, priorSearches.size()).clear();\n        }\n      }\n    }\n\n    finish();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8be580b58bcc650d428f3f22de81cadcf51d650a","date":1325279655,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestShardSearching#testSimple().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestShardSearching#testSimple().mjava","sourceNew":"  public void testSimple() throws Exception {\n    final int numNodes = _TestUtil.nextInt(random, 1, 10);\n\n    final double runTimeSec = atLeast(3);\n\n    final int minDocsToMakeTerms = _TestUtil.nextInt(random, 5, 20);\n\n    final int maxSearcherAgeSeconds = _TestUtil.nextInt(random, 1, 3);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: numNodes=\" + numNodes + \" runTimeSec=\" + runTimeSec + \" maxSearcherAgeSeconds=\" + maxSearcherAgeSeconds);\n    }\n\n    start(_TestUtil.getTempDir(\"TestShardSearching\").toString(),\n          numNodes,\n          runTimeSec,\n          maxSearcherAgeSeconds\n          );\n\n    final List<PreviousSearchState> priorSearches = new ArrayList<PreviousSearchState>();\n    List<BytesRef> terms = null;\n    while (System.nanoTime() < endTimeNanos) {\n\n      final boolean doFollowon = priorSearches.size() > 0 && random.nextInt(7) == 1;\n\n      // Pick a random node; we will run the query on this node:\n      final int myNodeID = random.nextInt(numNodes);\n\n      final NodeState.ShardIndexSearcher localShardSearcher;\n\n      final PreviousSearchState prevSearchState;\n\n      if (doFollowon) {\n        // Pretend user issued a followon query:\n        prevSearchState = priorSearches.get(random.nextInt(priorSearches.size()));\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: follow-on query age=\" + ((System.nanoTime() - prevSearchState.searchTimeNanos)/1000000000.0));\n        }\n\n        try {\n          localShardSearcher = nodes[myNodeID].acquire(prevSearchState.versions);\n        } catch (SearcherExpiredException see) {\n          // Expected, sometimes; in a \"real\" app we would\n          // either forward this error to the user (\"too\n          // much time has passed; please re-run your\n          // search\") or sneakily just switch to newest\n          // searcher w/o telling them...\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during local shard searcher init: \" + see);\n          }\n          priorSearches.remove(prevSearchState);\n          continue;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: fresh query\");\n        }\n        // Do fresh query:\n        localShardSearcher = nodes[myNodeID].acquire();\n        prevSearchState = null;\n      }\n\n      final IndexReader[] subs = new IndexReader[numNodes];\n\n      PreviousSearchState searchState = null;\n\n      try {\n\n        // Mock: now make a single reader (MultiReader) from all node\n        // searchers.  In a real shard env you can't do this... we\n        // do it to confirm results from the shard searcher\n        // are correct:\n        int docCount = 0;\n        try {\n          for(int nodeID=0;nodeID<numNodes;nodeID++) {\n            final long subVersion = localShardSearcher.nodeVersions[nodeID];\n            final IndexSearcher sub = nodes[nodeID].searchers.acquire(subVersion);\n            if (sub == null) {\n              nodeID--;\n              while(nodeID >= 0) {\n                subs[nodeID].decRef();\n                subs[nodeID] = null;\n                nodeID--;\n              }\n              throw new SearcherExpiredException(\"nodeID=\" + nodeID + \" version=\" + subVersion);\n            }\n            subs[nodeID] = sub.getIndexReader();\n            docCount += subs[nodeID].maxDoc();\n          }\n        } catch (SearcherExpiredException see) {\n          // Expected\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during mock reader init: \" + see);\n          }\n          continue;\n        }\n\n        final IndexReader mockReader = new MultiReader(subs);\n        final IndexSearcher mockSearcher = new IndexSearcher(mockReader);\n\n        Query query;\n        Sort sort;\n\n        if (prevSearchState != null) {\n          query = prevSearchState.query;\n          sort = prevSearchState.sort;\n        } else {\n          if (terms == null && docCount > minDocsToMakeTerms) {\n            // TODO: try to \"focus\" on high freq terms sometimes too\n            // TODO: maybe also periodically reset the terms...?\n            final TermsEnum termsEnum = MultiFields.getTerms(mockReader, \"body\").iterator(null);\n            terms = new ArrayList<BytesRef>();\n            while(termsEnum.next() != null) {\n              terms.add(BytesRef.deepCopyOf(termsEnum.term()));\n            }\n            if (VERBOSE) {\n              System.out.println(\"TEST: init terms: \" + terms.size() + \" terms\");\n            }\n            if (terms.size() == 0) {\n              terms = null;\n            }\n          }\n\n          if (VERBOSE) {\n            System.out.println(\"  maxDoc=\" + mockReader.maxDoc());\n          }\n\n          if (terms != null) {\n            if (random.nextBoolean()) {\n              query = new TermQuery(new Term(\"body\", terms.get(random.nextInt(terms.size()))));\n            } else {\n              final String t = terms.get(random.nextInt(terms.size())).utf8ToString();\n              final String prefix;\n              if (t.length() <= 1) {\n                prefix = t;\n              } else {\n                prefix = t.substring(0, _TestUtil.nextInt(random, 1, 2));\n              }\n              query = new PrefixQuery(new Term(\"body\", prefix));\n            }\n            \n            if (random.nextBoolean()) {\n              sort = null;\n            } else {\n              // TODO: sort by more than 1 field\n              final int what = random.nextInt(3);\n              if (what == 0) {\n                sort = new Sort(SortField.FIELD_SCORE);\n              } else if (what == 1) {\n                // TODO: this sort doesn't merge\n                // correctly... it's tricky because you\n                // could have > 2.1B docs across all shards: \n                //sort = new Sort(SortField.FIELD_DOC);\n                sort = null;\n              } else if (what == 2) {\n                sort = new Sort(new SortField[] {new SortField(\"docid\", SortField.Type.INT, random.nextBoolean())});\n              } else {\n                sort = new Sort(new SortField[] {new SortField(\"title\", SortField.Type.STRING, random.nextBoolean())});\n              }\n            }\n          } else {\n            query = null;\n            sort = null;\n          }\n        }\n\n        if (query != null) {\n\n          try {\n            searchState = assertSame(mockSearcher, localShardSearcher, query, sort, prevSearchState);\n          } catch (SearcherExpiredException see) {\n            // Expected; in a \"real\" app we would\n            // either forward this error to the user (\"too\n            // much time has passed; please re-run your\n            // search\") or sneakily just switch to newest\n            // searcher w/o telling them...\n            if (VERBOSE) {\n              System.out.println(\"  searcher expired during search: \" + see);\n              see.printStackTrace(System.out);\n            }\n            assert prevSearchState != null;\n            priorSearches.remove(prevSearchState);\n          }\n        }\n      } finally {\n        nodes[myNodeID].release(localShardSearcher);\n        for(IndexReader sub : subs) {\n          if (sub != null) {\n            sub.decRef();\n          }\n        }\n      }\n\n      if (searchState != null && searchState.searchAfterLocal != null && random.nextInt(5) == 3) {\n        priorSearches.add(searchState);\n        if (priorSearches.size() > 200) {\n          Collections.shuffle(priorSearches, random);\n          priorSearches.subList(100, priorSearches.size()).clear();\n        }\n      }\n    }\n\n    finish();\n  }\n\n","sourceOld":"  public void testSimple() throws Exception {\n    final int numNodes = _TestUtil.nextInt(random, 1, 10);\n\n    final double runTimeSec = atLeast(5) * RANDOM_MULTIPLIER;\n\n    final int minDocsToMakeTerms = _TestUtil.nextInt(random, 5, 20);\n\n    final int maxSearcherAgeSeconds = _TestUtil.nextInt(random, 1, 4);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: numNodes=\" + numNodes + \" runTimeSec=\" + runTimeSec + \" maxSearcherAgeSeconds=\" + maxSearcherAgeSeconds);\n    }\n\n    start(_TestUtil.getTempDir(\"TestShardSearching\").toString(),\n          numNodes,\n          runTimeSec,\n          maxSearcherAgeSeconds\n          );\n\n    final List<PreviousSearchState> priorSearches = new ArrayList<PreviousSearchState>();\n    List<BytesRef> terms = null;\n    while (System.nanoTime() < endTimeNanos) {\n\n      final boolean doFollowon = priorSearches.size() > 0 && random.nextInt(7) == 1;\n\n      // Pick a random node; we will run the query on this node:\n      final int myNodeID = random.nextInt(numNodes);\n\n      final NodeState.ShardIndexSearcher localShardSearcher;\n\n      final PreviousSearchState prevSearchState;\n\n      if (doFollowon) {\n        // Pretend user issued a followon query:\n        prevSearchState = priorSearches.get(random.nextInt(priorSearches.size()));\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: follow-on query age=\" + ((System.nanoTime() - prevSearchState.searchTimeNanos)/1000000000.0));\n        }\n\n        try {\n          localShardSearcher = nodes[myNodeID].acquire(prevSearchState.versions);\n        } catch (SearcherExpiredException see) {\n          // Expected, sometimes; in a \"real\" app we would\n          // either forward this error to the user (\"too\n          // much time has passed; please re-run your\n          // search\") or sneakily just switch to newest\n          // searcher w/o telling them...\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during local shard searcher init: \" + see);\n          }\n          priorSearches.remove(prevSearchState);\n          continue;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: fresh query\");\n        }\n        // Do fresh query:\n        localShardSearcher = nodes[myNodeID].acquire();\n        prevSearchState = null;\n      }\n\n      final IndexReader[] subs = new IndexReader[numNodes];\n\n      PreviousSearchState searchState = null;\n\n      try {\n\n        // Mock: now make a single reader (MultiReader) from all node\n        // searchers.  In a real shard env you can't do this... we\n        // do it to confirm results from the shard searcher\n        // are correct:\n        int docCount = 0;\n        try {\n          for(int nodeID=0;nodeID<numNodes;nodeID++) {\n            final long subVersion = localShardSearcher.nodeVersions[nodeID];\n            final IndexSearcher sub = nodes[nodeID].searchers.acquire(subVersion);\n            if (sub == null) {\n              nodeID--;\n              while(nodeID >= 0) {\n                subs[nodeID].decRef();\n                subs[nodeID] = null;\n                nodeID--;\n              }\n              throw new SearcherExpiredException(\"nodeID=\" + nodeID + \" version=\" + subVersion);\n            }\n            subs[nodeID] = sub.getIndexReader();\n            docCount += subs[nodeID].maxDoc();\n          }\n        } catch (SearcherExpiredException see) {\n          // Expected\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during mock reader init: \" + see);\n          }\n          continue;\n        }\n\n        final IndexReader mockReader = new MultiReader(subs);\n        final IndexSearcher mockSearcher = new IndexSearcher(mockReader);\n\n        Query query;\n        Sort sort;\n\n        if (prevSearchState != null) {\n          query = prevSearchState.query;\n          sort = prevSearchState.sort;\n        } else {\n          if (terms == null && docCount > minDocsToMakeTerms) {\n            // TODO: try to \"focus\" on high freq terms sometimes too\n            // TODO: maybe also periodically reset the terms...?\n            final TermsEnum termsEnum = MultiFields.getTerms(mockReader, \"body\").iterator(null);\n            terms = new ArrayList<BytesRef>();\n            while(termsEnum.next() != null) {\n              terms.add(BytesRef.deepCopyOf(termsEnum.term()));\n            }\n            if (VERBOSE) {\n              System.out.println(\"TEST: init terms: \" + terms.size() + \" terms\");\n            }\n            if (terms.size() == 0) {\n              terms = null;\n            }\n          }\n\n          if (VERBOSE) {\n            System.out.println(\"  maxDoc=\" + mockReader.maxDoc());\n          }\n\n          if (terms != null) {\n            if (random.nextBoolean()) {\n              query = new TermQuery(new Term(\"body\", terms.get(random.nextInt(terms.size()))));\n            } else {\n              final String t = terms.get(random.nextInt(terms.size())).utf8ToString();\n              final String prefix;\n              if (t.length() <= 1) {\n                prefix = t;\n              } else {\n                prefix = t.substring(0, _TestUtil.nextInt(random, 1, 2));\n              }\n              query = new PrefixQuery(new Term(\"body\", prefix));\n            }\n            \n            if (random.nextBoolean()) {\n              sort = null;\n            } else {\n              // TODO: sort by more than 1 field\n              final int what = random.nextInt(3);\n              if (what == 0) {\n                sort = new Sort(SortField.FIELD_SCORE);\n              } else if (what == 1) {\n                // TODO: this sort doesn't merge\n                // correctly... it's tricky because you\n                // could have > 2.1B docs across all shards: \n                //sort = new Sort(SortField.FIELD_DOC);\n                sort = null;\n              } else if (what == 2) {\n                sort = new Sort(new SortField[] {new SortField(\"docid\", SortField.Type.INT, random.nextBoolean())});\n              } else {\n                sort = new Sort(new SortField[] {new SortField(\"title\", SortField.Type.STRING, random.nextBoolean())});\n              }\n            }\n          } else {\n            query = null;\n            sort = null;\n          }\n        }\n\n        if (query != null) {\n\n          try {\n            searchState = assertSame(mockSearcher, localShardSearcher, query, sort, prevSearchState);\n          } catch (SearcherExpiredException see) {\n            // Expected; in a \"real\" app we would\n            // either forward this error to the user (\"too\n            // much time has passed; please re-run your\n            // search\") or sneakily just switch to newest\n            // searcher w/o telling them...\n            if (VERBOSE) {\n              System.out.println(\"  searcher expired during search: \" + see);\n              see.printStackTrace(System.out);\n            }\n            assert prevSearchState != null;\n            priorSearches.remove(prevSearchState);\n          }\n        }\n      } finally {\n        nodes[myNodeID].release(localShardSearcher);\n        for(IndexReader sub : subs) {\n          if (sub != null) {\n            sub.decRef();\n          }\n        }\n      }\n\n      if (searchState != null && searchState.searchAfterLocal != null && random.nextInt(5) == 3) {\n        priorSearches.add(searchState);\n        if (priorSearches.size() > 200) {\n          Collections.shuffle(priorSearches, random);\n          priorSearches.subList(100, priorSearches.size()).clear();\n        }\n      }\n    }\n\n    finish();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestShardSearching#testSimple().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestShardSearching#testSimple().mjava","sourceNew":"  public void testSimple() throws Exception {\n    final int numNodes = _TestUtil.nextInt(random, 1, 10);\n\n    final double runTimeSec = atLeast(3);\n\n    final int minDocsToMakeTerms = _TestUtil.nextInt(random, 5, 20);\n\n    final int maxSearcherAgeSeconds = _TestUtil.nextInt(random, 1, 3);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: numNodes=\" + numNodes + \" runTimeSec=\" + runTimeSec + \" maxSearcherAgeSeconds=\" + maxSearcherAgeSeconds);\n    }\n\n    start(_TestUtil.getTempDir(\"TestShardSearching\").toString(),\n          numNodes,\n          runTimeSec,\n          maxSearcherAgeSeconds\n          );\n\n    final List<PreviousSearchState> priorSearches = new ArrayList<PreviousSearchState>();\n    List<BytesRef> terms = null;\n    while (System.nanoTime() < endTimeNanos) {\n\n      final boolean doFollowon = priorSearches.size() > 0 && random.nextInt(7) == 1;\n\n      // Pick a random node; we will run the query on this node:\n      final int myNodeID = random.nextInt(numNodes);\n\n      final NodeState.ShardIndexSearcher localShardSearcher;\n\n      final PreviousSearchState prevSearchState;\n\n      if (doFollowon) {\n        // Pretend user issued a followon query:\n        prevSearchState = priorSearches.get(random.nextInt(priorSearches.size()));\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: follow-on query age=\" + ((System.nanoTime() - prevSearchState.searchTimeNanos)/1000000000.0));\n        }\n\n        try {\n          localShardSearcher = nodes[myNodeID].acquire(prevSearchState.versions);\n        } catch (SearcherExpiredException see) {\n          // Expected, sometimes; in a \"real\" app we would\n          // either forward this error to the user (\"too\n          // much time has passed; please re-run your\n          // search\") or sneakily just switch to newest\n          // searcher w/o telling them...\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during local shard searcher init: \" + see);\n          }\n          priorSearches.remove(prevSearchState);\n          continue;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: fresh query\");\n        }\n        // Do fresh query:\n        localShardSearcher = nodes[myNodeID].acquire();\n        prevSearchState = null;\n      }\n\n      final IndexReader[] subs = new IndexReader[numNodes];\n\n      PreviousSearchState searchState = null;\n\n      try {\n\n        // Mock: now make a single reader (MultiReader) from all node\n        // searchers.  In a real shard env you can't do this... we\n        // do it to confirm results from the shard searcher\n        // are correct:\n        int docCount = 0;\n        try {\n          for(int nodeID=0;nodeID<numNodes;nodeID++) {\n            final long subVersion = localShardSearcher.nodeVersions[nodeID];\n            final IndexSearcher sub = nodes[nodeID].searchers.acquire(subVersion);\n            if (sub == null) {\n              nodeID--;\n              while(nodeID >= 0) {\n                subs[nodeID].decRef();\n                subs[nodeID] = null;\n                nodeID--;\n              }\n              throw new SearcherExpiredException(\"nodeID=\" + nodeID + \" version=\" + subVersion);\n            }\n            subs[nodeID] = sub.getIndexReader();\n            docCount += subs[nodeID].maxDoc();\n          }\n        } catch (SearcherExpiredException see) {\n          // Expected\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during mock reader init: \" + see);\n          }\n          continue;\n        }\n\n        final IndexReader mockReader = new MultiReader(subs);\n        final IndexSearcher mockSearcher = new IndexSearcher(mockReader);\n\n        Query query;\n        Sort sort;\n\n        if (prevSearchState != null) {\n          query = prevSearchState.query;\n          sort = prevSearchState.sort;\n        } else {\n          if (terms == null && docCount > minDocsToMakeTerms) {\n            // TODO: try to \"focus\" on high freq terms sometimes too\n            // TODO: maybe also periodically reset the terms...?\n            final TermsEnum termsEnum = MultiFields.getTerms(mockReader, \"body\").iterator(null);\n            terms = new ArrayList<BytesRef>();\n            while(termsEnum.next() != null) {\n              terms.add(BytesRef.deepCopyOf(termsEnum.term()));\n            }\n            if (VERBOSE) {\n              System.out.println(\"TEST: init terms: \" + terms.size() + \" terms\");\n            }\n            if (terms.size() == 0) {\n              terms = null;\n            }\n          }\n\n          if (VERBOSE) {\n            System.out.println(\"  maxDoc=\" + mockReader.maxDoc());\n          }\n\n          if (terms != null) {\n            if (random.nextBoolean()) {\n              query = new TermQuery(new Term(\"body\", terms.get(random.nextInt(terms.size()))));\n            } else {\n              final String t = terms.get(random.nextInt(terms.size())).utf8ToString();\n              final String prefix;\n              if (t.length() <= 1) {\n                prefix = t;\n              } else {\n                prefix = t.substring(0, _TestUtil.nextInt(random, 1, 2));\n              }\n              query = new PrefixQuery(new Term(\"body\", prefix));\n            }\n            \n            if (random.nextBoolean()) {\n              sort = null;\n            } else {\n              // TODO: sort by more than 1 field\n              final int what = random.nextInt(3);\n              if (what == 0) {\n                sort = new Sort(SortField.FIELD_SCORE);\n              } else if (what == 1) {\n                // TODO: this sort doesn't merge\n                // correctly... it's tricky because you\n                // could have > 2.1B docs across all shards: \n                //sort = new Sort(SortField.FIELD_DOC);\n                sort = null;\n              } else if (what == 2) {\n                sort = new Sort(new SortField[] {new SortField(\"docid\", SortField.Type.INT, random.nextBoolean())});\n              } else {\n                sort = new Sort(new SortField[] {new SortField(\"title\", SortField.Type.STRING, random.nextBoolean())});\n              }\n            }\n          } else {\n            query = null;\n            sort = null;\n          }\n        }\n\n        if (query != null) {\n\n          try {\n            searchState = assertSame(mockSearcher, localShardSearcher, query, sort, prevSearchState);\n          } catch (SearcherExpiredException see) {\n            // Expected; in a \"real\" app we would\n            // either forward this error to the user (\"too\n            // much time has passed; please re-run your\n            // search\") or sneakily just switch to newest\n            // searcher w/o telling them...\n            if (VERBOSE) {\n              System.out.println(\"  searcher expired during search: \" + see);\n              see.printStackTrace(System.out);\n            }\n            assert prevSearchState != null;\n            priorSearches.remove(prevSearchState);\n          }\n        }\n      } finally {\n        nodes[myNodeID].release(localShardSearcher);\n        for(IndexReader sub : subs) {\n          if (sub != null) {\n            sub.decRef();\n          }\n        }\n      }\n\n      if (searchState != null && searchState.searchAfterLocal != null && random.nextInt(5) == 3) {\n        priorSearches.add(searchState);\n        if (priorSearches.size() > 200) {\n          Collections.shuffle(priorSearches, random);\n          priorSearches.subList(100, priorSearches.size()).clear();\n        }\n      }\n    }\n\n    finish();\n  }\n\n","sourceOld":"  public void testSimple() throws Exception {\n    final int numNodes = _TestUtil.nextInt(random, 1, 10);\n\n    final double runTimeSec = atLeast(3);\n\n    final int minDocsToMakeTerms = _TestUtil.nextInt(random, 5, 20);\n\n    final int maxSearcherAgeSeconds = _TestUtil.nextInt(random, 1, 3);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: numNodes=\" + numNodes + \" runTimeSec=\" + runTimeSec + \" maxSearcherAgeSeconds=\" + maxSearcherAgeSeconds);\n    }\n\n    start(_TestUtil.getTempDir(\"TestShardSearching\").toString(),\n          numNodes,\n          runTimeSec,\n          maxSearcherAgeSeconds\n          );\n\n    final List<PreviousSearchState> priorSearches = new ArrayList<PreviousSearchState>();\n    List<BytesRef> terms = null;\n    while (System.nanoTime() < endTimeNanos) {\n\n      final boolean doFollowon = priorSearches.size() > 0 && random.nextInt(7) == 1;\n\n      // Pick a random node; we will run the query on this node:\n      final int myNodeID = random.nextInt(numNodes);\n\n      final NodeState.ShardIndexSearcher localShardSearcher;\n\n      final PreviousSearchState prevSearchState;\n\n      if (doFollowon) {\n        // Pretend user issued a followon query:\n        prevSearchState = priorSearches.get(random.nextInt(priorSearches.size()));\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: follow-on query age=\" + ((System.nanoTime() - prevSearchState.searchTimeNanos)/1000000000.0));\n        }\n\n        try {\n          localShardSearcher = nodes[myNodeID].acquire(prevSearchState.versions);\n        } catch (SearcherExpiredException see) {\n          // Expected, sometimes; in a \"real\" app we would\n          // either forward this error to the user (\"too\n          // much time has passed; please re-run your\n          // search\") or sneakily just switch to newest\n          // searcher w/o telling them...\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during local shard searcher init: \" + see);\n          }\n          priorSearches.remove(prevSearchState);\n          continue;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: fresh query\");\n        }\n        // Do fresh query:\n        localShardSearcher = nodes[myNodeID].acquire();\n        prevSearchState = null;\n      }\n\n      final IndexReader[] subs = new IndexReader[numNodes];\n\n      PreviousSearchState searchState = null;\n\n      try {\n\n        // Mock: now make a single reader (MultiReader) from all node\n        // searchers.  In a real shard env you can't do this... we\n        // do it to confirm results from the shard searcher\n        // are correct:\n        int docCount = 0;\n        try {\n          for(int nodeID=0;nodeID<numNodes;nodeID++) {\n            final long subVersion = localShardSearcher.nodeVersions[nodeID];\n            final IndexSearcher sub = nodes[nodeID].searchers.acquire(subVersion);\n            if (sub == null) {\n              nodeID--;\n              while(nodeID >= 0) {\n                subs[nodeID].decRef();\n                subs[nodeID] = null;\n                nodeID--;\n              }\n              throw new SearcherExpiredException(\"nodeID=\" + nodeID + \" version=\" + subVersion);\n            }\n            subs[nodeID] = sub.getIndexReader();\n            docCount += subs[nodeID].maxDoc();\n          }\n        } catch (SearcherExpiredException see) {\n          // Expected\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during mock reader init: \" + see);\n          }\n          continue;\n        }\n\n        final IndexReader mockReader = new MultiReader(subs);\n        final IndexSearcher mockSearcher = new IndexSearcher(mockReader);\n\n        Query query;\n        Sort sort;\n\n        if (prevSearchState != null) {\n          query = prevSearchState.query;\n          sort = prevSearchState.sort;\n        } else {\n          if (terms == null && docCount > minDocsToMakeTerms) {\n            // TODO: try to \"focus\" on high freq terms sometimes too\n            // TODO: maybe also periodically reset the terms...?\n            final TermsEnum termsEnum = MultiFields.getTerms(mockReader, \"body\").iterator(null);\n            terms = new ArrayList<BytesRef>();\n            while(termsEnum.next() != null) {\n              terms.add(BytesRef.deepCopyOf(termsEnum.term()));\n            }\n            if (VERBOSE) {\n              System.out.println(\"TEST: init terms: \" + terms.size() + \" terms\");\n            }\n            if (terms.size() == 0) {\n              terms = null;\n            }\n          }\n\n          if (VERBOSE) {\n            System.out.println(\"  maxDoc=\" + mockReader.maxDoc());\n          }\n\n          if (terms != null) {\n            if (random.nextBoolean()) {\n              query = new TermQuery(new Term(\"body\", terms.get(random.nextInt(terms.size()))));\n            } else {\n              final String t = terms.get(random.nextInt(terms.size())).utf8ToString();\n              final String prefix;\n              if (t.length() <= 1) {\n                prefix = t;\n              } else {\n                prefix = t.substring(0, _TestUtil.nextInt(random, 1, 2));\n              }\n              query = new PrefixQuery(new Term(\"body\", prefix));\n            }\n            \n            if (random.nextBoolean()) {\n              sort = null;\n            } else {\n              // TODO: sort by more than 1 field\n              final int what = random.nextInt(3);\n              if (what == 0) {\n                sort = new Sort(SortField.FIELD_SCORE);\n              } else if (what == 1) {\n                // TODO: this sort doesn't merge\n                // correctly... it's tricky because you\n                // could have > 2.1B docs across all shards: \n                //sort = new Sort(SortField.FIELD_DOC);\n                sort = null;\n              } else if (what == 2) {\n                sort = new Sort(new SortField[] {new SortField(\"docid\", SortField.Type.INT, random.nextBoolean())});\n              } else {\n                sort = new Sort(new SortField[] {new SortField(\"title\", SortField.Type.STRING, random.nextBoolean())});\n              }\n            }\n          } else {\n            query = null;\n            sort = null;\n          }\n        }\n\n        if (query != null) {\n\n          try {\n            searchState = assertSame(mockSearcher, localShardSearcher, query, sort, prevSearchState);\n          } catch (SearcherExpiredException see) {\n            // Expected; in a \"real\" app we would\n            // either forward this error to the user (\"too\n            // much time has passed; please re-run your\n            // search\") or sneakily just switch to newest\n            // searcher w/o telling them...\n            if (VERBOSE) {\n              System.out.println(\"  searcher expired during search: \" + see);\n              see.printStackTrace(System.out);\n            }\n            assert prevSearchState != null;\n            priorSearches.remove(prevSearchState);\n          }\n        }\n      } finally {\n        nodes[myNodeID].release(localShardSearcher);\n        for(IndexReader sub : subs) {\n          if (sub != null) {\n            sub.decRef();\n          }\n        }\n      }\n\n      if (searchState != null && searchState.searchAfterLocal != null && random.nextInt(5) == 3) {\n        priorSearches.add(searchState);\n        if (priorSearches.size() > 200) {\n          Collections.shuffle(priorSearches, random);\n          priorSearches.subList(100, priorSearches.size()).clear();\n        }\n      }\n    }\n\n    finish();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["8be580b58bcc650d428f3f22de81cadcf51d650a"],"226aae72c0326f4299c16280195bade4530de537":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"8be580b58bcc650d428f3f22de81cadcf51d650a":["226aae72c0326f4299c16280195bade4530de537"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"]},"commit2Childs":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"226aae72c0326f4299c16280195bade4530de537":["8be580b58bcc650d428f3f22de81cadcf51d650a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["226aae72c0326f4299c16280195bade4530de537"],"8be580b58bcc650d428f3f22de81cadcf51d650a":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}