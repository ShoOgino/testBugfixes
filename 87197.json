{"path":"modules/queryparser/src/test/org/apache/lucene/queryparser/flexible/precedence/TestPrecedenceQueryParser#testBoost().mjava","commits":[{"id":"4cf7d991c51b580d4b7bf2ad583dba058c0a2dd1","date":1310612214,"type":1,"author":"Christopher John Male","isMerge":false,"pathNew":"modules/queryparser/src/test/org/apache/lucene/queryparser/flexible/precedence/TestPrecedenceQueryParser#testBoost().mjava","pathOld":"lucene/contrib/queryparser/src/test/org/apache/lucene/queryParser/precedence/TestPrecedenceQueryParser#testBoost().mjava","sourceNew":"  public void testBoost() throws Exception {\n    CharacterRunAutomaton stopSet = new CharacterRunAutomaton(BasicAutomata.makeString(\"on\"));\n    Analyzer oneStopAnalyzer = new MockAnalyzer(random, MockTokenizer.SIMPLE, true, stopSet, true);\n\n    PrecedenceQueryParser qp = new PrecedenceQueryParser();\n    qp.setAnalyzer(oneStopAnalyzer);\n    Query q = qp.parse(\"on^1.0\", \"field\");\n    assertNotNull(q);\n    q = qp.parse(\"\\\"hello\\\"^2.0\", \"field\");\n    assertNotNull(q);\n    assertEquals(q.getBoost(), (float) 2.0, (float) 0.5);\n    q = qp.parse(\"hello^2.0\", \"field\");\n    assertNotNull(q);\n    assertEquals(q.getBoost(), (float) 2.0, (float) 0.5);\n    q = qp.parse(\"\\\"on\\\"^1.0\", \"field\");\n    assertNotNull(q);\n\n    q = getParser(new MockAnalyzer(random, MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true)).parse(\"the^3\",\n        \"field\");\n    assertNotNull(q);\n  }\n\n","sourceOld":"  public void testBoost() throws Exception {\n    CharacterRunAutomaton stopSet = new CharacterRunAutomaton(BasicAutomata.makeString(\"on\"));\n    Analyzer oneStopAnalyzer = new MockAnalyzer(random, MockTokenizer.SIMPLE, true, stopSet, true);\n\n    PrecedenceQueryParser qp = new PrecedenceQueryParser();\n    qp.setAnalyzer(oneStopAnalyzer);\n    Query q = qp.parse(\"on^1.0\", \"field\");\n    assertNotNull(q);\n    q = qp.parse(\"\\\"hello\\\"^2.0\", \"field\");\n    assertNotNull(q);\n    assertEquals(q.getBoost(), (float) 2.0, (float) 0.5);\n    q = qp.parse(\"hello^2.0\", \"field\");\n    assertNotNull(q);\n    assertEquals(q.getBoost(), (float) 2.0, (float) 0.5);\n    q = qp.parse(\"\\\"on\\\"^1.0\", \"field\");\n    assertNotNull(q);\n\n    q = getParser(new MockAnalyzer(random, MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true)).parse(\"the^3\",\n        \"field\");\n    assertNotNull(q);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"modules/queryparser/src/test/org/apache/lucene/queryparser/flexible/precedence/TestPrecedenceQueryParser#testBoost().mjava","pathOld":"modules/queryparser/src/test/org/apache/lucene/queryparser/flexible/precedence/TestPrecedenceQueryParser#testBoost().mjava","sourceNew":"  public void testBoost() throws Exception {\n    CharacterRunAutomaton stopSet = new CharacterRunAutomaton(BasicAutomata.makeString(\"on\"));\n    Analyzer oneStopAnalyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, stopSet, true);\n\n    PrecedenceQueryParser qp = new PrecedenceQueryParser();\n    qp.setAnalyzer(oneStopAnalyzer);\n    Query q = qp.parse(\"on^1.0\", \"field\");\n    assertNotNull(q);\n    q = qp.parse(\"\\\"hello\\\"^2.0\", \"field\");\n    assertNotNull(q);\n    assertEquals(q.getBoost(), (float) 2.0, (float) 0.5);\n    q = qp.parse(\"hello^2.0\", \"field\");\n    assertNotNull(q);\n    assertEquals(q.getBoost(), (float) 2.0, (float) 0.5);\n    q = qp.parse(\"\\\"on\\\"^1.0\", \"field\");\n    assertNotNull(q);\n\n    q = getParser(new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true)).parse(\"the^3\",\n        \"field\");\n    assertNotNull(q);\n  }\n\n","sourceOld":"  public void testBoost() throws Exception {\n    CharacterRunAutomaton stopSet = new CharacterRunAutomaton(BasicAutomata.makeString(\"on\"));\n    Analyzer oneStopAnalyzer = new MockAnalyzer(random, MockTokenizer.SIMPLE, true, stopSet, true);\n\n    PrecedenceQueryParser qp = new PrecedenceQueryParser();\n    qp.setAnalyzer(oneStopAnalyzer);\n    Query q = qp.parse(\"on^1.0\", \"field\");\n    assertNotNull(q);\n    q = qp.parse(\"\\\"hello\\\"^2.0\", \"field\");\n    assertNotNull(q);\n    assertEquals(q.getBoost(), (float) 2.0, (float) 0.5);\n    q = qp.parse(\"hello^2.0\", \"field\");\n    assertNotNull(q);\n    assertEquals(q.getBoost(), (float) 2.0, (float) 0.5);\n    q = qp.parse(\"\\\"on\\\"^1.0\", \"field\");\n    assertNotNull(q);\n\n    q = getParser(new MockAnalyzer(random, MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true)).parse(\"the^3\",\n        \"field\");\n    assertNotNull(q);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/queryparser/src/test/org/apache/lucene/queryparser/flexible/precedence/TestPrecedenceQueryParser#testBoost().mjava","pathOld":"modules/queryparser/src/test/org/apache/lucene/queryparser/flexible/precedence/TestPrecedenceQueryParser#testBoost().mjava","sourceNew":"  public void testBoost() throws Exception {\n    CharacterRunAutomaton stopSet = new CharacterRunAutomaton(BasicAutomata.makeString(\"on\"));\n    Analyzer oneStopAnalyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, stopSet, true);\n\n    PrecedenceQueryParser qp = new PrecedenceQueryParser();\n    qp.setAnalyzer(oneStopAnalyzer);\n    Query q = qp.parse(\"on^1.0\", \"field\");\n    assertNotNull(q);\n    q = qp.parse(\"\\\"hello\\\"^2.0\", \"field\");\n    assertNotNull(q);\n    assertEquals(q.getBoost(), (float) 2.0, (float) 0.5);\n    q = qp.parse(\"hello^2.0\", \"field\");\n    assertNotNull(q);\n    assertEquals(q.getBoost(), (float) 2.0, (float) 0.5);\n    q = qp.parse(\"\\\"on\\\"^1.0\", \"field\");\n    assertNotNull(q);\n\n    q = getParser(new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true)).parse(\"the^3\",\n        \"field\");\n    assertNotNull(q);\n  }\n\n","sourceOld":"  public void testBoost() throws Exception {\n    CharacterRunAutomaton stopSet = new CharacterRunAutomaton(BasicAutomata.makeString(\"on\"));\n    Analyzer oneStopAnalyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, stopSet, true);\n\n    PrecedenceQueryParser qp = new PrecedenceQueryParser();\n    qp.setAnalyzer(oneStopAnalyzer);\n    Query q = qp.parse(\"on^1.0\", \"field\");\n    assertNotNull(q);\n    q = qp.parse(\"\\\"hello\\\"^2.0\", \"field\");\n    assertNotNull(q);\n    assertEquals(q.getBoost(), (float) 2.0, (float) 0.5);\n    q = qp.parse(\"hello^2.0\", \"field\");\n    assertNotNull(q);\n    assertEquals(q.getBoost(), (float) 2.0, (float) 0.5);\n    q = qp.parse(\"\\\"on\\\"^1.0\", \"field\");\n    assertNotNull(q);\n\n    q = getParser(new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true)).parse(\"the^3\",\n        \"field\");\n    assertNotNull(q);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"4cf7d991c51b580d4b7bf2ad583dba058c0a2dd1":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["4cf7d991c51b580d4b7bf2ad583dba058c0a2dd1"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b89678825b68eccaf09e6ab71675fc0b0af1e099"]},"commit2Childs":{"4cf7d991c51b580d4b7bf2ad583dba058c0a2dd1":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["4cf7d991c51b580d4b7bf2ad583dba058c0a2dd1"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}