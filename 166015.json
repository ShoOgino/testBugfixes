{"path":"lucene/core/src/test/org/apache/lucene/codecs/lucene54/TestLucene54DocValuesFormat#testSortedSetAroundBlockSize().mjava","commits":[{"id":"0d3eb7aae6b652507fd9c0ded03eebf8392d6eb4","date":1452532582,"type":0,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene54/TestLucene54DocValuesFormat#testSortedSetAroundBlockSize().mjava","pathOld":"/dev/null","sourceNew":"  @Slow\n  public void testSortedSetAroundBlockSize() throws IOException {\n    final int frontier = 1 << Lucene54DocValuesFormat.DIRECT_MONOTONIC_BLOCK_SHIFT;\n    for (int maxDoc = frontier - 1; maxDoc <= frontier + 1; ++maxDoc) {\n      final Directory dir = newDirectory();\n      IndexWriter w = new IndexWriter(dir, newIndexWriterConfig().setMergePolicy(newLogMergePolicy()));\n      RAMFile buffer = new RAMFile();\n      RAMOutputStream out = new RAMOutputStream(buffer, false);\n      Document doc = new Document();\n      SortedSetDocValuesField field1 = new SortedSetDocValuesField(\"sset\", new BytesRef());\n      doc.add(field1);\n      SortedSetDocValuesField field2 = new SortedSetDocValuesField(\"sset\", new BytesRef());\n      doc.add(field2);\n      for (int i = 0; i < maxDoc; ++i) {\n        BytesRef s1 = new BytesRef(TestUtil.randomSimpleString(random(), 2));\n        BytesRef s2 = new BytesRef(TestUtil.randomSimpleString(random(), 2));\n        field1.setBytesValue(s1);\n        field2.setBytesValue(s2);\n        w.addDocument(doc);\n        Set<BytesRef> set = new TreeSet<>(Arrays.asList(s1, s2));\n        out.writeVInt(set.size());\n        for (BytesRef ref : set) {\n          out.writeVInt(ref.length);\n          out.writeBytes(ref.bytes, ref.offset, ref.length);\n        }\n      }\n      out.close();\n      w.forceMerge(1);\n      DirectoryReader r = DirectoryReader.open(w, false);\n      w.close();\n      SegmentReader sr = getOnlySegmentReader(r);\n      assertEquals(maxDoc, sr.maxDoc());\n      SortedSetDocValues values = sr.getSortedSetDocValues(\"sset\");\n      assertNotNull(values);\n      RAMInputStream in = new RAMInputStream(\"\", buffer);\n      BytesRefBuilder b = new BytesRefBuilder();\n      for (int i = 0; i < maxDoc; ++i) {\n        values.setDocument(i);\n        final int numValues = in.readVInt();\n\n        for (int j = 0; j < numValues; ++j) {\n          b.setLength(in.readVInt());\n          b.grow(b.length());\n          in.readBytes(b.bytes(), 0, b.length());\n          assertEquals(b.get(), values.lookupOrd(values.nextOrd()));\n        }\n\n        assertEquals(SortedSetDocValues.NO_MORE_ORDS, values.nextOrd());\n      }\n      r.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2a1862266772deb28cdcb7d996b64d2177022687","date":1453077824,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene54/TestLucene54DocValuesFormat#testSortedSetAroundBlockSize().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene54/TestLucene54DocValuesFormat#testSortedSetAroundBlockSize().mjava","sourceNew":"  @Slow\n  public void testSortedSetAroundBlockSize() throws IOException {\n    final int frontier = 1 << Lucene54DocValuesFormat.DIRECT_MONOTONIC_BLOCK_SHIFT;\n    for (int maxDoc = frontier - 1; maxDoc <= frontier + 1; ++maxDoc) {\n      final Directory dir = newDirectory();\n      IndexWriter w = new IndexWriter(dir, newIndexWriterConfig().setMergePolicy(newLogMergePolicy()));\n      RAMFile buffer = new RAMFile();\n      RAMOutputStream out = new RAMOutputStream(buffer, false);\n      Document doc = new Document();\n      SortedSetDocValuesField field1 = new SortedSetDocValuesField(\"sset\", new BytesRef());\n      doc.add(field1);\n      SortedSetDocValuesField field2 = new SortedSetDocValuesField(\"sset\", new BytesRef());\n      doc.add(field2);\n      for (int i = 0; i < maxDoc; ++i) {\n        BytesRef s1 = new BytesRef(TestUtil.randomSimpleString(random(), 2));\n        BytesRef s2 = new BytesRef(TestUtil.randomSimpleString(random(), 2));\n        field1.setBytesValue(s1);\n        field2.setBytesValue(s2);\n        w.addDocument(doc);\n        Set<BytesRef> set = new TreeSet<>(Arrays.asList(s1, s2));\n        out.writeVInt(set.size());\n        for (BytesRef ref : set) {\n          out.writeVInt(ref.length);\n          out.writeBytes(ref.bytes, ref.offset, ref.length);\n        }\n      }\n      out.close();\n      w.forceMerge(1);\n      DirectoryReader r = DirectoryReader.open(w);\n      w.close();\n      SegmentReader sr = getOnlySegmentReader(r);\n      assertEquals(maxDoc, sr.maxDoc());\n      SortedSetDocValues values = sr.getSortedSetDocValues(\"sset\");\n      assertNotNull(values);\n      RAMInputStream in = new RAMInputStream(\"\", buffer);\n      BytesRefBuilder b = new BytesRefBuilder();\n      for (int i = 0; i < maxDoc; ++i) {\n        values.setDocument(i);\n        final int numValues = in.readVInt();\n\n        for (int j = 0; j < numValues; ++j) {\n          b.setLength(in.readVInt());\n          b.grow(b.length());\n          in.readBytes(b.bytes(), 0, b.length());\n          assertEquals(b.get(), values.lookupOrd(values.nextOrd()));\n        }\n\n        assertEquals(SortedSetDocValues.NO_MORE_ORDS, values.nextOrd());\n      }\n      r.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  @Slow\n  public void testSortedSetAroundBlockSize() throws IOException {\n    final int frontier = 1 << Lucene54DocValuesFormat.DIRECT_MONOTONIC_BLOCK_SHIFT;\n    for (int maxDoc = frontier - 1; maxDoc <= frontier + 1; ++maxDoc) {\n      final Directory dir = newDirectory();\n      IndexWriter w = new IndexWriter(dir, newIndexWriterConfig().setMergePolicy(newLogMergePolicy()));\n      RAMFile buffer = new RAMFile();\n      RAMOutputStream out = new RAMOutputStream(buffer, false);\n      Document doc = new Document();\n      SortedSetDocValuesField field1 = new SortedSetDocValuesField(\"sset\", new BytesRef());\n      doc.add(field1);\n      SortedSetDocValuesField field2 = new SortedSetDocValuesField(\"sset\", new BytesRef());\n      doc.add(field2);\n      for (int i = 0; i < maxDoc; ++i) {\n        BytesRef s1 = new BytesRef(TestUtil.randomSimpleString(random(), 2));\n        BytesRef s2 = new BytesRef(TestUtil.randomSimpleString(random(), 2));\n        field1.setBytesValue(s1);\n        field2.setBytesValue(s2);\n        w.addDocument(doc);\n        Set<BytesRef> set = new TreeSet<>(Arrays.asList(s1, s2));\n        out.writeVInt(set.size());\n        for (BytesRef ref : set) {\n          out.writeVInt(ref.length);\n          out.writeBytes(ref.bytes, ref.offset, ref.length);\n        }\n      }\n      out.close();\n      w.forceMerge(1);\n      DirectoryReader r = DirectoryReader.open(w, false);\n      w.close();\n      SegmentReader sr = getOnlySegmentReader(r);\n      assertEquals(maxDoc, sr.maxDoc());\n      SortedSetDocValues values = sr.getSortedSetDocValues(\"sset\");\n      assertNotNull(values);\n      RAMInputStream in = new RAMInputStream(\"\", buffer);\n      BytesRefBuilder b = new BytesRefBuilder();\n      for (int i = 0; i < maxDoc; ++i) {\n        values.setDocument(i);\n        final int numValues = in.readVInt();\n\n        for (int j = 0; j < numValues; ++j) {\n          b.setLength(in.readVInt());\n          b.grow(b.length());\n          in.readBytes(b.bytes(), 0, b.length());\n          assertEquals(b.get(), values.lookupOrd(values.nextOrd()));\n        }\n\n        assertEquals(SortedSetDocValues.NO_MORE_ORDS, values.nextOrd());\n      }\n      r.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1","date":1457644139,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene54/TestLucene54DocValuesFormat#testSortedSetAroundBlockSize().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene54/TestLucene54DocValuesFormat#testSortedSetAroundBlockSize().mjava","sourceNew":"  @Slow\n  public void testSortedSetAroundBlockSize() throws IOException {\n    final int frontier = 1 << Lucene54DocValuesFormat.DIRECT_MONOTONIC_BLOCK_SHIFT;\n    for (int maxDoc = frontier - 1; maxDoc <= frontier + 1; ++maxDoc) {\n      final Directory dir = newDirectory();\n      IndexWriter w = new IndexWriter(dir, newIndexWriterConfig().setMergePolicy(newLogMergePolicy()));\n      RAMFile buffer = new RAMFile();\n      RAMOutputStream out = new RAMOutputStream(buffer, false);\n      Document doc = new Document();\n      SortedSetDocValuesField field1 = new SortedSetDocValuesField(\"sset\", new BytesRef());\n      doc.add(field1);\n      SortedSetDocValuesField field2 = new SortedSetDocValuesField(\"sset\", new BytesRef());\n      doc.add(field2);\n      for (int i = 0; i < maxDoc; ++i) {\n        BytesRef s1 = new BytesRef(TestUtil.randomSimpleString(random(), 2));\n        BytesRef s2 = new BytesRef(TestUtil.randomSimpleString(random(), 2));\n        field1.setBytesValue(s1);\n        field2.setBytesValue(s2);\n        w.addDocument(doc);\n        Set<BytesRef> set = new TreeSet<>(Arrays.asList(s1, s2));\n        out.writeVInt(set.size());\n        for (BytesRef ref : set) {\n          out.writeVInt(ref.length);\n          out.writeBytes(ref.bytes, ref.offset, ref.length);\n        }\n      }\n      out.close();\n      w.forceMerge(1);\n      DirectoryReader r = DirectoryReader.open(w);\n      w.close();\n      LeafReader sr = getOnlyLeafReader(r);\n      assertEquals(maxDoc, sr.maxDoc());\n      SortedSetDocValues values = sr.getSortedSetDocValues(\"sset\");\n      assertNotNull(values);\n      RAMInputStream in = new RAMInputStream(\"\", buffer);\n      BytesRefBuilder b = new BytesRefBuilder();\n      for (int i = 0; i < maxDoc; ++i) {\n        values.setDocument(i);\n        final int numValues = in.readVInt();\n\n        for (int j = 0; j < numValues; ++j) {\n          b.setLength(in.readVInt());\n          b.grow(b.length());\n          in.readBytes(b.bytes(), 0, b.length());\n          assertEquals(b.get(), values.lookupOrd(values.nextOrd()));\n        }\n\n        assertEquals(SortedSetDocValues.NO_MORE_ORDS, values.nextOrd());\n      }\n      r.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  @Slow\n  public void testSortedSetAroundBlockSize() throws IOException {\n    final int frontier = 1 << Lucene54DocValuesFormat.DIRECT_MONOTONIC_BLOCK_SHIFT;\n    for (int maxDoc = frontier - 1; maxDoc <= frontier + 1; ++maxDoc) {\n      final Directory dir = newDirectory();\n      IndexWriter w = new IndexWriter(dir, newIndexWriterConfig().setMergePolicy(newLogMergePolicy()));\n      RAMFile buffer = new RAMFile();\n      RAMOutputStream out = new RAMOutputStream(buffer, false);\n      Document doc = new Document();\n      SortedSetDocValuesField field1 = new SortedSetDocValuesField(\"sset\", new BytesRef());\n      doc.add(field1);\n      SortedSetDocValuesField field2 = new SortedSetDocValuesField(\"sset\", new BytesRef());\n      doc.add(field2);\n      for (int i = 0; i < maxDoc; ++i) {\n        BytesRef s1 = new BytesRef(TestUtil.randomSimpleString(random(), 2));\n        BytesRef s2 = new BytesRef(TestUtil.randomSimpleString(random(), 2));\n        field1.setBytesValue(s1);\n        field2.setBytesValue(s2);\n        w.addDocument(doc);\n        Set<BytesRef> set = new TreeSet<>(Arrays.asList(s1, s2));\n        out.writeVInt(set.size());\n        for (BytesRef ref : set) {\n          out.writeVInt(ref.length);\n          out.writeBytes(ref.bytes, ref.offset, ref.length);\n        }\n      }\n      out.close();\n      w.forceMerge(1);\n      DirectoryReader r = DirectoryReader.open(w);\n      w.close();\n      SegmentReader sr = getOnlySegmentReader(r);\n      assertEquals(maxDoc, sr.maxDoc());\n      SortedSetDocValues values = sr.getSortedSetDocValues(\"sset\");\n      assertNotNull(values);\n      RAMInputStream in = new RAMInputStream(\"\", buffer);\n      BytesRefBuilder b = new BytesRefBuilder();\n      for (int i = 0; i < maxDoc; ++i) {\n        values.setDocument(i);\n        final int numValues = in.readVInt();\n\n        for (int j = 0; j < numValues; ++j) {\n          b.setLength(in.readVInt());\n          b.grow(b.length());\n          in.readBytes(b.bytes(), 0, b.length());\n          assertEquals(b.get(), values.lookupOrd(values.nextOrd()));\n        }\n\n        assertEquals(SortedSetDocValues.NO_MORE_ORDS, values.nextOrd());\n      }\n      r.close();\n      dir.close();\n    }\n  }\n\n","bugFix":["0d3eb7aae6b652507fd9c0ded03eebf8392d6eb4"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6652c74b2358a0b13223817a6a793bf1c9d0749d","date":1474465301,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene54/TestLucene54DocValuesFormat#testSortedSetAroundBlockSize().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene54/TestLucene54DocValuesFormat#testSortedSetAroundBlockSize().mjava","sourceNew":"  @Slow\n  public void testSortedSetAroundBlockSize() throws IOException {\n    final int frontier = 1 << Lucene54DocValuesFormat.DIRECT_MONOTONIC_BLOCK_SHIFT;\n    for (int maxDoc = frontier - 1; maxDoc <= frontier + 1; ++maxDoc) {\n      final Directory dir = newDirectory();\n      IndexWriter w = new IndexWriter(dir, newIndexWriterConfig().setMergePolicy(newLogMergePolicy()));\n      RAMFile buffer = new RAMFile();\n      RAMOutputStream out = new RAMOutputStream(buffer, false);\n      Document doc = new Document();\n      SortedSetDocValuesField field1 = new SortedSetDocValuesField(\"sset\", new BytesRef());\n      doc.add(field1);\n      SortedSetDocValuesField field2 = new SortedSetDocValuesField(\"sset\", new BytesRef());\n      doc.add(field2);\n      for (int i = 0; i < maxDoc; ++i) {\n        BytesRef s1 = new BytesRef(TestUtil.randomSimpleString(random(), 2));\n        BytesRef s2 = new BytesRef(TestUtil.randomSimpleString(random(), 2));\n        field1.setBytesValue(s1);\n        field2.setBytesValue(s2);\n        w.addDocument(doc);\n        Set<BytesRef> set = new TreeSet<>(Arrays.asList(s1, s2));\n        out.writeVInt(set.size());\n        for (BytesRef ref : set) {\n          out.writeVInt(ref.length);\n          out.writeBytes(ref.bytes, ref.offset, ref.length);\n        }\n      }\n      out.close();\n      w.forceMerge(1);\n      DirectoryReader r = DirectoryReader.open(w);\n      w.close();\n      LeafReader sr = getOnlyLeafReader(r);\n      assertEquals(maxDoc, sr.maxDoc());\n      SortedSetDocValues values = sr.getSortedSetDocValues(\"sset\");\n      assertNotNull(values);\n      RAMInputStream in = new RAMInputStream(\"\", buffer);\n      BytesRefBuilder b = new BytesRefBuilder();\n      for (int i = 0; i < maxDoc; ++i) {\n        assertEquals(i, values.nextDoc());\n        final int numValues = in.readVInt();\n\n        for (int j = 0; j < numValues; ++j) {\n          b.setLength(in.readVInt());\n          b.grow(b.length());\n          in.readBytes(b.bytes(), 0, b.length());\n          assertEquals(b.get(), values.lookupOrd(values.nextOrd()));\n        }\n\n        assertEquals(SortedSetDocValues.NO_MORE_ORDS, values.nextOrd());\n      }\n      r.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  @Slow\n  public void testSortedSetAroundBlockSize() throws IOException {\n    final int frontier = 1 << Lucene54DocValuesFormat.DIRECT_MONOTONIC_BLOCK_SHIFT;\n    for (int maxDoc = frontier - 1; maxDoc <= frontier + 1; ++maxDoc) {\n      final Directory dir = newDirectory();\n      IndexWriter w = new IndexWriter(dir, newIndexWriterConfig().setMergePolicy(newLogMergePolicy()));\n      RAMFile buffer = new RAMFile();\n      RAMOutputStream out = new RAMOutputStream(buffer, false);\n      Document doc = new Document();\n      SortedSetDocValuesField field1 = new SortedSetDocValuesField(\"sset\", new BytesRef());\n      doc.add(field1);\n      SortedSetDocValuesField field2 = new SortedSetDocValuesField(\"sset\", new BytesRef());\n      doc.add(field2);\n      for (int i = 0; i < maxDoc; ++i) {\n        BytesRef s1 = new BytesRef(TestUtil.randomSimpleString(random(), 2));\n        BytesRef s2 = new BytesRef(TestUtil.randomSimpleString(random(), 2));\n        field1.setBytesValue(s1);\n        field2.setBytesValue(s2);\n        w.addDocument(doc);\n        Set<BytesRef> set = new TreeSet<>(Arrays.asList(s1, s2));\n        out.writeVInt(set.size());\n        for (BytesRef ref : set) {\n          out.writeVInt(ref.length);\n          out.writeBytes(ref.bytes, ref.offset, ref.length);\n        }\n      }\n      out.close();\n      w.forceMerge(1);\n      DirectoryReader r = DirectoryReader.open(w);\n      w.close();\n      LeafReader sr = getOnlyLeafReader(r);\n      assertEquals(maxDoc, sr.maxDoc());\n      SortedSetDocValues values = sr.getSortedSetDocValues(\"sset\");\n      assertNotNull(values);\n      RAMInputStream in = new RAMInputStream(\"\", buffer);\n      BytesRefBuilder b = new BytesRefBuilder();\n      for (int i = 0; i < maxDoc; ++i) {\n        values.setDocument(i);\n        final int numValues = in.readVInt();\n\n        for (int j = 0; j < numValues; ++j) {\n          b.setLength(in.readVInt());\n          b.grow(b.length());\n          in.readBytes(b.bytes(), 0, b.length());\n          assertEquals(b.get(), values.lookupOrd(values.nextOrd()));\n        }\n\n        assertEquals(SortedSetDocValues.NO_MORE_ORDS, values.nextOrd());\n      }\n      r.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"17e5da53e4e5bd659e22add9bba1cfa222e7e30d","date":1475435902,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene54/TestLucene54DocValuesFormat#testSortedSetAroundBlockSize().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene54/TestLucene54DocValuesFormat#testSortedSetAroundBlockSize().mjava","sourceNew":"  @Slow\n  public void testSortedSetAroundBlockSize() throws IOException {\n    final int frontier = 1 << Lucene54DocValuesFormat.DIRECT_MONOTONIC_BLOCK_SHIFT;\n    for (int maxDoc = frontier - 1; maxDoc <= frontier + 1; ++maxDoc) {\n      final Directory dir = newDirectory();\n      IndexWriter w = new IndexWriter(dir, newIndexWriterConfig().setMergePolicy(newLogMergePolicy()));\n      RAMFile buffer = new RAMFile();\n      RAMOutputStream out = new RAMOutputStream(buffer, false);\n      Document doc = new Document();\n      SortedSetDocValuesField field1 = new SortedSetDocValuesField(\"sset\", new BytesRef());\n      doc.add(field1);\n      SortedSetDocValuesField field2 = new SortedSetDocValuesField(\"sset\", new BytesRef());\n      doc.add(field2);\n      for (int i = 0; i < maxDoc; ++i) {\n        BytesRef s1 = new BytesRef(TestUtil.randomSimpleString(random(), 2));\n        BytesRef s2 = new BytesRef(TestUtil.randomSimpleString(random(), 2));\n        field1.setBytesValue(s1);\n        field2.setBytesValue(s2);\n        w.addDocument(doc);\n        Set<BytesRef> set = new TreeSet<>(Arrays.asList(s1, s2));\n        out.writeVInt(set.size());\n        for (BytesRef ref : set) {\n          out.writeVInt(ref.length);\n          out.writeBytes(ref.bytes, ref.offset, ref.length);\n        }\n      }\n      out.close();\n      w.forceMerge(1);\n      DirectoryReader r = DirectoryReader.open(w);\n      w.close();\n      LeafReader sr = getOnlyLeafReader(r);\n      assertEquals(maxDoc, sr.maxDoc());\n      SortedSetDocValues values = sr.getSortedSetDocValues(\"sset\");\n      assertNotNull(values);\n      RAMInputStream in = new RAMInputStream(\"\", buffer);\n      BytesRefBuilder b = new BytesRefBuilder();\n      for (int i = 0; i < maxDoc; ++i) {\n        assertEquals(i, values.nextDoc());\n        final int numValues = in.readVInt();\n\n        for (int j = 0; j < numValues; ++j) {\n          b.setLength(in.readVInt());\n          b.grow(b.length());\n          in.readBytes(b.bytes(), 0, b.length());\n          assertEquals(b.get(), values.lookupOrd(values.nextOrd()));\n        }\n\n        assertEquals(SortedSetDocValues.NO_MORE_ORDS, values.nextOrd());\n      }\n      r.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  @Slow\n  public void testSortedSetAroundBlockSize() throws IOException {\n    final int frontier = 1 << Lucene54DocValuesFormat.DIRECT_MONOTONIC_BLOCK_SHIFT;\n    for (int maxDoc = frontier - 1; maxDoc <= frontier + 1; ++maxDoc) {\n      final Directory dir = newDirectory();\n      IndexWriter w = new IndexWriter(dir, newIndexWriterConfig().setMergePolicy(newLogMergePolicy()));\n      RAMFile buffer = new RAMFile();\n      RAMOutputStream out = new RAMOutputStream(buffer, false);\n      Document doc = new Document();\n      SortedSetDocValuesField field1 = new SortedSetDocValuesField(\"sset\", new BytesRef());\n      doc.add(field1);\n      SortedSetDocValuesField field2 = new SortedSetDocValuesField(\"sset\", new BytesRef());\n      doc.add(field2);\n      for (int i = 0; i < maxDoc; ++i) {\n        BytesRef s1 = new BytesRef(TestUtil.randomSimpleString(random(), 2));\n        BytesRef s2 = new BytesRef(TestUtil.randomSimpleString(random(), 2));\n        field1.setBytesValue(s1);\n        field2.setBytesValue(s2);\n        w.addDocument(doc);\n        Set<BytesRef> set = new TreeSet<>(Arrays.asList(s1, s2));\n        out.writeVInt(set.size());\n        for (BytesRef ref : set) {\n          out.writeVInt(ref.length);\n          out.writeBytes(ref.bytes, ref.offset, ref.length);\n        }\n      }\n      out.close();\n      w.forceMerge(1);\n      DirectoryReader r = DirectoryReader.open(w);\n      w.close();\n      LeafReader sr = getOnlyLeafReader(r);\n      assertEquals(maxDoc, sr.maxDoc());\n      SortedSetDocValues values = sr.getSortedSetDocValues(\"sset\");\n      assertNotNull(values);\n      RAMInputStream in = new RAMInputStream(\"\", buffer);\n      BytesRefBuilder b = new BytesRefBuilder();\n      for (int i = 0; i < maxDoc; ++i) {\n        values.setDocument(i);\n        final int numValues = in.readVInt();\n\n        for (int j = 0; j < numValues; ++j) {\n          b.setLength(in.readVInt());\n          b.grow(b.length());\n          in.readBytes(b.bytes(), 0, b.length());\n          assertEquals(b.get(), values.lookupOrd(values.nextOrd()));\n        }\n\n        assertEquals(SortedSetDocValues.NO_MORE_ORDS, values.nextOrd());\n      }\n      r.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7f3090f7e0cab5b1f5acf12d21f31f00fe74a262","date":1475755647,"type":5,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/backward-codecs/src/test/org/apache/lucene/codecs/lucene54/TestLucene54DocValuesFormat#testSortedSetAroundBlockSize().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene54/TestLucene54DocValuesFormat#testSortedSetAroundBlockSize().mjava","sourceNew":"  @Slow\n  public void testSortedSetAroundBlockSize() throws IOException {\n    final int frontier = 1 << Lucene54DocValuesFormat.DIRECT_MONOTONIC_BLOCK_SHIFT;\n    for (int maxDoc = frontier - 1; maxDoc <= frontier + 1; ++maxDoc) {\n      final Directory dir = newDirectory();\n      IndexWriter w = new IndexWriter(dir, newIndexWriterConfig().setMergePolicy(newLogMergePolicy()));\n      RAMFile buffer = new RAMFile();\n      RAMOutputStream out = new RAMOutputStream(buffer, false);\n      Document doc = new Document();\n      SortedSetDocValuesField field1 = new SortedSetDocValuesField(\"sset\", new BytesRef());\n      doc.add(field1);\n      SortedSetDocValuesField field2 = new SortedSetDocValuesField(\"sset\", new BytesRef());\n      doc.add(field2);\n      for (int i = 0; i < maxDoc; ++i) {\n        BytesRef s1 = new BytesRef(TestUtil.randomSimpleString(random(), 2));\n        BytesRef s2 = new BytesRef(TestUtil.randomSimpleString(random(), 2));\n        field1.setBytesValue(s1);\n        field2.setBytesValue(s2);\n        w.addDocument(doc);\n        Set<BytesRef> set = new TreeSet<>(Arrays.asList(s1, s2));\n        out.writeVInt(set.size());\n        for (BytesRef ref : set) {\n          out.writeVInt(ref.length);\n          out.writeBytes(ref.bytes, ref.offset, ref.length);\n        }\n      }\n      out.close();\n      w.forceMerge(1);\n      DirectoryReader r = DirectoryReader.open(w);\n      w.close();\n      LeafReader sr = getOnlyLeafReader(r);\n      assertEquals(maxDoc, sr.maxDoc());\n      SortedSetDocValues values = sr.getSortedSetDocValues(\"sset\");\n      assertNotNull(values);\n      RAMInputStream in = new RAMInputStream(\"\", buffer);\n      BytesRefBuilder b = new BytesRefBuilder();\n      for (int i = 0; i < maxDoc; ++i) {\n        assertEquals(i, values.nextDoc());\n        final int numValues = in.readVInt();\n\n        for (int j = 0; j < numValues; ++j) {\n          b.setLength(in.readVInt());\n          b.grow(b.length());\n          in.readBytes(b.bytes(), 0, b.length());\n          assertEquals(b.get(), values.lookupOrd(values.nextOrd()));\n        }\n\n        assertEquals(SortedSetDocValues.NO_MORE_ORDS, values.nextOrd());\n      }\n      r.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  @Slow\n  public void testSortedSetAroundBlockSize() throws IOException {\n    final int frontier = 1 << Lucene54DocValuesFormat.DIRECT_MONOTONIC_BLOCK_SHIFT;\n    for (int maxDoc = frontier - 1; maxDoc <= frontier + 1; ++maxDoc) {\n      final Directory dir = newDirectory();\n      IndexWriter w = new IndexWriter(dir, newIndexWriterConfig().setMergePolicy(newLogMergePolicy()));\n      RAMFile buffer = new RAMFile();\n      RAMOutputStream out = new RAMOutputStream(buffer, false);\n      Document doc = new Document();\n      SortedSetDocValuesField field1 = new SortedSetDocValuesField(\"sset\", new BytesRef());\n      doc.add(field1);\n      SortedSetDocValuesField field2 = new SortedSetDocValuesField(\"sset\", new BytesRef());\n      doc.add(field2);\n      for (int i = 0; i < maxDoc; ++i) {\n        BytesRef s1 = new BytesRef(TestUtil.randomSimpleString(random(), 2));\n        BytesRef s2 = new BytesRef(TestUtil.randomSimpleString(random(), 2));\n        field1.setBytesValue(s1);\n        field2.setBytesValue(s2);\n        w.addDocument(doc);\n        Set<BytesRef> set = new TreeSet<>(Arrays.asList(s1, s2));\n        out.writeVInt(set.size());\n        for (BytesRef ref : set) {\n          out.writeVInt(ref.length);\n          out.writeBytes(ref.bytes, ref.offset, ref.length);\n        }\n      }\n      out.close();\n      w.forceMerge(1);\n      DirectoryReader r = DirectoryReader.open(w);\n      w.close();\n      LeafReader sr = getOnlyLeafReader(r);\n      assertEquals(maxDoc, sr.maxDoc());\n      SortedSetDocValues values = sr.getSortedSetDocValues(\"sset\");\n      assertNotNull(values);\n      RAMInputStream in = new RAMInputStream(\"\", buffer);\n      BytesRefBuilder b = new BytesRefBuilder();\n      for (int i = 0; i < maxDoc; ++i) {\n        assertEquals(i, values.nextDoc());\n        final int numValues = in.readVInt();\n\n        for (int j = 0; j < numValues; ++j) {\n          b.setLength(in.readVInt());\n          b.grow(b.length());\n          in.readBytes(b.bytes(), 0, b.length());\n          assertEquals(b.get(), values.lookupOrd(values.nextOrd()));\n        }\n\n        assertEquals(SortedSetDocValues.NO_MORE_ORDS, values.nextOrd());\n      }\n      r.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":4,"author":"Kevin Risden","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene54/TestLucene54DocValuesFormat#testSortedSetAroundBlockSize().mjava","sourceNew":null,"sourceOld":"  @Slow\n  public void testSortedSetAroundBlockSize() throws IOException {\n    final int frontier = 1 << Lucene54DocValuesFormat.DIRECT_MONOTONIC_BLOCK_SHIFT;\n    for (int maxDoc = frontier - 1; maxDoc <= frontier + 1; ++maxDoc) {\n      final Directory dir = newDirectory();\n      IndexWriter w = new IndexWriter(dir, newIndexWriterConfig().setMergePolicy(newLogMergePolicy()));\n      RAMFile buffer = new RAMFile();\n      RAMOutputStream out = new RAMOutputStream(buffer, false);\n      Document doc = new Document();\n      SortedSetDocValuesField field1 = new SortedSetDocValuesField(\"sset\", new BytesRef());\n      doc.add(field1);\n      SortedSetDocValuesField field2 = new SortedSetDocValuesField(\"sset\", new BytesRef());\n      doc.add(field2);\n      for (int i = 0; i < maxDoc; ++i) {\n        BytesRef s1 = new BytesRef(TestUtil.randomSimpleString(random(), 2));\n        BytesRef s2 = new BytesRef(TestUtil.randomSimpleString(random(), 2));\n        field1.setBytesValue(s1);\n        field2.setBytesValue(s2);\n        w.addDocument(doc);\n        Set<BytesRef> set = new TreeSet<>(Arrays.asList(s1, s2));\n        out.writeVInt(set.size());\n        for (BytesRef ref : set) {\n          out.writeVInt(ref.length);\n          out.writeBytes(ref.bytes, ref.offset, ref.length);\n        }\n      }\n      out.close();\n      w.forceMerge(1);\n      DirectoryReader r = DirectoryReader.open(w);\n      w.close();\n      LeafReader sr = getOnlyLeafReader(r);\n      assertEquals(maxDoc, sr.maxDoc());\n      SortedSetDocValues values = sr.getSortedSetDocValues(\"sset\");\n      assertNotNull(values);\n      RAMInputStream in = new RAMInputStream(\"\", buffer);\n      BytesRefBuilder b = new BytesRefBuilder();\n      for (int i = 0; i < maxDoc; ++i) {\n        values.setDocument(i);\n        final int numValues = in.readVInt();\n\n        for (int j = 0; j < numValues; ++j) {\n          b.setLength(in.readVInt());\n          b.grow(b.length());\n          in.readBytes(b.bytes(), 0, b.length());\n          assertEquals(b.get(), values.lookupOrd(values.nextOrd()));\n        }\n\n        assertEquals(SortedSetDocValues.NO_MORE_ORDS, values.nextOrd());\n      }\n      r.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"7f3090f7e0cab5b1f5acf12d21f31f00fe74a262":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1":["2a1862266772deb28cdcb7d996b64d2177022687"],"2a1862266772deb28cdcb7d996b64d2177022687":["0d3eb7aae6b652507fd9c0ded03eebf8392d6eb4"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"17e5da53e4e5bd659e22add9bba1cfa222e7e30d":["0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1","6652c74b2358a0b13223817a6a793bf1c9d0749d"],"6652c74b2358a0b13223817a6a793bf1c9d0749d":["0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1"],"0d3eb7aae6b652507fd9c0ded03eebf8392d6eb4":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1","7f3090f7e0cab5b1f5acf12d21f31f00fe74a262"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["7f3090f7e0cab5b1f5acf12d21f31f00fe74a262"]},"commit2Childs":{"7f3090f7e0cab5b1f5acf12d21f31f00fe74a262":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d","6652c74b2358a0b13223817a6a793bf1c9d0749d","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"2a1862266772deb28cdcb7d996b64d2177022687":["0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1"],"17e5da53e4e5bd659e22add9bba1cfa222e7e30d":["7f3090f7e0cab5b1f5acf12d21f31f00fe74a262"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["0d3eb7aae6b652507fd9c0ded03eebf8392d6eb4"],"6652c74b2358a0b13223817a6a793bf1c9d0749d":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"0d3eb7aae6b652507fd9c0ded03eebf8392d6eb4":["2a1862266772deb28cdcb7d996b64d2177022687"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}