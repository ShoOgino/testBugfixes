{"path":"lucene/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","commits":[{"id":"9d7606b7ab7992bc238d10c3bddfe82a639d212a","date":1295971955,"type":0,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(\n            MockTokenizer.WHITESPACE, true, usePayload)));\n    int howMany = 1000;\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), Field.Store.YES,\n          Field.Index.ANALYZED));\n      writer.addDocument(doc);\n    }\n\n    // now do seaches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    for (int i = 0; i < 39 * RANDOM_MULTIPLIER; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      ReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = ReaderUtil.leaves(topReaderContext);\n      for (AtomicReaderContext atomicReaderContext : leaves) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader, bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader.maxDoc();\n        // initially advance or do next doc\n        if (random.nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random.nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc + \" payloads: \"\n            + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"29ef99d61cda9641b6250bf9567329a6e65f901d","date":1297244127,"type":0,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(\n            MockTokenizer.WHITESPACE, true, usePayload)));\n    int howMany = 1000;\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), Field.Store.YES,\n          Field.Index.ANALYZED));\n      writer.addDocument(doc);\n    }\n\n    // now do seaches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    for (int i = 0; i < 39 * RANDOM_MULTIPLIER; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      ReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = ReaderUtil.leaves(topReaderContext);\n      for (AtomicReaderContext atomicReaderContext : leaves) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader, bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader.maxDoc();\n        // initially advance or do next doc\n        if (random.nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random.nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc + \" payloads: \"\n            + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bde51b089eb7f86171eb3406e38a274743f9b7ac","date":1298336439,"type":0,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(\n            MockTokenizer.WHITESPACE, true, usePayload)));\n    int howMany = 1000;\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), Field.Store.YES,\n          Field.Index.ANALYZED));\n      writer.addDocument(doc);\n    }\n\n    // now do seaches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    for (int i = 0; i < 39 * RANDOM_MULTIPLIER; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      ReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = ReaderUtil.leaves(topReaderContext);\n      for (AtomicReaderContext atomicReaderContext : leaves) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader, bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader.maxDoc();\n        // initially advance or do next doc\n        if (random.nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random.nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc + \" payloads: \"\n            + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f2c5f0cb44df114db4228c8f77861714b5cabaea","date":1302542431,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","sourceNew":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    int howMany = 1000;\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), Field.Store.YES,\n          Field.Index.ANALYZED));\n      writer.addDocument(doc);\n    }\n\n    // now do seaches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    for (int i = 0; i < 39 * RANDOM_MULTIPLIER; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      ReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = ReaderUtil.leaves(topReaderContext);\n      for (AtomicReaderContext atomicReaderContext : leaves) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader, bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader.maxDoc();\n        // initially advance or do next doc\n        if (random.nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random.nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(\n            MockTokenizer.WHITESPACE, true, usePayload)));\n    int howMany = 1000;\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), Field.Store.YES,\n          Field.Index.ANALYZED));\n      writer.addDocument(doc);\n    }\n\n    // now do seaches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    for (int i = 0; i < 39 * RANDOM_MULTIPLIER; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      ReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = ReaderUtil.leaves(topReaderContext);\n      for (AtomicReaderContext atomicReaderContext : leaves) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader, bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader.maxDoc();\n        // initially advance or do next doc\n        if (random.nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random.nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc + \" payloads: \"\n            + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"962d04139994fce5193143ef35615499a9a96d78","date":1302693744,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","sourceNew":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    int howMany = 1000;\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), Field.Store.YES,\n          Field.Index.ANALYZED));\n      writer.addDocument(doc);\n    }\n\n    // now do seaches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    for (int i = 0; i < 39 * RANDOM_MULTIPLIER; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      ReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = ReaderUtil.leaves(topReaderContext);\n      for (AtomicReaderContext atomicReaderContext : leaves) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader, bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader.maxDoc();\n        // initially advance or do next doc\n        if (random.nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random.nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(\n            MockTokenizer.WHITESPACE, true, usePayload)));\n    int howMany = 1000;\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), Field.Store.YES,\n          Field.Index.ANALYZED));\n      writer.addDocument(doc);\n    }\n\n    // now do seaches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    for (int i = 0; i < 39 * RANDOM_MULTIPLIER; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      ReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = ReaderUtil.leaves(topReaderContext);\n      for (AtomicReaderContext atomicReaderContext : leaves) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader, bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader.maxDoc();\n        // initially advance or do next doc\n        if (random.nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random.nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc + \" payloads: \"\n            + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"135621f3a0670a9394eb563224a3b76cc4dddc0f","date":1304344257,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","sourceNew":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    int howMany = 1000;\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), Field.Store.YES,\n          Field.Index.ANALYZED));\n      writer.addDocument(doc);\n    }\n\n    // now do seaches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    for (int i = 0; i < 39 * RANDOM_MULTIPLIER; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      ReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = ReaderUtil.leaves(topReaderContext);\n      for (AtomicReaderContext atomicReaderContext : leaves) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader, bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader.maxDoc();\n        // initially advance or do next doc\n        if (random.nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random.nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(\n            MockTokenizer.WHITESPACE, true, usePayload)));\n    int howMany = 1000;\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), Field.Store.YES,\n          Field.Index.ANALYZED));\n      writer.addDocument(doc);\n    }\n\n    // now do seaches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    for (int i = 0; i < 39 * RANDOM_MULTIPLIER; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      ReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = ReaderUtil.leaves(topReaderContext);\n      for (AtomicReaderContext atomicReaderContext : leaves) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader, bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader.maxDoc();\n        // initially advance or do next doc\n        if (random.nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random.nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc + \" payloads: \"\n            + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","sourceNew":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    int howMany = 1000;\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), Field.Store.YES,\n          Field.Index.ANALYZED));\n      writer.addDocument(doc);\n    }\n\n    // now do seaches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    for (int i = 0; i < 39 * RANDOM_MULTIPLIER; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      ReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = ReaderUtil.leaves(topReaderContext);\n      for (AtomicReaderContext atomicReaderContext : leaves) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader, bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader.maxDoc();\n        // initially advance or do next doc\n        if (random.nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random.nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(\n            MockTokenizer.WHITESPACE, true, usePayload)));\n    int howMany = 1000;\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), Field.Store.YES,\n          Field.Index.ANALYZED));\n      writer.addDocument(doc);\n    }\n\n    // now do seaches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    for (int i = 0; i < 39 * RANDOM_MULTIPLIER; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      ReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = ReaderUtil.leaves(topReaderContext);\n      for (AtomicReaderContext atomicReaderContext : leaves) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader, bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader.maxDoc();\n        // initially advance or do next doc\n        if (random.nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random.nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc + \" payloads: \"\n            + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ff6fd241dc6610f7f81b62e3ba4cedf105939623","date":1307331653,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","sourceNew":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    int howMany = 1000;\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), Field.Store.NO,\n          Field.Index.ANALYZED_NO_NORMS));\n      writer.addDocument(doc);\n    }\n\n    // now do seaches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    for (int i = 0; i < (TEST_NIGHTLY ? 39 : 13) * RANDOM_MULTIPLIER; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      ReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = ReaderUtil.leaves(topReaderContext);\n      for (AtomicReaderContext atomicReaderContext : leaves) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader, bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader.maxDoc();\n        // initially advance or do next doc\n        if (random.nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random.nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    int howMany = 1000;\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), Field.Store.YES,\n          Field.Index.ANALYZED));\n      writer.addDocument(doc);\n    }\n\n    // now do seaches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    for (int i = 0; i < 39 * RANDOM_MULTIPLIER; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      ReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = ReaderUtil.leaves(topReaderContext);\n      for (AtomicReaderContext atomicReaderContext : leaves) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader, bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader.maxDoc();\n        // initially advance or do next doc\n        if (random.nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random.nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"79c2cb24929f2649a8875fb629086171f914d5ce","date":1307332717,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","sourceNew":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    int howMany = 1000;\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), Field.Store.NO,\n          Field.Index.ANALYZED_NO_NORMS));\n      writer.addDocument(doc);\n    }\n\n    // now do seaches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    for (int i = 0; i < (TEST_NIGHTLY ? 39 : 13) * RANDOM_MULTIPLIER; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      ReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = ReaderUtil.leaves(topReaderContext);\n      for (AtomicReaderContext atomicReaderContext : leaves) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader, bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader.maxDoc();\n        // initially advance or do next doc\n        if (random.nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random.nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    int howMany = 1000;\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), Field.Store.YES,\n          Field.Index.ANALYZED));\n      writer.addDocument(doc);\n    }\n\n    // now do seaches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    for (int i = 0; i < 39 * RANDOM_MULTIPLIER; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      ReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = ReaderUtil.leaves(topReaderContext);\n      for (AtomicReaderContext atomicReaderContext : leaves) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader, bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader.maxDoc();\n        // initially advance or do next doc\n        if (random.nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random.nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0762b640e0d0d12b6edb96db68986e13145c3484","date":1307575932,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","sourceNew":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    int howMany = 1000;\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), Field.Store.NO,\n          Field.Index.ANALYZED_NO_NORMS));\n      writer.addDocument(doc);\n    }\n\n    // now do seaches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      ReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = ReaderUtil.leaves(topReaderContext);\n      for (AtomicReaderContext atomicReaderContext : leaves) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader, bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader.maxDoc();\n        // initially advance or do next doc\n        if (random.nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random.nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    int howMany = 1000;\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), Field.Store.NO,\n          Field.Index.ANALYZED_NO_NORMS));\n      writer.addDocument(doc);\n    }\n\n    // now do seaches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    for (int i = 0; i < (TEST_NIGHTLY ? 39 : 13) * RANDOM_MULTIPLIER; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      ReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = ReaderUtil.leaves(topReaderContext);\n      for (AtomicReaderContext atomicReaderContext : leaves) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader, bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader.maxDoc();\n        // initially advance or do next doc\n        if (random.nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random.nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"77cf4379b2824f6ea34b091c495d6e95c38ff9e2","date":1307610475,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","sourceNew":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    int howMany = 1000;\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), Field.Store.NO,\n          Field.Index.ANALYZED_NO_NORMS));\n      writer.addDocument(doc);\n    }\n\n    // now do seaches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      ReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = ReaderUtil.leaves(topReaderContext);\n      for (AtomicReaderContext atomicReaderContext : leaves) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader, bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader.maxDoc();\n        // initially advance or do next doc\n        if (random.nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random.nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    int howMany = 1000;\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), Field.Store.YES,\n          Field.Index.ANALYZED));\n      writer.addDocument(doc);\n    }\n\n    // now do seaches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    for (int i = 0; i < 39 * RANDOM_MULTIPLIER; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      ReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = ReaderUtil.leaves(topReaderContext);\n      for (AtomicReaderContext atomicReaderContext : leaves) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader, bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader.maxDoc();\n        // initially advance or do next doc\n        if (random.nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random.nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a02058e0eaba4bbd5d05e6b06b9522c0acfd1655","date":1307729864,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","sourceNew":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    int howMany = 1000;\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), Field.Store.NO,\n          Field.Index.ANALYZED_NO_NORMS));\n      writer.addDocument(doc);\n    }\n\n    // now do seaches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      ReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = ReaderUtil.leaves(topReaderContext);\n      for (AtomicReaderContext atomicReaderContext : leaves) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader, bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader.maxDoc();\n        // initially advance or do next doc\n        if (random.nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random.nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    int howMany = 1000;\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), Field.Store.NO,\n          Field.Index.ANALYZED_NO_NORMS));\n      writer.addDocument(doc);\n    }\n\n    // now do seaches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    for (int i = 0; i < (TEST_NIGHTLY ? 39 : 13) * RANDOM_MULTIPLIER; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      ReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = ReaderUtil.leaves(topReaderContext);\n      for (AtomicReaderContext atomicReaderContext : leaves) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader, bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader.maxDoc();\n        // initially advance or do next doc\n        if (random.nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random.nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"60ba444201d2570214b6fcf1d15600dc1a01f548","date":1313868045,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","sourceNew":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    int howMany = 1000;\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), Field.Store.NO,\n          Field.Index.ANALYZED_NO_NORMS));\n      writer.addDocument(doc);\n    }\n\n    // now do searches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      ReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = ReaderUtil.leaves(topReaderContext);\n      for (AtomicReaderContext atomicReaderContext : leaves) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader, bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader.maxDoc();\n        // initially advance or do next doc\n        if (random.nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random.nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    int howMany = 1000;\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), Field.Store.NO,\n          Field.Index.ANALYZED_NO_NORMS));\n      writer.addDocument(doc);\n    }\n\n    // now do seaches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      ReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = ReaderUtil.leaves(topReaderContext);\n      for (AtomicReaderContext atomicReaderContext : leaves) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader, bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader.maxDoc();\n        // initially advance or do next doc\n        if (random.nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random.nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1509f151d7692d84fae414b2b799ac06ba60fcb4","date":1314451621,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","sourceNew":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    int howMany = 1000;\n    FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    // now do searches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      ReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = ReaderUtil.leaves(topReaderContext);\n      for (AtomicReaderContext atomicReaderContext : leaves) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader, bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader.maxDoc();\n        // initially advance or do next doc\n        if (random.nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random.nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    int howMany = 1000;\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), Field.Store.NO,\n          Field.Index.ANALYZED_NO_NORMS));\n      writer.addDocument(doc);\n    }\n\n    // now do searches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      ReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = ReaderUtil.leaves(topReaderContext);\n      for (AtomicReaderContext atomicReaderContext : leaves) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader, bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader.maxDoc();\n        // initially advance or do next doc\n        if (random.nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random.nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"868186558eb3a854ce7e720a52bb445795d54910","date":1327853682,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","sourceNew":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    int howMany = 1000;\n    FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    // now do searches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      ReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = ReaderUtil.leaves(topReaderContext);\n      for (AtomicReaderContext atomicReaderContext : leaves) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader(), bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader().maxDoc();\n        // initially advance or do next doc\n        if (random.nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random.nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    int howMany = 1000;\n    FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    // now do searches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      ReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = ReaderUtil.leaves(topReaderContext);\n      for (AtomicReaderContext atomicReaderContext : leaves) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader, bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader.maxDoc();\n        // initially advance or do next doc\n        if (random.nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random.nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8493985e6883b3fa8231d172694d2aa3a85cb182","date":1327920390,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","sourceNew":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    int howMany = 1000;\n    FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    // now do searches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      IndexReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = ReaderUtil.leaves(topReaderContext);\n      for (AtomicReaderContext atomicReaderContext : leaves) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader(), bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader().maxDoc();\n        // initially advance or do next doc\n        if (random.nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random.nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    int howMany = 1000;\n    FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    // now do searches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      ReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = ReaderUtil.leaves(topReaderContext);\n      for (AtomicReaderContext atomicReaderContext : leaves) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader(), bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader().maxDoc();\n        // initially advance or do next doc\n        if (random.nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random.nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5cab9a86bd67202d20b6adc463008c8e982b070a","date":1327966443,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","sourceNew":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    int howMany = 1000;\n    FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    // now do searches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      IndexReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = ReaderUtil.leaves(topReaderContext);\n      for (AtomicReaderContext atomicReaderContext : leaves) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader(), bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader().maxDoc();\n        // initially advance or do next doc\n        if (random.nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random.nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    int howMany = 1000;\n    FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    // now do searches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      ReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = ReaderUtil.leaves(topReaderContext);\n      for (AtomicReaderContext atomicReaderContext : leaves) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader, bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader.maxDoc();\n        // initially advance or do next doc\n        if (random.nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random.nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","sourceNew":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    int howMany = 1000;\n    FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    // now do searches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      IndexReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = ReaderUtil.leaves(topReaderContext);\n      for (AtomicReaderContext atomicReaderContext : leaves) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader(), bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader().maxDoc();\n        // initially advance or do next doc\n        if (random.nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random.nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    int howMany = 1000;\n    FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    // now do searches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      IndexReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = ReaderUtil.leaves(topReaderContext);\n      for (AtomicReaderContext atomicReaderContext : leaves) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader(), bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader().maxDoc();\n        // initially advance or do next doc\n        if (random.nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random.nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"8493985e6883b3fa8231d172694d2aa3a85cb182":["868186558eb3a854ce7e720a52bb445795d54910"],"a02058e0eaba4bbd5d05e6b06b9522c0acfd1655":["79c2cb24929f2649a8875fb629086171f914d5ce","0762b640e0d0d12b6edb96db68986e13145c3484"],"ff6fd241dc6610f7f81b62e3ba4cedf105939623":["f2c5f0cb44df114db4228c8f77861714b5cabaea"],"0762b640e0d0d12b6edb96db68986e13145c3484":["ff6fd241dc6610f7f81b62e3ba4cedf105939623"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["5cab9a86bd67202d20b6adc463008c8e982b070a"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["29ef99d61cda9641b6250bf9567329a6e65f901d","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"962d04139994fce5193143ef35615499a9a96d78":["bde51b089eb7f86171eb3406e38a274743f9b7ac","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"5cab9a86bd67202d20b6adc463008c8e982b070a":["1509f151d7692d84fae414b2b799ac06ba60fcb4","8493985e6883b3fa8231d172694d2aa3a85cb182"],"60ba444201d2570214b6fcf1d15600dc1a01f548":["0762b640e0d0d12b6edb96db68986e13145c3484"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["9d7606b7ab7992bc238d10c3bddfe82a639d212a"],"79c2cb24929f2649a8875fb629086171f914d5ce":["a3776dccca01c11e7046323cfad46a3b4a471233","ff6fd241dc6610f7f81b62e3ba4cedf105939623"],"a3776dccca01c11e7046323cfad46a3b4a471233":["9d7606b7ab7992bc238d10c3bddfe82a639d212a","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","9d7606b7ab7992bc238d10c3bddfe82a639d212a"],"9d7606b7ab7992bc238d10c3bddfe82a639d212a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"77cf4379b2824f6ea34b091c495d6e95c38ff9e2":["135621f3a0670a9394eb563224a3b76cc4dddc0f","0762b640e0d0d12b6edb96db68986e13145c3484"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["60ba444201d2570214b6fcf1d15600dc1a01f548"],"868186558eb3a854ce7e720a52bb445795d54910":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","9d7606b7ab7992bc238d10c3bddfe82a639d212a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"]},"commit2Childs":{"8493985e6883b3fa8231d172694d2aa3a85cb182":["5cab9a86bd67202d20b6adc463008c8e982b070a"],"a02058e0eaba4bbd5d05e6b06b9522c0acfd1655":[],"ff6fd241dc6610f7f81b62e3ba4cedf105939623":["0762b640e0d0d12b6edb96db68986e13145c3484","79c2cb24929f2649a8875fb629086171f914d5ce"],"0762b640e0d0d12b6edb96db68986e13145c3484":["a02058e0eaba4bbd5d05e6b06b9522c0acfd1655","60ba444201d2570214b6fcf1d15600dc1a01f548","77cf4379b2824f6ea34b091c495d6e95c38ff9e2"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["77cf4379b2824f6ea34b091c495d6e95c38ff9e2"],"962d04139994fce5193143ef35615499a9a96d78":[],"5cab9a86bd67202d20b6adc463008c8e982b070a":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"60ba444201d2570214b6fcf1d15600dc1a01f548":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["ff6fd241dc6610f7f81b62e3ba4cedf105939623","135621f3a0670a9394eb563224a3b76cc4dddc0f","962d04139994fce5193143ef35615499a9a96d78","a3776dccca01c11e7046323cfad46a3b4a471233"],"79c2cb24929f2649a8875fb629086171f914d5ce":["a02058e0eaba4bbd5d05e6b06b9522c0acfd1655"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["135621f3a0670a9394eb563224a3b76cc4dddc0f"],"a3776dccca01c11e7046323cfad46a3b4a471233":["79c2cb24929f2649a8875fb629086171f914d5ce"],"9d7606b7ab7992bc238d10c3bddfe82a639d212a":["f2c5f0cb44df114db4228c8f77861714b5cabaea","a3776dccca01c11e7046323cfad46a3b4a471233","29ef99d61cda9641b6250bf9567329a6e65f901d","bde51b089eb7f86171eb3406e38a274743f9b7ac"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["29ef99d61cda9641b6250bf9567329a6e65f901d","9d7606b7ab7992bc238d10c3bddfe82a639d212a","bde51b089eb7f86171eb3406e38a274743f9b7ac"],"77cf4379b2824f6ea34b091c495d6e95c38ff9e2":[],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["5cab9a86bd67202d20b6adc463008c8e982b070a","868186558eb3a854ce7e720a52bb445795d54910"],"868186558eb3a854ce7e720a52bb445795d54910":["8493985e6883b3fa8231d172694d2aa3a85cb182"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["962d04139994fce5193143ef35615499a9a96d78"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a02058e0eaba4bbd5d05e6b06b9522c0acfd1655","962d04139994fce5193143ef35615499a9a96d78","77cf4379b2824f6ea34b091c495d6e95c38ff9e2","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}