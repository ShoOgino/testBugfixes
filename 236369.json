{"path":"lucene/core/src/test/org/apache/lucene/search/TestTermVectors#testRareVectors().mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestTermVectors#testRareVectors().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestTermVectors#testRareVectors().mjava","sourceNew":"  // Test only a few docs having vectors\n  public void testRareVectors() throws IOException {\n    RandomIndexWriter writer = new RandomIndexWriter(random, directory, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.SIMPLE, true))\n        .setOpenMode(OpenMode.CREATE));\n    if (VERBOSE) {\n      System.out.println(\"TEST: now add non-vectors\");\n    }\n    for (int i = 0; i < 100; i++) {\n      Document doc = new Document();\n      doc.add(newField(\"field\", English.intToEnglish(i), TextField.TYPE_STORED));\n      writer.addDocument(doc);\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: now add vectors\");\n    }\n    FieldType ft = new FieldType(TextField.TYPE_STORED);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorOffsets(true);\n    ft.setStoreTermVectorPositions(true);\n    for(int i=0;i<10;i++) {\n      Document doc = new Document();\n      doc.add(newField(\"field\", English.intToEnglish(100+i), ft));\n      writer.addDocument(doc);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now getReader\");\n    }\n    IndexReader reader = writer.getReader();\n    writer.close();\n    IndexSearcher searcher = newSearcher(reader);\n\n    Query query = new TermQuery(new Term(\"field\", \"hundred\"));\n    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;\n    assertEquals(10, hits.length);\n    for (int i = 0; i < hits.length; i++) {\n\n      Fields vectors = searcher.reader.getTermVectors(hits[i].doc);\n      assertNotNull(vectors);\n      assertEquals(1, vectors.getUniqueFieldCount());\n    }\n    reader.close();\n  }\n\n","sourceOld":"  // Test only a few docs having vectors\n  public void testRareVectors() throws IOException {\n    RandomIndexWriter writer = new RandomIndexWriter(random, directory, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.SIMPLE, true))\n        .setOpenMode(OpenMode.CREATE));\n    if (VERBOSE) {\n      System.out.println(\"TEST: now add non-vectors\");\n    }\n    for (int i = 0; i < 100; i++) {\n      Document doc = new Document();\n      doc.add(newField(\"field\", English.intToEnglish(i), TextField.TYPE_STORED));\n      writer.addDocument(doc);\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: now add vectors\");\n    }\n    FieldType ft = new FieldType(TextField.TYPE_STORED);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorOffsets(true);\n    ft.setStoreTermVectorPositions(true);\n    for(int i=0;i<10;i++) {\n      Document doc = new Document();\n      doc.add(newField(\"field\", English.intToEnglish(100+i), ft));\n      writer.addDocument(doc);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now getReader\");\n    }\n    IndexReader reader = writer.getReader();\n    writer.close();\n    IndexSearcher searcher = newSearcher(reader);\n\n    Query query = new TermQuery(new Term(\"field\", \"hundred\"));\n    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;\n    assertEquals(10, hits.length);\n    for (int i = 0; i < hits.length; i++) {\n\n      Fields vectors = searcher.reader.getTermVectors(hits[i].doc);\n      assertNotNull(vectors);\n      assertEquals(1, vectors.getUniqueFieldCount());\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d08eba3d52b63561ebf936481ce73e6b6a14aa03","date":1333879759,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestTermVectors#testRareVectors().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestTermVectors#testRareVectors().mjava","sourceNew":"  // Test only a few docs having vectors\n  public void testRareVectors() throws IOException {\n    RandomIndexWriter writer = new RandomIndexWriter(random, directory, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.SIMPLE, true))\n        .setOpenMode(OpenMode.CREATE));\n    if (VERBOSE) {\n      System.out.println(\"TEST: now add non-vectors\");\n    }\n    for (int i = 0; i < 100; i++) {\n      Document doc = new Document();\n      doc.add(newField(\"field\", English.intToEnglish(i), TextField.TYPE_STORED));\n      writer.addDocument(doc);\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: now add vectors\");\n    }\n    FieldType ft = new FieldType(TextField.TYPE_STORED);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorOffsets(true);\n    ft.setStoreTermVectorPositions(true);\n    for(int i=0;i<10;i++) {\n      Document doc = new Document();\n      doc.add(newField(\"field\", English.intToEnglish(100+i), ft));\n      writer.addDocument(doc);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now getReader\");\n    }\n    IndexReader reader = writer.getReader();\n    writer.close();\n    IndexSearcher searcher = newSearcher(reader);\n\n    Query query = new TermQuery(new Term(\"field\", \"hundred\"));\n    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;\n    assertEquals(10, hits.length);\n    for (int i = 0; i < hits.length; i++) {\n\n      InvertedFields vectors = searcher.reader.getTermVectors(hits[i].doc);\n      assertNotNull(vectors);\n      assertEquals(1, vectors.getUniqueFieldCount());\n    }\n    reader.close();\n  }\n\n","sourceOld":"  // Test only a few docs having vectors\n  public void testRareVectors() throws IOException {\n    RandomIndexWriter writer = new RandomIndexWriter(random, directory, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.SIMPLE, true))\n        .setOpenMode(OpenMode.CREATE));\n    if (VERBOSE) {\n      System.out.println(\"TEST: now add non-vectors\");\n    }\n    for (int i = 0; i < 100; i++) {\n      Document doc = new Document();\n      doc.add(newField(\"field\", English.intToEnglish(i), TextField.TYPE_STORED));\n      writer.addDocument(doc);\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: now add vectors\");\n    }\n    FieldType ft = new FieldType(TextField.TYPE_STORED);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorOffsets(true);\n    ft.setStoreTermVectorPositions(true);\n    for(int i=0;i<10;i++) {\n      Document doc = new Document();\n      doc.add(newField(\"field\", English.intToEnglish(100+i), ft));\n      writer.addDocument(doc);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now getReader\");\n    }\n    IndexReader reader = writer.getReader();\n    writer.close();\n    IndexSearcher searcher = newSearcher(reader);\n\n    Query query = new TermQuery(new Term(\"field\", \"hundred\"));\n    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;\n    assertEquals(10, hits.length);\n    for (int i = 0; i < hits.length; i++) {\n\n      Fields vectors = searcher.reader.getTermVectors(hits[i].doc);\n      assertNotNull(vectors);\n      assertEquals(1, vectors.getUniqueFieldCount());\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf","date":1333892281,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestTermVectors#testRareVectors().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestTermVectors#testRareVectors().mjava","sourceNew":"  // Test only a few docs having vectors\n  public void testRareVectors() throws IOException {\n    RandomIndexWriter writer = new RandomIndexWriter(random, directory, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.SIMPLE, true))\n        .setOpenMode(OpenMode.CREATE));\n    if (VERBOSE) {\n      System.out.println(\"TEST: now add non-vectors\");\n    }\n    for (int i = 0; i < 100; i++) {\n      Document doc = new Document();\n      doc.add(newField(\"field\", English.intToEnglish(i), TextField.TYPE_STORED));\n      writer.addDocument(doc);\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: now add vectors\");\n    }\n    FieldType ft = new FieldType(TextField.TYPE_STORED);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorOffsets(true);\n    ft.setStoreTermVectorPositions(true);\n    for(int i=0;i<10;i++) {\n      Document doc = new Document();\n      doc.add(newField(\"field\", English.intToEnglish(100+i), ft));\n      writer.addDocument(doc);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now getReader\");\n    }\n    IndexReader reader = writer.getReader();\n    writer.close();\n    IndexSearcher searcher = newSearcher(reader);\n\n    Query query = new TermQuery(new Term(\"field\", \"hundred\"));\n    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;\n    assertEquals(10, hits.length);\n    for (int i = 0; i < hits.length; i++) {\n\n      Fields vectors = searcher.reader.getTermVectors(hits[i].doc);\n      assertNotNull(vectors);\n      assertEquals(1, vectors.getUniqueFieldCount());\n    }\n    reader.close();\n  }\n\n","sourceOld":"  // Test only a few docs having vectors\n  public void testRareVectors() throws IOException {\n    RandomIndexWriter writer = new RandomIndexWriter(random, directory, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.SIMPLE, true))\n        .setOpenMode(OpenMode.CREATE));\n    if (VERBOSE) {\n      System.out.println(\"TEST: now add non-vectors\");\n    }\n    for (int i = 0; i < 100; i++) {\n      Document doc = new Document();\n      doc.add(newField(\"field\", English.intToEnglish(i), TextField.TYPE_STORED));\n      writer.addDocument(doc);\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: now add vectors\");\n    }\n    FieldType ft = new FieldType(TextField.TYPE_STORED);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorOffsets(true);\n    ft.setStoreTermVectorPositions(true);\n    for(int i=0;i<10;i++) {\n      Document doc = new Document();\n      doc.add(newField(\"field\", English.intToEnglish(100+i), ft));\n      writer.addDocument(doc);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now getReader\");\n    }\n    IndexReader reader = writer.getReader();\n    writer.close();\n    IndexSearcher searcher = newSearcher(reader);\n\n    Query query = new TermQuery(new Term(\"field\", \"hundred\"));\n    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;\n    assertEquals(10, hits.length);\n    for (int i = 0; i < hits.length; i++) {\n\n      InvertedFields vectors = searcher.reader.getTermVectors(hits[i].doc);\n      assertNotNull(vectors);\n      assertEquals(1, vectors.getUniqueFieldCount());\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bdb5e42b0cecd8dfb27767a02ada71899bf17917","date":1334100099,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestTermVectors#testRareVectors().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestTermVectors#testRareVectors().mjava","sourceNew":"  // Test only a few docs having vectors\n  public void testRareVectors() throws IOException {\n    RandomIndexWriter writer = new RandomIndexWriter(random, directory, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.SIMPLE, true))\n        .setOpenMode(OpenMode.CREATE));\n    if (VERBOSE) {\n      System.out.println(\"TEST: now add non-vectors\");\n    }\n    for (int i = 0; i < 100; i++) {\n      Document doc = new Document();\n      doc.add(newField(\"field\", English.intToEnglish(i), TextField.TYPE_STORED));\n      writer.addDocument(doc);\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: now add vectors\");\n    }\n    FieldType ft = new FieldType(TextField.TYPE_STORED);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorOffsets(true);\n    ft.setStoreTermVectorPositions(true);\n    for(int i=0;i<10;i++) {\n      Document doc = new Document();\n      doc.add(newField(\"field\", English.intToEnglish(100+i), ft));\n      writer.addDocument(doc);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now getReader\");\n    }\n    IndexReader reader = writer.getReader();\n    writer.close();\n    IndexSearcher searcher = newSearcher(reader);\n\n    Query query = new TermQuery(new Term(\"field\", \"hundred\"));\n    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;\n    assertEquals(10, hits.length);\n    for (int i = 0; i < hits.length; i++) {\n\n      Fields vectors = searcher.reader.getTermVectors(hits[i].doc);\n      assertNotNull(vectors);\n      assertEquals(1, vectors.size());\n    }\n    reader.close();\n  }\n\n","sourceOld":"  // Test only a few docs having vectors\n  public void testRareVectors() throws IOException {\n    RandomIndexWriter writer = new RandomIndexWriter(random, directory, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.SIMPLE, true))\n        .setOpenMode(OpenMode.CREATE));\n    if (VERBOSE) {\n      System.out.println(\"TEST: now add non-vectors\");\n    }\n    for (int i = 0; i < 100; i++) {\n      Document doc = new Document();\n      doc.add(newField(\"field\", English.intToEnglish(i), TextField.TYPE_STORED));\n      writer.addDocument(doc);\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: now add vectors\");\n    }\n    FieldType ft = new FieldType(TextField.TYPE_STORED);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorOffsets(true);\n    ft.setStoreTermVectorPositions(true);\n    for(int i=0;i<10;i++) {\n      Document doc = new Document();\n      doc.add(newField(\"field\", English.intToEnglish(100+i), ft));\n      writer.addDocument(doc);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now getReader\");\n    }\n    IndexReader reader = writer.getReader();\n    writer.close();\n    IndexSearcher searcher = newSearcher(reader);\n\n    Query query = new TermQuery(new Term(\"field\", \"hundred\"));\n    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;\n    assertEquals(10, hits.length);\n    for (int i = 0; i < hits.length; i++) {\n\n      Fields vectors = searcher.reader.getTermVectors(hits[i].doc);\n      assertNotNull(vectors);\n      assertEquals(1, vectors.getUniqueFieldCount());\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5a238fc456663f685a9db1ed8d680e348bb45171","date":1334173266,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestTermVectors#testRareVectors().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestTermVectors#testRareVectors().mjava","sourceNew":"  // Test only a few docs having vectors\n  public void testRareVectors() throws IOException {\n    RandomIndexWriter writer = new RandomIndexWriter(random, directory, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.SIMPLE, true))\n        .setOpenMode(OpenMode.CREATE));\n    if (VERBOSE) {\n      System.out.println(\"TEST: now add non-vectors\");\n    }\n    for (int i = 0; i < 100; i++) {\n      Document doc = new Document();\n      doc.add(newField(\"field\", English.intToEnglish(i), TextField.TYPE_STORED));\n      writer.addDocument(doc);\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: now add vectors\");\n    }\n    FieldType ft = new FieldType(TextField.TYPE_STORED);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorOffsets(true);\n    ft.setStoreTermVectorPositions(true);\n    for(int i=0;i<10;i++) {\n      Document doc = new Document();\n      doc.add(newField(\"field\", English.intToEnglish(100+i), ft));\n      writer.addDocument(doc);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now getReader\");\n    }\n    IndexReader reader = writer.getReader();\n    writer.close();\n    IndexSearcher searcher = newSearcher(reader);\n\n    Query query = new TermQuery(new Term(\"field\", \"hundred\"));\n    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;\n    assertEquals(10, hits.length);\n    for (int i = 0; i < hits.length; i++) {\n\n      Fields vectors = searcher.reader.getTermVectors(hits[i].doc);\n      assertNotNull(vectors);\n      assertEquals(1, vectors.size());\n    }\n    reader.close();\n  }\n\n","sourceOld":"  // Test only a few docs having vectors\n  public void testRareVectors() throws IOException {\n    RandomIndexWriter writer = new RandomIndexWriter(random, directory, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.SIMPLE, true))\n        .setOpenMode(OpenMode.CREATE));\n    if (VERBOSE) {\n      System.out.println(\"TEST: now add non-vectors\");\n    }\n    for (int i = 0; i < 100; i++) {\n      Document doc = new Document();\n      doc.add(newField(\"field\", English.intToEnglish(i), TextField.TYPE_STORED));\n      writer.addDocument(doc);\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: now add vectors\");\n    }\n    FieldType ft = new FieldType(TextField.TYPE_STORED);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorOffsets(true);\n    ft.setStoreTermVectorPositions(true);\n    for(int i=0;i<10;i++) {\n      Document doc = new Document();\n      doc.add(newField(\"field\", English.intToEnglish(100+i), ft));\n      writer.addDocument(doc);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now getReader\");\n    }\n    IndexReader reader = writer.getReader();\n    writer.close();\n    IndexSearcher searcher = newSearcher(reader);\n\n    Query query = new TermQuery(new Term(\"field\", \"hundred\"));\n    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;\n    assertEquals(10, hits.length);\n    for (int i = 0; i < hits.length; i++) {\n\n      Fields vectors = searcher.reader.getTermVectors(hits[i].doc);\n      assertNotNull(vectors);\n      assertEquals(1, vectors.getUniqueFieldCount());\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestTermVectors#testRareVectors().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestTermVectors#testRareVectors().mjava","sourceNew":"  // Test only a few docs having vectors\n  public void testRareVectors() throws IOException {\n    RandomIndexWriter writer = new RandomIndexWriter(random(), directory, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.SIMPLE, true))\n        .setOpenMode(OpenMode.CREATE));\n    if (VERBOSE) {\n      System.out.println(\"TEST: now add non-vectors\");\n    }\n    for (int i = 0; i < 100; i++) {\n      Document doc = new Document();\n      doc.add(newField(\"field\", English.intToEnglish(i), TextField.TYPE_STORED));\n      writer.addDocument(doc);\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: now add vectors\");\n    }\n    FieldType ft = new FieldType(TextField.TYPE_STORED);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorOffsets(true);\n    ft.setStoreTermVectorPositions(true);\n    for(int i=0;i<10;i++) {\n      Document doc = new Document();\n      doc.add(newField(\"field\", English.intToEnglish(100+i), ft));\n      writer.addDocument(doc);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now getReader\");\n    }\n    IndexReader reader = writer.getReader();\n    writer.close();\n    IndexSearcher searcher = newSearcher(reader);\n\n    Query query = new TermQuery(new Term(\"field\", \"hundred\"));\n    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;\n    assertEquals(10, hits.length);\n    for (int i = 0; i < hits.length; i++) {\n\n      Fields vectors = searcher.reader.getTermVectors(hits[i].doc);\n      assertNotNull(vectors);\n      assertEquals(1, vectors.size());\n    }\n    reader.close();\n  }\n\n","sourceOld":"  // Test only a few docs having vectors\n  public void testRareVectors() throws IOException {\n    RandomIndexWriter writer = new RandomIndexWriter(random, directory, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.SIMPLE, true))\n        .setOpenMode(OpenMode.CREATE));\n    if (VERBOSE) {\n      System.out.println(\"TEST: now add non-vectors\");\n    }\n    for (int i = 0; i < 100; i++) {\n      Document doc = new Document();\n      doc.add(newField(\"field\", English.intToEnglish(i), TextField.TYPE_STORED));\n      writer.addDocument(doc);\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: now add vectors\");\n    }\n    FieldType ft = new FieldType(TextField.TYPE_STORED);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorOffsets(true);\n    ft.setStoreTermVectorPositions(true);\n    for(int i=0;i<10;i++) {\n      Document doc = new Document();\n      doc.add(newField(\"field\", English.intToEnglish(100+i), ft));\n      writer.addDocument(doc);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now getReader\");\n    }\n    IndexReader reader = writer.getReader();\n    writer.close();\n    IndexSearcher searcher = newSearcher(reader);\n\n    Query query = new TermQuery(new Term(\"field\", \"hundred\"));\n    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;\n    assertEquals(10, hits.length);\n    for (int i = 0; i < hits.length; i++) {\n\n      Fields vectors = searcher.reader.getTermVectors(hits[i].doc);\n      assertNotNull(vectors);\n      assertEquals(1, vectors.size());\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"04f07771a2a7dd3a395700665ed839c3dae2def2","date":1339350139,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestTermVectors#testRareVectors().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestTermVectors#testRareVectors().mjava","sourceNew":"  // Test only a few docs having vectors\n  public void testRareVectors() throws IOException {\n    RandomIndexWriter writer = new RandomIndexWriter(random(), directory, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.SIMPLE, true))\n        .setOpenMode(OpenMode.CREATE));\n    if (VERBOSE) {\n      System.out.println(\"TEST: now add non-vectors\");\n    }\n    for (int i = 0; i < 100; i++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"field\", English.intToEnglish(i), Field.Store.YES));\n      writer.addDocument(doc);\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: now add vectors\");\n    }\n    FieldType ft = new FieldType(TextField.TYPE_STORED);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorOffsets(true);\n    ft.setStoreTermVectorPositions(true);\n    for(int i=0;i<10;i++) {\n      Document doc = new Document();\n      doc.add(newField(\"field\", English.intToEnglish(100+i), ft));\n      writer.addDocument(doc);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now getReader\");\n    }\n    IndexReader reader = writer.getReader();\n    writer.close();\n    IndexSearcher searcher = newSearcher(reader);\n\n    Query query = new TermQuery(new Term(\"field\", \"hundred\"));\n    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;\n    assertEquals(10, hits.length);\n    for (int i = 0; i < hits.length; i++) {\n\n      Fields vectors = searcher.reader.getTermVectors(hits[i].doc);\n      assertNotNull(vectors);\n      assertEquals(1, vectors.size());\n    }\n    reader.close();\n  }\n\n","sourceOld":"  // Test only a few docs having vectors\n  public void testRareVectors() throws IOException {\n    RandomIndexWriter writer = new RandomIndexWriter(random(), directory, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.SIMPLE, true))\n        .setOpenMode(OpenMode.CREATE));\n    if (VERBOSE) {\n      System.out.println(\"TEST: now add non-vectors\");\n    }\n    for (int i = 0; i < 100; i++) {\n      Document doc = new Document();\n      doc.add(newField(\"field\", English.intToEnglish(i), TextField.TYPE_STORED));\n      writer.addDocument(doc);\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: now add vectors\");\n    }\n    FieldType ft = new FieldType(TextField.TYPE_STORED);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorOffsets(true);\n    ft.setStoreTermVectorPositions(true);\n    for(int i=0;i<10;i++) {\n      Document doc = new Document();\n      doc.add(newField(\"field\", English.intToEnglish(100+i), ft));\n      writer.addDocument(doc);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now getReader\");\n    }\n    IndexReader reader = writer.getReader();\n    writer.close();\n    IndexSearcher searcher = newSearcher(reader);\n\n    Query query = new TermQuery(new Term(\"field\", \"hundred\"));\n    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;\n    assertEquals(10, hits.length);\n    for (int i = 0; i < hits.length; i++) {\n\n      Fields vectors = searcher.reader.getTermVectors(hits[i].doc);\n      assertNotNull(vectors);\n      assertEquals(1, vectors.size());\n    }\n    reader.close();\n  }\n\n","bugFix":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f21ce13f410ee015e1ba14687ab4b8518ac52a11","date":1359713213,"type":4,"author":"Adrien Grand","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestTermVectors#testRareVectors().mjava","sourceNew":null,"sourceOld":"  // Test only a few docs having vectors\n  public void testRareVectors() throws IOException {\n    RandomIndexWriter writer = new RandomIndexWriter(random(), directory, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.SIMPLE, true))\n        .setOpenMode(OpenMode.CREATE));\n    if (VERBOSE) {\n      System.out.println(\"TEST: now add non-vectors\");\n    }\n    for (int i = 0; i < 100; i++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"field\", English.intToEnglish(i), Field.Store.YES));\n      writer.addDocument(doc);\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: now add vectors\");\n    }\n    FieldType ft = new FieldType(TextField.TYPE_STORED);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorOffsets(true);\n    ft.setStoreTermVectorPositions(true);\n    for(int i=0;i<10;i++) {\n      Document doc = new Document();\n      doc.add(newField(\"field\", English.intToEnglish(100+i), ft));\n      writer.addDocument(doc);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now getReader\");\n    }\n    IndexReader reader = writer.getReader();\n    writer.close();\n    IndexSearcher searcher = newSearcher(reader);\n\n    Query query = new TermQuery(new Term(\"field\", \"hundred\"));\n    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;\n    assertEquals(10, hits.length);\n    for (int i = 0; i < hits.length; i++) {\n\n      Fields vectors = searcher.reader.getTermVectors(hits[i].doc);\n      assertNotNull(vectors);\n      assertEquals(1, vectors.size());\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0fa6955ed1b1007ded1349ab72cea4555640432f","date":1359721908,"type":4,"author":"Robert Muir","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestTermVectors#testRareVectors().mjava","sourceNew":null,"sourceOld":"  // Test only a few docs having vectors\n  public void testRareVectors() throws IOException {\n    RandomIndexWriter writer = new RandomIndexWriter(random(), directory, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.SIMPLE, true))\n        .setOpenMode(OpenMode.CREATE));\n    if (VERBOSE) {\n      System.out.println(\"TEST: now add non-vectors\");\n    }\n    for (int i = 0; i < 100; i++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"field\", English.intToEnglish(i), Field.Store.YES));\n      writer.addDocument(doc);\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: now add vectors\");\n    }\n    FieldType ft = new FieldType(TextField.TYPE_STORED);\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorOffsets(true);\n    ft.setStoreTermVectorPositions(true);\n    for(int i=0;i<10;i++) {\n      Document doc = new Document();\n      doc.add(newField(\"field\", English.intToEnglish(100+i), ft));\n      writer.addDocument(doc);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now getReader\");\n    }\n    IndexReader reader = writer.getReader();\n    writer.close();\n    IndexSearcher searcher = newSearcher(reader);\n\n    Query query = new TermQuery(new Term(\"field\", \"hundred\"));\n    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;\n    assertEquals(10, hits.length);\n    for (int i = 0; i < hits.length; i++) {\n\n      Fields vectors = searcher.reader.getTermVectors(hits[i].doc);\n      assertNotNull(vectors);\n      assertEquals(1, vectors.size());\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"04f07771a2a7dd3a395700665ed839c3dae2def2":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"0fa6955ed1b1007ded1349ab72cea4555640432f":["04f07771a2a7dd3a395700665ed839c3dae2def2","f21ce13f410ee015e1ba14687ab4b8518ac52a11"],"bdb5e42b0cecd8dfb27767a02ada71899bf17917":["e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf"],"5a238fc456663f685a9db1ed8d680e348bb45171":["e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf","bdb5e42b0cecd8dfb27767a02ada71899bf17917"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf":["d08eba3d52b63561ebf936481ce73e6b6a14aa03"],"f21ce13f410ee015e1ba14687ab4b8518ac52a11":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"d08eba3d52b63561ebf936481ce73e6b6a14aa03":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["bdb5e42b0cecd8dfb27767a02ada71899bf17917"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["f21ce13f410ee015e1ba14687ab4b8518ac52a11"]},"commit2Childs":{"04f07771a2a7dd3a395700665ed839c3dae2def2":["0fa6955ed1b1007ded1349ab72cea4555640432f","f21ce13f410ee015e1ba14687ab4b8518ac52a11"],"0fa6955ed1b1007ded1349ab72cea4555640432f":[],"bdb5e42b0cecd8dfb27767a02ada71899bf17917":["5a238fc456663f685a9db1ed8d680e348bb45171","629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"5a238fc456663f685a9db1ed8d680e348bb45171":[],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["d08eba3d52b63561ebf936481ce73e6b6a14aa03"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf":["bdb5e42b0cecd8dfb27767a02ada71899bf17917","5a238fc456663f685a9db1ed8d680e348bb45171"],"f21ce13f410ee015e1ba14687ab4b8518ac52a11":["0fa6955ed1b1007ded1349ab72cea4555640432f","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"d08eba3d52b63561ebf936481ce73e6b6a14aa03":["e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["0fa6955ed1b1007ded1349ab72cea4555640432f","5a238fc456663f685a9db1ed8d680e348bb45171","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}