{"path":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpans#testSpanScorerZeroSloppyFreq().mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpans#testSpanScorerZeroSloppyFreq().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/spans/TestSpans#testSpanScorerZeroSloppyFreq().mjava","sourceNew":"  public void testSpanScorerZeroSloppyFreq() throws Exception {\n    boolean ordered = true;\n    int slop = 1;\n    IndexReaderContext topReaderContext = searcher.getTopReaderContext();\n    AtomicReaderContext[] leaves = ReaderUtil.leaves(topReaderContext);\n    int subIndex = ReaderUtil.subIndex(11, leaves);\n    for (int i = 0; i < leaves.length; i++) {\n      \n     \n      final Similarity sim = new DefaultSimilarity() {\n        @Override\n        public float sloppyFreq(int distance) {\n          return 0.0f;\n        }\n      };\n  \n      final Similarity oldSim = searcher.getSimilarity();\n      Scorer spanScorer;\n      try {\n        searcher.setSimilarity(sim);\n        SpanNearQuery snq = new SpanNearQuery(\n                                new SpanQuery[] {\n                                  makeSpanTermQuery(\"t1\"),\n                                  makeSpanTermQuery(\"t2\") },\n                                slop,\n                                ordered);\n  \n        spanScorer = searcher.createNormalizedWeight(snq).scorer(leaves[i], true, false, leaves[i].reader().getLiveDocs());\n      } finally {\n        searcher.setSimilarity(oldSim);\n      }\n      if (i == subIndex) {\n        assertTrue(\"first doc\", spanScorer.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n        assertEquals(\"first doc number\", spanScorer.docID() + leaves[i].docBase, 11);\n        float score = spanScorer.score();\n        assertTrue(\"first doc score should be zero, \" + score, score == 0.0f);\n      }  else {\n        assertTrue(\"no second doc\", spanScorer.nextDoc() == DocIdSetIterator.NO_MORE_DOCS);\n      }\n    }\n  }\n\n","sourceOld":"  public void testSpanScorerZeroSloppyFreq() throws Exception {\n    boolean ordered = true;\n    int slop = 1;\n    IndexReaderContext topReaderContext = searcher.getTopReaderContext();\n    AtomicReaderContext[] leaves = ReaderUtil.leaves(topReaderContext);\n    int subIndex = ReaderUtil.subIndex(11, leaves);\n    for (int i = 0; i < leaves.length; i++) {\n      \n     \n      final Similarity sim = new DefaultSimilarity() {\n        @Override\n        public float sloppyFreq(int distance) {\n          return 0.0f;\n        }\n      };\n  \n      final Similarity oldSim = searcher.getSimilarity();\n      Scorer spanScorer;\n      try {\n        searcher.setSimilarity(sim);\n        SpanNearQuery snq = new SpanNearQuery(\n                                new SpanQuery[] {\n                                  makeSpanTermQuery(\"t1\"),\n                                  makeSpanTermQuery(\"t2\") },\n                                slop,\n                                ordered);\n  \n        spanScorer = searcher.createNormalizedWeight(snq).scorer(leaves[i], true, false, leaves[i].reader().getLiveDocs());\n      } finally {\n        searcher.setSimilarity(oldSim);\n      }\n      if (i == subIndex) {\n        assertTrue(\"first doc\", spanScorer.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n        assertEquals(\"first doc number\", spanScorer.docID() + leaves[i].docBase, 11);\n        float score = spanScorer.score();\n        assertTrue(\"first doc score should be zero, \" + score, score == 0.0f);\n      }  else {\n        assertTrue(\"no second doc\", spanScorer.nextDoc() == DocIdSetIterator.NO_MORE_DOCS);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0d4602ca2700dfd2f6159ad1499e5b6d1f3b92a8","date":1328775259,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpans#testSpanScorerZeroSloppyFreq().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpans#testSpanScorerZeroSloppyFreq().mjava","sourceNew":"  public void testSpanScorerZeroSloppyFreq() throws Exception {\n    boolean ordered = true;\n    int slop = 1;\n    IndexReaderContext topReaderContext = searcher.getTopReaderContext();\n    AtomicReaderContext[] leaves = topReaderContext.leaves();\n    int subIndex = ReaderUtil.subIndex(11, leaves);\n    for (int i = 0; i < leaves.length; i++) {\n      \n     \n      final Similarity sim = new DefaultSimilarity() {\n        @Override\n        public float sloppyFreq(int distance) {\n          return 0.0f;\n        }\n      };\n  \n      final Similarity oldSim = searcher.getSimilarity();\n      Scorer spanScorer;\n      try {\n        searcher.setSimilarity(sim);\n        SpanNearQuery snq = new SpanNearQuery(\n                                new SpanQuery[] {\n                                  makeSpanTermQuery(\"t1\"),\n                                  makeSpanTermQuery(\"t2\") },\n                                slop,\n                                ordered);\n  \n        spanScorer = searcher.createNormalizedWeight(snq).scorer(leaves[i], true, false, leaves[i].reader().getLiveDocs());\n      } finally {\n        searcher.setSimilarity(oldSim);\n      }\n      if (i == subIndex) {\n        assertTrue(\"first doc\", spanScorer.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n        assertEquals(\"first doc number\", spanScorer.docID() + leaves[i].docBase, 11);\n        float score = spanScorer.score();\n        assertTrue(\"first doc score should be zero, \" + score, score == 0.0f);\n      }  else {\n        assertTrue(\"no second doc\", spanScorer.nextDoc() == DocIdSetIterator.NO_MORE_DOCS);\n      }\n    }\n  }\n\n","sourceOld":"  public void testSpanScorerZeroSloppyFreq() throws Exception {\n    boolean ordered = true;\n    int slop = 1;\n    IndexReaderContext topReaderContext = searcher.getTopReaderContext();\n    AtomicReaderContext[] leaves = ReaderUtil.leaves(topReaderContext);\n    int subIndex = ReaderUtil.subIndex(11, leaves);\n    for (int i = 0; i < leaves.length; i++) {\n      \n     \n      final Similarity sim = new DefaultSimilarity() {\n        @Override\n        public float sloppyFreq(int distance) {\n          return 0.0f;\n        }\n      };\n  \n      final Similarity oldSim = searcher.getSimilarity();\n      Scorer spanScorer;\n      try {\n        searcher.setSimilarity(sim);\n        SpanNearQuery snq = new SpanNearQuery(\n                                new SpanQuery[] {\n                                  makeSpanTermQuery(\"t1\"),\n                                  makeSpanTermQuery(\"t2\") },\n                                slop,\n                                ordered);\n  \n        spanScorer = searcher.createNormalizedWeight(snq).scorer(leaves[i], true, false, leaves[i].reader().getLiveDocs());\n      } finally {\n        searcher.setSimilarity(oldSim);\n      }\n      if (i == subIndex) {\n        assertTrue(\"first doc\", spanScorer.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n        assertEquals(\"first doc number\", spanScorer.docID() + leaves[i].docBase, 11);\n        float score = spanScorer.score();\n        assertTrue(\"first doc score should be zero, \" + score, score == 0.0f);\n      }  else {\n        assertTrue(\"no second doc\", spanScorer.nextDoc() == DocIdSetIterator.NO_MORE_DOCS);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c","date":1340090669,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpans#testSpanScorerZeroSloppyFreq().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpans#testSpanScorerZeroSloppyFreq().mjava","sourceNew":"  public void testSpanScorerZeroSloppyFreq() throws Exception {\n    boolean ordered = true;\n    int slop = 1;\n    IndexReaderContext topReaderContext = searcher.getTopReaderContext();\n    List<AtomicReaderContext> leaves = topReaderContext.leaves();\n    int subIndex = ReaderUtil.subIndex(11, leaves);\n    for (int i = 0, c = leaves.size(); i < c; i++) {\n      final AtomicReaderContext ctx = leaves.get(i);\n     \n      final Similarity sim = new DefaultSimilarity() {\n        @Override\n        public float sloppyFreq(int distance) {\n          return 0.0f;\n        }\n      };\n  \n      final Similarity oldSim = searcher.getSimilarity();\n      Scorer spanScorer;\n      try {\n        searcher.setSimilarity(sim);\n        SpanNearQuery snq = new SpanNearQuery(\n                                new SpanQuery[] {\n                                  makeSpanTermQuery(\"t1\"),\n                                  makeSpanTermQuery(\"t2\") },\n                                slop,\n                                ordered);\n  \n        spanScorer = searcher.createNormalizedWeight(snq).scorer(ctx, true, false, ctx.reader().getLiveDocs());\n      } finally {\n        searcher.setSimilarity(oldSim);\n      }\n      if (i == subIndex) {\n        assertTrue(\"first doc\", spanScorer.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n        assertEquals(\"first doc number\", spanScorer.docID() + ctx.docBase, 11);\n        float score = spanScorer.score();\n        assertTrue(\"first doc score should be zero, \" + score, score == 0.0f);\n      }  else {\n        assertTrue(\"no second doc\", spanScorer.nextDoc() == DocIdSetIterator.NO_MORE_DOCS);\n      }\n    }\n  }\n\n","sourceOld":"  public void testSpanScorerZeroSloppyFreq() throws Exception {\n    boolean ordered = true;\n    int slop = 1;\n    IndexReaderContext topReaderContext = searcher.getTopReaderContext();\n    AtomicReaderContext[] leaves = topReaderContext.leaves();\n    int subIndex = ReaderUtil.subIndex(11, leaves);\n    for (int i = 0; i < leaves.length; i++) {\n      \n     \n      final Similarity sim = new DefaultSimilarity() {\n        @Override\n        public float sloppyFreq(int distance) {\n          return 0.0f;\n        }\n      };\n  \n      final Similarity oldSim = searcher.getSimilarity();\n      Scorer spanScorer;\n      try {\n        searcher.setSimilarity(sim);\n        SpanNearQuery snq = new SpanNearQuery(\n                                new SpanQuery[] {\n                                  makeSpanTermQuery(\"t1\"),\n                                  makeSpanTermQuery(\"t2\") },\n                                slop,\n                                ordered);\n  \n        spanScorer = searcher.createNormalizedWeight(snq).scorer(leaves[i], true, false, leaves[i].reader().getLiveDocs());\n      } finally {\n        searcher.setSimilarity(oldSim);\n      }\n      if (i == subIndex) {\n        assertTrue(\"first doc\", spanScorer.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n        assertEquals(\"first doc number\", spanScorer.docID() + leaves[i].docBase, 11);\n        float score = spanScorer.score();\n        assertTrue(\"first doc score should be zero, \" + score, score == 0.0f);\n      }  else {\n        assertTrue(\"no second doc\", spanScorer.nextDoc() == DocIdSetIterator.NO_MORE_DOCS);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2e18c86f811939bfa8cd24046c96ed026f2e9b34","date":1393893071,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpans#testSpanScorerZeroSloppyFreq().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpans#testSpanScorerZeroSloppyFreq().mjava","sourceNew":"  public void testSpanScorerZeroSloppyFreq() throws Exception {\n    boolean ordered = true;\n    int slop = 1;\n    IndexReaderContext topReaderContext = searcher.getTopReaderContext();\n    List<AtomicReaderContext> leaves = topReaderContext.leaves();\n    int subIndex = ReaderUtil.subIndex(11, leaves);\n    for (int i = 0, c = leaves.size(); i < c; i++) {\n      final AtomicReaderContext ctx = leaves.get(i);\n     \n      final Similarity sim = new DefaultSimilarity() {\n        @Override\n        public float sloppyFreq(int distance) {\n          return 0.0f;\n        }\n      };\n  \n      final Similarity oldSim = searcher.getSimilarity();\n      Scorer spanScorer;\n      try {\n        searcher.setSimilarity(sim);\n        SpanNearQuery snq = new SpanNearQuery(\n                                new SpanQuery[] {\n                                  makeSpanTermQuery(\"t1\"),\n                                  makeSpanTermQuery(\"t2\") },\n                                slop,\n                                ordered);\n  \n        spanScorer = searcher.createNormalizedWeight(snq).scorer(ctx, ctx.reader().getLiveDocs());\n      } finally {\n        searcher.setSimilarity(oldSim);\n      }\n      if (i == subIndex) {\n        assertTrue(\"first doc\", spanScorer.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n        assertEquals(\"first doc number\", spanScorer.docID() + ctx.docBase, 11);\n        float score = spanScorer.score();\n        assertTrue(\"first doc score should be zero, \" + score, score == 0.0f);\n      }  else {\n        assertTrue(\"no second doc\", spanScorer.nextDoc() == DocIdSetIterator.NO_MORE_DOCS);\n      }\n    }\n  }\n\n","sourceOld":"  public void testSpanScorerZeroSloppyFreq() throws Exception {\n    boolean ordered = true;\n    int slop = 1;\n    IndexReaderContext topReaderContext = searcher.getTopReaderContext();\n    List<AtomicReaderContext> leaves = topReaderContext.leaves();\n    int subIndex = ReaderUtil.subIndex(11, leaves);\n    for (int i = 0, c = leaves.size(); i < c; i++) {\n      final AtomicReaderContext ctx = leaves.get(i);\n     \n      final Similarity sim = new DefaultSimilarity() {\n        @Override\n        public float sloppyFreq(int distance) {\n          return 0.0f;\n        }\n      };\n  \n      final Similarity oldSim = searcher.getSimilarity();\n      Scorer spanScorer;\n      try {\n        searcher.setSimilarity(sim);\n        SpanNearQuery snq = new SpanNearQuery(\n                                new SpanQuery[] {\n                                  makeSpanTermQuery(\"t1\"),\n                                  makeSpanTermQuery(\"t2\") },\n                                slop,\n                                ordered);\n  \n        spanScorer = searcher.createNormalizedWeight(snq).scorer(ctx, true, false, ctx.reader().getLiveDocs());\n      } finally {\n        searcher.setSimilarity(oldSim);\n      }\n      if (i == subIndex) {\n        assertTrue(\"first doc\", spanScorer.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n        assertEquals(\"first doc number\", spanScorer.docID() + ctx.docBase, 11);\n        float score = spanScorer.score();\n        assertTrue(\"first doc score should be zero, \" + score, score == 0.0f);\n      }  else {\n        assertTrue(\"no second doc\", spanScorer.nextDoc() == DocIdSetIterator.NO_MORE_DOCS);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["781239fc84d36be12b84e4d3e2618f5f07a182e3"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"acf00221f44c5f08ccea014f2492b53af15ecd66","date":1394568293,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpans#testSpanScorerZeroSloppyFreq().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpans#testSpanScorerZeroSloppyFreq().mjava","sourceNew":"  public void testSpanScorerZeroSloppyFreq() throws Exception {\n    boolean ordered = true;\n    int slop = 1;\n    IndexReaderContext topReaderContext = searcher.getTopReaderContext();\n    List<AtomicReaderContext> leaves = topReaderContext.leaves();\n    int subIndex = ReaderUtil.subIndex(11, leaves);\n    for (int i = 0, c = leaves.size(); i < c; i++) {\n      final AtomicReaderContext ctx = leaves.get(i);\n     \n      final Similarity sim = new DefaultSimilarity() {\n        @Override\n        public float sloppyFreq(int distance) {\n          return 0.0f;\n        }\n      };\n  \n      final Similarity oldSim = searcher.getSimilarity();\n      Scorer spanScorer;\n      try {\n        searcher.setSimilarity(sim);\n        SpanNearQuery snq = new SpanNearQuery(\n                                new SpanQuery[] {\n                                  makeSpanTermQuery(\"t1\"),\n                                  makeSpanTermQuery(\"t2\") },\n                                slop,\n                                ordered);\n  \n        spanScorer = searcher.createNormalizedWeight(snq).scorer(ctx, ctx.reader().getLiveDocs());\n      } finally {\n        searcher.setSimilarity(oldSim);\n      }\n      if (i == subIndex) {\n        assertTrue(\"first doc\", spanScorer.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n        assertEquals(\"first doc number\", spanScorer.docID() + ctx.docBase, 11);\n        float score = spanScorer.score();\n        assertTrue(\"first doc score should be zero, \" + score, score == 0.0f);\n      }  else {\n        assertTrue(\"no second doc\", spanScorer.nextDoc() == DocIdSetIterator.NO_MORE_DOCS);\n      }\n    }\n  }\n\n","sourceOld":"  public void testSpanScorerZeroSloppyFreq() throws Exception {\n    boolean ordered = true;\n    int slop = 1;\n    IndexReaderContext topReaderContext = searcher.getTopReaderContext();\n    List<AtomicReaderContext> leaves = topReaderContext.leaves();\n    int subIndex = ReaderUtil.subIndex(11, leaves);\n    for (int i = 0, c = leaves.size(); i < c; i++) {\n      final AtomicReaderContext ctx = leaves.get(i);\n     \n      final Similarity sim = new DefaultSimilarity() {\n        @Override\n        public float sloppyFreq(int distance) {\n          return 0.0f;\n        }\n      };\n  \n      final Similarity oldSim = searcher.getSimilarity();\n      Scorer spanScorer;\n      try {\n        searcher.setSimilarity(sim);\n        SpanNearQuery snq = new SpanNearQuery(\n                                new SpanQuery[] {\n                                  makeSpanTermQuery(\"t1\"),\n                                  makeSpanTermQuery(\"t2\") },\n                                slop,\n                                ordered);\n  \n        spanScorer = searcher.createNormalizedWeight(snq).scorer(ctx, true, false, ctx.reader().getLiveDocs());\n      } finally {\n        searcher.setSimilarity(oldSim);\n      }\n      if (i == subIndex) {\n        assertTrue(\"first doc\", spanScorer.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n        assertEquals(\"first doc number\", spanScorer.docID() + ctx.docBase, 11);\n        float score = spanScorer.score();\n        assertTrue(\"first doc score should be zero, \" + score, score == 0.0f);\n      }  else {\n        assertTrue(\"no second doc\", spanScorer.nextDoc() == DocIdSetIterator.NO_MORE_DOCS);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c9fb5f46e264daf5ba3860defe623a89d202dd87","date":1411516315,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpans#testSpanScorerZeroSloppyFreq().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpans#testSpanScorerZeroSloppyFreq().mjava","sourceNew":"  public void testSpanScorerZeroSloppyFreq() throws Exception {\n    boolean ordered = true;\n    int slop = 1;\n    IndexReaderContext topReaderContext = searcher.getTopReaderContext();\n    List<LeafReaderContext> leaves = topReaderContext.leaves();\n    int subIndex = ReaderUtil.subIndex(11, leaves);\n    for (int i = 0, c = leaves.size(); i < c; i++) {\n      final LeafReaderContext ctx = leaves.get(i);\n     \n      final Similarity sim = new DefaultSimilarity() {\n        @Override\n        public float sloppyFreq(int distance) {\n          return 0.0f;\n        }\n      };\n  \n      final Similarity oldSim = searcher.getSimilarity();\n      Scorer spanScorer;\n      try {\n        searcher.setSimilarity(sim);\n        SpanNearQuery snq = new SpanNearQuery(\n                                new SpanQuery[] {\n                                  makeSpanTermQuery(\"t1\"),\n                                  makeSpanTermQuery(\"t2\") },\n                                slop,\n                                ordered);\n  \n        spanScorer = searcher.createNormalizedWeight(snq).scorer(ctx, ctx.reader().getLiveDocs());\n      } finally {\n        searcher.setSimilarity(oldSim);\n      }\n      if (i == subIndex) {\n        assertTrue(\"first doc\", spanScorer.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n        assertEquals(\"first doc number\", spanScorer.docID() + ctx.docBase, 11);\n        float score = spanScorer.score();\n        assertTrue(\"first doc score should be zero, \" + score, score == 0.0f);\n      }  else {\n        assertTrue(\"no second doc\", spanScorer.nextDoc() == DocIdSetIterator.NO_MORE_DOCS);\n      }\n    }\n  }\n\n","sourceOld":"  public void testSpanScorerZeroSloppyFreq() throws Exception {\n    boolean ordered = true;\n    int slop = 1;\n    IndexReaderContext topReaderContext = searcher.getTopReaderContext();\n    List<AtomicReaderContext> leaves = topReaderContext.leaves();\n    int subIndex = ReaderUtil.subIndex(11, leaves);\n    for (int i = 0, c = leaves.size(); i < c; i++) {\n      final AtomicReaderContext ctx = leaves.get(i);\n     \n      final Similarity sim = new DefaultSimilarity() {\n        @Override\n        public float sloppyFreq(int distance) {\n          return 0.0f;\n        }\n      };\n  \n      final Similarity oldSim = searcher.getSimilarity();\n      Scorer spanScorer;\n      try {\n        searcher.setSimilarity(sim);\n        SpanNearQuery snq = new SpanNearQuery(\n                                new SpanQuery[] {\n                                  makeSpanTermQuery(\"t1\"),\n                                  makeSpanTermQuery(\"t2\") },\n                                slop,\n                                ordered);\n  \n        spanScorer = searcher.createNormalizedWeight(snq).scorer(ctx, ctx.reader().getLiveDocs());\n      } finally {\n        searcher.setSimilarity(oldSim);\n      }\n      if (i == subIndex) {\n        assertTrue(\"first doc\", spanScorer.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n        assertEquals(\"first doc number\", spanScorer.docID() + ctx.docBase, 11);\n        float score = spanScorer.score();\n        assertTrue(\"first doc score should be zero, \" + score, score == 0.0f);\n      }  else {\n        assertTrue(\"no second doc\", spanScorer.nextDoc() == DocIdSetIterator.NO_MORE_DOCS);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"781239fc84d36be12b84e4d3e2618f5f07a182e3","date":1423139668,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpans#testSpanScorerZeroSloppyFreq().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpans#testSpanScorerZeroSloppyFreq().mjava","sourceNew":"  public void testSpanScorerZeroSloppyFreq() throws Exception {\n    boolean ordered = true;\n    int slop = 1;\n    IndexReaderContext topReaderContext = searcher.getTopReaderContext();\n    List<LeafReaderContext> leaves = topReaderContext.leaves();\n    int subIndex = ReaderUtil.subIndex(11, leaves);\n    for (int i = 0, c = leaves.size(); i < c; i++) {\n      final LeafReaderContext ctx = leaves.get(i);\n     \n      final Similarity sim = new DefaultSimilarity() {\n        @Override\n        public float sloppyFreq(int distance) {\n          return 0.0f;\n        }\n      };\n  \n      final Similarity oldSim = searcher.getSimilarity();\n      Scorer spanScorer;\n      try {\n        searcher.setSimilarity(sim);\n        SpanNearQuery snq = new SpanNearQuery(\n                                new SpanQuery[] {\n                                  makeSpanTermQuery(\"t1\"),\n                                  makeSpanTermQuery(\"t2\") },\n                                slop,\n                                ordered);\n  \n        spanScorer = searcher.createNormalizedWeight(snq).scorer(ctx, ctx.reader().getLiveDocs(), true);\n      } finally {\n        searcher.setSimilarity(oldSim);\n      }\n      if (i == subIndex) {\n        assertTrue(\"first doc\", spanScorer.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n        assertEquals(\"first doc number\", spanScorer.docID() + ctx.docBase, 11);\n        float score = spanScorer.score();\n        assertTrue(\"first doc score should be zero, \" + score, score == 0.0f);\n      }  else {\n        assertTrue(\"no second doc\", spanScorer.nextDoc() == DocIdSetIterator.NO_MORE_DOCS);\n      }\n    }\n  }\n\n","sourceOld":"  public void testSpanScorerZeroSloppyFreq() throws Exception {\n    boolean ordered = true;\n    int slop = 1;\n    IndexReaderContext topReaderContext = searcher.getTopReaderContext();\n    List<LeafReaderContext> leaves = topReaderContext.leaves();\n    int subIndex = ReaderUtil.subIndex(11, leaves);\n    for (int i = 0, c = leaves.size(); i < c; i++) {\n      final LeafReaderContext ctx = leaves.get(i);\n     \n      final Similarity sim = new DefaultSimilarity() {\n        @Override\n        public float sloppyFreq(int distance) {\n          return 0.0f;\n        }\n      };\n  \n      final Similarity oldSim = searcher.getSimilarity();\n      Scorer spanScorer;\n      try {\n        searcher.setSimilarity(sim);\n        SpanNearQuery snq = new SpanNearQuery(\n                                new SpanQuery[] {\n                                  makeSpanTermQuery(\"t1\"),\n                                  makeSpanTermQuery(\"t2\") },\n                                slop,\n                                ordered);\n  \n        spanScorer = searcher.createNormalizedWeight(snq).scorer(ctx, ctx.reader().getLiveDocs());\n      } finally {\n        searcher.setSimilarity(oldSim);\n      }\n      if (i == subIndex) {\n        assertTrue(\"first doc\", spanScorer.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n        assertEquals(\"first doc number\", spanScorer.docID() + ctx.docBase, 11);\n        float score = spanScorer.score();\n        assertTrue(\"first doc score should be zero, \" + score, score == 0.0f);\n      }  else {\n        assertTrue(\"no second doc\", spanScorer.nextDoc() == DocIdSetIterator.NO_MORE_DOCS);\n      }\n    }\n  }\n\n","bugFix":["2e18c86f811939bfa8cd24046c96ed026f2e9b34"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fb17639909a369c1e64866842e5c213440acc17e","date":1423238093,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpans#testSpanScorerZeroSloppyFreq().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpans#testSpanScorerZeroSloppyFreq().mjava","sourceNew":"  public void testSpanScorerZeroSloppyFreq() throws Exception {\n    boolean ordered = true;\n    int slop = 1;\n    IndexReaderContext topReaderContext = searcher.getTopReaderContext();\n    List<LeafReaderContext> leaves = topReaderContext.leaves();\n    int subIndex = ReaderUtil.subIndex(11, leaves);\n    for (int i = 0, c = leaves.size(); i < c; i++) {\n      final LeafReaderContext ctx = leaves.get(i);\n     \n      final Similarity sim = new DefaultSimilarity() {\n        @Override\n        public float sloppyFreq(int distance) {\n          return 0.0f;\n        }\n      };\n  \n      final Similarity oldSim = searcher.getSimilarity();\n      Scorer spanScorer;\n      try {\n        searcher.setSimilarity(sim);\n        SpanNearQuery snq = new SpanNearQuery(\n                                new SpanQuery[] {\n                                  makeSpanTermQuery(\"t1\"),\n                                  makeSpanTermQuery(\"t2\") },\n                                slop,\n                                ordered);\n  \n        spanScorer = searcher.createNormalizedWeight(snq, true).scorer(ctx, ctx.reader().getLiveDocs());\n      } finally {\n        searcher.setSimilarity(oldSim);\n      }\n      if (i == subIndex) {\n        assertTrue(\"first doc\", spanScorer.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n        assertEquals(\"first doc number\", spanScorer.docID() + ctx.docBase, 11);\n        float score = spanScorer.score();\n        assertTrue(\"first doc score should be zero, \" + score, score == 0.0f);\n      }  else {\n        assertTrue(\"no second doc\", spanScorer.nextDoc() == DocIdSetIterator.NO_MORE_DOCS);\n      }\n    }\n  }\n\n","sourceOld":"  public void testSpanScorerZeroSloppyFreq() throws Exception {\n    boolean ordered = true;\n    int slop = 1;\n    IndexReaderContext topReaderContext = searcher.getTopReaderContext();\n    List<LeafReaderContext> leaves = topReaderContext.leaves();\n    int subIndex = ReaderUtil.subIndex(11, leaves);\n    for (int i = 0, c = leaves.size(); i < c; i++) {\n      final LeafReaderContext ctx = leaves.get(i);\n     \n      final Similarity sim = new DefaultSimilarity() {\n        @Override\n        public float sloppyFreq(int distance) {\n          return 0.0f;\n        }\n      };\n  \n      final Similarity oldSim = searcher.getSimilarity();\n      Scorer spanScorer;\n      try {\n        searcher.setSimilarity(sim);\n        SpanNearQuery snq = new SpanNearQuery(\n                                new SpanQuery[] {\n                                  makeSpanTermQuery(\"t1\"),\n                                  makeSpanTermQuery(\"t2\") },\n                                slop,\n                                ordered);\n  \n        spanScorer = searcher.createNormalizedWeight(snq).scorer(ctx, ctx.reader().getLiveDocs(), true);\n      } finally {\n        searcher.setSimilarity(oldSim);\n      }\n      if (i == subIndex) {\n        assertTrue(\"first doc\", spanScorer.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n        assertEquals(\"first doc number\", spanScorer.docID() + ctx.docBase, 11);\n        float score = spanScorer.score();\n        assertTrue(\"first doc score should be zero, \" + score, score == 0.0f);\n      }  else {\n        assertTrue(\"no second doc\", spanScorer.nextDoc() == DocIdSetIterator.NO_MORE_DOCS);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"954e59be3da8dc1b046646ad7af4b466852009d3","date":1423482367,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpans#testSpanScorerZeroSloppyFreq().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpans#testSpanScorerZeroSloppyFreq().mjava","sourceNew":"  public void testSpanScorerZeroSloppyFreq() throws Exception {\n    boolean ordered = true;\n    int slop = 1;\n    IndexReaderContext topReaderContext = searcher.getTopReaderContext();\n    List<LeafReaderContext> leaves = topReaderContext.leaves();\n    int subIndex = ReaderUtil.subIndex(11, leaves);\n    for (int i = 0, c = leaves.size(); i < c; i++) {\n      final LeafReaderContext ctx = leaves.get(i);\n     \n      final Similarity sim = new DefaultSimilarity() {\n        @Override\n        public float sloppyFreq(int distance) {\n          return 0.0f;\n        }\n      };\n  \n      final Similarity oldSim = searcher.getSimilarity();\n      Scorer spanScorer;\n      try {\n        searcher.setSimilarity(sim);\n        SpanNearQuery snq = new SpanNearQuery(\n                                new SpanQuery[] {\n                                  makeSpanTermQuery(\"t1\"),\n                                  makeSpanTermQuery(\"t2\") },\n                                slop,\n                                ordered);\n  \n        spanScorer = searcher.createNormalizedWeight(snq, PostingsEnum.FLAG_FREQS).scorer(ctx, ctx.reader().getLiveDocs());\n      } finally {\n        searcher.setSimilarity(oldSim);\n      }\n      if (i == subIndex) {\n        assertTrue(\"first doc\", spanScorer.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n        assertEquals(\"first doc number\", spanScorer.docID() + ctx.docBase, 11);\n        float score = spanScorer.score();\n        assertTrue(\"first doc score should be zero, \" + score, score == 0.0f);\n      }  else {\n        assertTrue(\"no second doc\", spanScorer.nextDoc() == DocIdSetIterator.NO_MORE_DOCS);\n      }\n    }\n  }\n\n","sourceOld":"  public void testSpanScorerZeroSloppyFreq() throws Exception {\n    boolean ordered = true;\n    int slop = 1;\n    IndexReaderContext topReaderContext = searcher.getTopReaderContext();\n    List<LeafReaderContext> leaves = topReaderContext.leaves();\n    int subIndex = ReaderUtil.subIndex(11, leaves);\n    for (int i = 0, c = leaves.size(); i < c; i++) {\n      final LeafReaderContext ctx = leaves.get(i);\n     \n      final Similarity sim = new DefaultSimilarity() {\n        @Override\n        public float sloppyFreq(int distance) {\n          return 0.0f;\n        }\n      };\n  \n      final Similarity oldSim = searcher.getSimilarity();\n      Scorer spanScorer;\n      try {\n        searcher.setSimilarity(sim);\n        SpanNearQuery snq = new SpanNearQuery(\n                                new SpanQuery[] {\n                                  makeSpanTermQuery(\"t1\"),\n                                  makeSpanTermQuery(\"t2\") },\n                                slop,\n                                ordered);\n  \n        spanScorer = searcher.createNormalizedWeight(snq, true).scorer(ctx, ctx.reader().getLiveDocs());\n      } finally {\n        searcher.setSimilarity(oldSim);\n      }\n      if (i == subIndex) {\n        assertTrue(\"first doc\", spanScorer.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n        assertEquals(\"first doc number\", spanScorer.docID() + ctx.docBase, 11);\n        float score = spanScorer.score();\n        assertTrue(\"first doc score should be zero, \" + score, score == 0.0f);\n      }  else {\n        assertTrue(\"no second doc\", spanScorer.nextDoc() == DocIdSetIterator.NO_MORE_DOCS);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6a47d642ab24da1a811adce4bda9cc52c520ca13","date":1423483323,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpans#testSpanScorerZeroSloppyFreq().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpans#testSpanScorerZeroSloppyFreq().mjava","sourceNew":"  public void testSpanScorerZeroSloppyFreq() throws Exception {\n    boolean ordered = true;\n    int slop = 1;\n    IndexReaderContext topReaderContext = searcher.getTopReaderContext();\n    List<LeafReaderContext> leaves = topReaderContext.leaves();\n    int subIndex = ReaderUtil.subIndex(11, leaves);\n    for (int i = 0, c = leaves.size(); i < c; i++) {\n      final LeafReaderContext ctx = leaves.get(i);\n     \n      final Similarity sim = new DefaultSimilarity() {\n        @Override\n        public float sloppyFreq(int distance) {\n          return 0.0f;\n        }\n      };\n  \n      final Similarity oldSim = searcher.getSimilarity();\n      Scorer spanScorer;\n      try {\n        searcher.setSimilarity(sim);\n        SpanNearQuery snq = new SpanNearQuery(\n                                new SpanQuery[] {\n                                  makeSpanTermQuery(\"t1\"),\n                                  makeSpanTermQuery(\"t2\") },\n                                slop,\n                                ordered);\n  \n        spanScorer = searcher.createNormalizedWeight(snq, true).scorer(ctx, ctx.reader().getLiveDocs());\n      } finally {\n        searcher.setSimilarity(oldSim);\n      }\n      if (i == subIndex) {\n        assertTrue(\"first doc\", spanScorer.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n        assertEquals(\"first doc number\", spanScorer.docID() + ctx.docBase, 11);\n        float score = spanScorer.score();\n        assertTrue(\"first doc score should be zero, \" + score, score == 0.0f);\n      }  else {\n        assertTrue(\"no second doc\", spanScorer.nextDoc() == DocIdSetIterator.NO_MORE_DOCS);\n      }\n    }\n  }\n\n","sourceOld":"  public void testSpanScorerZeroSloppyFreq() throws Exception {\n    boolean ordered = true;\n    int slop = 1;\n    IndexReaderContext topReaderContext = searcher.getTopReaderContext();\n    List<LeafReaderContext> leaves = topReaderContext.leaves();\n    int subIndex = ReaderUtil.subIndex(11, leaves);\n    for (int i = 0, c = leaves.size(); i < c; i++) {\n      final LeafReaderContext ctx = leaves.get(i);\n     \n      final Similarity sim = new DefaultSimilarity() {\n        @Override\n        public float sloppyFreq(int distance) {\n          return 0.0f;\n        }\n      };\n  \n      final Similarity oldSim = searcher.getSimilarity();\n      Scorer spanScorer;\n      try {\n        searcher.setSimilarity(sim);\n        SpanNearQuery snq = new SpanNearQuery(\n                                new SpanQuery[] {\n                                  makeSpanTermQuery(\"t1\"),\n                                  makeSpanTermQuery(\"t2\") },\n                                slop,\n                                ordered);\n  \n        spanScorer = searcher.createNormalizedWeight(snq, PostingsEnum.FLAG_FREQS).scorer(ctx, ctx.reader().getLiveDocs());\n      } finally {\n        searcher.setSimilarity(oldSim);\n      }\n      if (i == subIndex) {\n        assertTrue(\"first doc\", spanScorer.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n        assertEquals(\"first doc number\", spanScorer.docID() + ctx.docBase, 11);\n        float score = spanScorer.score();\n        assertTrue(\"first doc score should be zero, \" + score, score == 0.0f);\n      }  else {\n        assertTrue(\"no second doc\", spanScorer.nextDoc() == DocIdSetIterator.NO_MORE_DOCS);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b9ac0388844fde04af210a292c96559b0f849850","date":1427792528,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpans#testSpanScorerZeroSloppyFreq().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpans#testSpanScorerZeroSloppyFreq().mjava","sourceNew":"  public void testSpanScorerZeroSloppyFreq() throws Exception {\n    boolean ordered = true;\n    int slop = 1;\n    IndexReaderContext topReaderContext = searcher.getTopReaderContext();\n    List<LeafReaderContext> leaves = topReaderContext.leaves();\n    int subIndex = ReaderUtil.subIndex(11, leaves);\n    for (int i = 0, c = leaves.size(); i < c; i++) {\n      final LeafReaderContext ctx = leaves.get(i);\n     \n      final Similarity sim = new DefaultSimilarity() {\n        @Override\n        public float sloppyFreq(int distance) {\n          return 0.0f;\n        }\n      };\n  \n      final Similarity oldSim = searcher.getSimilarity();\n      Scorer spanScorer;\n      try {\n        searcher.setSimilarity(sim);\n        SpanNearQuery snq = new SpanNearQuery(\n                                new SpanQuery[] {\n                                  makeSpanTermQuery(\"t1\"),\n                                  makeSpanTermQuery(\"t2\") },\n                                slop,\n                                ordered);\n  \n        spanScorer = searcher.createNormalizedWeight(snq, true).scorer(ctx, ctx.reader().getLiveDocs());\n      } finally {\n        searcher.setSimilarity(oldSim);\n      }\n      if (i == subIndex) {\n        assertTrue(\"first doc\", spanScorer.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n        assertEquals(\"first doc number\", spanScorer.docID() + ctx.docBase, 11);\n        float score = spanScorer.score();\n        assertTrue(\"first doc score should be zero, \" + score, score == 0.0f);\n      } else {\n        assertTrue(\"no second doc\", spanScorer == null || spanScorer.nextDoc() == DocIdSetIterator.NO_MORE_DOCS);\n      }\n    }\n  }\n\n","sourceOld":"  public void testSpanScorerZeroSloppyFreq() throws Exception {\n    boolean ordered = true;\n    int slop = 1;\n    IndexReaderContext topReaderContext = searcher.getTopReaderContext();\n    List<LeafReaderContext> leaves = topReaderContext.leaves();\n    int subIndex = ReaderUtil.subIndex(11, leaves);\n    for (int i = 0, c = leaves.size(); i < c; i++) {\n      final LeafReaderContext ctx = leaves.get(i);\n     \n      final Similarity sim = new DefaultSimilarity() {\n        @Override\n        public float sloppyFreq(int distance) {\n          return 0.0f;\n        }\n      };\n  \n      final Similarity oldSim = searcher.getSimilarity();\n      Scorer spanScorer;\n      try {\n        searcher.setSimilarity(sim);\n        SpanNearQuery snq = new SpanNearQuery(\n                                new SpanQuery[] {\n                                  makeSpanTermQuery(\"t1\"),\n                                  makeSpanTermQuery(\"t2\") },\n                                slop,\n                                ordered);\n  \n        spanScorer = searcher.createNormalizedWeight(snq, true).scorer(ctx, ctx.reader().getLiveDocs());\n      } finally {\n        searcher.setSimilarity(oldSim);\n      }\n      if (i == subIndex) {\n        assertTrue(\"first doc\", spanScorer.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n        assertEquals(\"first doc number\", spanScorer.docID() + ctx.docBase, 11);\n        float score = spanScorer.score();\n        assertTrue(\"first doc score should be zero, \" + score, score == 0.0f);\n      }  else {\n        assertTrue(\"no second doc\", spanScorer.nextDoc() == DocIdSetIterator.NO_MORE_DOCS);\n      }\n    }\n  }\n\n","bugFix":["c8323d210478d76a02372693d254b69aac614689"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fab172655716b96f7e42376116235017a922de3a","date":1427850611,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpans#testSpanScorerZeroSloppyFreq().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpans#testSpanScorerZeroSloppyFreq().mjava","sourceNew":"  public void testSpanScorerZeroSloppyFreq() throws Exception {\n    boolean ordered = true;\n    int slop = 1;\n    IndexReaderContext topReaderContext = searcher.getTopReaderContext();\n    List<LeafReaderContext> leaves = topReaderContext.leaves();\n    int subIndex = ReaderUtil.subIndex(11, leaves);\n    for (int i = 0, c = leaves.size(); i < c; i++) {\n      final LeafReaderContext ctx = leaves.get(i);\n     \n      final Similarity sim = new DefaultSimilarity() {\n        @Override\n        public float sloppyFreq(int distance) {\n          return 0.0f;\n        }\n      };\n  \n      final Similarity oldSim = searcher.getSimilarity();\n      Scorer spanScorer;\n      try {\n        searcher.setSimilarity(sim);\n        SpanNearQuery snq = new SpanNearQuery(\n                                new SpanQuery[] {\n                                  makeSpanTermQuery(\"t1\"),\n                                  makeSpanTermQuery(\"t2\") },\n                                slop,\n                                ordered);\n  \n        spanScorer = searcher.createNormalizedWeight(snq, true).scorer(ctx, ctx.reader().getLiveDocs());\n      } finally {\n        searcher.setSimilarity(oldSim);\n      }\n      if (i == subIndex) {\n        assertTrue(\"first doc\", spanScorer.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n        assertEquals(\"first doc number\", spanScorer.docID() + ctx.docBase, 11);\n        float score = spanScorer.score();\n        assertTrue(\"first doc score should be zero, \" + score, score == 0.0f);\n      } else {\n        assertTrue(\"no second doc\", spanScorer == null || spanScorer.nextDoc() == DocIdSetIterator.NO_MORE_DOCS);\n      }\n    }\n  }\n\n","sourceOld":"  public void testSpanScorerZeroSloppyFreq() throws Exception {\n    boolean ordered = true;\n    int slop = 1;\n    IndexReaderContext topReaderContext = searcher.getTopReaderContext();\n    List<LeafReaderContext> leaves = topReaderContext.leaves();\n    int subIndex = ReaderUtil.subIndex(11, leaves);\n    for (int i = 0, c = leaves.size(); i < c; i++) {\n      final LeafReaderContext ctx = leaves.get(i);\n     \n      final Similarity sim = new DefaultSimilarity() {\n        @Override\n        public float sloppyFreq(int distance) {\n          return 0.0f;\n        }\n      };\n  \n      final Similarity oldSim = searcher.getSimilarity();\n      Scorer spanScorer;\n      try {\n        searcher.setSimilarity(sim);\n        SpanNearQuery snq = new SpanNearQuery(\n                                new SpanQuery[] {\n                                  makeSpanTermQuery(\"t1\"),\n                                  makeSpanTermQuery(\"t2\") },\n                                slop,\n                                ordered);\n  \n        spanScorer = searcher.createNormalizedWeight(snq, true).scorer(ctx, ctx.reader().getLiveDocs());\n      } finally {\n        searcher.setSimilarity(oldSim);\n      }\n      if (i == subIndex) {\n        assertTrue(\"first doc\", spanScorer.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n        assertEquals(\"first doc number\", spanScorer.docID() + ctx.docBase, 11);\n        float score = spanScorer.score();\n        assertTrue(\"first doc score should be zero, \" + score, score == 0.0f);\n      }  else {\n        assertTrue(\"no second doc\", spanScorer.nextDoc() == DocIdSetIterator.NO_MORE_DOCS);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c4f600f812447b5512daeaf8e5c9df5dbcc4a254","date":1428874774,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpans#testSpanScorerZeroSloppyFreq().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpans#testSpanScorerZeroSloppyFreq().mjava","sourceNew":"  public void testSpanScorerZeroSloppyFreq() throws Exception {\n    IndexReaderContext topReaderContext = searcher.getTopReaderContext();\n    List<LeafReaderContext> leaves = topReaderContext.leaves();\n    int subIndex = ReaderUtil.subIndex(11, leaves);\n    for (int i = 0, c = leaves.size(); i < c; i++) {\n      final LeafReaderContext ctx = leaves.get(i);\n     \n      final Similarity sim = new DefaultSimilarity() {\n        @Override\n        public float sloppyFreq(int distance) {\n          return 0.0f;\n        }\n      };\n  \n      final Similarity oldSim = searcher.getSimilarity();\n      Scorer spanScorer;\n      try {\n        searcher.setSimilarity(sim);\n        SpanQuery snq = spanNearOrderedQuery(field, 1, \"t1\", \"t2\");\n        spanScorer = searcher.createNormalizedWeight(snq, true).scorer(ctx, ctx.reader().getLiveDocs());\n      } finally {\n        searcher.setSimilarity(oldSim);\n      }\n      if (i == subIndex) {\n        assertTrue(\"first doc\", spanScorer.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n        assertEquals(\"first doc number\", spanScorer.docID() + ctx.docBase, 11);\n        float score = spanScorer.score();\n        assertTrue(\"first doc score should be zero, \" + score, score == 0.0f);\n      } else {\n        assertTrue(\"no second doc\", spanScorer == null || spanScorer.nextDoc() == DocIdSetIterator.NO_MORE_DOCS);\n      }\n    }\n  }\n\n","sourceOld":"  public void testSpanScorerZeroSloppyFreq() throws Exception {\n    boolean ordered = true;\n    int slop = 1;\n    IndexReaderContext topReaderContext = searcher.getTopReaderContext();\n    List<LeafReaderContext> leaves = topReaderContext.leaves();\n    int subIndex = ReaderUtil.subIndex(11, leaves);\n    for (int i = 0, c = leaves.size(); i < c; i++) {\n      final LeafReaderContext ctx = leaves.get(i);\n     \n      final Similarity sim = new DefaultSimilarity() {\n        @Override\n        public float sloppyFreq(int distance) {\n          return 0.0f;\n        }\n      };\n  \n      final Similarity oldSim = searcher.getSimilarity();\n      Scorer spanScorer;\n      try {\n        searcher.setSimilarity(sim);\n        SpanNearQuery snq = new SpanNearQuery(\n                                new SpanQuery[] {\n                                  makeSpanTermQuery(\"t1\"),\n                                  makeSpanTermQuery(\"t2\") },\n                                slop,\n                                ordered);\n  \n        spanScorer = searcher.createNormalizedWeight(snq, true).scorer(ctx, ctx.reader().getLiveDocs());\n      } finally {\n        searcher.setSimilarity(oldSim);\n      }\n      if (i == subIndex) {\n        assertTrue(\"first doc\", spanScorer.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n        assertEquals(\"first doc number\", spanScorer.docID() + ctx.docBase, 11);\n        float score = spanScorer.score();\n        assertTrue(\"first doc score should be zero, \" + score, score == 0.0f);\n      } else {\n        assertTrue(\"no second doc\", spanScorer == null || spanScorer.nextDoc() == DocIdSetIterator.NO_MORE_DOCS);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"485545da3b4429d6f138b4baac573a97820ee93b","date":1433876557,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpans#testSpanScorerZeroSloppyFreq().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpans#testSpanScorerZeroSloppyFreq().mjava","sourceNew":"  public void testSpanScorerZeroSloppyFreq() throws Exception {\n    IndexReaderContext topReaderContext = searcher.getTopReaderContext();\n    List<LeafReaderContext> leaves = topReaderContext.leaves();\n    int subIndex = ReaderUtil.subIndex(11, leaves);\n    for (int i = 0, c = leaves.size(); i < c; i++) {\n      final LeafReaderContext ctx = leaves.get(i);\n     \n      final Similarity sim = new DefaultSimilarity() {\n        @Override\n        public float sloppyFreq(int distance) {\n          return 0.0f;\n        }\n      };\n  \n      final Similarity oldSim = searcher.getSimilarity(true);\n      Scorer spanScorer;\n      try {\n        searcher.setSimilarity(sim);\n        SpanQuery snq = spanNearOrderedQuery(field, 1, \"t1\", \"t2\");\n        spanScorer = searcher.createNormalizedWeight(snq, true).scorer(ctx, ctx.reader().getLiveDocs());\n      } finally {\n        searcher.setSimilarity(oldSim);\n      }\n      if (i == subIndex) {\n        assertTrue(\"first doc\", spanScorer.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n        assertEquals(\"first doc number\", spanScorer.docID() + ctx.docBase, 11);\n        float score = spanScorer.score();\n        assertTrue(\"first doc score should be zero, \" + score, score == 0.0f);\n      } else {\n        assertTrue(\"no second doc\", spanScorer == null || spanScorer.nextDoc() == DocIdSetIterator.NO_MORE_DOCS);\n      }\n    }\n  }\n\n","sourceOld":"  public void testSpanScorerZeroSloppyFreq() throws Exception {\n    IndexReaderContext topReaderContext = searcher.getTopReaderContext();\n    List<LeafReaderContext> leaves = topReaderContext.leaves();\n    int subIndex = ReaderUtil.subIndex(11, leaves);\n    for (int i = 0, c = leaves.size(); i < c; i++) {\n      final LeafReaderContext ctx = leaves.get(i);\n     \n      final Similarity sim = new DefaultSimilarity() {\n        @Override\n        public float sloppyFreq(int distance) {\n          return 0.0f;\n        }\n      };\n  \n      final Similarity oldSim = searcher.getSimilarity();\n      Scorer spanScorer;\n      try {\n        searcher.setSimilarity(sim);\n        SpanQuery snq = spanNearOrderedQuery(field, 1, \"t1\", \"t2\");\n        spanScorer = searcher.createNormalizedWeight(snq, true).scorer(ctx, ctx.reader().getLiveDocs());\n      } finally {\n        searcher.setSimilarity(oldSim);\n      }\n      if (i == subIndex) {\n        assertTrue(\"first doc\", spanScorer.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n        assertEquals(\"first doc number\", spanScorer.docID() + ctx.docBase, 11);\n        float score = spanScorer.score();\n        assertTrue(\"first doc score should be zero, \" + score, score == 0.0f);\n      } else {\n        assertTrue(\"no second doc\", spanScorer == null || spanScorer.nextDoc() == DocIdSetIterator.NO_MORE_DOCS);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0f4464508ee83288c8c4585b533f9faaa93aa314","date":1435240759,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpans#testSpanScorerZeroSloppyFreq().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpans#testSpanScorerZeroSloppyFreq().mjava","sourceNew":"  public void testSpanScorerZeroSloppyFreq() throws Exception {\n    IndexReaderContext topReaderContext = searcher.getTopReaderContext();\n    List<LeafReaderContext> leaves = topReaderContext.leaves();\n    int subIndex = ReaderUtil.subIndex(11, leaves);\n    for (int i = 0, c = leaves.size(); i < c; i++) {\n      final LeafReaderContext ctx = leaves.get(i);\n     \n      final Similarity sim = new DefaultSimilarity() {\n        @Override\n        public float sloppyFreq(int distance) {\n          return 0.0f;\n        }\n      };\n  \n      final Similarity oldSim = searcher.getSimilarity(true);\n      Scorer spanScorer;\n      try {\n        searcher.setSimilarity(sim);\n        SpanQuery snq = spanNearOrderedQuery(field, 1, \"t1\", \"t2\");\n        spanScorer = searcher.createNormalizedWeight(snq, true).scorer(ctx);\n      } finally {\n        searcher.setSimilarity(oldSim);\n      }\n      if (i == subIndex) {\n        assertTrue(\"first doc\", spanScorer.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n        assertEquals(\"first doc number\", spanScorer.docID() + ctx.docBase, 11);\n        float score = spanScorer.score();\n        assertTrue(\"first doc score should be zero, \" + score, score == 0.0f);\n      } else {\n        assertTrue(\"no second doc\", spanScorer == null || spanScorer.nextDoc() == DocIdSetIterator.NO_MORE_DOCS);\n      }\n    }\n  }\n\n","sourceOld":"  public void testSpanScorerZeroSloppyFreq() throws Exception {\n    IndexReaderContext topReaderContext = searcher.getTopReaderContext();\n    List<LeafReaderContext> leaves = topReaderContext.leaves();\n    int subIndex = ReaderUtil.subIndex(11, leaves);\n    for (int i = 0, c = leaves.size(); i < c; i++) {\n      final LeafReaderContext ctx = leaves.get(i);\n     \n      final Similarity sim = new DefaultSimilarity() {\n        @Override\n        public float sloppyFreq(int distance) {\n          return 0.0f;\n        }\n      };\n  \n      final Similarity oldSim = searcher.getSimilarity(true);\n      Scorer spanScorer;\n      try {\n        searcher.setSimilarity(sim);\n        SpanQuery snq = spanNearOrderedQuery(field, 1, \"t1\", \"t2\");\n        spanScorer = searcher.createNormalizedWeight(snq, true).scorer(ctx, ctx.reader().getLiveDocs());\n      } finally {\n        searcher.setSimilarity(oldSim);\n      }\n      if (i == subIndex) {\n        assertTrue(\"first doc\", spanScorer.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n        assertEquals(\"first doc number\", spanScorer.docID() + ctx.docBase, 11);\n        float score = spanScorer.score();\n        assertTrue(\"first doc score should be zero, \" + score, score == 0.0f);\n      } else {\n        assertTrue(\"no second doc\", spanScorer == null || spanScorer.nextDoc() == DocIdSetIterator.NO_MORE_DOCS);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"81d0720146de53dd3a4a023d2a3d1089d86d748d","date":1442268215,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpans#testSpanScorerZeroSloppyFreq().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpans#testSpanScorerZeroSloppyFreq().mjava","sourceNew":"  public void testSpanScorerZeroSloppyFreq() throws Exception {\n    IndexReaderContext topReaderContext = searcher.getTopReaderContext();\n    List<LeafReaderContext> leaves = topReaderContext.leaves();\n    int subIndex = ReaderUtil.subIndex(11, leaves);\n    for (int i = 0, c = leaves.size(); i < c; i++) {\n      final LeafReaderContext ctx = leaves.get(i);\n     \n      final Similarity sim = new ClassicSimilarity() {\n        @Override\n        public float sloppyFreq(int distance) {\n          return 0.0f;\n        }\n      };\n  \n      final Similarity oldSim = searcher.getSimilarity(true);\n      Scorer spanScorer;\n      try {\n        searcher.setSimilarity(sim);\n        SpanQuery snq = spanNearOrderedQuery(field, 1, \"t1\", \"t2\");\n        spanScorer = searcher.createNormalizedWeight(snq, true).scorer(ctx);\n      } finally {\n        searcher.setSimilarity(oldSim);\n      }\n      if (i == subIndex) {\n        assertTrue(\"first doc\", spanScorer.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n        assertEquals(\"first doc number\", spanScorer.docID() + ctx.docBase, 11);\n        float score = spanScorer.score();\n        assertTrue(\"first doc score should be zero, \" + score, score == 0.0f);\n      } else {\n        assertTrue(\"no second doc\", spanScorer == null || spanScorer.nextDoc() == DocIdSetIterator.NO_MORE_DOCS);\n      }\n    }\n  }\n\n","sourceOld":"  public void testSpanScorerZeroSloppyFreq() throws Exception {\n    IndexReaderContext topReaderContext = searcher.getTopReaderContext();\n    List<LeafReaderContext> leaves = topReaderContext.leaves();\n    int subIndex = ReaderUtil.subIndex(11, leaves);\n    for (int i = 0, c = leaves.size(); i < c; i++) {\n      final LeafReaderContext ctx = leaves.get(i);\n     \n      final Similarity sim = new DefaultSimilarity() {\n        @Override\n        public float sloppyFreq(int distance) {\n          return 0.0f;\n        }\n      };\n  \n      final Similarity oldSim = searcher.getSimilarity(true);\n      Scorer spanScorer;\n      try {\n        searcher.setSimilarity(sim);\n        SpanQuery snq = spanNearOrderedQuery(field, 1, \"t1\", \"t2\");\n        spanScorer = searcher.createNormalizedWeight(snq, true).scorer(ctx);\n      } finally {\n        searcher.setSimilarity(oldSim);\n      }\n      if (i == subIndex) {\n        assertTrue(\"first doc\", spanScorer.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n        assertEquals(\"first doc number\", spanScorer.docID() + ctx.docBase, 11);\n        float score = spanScorer.score();\n        assertTrue(\"first doc score should be zero, \" + score, score == 0.0f);\n      } else {\n        assertTrue(\"no second doc\", spanScorer == null || spanScorer.nextDoc() == DocIdSetIterator.NO_MORE_DOCS);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7dd748bb245633a8195281556bb0e68a6ea97d18","date":1449755030,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpans#testSpanScorerZeroSloppyFreq().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpans#testSpanScorerZeroSloppyFreq().mjava","sourceNew":"  public void testSpanScorerZeroSloppyFreq() throws Exception {\n    IndexReaderContext topReaderContext = searcher.getTopReaderContext();\n    List<LeafReaderContext> leaves = topReaderContext.leaves();\n    int subIndex = ReaderUtil.subIndex(11, leaves);\n    for (int i = 0, c = leaves.size(); i < c; i++) {\n      final LeafReaderContext ctx = leaves.get(i);\n     \n      final Similarity sim = new ClassicSimilarity() {\n        @Override\n        public float sloppyFreq(int distance) {\n          return 0.0f;\n        }\n      };\n  \n      final Similarity oldSim = searcher.getSimilarity(true);\n      Scorer spanScorer;\n      try {\n        searcher.setSimilarity(sim);\n        SpanQuery snq = spanNearOrderedQuery(field, 1, \"t1\", \"t2\");\n        spanScorer = searcher.createNormalizedWeight(snq, true).scorer(ctx);\n      } finally {\n        searcher.setSimilarity(oldSim);\n      }\n      if (i == subIndex) {\n        assertTrue(\"first doc\", spanScorer.iterator().nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n        assertEquals(\"first doc number\", spanScorer.docID() + ctx.docBase, 11);\n        float score = spanScorer.score();\n        assertTrue(\"first doc score should be zero, \" + score, score == 0.0f);\n      } else {\n        assertTrue(\"no second doc\", spanScorer == null || spanScorer.iterator().nextDoc() == DocIdSetIterator.NO_MORE_DOCS);\n      }\n    }\n  }\n\n","sourceOld":"  public void testSpanScorerZeroSloppyFreq() throws Exception {\n    IndexReaderContext topReaderContext = searcher.getTopReaderContext();\n    List<LeafReaderContext> leaves = topReaderContext.leaves();\n    int subIndex = ReaderUtil.subIndex(11, leaves);\n    for (int i = 0, c = leaves.size(); i < c; i++) {\n      final LeafReaderContext ctx = leaves.get(i);\n     \n      final Similarity sim = new ClassicSimilarity() {\n        @Override\n        public float sloppyFreq(int distance) {\n          return 0.0f;\n        }\n      };\n  \n      final Similarity oldSim = searcher.getSimilarity(true);\n      Scorer spanScorer;\n      try {\n        searcher.setSimilarity(sim);\n        SpanQuery snq = spanNearOrderedQuery(field, 1, \"t1\", \"t2\");\n        spanScorer = searcher.createNormalizedWeight(snq, true).scorer(ctx);\n      } finally {\n        searcher.setSimilarity(oldSim);\n      }\n      if (i == subIndex) {\n        assertTrue(\"first doc\", spanScorer.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n        assertEquals(\"first doc number\", spanScorer.docID() + ctx.docBase, 11);\n        float score = spanScorer.score();\n        assertTrue(\"first doc score should be zero, \" + score, score == 0.0f);\n      } else {\n        assertTrue(\"no second doc\", spanScorer == null || spanScorer.nextDoc() == DocIdSetIterator.NO_MORE_DOCS);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b9b82182bcb9110d24f7de32032113dbf31606c2","date":1510306998,"type":4,"author":"Alan Woodward","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/core/src/test/org/apache/lucene/search/spans/TestSpans#testSpanScorerZeroSloppyFreq().mjava","sourceNew":null,"sourceOld":"  public void testSpanScorerZeroSloppyFreq() throws Exception {\n    IndexReaderContext topReaderContext = searcher.getTopReaderContext();\n    List<LeafReaderContext> leaves = topReaderContext.leaves();\n    int subIndex = ReaderUtil.subIndex(11, leaves);\n    for (int i = 0, c = leaves.size(); i < c; i++) {\n      final LeafReaderContext ctx = leaves.get(i);\n     \n      final Similarity sim = new ClassicSimilarity() {\n        @Override\n        public float sloppyFreq(int distance) {\n          return 0.0f;\n        }\n      };\n  \n      final Similarity oldSim = searcher.getSimilarity(true);\n      Scorer spanScorer;\n      try {\n        searcher.setSimilarity(sim);\n        SpanQuery snq = spanNearOrderedQuery(field, 1, \"t1\", \"t2\");\n        spanScorer = searcher.createNormalizedWeight(snq, true).scorer(ctx);\n      } finally {\n        searcher.setSimilarity(oldSim);\n      }\n      if (i == subIndex) {\n        assertTrue(\"first doc\", spanScorer.iterator().nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n        assertEquals(\"first doc number\", spanScorer.docID() + ctx.docBase, 11);\n        float score = spanScorer.score();\n        assertTrue(\"first doc score should be zero, \" + score, score == 0.0f);\n      } else {\n        assertTrue(\"no second doc\", spanScorer == null || spanScorer.iterator().nextDoc() == DocIdSetIterator.NO_MORE_DOCS);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"2e18c86f811939bfa8cd24046c96ed026f2e9b34":["4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c"],"6a47d642ab24da1a811adce4bda9cc52c520ca13":["954e59be3da8dc1b046646ad7af4b466852009d3"],"fb17639909a369c1e64866842e5c213440acc17e":["781239fc84d36be12b84e4d3e2618f5f07a182e3"],"781239fc84d36be12b84e4d3e2618f5f07a182e3":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c":["0d4602ca2700dfd2f6159ad1499e5b6d1f3b92a8"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"485545da3b4429d6f138b4baac573a97820ee93b":["c4f600f812447b5512daeaf8e5c9df5dbcc4a254"],"0d4602ca2700dfd2f6159ad1499e5b6d1f3b92a8":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"81d0720146de53dd3a4a023d2a3d1089d86d748d":["0f4464508ee83288c8c4585b533f9faaa93aa314"],"954e59be3da8dc1b046646ad7af4b466852009d3":["fb17639909a369c1e64866842e5c213440acc17e"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["acf00221f44c5f08ccea014f2492b53af15ecd66"],"0f4464508ee83288c8c4585b533f9faaa93aa314":["485545da3b4429d6f138b4baac573a97820ee93b"],"b9ac0388844fde04af210a292c96559b0f849850":["6a47d642ab24da1a811adce4bda9cc52c520ca13"],"c4f600f812447b5512daeaf8e5c9df5dbcc4a254":["b9ac0388844fde04af210a292c96559b0f849850"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"7dd748bb245633a8195281556bb0e68a6ea97d18":["81d0720146de53dd3a4a023d2a3d1089d86d748d"],"acf00221f44c5f08ccea014f2492b53af15ecd66":["4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c","2e18c86f811939bfa8cd24046c96ed026f2e9b34"],"b9b82182bcb9110d24f7de32032113dbf31606c2":["7dd748bb245633a8195281556bb0e68a6ea97d18"],"fab172655716b96f7e42376116235017a922de3a":["6a47d642ab24da1a811adce4bda9cc52c520ca13","b9ac0388844fde04af210a292c96559b0f849850"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b9b82182bcb9110d24f7de32032113dbf31606c2"]},"commit2Childs":{"2e18c86f811939bfa8cd24046c96ed026f2e9b34":["acf00221f44c5f08ccea014f2492b53af15ecd66"],"6a47d642ab24da1a811adce4bda9cc52c520ca13":["b9ac0388844fde04af210a292c96559b0f849850","fab172655716b96f7e42376116235017a922de3a"],"fb17639909a369c1e64866842e5c213440acc17e":["954e59be3da8dc1b046646ad7af4b466852009d3"],"4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c":["2e18c86f811939bfa8cd24046c96ed026f2e9b34","acf00221f44c5f08ccea014f2492b53af15ecd66"],"781239fc84d36be12b84e4d3e2618f5f07a182e3":["fb17639909a369c1e64866842e5c213440acc17e"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["0d4602ca2700dfd2f6159ad1499e5b6d1f3b92a8"],"0d4602ca2700dfd2f6159ad1499e5b6d1f3b92a8":["4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c"],"485545da3b4429d6f138b4baac573a97820ee93b":["0f4464508ee83288c8c4585b533f9faaa93aa314"],"954e59be3da8dc1b046646ad7af4b466852009d3":["6a47d642ab24da1a811adce4bda9cc52c520ca13"],"81d0720146de53dd3a4a023d2a3d1089d86d748d":["7dd748bb245633a8195281556bb0e68a6ea97d18"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["781239fc84d36be12b84e4d3e2618f5f07a182e3"],"0f4464508ee83288c8c4585b533f9faaa93aa314":["81d0720146de53dd3a4a023d2a3d1089d86d748d"],"b9ac0388844fde04af210a292c96559b0f849850":["c4f600f812447b5512daeaf8e5c9df5dbcc4a254","fab172655716b96f7e42376116235017a922de3a"],"c4f600f812447b5512daeaf8e5c9df5dbcc4a254":["485545da3b4429d6f138b4baac573a97820ee93b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"acf00221f44c5f08ccea014f2492b53af15ecd66":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"7dd748bb245633a8195281556bb0e68a6ea97d18":["b9b82182bcb9110d24f7de32032113dbf31606c2"],"b9b82182bcb9110d24f7de32032113dbf31606c2":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"fab172655716b96f7e42376116235017a922de3a":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["fab172655716b96f7e42376116235017a922de3a","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}