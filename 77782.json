{"path":"lucene/core/src/java/org/apache/lucene/index/TermsHashPerField#TermsHashPerField(DocInverterPerField,TermsHash,TermsHash,FieldInfo).mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/TermsHashPerField#TermsHashPerField(DocInverterPerField,TermsHash,TermsHash,FieldInfo).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#TermsHashPerField(DocInverterPerField,TermsHash,TermsHash,FieldInfo).mjava","sourceNew":"  public TermsHashPerField(DocInverterPerField docInverterPerField, final TermsHash termsHash, final TermsHash nextTermsHash, final FieldInfo fieldInfo) {\n    intPool = termsHash.intPool;\n    bytePool = termsHash.bytePool;\n    termBytePool = termsHash.termBytePool;\n    docState = termsHash.docState;\n    this.termsHash = termsHash;\n    bytesUsed = termsHash.trackAllocations ? termsHash.docWriter.bytesUsed\n        : Counter.newCounter();\n    fieldState = docInverterPerField.fieldState;\n    this.consumer = termsHash.consumer.addField(this, fieldInfo);\n    PostingsBytesStartArray byteStarts = new PostingsBytesStartArray(this, bytesUsed);\n    bytesHash = new BytesRefHash(termBytePool, HASH_INIT_SIZE, byteStarts);\n    streamCount = consumer.getStreamCount();\n    numPostingInt = 2*streamCount;\n    this.fieldInfo = fieldInfo;\n    if (nextTermsHash != null)\n      nextPerField = (TermsHashPerField) nextTermsHash.addField(docInverterPerField, fieldInfo);\n    else\n      nextPerField = null;\n  }\n\n","sourceOld":"  public TermsHashPerField(DocInverterPerField docInverterPerField, final TermsHash termsHash, final TermsHash nextTermsHash, final FieldInfo fieldInfo) {\n    intPool = termsHash.intPool;\n    bytePool = termsHash.bytePool;\n    termBytePool = termsHash.termBytePool;\n    docState = termsHash.docState;\n    this.termsHash = termsHash;\n    bytesUsed = termsHash.trackAllocations ? termsHash.docWriter.bytesUsed\n        : Counter.newCounter();\n    fieldState = docInverterPerField.fieldState;\n    this.consumer = termsHash.consumer.addField(this, fieldInfo);\n    PostingsBytesStartArray byteStarts = new PostingsBytesStartArray(this, bytesUsed);\n    bytesHash = new BytesRefHash(termBytePool, HASH_INIT_SIZE, byteStarts);\n    streamCount = consumer.getStreamCount();\n    numPostingInt = 2*streamCount;\n    this.fieldInfo = fieldInfo;\n    if (nextTermsHash != null)\n      nextPerField = (TermsHashPerField) nextTermsHash.addField(docInverterPerField, fieldInfo);\n    else\n      nextPerField = null;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"30fd30bfbfa6b9e036bcd99c8339712e965d4a63","date":1351859294,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/TermsHashPerField#TermsHashPerField(DocInverterPerField,TermsHash,TermsHash,FieldInfo).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/TermsHashPerField#TermsHashPerField(DocInverterPerField,TermsHash,TermsHash,FieldInfo).mjava","sourceNew":"  public TermsHashPerField(DocInverterPerField docInverterPerField, final TermsHash termsHash, final TermsHash nextTermsHash, final FieldInfo fieldInfo) {\n    intPool = termsHash.intPool;\n    bytePool = termsHash.bytePool;\n    termBytePool = termsHash.termBytePool;\n    docState = termsHash.docState;\n    this.termsHash = termsHash;\n    bytesUsed = termsHash.bytesUsed;\n    fieldState = docInverterPerField.fieldState;\n    this.consumer = termsHash.consumer.addField(this, fieldInfo);\n    PostingsBytesStartArray byteStarts = new PostingsBytesStartArray(this, bytesUsed);\n    bytesHash = new BytesRefHash(termBytePool, HASH_INIT_SIZE, byteStarts);\n    streamCount = consumer.getStreamCount();\n    numPostingInt = 2*streamCount;\n    this.fieldInfo = fieldInfo;\n    if (nextTermsHash != null)\n      nextPerField = (TermsHashPerField) nextTermsHash.addField(docInverterPerField, fieldInfo);\n    else\n      nextPerField = null;\n  }\n\n","sourceOld":"  public TermsHashPerField(DocInverterPerField docInverterPerField, final TermsHash termsHash, final TermsHash nextTermsHash, final FieldInfo fieldInfo) {\n    intPool = termsHash.intPool;\n    bytePool = termsHash.bytePool;\n    termBytePool = termsHash.termBytePool;\n    docState = termsHash.docState;\n    this.termsHash = termsHash;\n    bytesUsed = termsHash.trackAllocations ? termsHash.docWriter.bytesUsed\n        : Counter.newCounter();\n    fieldState = docInverterPerField.fieldState;\n    this.consumer = termsHash.consumer.addField(this, fieldInfo);\n    PostingsBytesStartArray byteStarts = new PostingsBytesStartArray(this, bytesUsed);\n    bytesHash = new BytesRefHash(termBytePool, HASH_INIT_SIZE, byteStarts);\n    streamCount = consumer.getStreamCount();\n    numPostingInt = 2*streamCount;\n    this.fieldInfo = fieldInfo;\n    if (nextTermsHash != null)\n      nextPerField = (TermsHashPerField) nextTermsHash.addField(docInverterPerField, fieldInfo);\n    else\n      nextPerField = null;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"52c7e49be259508735752fba88085255014a6ecf","date":1398706273,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/TermsHashPerField#TermsHashPerField(int,FieldInvertState,TermsHash,TermsHashPerField,FieldInfo).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/TermsHashPerField#TermsHashPerField(DocInverterPerField,TermsHash,TermsHash,FieldInfo).mjava","sourceNew":"  /** streamCount: how many streams this field stores per term.\n   * E.g. doc(+freq) is 1 stream, prox+offset is a second. */\n\n  public TermsHashPerField(int streamCount, FieldInvertState fieldState, TermsHash termsHash, TermsHashPerField nextPerField, FieldInfo fieldInfo) {\n    intPool = termsHash.intPool;\n    bytePool = termsHash.bytePool;\n    termBytePool = termsHash.termBytePool;\n    docState = termsHash.docState;\n    this.termsHash = termsHash;\n    bytesUsed = termsHash.bytesUsed;\n    this.fieldState = fieldState;\n    this.streamCount = streamCount;\n    numPostingInt = 2*streamCount;\n    this.fieldInfo = fieldInfo;\n    this.nextPerField = nextPerField;\n    PostingsBytesStartArray byteStarts = new PostingsBytesStartArray(this, bytesUsed);\n    bytesHash = new BytesRefHash(termBytePool, HASH_INIT_SIZE, byteStarts);\n  }\n\n","sourceOld":"  public TermsHashPerField(DocInverterPerField docInverterPerField, final TermsHash termsHash, final TermsHash nextTermsHash, final FieldInfo fieldInfo) {\n    intPool = termsHash.intPool;\n    bytePool = termsHash.bytePool;\n    termBytePool = termsHash.termBytePool;\n    docState = termsHash.docState;\n    this.termsHash = termsHash;\n    bytesUsed = termsHash.bytesUsed;\n    fieldState = docInverterPerField.fieldState;\n    this.consumer = termsHash.consumer.addField(this, fieldInfo);\n    PostingsBytesStartArray byteStarts = new PostingsBytesStartArray(this, bytesUsed);\n    bytesHash = new BytesRefHash(termBytePool, HASH_INIT_SIZE, byteStarts);\n    streamCount = consumer.getStreamCount();\n    numPostingInt = 2*streamCount;\n    this.fieldInfo = fieldInfo;\n    if (nextTermsHash != null)\n      nextPerField = (TermsHashPerField) nextTermsHash.addField(docInverterPerField, fieldInfo);\n    else\n      nextPerField = null;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3394716f52b34ab259ad5247e7595d9f9db6e935","date":1398791921,"type":5,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/TermsHashPerField#TermsHashPerField(int,FieldInvertState,TermsHash,TermsHashPerField,FieldInfo).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/TermsHashPerField#TermsHashPerField(DocInverterPerField,TermsHash,TermsHash,FieldInfo).mjava","sourceNew":"  /** streamCount: how many streams this field stores per term.\n   * E.g. doc(+freq) is 1 stream, prox+offset is a second. */\n\n  public TermsHashPerField(int streamCount, FieldInvertState fieldState, TermsHash termsHash, TermsHashPerField nextPerField, FieldInfo fieldInfo) {\n    intPool = termsHash.intPool;\n    bytePool = termsHash.bytePool;\n    termBytePool = termsHash.termBytePool;\n    docState = termsHash.docState;\n    this.termsHash = termsHash;\n    bytesUsed = termsHash.bytesUsed;\n    this.fieldState = fieldState;\n    this.streamCount = streamCount;\n    numPostingInt = 2*streamCount;\n    this.fieldInfo = fieldInfo;\n    this.nextPerField = nextPerField;\n    PostingsBytesStartArray byteStarts = new PostingsBytesStartArray(this, bytesUsed);\n    bytesHash = new BytesRefHash(termBytePool, HASH_INIT_SIZE, byteStarts);\n  }\n\n","sourceOld":"  public TermsHashPerField(DocInverterPerField docInverterPerField, final TermsHash termsHash, final TermsHash nextTermsHash, final FieldInfo fieldInfo) {\n    intPool = termsHash.intPool;\n    bytePool = termsHash.bytePool;\n    termBytePool = termsHash.termBytePool;\n    docState = termsHash.docState;\n    this.termsHash = termsHash;\n    bytesUsed = termsHash.bytesUsed;\n    fieldState = docInverterPerField.fieldState;\n    this.consumer = termsHash.consumer.addField(this, fieldInfo);\n    PostingsBytesStartArray byteStarts = new PostingsBytesStartArray(this, bytesUsed);\n    bytesHash = new BytesRefHash(termBytePool, HASH_INIT_SIZE, byteStarts);\n    streamCount = consumer.getStreamCount();\n    numPostingInt = 2*streamCount;\n    this.fieldInfo = fieldInfo;\n    if (nextTermsHash != null)\n      nextPerField = (TermsHashPerField) nextTermsHash.addField(docInverterPerField, fieldInfo);\n    else\n      nextPerField = null;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c0cd85fde84cb318b4dc97710dcf15e2959a1bbe","date":1398844771,"type":5,"author":"Dawid Weiss","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/TermsHashPerField#TermsHashPerField(int,FieldInvertState,TermsHash,TermsHashPerField,FieldInfo).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/TermsHashPerField#TermsHashPerField(DocInverterPerField,TermsHash,TermsHash,FieldInfo).mjava","sourceNew":"  /** streamCount: how many streams this field stores per term.\n   * E.g. doc(+freq) is 1 stream, prox+offset is a second. */\n\n  public TermsHashPerField(int streamCount, FieldInvertState fieldState, TermsHash termsHash, TermsHashPerField nextPerField, FieldInfo fieldInfo) {\n    intPool = termsHash.intPool;\n    bytePool = termsHash.bytePool;\n    termBytePool = termsHash.termBytePool;\n    docState = termsHash.docState;\n    this.termsHash = termsHash;\n    bytesUsed = termsHash.bytesUsed;\n    this.fieldState = fieldState;\n    this.streamCount = streamCount;\n    numPostingInt = 2*streamCount;\n    this.fieldInfo = fieldInfo;\n    this.nextPerField = nextPerField;\n    PostingsBytesStartArray byteStarts = new PostingsBytesStartArray(this, bytesUsed);\n    bytesHash = new BytesRefHash(termBytePool, HASH_INIT_SIZE, byteStarts);\n  }\n\n","sourceOld":"  public TermsHashPerField(DocInverterPerField docInverterPerField, final TermsHash termsHash, final TermsHash nextTermsHash, final FieldInfo fieldInfo) {\n    intPool = termsHash.intPool;\n    bytePool = termsHash.bytePool;\n    termBytePool = termsHash.termBytePool;\n    docState = termsHash.docState;\n    this.termsHash = termsHash;\n    bytesUsed = termsHash.bytesUsed;\n    fieldState = docInverterPerField.fieldState;\n    this.consumer = termsHash.consumer.addField(this, fieldInfo);\n    PostingsBytesStartArray byteStarts = new PostingsBytesStartArray(this, bytesUsed);\n    bytesHash = new BytesRefHash(termBytePool, HASH_INIT_SIZE, byteStarts);\n    streamCount = consumer.getStreamCount();\n    numPostingInt = 2*streamCount;\n    this.fieldInfo = fieldInfo;\n    if (nextTermsHash != null)\n      nextPerField = (TermsHashPerField) nextTermsHash.addField(docInverterPerField, fieldInfo);\n    else\n      nextPerField = null;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"3394716f52b34ab259ad5247e7595d9f9db6e935":["30fd30bfbfa6b9e036bcd99c8339712e965d4a63","52c7e49be259508735752fba88085255014a6ecf"],"c0cd85fde84cb318b4dc97710dcf15e2959a1bbe":["30fd30bfbfa6b9e036bcd99c8339712e965d4a63","3394716f52b34ab259ad5247e7595d9f9db6e935"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"30fd30bfbfa6b9e036bcd99c8339712e965d4a63":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"52c7e49be259508735752fba88085255014a6ecf":["30fd30bfbfa6b9e036bcd99c8339712e965d4a63"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3394716f52b34ab259ad5247e7595d9f9db6e935"]},"commit2Childs":{"3394716f52b34ab259ad5247e7595d9f9db6e935":["c0cd85fde84cb318b4dc97710dcf15e2959a1bbe","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"c0cd85fde84cb318b4dc97710dcf15e2959a1bbe":[],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["30fd30bfbfa6b9e036bcd99c8339712e965d4a63"],"30fd30bfbfa6b9e036bcd99c8339712e965d4a63":["3394716f52b34ab259ad5247e7595d9f9db6e935","c0cd85fde84cb318b4dc97710dcf15e2959a1bbe","52c7e49be259508735752fba88085255014a6ecf"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"52c7e49be259508735752fba88085255014a6ecf":["3394716f52b34ab259ad5247e7595d9f9db6e935"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["c0cd85fde84cb318b4dc97710dcf15e2959a1bbe","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}