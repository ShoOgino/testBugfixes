{"path":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#makePreFlexSegment(Random,String,Directory,FieldInfos,Codec,List[Term]).mjava","commits":[{"id":"4f29ba80b723649f5feb7e37afe1a558dd2c1304","date":1278318805,"type":1,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#makePreFlexSegment(Random,String,Directory,FieldInfos,Codec,List[Term]).mjava","pathOld":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#makePreFlexSegment(Random,String,Directory,FieldInfos,Codec,List[FieldAndText]).mjava","sourceNew":"  private SegmentInfo makePreFlexSegment(Random r, String segName, Directory dir, FieldInfos fieldInfos, Codec codec, List<Term> fieldTerms) throws IOException {\n\n    final int numField = _TestUtil.nextInt(r, 2, 5);\n\n    List<Term> terms = new ArrayList<Term>();\n\n    int tc = 0;\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      Term protoTerm = new Term(field);\n\n      fieldInfos.add(field, true, false, false, false, false, false, false);\n      final int numTerms = 10000*_TestUtil.getRandomMultiplier();\n      for(int i=0;i<numTerms;i++) {\n        String s;\n        if (r.nextInt(3) == 1) {\n          s = makeDifficultRandomUnicodeString(r);\n        } else {\n          s = _TestUtil.randomUnicodeString(r);\n\n          // The surrogate dance uses 0xffff to seek-to-end\n          // of blocks.  Also, pre-4.0 indices are already\n          // guaranteed to not contain the char 0xffff since\n          // it's mapped during indexing:\n          s = s.replace((char) 0xffff, (char) 0xfffe);\n        }\n        terms.add(protoTerm.createTerm(s + \"_\" + (tc++)));\n      }\n    }\n\n    fieldInfos.write(dir, segName);\n\n    // sorts in UTF16 order, just like preflex:\n    Collections.sort(terms, new Comparator<Term>() {\n      public int compare(Term o1, Term o2) {\n        return o1.compareToUTF16(o2);\n      }\n    });\n\n    TermInfosWriter w = new TermInfosWriter(dir, segName, fieldInfos, 128);\n    TermInfo ti = new TermInfo();\n    String lastText = null;\n    int uniqueTermCount = 0;\n    if (VERBOSE) {\n      System.out.println(\"TEST: utf16 order:\");\n    }\n    for(Term t : terms) {\n      FieldInfo fi = fieldInfos.fieldInfo(t.field());\n\n      String text = t.text();\n      if (lastText != null && lastText.equals(text)) {\n        continue;\n      }\n      fieldTerms.add(t);\n      uniqueTermCount++;\n      lastText = text;\n\n      if (VERBOSE) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n      w.add(fi.number, t.bytes().bytes, t.bytes().length, ti);\n    }\n    w.close();\n\n    Collections.sort(fieldTerms);\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + t.field() + \":\" + toHexString(t));\n      }\n    }\n\n    dir.createOutput(segName + \".prx\").close();\n    dir.createOutput(segName + \".frq\").close();\n\n    // !!hack alert!! stuffing uniqueTermCount in as docCount\n    return new SegmentInfo(segName, uniqueTermCount, dir, false, -1, null, false, true, codec);\n  }\n\n","sourceOld":"  private SegmentInfo makePreFlexSegment(Random r, String segName, Directory dir, FieldInfos fieldInfos, Codec codec, List<FieldAndText> fieldTerms) throws IOException {\n\n    final int numField = _TestUtil.nextInt(r, 2, 5);\n\n    List<Term> terms = new ArrayList<Term>();\n\n    int tc = 0;\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      Term protoTerm = new Term(field);\n\n      fieldInfos.add(field, true, false, false, false, false, false, false);\n      final int numTerms = 10000*_TestUtil.getRandomMultiplier();\n      for(int i=0;i<numTerms;i++) {\n        String s;\n        if (r.nextInt(3) == 1) {\n          s = makeDifficultRandomUnicodeString(r);\n        } else {\n          s = _TestUtil.randomUnicodeString(r);\n\n          // The surrogate dance uses 0xffff to seek-to-end\n          // of blocks.  Also, pre-4.0 indices are already\n          // guaranteed to not contain the char 0xffff since\n          // it's mapped during indexing:\n          s = s.replace((char) 0xffff, (char) 0xfffe);\n        }\n        terms.add(protoTerm.createTerm(s + \"_\" + (tc++)));\n      }\n    }\n\n    fieldInfos.write(dir, segName);\n\n    // sorts in UTF16 order, just like preflex:\n    Collections.sort(terms);\n\n    TermInfosWriter w = new TermInfosWriter(dir, segName, fieldInfos, 128);\n    TermInfo ti = new TermInfo();\n    BytesRef utf8 = new BytesRef(10);\n    String lastText = null;\n    int uniqueTermCount = 0;\n    if (VERBOSE) {\n      System.out.println(\"TEST: utf16 order:\");\n    }\n    for(Term t : terms) {\n      FieldInfo fi = fieldInfos.fieldInfo(t.field());\n\n      String text = t.text();\n      if (lastText != null && lastText.equals(text)) {\n        continue;\n      }\n      fieldTerms.add(new FieldAndText(t));\n      uniqueTermCount++;\n      lastText = text;\n      UnicodeUtil.UTF16toUTF8(text, 0, text.length(), utf8);\n\n      if (VERBOSE) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n      w.add(fi.number, utf8.bytes, utf8.length, ti);\n    }\n    w.close();\n\n    Collections.sort(fieldTerms);\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(FieldAndText t: fieldTerms) {\n        System.out.println(\"  \" + t.field + \":\" + UnicodeUtil.toHexString(t.text.utf8ToString()));\n      }\n    }\n\n    dir.createOutput(segName + \".prx\").close();\n    dir.createOutput(segName + \".frq\").close();\n\n    // !!hack alert!! stuffing uniqueTermCount in as docCount\n    return new SegmentInfo(segName, uniqueTermCount, dir, false, -1, null, false, true, codec);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5f4e87790277826a2aea119328600dfb07761f32","date":1279827275,"type":0,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#makePreFlexSegment(Random,String,Directory,FieldInfos,Codec,List[Term]).mjava","pathOld":"/dev/null","sourceNew":"  private SegmentInfo makePreFlexSegment(Random r, String segName, Directory dir, FieldInfos fieldInfos, Codec codec, List<Term> fieldTerms) throws IOException {\n\n    final int numField = _TestUtil.nextInt(r, 2, 5);\n\n    List<Term> terms = new ArrayList<Term>();\n\n    int tc = 0;\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      Term protoTerm = new Term(field);\n\n      fieldInfos.add(field, true, false, false, false, false, false, false);\n      final int numTerms = 10000*_TestUtil.getRandomMultiplier();\n      for(int i=0;i<numTerms;i++) {\n        String s;\n        if (r.nextInt(3) == 1) {\n          s = makeDifficultRandomUnicodeString(r);\n        } else {\n          s = _TestUtil.randomUnicodeString(r);\n\n          // The surrogate dance uses 0xffff to seek-to-end\n          // of blocks.  Also, pre-4.0 indices are already\n          // guaranteed to not contain the char 0xffff since\n          // it's mapped during indexing:\n          s = s.replace((char) 0xffff, (char) 0xfffe);\n        }\n        terms.add(protoTerm.createTerm(s + \"_\" + (tc++)));\n      }\n    }\n\n    fieldInfos.write(dir, segName);\n\n    // sorts in UTF16 order, just like preflex:\n    Collections.sort(terms, new Comparator<Term>() {\n      public int compare(Term o1, Term o2) {\n        return o1.compareToUTF16(o2);\n      }\n    });\n\n    TermInfosWriter w = new TermInfosWriter(dir, segName, fieldInfos, 128);\n    TermInfo ti = new TermInfo();\n    String lastText = null;\n    int uniqueTermCount = 0;\n    if (VERBOSE) {\n      System.out.println(\"TEST: utf16 order:\");\n    }\n    for(Term t : terms) {\n      FieldInfo fi = fieldInfos.fieldInfo(t.field());\n\n      String text = t.text();\n      if (lastText != null && lastText.equals(text)) {\n        continue;\n      }\n      fieldTerms.add(t);\n      uniqueTermCount++;\n      lastText = text;\n\n      if (VERBOSE) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n      w.add(fi.number, t.bytes().bytes, t.bytes().length, ti);\n    }\n    w.close();\n\n    Collections.sort(fieldTerms);\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + t.field() + \":\" + toHexString(t));\n      }\n    }\n\n    dir.createOutput(segName + \".prx\").close();\n    dir.createOutput(segName + \".frq\").close();\n\n    // !!hack alert!! stuffing uniqueTermCount in as docCount\n    return new SegmentInfo(segName, uniqueTermCount, dir, false, -1, null, false, true, codec);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"163fe85a71d778fd2b7747f65ca27b54829e2e57","date":1279898785,"type":4,"author":"Robert Muir","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#makePreFlexSegment(Random,String,Directory,FieldInfos,Codec,List[Term]).mjava","sourceNew":null,"sourceOld":"  private SegmentInfo makePreFlexSegment(Random r, String segName, Directory dir, FieldInfos fieldInfos, Codec codec, List<Term> fieldTerms) throws IOException {\n\n    final int numField = _TestUtil.nextInt(r, 2, 5);\n\n    List<Term> terms = new ArrayList<Term>();\n\n    int tc = 0;\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      Term protoTerm = new Term(field);\n\n      fieldInfos.add(field, true, false, false, false, false, false, false);\n      final int numTerms = 10000*_TestUtil.getRandomMultiplier();\n      for(int i=0;i<numTerms;i++) {\n        String s;\n        if (r.nextInt(3) == 1) {\n          s = makeDifficultRandomUnicodeString(r);\n        } else {\n          s = _TestUtil.randomUnicodeString(r);\n\n          // The surrogate dance uses 0xffff to seek-to-end\n          // of blocks.  Also, pre-4.0 indices are already\n          // guaranteed to not contain the char 0xffff since\n          // it's mapped during indexing:\n          s = s.replace((char) 0xffff, (char) 0xfffe);\n        }\n        terms.add(protoTerm.createTerm(s + \"_\" + (tc++)));\n      }\n    }\n\n    fieldInfos.write(dir, segName);\n\n    // sorts in UTF16 order, just like preflex:\n    Collections.sort(terms, new Comparator<Term>() {\n      public int compare(Term o1, Term o2) {\n        return o1.compareToUTF16(o2);\n      }\n    });\n\n    TermInfosWriter w = new TermInfosWriter(dir, segName, fieldInfos, 128);\n    TermInfo ti = new TermInfo();\n    String lastText = null;\n    int uniqueTermCount = 0;\n    if (VERBOSE) {\n      System.out.println(\"TEST: utf16 order:\");\n    }\n    for(Term t : terms) {\n      FieldInfo fi = fieldInfos.fieldInfo(t.field());\n\n      String text = t.text();\n      if (lastText != null && lastText.equals(text)) {\n        continue;\n      }\n      fieldTerms.add(t);\n      uniqueTermCount++;\n      lastText = text;\n\n      if (VERBOSE) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n      w.add(fi.number, t.bytes().bytes, t.bytes().length, ti);\n    }\n    w.close();\n\n    Collections.sort(fieldTerms);\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + t.field() + \":\" + toHexString(t));\n      }\n    }\n\n    dir.createOutput(segName + \".prx\").close();\n    dir.createOutput(segName + \".frq\").close();\n\n    // !!hack alert!! stuffing uniqueTermCount in as docCount\n    return new SegmentInfo(segName, uniqueTermCount, dir, false, -1, null, false, true, codec);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"833a7987bc1c94455fde83e3311f72bddedcfb93","date":1279951470,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#makePreFlexSegment(Random,String,Directory,FieldInfos,Codec,List[Term]).mjava","pathOld":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#makePreFlexSegment(Random,String,Directory,FieldInfos,Codec,List[Term]).mjava","sourceNew":"  private SegmentInfo makePreFlexSegment(Random r, String segName, Directory dir, FieldInfos fieldInfos, Codec codec, List<Term> fieldTerms) throws IOException {\n\n    final int numField = _TestUtil.nextInt(r, 2, 5);\n\n    List<Term> terms = new ArrayList<Term>();\n\n    int tc = 0;\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      Term protoTerm = new Term(field);\n\n      fieldInfos.add(field, true, false, false, false, false, false, false);\n      final int numTerms = 10000*_TestUtil.getRandomMultiplier();\n      for(int i=0;i<numTerms;i++) {\n        String s;\n        if (r.nextInt(3) == 1) {\n          s = makeDifficultRandomUnicodeString(r);\n        } else {\n          s = _TestUtil.randomUnicodeString(r);\n\n          // The surrogate dance uses 0xffff to seek-to-end\n          // of blocks.  Also, pre-4.0 indices are already\n          // guaranteed to not contain the char 0xffff since\n          // it's mapped during indexing:\n          s = s.replace((char) 0xffff, (char) 0xfffe);\n        }\n        terms.add(protoTerm.createTerm(s + \"_\" + (tc++)));\n      }\n    }\n\n    fieldInfos.write(dir, segName);\n\n    // sorts in UTF16 order, just like preflex:\n    Collections.sort(terms, new Comparator<Term>() {\n      public int compare(Term o1, Term o2) {\n        return o1.compareToUTF16(o2);\n      }\n    });\n\n    TermInfosWriter w = new TermInfosWriter(dir, segName, fieldInfos, 128);\n    TermInfo ti = new TermInfo();\n    String lastText = null;\n    int uniqueTermCount = 0;\n    if (VERBOSE) {\n      System.out.println(\"TEST: utf16 order:\");\n    }\n    for(Term t : terms) {\n      FieldInfo fi = fieldInfos.fieldInfo(t.field());\n\n      String text = t.text();\n      if (lastText != null && lastText.equals(text)) {\n        continue;\n      }\n      fieldTerms.add(t);\n      uniqueTermCount++;\n      lastText = text;\n\n      if (VERBOSE) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n      w.add(fi.number, t.bytes().bytes, t.bytes().length, ti);\n    }\n    w.close();\n\n    Collections.sort(fieldTerms);\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + t.field() + \":\" + toHexString(t));\n      }\n    }\n\n    dir.createOutput(segName + \".prx\").close();\n    dir.createOutput(segName + \".frq\").close();\n\n    // !!hack alert!! stuffing uniqueTermCount in as docCount\n    return new SegmentInfo(segName, uniqueTermCount, dir, false, true, codec);\n  }\n\n","sourceOld":"  private SegmentInfo makePreFlexSegment(Random r, String segName, Directory dir, FieldInfos fieldInfos, Codec codec, List<Term> fieldTerms) throws IOException {\n\n    final int numField = _TestUtil.nextInt(r, 2, 5);\n\n    List<Term> terms = new ArrayList<Term>();\n\n    int tc = 0;\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      Term protoTerm = new Term(field);\n\n      fieldInfos.add(field, true, false, false, false, false, false, false);\n      final int numTerms = 10000*_TestUtil.getRandomMultiplier();\n      for(int i=0;i<numTerms;i++) {\n        String s;\n        if (r.nextInt(3) == 1) {\n          s = makeDifficultRandomUnicodeString(r);\n        } else {\n          s = _TestUtil.randomUnicodeString(r);\n\n          // The surrogate dance uses 0xffff to seek-to-end\n          // of blocks.  Also, pre-4.0 indices are already\n          // guaranteed to not contain the char 0xffff since\n          // it's mapped during indexing:\n          s = s.replace((char) 0xffff, (char) 0xfffe);\n        }\n        terms.add(protoTerm.createTerm(s + \"_\" + (tc++)));\n      }\n    }\n\n    fieldInfos.write(dir, segName);\n\n    // sorts in UTF16 order, just like preflex:\n    Collections.sort(terms, new Comparator<Term>() {\n      public int compare(Term o1, Term o2) {\n        return o1.compareToUTF16(o2);\n      }\n    });\n\n    TermInfosWriter w = new TermInfosWriter(dir, segName, fieldInfos, 128);\n    TermInfo ti = new TermInfo();\n    String lastText = null;\n    int uniqueTermCount = 0;\n    if (VERBOSE) {\n      System.out.println(\"TEST: utf16 order:\");\n    }\n    for(Term t : terms) {\n      FieldInfo fi = fieldInfos.fieldInfo(t.field());\n\n      String text = t.text();\n      if (lastText != null && lastText.equals(text)) {\n        continue;\n      }\n      fieldTerms.add(t);\n      uniqueTermCount++;\n      lastText = text;\n\n      if (VERBOSE) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n      w.add(fi.number, t.bytes().bytes, t.bytes().length, ti);\n    }\n    w.close();\n\n    Collections.sort(fieldTerms);\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + t.field() + \":\" + toHexString(t));\n      }\n    }\n\n    dir.createOutput(segName + \".prx\").close();\n    dir.createOutput(segName + \".frq\").close();\n\n    // !!hack alert!! stuffing uniqueTermCount in as docCount\n    return new SegmentInfo(segName, uniqueTermCount, dir, false, -1, null, false, true, codec);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4b103252dee6afa1b6d7a622c773d178788eb85a","date":1280180143,"type":4,"author":"Robert Muir","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#makePreFlexSegment(Random,String,Directory,FieldInfos,Codec,List[Term]).mjava","sourceNew":null,"sourceOld":"  private SegmentInfo makePreFlexSegment(Random r, String segName, Directory dir, FieldInfos fieldInfos, Codec codec, List<Term> fieldTerms) throws IOException {\n\n    final int numField = _TestUtil.nextInt(r, 2, 5);\n\n    List<Term> terms = new ArrayList<Term>();\n\n    int tc = 0;\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      Term protoTerm = new Term(field);\n\n      fieldInfos.add(field, true, false, false, false, false, false, false);\n      final int numTerms = 10000*_TestUtil.getRandomMultiplier();\n      for(int i=0;i<numTerms;i++) {\n        String s;\n        if (r.nextInt(3) == 1) {\n          s = makeDifficultRandomUnicodeString(r);\n        } else {\n          s = _TestUtil.randomUnicodeString(r);\n\n          // The surrogate dance uses 0xffff to seek-to-end\n          // of blocks.  Also, pre-4.0 indices are already\n          // guaranteed to not contain the char 0xffff since\n          // it's mapped during indexing:\n          s = s.replace((char) 0xffff, (char) 0xfffe);\n        }\n        terms.add(protoTerm.createTerm(s + \"_\" + (tc++)));\n      }\n    }\n\n    fieldInfos.write(dir, segName);\n\n    // sorts in UTF16 order, just like preflex:\n    Collections.sort(terms, new Comparator<Term>() {\n      public int compare(Term o1, Term o2) {\n        return o1.compareToUTF16(o2);\n      }\n    });\n\n    TermInfosWriter w = new TermInfosWriter(dir, segName, fieldInfos, 128);\n    TermInfo ti = new TermInfo();\n    String lastText = null;\n    int uniqueTermCount = 0;\n    if (VERBOSE) {\n      System.out.println(\"TEST: utf16 order:\");\n    }\n    for(Term t : terms) {\n      FieldInfo fi = fieldInfos.fieldInfo(t.field());\n\n      String text = t.text();\n      if (lastText != null && lastText.equals(text)) {\n        continue;\n      }\n      fieldTerms.add(t);\n      uniqueTermCount++;\n      lastText = text;\n\n      if (VERBOSE) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n      w.add(fi.number, t.bytes().bytes, t.bytes().length, ti);\n    }\n    w.close();\n\n    Collections.sort(fieldTerms);\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + t.field() + \":\" + toHexString(t));\n      }\n    }\n\n    dir.createOutput(segName + \".prx\").close();\n    dir.createOutput(segName + \".frq\").close();\n\n    // !!hack alert!! stuffing uniqueTermCount in as docCount\n    return new SegmentInfo(segName, uniqueTermCount, dir, false, -1, null, false, true, codec);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3242a09f703274d3b9283f2064a1a33064b53a1b","date":1280263474,"type":4,"author":"Michael Busch","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#makePreFlexSegment(Random,String,Directory,FieldInfos,Codec,List[Term]).mjava","sourceNew":null,"sourceOld":"  private SegmentInfo makePreFlexSegment(Random r, String segName, Directory dir, FieldInfos fieldInfos, Codec codec, List<Term> fieldTerms) throws IOException {\n\n    final int numField = _TestUtil.nextInt(r, 2, 5);\n\n    List<Term> terms = new ArrayList<Term>();\n\n    int tc = 0;\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      Term protoTerm = new Term(field);\n\n      fieldInfos.add(field, true, false, false, false, false, false, false);\n      final int numTerms = 10000*_TestUtil.getRandomMultiplier();\n      for(int i=0;i<numTerms;i++) {\n        String s;\n        if (r.nextInt(3) == 1) {\n          s = makeDifficultRandomUnicodeString(r);\n        } else {\n          s = _TestUtil.randomUnicodeString(r);\n\n          // The surrogate dance uses 0xffff to seek-to-end\n          // of blocks.  Also, pre-4.0 indices are already\n          // guaranteed to not contain the char 0xffff since\n          // it's mapped during indexing:\n          s = s.replace((char) 0xffff, (char) 0xfffe);\n        }\n        terms.add(protoTerm.createTerm(s + \"_\" + (tc++)));\n      }\n    }\n\n    fieldInfos.write(dir, segName);\n\n    // sorts in UTF16 order, just like preflex:\n    Collections.sort(terms, new Comparator<Term>() {\n      public int compare(Term o1, Term o2) {\n        return o1.compareToUTF16(o2);\n      }\n    });\n\n    TermInfosWriter w = new TermInfosWriter(dir, segName, fieldInfos, 128);\n    TermInfo ti = new TermInfo();\n    String lastText = null;\n    int uniqueTermCount = 0;\n    if (VERBOSE) {\n      System.out.println(\"TEST: utf16 order:\");\n    }\n    for(Term t : terms) {\n      FieldInfo fi = fieldInfos.fieldInfo(t.field());\n\n      String text = t.text();\n      if (lastText != null && lastText.equals(text)) {\n        continue;\n      }\n      fieldTerms.add(t);\n      uniqueTermCount++;\n      lastText = text;\n\n      if (VERBOSE) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n      w.add(fi.number, t.bytes().bytes, t.bytes().length, ti);\n    }\n    w.close();\n\n    Collections.sort(fieldTerms);\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + t.field() + \":\" + toHexString(t));\n      }\n    }\n\n    dir.createOutput(segName + \".prx\").close();\n    dir.createOutput(segName + \".frq\").close();\n\n    // !!hack alert!! stuffing uniqueTermCount in as docCount\n    return new SegmentInfo(segName, uniqueTermCount, dir, false, true, codec);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"4f29ba80b723649f5feb7e37afe1a558dd2c1304":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"3242a09f703274d3b9283f2064a1a33064b53a1b":["833a7987bc1c94455fde83e3311f72bddedcfb93","4b103252dee6afa1b6d7a622c773d178788eb85a"],"4b103252dee6afa1b6d7a622c773d178788eb85a":["4f29ba80b723649f5feb7e37afe1a558dd2c1304","163fe85a71d778fd2b7747f65ca27b54829e2e57"],"163fe85a71d778fd2b7747f65ca27b54829e2e57":["4f29ba80b723649f5feb7e37afe1a558dd2c1304"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"5f4e87790277826a2aea119328600dfb07761f32":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","4f29ba80b723649f5feb7e37afe1a558dd2c1304"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["4b103252dee6afa1b6d7a622c773d178788eb85a"],"833a7987bc1c94455fde83e3311f72bddedcfb93":["5f4e87790277826a2aea119328600dfb07761f32"]},"commit2Childs":{"4f29ba80b723649f5feb7e37afe1a558dd2c1304":["4b103252dee6afa1b6d7a622c773d178788eb85a","163fe85a71d778fd2b7747f65ca27b54829e2e57","5f4e87790277826a2aea119328600dfb07761f32"],"3242a09f703274d3b9283f2064a1a33064b53a1b":[],"4b103252dee6afa1b6d7a622c773d178788eb85a":["3242a09f703274d3b9283f2064a1a33064b53a1b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"163fe85a71d778fd2b7747f65ca27b54829e2e57":["4b103252dee6afa1b6d7a622c773d178788eb85a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["4f29ba80b723649f5feb7e37afe1a558dd2c1304","5f4e87790277826a2aea119328600dfb07761f32"],"5f4e87790277826a2aea119328600dfb07761f32":["833a7987bc1c94455fde83e3311f72bddedcfb93"],"833a7987bc1c94455fde83e3311f72bddedcfb93":["3242a09f703274d3b9283f2064a1a33064b53a1b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["3242a09f703274d3b9283f2064a1a33064b53a1b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}