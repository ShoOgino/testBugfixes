{"path":"lucene/src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String,SegmentInfo).mjava","commits":[{"id":"955c32f886db6f6356c9fcdea6b1f1cb4effda24","date":1270581567,"type":0,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String,SegmentInfo).mjava","pathOld":"/dev/null","sourceNew":"  final List<String> createCompoundFile(String fileName, final SegmentInfo info)\n          throws IOException {\n    CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, fileName, checkAbort);\n\n    Set<String> fileSet = new HashSet<String>();\n\n    // Basic files\n    for (String ext : IndexFileNames.COMPOUND_EXTENSIONS_NOT_CODEC) {\n      if (mergeDocStores || (!ext.equals(IndexFileNames.FIELDS_EXTENSION) &&\n                             !ext.equals(IndexFileNames.FIELDS_INDEX_EXTENSION)))\n        fileSet.add(IndexFileNames.segmentFileName(segment, ext));\n    }\n\n    codec.files(directory, info, fileSet);\n    \n    // Fieldable norm files\n    int numFIs = fieldInfos.size();\n    for (int i = 0; i < numFIs; i++) {\n      FieldInfo fi = fieldInfos.fieldInfo(i);\n      if (fi.isIndexed && !fi.omitNorms) {\n        fileSet.add(IndexFileNames.segmentFileName(segment, IndexFileNames.NORMS_EXTENSION));\n        break;\n      }\n    }\n\n    // Vector files\n    if (fieldInfos.hasVectors() && mergeDocStores) {\n      for (String ext : IndexFileNames.VECTOR_EXTENSIONS) {\n        fileSet.add(IndexFileNames.segmentFileName(segment, ext));\n      }\n    }\n\n    // Now merge all added files\n    for (String file : fileSet) {\n      cfsWriter.addFile(file);\n    }\n    \n    // Perform the merge\n    cfsWriter.close();\n   \n    return new ArrayList<String>(fileSet);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["8cac9bbcf5acbef2d0d83f6e9e32a22d71301db5"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fb10b6bcde550b87d8f10e5f010bd8f3021023b6","date":1274974592,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String,SegmentInfo).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String,SegmentInfo).mjava","sourceNew":"  final List<String> createCompoundFile(String fileName, final SegmentInfo info)\n          throws IOException {\n    CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, fileName, checkAbort);\n\n    Set<String> fileSet = new HashSet<String>();\n\n    // Basic files\n    for (String ext : IndexFileNames.COMPOUND_EXTENSIONS_NOT_CODEC) {\n      if (mergeDocStores || (!ext.equals(IndexFileNames.FIELDS_EXTENSION) &&\n                             !ext.equals(IndexFileNames.FIELDS_INDEX_EXTENSION)))\n        fileSet.add(IndexFileNames.segmentFileName(segment, \"\", ext));\n    }\n\n    codec.files(directory, info, fileSet);\n    \n    // Fieldable norm files\n    int numFIs = fieldInfos.size();\n    for (int i = 0; i < numFIs; i++) {\n      FieldInfo fi = fieldInfos.fieldInfo(i);\n      if (fi.isIndexed && !fi.omitNorms) {\n        fileSet.add(IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.NORMS_EXTENSION));\n        break;\n      }\n    }\n\n    // Vector files\n    if (fieldInfos.hasVectors() && mergeDocStores) {\n      for (String ext : IndexFileNames.VECTOR_EXTENSIONS) {\n        fileSet.add(IndexFileNames.segmentFileName(segment, \"\", ext));\n      }\n    }\n\n    // Now merge all added files\n    for (String file : fileSet) {\n      cfsWriter.addFile(file);\n    }\n    \n    // Perform the merge\n    cfsWriter.close();\n   \n    return new ArrayList<String>(fileSet);\n  }\n\n","sourceOld":"  final List<String> createCompoundFile(String fileName, final SegmentInfo info)\n          throws IOException {\n    CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, fileName, checkAbort);\n\n    Set<String> fileSet = new HashSet<String>();\n\n    // Basic files\n    for (String ext : IndexFileNames.COMPOUND_EXTENSIONS_NOT_CODEC) {\n      if (mergeDocStores || (!ext.equals(IndexFileNames.FIELDS_EXTENSION) &&\n                             !ext.equals(IndexFileNames.FIELDS_INDEX_EXTENSION)))\n        fileSet.add(IndexFileNames.segmentFileName(segment, ext));\n    }\n\n    codec.files(directory, info, fileSet);\n    \n    // Fieldable norm files\n    int numFIs = fieldInfos.size();\n    for (int i = 0; i < numFIs; i++) {\n      FieldInfo fi = fieldInfos.fieldInfo(i);\n      if (fi.isIndexed && !fi.omitNorms) {\n        fileSet.add(IndexFileNames.segmentFileName(segment, IndexFileNames.NORMS_EXTENSION));\n        break;\n      }\n    }\n\n    // Vector files\n    if (fieldInfos.hasVectors() && mergeDocStores) {\n      for (String ext : IndexFileNames.VECTOR_EXTENSIONS) {\n        fileSet.add(IndexFileNames.segmentFileName(segment, ext));\n      }\n    }\n\n    // Now merge all added files\n    for (String file : fileSet) {\n      cfsWriter.addFile(file);\n    }\n    \n    // Perform the merge\n    cfsWriter.close();\n   \n    return new ArrayList<String>(fileSet);\n  }\n\n","bugFix":null,"bugIntro":["8cac9bbcf5acbef2d0d83f6e9e32a22d71301db5"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"833a7987bc1c94455fde83e3311f72bddedcfb93","date":1279951470,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String,SegmentInfo).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String,SegmentInfo).mjava","sourceNew":"  final List<String> createCompoundFile(String fileName, final SegmentInfo info)\n          throws IOException {\n    CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, fileName, checkAbort);\n\n    Set<String> fileSet = new HashSet<String>();\n\n    // Basic files\n    for (String ext : IndexFileNames.COMPOUND_EXTENSIONS_NOT_CODEC) {\n      fileSet.add(IndexFileNames.segmentFileName(segment, \"\", ext));\n    }\n\n    codec.files(directory, info, fileSet);\n    \n    // Fieldable norm files\n    int numFIs = fieldInfos.size();\n    for (int i = 0; i < numFIs; i++) {\n      FieldInfo fi = fieldInfos.fieldInfo(i);\n      if (fi.isIndexed && !fi.omitNorms) {\n        fileSet.add(IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.NORMS_EXTENSION));\n        break;\n      }\n    }\n\n    // Vector files\n    if (fieldInfos.hasVectors()) {\n      for (String ext : IndexFileNames.VECTOR_EXTENSIONS) {\n        fileSet.add(IndexFileNames.segmentFileName(segment, \"\", ext));\n      }\n    }\n\n    // Now merge all added files\n    for (String file : fileSet) {\n      cfsWriter.addFile(file);\n    }\n    \n    // Perform the merge\n    cfsWriter.close();\n   \n    return new ArrayList<String>(fileSet);\n  }\n\n","sourceOld":"  final List<String> createCompoundFile(String fileName, final SegmentInfo info)\n          throws IOException {\n    CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, fileName, checkAbort);\n\n    Set<String> fileSet = new HashSet<String>();\n\n    // Basic files\n    for (String ext : IndexFileNames.COMPOUND_EXTENSIONS_NOT_CODEC) {\n      if (mergeDocStores || (!ext.equals(IndexFileNames.FIELDS_EXTENSION) &&\n                             !ext.equals(IndexFileNames.FIELDS_INDEX_EXTENSION)))\n        fileSet.add(IndexFileNames.segmentFileName(segment, \"\", ext));\n    }\n\n    codec.files(directory, info, fileSet);\n    \n    // Fieldable norm files\n    int numFIs = fieldInfos.size();\n    for (int i = 0; i < numFIs; i++) {\n      FieldInfo fi = fieldInfos.fieldInfo(i);\n      if (fi.isIndexed && !fi.omitNorms) {\n        fileSet.add(IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.NORMS_EXTENSION));\n        break;\n      }\n    }\n\n    // Vector files\n    if (fieldInfos.hasVectors() && mergeDocStores) {\n      for (String ext : IndexFileNames.VECTOR_EXTENSIONS) {\n        fileSet.add(IndexFileNames.segmentFileName(segment, \"\", ext));\n      }\n    }\n\n    // Now merge all added files\n    for (String file : fileSet) {\n      cfsWriter.addFile(file);\n    }\n    \n    // Perform the merge\n    cfsWriter.close();\n   \n    return new ArrayList<String>(fileSet);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"01f60198ece724a6e96cd0b45f289cf42ff83d4f","date":1286864103,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String,SegmentInfo).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String,SegmentInfo).mjava","sourceNew":"  final List<String> createCompoundFile(String fileName, final SegmentInfo info)\n          throws IOException {\n    CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, fileName, checkAbort);\n\n    Set<String> fileSet = new HashSet<String>();\n\n    // Basic files\n    for (String ext : IndexFileNames.COMPOUND_EXTENSIONS_NOT_CODEC) {\n      if (mergeDocStores || (!ext.equals(IndexFileNames.FIELDS_EXTENSION) &&\n                             !ext.equals(IndexFileNames.FIELDS_INDEX_EXTENSION)))\n        fileSet.add(IndexFileNames.segmentFileName(segment, \"\", ext));\n    }\n    codec.files(directory, info, fileSet);\n    \n    // Fieldable norm files\n    final int numFIs = fieldInfos.size();\n    for (int i = 0; i < numFIs; i++) {\n      final FieldInfo fi = fieldInfos.fieldInfo(i);\n      // Index Values aka. CSF\n      if (fi.indexValues != null) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(segment, Integer\n            .toString(fi.number), IndexFileNames.CSF_DATA_EXTENSION), directory);\n        addIfExists(fileSet, IndexFileNames.segmentFileName(segment, Integer\n            .toString(fi.number), IndexFileNames.CSF_INDEX_EXTENSION),\n            directory);\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        fileSet.add(IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.NORMS_EXTENSION));\n        break;\n      }\n    }\n\n    // Vector files\n    if (fieldInfos.hasVectors() && mergeDocStores) {\n      for (String ext : IndexFileNames.VECTOR_EXTENSIONS) {\n        fileSet.add(IndexFileNames.segmentFileName(segment, \"\", ext));\n      }\n    }\n\n    // Now merge all added files\n    for (String file : fileSet) {\n      cfsWriter.addFile(file);\n    }\n    \n    // Perform the merge\n    cfsWriter.close();\n   \n    return new ArrayList<String>(fileSet);\n  }\n\n","sourceOld":"  final List<String> createCompoundFile(String fileName, final SegmentInfo info)\n          throws IOException {\n    CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, fileName, checkAbort);\n\n    Set<String> fileSet = new HashSet<String>();\n\n    // Basic files\n    for (String ext : IndexFileNames.COMPOUND_EXTENSIONS_NOT_CODEC) {\n      if (mergeDocStores || (!ext.equals(IndexFileNames.FIELDS_EXTENSION) &&\n                             !ext.equals(IndexFileNames.FIELDS_INDEX_EXTENSION)))\n        fileSet.add(IndexFileNames.segmentFileName(segment, \"\", ext));\n    }\n\n    codec.files(directory, info, fileSet);\n    \n    // Fieldable norm files\n    int numFIs = fieldInfos.size();\n    for (int i = 0; i < numFIs; i++) {\n      FieldInfo fi = fieldInfos.fieldInfo(i);\n      if (fi.isIndexed && !fi.omitNorms) {\n        fileSet.add(IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.NORMS_EXTENSION));\n        break;\n      }\n    }\n\n    // Vector files\n    if (fieldInfos.hasVectors() && mergeDocStores) {\n      for (String ext : IndexFileNames.VECTOR_EXTENSIONS) {\n        fileSet.add(IndexFileNames.segmentFileName(segment, \"\", ext));\n      }\n    }\n\n    // Now merge all added files\n    for (String file : fileSet) {\n      cfsWriter.addFile(file);\n    }\n    \n    // Perform the merge\n    cfsWriter.close();\n   \n    return new ArrayList<String>(fileSet);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0e28c49f1fb6215a550fdadcf3805aa629b63ec0","date":1288081775,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String,SegmentInfo).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String,SegmentInfo).mjava","sourceNew":"  final List<String> createCompoundFile(String fileName, final SegmentInfo info)\n          throws IOException {\n    CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, fileName, checkAbort);\n\n    Set<String> fileSet = new HashSet<String>();\n\n    // Basic files\n    for (String ext : IndexFileNames.COMPOUND_EXTENSIONS_NOT_CODEC) {\n      if (mergeDocStores || (!ext.equals(IndexFileNames.FIELDS_EXTENSION) &&\n                             !ext.equals(IndexFileNames.FIELDS_INDEX_EXTENSION)))\n        fileSet.add(IndexFileNames.segmentFileName(segment, \"\", ext));\n    }\n    codec.files(directory, info, fileSet);\n    \n    // Fieldable norm files\n    final int numFIs = fieldInfos.size();\n    for (int i = 0; i < numFIs; i++) {\n      final FieldInfo fi = fieldInfos.fieldInfo(i);\n      if (fi.isIndexed && !fi.omitNorms) {\n        fileSet.add(IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.NORMS_EXTENSION));\n        break;\n      }\n    }\n\n    // Vector files\n    if (fieldInfos.hasVectors() && mergeDocStores) {\n      for (String ext : IndexFileNames.VECTOR_EXTENSIONS) {\n        fileSet.add(IndexFileNames.segmentFileName(segment, \"\", ext));\n      }\n    }\n\n    // Now merge all added files\n    for (String file : fileSet) {\n      cfsWriter.addFile(file);\n    }\n    \n    // Perform the merge\n    cfsWriter.close();\n   \n    return new ArrayList<String>(fileSet);\n  }\n\n","sourceOld":"  final List<String> createCompoundFile(String fileName, final SegmentInfo info)\n          throws IOException {\n    CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, fileName, checkAbort);\n\n    Set<String> fileSet = new HashSet<String>();\n\n    // Basic files\n    for (String ext : IndexFileNames.COMPOUND_EXTENSIONS_NOT_CODEC) {\n      if (mergeDocStores || (!ext.equals(IndexFileNames.FIELDS_EXTENSION) &&\n                             !ext.equals(IndexFileNames.FIELDS_INDEX_EXTENSION)))\n        fileSet.add(IndexFileNames.segmentFileName(segment, \"\", ext));\n    }\n    codec.files(directory, info, fileSet);\n    \n    // Fieldable norm files\n    final int numFIs = fieldInfos.size();\n    for (int i = 0; i < numFIs; i++) {\n      final FieldInfo fi = fieldInfos.fieldInfo(i);\n      // Index Values aka. CSF\n      if (fi.indexValues != null) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(segment, Integer\n            .toString(fi.number), IndexFileNames.CSF_DATA_EXTENSION), directory);\n        addIfExists(fileSet, IndexFileNames.segmentFileName(segment, Integer\n            .toString(fi.number), IndexFileNames.CSF_INDEX_EXTENSION),\n            directory);\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        fileSet.add(IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.NORMS_EXTENSION));\n        break;\n      }\n    }\n\n    // Vector files\n    if (fieldInfos.hasVectors() && mergeDocStores) {\n      for (String ext : IndexFileNames.VECTOR_EXTENSIONS) {\n        fileSet.add(IndexFileNames.segmentFileName(segment, \"\", ext));\n      }\n    }\n\n    // Now merge all added files\n    for (String file : fileSet) {\n      cfsWriter.addFile(file);\n    }\n    \n    // Perform the merge\n    cfsWriter.close();\n   \n    return new ArrayList<String>(fileSet);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a493e6d0c3ad86bd55c0a1360d110142e948f2bd","date":1289406991,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String,SegmentInfo).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String,SegmentInfo).mjava","sourceNew":"  final List<String> createCompoundFile(String fileName, final SegmentInfo info)\n          throws IOException {\n    CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, fileName, checkAbort);\n\n    Set<String> fileSet = new HashSet<String>();\n\n    // Basic files\n    for (String ext : IndexFileNames.COMPOUND_EXTENSIONS_NOT_CODEC) {\n      if (mergeDocStores || (!ext.equals(IndexFileNames.FIELDS_EXTENSION) &&\n                             !ext.equals(IndexFileNames.FIELDS_INDEX_EXTENSION)))\n        fileSet.add(IndexFileNames.segmentFileName(segment, \"\", ext));\n    }\n\n    segmentWriteState.segmentCodecs.files(directory, info, fileSet);\n    \n    // Fieldable norm files\n    int numFIs = fieldInfos.size();\n    for (int i = 0; i < numFIs; i++) {\n      FieldInfo fi = fieldInfos.fieldInfo(i);\n      if (fi.isIndexed && !fi.omitNorms) {\n        fileSet.add(IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.NORMS_EXTENSION));\n        break;\n      }\n    }\n\n    // Vector files\n    if (fieldInfos.hasVectors() && mergeDocStores) {\n      for (String ext : IndexFileNames.VECTOR_EXTENSIONS) {\n        fileSet.add(IndexFileNames.segmentFileName(segment, \"\", ext));\n      }\n    }\n\n    // Now merge all added files\n    for (String file : fileSet) {\n      cfsWriter.addFile(file);\n    }\n    \n    // Perform the merge\n    cfsWriter.close();\n   \n    return new ArrayList<String>(fileSet);\n  }\n\n","sourceOld":"  final List<String> createCompoundFile(String fileName, final SegmentInfo info)\n          throws IOException {\n    CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, fileName, checkAbort);\n\n    Set<String> fileSet = new HashSet<String>();\n\n    // Basic files\n    for (String ext : IndexFileNames.COMPOUND_EXTENSIONS_NOT_CODEC) {\n      if (mergeDocStores || (!ext.equals(IndexFileNames.FIELDS_EXTENSION) &&\n                             !ext.equals(IndexFileNames.FIELDS_INDEX_EXTENSION)))\n        fileSet.add(IndexFileNames.segmentFileName(segment, \"\", ext));\n    }\n\n    codec.files(directory, info, fileSet);\n    \n    // Fieldable norm files\n    int numFIs = fieldInfos.size();\n    for (int i = 0; i < numFIs; i++) {\n      FieldInfo fi = fieldInfos.fieldInfo(i);\n      if (fi.isIndexed && !fi.omitNorms) {\n        fileSet.add(IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.NORMS_EXTENSION));\n        break;\n      }\n    }\n\n    // Vector files\n    if (fieldInfos.hasVectors() && mergeDocStores) {\n      for (String ext : IndexFileNames.VECTOR_EXTENSIONS) {\n        fileSet.add(IndexFileNames.segmentFileName(segment, \"\", ext));\n      }\n    }\n\n    // Now merge all added files\n    for (String file : fileSet) {\n      cfsWriter.addFile(file);\n    }\n    \n    // Perform the merge\n    cfsWriter.close();\n   \n    return new ArrayList<String>(fileSet);\n  }\n\n","bugFix":null,"bugIntro":["8cac9bbcf5acbef2d0d83f6e9e32a22d71301db5"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"85a883878c0af761245ab048babc63d099f835f3","date":1289553330,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String,SegmentInfo).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String,SegmentInfo).mjava","sourceNew":"  final List<String> createCompoundFile(String fileName, final SegmentInfo info)\n          throws IOException {\n    CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, fileName, checkAbort);\n\n    Set<String> fileSet = new HashSet<String>();\n\n    // Basic files\n    for (String ext : IndexFileNames.COMPOUND_EXTENSIONS_NOT_CODEC) {\n      if (mergeDocStores || (!ext.equals(IndexFileNames.FIELDS_EXTENSION) &&\n                             !ext.equals(IndexFileNames.FIELDS_INDEX_EXTENSION)))\n        fileSet.add(IndexFileNames.segmentFileName(segment, \"\", ext));\n    }\n    segmentWriteState.segmentCodecs.files(directory, info, fileSet);\n    \n    // Fieldable norm files\n    final int numFIs = fieldInfos.size();\n    for (int i = 0; i < numFIs; i++) {\n      final FieldInfo fi = fieldInfos.fieldInfo(i);\n      if (fi.isIndexed && !fi.omitNorms) {\n        fileSet.add(IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.NORMS_EXTENSION));\n        break;\n      }\n    }\n\n    // Vector files\n    if (fieldInfos.hasVectors() && mergeDocStores) {\n      for (String ext : IndexFileNames.VECTOR_EXTENSIONS) {\n        fileSet.add(IndexFileNames.segmentFileName(segment, \"\", ext));\n      }\n    }\n\n    // Now merge all added files\n    for (String file : fileSet) {\n      cfsWriter.addFile(file);\n    }\n    \n    // Perform the merge\n    cfsWriter.close();\n   \n    return new ArrayList<String>(fileSet);\n  }\n\n","sourceOld":"  final List<String> createCompoundFile(String fileName, final SegmentInfo info)\n          throws IOException {\n    CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, fileName, checkAbort);\n\n    Set<String> fileSet = new HashSet<String>();\n\n    // Basic files\n    for (String ext : IndexFileNames.COMPOUND_EXTENSIONS_NOT_CODEC) {\n      if (mergeDocStores || (!ext.equals(IndexFileNames.FIELDS_EXTENSION) &&\n                             !ext.equals(IndexFileNames.FIELDS_INDEX_EXTENSION)))\n        fileSet.add(IndexFileNames.segmentFileName(segment, \"\", ext));\n    }\n    codec.files(directory, info, fileSet);\n    \n    // Fieldable norm files\n    final int numFIs = fieldInfos.size();\n    for (int i = 0; i < numFIs; i++) {\n      final FieldInfo fi = fieldInfos.fieldInfo(i);\n      if (fi.isIndexed && !fi.omitNorms) {\n        fileSet.add(IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.NORMS_EXTENSION));\n        break;\n      }\n    }\n\n    // Vector files\n    if (fieldInfos.hasVectors() && mergeDocStores) {\n      for (String ext : IndexFileNames.VECTOR_EXTENSIONS) {\n        fileSet.add(IndexFileNames.segmentFileName(segment, \"\", ext));\n      }\n    }\n\n    // Now merge all added files\n    for (String file : fileSet) {\n      cfsWriter.addFile(file);\n    }\n    \n    // Perform the merge\n    cfsWriter.close();\n   \n    return new ArrayList<String>(fileSet);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8cac9bbcf5acbef2d0d83f6e9e32a22d71301db5","date":1290247889,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String,SegmentInfo).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String,SegmentInfo).mjava","sourceNew":"  final Collection<String> createCompoundFile(String fileName, final SegmentInfo info)\n          throws IOException {\n\n    // Now merge all added files\n    Collection<String> files = getMergedFiles(info);\n    CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, fileName, checkAbort);\n    for (String file : files) {\n      cfsWriter.addFile(file);\n    }\n    \n    // Perform the merge\n    cfsWriter.close();\n   \n    return files;\n  }\n\n","sourceOld":"  final List<String> createCompoundFile(String fileName, final SegmentInfo info)\n          throws IOException {\n    CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, fileName, checkAbort);\n\n    Set<String> fileSet = new HashSet<String>();\n\n    // Basic files\n    for (String ext : IndexFileNames.COMPOUND_EXTENSIONS_NOT_CODEC) {\n      if (mergeDocStores || (!ext.equals(IndexFileNames.FIELDS_EXTENSION) &&\n                             !ext.equals(IndexFileNames.FIELDS_INDEX_EXTENSION)))\n        fileSet.add(IndexFileNames.segmentFileName(segment, \"\", ext));\n    }\n\n    segmentWriteState.segmentCodecs.files(directory, info, fileSet);\n    \n    // Fieldable norm files\n    int numFIs = fieldInfos.size();\n    for (int i = 0; i < numFIs; i++) {\n      FieldInfo fi = fieldInfos.fieldInfo(i);\n      if (fi.isIndexed && !fi.omitNorms) {\n        fileSet.add(IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.NORMS_EXTENSION));\n        break;\n      }\n    }\n\n    // Vector files\n    if (fieldInfos.hasVectors() && mergeDocStores) {\n      for (String ext : IndexFileNames.VECTOR_EXTENSIONS) {\n        fileSet.add(IndexFileNames.segmentFileName(segment, \"\", ext));\n      }\n    }\n\n    // Now merge all added files\n    for (String file : fileSet) {\n      cfsWriter.addFile(file);\n    }\n    \n    // Perform the merge\n    cfsWriter.close();\n   \n    return new ArrayList<String>(fileSet);\n  }\n\n","bugFix":["a493e6d0c3ad86bd55c0a1360d110142e948f2bd","fb10b6bcde550b87d8f10e5f010bd8f3021023b6","955c32f886db6f6356c9fcdea6b1f1cb4effda24"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3bb13258feba31ab676502787ab2e1779f129b7a","date":1291596436,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String,SegmentInfo).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String,SegmentInfo).mjava","sourceNew":"  final Collection<String> createCompoundFile(String fileName, final SegmentInfo info)\n          throws IOException {\n\n    // Now merge all added files\n    Collection<String> files = getMergedFiles(info);\n    CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, fileName, checkAbort);\n    for (String file : files) {\n      cfsWriter.addFile(file);\n    }\n    \n    // Perform the merge\n    cfsWriter.close();\n   \n    return files;\n  }\n\n","sourceOld":"  final List<String> createCompoundFile(String fileName, final SegmentInfo info)\n          throws IOException {\n    CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, fileName, checkAbort);\n\n    Set<String> fileSet = new HashSet<String>();\n\n    // Basic files\n    for (String ext : IndexFileNames.COMPOUND_EXTENSIONS_NOT_CODEC) {\n      if (mergeDocStores || (!ext.equals(IndexFileNames.FIELDS_EXTENSION) &&\n                             !ext.equals(IndexFileNames.FIELDS_INDEX_EXTENSION)))\n        fileSet.add(IndexFileNames.segmentFileName(segment, \"\", ext));\n    }\n    segmentWriteState.segmentCodecs.files(directory, info, fileSet);\n    \n    // Fieldable norm files\n    final int numFIs = fieldInfos.size();\n    for (int i = 0; i < numFIs; i++) {\n      final FieldInfo fi = fieldInfos.fieldInfo(i);\n      if (fi.isIndexed && !fi.omitNorms) {\n        fileSet.add(IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.NORMS_EXTENSION));\n        break;\n      }\n    }\n\n    // Vector files\n    if (fieldInfos.hasVectors() && mergeDocStores) {\n      for (String ext : IndexFileNames.VECTOR_EXTENSIONS) {\n        fileSet.add(IndexFileNames.segmentFileName(segment, \"\", ext));\n      }\n    }\n\n    // Now merge all added files\n    for (String file : fileSet) {\n      cfsWriter.addFile(file);\n    }\n    \n    // Perform the merge\n    cfsWriter.close();\n   \n    return new ArrayList<String>(fileSet);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String,SegmentInfo).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String,SegmentInfo).mjava","sourceNew":"  final Collection<String> createCompoundFile(String fileName, final SegmentInfo info)\n          throws IOException {\n\n    // Now merge all added files\n    Collection<String> files = getMergedFiles(info);\n    CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, fileName, checkAbort);\n    for (String file : files) {\n      cfsWriter.addFile(file);\n    }\n\n    // Perform the merge\n    cfsWriter.close();\n\n    return files;\n  }\n\n","sourceOld":"  final List<String> createCompoundFile(String fileName, final SegmentInfo info)\n          throws IOException {\n    CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, fileName, checkAbort);\n\n    Set<String> fileSet = new HashSet<String>();\n\n    // Basic files\n    for (String ext : IndexFileNames.COMPOUND_EXTENSIONS_NOT_CODEC) {\n      fileSet.add(IndexFileNames.segmentFileName(segment, \"\", ext));\n    }\n\n    codec.files(directory, info, fileSet);\n    \n    // Fieldable norm files\n    int numFIs = fieldInfos.size();\n    for (int i = 0; i < numFIs; i++) {\n      FieldInfo fi = fieldInfos.fieldInfo(i);\n      if (fi.isIndexed && !fi.omitNorms) {\n        fileSet.add(IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.NORMS_EXTENSION));\n        break;\n      }\n    }\n\n    // Vector files\n    if (fieldInfos.hasVectors()) {\n      for (String ext : IndexFileNames.VECTOR_EXTENSIONS) {\n        fileSet.add(IndexFileNames.segmentFileName(segment, \"\", ext));\n      }\n    }\n\n    // Now merge all added files\n    for (String file : fileSet) {\n      cfsWriter.addFile(file);\n    }\n    \n    // Perform the merge\n    cfsWriter.close();\n   \n    return new ArrayList<String>(fileSet);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fdc49cf4bbf2603a647b53ff5cfa6878743a3ffe","date":1294227869,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String,SegmentInfo).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String,SegmentInfo).mjava","sourceNew":"  final Collection<String> createCompoundFile(String fileName, final SegmentInfo info)\n          throws IOException {\n\n    // Now merge all added files\n    Collection<String> files = info.files();\n    CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, fileName, checkAbort);\n    for (String file : files) {\n      cfsWriter.addFile(file);\n    }\n    \n    // Perform the merge\n    cfsWriter.close();\n   \n    return files;\n  }\n\n","sourceOld":"  final Collection<String> createCompoundFile(String fileName, final SegmentInfo info)\n          throws IOException {\n\n    // Now merge all added files\n    Collection<String> files = getMergedFiles(info);\n    CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, fileName, checkAbort);\n    for (String file : files) {\n      cfsWriter.addFile(file);\n    }\n    \n    // Perform the merge\n    cfsWriter.close();\n   \n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"70ad682703b8585f5d0a637efec044d57ec05efb","date":1294259117,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String,SegmentInfo).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String,SegmentInfo).mjava","sourceNew":"  final Collection<String> createCompoundFile(String fileName, final SegmentInfo info)\n          throws IOException {\n\n    // Now merge all added files\n    Collection<String> files = info.files();\n    CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, fileName, checkAbort);\n    for (String file : files) {\n      cfsWriter.addFile(file);\n    }\n    \n    // Perform the merge\n    cfsWriter.close();\n   \n    return files;\n  }\n\n","sourceOld":"  final Collection<String> createCompoundFile(String fileName, final SegmentInfo info)\n          throws IOException {\n\n    // Now merge all added files\n    Collection<String> files = getMergedFiles(info);\n    CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, fileName, checkAbort);\n    for (String file : files) {\n      cfsWriter.addFile(file);\n    }\n    \n    // Perform the merge\n    cfsWriter.close();\n   \n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"868da859b43505d9d2a023bfeae6dd0c795f5295","date":1294948401,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String,SegmentInfo).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String,SegmentInfo).mjava","sourceNew":"  final Collection<String> createCompoundFile(String fileName, final SegmentInfo info)\n          throws IOException {\n\n    // Now merge all added files\n    Collection<String> files = info.files();\n    CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, fileName, checkAbort);\n    for (String file : files) {\n      cfsWriter.addFile(file);\n    }\n\n    // Perform the merge\n    cfsWriter.close();\n\n    return files;\n  }\n\n","sourceOld":"  final Collection<String> createCompoundFile(String fileName, final SegmentInfo info)\n          throws IOException {\n\n    // Now merge all added files\n    Collection<String> files = getMergedFiles(info);\n    CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, fileName, checkAbort);\n    for (String file : files) {\n      cfsWriter.addFile(file);\n    }\n\n    // Perform the merge\n    cfsWriter.close();\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b3e06be49006ecac364d39d12b9c9f74882f9b9f","date":1304289513,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String,SegmentInfo).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String,SegmentInfo).mjava","sourceNew":"  final Collection<String> createCompoundFile(String fileName, final SegmentInfo info)\n          throws IOException {\n\n    // Now merge all added files\n    Collection<String> files = info.files();\n    CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, fileName, checkAbort);\n    for (String file : files) {\n      cfsWriter.addFile(file);\n    }\n\n    // Perform the merge\n    cfsWriter.close();\n\n    return files;\n  }\n\n","sourceOld":"  final Collection<String> createCompoundFile(String fileName, final SegmentInfo info)\n          throws IOException {\n\n    // Now merge all added files\n    Collection<String> files = info.files();\n    CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, fileName, checkAbort);\n    for (String file : files) {\n      cfsWriter.addFile(file);\n    }\n    \n    // Perform the merge\n    cfsWriter.close();\n   \n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"135621f3a0670a9394eb563224a3b76cc4dddc0f","date":1304344257,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String,SegmentInfo).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String,SegmentInfo).mjava","sourceNew":"  final Collection<String> createCompoundFile(String fileName, final SegmentInfo info)\n          throws IOException {\n\n    // Now merge all added files\n    Collection<String> files = info.files();\n    CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, fileName, checkAbort);\n    for (String file : files) {\n      cfsWriter.addFile(file);\n    }\n\n    // Perform the merge\n    cfsWriter.close();\n\n    return files;\n  }\n\n","sourceOld":"  final Collection<String> createCompoundFile(String fileName, final SegmentInfo info)\n          throws IOException {\n\n    // Now merge all added files\n    Collection<String> files = info.files();\n    CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, fileName, checkAbort);\n    for (String file : files) {\n      cfsWriter.addFile(file);\n    }\n    \n    // Perform the merge\n    cfsWriter.close();\n   \n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String,SegmentInfo).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String,SegmentInfo).mjava","sourceNew":"  final Collection<String> createCompoundFile(String fileName, final SegmentInfo info)\n          throws IOException {\n\n    // Now merge all added files\n    Collection<String> files = info.files();\n    CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, fileName, checkAbort);\n    for (String file : files) {\n      cfsWriter.addFile(file);\n    }\n\n    // Perform the merge\n    cfsWriter.close();\n\n    return files;\n  }\n\n","sourceOld":"  final Collection<String> createCompoundFile(String fileName, final SegmentInfo info)\n          throws IOException {\n\n    // Now merge all added files\n    Collection<String> files = info.files();\n    CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, fileName, checkAbort);\n    for (String file : files) {\n      cfsWriter.addFile(file);\n    }\n    \n    // Perform the merge\n    cfsWriter.close();\n   \n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c30fc6c6819ecb25af47f81683b9f52a3122054e","date":1306346530,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String,SegmentInfo).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String,SegmentInfo).mjava","sourceNew":"  /**\n   * NOTE: this method creates a compound file for all files returned by\n   * info.files(). While, generally, this may include separate norms and\n   * deletion files, this SegmentInfo must not reference such files when this\n   * method is called, because they are not allowed within a compound file.\n   */\n  final Collection<String> createCompoundFile(String fileName, final SegmentInfo info)\n          throws IOException {\n\n    // Now merge all added files\n    Collection<String> files = info.files();\n    CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, fileName, checkAbort);\n    for (String file : files) {\n      assert !IndexFileNames.matchesExtension(file, IndexFileNames.DELETES_EXTENSION) \n                : \".del file is not allowed in .cfs: \" + file;\n      assert !file.substring(file.lastIndexOf('.') + 1).startsWith(IndexFileNames.SEPARATE_NORMS_EXTENSION) \n                : \"separate norms file (.s*) is not allowed in .cfs: \" + file;\n      cfsWriter.addFile(file);\n    }\n\n    // Perform the merge\n    cfsWriter.close();\n\n    return files;\n  }\n\n","sourceOld":"  final Collection<String> createCompoundFile(String fileName, final SegmentInfo info)\n          throws IOException {\n\n    // Now merge all added files\n    Collection<String> files = info.files();\n    CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, fileName, checkAbort);\n    for (String file : files) {\n      cfsWriter.addFile(file);\n    }\n\n    // Perform the merge\n    cfsWriter.close();\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ed004bd98627df9d3b3a1a9ec80423e8d456bdb3","date":1306370077,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String,SegmentInfo).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String,SegmentInfo).mjava","sourceNew":"  /**\n   * NOTE: this method creates a compound file for all files returned by\n   * info.files(). While, generally, this may include separate norms and\n   * deletion files, this SegmentInfo must not reference such files when this\n   * method is called, because they are not allowed within a compound file.\n   */\n  final Collection<String> createCompoundFile(String fileName, final SegmentInfo info)\n          throws IOException {\n\n    // Now merge all added files\n    Collection<String> files = info.files();\n    CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, fileName, checkAbort);\n    for (String file : files) {\n      assert !IndexFileNames.matchesExtension(file, IndexFileNames.DELETES_EXTENSION) \n                : \".del file is not allowed in .cfs: \" + file;\n      assert !Pattern.matches(\"^.+[.]\" + IndexFileNames.SEPARATE_NORMS_EXTENSION  + \"\\\\d+$\", file) \n                : \"separate norms file (.s[0-9]*) is not allowed in .cfs: \" + file;\n      cfsWriter.addFile(file);\n    }\n\n    // Perform the merge\n    cfsWriter.close();\n\n    return files;\n  }\n\n","sourceOld":"  /**\n   * NOTE: this method creates a compound file for all files returned by\n   * info.files(). While, generally, this may include separate norms and\n   * deletion files, this SegmentInfo must not reference such files when this\n   * method is called, because they are not allowed within a compound file.\n   */\n  final Collection<String> createCompoundFile(String fileName, final SegmentInfo info)\n          throws IOException {\n\n    // Now merge all added files\n    Collection<String> files = info.files();\n    CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, fileName, checkAbort);\n    for (String file : files) {\n      assert !IndexFileNames.matchesExtension(file, IndexFileNames.DELETES_EXTENSION) \n                : \".del file is not allowed in .cfs: \" + file;\n      assert !file.substring(file.lastIndexOf('.') + 1).startsWith(IndexFileNames.SEPARATE_NORMS_EXTENSION) \n                : \"separate norms file (.s*) is not allowed in .cfs: \" + file;\n      cfsWriter.addFile(file);\n    }\n\n    // Perform the merge\n    cfsWriter.close();\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":["57ad8ee2555a290f9ce56ba46049309968819d93"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"57ad8ee2555a290f9ce56ba46049309968819d93","date":1306403052,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String,SegmentInfo).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String,SegmentInfo).mjava","sourceNew":"  /**\n   * NOTE: this method creates a compound file for all files returned by\n   * info.files(). While, generally, this may include separate norms and\n   * deletion files, this SegmentInfo must not reference such files when this\n   * method is called, because they are not allowed within a compound file.\n   */\n  final Collection<String> createCompoundFile(String fileName, final SegmentInfo info)\n          throws IOException {\n\n    // Now merge all added files\n    Collection<String> files = info.files();\n    CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, fileName, checkAbort);\n    for (String file : files) {\n      assert !IndexFileNames.matchesExtension(file, IndexFileNames.DELETES_EXTENSION) \n                : \".del file is not allowed in .cfs: \" + file;\n      assert !IndexFileNames.isSeparateNormsFile(file) \n                : \"separate norms file (.s[0-9]+) is not allowed in .cfs: \" + file;\n      cfsWriter.addFile(file);\n    }\n\n    // Perform the merge\n    cfsWriter.close();\n\n    return files;\n  }\n\n","sourceOld":"  /**\n   * NOTE: this method creates a compound file for all files returned by\n   * info.files(). While, generally, this may include separate norms and\n   * deletion files, this SegmentInfo must not reference such files when this\n   * method is called, because they are not allowed within a compound file.\n   */\n  final Collection<String> createCompoundFile(String fileName, final SegmentInfo info)\n          throws IOException {\n\n    // Now merge all added files\n    Collection<String> files = info.files();\n    CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, fileName, checkAbort);\n    for (String file : files) {\n      assert !IndexFileNames.matchesExtension(file, IndexFileNames.DELETES_EXTENSION) \n                : \".del file is not allowed in .cfs: \" + file;\n      assert !Pattern.matches(\"^.+[.]\" + IndexFileNames.SEPARATE_NORMS_EXTENSION  + \"\\\\d+$\", file) \n                : \"separate norms file (.s[0-9]*) is not allowed in .cfs: \" + file;\n      cfsWriter.addFile(file);\n    }\n\n    // Perform the merge\n    cfsWriter.close();\n\n    return files;\n  }\n\n","bugFix":["ed004bd98627df9d3b3a1a9ec80423e8d456bdb3"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5128b7b3b73fedff05fdc5ea2e6be53c1020bb91","date":1306767085,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String,SegmentInfo).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String,SegmentInfo).mjava","sourceNew":"  /**\n   * NOTE: this method creates a compound file for all files returned by\n   * info.files(). While, generally, this may include separate norms and\n   * deletion files, this SegmentInfo must not reference such files when this\n   * method is called, because they are not allowed within a compound file.\n   */\n  final Collection<String> createCompoundFile(String fileName, final SegmentInfo info)\n          throws IOException {\n\n    // Now merge all added files\n    Collection<String> files = info.files();\n    CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, fileName, checkAbort);\n    for (String file : files) {\n      assert !IndexFileNames.matchesExtension(file, IndexFileNames.DELETES_EXTENSION) \n                : \".del file is not allowed in .cfs: \" + file;\n      assert !IndexFileNames.isSeparateNormsFile(file) \n                : \"separate norms file (.s[0-9]+) is not allowed in .cfs: \" + file;\n      cfsWriter.addFile(file);\n    }\n\n    // Perform the merge\n    cfsWriter.close();\n\n    return files;\n  }\n\n","sourceOld":"  final Collection<String> createCompoundFile(String fileName, final SegmentInfo info)\n          throws IOException {\n\n    // Now merge all added files\n    Collection<String> files = info.files();\n    CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, fileName, checkAbort);\n    for (String file : files) {\n      cfsWriter.addFile(file);\n    }\n\n    // Perform the merge\n    cfsWriter.close();\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2e10cb22a8bdb44339e282925a29182bb2f3174d","date":1306841137,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String,SegmentInfo).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String,SegmentInfo).mjava","sourceNew":"  /**\n   * NOTE: this method creates a compound file for all files returned by\n   * info.files(). While, generally, this may include separate norms and\n   * deletion files, this SegmentInfo must not reference such files when this\n   * method is called, because they are not allowed within a compound file.\n   */\n  final Collection<String> createCompoundFile(String fileName, final SegmentInfo info)\n          throws IOException {\n\n    // Now merge all added files\n    Collection<String> files = info.files();\n    CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, fileName, checkAbort);\n    for (String file : files) {\n      assert !IndexFileNames.matchesExtension(file, IndexFileNames.DELETES_EXTENSION) \n                : \".del file is not allowed in .cfs: \" + file;\n      assert !IndexFileNames.isSeparateNormsFile(file) \n                : \"separate norms file (.s[0-9]+) is not allowed in .cfs: \" + file;\n      cfsWriter.addFile(file);\n    }\n\n    // Perform the merge\n    cfsWriter.close();\n\n    return files;\n  }\n\n","sourceOld":"  final Collection<String> createCompoundFile(String fileName, final SegmentInfo info)\n          throws IOException {\n\n    // Now merge all added files\n    Collection<String> files = info.files();\n    CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, fileName, checkAbort);\n    for (String file : files) {\n      cfsWriter.addFile(file);\n    }\n\n    // Perform the merge\n    cfsWriter.close();\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"639c36565ce03aed5b0fce7c9e4448e53a1f7efd","date":1308580104,"type":5,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String,SegmentInfo,IOContext).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String,SegmentInfo).mjava","sourceNew":"  /**\n   * NOTE: this method creates a compound file for all files returned by\n   * info.files(). While, generally, this may include separate norms and\n   * deletion files, this SegmentInfo must not reference such files when this\n   * method is called, because they are not allowed within a compound file.\n   */\n  final Collection<String> createCompoundFile(String fileName, final SegmentInfo info, IOContext context)\n          throws IOException {\n\n    // Now merge all added files\n    Collection<String> files = info.files();\n    CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, fileName, context, checkAbort);\n    for (String file : files) {\n      assert !IndexFileNames.matchesExtension(file, IndexFileNames.DELETES_EXTENSION) \n                : \".del file is not allowed in .cfs: \" + file;\n      assert !IndexFileNames.isSeparateNormsFile(file) \n                : \"separate norms file (.s[0-9]+) is not allowed in .cfs: \" + file;\n      cfsWriter.addFile(file);\n    }\n\n    // Perform the merge\n    cfsWriter.close();\n\n    return files;\n  }\n\n","sourceOld":"  /**\n   * NOTE: this method creates a compound file for all files returned by\n   * info.files(). While, generally, this may include separate norms and\n   * deletion files, this SegmentInfo must not reference such files when this\n   * method is called, because they are not allowed within a compound file.\n   */\n  final Collection<String> createCompoundFile(String fileName, final SegmentInfo info)\n          throws IOException {\n\n    // Now merge all added files\n    Collection<String> files = info.files();\n    CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, fileName, checkAbort);\n    for (String file : files) {\n      assert !IndexFileNames.matchesExtension(file, IndexFileNames.DELETES_EXTENSION) \n                : \".del file is not allowed in .cfs: \" + file;\n      assert !IndexFileNames.isSeparateNormsFile(file) \n                : \"separate norms file (.s[0-9]+) is not allowed in .cfs: \" + file;\n      cfsWriter.addFile(file);\n    }\n\n    // Perform the merge\n    cfsWriter.close();\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0aab6e810b4b0d3743d6a048be0602801f4b3920","date":1308671625,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String,SegmentInfo).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String,SegmentInfo).mjava","sourceNew":"  /**\n   * NOTE: this method creates a compound file for all files returned by\n   * info.files(). While, generally, this may include separate norms and\n   * deletion files, this SegmentInfo must not reference such files when this\n   * method is called, because they are not allowed within a compound file.\n   */\n  final Collection<String> createCompoundFile(String fileName, final SegmentInfo info)\n          throws IOException {\n\n    // Now merge all added files\n    Collection<String> files = info.files();\n    CompoundFileDirectory cfsDir = directory.createCompoundOutput(fileName);\n    try {\n      for (String file : files) {\n        assert !IndexFileNames.matchesExtension(file, IndexFileNames.DELETES_EXTENSION) \n                  : \".del file is not allowed in .cfs: \" + file;\n        assert !IndexFileNames.isSeparateNormsFile(file) \n                  : \"separate norms file (.s[0-9]+) is not allowed in .cfs: \" + file;\n        directory.copy(cfsDir, file, file);\n        checkAbort.work(directory.fileLength(file));\n      }\n    } finally {\n      cfsDir.close();\n    }\n\n    return files;\n  }\n\n","sourceOld":"  /**\n   * NOTE: this method creates a compound file for all files returned by\n   * info.files(). While, generally, this may include separate norms and\n   * deletion files, this SegmentInfo must not reference such files when this\n   * method is called, because they are not allowed within a compound file.\n   */\n  final Collection<String> createCompoundFile(String fileName, final SegmentInfo info)\n          throws IOException {\n\n    // Now merge all added files\n    Collection<String> files = info.files();\n    CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, fileName, checkAbort);\n    for (String file : files) {\n      assert !IndexFileNames.matchesExtension(file, IndexFileNames.DELETES_EXTENSION) \n                : \".del file is not allowed in .cfs: \" + file;\n      assert !IndexFileNames.isSeparateNormsFile(file) \n                : \"separate norms file (.s[0-9]+) is not allowed in .cfs: \" + file;\n      cfsWriter.addFile(file);\n    }\n\n    // Perform the merge\n    cfsWriter.close();\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2553b00f699380c64959ccb27991289aae87be2e","date":1309290151,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String,SegmentInfo).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String,SegmentInfo).mjava","sourceNew":"  /**\n   * NOTE: this method creates a compound file for all files returned by\n   * info.files(). While, generally, this may include separate norms and\n   * deletion files, this SegmentInfo must not reference such files when this\n   * method is called, because they are not allowed within a compound file.\n   */\n  final Collection<String> createCompoundFile(String fileName, final SegmentInfo info)\n          throws IOException {\n\n    // Now merge all added files\n    Collection<String> files = info.files();\n    CompoundFileDirectory cfsDir = directory.createCompoundOutput(fileName);\n    try {\n      for (String file : files) {\n        assert !IndexFileNames.matchesExtension(file, IndexFileNames.DELETES_EXTENSION) \n                  : \".del file is not allowed in .cfs: \" + file;\n        assert !IndexFileNames.isSeparateNormsFile(file) \n                  : \"separate norms file (.s[0-9]+) is not allowed in .cfs: \" + file;\n        directory.copy(cfsDir, file, file);\n        checkAbort.work(directory.fileLength(file));\n      }\n    } finally {\n      cfsDir.close();\n    }\n\n    return files;\n  }\n\n","sourceOld":"  /**\n   * NOTE: this method creates a compound file for all files returned by\n   * info.files(). While, generally, this may include separate norms and\n   * deletion files, this SegmentInfo must not reference such files when this\n   * method is called, because they are not allowed within a compound file.\n   */\n  final Collection<String> createCompoundFile(String fileName, final SegmentInfo info)\n          throws IOException {\n\n    // Now merge all added files\n    Collection<String> files = info.files();\n    CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, fileName, checkAbort);\n    for (String file : files) {\n      assert !IndexFileNames.matchesExtension(file, IndexFileNames.DELETES_EXTENSION) \n                : \".del file is not allowed in .cfs: \" + file;\n      assert !IndexFileNames.isSeparateNormsFile(file) \n                : \"separate norms file (.s[0-9]+) is not allowed in .cfs: \" + file;\n      cfsWriter.addFile(file);\n    }\n\n    // Perform the merge\n    cfsWriter.close();\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ddc4c914be86e34b54f70023f45a60fa7f04e929","date":1310115160,"type":5,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String,SegmentInfo,IOContext).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String,SegmentInfo).mjava","sourceNew":"  /**\n   * NOTE: this method creates a compound file for all files returned by\n   * info.files(). While, generally, this may include separate norms and\n   * deletion files, this SegmentInfo must not reference such files when this\n   * method is called, because they are not allowed within a compound file.\n   */\n  final Collection<String> createCompoundFile(String fileName, final SegmentInfo info, IOContext context)\n          throws IOException {\n\n    // Now merge all added files\n    Collection<String> files = info.files();\n    CompoundFileDirectory cfsDir = directory.createCompoundOutput(fileName, context);\n    try {\n      for (String file : files) {\n        assert !IndexFileNames.matchesExtension(file, IndexFileNames.DELETES_EXTENSION) \n                  : \".del file is not allowed in .cfs: \" + file;\n        assert !IndexFileNames.isSeparateNormsFile(file) \n                  : \"separate norms file (.s[0-9]+) is not allowed in .cfs: \" + file;\n        directory.copy(cfsDir, file, file, context);\n        checkAbort.work(directory.fileLength(file));\n      }\n    } finally {\n      cfsDir.close();\n    }\n\n    return files;\n  }\n\n","sourceOld":"  /**\n   * NOTE: this method creates a compound file for all files returned by\n   * info.files(). While, generally, this may include separate norms and\n   * deletion files, this SegmentInfo must not reference such files when this\n   * method is called, because they are not allowed within a compound file.\n   */\n  final Collection<String> createCompoundFile(String fileName, final SegmentInfo info)\n          throws IOException {\n\n    // Now merge all added files\n    Collection<String> files = info.files();\n    CompoundFileDirectory cfsDir = directory.createCompoundOutput(fileName);\n    try {\n      for (String file : files) {\n        assert !IndexFileNames.matchesExtension(file, IndexFileNames.DELETES_EXTENSION) \n                  : \".del file is not allowed in .cfs: \" + file;\n        assert !IndexFileNames.isSeparateNormsFile(file) \n                  : \"separate norms file (.s[0-9]+) is not allowed in .cfs: \" + file;\n        directory.copy(cfsDir, file, file);\n        checkAbort.work(directory.fileLength(file));\n      }\n    } finally {\n      cfsDir.close();\n    }\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5d004d0e0b3f65bb40da76d476d659d7888270e8","date":1310158940,"type":5,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String,SegmentInfo,IOContext).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String,SegmentInfo).mjava","sourceNew":"  /**\n   * NOTE: this method creates a compound file for all files returned by\n   * info.files(). While, generally, this may include separate norms and\n   * deletion files, this SegmentInfo must not reference such files when this\n   * method is called, because they are not allowed within a compound file.\n   */\n  final Collection<String> createCompoundFile(String fileName, final SegmentInfo info, IOContext context)\n          throws IOException {\n\n    // Now merge all added files\n    Collection<String> files = info.files();\n    CompoundFileDirectory cfsDir = directory.createCompoundOutput(fileName, context);\n    try {\n      for (String file : files) {\n        assert !IndexFileNames.matchesExtension(file, IndexFileNames.DELETES_EXTENSION) \n                  : \".del file is not allowed in .cfs: \" + file;\n        assert !IndexFileNames.isSeparateNormsFile(file) \n                  : \"separate norms file (.s[0-9]+) is not allowed in .cfs: \" + file;\n        directory.copy(cfsDir, file, file, context);\n        checkAbort.work(directory.fileLength(file));\n      }\n    } finally {\n      cfsDir.close();\n    }\n\n    return files;\n  }\n\n","sourceOld":"  /**\n   * NOTE: this method creates a compound file for all files returned by\n   * info.files(). While, generally, this may include separate norms and\n   * deletion files, this SegmentInfo must not reference such files when this\n   * method is called, because they are not allowed within a compound file.\n   */\n  final Collection<String> createCompoundFile(String fileName, final SegmentInfo info)\n          throws IOException {\n\n    // Now merge all added files\n    Collection<String> files = info.files();\n    CompoundFileDirectory cfsDir = directory.createCompoundOutput(fileName);\n    try {\n      for (String file : files) {\n        assert !IndexFileNames.matchesExtension(file, IndexFileNames.DELETES_EXTENSION) \n                  : \".del file is not allowed in .cfs: \" + file;\n        assert !IndexFileNames.isSeparateNormsFile(file) \n                  : \"separate norms file (.s[0-9]+) is not allowed in .cfs: \" + file;\n        directory.copy(cfsDir, file, file);\n        checkAbort.work(directory.fileLength(file));\n      }\n    } finally {\n      cfsDir.close();\n    }\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"8cac9bbcf5acbef2d0d83f6e9e32a22d71301db5":["a493e6d0c3ad86bd55c0a1360d110142e948f2bd"],"a493e6d0c3ad86bd55c0a1360d110142e948f2bd":["fb10b6bcde550b87d8f10e5f010bd8f3021023b6"],"955c32f886db6f6356c9fcdea6b1f1cb4effda24":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"639c36565ce03aed5b0fce7c9e4448e53a1f7efd":["57ad8ee2555a290f9ce56ba46049309968819d93"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["833a7987bc1c94455fde83e3311f72bddedcfb93","8cac9bbcf5acbef2d0d83f6e9e32a22d71301db5"],"01f60198ece724a6e96cd0b45f289cf42ff83d4f":["fb10b6bcde550b87d8f10e5f010bd8f3021023b6"],"5128b7b3b73fedff05fdc5ea2e6be53c1020bb91":["a3776dccca01c11e7046323cfad46a3b4a471233","57ad8ee2555a290f9ce56ba46049309968819d93"],"57ad8ee2555a290f9ce56ba46049309968819d93":["ed004bd98627df9d3b3a1a9ec80423e8d456bdb3"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"5d004d0e0b3f65bb40da76d476d659d7888270e8":["2553b00f699380c64959ccb27991289aae87be2e","ddc4c914be86e34b54f70023f45a60fa7f04e929"],"ddc4c914be86e34b54f70023f45a60fa7f04e929":["0aab6e810b4b0d3743d6a048be0602801f4b3920","639c36565ce03aed5b0fce7c9e4448e53a1f7efd"],"fdc49cf4bbf2603a647b53ff5cfa6878743a3ffe":["8cac9bbcf5acbef2d0d83f6e9e32a22d71301db5"],"833a7987bc1c94455fde83e3311f72bddedcfb93":["fb10b6bcde550b87d8f10e5f010bd8f3021023b6"],"2e10cb22a8bdb44339e282925a29182bb2f3174d":["135621f3a0670a9394eb563224a3b76cc4dddc0f","57ad8ee2555a290f9ce56ba46049309968819d93"],"70ad682703b8585f5d0a637efec044d57ec05efb":["3bb13258feba31ab676502787ab2e1779f129b7a","fdc49cf4bbf2603a647b53ff5cfa6878743a3ffe"],"85a883878c0af761245ab048babc63d099f835f3":["0e28c49f1fb6215a550fdadcf3805aa629b63ec0","a493e6d0c3ad86bd55c0a1360d110142e948f2bd"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["70ad682703b8585f5d0a637efec044d57ec05efb","b3e06be49006ecac364d39d12b9c9f74882f9b9f"],"0aab6e810b4b0d3743d6a048be0602801f4b3920":["57ad8ee2555a290f9ce56ba46049309968819d93"],"b3e06be49006ecac364d39d12b9c9f74882f9b9f":["fdc49cf4bbf2603a647b53ff5cfa6878743a3ffe","868da859b43505d9d2a023bfeae6dd0c795f5295"],"ed004bd98627df9d3b3a1a9ec80423e8d456bdb3":["c30fc6c6819ecb25af47f81683b9f52a3122054e"],"2553b00f699380c64959ccb27991289aae87be2e":["5128b7b3b73fedff05fdc5ea2e6be53c1020bb91","0aab6e810b4b0d3743d6a048be0602801f4b3920"],"fb10b6bcde550b87d8f10e5f010bd8f3021023b6":["955c32f886db6f6356c9fcdea6b1f1cb4effda24"],"a3776dccca01c11e7046323cfad46a3b4a471233":["fdc49cf4bbf2603a647b53ff5cfa6878743a3ffe","b3e06be49006ecac364d39d12b9c9f74882f9b9f"],"c30fc6c6819ecb25af47f81683b9f52a3122054e":["b3e06be49006ecac364d39d12b9c9f74882f9b9f"],"868da859b43505d9d2a023bfeae6dd0c795f5295":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","fdc49cf4bbf2603a647b53ff5cfa6878743a3ffe"],"0e28c49f1fb6215a550fdadcf3805aa629b63ec0":["01f60198ece724a6e96cd0b45f289cf42ff83d4f"],"3bb13258feba31ab676502787ab2e1779f129b7a":["85a883878c0af761245ab048babc63d099f835f3","8cac9bbcf5acbef2d0d83f6e9e32a22d71301db5"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["ddc4c914be86e34b54f70023f45a60fa7f04e929"]},"commit2Childs":{"8cac9bbcf5acbef2d0d83f6e9e32a22d71301db5":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","fdc49cf4bbf2603a647b53ff5cfa6878743a3ffe","3bb13258feba31ab676502787ab2e1779f129b7a"],"a493e6d0c3ad86bd55c0a1360d110142e948f2bd":["8cac9bbcf5acbef2d0d83f6e9e32a22d71301db5","85a883878c0af761245ab048babc63d099f835f3"],"955c32f886db6f6356c9fcdea6b1f1cb4effda24":["fb10b6bcde550b87d8f10e5f010bd8f3021023b6"],"639c36565ce03aed5b0fce7c9e4448e53a1f7efd":["ddc4c914be86e34b54f70023f45a60fa7f04e929"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["868da859b43505d9d2a023bfeae6dd0c795f5295"],"01f60198ece724a6e96cd0b45f289cf42ff83d4f":["0e28c49f1fb6215a550fdadcf3805aa629b63ec0"],"5128b7b3b73fedff05fdc5ea2e6be53c1020bb91":["2553b00f699380c64959ccb27991289aae87be2e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["955c32f886db6f6356c9fcdea6b1f1cb4effda24"],"57ad8ee2555a290f9ce56ba46049309968819d93":["639c36565ce03aed5b0fce7c9e4448e53a1f7efd","5128b7b3b73fedff05fdc5ea2e6be53c1020bb91","2e10cb22a8bdb44339e282925a29182bb2f3174d","0aab6e810b4b0d3743d6a048be0602801f4b3920"],"5d004d0e0b3f65bb40da76d476d659d7888270e8":[],"ddc4c914be86e34b54f70023f45a60fa7f04e929":["5d004d0e0b3f65bb40da76d476d659d7888270e8","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"fdc49cf4bbf2603a647b53ff5cfa6878743a3ffe":["70ad682703b8585f5d0a637efec044d57ec05efb","b3e06be49006ecac364d39d12b9c9f74882f9b9f","a3776dccca01c11e7046323cfad46a3b4a471233","868da859b43505d9d2a023bfeae6dd0c795f5295"],"833a7987bc1c94455fde83e3311f72bddedcfb93":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"2e10cb22a8bdb44339e282925a29182bb2f3174d":[],"70ad682703b8585f5d0a637efec044d57ec05efb":["135621f3a0670a9394eb563224a3b76cc4dddc0f"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["2e10cb22a8bdb44339e282925a29182bb2f3174d"],"85a883878c0af761245ab048babc63d099f835f3":["3bb13258feba31ab676502787ab2e1779f129b7a"],"0aab6e810b4b0d3743d6a048be0602801f4b3920":["ddc4c914be86e34b54f70023f45a60fa7f04e929","2553b00f699380c64959ccb27991289aae87be2e"],"b3e06be49006ecac364d39d12b9c9f74882f9b9f":["135621f3a0670a9394eb563224a3b76cc4dddc0f","a3776dccca01c11e7046323cfad46a3b4a471233","c30fc6c6819ecb25af47f81683b9f52a3122054e"],"ed004bd98627df9d3b3a1a9ec80423e8d456bdb3":["57ad8ee2555a290f9ce56ba46049309968819d93"],"2553b00f699380c64959ccb27991289aae87be2e":["5d004d0e0b3f65bb40da76d476d659d7888270e8"],"fb10b6bcde550b87d8f10e5f010bd8f3021023b6":["a493e6d0c3ad86bd55c0a1360d110142e948f2bd","01f60198ece724a6e96cd0b45f289cf42ff83d4f","833a7987bc1c94455fde83e3311f72bddedcfb93"],"a3776dccca01c11e7046323cfad46a3b4a471233":["5128b7b3b73fedff05fdc5ea2e6be53c1020bb91"],"c30fc6c6819ecb25af47f81683b9f52a3122054e":["ed004bd98627df9d3b3a1a9ec80423e8d456bdb3"],"0e28c49f1fb6215a550fdadcf3805aa629b63ec0":["85a883878c0af761245ab048babc63d099f835f3"],"868da859b43505d9d2a023bfeae6dd0c795f5295":["b3e06be49006ecac364d39d12b9c9f74882f9b9f"],"3bb13258feba31ab676502787ab2e1779f129b7a":["70ad682703b8585f5d0a637efec044d57ec05efb"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["5d004d0e0b3f65bb40da76d476d659d7888270e8","2e10cb22a8bdb44339e282925a29182bb2f3174d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}