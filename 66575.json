{"path":"lucene/core/src/java/org/apache/lucene/index/FrozenBufferedUpdates#forceApply(IndexWriter).mjava","commits":[{"id":"72332a99ce230f8edf8404d6043ac18a0e26dfeb","date":1542806419,"type":0,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FrozenBufferedUpdates#forceApply(IndexWriter).mjava","pathOld":"/dev/null","sourceNew":"  /** Translates a frozen packet of delete term/query, or doc values\n   *  updates, into their actual docIDs in the index, and applies the change.  This is a heavy\n   *  operation and is done concurrently by incoming indexing threads.\n   *  */\n  void forceApply(IndexWriter writer) throws IOException {\n    applyLock.lock();\n    try {\n      if (applied.getCount() == 0) {\n        // already done\n        return;\n      }\n      long startNS = System.nanoTime();\n\n      assert any();\n\n      Set<SegmentCommitInfo> seenSegments = new HashSet<>();\n\n      int iter = 0;\n      int totalSegmentCount = 0;\n      long totalDelCount = 0;\n\n      boolean finished = false;\n\n      // Optimistic concurrency: assume we are free to resolve the deletes against all current segments in the index, despite that\n      // concurrent merges are running.  Once we are done, we check to see if a merge completed while we were running.  If so, we must retry\n      // resolving against the newly merged segment(s).  Eventually no merge finishes while we were running and we are done.\n      while (true) {\n        String messagePrefix;\n        if (iter == 0) {\n          messagePrefix = \"\";\n        } else {\n          messagePrefix = \"iter \" + iter;\n        }\n\n        long iterStartNS = System.nanoTime();\n\n        long mergeGenStart = writer.mergeFinishedGen.get();\n\n        Set<String> delFiles = new HashSet<>();\n        BufferedUpdatesStream.SegmentState[] segStates;\n\n        synchronized (writer) {\n          List<SegmentCommitInfo> infos = getInfosToApply(writer);\n          if (infos == null) {\n            break;\n          }\n\n          for (SegmentCommitInfo info : infos) {\n            delFiles.addAll(info.files());\n          }\n\n          // Must open while holding IW lock so that e.g. segments are not merged\n          // away, dropped from 100% deletions, etc., before we can open the readers\n          segStates = openSegmentStates(writer, infos, seenSegments, delGen());\n\n          if (segStates.length == 0) {\n\n            if (infoStream.isEnabled(\"BD\")) {\n              infoStream.message(\"BD\", \"packet matches no segments\");\n            }\n            break;\n          }\n\n          if (infoStream.isEnabled(\"BD\")) {\n            infoStream.message(\"BD\", String.format(Locale.ROOT,\n                messagePrefix + \"now apply del packet (%s) to %d segments, mergeGen %d\",\n                this, segStates.length, mergeGenStart));\n          }\n\n          totalSegmentCount += segStates.length;\n\n          // Important, else IFD may try to delete our files while we are still using them,\n          // if e.g. a merge finishes on some of the segments we are resolving on:\n          writer.deleter.incRef(delFiles);\n        }\n\n        AtomicBoolean success = new AtomicBoolean();\n        long delCount;\n        try (Closeable finalizer = () -> finishApply(writer, segStates, success.get(), delFiles)) {\n          // don't hold IW monitor lock here so threads are free concurrently resolve deletes/updates:\n          delCount = apply(segStates);\n          success.set(true);\n        }\n\n        // Since we just resolved some more deletes/updates, now is a good time to write them:\n        writer.writeSomeDocValuesUpdates();\n\n        // It's OK to add this here, even if the while loop retries, because delCount only includes newly\n        // deleted documents, on the segments we didn't already do in previous iterations:\n        totalDelCount += delCount;\n\n        if (infoStream.isEnabled(\"BD\")) {\n          infoStream.message(\"BD\", String.format(Locale.ROOT,\n              messagePrefix + \"done inner apply del packet (%s) to %d segments; %d new deletes/updates; took %.3f sec\",\n              this, segStates.length, delCount, (System.nanoTime() - iterStartNS) / 1000000000.));\n        }\n        if (privateSegment != null) {\n          // No need to retry for a segment-private packet: the merge that folds in our private segment already waits for all deletes to\n          // be applied before it kicks off, so this private segment must already not be in the set of merging segments\n\n          break;\n        }\n\n        // Must sync on writer here so that IW.mergeCommit is not running concurrently, so that if we exit, we know mergeCommit will succeed\n        // in pulling all our delGens into a merge:\n        synchronized (writer) {\n          long mergeGenCur = writer.mergeFinishedGen.get();\n\n          if (mergeGenCur == mergeGenStart) {\n\n            // Must do this while still holding IW lock else a merge could finish and skip carrying over our updates:\n\n            // Record that this packet is finished:\n            writer.finished(this);\n\n            finished = true;\n\n            // No merge finished while we were applying, so we are done!\n            break;\n          }\n        }\n\n        if (infoStream.isEnabled(\"BD\")) {\n          infoStream.message(\"BD\", messagePrefix + \"concurrent merges finished; move to next iter\");\n        }\n\n        // A merge completed while we were running.  In this case, that merge may have picked up some of the updates we did, but not\n        // necessarily all of them, so we cycle again, re-applying all our updates to the newly merged segment.\n\n        iter++;\n      }\n\n      if (finished == false) {\n        // Record that this packet is finished:\n        writer.finished(this);\n      }\n\n      if (infoStream.isEnabled(\"BD\")) {\n        String message = String.format(Locale.ROOT,\n            \"done apply del packet (%s) to %d segments; %d new deletes/updates; took %.3f sec\",\n            this, totalSegmentCount, totalDelCount, (System.nanoTime() - startNS) / 1000000000.);\n        if (iter > 0) {\n          message += \"; \" + (iter + 1) + \" iters due to concurrent merges\";\n        }\n        message += \"; \" + writer.getPendingUpdatesCount() + \" packets remain\";\n        infoStream.message(\"BD\", message);\n      }\n    } finally {\n      applyLock.unlock();\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ee67a99e7e36da49a4b68758a01d1ac09ff5472c","date":1547653069,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FrozenBufferedUpdates#forceApply(IndexWriter).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FrozenBufferedUpdates#forceApply(IndexWriter).mjava","sourceNew":"  /** Translates a frozen packet of delete term/query, or doc values\n   *  updates, into their actual docIDs in the index, and applies the change.  This is a heavy\n   *  operation and is done concurrently by incoming indexing threads.\n   *  */\n  void forceApply(IndexWriter writer) throws IOException {\n    applyLock.lock();\n    try {\n      if (applied.getCount() == 0) {\n        // already done\n        return;\n      }\n      long startNS = System.nanoTime();\n\n      assert any();\n\n      Set<SegmentCommitInfo> seenSegments = new HashSet<>();\n\n      int iter = 0;\n      int totalSegmentCount = 0;\n      long totalDelCount = 0;\n\n      boolean finished = false;\n\n      // Optimistic concurrency: assume we are free to resolve the deletes against all current segments in the index, despite that\n      // concurrent merges are running.  Once we are done, we check to see if a merge completed while we were running.  If so, we must retry\n      // resolving against the newly merged segment(s).  Eventually no merge finishes while we were running and we are done.\n      while (true) {\n        String messagePrefix;\n        if (iter == 0) {\n          messagePrefix = \"\";\n        } else {\n          messagePrefix = \"iter \" + iter;\n        }\n\n        long iterStartNS = System.nanoTime();\n\n        long mergeGenStart = writer.mergeFinishedGen.get();\n\n        Set<String> delFiles = new HashSet<>();\n        BufferedUpdatesStream.SegmentState[] segStates;\n\n        synchronized (writer) {\n          List<SegmentCommitInfo> infos = getInfosToApply(writer);\n          if (infos == null) {\n            break;\n          }\n\n          for (SegmentCommitInfo info : infos) {\n            delFiles.addAll(info.files());\n          }\n\n          // Must open while holding IW lock so that e.g. segments are not merged\n          // away, dropped from 100% deletions, etc., before we can open the readers\n          segStates = openSegmentStates(writer, infos, seenSegments, delGen());\n\n          if (segStates.length == 0) {\n\n            if (infoStream.isEnabled(\"BD\")) {\n              infoStream.message(\"BD\", \"packet matches no segments\");\n            }\n            break;\n          }\n\n          if (infoStream.isEnabled(\"BD\")) {\n            infoStream.message(\"BD\", String.format(Locale.ROOT,\n                messagePrefix + \"now apply del packet (%s) to %d segments, mergeGen %d\",\n                this, segStates.length, mergeGenStart));\n          }\n\n          totalSegmentCount += segStates.length;\n\n          // Important, else IFD may try to delete our files while we are still using them,\n          // if e.g. a merge finishes on some of the segments we are resolving on:\n          writer.deleter.incRef(delFiles);\n        }\n\n        AtomicBoolean success = new AtomicBoolean();\n        long delCount;\n        try (Closeable finalizer = () -> finishApply(writer, segStates, success.get(), delFiles)) {\n          assert finalizer != null; // access the finalizer to prevent a warning\n          // don't hold IW monitor lock here so threads are free concurrently resolve deletes/updates:\n          delCount = apply(segStates);\n          success.set(true);\n        }\n\n        // Since we just resolved some more deletes/updates, now is a good time to write them:\n        writer.writeSomeDocValuesUpdates();\n\n        // It's OK to add this here, even if the while loop retries, because delCount only includes newly\n        // deleted documents, on the segments we didn't already do in previous iterations:\n        totalDelCount += delCount;\n\n        if (infoStream.isEnabled(\"BD\")) {\n          infoStream.message(\"BD\", String.format(Locale.ROOT,\n              messagePrefix + \"done inner apply del packet (%s) to %d segments; %d new deletes/updates; took %.3f sec\",\n              this, segStates.length, delCount, (System.nanoTime() - iterStartNS) / 1000000000.));\n        }\n        if (privateSegment != null) {\n          // No need to retry for a segment-private packet: the merge that folds in our private segment already waits for all deletes to\n          // be applied before it kicks off, so this private segment must already not be in the set of merging segments\n\n          break;\n        }\n\n        // Must sync on writer here so that IW.mergeCommit is not running concurrently, so that if we exit, we know mergeCommit will succeed\n        // in pulling all our delGens into a merge:\n        synchronized (writer) {\n          long mergeGenCur = writer.mergeFinishedGen.get();\n\n          if (mergeGenCur == mergeGenStart) {\n\n            // Must do this while still holding IW lock else a merge could finish and skip carrying over our updates:\n\n            // Record that this packet is finished:\n            writer.finished(this);\n\n            finished = true;\n\n            // No merge finished while we were applying, so we are done!\n            break;\n          }\n        }\n\n        if (infoStream.isEnabled(\"BD\")) {\n          infoStream.message(\"BD\", messagePrefix + \"concurrent merges finished; move to next iter\");\n        }\n\n        // A merge completed while we were running.  In this case, that merge may have picked up some of the updates we did, but not\n        // necessarily all of them, so we cycle again, re-applying all our updates to the newly merged segment.\n\n        iter++;\n      }\n\n      if (finished == false) {\n        // Record that this packet is finished:\n        writer.finished(this);\n      }\n\n      if (infoStream.isEnabled(\"BD\")) {\n        String message = String.format(Locale.ROOT,\n            \"done apply del packet (%s) to %d segments; %d new deletes/updates; took %.3f sec\",\n            this, totalSegmentCount, totalDelCount, (System.nanoTime() - startNS) / 1000000000.);\n        if (iter > 0) {\n          message += \"; \" + (iter + 1) + \" iters due to concurrent merges\";\n        }\n        message += \"; \" + writer.getPendingUpdatesCount() + \" packets remain\";\n        infoStream.message(\"BD\", message);\n      }\n    } finally {\n      applyLock.unlock();\n    }\n  }\n\n","sourceOld":"  /** Translates a frozen packet of delete term/query, or doc values\n   *  updates, into their actual docIDs in the index, and applies the change.  This is a heavy\n   *  operation and is done concurrently by incoming indexing threads.\n   *  */\n  void forceApply(IndexWriter writer) throws IOException {\n    applyLock.lock();\n    try {\n      if (applied.getCount() == 0) {\n        // already done\n        return;\n      }\n      long startNS = System.nanoTime();\n\n      assert any();\n\n      Set<SegmentCommitInfo> seenSegments = new HashSet<>();\n\n      int iter = 0;\n      int totalSegmentCount = 0;\n      long totalDelCount = 0;\n\n      boolean finished = false;\n\n      // Optimistic concurrency: assume we are free to resolve the deletes against all current segments in the index, despite that\n      // concurrent merges are running.  Once we are done, we check to see if a merge completed while we were running.  If so, we must retry\n      // resolving against the newly merged segment(s).  Eventually no merge finishes while we were running and we are done.\n      while (true) {\n        String messagePrefix;\n        if (iter == 0) {\n          messagePrefix = \"\";\n        } else {\n          messagePrefix = \"iter \" + iter;\n        }\n\n        long iterStartNS = System.nanoTime();\n\n        long mergeGenStart = writer.mergeFinishedGen.get();\n\n        Set<String> delFiles = new HashSet<>();\n        BufferedUpdatesStream.SegmentState[] segStates;\n\n        synchronized (writer) {\n          List<SegmentCommitInfo> infos = getInfosToApply(writer);\n          if (infos == null) {\n            break;\n          }\n\n          for (SegmentCommitInfo info : infos) {\n            delFiles.addAll(info.files());\n          }\n\n          // Must open while holding IW lock so that e.g. segments are not merged\n          // away, dropped from 100% deletions, etc., before we can open the readers\n          segStates = openSegmentStates(writer, infos, seenSegments, delGen());\n\n          if (segStates.length == 0) {\n\n            if (infoStream.isEnabled(\"BD\")) {\n              infoStream.message(\"BD\", \"packet matches no segments\");\n            }\n            break;\n          }\n\n          if (infoStream.isEnabled(\"BD\")) {\n            infoStream.message(\"BD\", String.format(Locale.ROOT,\n                messagePrefix + \"now apply del packet (%s) to %d segments, mergeGen %d\",\n                this, segStates.length, mergeGenStart));\n          }\n\n          totalSegmentCount += segStates.length;\n\n          // Important, else IFD may try to delete our files while we are still using them,\n          // if e.g. a merge finishes on some of the segments we are resolving on:\n          writer.deleter.incRef(delFiles);\n        }\n\n        AtomicBoolean success = new AtomicBoolean();\n        long delCount;\n        try (Closeable finalizer = () -> finishApply(writer, segStates, success.get(), delFiles)) {\n          // don't hold IW monitor lock here so threads are free concurrently resolve deletes/updates:\n          delCount = apply(segStates);\n          success.set(true);\n        }\n\n        // Since we just resolved some more deletes/updates, now is a good time to write them:\n        writer.writeSomeDocValuesUpdates();\n\n        // It's OK to add this here, even if the while loop retries, because delCount only includes newly\n        // deleted documents, on the segments we didn't already do in previous iterations:\n        totalDelCount += delCount;\n\n        if (infoStream.isEnabled(\"BD\")) {\n          infoStream.message(\"BD\", String.format(Locale.ROOT,\n              messagePrefix + \"done inner apply del packet (%s) to %d segments; %d new deletes/updates; took %.3f sec\",\n              this, segStates.length, delCount, (System.nanoTime() - iterStartNS) / 1000000000.));\n        }\n        if (privateSegment != null) {\n          // No need to retry for a segment-private packet: the merge that folds in our private segment already waits for all deletes to\n          // be applied before it kicks off, so this private segment must already not be in the set of merging segments\n\n          break;\n        }\n\n        // Must sync on writer here so that IW.mergeCommit is not running concurrently, so that if we exit, we know mergeCommit will succeed\n        // in pulling all our delGens into a merge:\n        synchronized (writer) {\n          long mergeGenCur = writer.mergeFinishedGen.get();\n\n          if (mergeGenCur == mergeGenStart) {\n\n            // Must do this while still holding IW lock else a merge could finish and skip carrying over our updates:\n\n            // Record that this packet is finished:\n            writer.finished(this);\n\n            finished = true;\n\n            // No merge finished while we were applying, so we are done!\n            break;\n          }\n        }\n\n        if (infoStream.isEnabled(\"BD\")) {\n          infoStream.message(\"BD\", messagePrefix + \"concurrent merges finished; move to next iter\");\n        }\n\n        // A merge completed while we were running.  In this case, that merge may have picked up some of the updates we did, but not\n        // necessarily all of them, so we cycle again, re-applying all our updates to the newly merged segment.\n\n        iter++;\n      }\n\n      if (finished == false) {\n        // Record that this packet is finished:\n        writer.finished(this);\n      }\n\n      if (infoStream.isEnabled(\"BD\")) {\n        String message = String.format(Locale.ROOT,\n            \"done apply del packet (%s) to %d segments; %d new deletes/updates; took %.3f sec\",\n            this, totalSegmentCount, totalDelCount, (System.nanoTime() - startNS) / 1000000000.);\n        if (iter > 0) {\n          message += \"; \" + (iter + 1) + \" iters due to concurrent merges\";\n        }\n        message += \"; \" + writer.getPendingUpdatesCount() + \" packets remain\";\n        infoStream.message(\"BD\", message);\n      }\n    } finally {\n      applyLock.unlock();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9f21f1920c232db2352489eed260fe5c1f39e5a0","date":1587748041,"type":5,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#forceApply(FrozenBufferedUpdates).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FrozenBufferedUpdates#forceApply(IndexWriter).mjava","sourceNew":"  /**\n   * Translates a frozen packet of delete term/query, or doc values\n   * updates, into their actual docIDs in the index, and applies the change.  This is a heavy\n   * operation and is done concurrently by incoming indexing threads.\n   */\n  void forceApply(FrozenBufferedUpdates updates) throws IOException {\n    updates.lock();\n    try {\n      if (updates.isApplied()) {\n        // already done\n        return;\n      }\n      long startNS = System.nanoTime();\n\n      assert updates.any();\n\n      Set<SegmentCommitInfo> seenSegments = new HashSet<>();\n\n      int iter = 0;\n      int totalSegmentCount = 0;\n      long totalDelCount = 0;\n\n      boolean finished = false;\n\n      // Optimistic concurrency: assume we are free to resolve the deletes against all current segments in the index, despite that\n      // concurrent merges are running.  Once we are done, we check to see if a merge completed while we were running.  If so, we must retry\n      // resolving against the newly merged segment(s).  Eventually no merge finishes while we were running and we are done.\n      while (true) {\n        String messagePrefix;\n        if (iter == 0) {\n          messagePrefix = \"\";\n        } else {\n          messagePrefix = \"iter \" + iter;\n        }\n\n        long iterStartNS = System.nanoTime();\n\n        long mergeGenStart = mergeFinishedGen.get();\n\n        Set<String> delFiles = new HashSet<>();\n        BufferedUpdatesStream.SegmentState[] segStates;\n\n        synchronized (this) {\n          List<SegmentCommitInfo> infos = getInfosToApply(updates);\n          if (infos == null) {\n            break;\n          }\n\n          for (SegmentCommitInfo info : infos) {\n            delFiles.addAll(info.files());\n          }\n\n          // Must open while holding IW lock so that e.g. segments are not merged\n          // away, dropped from 100% deletions, etc., before we can open the readers\n          segStates = openSegmentStates(infos, seenSegments, updates.delGen());\n\n          if (segStates.length == 0) {\n\n            if (infoStream.isEnabled(\"BD\")) {\n              infoStream.message(\"BD\", \"packet matches no segments\");\n            }\n            break;\n          }\n\n          if (infoStream.isEnabled(\"BD\")) {\n            infoStream.message(\"BD\", String.format(Locale.ROOT,\n                messagePrefix + \"now apply del packet (%s) to %d segments, mergeGen %d\",\n                this, segStates.length, mergeGenStart));\n          }\n\n          totalSegmentCount += segStates.length;\n\n          // Important, else IFD may try to delete our files while we are still using them,\n          // if e.g. a merge finishes on some of the segments we are resolving on:\n          deleter.incRef(delFiles);\n        }\n\n        AtomicBoolean success = new AtomicBoolean();\n        long delCount;\n        try (Closeable finalizer = () -> finishApply(segStates, success.get(), delFiles)) {\n          assert finalizer != null; // access the finalizer to prevent a warning\n          // don't hold IW monitor lock here so threads are free concurrently resolve deletes/updates:\n          delCount = updates.apply(segStates);\n          success.set(true);\n        }\n\n        // Since we just resolved some more deletes/updates, now is a good time to write them:\n        writeSomeDocValuesUpdates();\n\n        // It's OK to add this here, even if the while loop retries, because delCount only includes newly\n        // deleted documents, on the segments we didn't already do in previous iterations:\n        totalDelCount += delCount;\n\n        if (infoStream.isEnabled(\"BD\")) {\n          infoStream.message(\"BD\", String.format(Locale.ROOT,\n              messagePrefix + \"done inner apply del packet (%s) to %d segments; %d new deletes/updates; took %.3f sec\",\n              this, segStates.length, delCount, (System.nanoTime() - iterStartNS) / 1000000000.));\n        }\n        if (updates.privateSegment != null) {\n          // No need to retry for a segment-private packet: the merge that folds in our private segment already waits for all deletes to\n          // be applied before it kicks off, so this private segment must already not be in the set of merging segments\n\n          break;\n        }\n\n        // Must sync on writer here so that IW.mergeCommit is not running concurrently, so that if we exit, we know mergeCommit will succeed\n        // in pulling all our delGens into a merge:\n        synchronized (this) {\n          long mergeGenCur = mergeFinishedGen.get();\n\n          if (mergeGenCur == mergeGenStart) {\n\n            // Must do this while still holding IW lock else a merge could finish and skip carrying over our updates:\n\n            // Record that this packet is finished:\n            bufferedUpdatesStream.finished(updates);\n\n            finished = true;\n\n            // No merge finished while we were applying, so we are done!\n            break;\n          }\n        }\n\n        if (infoStream.isEnabled(\"BD\")) {\n          infoStream.message(\"BD\", messagePrefix + \"concurrent merges finished; move to next iter\");\n        }\n\n        // A merge completed while we were running.  In this case, that merge may have picked up some of the updates we did, but not\n        // necessarily all of them, so we cycle again, re-applying all our updates to the newly merged segment.\n\n        iter++;\n      }\n\n      if (finished == false) {\n        // Record that this packet is finished:\n        bufferedUpdatesStream.finished(updates);\n      }\n\n      if (infoStream.isEnabled(\"BD\")) {\n        String message = String.format(Locale.ROOT,\n            \"done apply del packet (%s) to %d segments; %d new deletes/updates; took %.3f sec\",\n            this, totalSegmentCount, totalDelCount, (System.nanoTime() - startNS) / 1000000000.);\n        if (iter > 0) {\n          message += \"; \" + (iter + 1) + \" iters due to concurrent merges\";\n        }\n        message += \"; \" + bufferedUpdatesStream.getPendingUpdatesCount() + \" packets remain\";\n        infoStream.message(\"BD\", message);\n      }\n    } finally {\n      updates.unlock();\n    }\n  }\n\n","sourceOld":"  /** Translates a frozen packet of delete term/query, or doc values\n   *  updates, into their actual docIDs in the index, and applies the change.  This is a heavy\n   *  operation and is done concurrently by incoming indexing threads.\n   *  */\n  void forceApply(IndexWriter writer) throws IOException {\n    applyLock.lock();\n    try {\n      if (applied.getCount() == 0) {\n        // already done\n        return;\n      }\n      long startNS = System.nanoTime();\n\n      assert any();\n\n      Set<SegmentCommitInfo> seenSegments = new HashSet<>();\n\n      int iter = 0;\n      int totalSegmentCount = 0;\n      long totalDelCount = 0;\n\n      boolean finished = false;\n\n      // Optimistic concurrency: assume we are free to resolve the deletes against all current segments in the index, despite that\n      // concurrent merges are running.  Once we are done, we check to see if a merge completed while we were running.  If so, we must retry\n      // resolving against the newly merged segment(s).  Eventually no merge finishes while we were running and we are done.\n      while (true) {\n        String messagePrefix;\n        if (iter == 0) {\n          messagePrefix = \"\";\n        } else {\n          messagePrefix = \"iter \" + iter;\n        }\n\n        long iterStartNS = System.nanoTime();\n\n        long mergeGenStart = writer.mergeFinishedGen.get();\n\n        Set<String> delFiles = new HashSet<>();\n        BufferedUpdatesStream.SegmentState[] segStates;\n\n        synchronized (writer) {\n          List<SegmentCommitInfo> infos = getInfosToApply(writer);\n          if (infos == null) {\n            break;\n          }\n\n          for (SegmentCommitInfo info : infos) {\n            delFiles.addAll(info.files());\n          }\n\n          // Must open while holding IW lock so that e.g. segments are not merged\n          // away, dropped from 100% deletions, etc., before we can open the readers\n          segStates = openSegmentStates(writer, infos, seenSegments, delGen());\n\n          if (segStates.length == 0) {\n\n            if (infoStream.isEnabled(\"BD\")) {\n              infoStream.message(\"BD\", \"packet matches no segments\");\n            }\n            break;\n          }\n\n          if (infoStream.isEnabled(\"BD\")) {\n            infoStream.message(\"BD\", String.format(Locale.ROOT,\n                messagePrefix + \"now apply del packet (%s) to %d segments, mergeGen %d\",\n                this, segStates.length, mergeGenStart));\n          }\n\n          totalSegmentCount += segStates.length;\n\n          // Important, else IFD may try to delete our files while we are still using them,\n          // if e.g. a merge finishes on some of the segments we are resolving on:\n          writer.deleter.incRef(delFiles);\n        }\n\n        AtomicBoolean success = new AtomicBoolean();\n        long delCount;\n        try (Closeable finalizer = () -> finishApply(writer, segStates, success.get(), delFiles)) {\n          assert finalizer != null; // access the finalizer to prevent a warning\n          // don't hold IW monitor lock here so threads are free concurrently resolve deletes/updates:\n          delCount = apply(segStates);\n          success.set(true);\n        }\n\n        // Since we just resolved some more deletes/updates, now is a good time to write them:\n        writer.writeSomeDocValuesUpdates();\n\n        // It's OK to add this here, even if the while loop retries, because delCount only includes newly\n        // deleted documents, on the segments we didn't already do in previous iterations:\n        totalDelCount += delCount;\n\n        if (infoStream.isEnabled(\"BD\")) {\n          infoStream.message(\"BD\", String.format(Locale.ROOT,\n              messagePrefix + \"done inner apply del packet (%s) to %d segments; %d new deletes/updates; took %.3f sec\",\n              this, segStates.length, delCount, (System.nanoTime() - iterStartNS) / 1000000000.));\n        }\n        if (privateSegment != null) {\n          // No need to retry for a segment-private packet: the merge that folds in our private segment already waits for all deletes to\n          // be applied before it kicks off, so this private segment must already not be in the set of merging segments\n\n          break;\n        }\n\n        // Must sync on writer here so that IW.mergeCommit is not running concurrently, so that if we exit, we know mergeCommit will succeed\n        // in pulling all our delGens into a merge:\n        synchronized (writer) {\n          long mergeGenCur = writer.mergeFinishedGen.get();\n\n          if (mergeGenCur == mergeGenStart) {\n\n            // Must do this while still holding IW lock else a merge could finish and skip carrying over our updates:\n\n            // Record that this packet is finished:\n            writer.finished(this);\n\n            finished = true;\n\n            // No merge finished while we were applying, so we are done!\n            break;\n          }\n        }\n\n        if (infoStream.isEnabled(\"BD\")) {\n          infoStream.message(\"BD\", messagePrefix + \"concurrent merges finished; move to next iter\");\n        }\n\n        // A merge completed while we were running.  In this case, that merge may have picked up some of the updates we did, but not\n        // necessarily all of them, so we cycle again, re-applying all our updates to the newly merged segment.\n\n        iter++;\n      }\n\n      if (finished == false) {\n        // Record that this packet is finished:\n        writer.finished(this);\n      }\n\n      if (infoStream.isEnabled(\"BD\")) {\n        String message = String.format(Locale.ROOT,\n            \"done apply del packet (%s) to %d segments; %d new deletes/updates; took %.3f sec\",\n            this, totalSegmentCount, totalDelCount, (System.nanoTime() - startNS) / 1000000000.);\n        if (iter > 0) {\n          message += \"; \" + (iter + 1) + \" iters due to concurrent merges\";\n        }\n        message += \"; \" + writer.getPendingUpdatesCount() + \" packets remain\";\n        infoStream.message(\"BD\", message);\n      }\n    } finally {\n      applyLock.unlock();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"9f21f1920c232db2352489eed260fe5c1f39e5a0":["ee67a99e7e36da49a4b68758a01d1ac09ff5472c"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"ee67a99e7e36da49a4b68758a01d1ac09ff5472c":["72332a99ce230f8edf8404d6043ac18a0e26dfeb"],"72332a99ce230f8edf8404d6043ac18a0e26dfeb":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9f21f1920c232db2352489eed260fe5c1f39e5a0"]},"commit2Childs":{"9f21f1920c232db2352489eed260fe5c1f39e5a0":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["72332a99ce230f8edf8404d6043ac18a0e26dfeb"],"ee67a99e7e36da49a4b68758a01d1ac09ff5472c":["9f21f1920c232db2352489eed260fe5c1f39e5a0"],"72332a99ce230f8edf8404d6043ac18a0e26dfeb":["ee67a99e7e36da49a4b68758a01d1ac09ff5472c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}