{"path":"lucene/suggest/src/java/org/apache/lucene/search/suggest/document/CompletionTokenStream#toAutomaton(boolean).mjava","commits":[{"id":"8c33f6677a2078739058f81eca1df69d12cd62b0","date":1432799589,"type":1,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/document/CompletionTokenStream#toAutomaton(boolean).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/document/CompletionTokenStream#toAutomaton(TokenStream).mjava","sourceNew":"  /**\n   * Converts the tokenStream to an automaton\n   */\n  public Automaton toAutomaton(boolean unicodeAware) throws IOException {\n    // TODO refactor this\n    // maybe we could hook up a modified automaton from TermAutomatonQuery here?\n    Automaton automaton = null;\n    try {\n      // Create corresponding automaton: labels are bytes\n      // from each analyzed token, with byte 0 used as\n      // separator between tokens:\n      final TokenStreamToAutomaton tsta;\n      if (preserveSep) {\n        tsta = new EscapingTokenStreamToAutomaton((char) SEP_LABEL);\n      } else {\n        // When we're not preserving sep, we don't steal 0xff\n        // byte, so we don't need to do any escaping:\n        tsta = new TokenStreamToAutomaton();\n      }\n      tsta.setPreservePositionIncrements(preservePositionIncrements);\n      tsta.setUnicodeArcs(unicodeAware);\n\n      automaton = tsta.toAutomaton(input);\n    } finally {\n      IOUtils.closeWhileHandlingException(input);\n    }\n\n    // TODO: we can optimize this somewhat by determinizing\n    // while we convert\n    automaton = replaceSep(automaton, preserveSep, SEP_LABEL);\n    // This automaton should not blow up during determinize:\n    return Operations.determinize(automaton, maxGraphExpansions);\n  }\n\n","sourceOld":"  /**\n   * Converts <code>tokenStream</code> to an automaton\n   */\n  public Automaton toAutomaton(TokenStream tokenStream) throws IOException {\n    // TODO refactor this\n    // maybe we could hook up a modified automaton from TermAutomatonQuery here?\n    Automaton automaton = null;\n    try {\n      // Create corresponding automaton: labels are bytes\n      // from each analyzed token, with byte 0 used as\n      // separator between tokens:\n      final TokenStreamToAutomaton tsta;\n      if (preserveSep) {\n        tsta = new EscapingTokenStreamToAutomaton((char) SEP_LABEL);\n      } else {\n        // When we're not preserving sep, we don't steal 0xff\n        // byte, so we don't need to do any escaping:\n        tsta = new TokenStreamToAutomaton();\n      }\n      tsta.setPreservePositionIncrements(preservePositionIncrements);\n\n      automaton = tsta.toAutomaton(tokenStream);\n    } finally {\n      IOUtils.closeWhileHandlingException(tokenStream);\n    }\n\n    // TODO: we can optimize this somewhat by determinizing\n    // while we convert\n    automaton = replaceSep(automaton, preserveSep, SEP_LABEL);\n    // This automaton should not blow up during determinize:\n    return Operations.determinize(automaton, maxGraphExpansions);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"509ddf2b18aec24f54a1cbabf7d15ed537d61ff2","date":1446074047,"type":3,"author":"Areek Zillur","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/document/CompletionTokenStream#toAutomaton(boolean).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/document/CompletionTokenStream#toAutomaton(boolean).mjava","sourceNew":"  /**\n   * Converts the tokenStream to an automaton\n   */\n  public Automaton toAutomaton(boolean unicodeAware) throws IOException {\n    // TODO refactor this\n    // maybe we could hook up a modified automaton from TermAutomatonQuery here?\n    Automaton automaton = null;\n    try {\n      // Create corresponding automaton: labels are bytes\n      // from each analyzed token, with byte 0 used as\n      // separator between tokens:\n      final TokenStreamToAutomaton tsta;\n      if (preserveSep) {\n        tsta = new EscapingTokenStreamToAutomaton((char) SEP_LABEL);\n      } else {\n        // When we're not preserving sep, we don't steal 0xff\n        // byte, so we don't need to do any escaping:\n        tsta = new TokenStreamToAutomaton();\n      }\n      tsta.setPreservePositionIncrements(preservePositionIncrements);\n      tsta.setUnicodeArcs(unicodeAware);\n\n      automaton = tsta.toAutomaton(inputTokenStream);\n    } finally {\n      IOUtils.closeWhileHandlingException(inputTokenStream);\n    }\n\n    // TODO: we can optimize this somewhat by determinizing\n    // while we convert\n    automaton = replaceSep(automaton, preserveSep, SEP_LABEL);\n    // This automaton should not blow up during determinize:\n    return Operations.determinize(automaton, maxGraphExpansions);\n  }\n\n","sourceOld":"  /**\n   * Converts the tokenStream to an automaton\n   */\n  public Automaton toAutomaton(boolean unicodeAware) throws IOException {\n    // TODO refactor this\n    // maybe we could hook up a modified automaton from TermAutomatonQuery here?\n    Automaton automaton = null;\n    try {\n      // Create corresponding automaton: labels are bytes\n      // from each analyzed token, with byte 0 used as\n      // separator between tokens:\n      final TokenStreamToAutomaton tsta;\n      if (preserveSep) {\n        tsta = new EscapingTokenStreamToAutomaton((char) SEP_LABEL);\n      } else {\n        // When we're not preserving sep, we don't steal 0xff\n        // byte, so we don't need to do any escaping:\n        tsta = new TokenStreamToAutomaton();\n      }\n      tsta.setPreservePositionIncrements(preservePositionIncrements);\n      tsta.setUnicodeArcs(unicodeAware);\n\n      automaton = tsta.toAutomaton(input);\n    } finally {\n      IOUtils.closeWhileHandlingException(input);\n    }\n\n    // TODO: we can optimize this somewhat by determinizing\n    // while we convert\n    automaton = replaceSep(automaton, preserveSep, SEP_LABEL);\n    // This automaton should not blow up during determinize:\n    return Operations.determinize(automaton, maxGraphExpansions);\n  }\n\n","bugFix":["8c33f6677a2078739058f81eca1df69d12cd62b0"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9e45ad199e1b1a4bbc15c1c08dcd73dc08fa927a","date":1528168051,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/document/CompletionTokenStream#toAutomaton(boolean).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/document/CompletionTokenStream#toAutomaton(boolean).mjava","sourceNew":"  /** Delegates to...\n   *  @see ConcatenateGraphFilter#toAutomaton(boolean) */\n  public Automaton toAutomaton(boolean unicodeAware) throws IOException {\n    return ((ConcatenateGraphFilter)input).toAutomaton(unicodeAware);\n  }\n\n","sourceOld":"  /**\n   * Converts the tokenStream to an automaton\n   */\n  public Automaton toAutomaton(boolean unicodeAware) throws IOException {\n    // TODO refactor this\n    // maybe we could hook up a modified automaton from TermAutomatonQuery here?\n    Automaton automaton = null;\n    try {\n      // Create corresponding automaton: labels are bytes\n      // from each analyzed token, with byte 0 used as\n      // separator between tokens:\n      final TokenStreamToAutomaton tsta;\n      if (preserveSep) {\n        tsta = new EscapingTokenStreamToAutomaton((char) SEP_LABEL);\n      } else {\n        // When we're not preserving sep, we don't steal 0xff\n        // byte, so we don't need to do any escaping:\n        tsta = new TokenStreamToAutomaton();\n      }\n      tsta.setPreservePositionIncrements(preservePositionIncrements);\n      tsta.setUnicodeArcs(unicodeAware);\n\n      automaton = tsta.toAutomaton(inputTokenStream);\n    } finally {\n      IOUtils.closeWhileHandlingException(inputTokenStream);\n    }\n\n    // TODO: we can optimize this somewhat by determinizing\n    // while we convert\n    automaton = replaceSep(automaton, preserveSep, SEP_LABEL);\n    // This automaton should not blow up during determinize:\n    return Operations.determinize(automaton, maxGraphExpansions);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f592209545c71895260367152601e9200399776d","date":1528238935,"type":3,"author":"Michael Braun","isMerge":true,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/document/CompletionTokenStream#toAutomaton(boolean).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/document/CompletionTokenStream#toAutomaton(boolean).mjava","sourceNew":"  /** Delegates to...\n   *  @see ConcatenateGraphFilter#toAutomaton(boolean) */\n  public Automaton toAutomaton(boolean unicodeAware) throws IOException {\n    return ((ConcatenateGraphFilter)input).toAutomaton(unicodeAware);\n  }\n\n","sourceOld":"  /**\n   * Converts the tokenStream to an automaton\n   */\n  public Automaton toAutomaton(boolean unicodeAware) throws IOException {\n    // TODO refactor this\n    // maybe we could hook up a modified automaton from TermAutomatonQuery here?\n    Automaton automaton = null;\n    try {\n      // Create corresponding automaton: labels are bytes\n      // from each analyzed token, with byte 0 used as\n      // separator between tokens:\n      final TokenStreamToAutomaton tsta;\n      if (preserveSep) {\n        tsta = new EscapingTokenStreamToAutomaton((char) SEP_LABEL);\n      } else {\n        // When we're not preserving sep, we don't steal 0xff\n        // byte, so we don't need to do any escaping:\n        tsta = new TokenStreamToAutomaton();\n      }\n      tsta.setPreservePositionIncrements(preservePositionIncrements);\n      tsta.setUnicodeArcs(unicodeAware);\n\n      automaton = tsta.toAutomaton(inputTokenStream);\n    } finally {\n      IOUtils.closeWhileHandlingException(inputTokenStream);\n    }\n\n    // TODO: we can optimize this somewhat by determinizing\n    // while we convert\n    automaton = replaceSep(automaton, preserveSep, SEP_LABEL);\n    // This automaton should not blow up during determinize:\n    return Operations.determinize(automaton, maxGraphExpansions);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b70042a8a492f7054d480ccdd2be9796510d4327","date":1528386658,"type":3,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/document/CompletionTokenStream#toAutomaton(boolean).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/document/CompletionTokenStream#toAutomaton(boolean).mjava","sourceNew":"  /** Delegates to...\n   *  @see ConcatenateGraphFilter#toAutomaton(boolean) */\n  public Automaton toAutomaton(boolean unicodeAware) throws IOException {\n    return ((ConcatenateGraphFilter)input).toAutomaton(unicodeAware);\n  }\n\n","sourceOld":"  /**\n   * Converts the tokenStream to an automaton\n   */\n  public Automaton toAutomaton(boolean unicodeAware) throws IOException {\n    // TODO refactor this\n    // maybe we could hook up a modified automaton from TermAutomatonQuery here?\n    Automaton automaton = null;\n    try {\n      // Create corresponding automaton: labels are bytes\n      // from each analyzed token, with byte 0 used as\n      // separator between tokens:\n      final TokenStreamToAutomaton tsta;\n      if (preserveSep) {\n        tsta = new EscapingTokenStreamToAutomaton((char) SEP_LABEL);\n      } else {\n        // When we're not preserving sep, we don't steal 0xff\n        // byte, so we don't need to do any escaping:\n        tsta = new TokenStreamToAutomaton();\n      }\n      tsta.setPreservePositionIncrements(preservePositionIncrements);\n      tsta.setUnicodeArcs(unicodeAware);\n\n      automaton = tsta.toAutomaton(inputTokenStream);\n    } finally {\n      IOUtils.closeWhileHandlingException(inputTokenStream);\n    }\n\n    // TODO: we can optimize this somewhat by determinizing\n    // while we convert\n    automaton = replaceSep(automaton, preserveSep, SEP_LABEL);\n    // This automaton should not blow up during determinize:\n    return Operations.determinize(automaton, maxGraphExpansions);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"509ddf2b18aec24f54a1cbabf7d15ed537d61ff2":["8c33f6677a2078739058f81eca1df69d12cd62b0"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b70042a8a492f7054d480ccdd2be9796510d4327":["509ddf2b18aec24f54a1cbabf7d15ed537d61ff2","9e45ad199e1b1a4bbc15c1c08dcd73dc08fa927a"],"8c33f6677a2078739058f81eca1df69d12cd62b0":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"9e45ad199e1b1a4bbc15c1c08dcd73dc08fa927a":["509ddf2b18aec24f54a1cbabf7d15ed537d61ff2"],"f592209545c71895260367152601e9200399776d":["509ddf2b18aec24f54a1cbabf7d15ed537d61ff2","9e45ad199e1b1a4bbc15c1c08dcd73dc08fa927a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9e45ad199e1b1a4bbc15c1c08dcd73dc08fa927a"]},"commit2Childs":{"509ddf2b18aec24f54a1cbabf7d15ed537d61ff2":["b70042a8a492f7054d480ccdd2be9796510d4327","9e45ad199e1b1a4bbc15c1c08dcd73dc08fa927a","f592209545c71895260367152601e9200399776d"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["8c33f6677a2078739058f81eca1df69d12cd62b0"],"b70042a8a492f7054d480ccdd2be9796510d4327":[],"8c33f6677a2078739058f81eca1df69d12cd62b0":["509ddf2b18aec24f54a1cbabf7d15ed537d61ff2"],"9e45ad199e1b1a4bbc15c1c08dcd73dc08fa927a":["b70042a8a492f7054d480ccdd2be9796510d4327","f592209545c71895260367152601e9200399776d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"f592209545c71895260367152601e9200399776d":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["b70042a8a492f7054d480ccdd2be9796510d4327","f592209545c71895260367152601e9200399776d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}