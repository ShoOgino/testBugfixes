{"path":"modules/grouping/src/java/org/apache/lucene/search/grouping/FirstPassGroupingCollector#collect(int).mjava","commits":[{"id":"307cff5af2b00f126fdf9d3435b75d5ed4d0f402","date":1305370109,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"modules/grouping/src/java/org/apache/lucene/search/grouping/FirstPassGroupingCollector#collect(int).mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public void collect(int doc) throws IOException {\n    //System.out.println(\"FP.collect doc=\" + doc);\n\n    // If orderedGroups != null we already have collected N groups and\n    // can short circuit by comparing this document to the bottom group,\n    // without having to find what group this document belongs to.\n    \n    // Even if this document belongs to a group in the top N, we'll know that\n    // we don't have to update that group.\n\n    // Downside: if the number of unique groups is very low, this is\n    // wasted effort as we will most likely be updating an existing group.\n    if (orderedGroups != null) {\n      for (int compIDX = 0;; compIDX++) {\n        final int c = reversed[compIDX] * comparators[compIDX].compareBottom(doc);\n        if (c < 0) {\n          // Definitely not competitive. So don't even bother to continue\n          return;\n        } else if (c > 0) {\n          // Definitely competitive.\n          break;\n        } else if (compIDX == compIDXEnd) {\n          // Here c=0. If we're at the last comparator, this doc is not\n          // competitive, since docs are visited in doc Id order, which means\n          // this doc cannot compete with any other document in the queue.\n          return;\n        }\n      }\n    }\n\n    // TODO: should we add option to mean \"ignore docs that\n    // don't have the group field\" (instead of stuffing them\n    // under null group)?\n    final int ord = index.getOrd(doc);\n    //System.out.println(\"  ord=\" + ord);\n\n    final BytesRef br = ord == 0 ? null : index.lookup(ord, scratchBytesRef);\n    //System.out.println(\"  group=\" + (br == null ? \"null\" : br.utf8ToString()));\n\n    final CollectedSearchGroup group = groupMap.get(br);\n\n    if (group == null) {\n\n      // First time we are seeing this group, or, we've seen\n      // it before but it fell out of the top N and is now\n      // coming back\n\n      if (groupMap.size() < topNGroups) {\n\n        // Still in startup transient: we have not\n        // seen enough unique groups to start pruning them;\n        // just keep collecting them\n\n        // Add a new CollectedSearchGroup:\n        CollectedSearchGroup sg = new CollectedSearchGroup();\n        sg.groupValue = ord == 0 ? null : new BytesRef(scratchBytesRef);\n        sg.comparatorSlot = groupMap.size();\n        sg.topDoc = docBase + doc;\n        for (FieldComparator fc : comparators) {\n          fc.copy(sg.comparatorSlot, doc);\n        }\n        groupMap.put(sg.groupValue, sg);\n\n        if (groupMap.size() == topNGroups) {\n          // End of startup transient: we now have max\n          // number of groups; from here on we will drop\n          // bottom group when we insert new one:\n          buildSortedSet();\n        }\n\n        return;\n      }\n\n      // We already tested that the document is competitive, so replace\n      // the bottom group with this new group.\n\n      final CollectedSearchGroup bottomGroup = orderedGroups.pollLast();\n      assert orderedGroups.size() == topNGroups -1;\n\n      groupMap.remove(bottomGroup.groupValue);\n\n      // reuse the removed CollectedSearchGroup\n      if (br == null) {\n        bottomGroup.groupValue = null;\n      } else if (bottomGroup.groupValue != null) {\n        bottomGroup.groupValue.copy(br);\n      } else {\n        bottomGroup.groupValue = new BytesRef(br);\n      }\n      bottomGroup.topDoc = docBase + doc;\n\n      for (FieldComparator fc : comparators) {\n        fc.copy(bottomGroup.comparatorSlot, doc);\n      }\n\n      groupMap.put(bottomGroup.groupValue, bottomGroup);\n      orderedGroups.add(bottomGroup);\n      assert orderedGroups.size() == topNGroups;\n\n      final int lastComparatorSlot = orderedGroups.last().comparatorSlot;\n      for (FieldComparator fc : comparators) {\n        fc.setBottom(lastComparatorSlot);\n      }\n\n      return;\n    }\n\n    // Update existing group:\n    for (int compIDX = 0;; compIDX++) {\n      final FieldComparator fc = comparators[compIDX];\n      fc.copy(spareSlot, doc);\n\n      final int c = reversed[compIDX] * fc.compare(group.comparatorSlot, spareSlot);\n      if (c < 0) {\n        // Definitely not competitive.\n        return;\n      } else if (c > 0) {\n        // Definitely competitive; set remaining comparators:\n        for (int compIDX2=compIDX+1; compIDX2<comparators.length; compIDX2++) {\n          comparators[compIDX2].copy(spareSlot, doc);\n        }\n        break;\n      } else if (compIDX == compIDXEnd) {\n        // Here c=0. If we're at the last comparator, this doc is not\n        // competitive, since docs are visited in doc Id order, which means\n        // this doc cannot compete with any other document in the queue.\n        return;\n      }\n    }\n\n    // Remove before updating the group since lookup is done via comparators\n    // TODO: optimize this\n\n    final CollectedSearchGroup prevLast;\n    if (orderedGroups != null) {\n      prevLast = orderedGroups.last();\n      orderedGroups.remove(group);\n      assert orderedGroups.size() == topNGroups-1;\n    } else {\n      prevLast = null;\n    }\n\n    group.topDoc = docBase + doc;\n\n    // Swap slots\n    final int tmp = spareSlot;\n    spareSlot = group.comparatorSlot;\n    group.comparatorSlot = tmp;\n\n    // Re-add the changed group\n    if (orderedGroups != null) {\n      orderedGroups.add(group);\n      assert orderedGroups.size() == topNGroups;\n      final CollectedSearchGroup newLast = orderedGroups.last();\n      // If we changed the value of the last group, or changed which group was last, then update bottom:\n      if (group == newLast || prevLast != newLast) {\n        for (FieldComparator fc : comparators) {\n          fc.setBottom(newLast.comparatorSlot);\n        }\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a7eeb270ab6ec07042d54fe23ad05cc7013c1552","date":1305372356,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"modules/grouping/src/java/org/apache/lucene/search/grouping/FirstPassGroupingCollector#collect(int).mjava","pathOld":"modules/grouping/src/java/org/apache/lucene/search/grouping/FirstPassGroupingCollector#collect(int).mjava","sourceNew":"  @Override\n  public void collect(int doc) throws IOException {\n    //System.out.println(\"FP.collect doc=\" + doc);\n\n    // If orderedGroups != null we already have collected N groups and\n    // can short circuit by comparing this document to the bottom group,\n    // without having to find what group this document belongs to.\n    \n    // Even if this document belongs to a group in the top N, we'll know that\n    // we don't have to update that group.\n\n    // Downside: if the number of unique groups is very low, this is\n    // wasted effort as we will most likely be updating an existing group.\n    if (orderedGroups != null) {\n      for (int compIDX = 0;; compIDX++) {\n        final int c = reversed[compIDX] * comparators[compIDX].compareBottom(doc);\n        if (c < 0) {\n          // Definitely not competitive. So don't even bother to continue\n          return;\n        } else if (c > 0) {\n          // Definitely competitive.\n          break;\n        } else if (compIDX == compIDXEnd) {\n          // Here c=0. If we're at the last comparator, this doc is not\n          // competitive, since docs are visited in doc Id order, which means\n          // this doc cannot compete with any other document in the queue.\n          return;\n        }\n      }\n    }\n\n    // TODO: should we add option to mean \"ignore docs that\n    // don't have the group field\" (instead of stuffing them\n    // under null group)?\n    final int ord = index.getOrd(doc);\n    //System.out.println(\"  ord=\" + ord);\n\n    final BytesRef br = ord == 0 ? null : index.lookup(ord, scratchBytesRef);\n    //System.out.println(\"  group=\" + (br == null ? \"null\" : br.utf8ToString()));\n\n    final CollectedSearchGroup group = groupMap.get(br);\n\n    if (group == null) {\n\n      // First time we are seeing this group, or, we've seen\n      // it before but it fell out of the top N and is now\n      // coming back\n\n      if (groupMap.size() < topNGroups) {\n\n        // Still in startup transient: we have not\n        // seen enough unique groups to start pruning them;\n        // just keep collecting them\n\n        // Add a new CollectedSearchGroup:\n        CollectedSearchGroup sg = new CollectedSearchGroup();\n        sg.groupValue = ord == 0 ? null : new BytesRef(scratchBytesRef);\n        sg.comparatorSlot = groupMap.size();\n        sg.topDoc = docBase + doc;\n        for (FieldComparator fc : comparators) {\n          fc.copy(sg.comparatorSlot, doc);\n        }\n        groupMap.put(sg.groupValue, sg);\n\n        if (groupMap.size() == topNGroups) {\n          // End of startup transient: we now have max\n          // number of groups; from here on we will drop\n          // bottom group when we insert new one:\n          buildSortedSet();\n        }\n\n        return;\n      }\n\n      // We already tested that the document is competitive, so replace\n      // the bottom group with this new group.\n\n      // java 6-only: final CollectedSearchGroup bottomGroup = orderedGroups.pollLast();\n      final CollectedSearchGroup bottomGroup = orderedGroups.last();\n      orderedGroups.remove(bottomGroup);\n      assert orderedGroups.size() == topNGroups -1;\n\n      groupMap.remove(bottomGroup.groupValue);\n\n      // reuse the removed CollectedSearchGroup\n      if (br == null) {\n        bottomGroup.groupValue = null;\n      } else if (bottomGroup.groupValue != null) {\n        bottomGroup.groupValue.copy(br);\n      } else {\n        bottomGroup.groupValue = new BytesRef(br);\n      }\n      bottomGroup.topDoc = docBase + doc;\n\n      for (FieldComparator fc : comparators) {\n        fc.copy(bottomGroup.comparatorSlot, doc);\n      }\n\n      groupMap.put(bottomGroup.groupValue, bottomGroup);\n      orderedGroups.add(bottomGroup);\n      assert orderedGroups.size() == topNGroups;\n\n      final int lastComparatorSlot = orderedGroups.last().comparatorSlot;\n      for (FieldComparator fc : comparators) {\n        fc.setBottom(lastComparatorSlot);\n      }\n\n      return;\n    }\n\n    // Update existing group:\n    for (int compIDX = 0;; compIDX++) {\n      final FieldComparator fc = comparators[compIDX];\n      fc.copy(spareSlot, doc);\n\n      final int c = reversed[compIDX] * fc.compare(group.comparatorSlot, spareSlot);\n      if (c < 0) {\n        // Definitely not competitive.\n        return;\n      } else if (c > 0) {\n        // Definitely competitive; set remaining comparators:\n        for (int compIDX2=compIDX+1; compIDX2<comparators.length; compIDX2++) {\n          comparators[compIDX2].copy(spareSlot, doc);\n        }\n        break;\n      } else if (compIDX == compIDXEnd) {\n        // Here c=0. If we're at the last comparator, this doc is not\n        // competitive, since docs are visited in doc Id order, which means\n        // this doc cannot compete with any other document in the queue.\n        return;\n      }\n    }\n\n    // Remove before updating the group since lookup is done via comparators\n    // TODO: optimize this\n\n    final CollectedSearchGroup prevLast;\n    if (orderedGroups != null) {\n      prevLast = orderedGroups.last();\n      orderedGroups.remove(group);\n      assert orderedGroups.size() == topNGroups-1;\n    } else {\n      prevLast = null;\n    }\n\n    group.topDoc = docBase + doc;\n\n    // Swap slots\n    final int tmp = spareSlot;\n    spareSlot = group.comparatorSlot;\n    group.comparatorSlot = tmp;\n\n    // Re-add the changed group\n    if (orderedGroups != null) {\n      orderedGroups.add(group);\n      assert orderedGroups.size() == topNGroups;\n      final CollectedSearchGroup newLast = orderedGroups.last();\n      // If we changed the value of the last group, or changed which group was last, then update bottom:\n      if (group == newLast || prevLast != newLast) {\n        for (FieldComparator fc : comparators) {\n          fc.setBottom(newLast.comparatorSlot);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void collect(int doc) throws IOException {\n    //System.out.println(\"FP.collect doc=\" + doc);\n\n    // If orderedGroups != null we already have collected N groups and\n    // can short circuit by comparing this document to the bottom group,\n    // without having to find what group this document belongs to.\n    \n    // Even if this document belongs to a group in the top N, we'll know that\n    // we don't have to update that group.\n\n    // Downside: if the number of unique groups is very low, this is\n    // wasted effort as we will most likely be updating an existing group.\n    if (orderedGroups != null) {\n      for (int compIDX = 0;; compIDX++) {\n        final int c = reversed[compIDX] * comparators[compIDX].compareBottom(doc);\n        if (c < 0) {\n          // Definitely not competitive. So don't even bother to continue\n          return;\n        } else if (c > 0) {\n          // Definitely competitive.\n          break;\n        } else if (compIDX == compIDXEnd) {\n          // Here c=0. If we're at the last comparator, this doc is not\n          // competitive, since docs are visited in doc Id order, which means\n          // this doc cannot compete with any other document in the queue.\n          return;\n        }\n      }\n    }\n\n    // TODO: should we add option to mean \"ignore docs that\n    // don't have the group field\" (instead of stuffing them\n    // under null group)?\n    final int ord = index.getOrd(doc);\n    //System.out.println(\"  ord=\" + ord);\n\n    final BytesRef br = ord == 0 ? null : index.lookup(ord, scratchBytesRef);\n    //System.out.println(\"  group=\" + (br == null ? \"null\" : br.utf8ToString()));\n\n    final CollectedSearchGroup group = groupMap.get(br);\n\n    if (group == null) {\n\n      // First time we are seeing this group, or, we've seen\n      // it before but it fell out of the top N and is now\n      // coming back\n\n      if (groupMap.size() < topNGroups) {\n\n        // Still in startup transient: we have not\n        // seen enough unique groups to start pruning them;\n        // just keep collecting them\n\n        // Add a new CollectedSearchGroup:\n        CollectedSearchGroup sg = new CollectedSearchGroup();\n        sg.groupValue = ord == 0 ? null : new BytesRef(scratchBytesRef);\n        sg.comparatorSlot = groupMap.size();\n        sg.topDoc = docBase + doc;\n        for (FieldComparator fc : comparators) {\n          fc.copy(sg.comparatorSlot, doc);\n        }\n        groupMap.put(sg.groupValue, sg);\n\n        if (groupMap.size() == topNGroups) {\n          // End of startup transient: we now have max\n          // number of groups; from here on we will drop\n          // bottom group when we insert new one:\n          buildSortedSet();\n        }\n\n        return;\n      }\n\n      // We already tested that the document is competitive, so replace\n      // the bottom group with this new group.\n\n      final CollectedSearchGroup bottomGroup = orderedGroups.pollLast();\n      assert orderedGroups.size() == topNGroups -1;\n\n      groupMap.remove(bottomGroup.groupValue);\n\n      // reuse the removed CollectedSearchGroup\n      if (br == null) {\n        bottomGroup.groupValue = null;\n      } else if (bottomGroup.groupValue != null) {\n        bottomGroup.groupValue.copy(br);\n      } else {\n        bottomGroup.groupValue = new BytesRef(br);\n      }\n      bottomGroup.topDoc = docBase + doc;\n\n      for (FieldComparator fc : comparators) {\n        fc.copy(bottomGroup.comparatorSlot, doc);\n      }\n\n      groupMap.put(bottomGroup.groupValue, bottomGroup);\n      orderedGroups.add(bottomGroup);\n      assert orderedGroups.size() == topNGroups;\n\n      final int lastComparatorSlot = orderedGroups.last().comparatorSlot;\n      for (FieldComparator fc : comparators) {\n        fc.setBottom(lastComparatorSlot);\n      }\n\n      return;\n    }\n\n    // Update existing group:\n    for (int compIDX = 0;; compIDX++) {\n      final FieldComparator fc = comparators[compIDX];\n      fc.copy(spareSlot, doc);\n\n      final int c = reversed[compIDX] * fc.compare(group.comparatorSlot, spareSlot);\n      if (c < 0) {\n        // Definitely not competitive.\n        return;\n      } else if (c > 0) {\n        // Definitely competitive; set remaining comparators:\n        for (int compIDX2=compIDX+1; compIDX2<comparators.length; compIDX2++) {\n          comparators[compIDX2].copy(spareSlot, doc);\n        }\n        break;\n      } else if (compIDX == compIDXEnd) {\n        // Here c=0. If we're at the last comparator, this doc is not\n        // competitive, since docs are visited in doc Id order, which means\n        // this doc cannot compete with any other document in the queue.\n        return;\n      }\n    }\n\n    // Remove before updating the group since lookup is done via comparators\n    // TODO: optimize this\n\n    final CollectedSearchGroup prevLast;\n    if (orderedGroups != null) {\n      prevLast = orderedGroups.last();\n      orderedGroups.remove(group);\n      assert orderedGroups.size() == topNGroups-1;\n    } else {\n      prevLast = null;\n    }\n\n    group.topDoc = docBase + doc;\n\n    // Swap slots\n    final int tmp = spareSlot;\n    spareSlot = group.comparatorSlot;\n    group.comparatorSlot = tmp;\n\n    // Re-add the changed group\n    if (orderedGroups != null) {\n      orderedGroups.add(group);\n      assert orderedGroups.size() == topNGroups;\n      final CollectedSearchGroup newLast = orderedGroups.last();\n      // If we changed the value of the last group, or changed which group was last, then update bottom:\n      if (group == newLast || prevLast != newLast) {\n        for (FieldComparator fc : comparators) {\n          fc.setBottom(newLast.comparatorSlot);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c3a8a449466c1ff7ce2274fe73dab487256964b4","date":1305735867,"type":0,"author":"Simon Willnauer","isMerge":true,"pathNew":"modules/grouping/src/java/org/apache/lucene/search/grouping/FirstPassGroupingCollector#collect(int).mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public void collect(int doc) throws IOException {\n    //System.out.println(\"FP.collect doc=\" + doc);\n\n    // If orderedGroups != null we already have collected N groups and\n    // can short circuit by comparing this document to the bottom group,\n    // without having to find what group this document belongs to.\n    \n    // Even if this document belongs to a group in the top N, we'll know that\n    // we don't have to update that group.\n\n    // Downside: if the number of unique groups is very low, this is\n    // wasted effort as we will most likely be updating an existing group.\n    if (orderedGroups != null) {\n      for (int compIDX = 0;; compIDX++) {\n        final int c = reversed[compIDX] * comparators[compIDX].compareBottom(doc);\n        if (c < 0) {\n          // Definitely not competitive. So don't even bother to continue\n          return;\n        } else if (c > 0) {\n          // Definitely competitive.\n          break;\n        } else if (compIDX == compIDXEnd) {\n          // Here c=0. If we're at the last comparator, this doc is not\n          // competitive, since docs are visited in doc Id order, which means\n          // this doc cannot compete with any other document in the queue.\n          return;\n        }\n      }\n    }\n\n    // TODO: should we add option to mean \"ignore docs that\n    // don't have the group field\" (instead of stuffing them\n    // under null group)?\n    final int ord = index.getOrd(doc);\n    //System.out.println(\"  ord=\" + ord);\n\n    final BytesRef br = ord == 0 ? null : index.lookup(ord, scratchBytesRef);\n    //System.out.println(\"  group=\" + (br == null ? \"null\" : br.utf8ToString()));\n\n    final CollectedSearchGroup group = groupMap.get(br);\n\n    if (group == null) {\n\n      // First time we are seeing this group, or, we've seen\n      // it before but it fell out of the top N and is now\n      // coming back\n\n      if (groupMap.size() < topNGroups) {\n\n        // Still in startup transient: we have not\n        // seen enough unique groups to start pruning them;\n        // just keep collecting them\n\n        // Add a new CollectedSearchGroup:\n        CollectedSearchGroup sg = new CollectedSearchGroup();\n        sg.groupValue = ord == 0 ? null : new BytesRef(scratchBytesRef);\n        sg.comparatorSlot = groupMap.size();\n        sg.topDoc = docBase + doc;\n        for (FieldComparator fc : comparators) {\n          fc.copy(sg.comparatorSlot, doc);\n        }\n        groupMap.put(sg.groupValue, sg);\n\n        if (groupMap.size() == topNGroups) {\n          // End of startup transient: we now have max\n          // number of groups; from here on we will drop\n          // bottom group when we insert new one:\n          buildSortedSet();\n        }\n\n        return;\n      }\n\n      // We already tested that the document is competitive, so replace\n      // the bottom group with this new group.\n\n      // java 6-only: final CollectedSearchGroup bottomGroup = orderedGroups.pollLast();\n      final CollectedSearchGroup bottomGroup = orderedGroups.last();\n      orderedGroups.remove(bottomGroup);\n      assert orderedGroups.size() == topNGroups -1;\n\n      groupMap.remove(bottomGroup.groupValue);\n\n      // reuse the removed CollectedSearchGroup\n      if (br == null) {\n        bottomGroup.groupValue = null;\n      } else if (bottomGroup.groupValue != null) {\n        bottomGroup.groupValue.copy(br);\n      } else {\n        bottomGroup.groupValue = new BytesRef(br);\n      }\n      bottomGroup.topDoc = docBase + doc;\n\n      for (FieldComparator fc : comparators) {\n        fc.copy(bottomGroup.comparatorSlot, doc);\n      }\n\n      groupMap.put(bottomGroup.groupValue, bottomGroup);\n      orderedGroups.add(bottomGroup);\n      assert orderedGroups.size() == topNGroups;\n\n      final int lastComparatorSlot = orderedGroups.last().comparatorSlot;\n      for (FieldComparator fc : comparators) {\n        fc.setBottom(lastComparatorSlot);\n      }\n\n      return;\n    }\n\n    // Update existing group:\n    for (int compIDX = 0;; compIDX++) {\n      final FieldComparator fc = comparators[compIDX];\n      fc.copy(spareSlot, doc);\n\n      final int c = reversed[compIDX] * fc.compare(group.comparatorSlot, spareSlot);\n      if (c < 0) {\n        // Definitely not competitive.\n        return;\n      } else if (c > 0) {\n        // Definitely competitive; set remaining comparators:\n        for (int compIDX2=compIDX+1; compIDX2<comparators.length; compIDX2++) {\n          comparators[compIDX2].copy(spareSlot, doc);\n        }\n        break;\n      } else if (compIDX == compIDXEnd) {\n        // Here c=0. If we're at the last comparator, this doc is not\n        // competitive, since docs are visited in doc Id order, which means\n        // this doc cannot compete with any other document in the queue.\n        return;\n      }\n    }\n\n    // Remove before updating the group since lookup is done via comparators\n    // TODO: optimize this\n\n    final CollectedSearchGroup prevLast;\n    if (orderedGroups != null) {\n      prevLast = orderedGroups.last();\n      orderedGroups.remove(group);\n      assert orderedGroups.size() == topNGroups-1;\n    } else {\n      prevLast = null;\n    }\n\n    group.topDoc = docBase + doc;\n\n    // Swap slots\n    final int tmp = spareSlot;\n    spareSlot = group.comparatorSlot;\n    group.comparatorSlot = tmp;\n\n    // Re-add the changed group\n    if (orderedGroups != null) {\n      orderedGroups.add(group);\n      assert orderedGroups.size() == topNGroups;\n      final CollectedSearchGroup newLast = orderedGroups.last();\n      // If we changed the value of the last group, or changed which group was last, then update bottom:\n      if (group == newLast || prevLast != newLast) {\n        for (FieldComparator fc : comparators) {\n          fc.setBottom(newLast.comparatorSlot);\n        }\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":0,"author":"Steven Rowe","isMerge":true,"pathNew":"modules/grouping/src/java/org/apache/lucene/search/grouping/FirstPassGroupingCollector#collect(int).mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public void collect(int doc) throws IOException {\n    //System.out.println(\"FP.collect doc=\" + doc);\n\n    // If orderedGroups != null we already have collected N groups and\n    // can short circuit by comparing this document to the bottom group,\n    // without having to find what group this document belongs to.\n    \n    // Even if this document belongs to a group in the top N, we'll know that\n    // we don't have to update that group.\n\n    // Downside: if the number of unique groups is very low, this is\n    // wasted effort as we will most likely be updating an existing group.\n    if (orderedGroups != null) {\n      for (int compIDX = 0;; compIDX++) {\n        final int c = reversed[compIDX] * comparators[compIDX].compareBottom(doc);\n        if (c < 0) {\n          // Definitely not competitive. So don't even bother to continue\n          return;\n        } else if (c > 0) {\n          // Definitely competitive.\n          break;\n        } else if (compIDX == compIDXEnd) {\n          // Here c=0. If we're at the last comparator, this doc is not\n          // competitive, since docs are visited in doc Id order, which means\n          // this doc cannot compete with any other document in the queue.\n          return;\n        }\n      }\n    }\n\n    // TODO: should we add option to mean \"ignore docs that\n    // don't have the group field\" (instead of stuffing them\n    // under null group)?\n    final int ord = index.getOrd(doc);\n    //System.out.println(\"  ord=\" + ord);\n\n    final BytesRef br = ord == 0 ? null : index.lookup(ord, scratchBytesRef);\n    //System.out.println(\"  group=\" + (br == null ? \"null\" : br.utf8ToString()));\n\n    final CollectedSearchGroup group = groupMap.get(br);\n\n    if (group == null) {\n\n      // First time we are seeing this group, or, we've seen\n      // it before but it fell out of the top N and is now\n      // coming back\n\n      if (groupMap.size() < topNGroups) {\n\n        // Still in startup transient: we have not\n        // seen enough unique groups to start pruning them;\n        // just keep collecting them\n\n        // Add a new CollectedSearchGroup:\n        CollectedSearchGroup sg = new CollectedSearchGroup();\n        sg.groupValue = ord == 0 ? null : new BytesRef(scratchBytesRef);\n        sg.comparatorSlot = groupMap.size();\n        sg.topDoc = docBase + doc;\n        for (FieldComparator fc : comparators) {\n          fc.copy(sg.comparatorSlot, doc);\n        }\n        groupMap.put(sg.groupValue, sg);\n\n        if (groupMap.size() == topNGroups) {\n          // End of startup transient: we now have max\n          // number of groups; from here on we will drop\n          // bottom group when we insert new one:\n          buildSortedSet();\n        }\n\n        return;\n      }\n\n      // We already tested that the document is competitive, so replace\n      // the bottom group with this new group.\n\n      // java 6-only: final CollectedSearchGroup bottomGroup = orderedGroups.pollLast();\n      final CollectedSearchGroup bottomGroup = orderedGroups.last();\n      orderedGroups.remove(bottomGroup);\n      assert orderedGroups.size() == topNGroups -1;\n\n      groupMap.remove(bottomGroup.groupValue);\n\n      // reuse the removed CollectedSearchGroup\n      if (br == null) {\n        bottomGroup.groupValue = null;\n      } else if (bottomGroup.groupValue != null) {\n        bottomGroup.groupValue.copy(br);\n      } else {\n        bottomGroup.groupValue = new BytesRef(br);\n      }\n      bottomGroup.topDoc = docBase + doc;\n\n      for (FieldComparator fc : comparators) {\n        fc.copy(bottomGroup.comparatorSlot, doc);\n      }\n\n      groupMap.put(bottomGroup.groupValue, bottomGroup);\n      orderedGroups.add(bottomGroup);\n      assert orderedGroups.size() == topNGroups;\n\n      final int lastComparatorSlot = orderedGroups.last().comparatorSlot;\n      for (FieldComparator fc : comparators) {\n        fc.setBottom(lastComparatorSlot);\n      }\n\n      return;\n    }\n\n    // Update existing group:\n    for (int compIDX = 0;; compIDX++) {\n      final FieldComparator fc = comparators[compIDX];\n      fc.copy(spareSlot, doc);\n\n      final int c = reversed[compIDX] * fc.compare(group.comparatorSlot, spareSlot);\n      if (c < 0) {\n        // Definitely not competitive.\n        return;\n      } else if (c > 0) {\n        // Definitely competitive; set remaining comparators:\n        for (int compIDX2=compIDX+1; compIDX2<comparators.length; compIDX2++) {\n          comparators[compIDX2].copy(spareSlot, doc);\n        }\n        break;\n      } else if (compIDX == compIDXEnd) {\n        // Here c=0. If we're at the last comparator, this doc is not\n        // competitive, since docs are visited in doc Id order, which means\n        // this doc cannot compete with any other document in the queue.\n        return;\n      }\n    }\n\n    // Remove before updating the group since lookup is done via comparators\n    // TODO: optimize this\n\n    final CollectedSearchGroup prevLast;\n    if (orderedGroups != null) {\n      prevLast = orderedGroups.last();\n      orderedGroups.remove(group);\n      assert orderedGroups.size() == topNGroups-1;\n    } else {\n      prevLast = null;\n    }\n\n    group.topDoc = docBase + doc;\n\n    // Swap slots\n    final int tmp = spareSlot;\n    spareSlot = group.comparatorSlot;\n    group.comparatorSlot = tmp;\n\n    // Re-add the changed group\n    if (orderedGroups != null) {\n      orderedGroups.add(group);\n      assert orderedGroups.size() == topNGroups;\n      final CollectedSearchGroup newLast = orderedGroups.last();\n      // If we changed the value of the last group, or changed which group was last, then update bottom:\n      if (group == newLast || prevLast != newLast) {\n        for (FieldComparator fc : comparators) {\n          fc.setBottom(newLast.comparatorSlot);\n        }\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1fa60a501961bce2ff07ee1cde7c78699025547e","date":1307054117,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"modules/grouping/src/java/org/apache/lucene/search/grouping/AbstractFirstPassGroupingCollector#collect(int).mjava","pathOld":"modules/grouping/src/java/org/apache/lucene/search/grouping/FirstPassGroupingCollector#collect(int).mjava","sourceNew":"  @Override\n  public void collect(int doc) throws IOException {\n    //System.out.println(\"FP.collect doc=\" + doc);\n\n    // If orderedGroups != null we already have collected N groups and\n    // can short circuit by comparing this document to the bottom group,\n    // without having to find what group this document belongs to.\n    \n    // Even if this document belongs to a group in the top N, we'll know that\n    // we don't have to update that group.\n\n    // Downside: if the number of unique groups is very low, this is\n    // wasted effort as we will most likely be updating an existing group.\n    if (orderedGroups != null) {\n      for (int compIDX = 0;; compIDX++) {\n        final int c = reversed[compIDX] * comparators[compIDX].compareBottom(doc);\n        if (c < 0) {\n          // Definitely not competitive. So don't even bother to continue\n          return;\n        } else if (c > 0) {\n          // Definitely competitive.\n          break;\n        } else if (compIDX == compIDXEnd) {\n          // Here c=0. If we're at the last comparator, this doc is not\n          // competitive, since docs are visited in doc Id order, which means\n          // this doc cannot compete with any other document in the queue.\n          return;\n        }\n      }\n    }\n\n    // TODO: should we add option to mean \"ignore docs that\n    // don't have the group field\" (instead of stuffing them\n    // under null group)?\n    final GROUP_VALUE_TYPE groupValue = getDocGroupValue(doc);\n\n    final CollectedSearchGroup<GROUP_VALUE_TYPE> group = groupMap.get(groupValue);\n\n    if (group == null) {\n\n      // First time we are seeing this group, or, we've seen\n      // it before but it fell out of the top N and is now\n      // coming back\n\n      if (groupMap.size() < topNGroups) {\n\n        // Still in startup transient: we have not\n        // seen enough unique groups to start pruning them;\n        // just keep collecting them\n\n        // Add a new CollectedSearchGroup:\n        CollectedSearchGroup<GROUP_VALUE_TYPE> sg = new CollectedSearchGroup<GROUP_VALUE_TYPE>();\n        sg.groupValue = copyDocGroupValue(groupValue, null);\n        sg.comparatorSlot = groupMap.size();\n        sg.topDoc = docBase + doc;\n        for (FieldComparator fc : comparators) {\n          fc.copy(sg.comparatorSlot, doc);\n        }\n        groupMap.put(sg.groupValue, sg);\n\n        if (groupMap.size() == topNGroups) {\n          // End of startup transient: we now have max\n          // number of groups; from here on we will drop\n          // bottom group when we insert new one:\n          buildSortedSet();\n        }\n\n        return;\n      }\n\n      // We already tested that the document is competitive, so replace\n      // the bottom group with this new group.\n\n      // java 6-only: final CollectedSearchGroup bottomGroup = orderedGroups.pollLast();\n      final CollectedSearchGroup<GROUP_VALUE_TYPE> bottomGroup = orderedGroups.last();\n      orderedGroups.remove(bottomGroup);\n      assert orderedGroups.size() == topNGroups -1;\n\n      groupMap.remove(bottomGroup.groupValue);\n\n      // reuse the removed CollectedSearchGroup\n      bottomGroup.groupValue = copyDocGroupValue(groupValue, bottomGroup.groupValue);\n      bottomGroup.topDoc = docBase + doc;\n\n      for (FieldComparator fc : comparators) {\n        fc.copy(bottomGroup.comparatorSlot, doc);\n      }\n\n      groupMap.put(bottomGroup.groupValue, bottomGroup);\n      orderedGroups.add(bottomGroup);\n      assert orderedGroups.size() == topNGroups;\n\n      final int lastComparatorSlot = orderedGroups.last().comparatorSlot;\n      for (FieldComparator fc : comparators) {\n        fc.setBottom(lastComparatorSlot);\n      }\n\n      return;\n    }\n\n    // Update existing group:\n    for (int compIDX = 0;; compIDX++) {\n      final FieldComparator fc = comparators[compIDX];\n      fc.copy(spareSlot, doc);\n\n      final int c = reversed[compIDX] * fc.compare(group.comparatorSlot, spareSlot);\n      if (c < 0) {\n        // Definitely not competitive.\n        return;\n      } else if (c > 0) {\n        // Definitely competitive; set remaining comparators:\n        for (int compIDX2=compIDX+1; compIDX2<comparators.length; compIDX2++) {\n          comparators[compIDX2].copy(spareSlot, doc);\n        }\n        break;\n      } else if (compIDX == compIDXEnd) {\n        // Here c=0. If we're at the last comparator, this doc is not\n        // competitive, since docs are visited in doc Id order, which means\n        // this doc cannot compete with any other document in the queue.\n        return;\n      }\n    }\n\n    // Remove before updating the group since lookup is done via comparators\n    // TODO: optimize this\n\n    final CollectedSearchGroup<GROUP_VALUE_TYPE> prevLast;\n    if (orderedGroups != null) {\n      prevLast = orderedGroups.last();\n      orderedGroups.remove(group);\n      assert orderedGroups.size() == topNGroups-1;\n    } else {\n      prevLast = null;\n    }\n\n    group.topDoc = docBase + doc;\n\n    // Swap slots\n    final int tmp = spareSlot;\n    spareSlot = group.comparatorSlot;\n    group.comparatorSlot = tmp;\n\n    // Re-add the changed group\n    if (orderedGroups != null) {\n      orderedGroups.add(group);\n      assert orderedGroups.size() == topNGroups;\n      final CollectedSearchGroup newLast = orderedGroups.last();\n      // If we changed the value of the last group, or changed which group was last, then update bottom:\n      if (group == newLast || prevLast != newLast) {\n        for (FieldComparator fc : comparators) {\n          fc.setBottom(newLast.comparatorSlot);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void collect(int doc) throws IOException {\n    //System.out.println(\"FP.collect doc=\" + doc);\n\n    // If orderedGroups != null we already have collected N groups and\n    // can short circuit by comparing this document to the bottom group,\n    // without having to find what group this document belongs to.\n    \n    // Even if this document belongs to a group in the top N, we'll know that\n    // we don't have to update that group.\n\n    // Downside: if the number of unique groups is very low, this is\n    // wasted effort as we will most likely be updating an existing group.\n    if (orderedGroups != null) {\n      for (int compIDX = 0;; compIDX++) {\n        final int c = reversed[compIDX] * comparators[compIDX].compareBottom(doc);\n        if (c < 0) {\n          // Definitely not competitive. So don't even bother to continue\n          return;\n        } else if (c > 0) {\n          // Definitely competitive.\n          break;\n        } else if (compIDX == compIDXEnd) {\n          // Here c=0. If we're at the last comparator, this doc is not\n          // competitive, since docs are visited in doc Id order, which means\n          // this doc cannot compete with any other document in the queue.\n          return;\n        }\n      }\n    }\n\n    // TODO: should we add option to mean \"ignore docs that\n    // don't have the group field\" (instead of stuffing them\n    // under null group)?\n    final int ord = index.getOrd(doc);\n    //System.out.println(\"  ord=\" + ord);\n\n    final BytesRef br = ord == 0 ? null : index.lookup(ord, scratchBytesRef);\n    //System.out.println(\"  group=\" + (br == null ? \"null\" : br.utf8ToString()));\n\n    final CollectedSearchGroup group = groupMap.get(br);\n\n    if (group == null) {\n\n      // First time we are seeing this group, or, we've seen\n      // it before but it fell out of the top N and is now\n      // coming back\n\n      if (groupMap.size() < topNGroups) {\n\n        // Still in startup transient: we have not\n        // seen enough unique groups to start pruning them;\n        // just keep collecting them\n\n        // Add a new CollectedSearchGroup:\n        CollectedSearchGroup sg = new CollectedSearchGroup();\n        sg.groupValue = ord == 0 ? null : new BytesRef(scratchBytesRef);\n        sg.comparatorSlot = groupMap.size();\n        sg.topDoc = docBase + doc;\n        for (FieldComparator fc : comparators) {\n          fc.copy(sg.comparatorSlot, doc);\n        }\n        groupMap.put(sg.groupValue, sg);\n\n        if (groupMap.size() == topNGroups) {\n          // End of startup transient: we now have max\n          // number of groups; from here on we will drop\n          // bottom group when we insert new one:\n          buildSortedSet();\n        }\n\n        return;\n      }\n\n      // We already tested that the document is competitive, so replace\n      // the bottom group with this new group.\n\n      // java 6-only: final CollectedSearchGroup bottomGroup = orderedGroups.pollLast();\n      final CollectedSearchGroup bottomGroup = orderedGroups.last();\n      orderedGroups.remove(bottomGroup);\n      assert orderedGroups.size() == topNGroups -1;\n\n      groupMap.remove(bottomGroup.groupValue);\n\n      // reuse the removed CollectedSearchGroup\n      if (br == null) {\n        bottomGroup.groupValue = null;\n      } else if (bottomGroup.groupValue != null) {\n        bottomGroup.groupValue.copy(br);\n      } else {\n        bottomGroup.groupValue = new BytesRef(br);\n      }\n      bottomGroup.topDoc = docBase + doc;\n\n      for (FieldComparator fc : comparators) {\n        fc.copy(bottomGroup.comparatorSlot, doc);\n      }\n\n      groupMap.put(bottomGroup.groupValue, bottomGroup);\n      orderedGroups.add(bottomGroup);\n      assert orderedGroups.size() == topNGroups;\n\n      final int lastComparatorSlot = orderedGroups.last().comparatorSlot;\n      for (FieldComparator fc : comparators) {\n        fc.setBottom(lastComparatorSlot);\n      }\n\n      return;\n    }\n\n    // Update existing group:\n    for (int compIDX = 0;; compIDX++) {\n      final FieldComparator fc = comparators[compIDX];\n      fc.copy(spareSlot, doc);\n\n      final int c = reversed[compIDX] * fc.compare(group.comparatorSlot, spareSlot);\n      if (c < 0) {\n        // Definitely not competitive.\n        return;\n      } else if (c > 0) {\n        // Definitely competitive; set remaining comparators:\n        for (int compIDX2=compIDX+1; compIDX2<comparators.length; compIDX2++) {\n          comparators[compIDX2].copy(spareSlot, doc);\n        }\n        break;\n      } else if (compIDX == compIDXEnd) {\n        // Here c=0. If we're at the last comparator, this doc is not\n        // competitive, since docs are visited in doc Id order, which means\n        // this doc cannot compete with any other document in the queue.\n        return;\n      }\n    }\n\n    // Remove before updating the group since lookup is done via comparators\n    // TODO: optimize this\n\n    final CollectedSearchGroup prevLast;\n    if (orderedGroups != null) {\n      prevLast = orderedGroups.last();\n      orderedGroups.remove(group);\n      assert orderedGroups.size() == topNGroups-1;\n    } else {\n      prevLast = null;\n    }\n\n    group.topDoc = docBase + doc;\n\n    // Swap slots\n    final int tmp = spareSlot;\n    spareSlot = group.comparatorSlot;\n    group.comparatorSlot = tmp;\n\n    // Re-add the changed group\n    if (orderedGroups != null) {\n      orderedGroups.add(group);\n      assert orderedGroups.size() == topNGroups;\n      final CollectedSearchGroup newLast = orderedGroups.last();\n      // If we changed the value of the last group, or changed which group was last, then update bottom:\n      if (group == newLast || prevLast != newLast) {\n        for (FieldComparator fc : comparators) {\n          fc.setBottom(newLast.comparatorSlot);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c03daa6ddcb4768a702115ec63799cab5fff3d92","date":1307140842,"type":4,"author":"Simon Willnauer","isMerge":true,"pathNew":"/dev/null","pathOld":"modules/grouping/src/java/org/apache/lucene/search/grouping/FirstPassGroupingCollector#collect(int).mjava","sourceNew":null,"sourceOld":"  @Override\n  public void collect(int doc) throws IOException {\n    //System.out.println(\"FP.collect doc=\" + doc);\n\n    // If orderedGroups != null we already have collected N groups and\n    // can short circuit by comparing this document to the bottom group,\n    // without having to find what group this document belongs to.\n    \n    // Even if this document belongs to a group in the top N, we'll know that\n    // we don't have to update that group.\n\n    // Downside: if the number of unique groups is very low, this is\n    // wasted effort as we will most likely be updating an existing group.\n    if (orderedGroups != null) {\n      for (int compIDX = 0;; compIDX++) {\n        final int c = reversed[compIDX] * comparators[compIDX].compareBottom(doc);\n        if (c < 0) {\n          // Definitely not competitive. So don't even bother to continue\n          return;\n        } else if (c > 0) {\n          // Definitely competitive.\n          break;\n        } else if (compIDX == compIDXEnd) {\n          // Here c=0. If we're at the last comparator, this doc is not\n          // competitive, since docs are visited in doc Id order, which means\n          // this doc cannot compete with any other document in the queue.\n          return;\n        }\n      }\n    }\n\n    // TODO: should we add option to mean \"ignore docs that\n    // don't have the group field\" (instead of stuffing them\n    // under null group)?\n    final int ord = index.getOrd(doc);\n    //System.out.println(\"  ord=\" + ord);\n\n    final BytesRef br = ord == 0 ? null : index.lookup(ord, scratchBytesRef);\n    //System.out.println(\"  group=\" + (br == null ? \"null\" : br.utf8ToString()));\n\n    final CollectedSearchGroup group = groupMap.get(br);\n\n    if (group == null) {\n\n      // First time we are seeing this group, or, we've seen\n      // it before but it fell out of the top N and is now\n      // coming back\n\n      if (groupMap.size() < topNGroups) {\n\n        // Still in startup transient: we have not\n        // seen enough unique groups to start pruning them;\n        // just keep collecting them\n\n        // Add a new CollectedSearchGroup:\n        CollectedSearchGroup sg = new CollectedSearchGroup();\n        sg.groupValue = ord == 0 ? null : new BytesRef(scratchBytesRef);\n        sg.comparatorSlot = groupMap.size();\n        sg.topDoc = docBase + doc;\n        for (FieldComparator fc : comparators) {\n          fc.copy(sg.comparatorSlot, doc);\n        }\n        groupMap.put(sg.groupValue, sg);\n\n        if (groupMap.size() == topNGroups) {\n          // End of startup transient: we now have max\n          // number of groups; from here on we will drop\n          // bottom group when we insert new one:\n          buildSortedSet();\n        }\n\n        return;\n      }\n\n      // We already tested that the document is competitive, so replace\n      // the bottom group with this new group.\n\n      // java 6-only: final CollectedSearchGroup bottomGroup = orderedGroups.pollLast();\n      final CollectedSearchGroup bottomGroup = orderedGroups.last();\n      orderedGroups.remove(bottomGroup);\n      assert orderedGroups.size() == topNGroups -1;\n\n      groupMap.remove(bottomGroup.groupValue);\n\n      // reuse the removed CollectedSearchGroup\n      if (br == null) {\n        bottomGroup.groupValue = null;\n      } else if (bottomGroup.groupValue != null) {\n        bottomGroup.groupValue.copy(br);\n      } else {\n        bottomGroup.groupValue = new BytesRef(br);\n      }\n      bottomGroup.topDoc = docBase + doc;\n\n      for (FieldComparator fc : comparators) {\n        fc.copy(bottomGroup.comparatorSlot, doc);\n      }\n\n      groupMap.put(bottomGroup.groupValue, bottomGroup);\n      orderedGroups.add(bottomGroup);\n      assert orderedGroups.size() == topNGroups;\n\n      final int lastComparatorSlot = orderedGroups.last().comparatorSlot;\n      for (FieldComparator fc : comparators) {\n        fc.setBottom(lastComparatorSlot);\n      }\n\n      return;\n    }\n\n    // Update existing group:\n    for (int compIDX = 0;; compIDX++) {\n      final FieldComparator fc = comparators[compIDX];\n      fc.copy(spareSlot, doc);\n\n      final int c = reversed[compIDX] * fc.compare(group.comparatorSlot, spareSlot);\n      if (c < 0) {\n        // Definitely not competitive.\n        return;\n      } else if (c > 0) {\n        // Definitely competitive; set remaining comparators:\n        for (int compIDX2=compIDX+1; compIDX2<comparators.length; compIDX2++) {\n          comparators[compIDX2].copy(spareSlot, doc);\n        }\n        break;\n      } else if (compIDX == compIDXEnd) {\n        // Here c=0. If we're at the last comparator, this doc is not\n        // competitive, since docs are visited in doc Id order, which means\n        // this doc cannot compete with any other document in the queue.\n        return;\n      }\n    }\n\n    // Remove before updating the group since lookup is done via comparators\n    // TODO: optimize this\n\n    final CollectedSearchGroup prevLast;\n    if (orderedGroups != null) {\n      prevLast = orderedGroups.last();\n      orderedGroups.remove(group);\n      assert orderedGroups.size() == topNGroups-1;\n    } else {\n      prevLast = null;\n    }\n\n    group.topDoc = docBase + doc;\n\n    // Swap slots\n    final int tmp = spareSlot;\n    spareSlot = group.comparatorSlot;\n    group.comparatorSlot = tmp;\n\n    // Re-add the changed group\n    if (orderedGroups != null) {\n      orderedGroups.add(group);\n      assert orderedGroups.size() == topNGroups;\n      final CollectedSearchGroup newLast = orderedGroups.last();\n      // If we changed the value of the last group, or changed which group was last, then update bottom:\n      if (group == newLast || prevLast != newLast) {\n        for (FieldComparator fc : comparators) {\n          fc.setBottom(newLast.comparatorSlot);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1e7c99bd45fa88a3d93a03fdd773053bef72268e","date":1307218088,"type":5,"author":"Steven Rowe","isMerge":true,"pathNew":"modules/grouping/src/java/org/apache/lucene/search/grouping/AbstractFirstPassGroupingCollector#collect(int).mjava","pathOld":"modules/grouping/src/java/org/apache/lucene/search/grouping/FirstPassGroupingCollector#collect(int).mjava","sourceNew":"  @Override\n  public void collect(int doc) throws IOException {\n    //System.out.println(\"FP.collect doc=\" + doc);\n\n    // If orderedGroups != null we already have collected N groups and\n    // can short circuit by comparing this document to the bottom group,\n    // without having to find what group this document belongs to.\n    \n    // Even if this document belongs to a group in the top N, we'll know that\n    // we don't have to update that group.\n\n    // Downside: if the number of unique groups is very low, this is\n    // wasted effort as we will most likely be updating an existing group.\n    if (orderedGroups != null) {\n      for (int compIDX = 0;; compIDX++) {\n        final int c = reversed[compIDX] * comparators[compIDX].compareBottom(doc);\n        if (c < 0) {\n          // Definitely not competitive. So don't even bother to continue\n          return;\n        } else if (c > 0) {\n          // Definitely competitive.\n          break;\n        } else if (compIDX == compIDXEnd) {\n          // Here c=0. If we're at the last comparator, this doc is not\n          // competitive, since docs are visited in doc Id order, which means\n          // this doc cannot compete with any other document in the queue.\n          return;\n        }\n      }\n    }\n\n    // TODO: should we add option to mean \"ignore docs that\n    // don't have the group field\" (instead of stuffing them\n    // under null group)?\n    final GROUP_VALUE_TYPE groupValue = getDocGroupValue(doc);\n\n    final CollectedSearchGroup<GROUP_VALUE_TYPE> group = groupMap.get(groupValue);\n\n    if (group == null) {\n\n      // First time we are seeing this group, or, we've seen\n      // it before but it fell out of the top N and is now\n      // coming back\n\n      if (groupMap.size() < topNGroups) {\n\n        // Still in startup transient: we have not\n        // seen enough unique groups to start pruning them;\n        // just keep collecting them\n\n        // Add a new CollectedSearchGroup:\n        CollectedSearchGroup<GROUP_VALUE_TYPE> sg = new CollectedSearchGroup<GROUP_VALUE_TYPE>();\n        sg.groupValue = copyDocGroupValue(groupValue, null);\n        sg.comparatorSlot = groupMap.size();\n        sg.topDoc = docBase + doc;\n        for (FieldComparator fc : comparators) {\n          fc.copy(sg.comparatorSlot, doc);\n        }\n        groupMap.put(sg.groupValue, sg);\n\n        if (groupMap.size() == topNGroups) {\n          // End of startup transient: we now have max\n          // number of groups; from here on we will drop\n          // bottom group when we insert new one:\n          buildSortedSet();\n        }\n\n        return;\n      }\n\n      // We already tested that the document is competitive, so replace\n      // the bottom group with this new group.\n\n      // java 6-only: final CollectedSearchGroup bottomGroup = orderedGroups.pollLast();\n      final CollectedSearchGroup<GROUP_VALUE_TYPE> bottomGroup = orderedGroups.last();\n      orderedGroups.remove(bottomGroup);\n      assert orderedGroups.size() == topNGroups -1;\n\n      groupMap.remove(bottomGroup.groupValue);\n\n      // reuse the removed CollectedSearchGroup\n      bottomGroup.groupValue = copyDocGroupValue(groupValue, bottomGroup.groupValue);\n      bottomGroup.topDoc = docBase + doc;\n\n      for (FieldComparator fc : comparators) {\n        fc.copy(bottomGroup.comparatorSlot, doc);\n      }\n\n      groupMap.put(bottomGroup.groupValue, bottomGroup);\n      orderedGroups.add(bottomGroup);\n      assert orderedGroups.size() == topNGroups;\n\n      final int lastComparatorSlot = orderedGroups.last().comparatorSlot;\n      for (FieldComparator fc : comparators) {\n        fc.setBottom(lastComparatorSlot);\n      }\n\n      return;\n    }\n\n    // Update existing group:\n    for (int compIDX = 0;; compIDX++) {\n      final FieldComparator fc = comparators[compIDX];\n      fc.copy(spareSlot, doc);\n\n      final int c = reversed[compIDX] * fc.compare(group.comparatorSlot, spareSlot);\n      if (c < 0) {\n        // Definitely not competitive.\n        return;\n      } else if (c > 0) {\n        // Definitely competitive; set remaining comparators:\n        for (int compIDX2=compIDX+1; compIDX2<comparators.length; compIDX2++) {\n          comparators[compIDX2].copy(spareSlot, doc);\n        }\n        break;\n      } else if (compIDX == compIDXEnd) {\n        // Here c=0. If we're at the last comparator, this doc is not\n        // competitive, since docs are visited in doc Id order, which means\n        // this doc cannot compete with any other document in the queue.\n        return;\n      }\n    }\n\n    // Remove before updating the group since lookup is done via comparators\n    // TODO: optimize this\n\n    final CollectedSearchGroup<GROUP_VALUE_TYPE> prevLast;\n    if (orderedGroups != null) {\n      prevLast = orderedGroups.last();\n      orderedGroups.remove(group);\n      assert orderedGroups.size() == topNGroups-1;\n    } else {\n      prevLast = null;\n    }\n\n    group.topDoc = docBase + doc;\n\n    // Swap slots\n    final int tmp = spareSlot;\n    spareSlot = group.comparatorSlot;\n    group.comparatorSlot = tmp;\n\n    // Re-add the changed group\n    if (orderedGroups != null) {\n      orderedGroups.add(group);\n      assert orderedGroups.size() == topNGroups;\n      final CollectedSearchGroup newLast = orderedGroups.last();\n      // If we changed the value of the last group, or changed which group was last, then update bottom:\n      if (group == newLast || prevLast != newLast) {\n        for (FieldComparator fc : comparators) {\n          fc.setBottom(newLast.comparatorSlot);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void collect(int doc) throws IOException {\n    //System.out.println(\"FP.collect doc=\" + doc);\n\n    // If orderedGroups != null we already have collected N groups and\n    // can short circuit by comparing this document to the bottom group,\n    // without having to find what group this document belongs to.\n    \n    // Even if this document belongs to a group in the top N, we'll know that\n    // we don't have to update that group.\n\n    // Downside: if the number of unique groups is very low, this is\n    // wasted effort as we will most likely be updating an existing group.\n    if (orderedGroups != null) {\n      for (int compIDX = 0;; compIDX++) {\n        final int c = reversed[compIDX] * comparators[compIDX].compareBottom(doc);\n        if (c < 0) {\n          // Definitely not competitive. So don't even bother to continue\n          return;\n        } else if (c > 0) {\n          // Definitely competitive.\n          break;\n        } else if (compIDX == compIDXEnd) {\n          // Here c=0. If we're at the last comparator, this doc is not\n          // competitive, since docs are visited in doc Id order, which means\n          // this doc cannot compete with any other document in the queue.\n          return;\n        }\n      }\n    }\n\n    // TODO: should we add option to mean \"ignore docs that\n    // don't have the group field\" (instead of stuffing them\n    // under null group)?\n    final int ord = index.getOrd(doc);\n    //System.out.println(\"  ord=\" + ord);\n\n    final BytesRef br = ord == 0 ? null : index.lookup(ord, scratchBytesRef);\n    //System.out.println(\"  group=\" + (br == null ? \"null\" : br.utf8ToString()));\n\n    final CollectedSearchGroup group = groupMap.get(br);\n\n    if (group == null) {\n\n      // First time we are seeing this group, or, we've seen\n      // it before but it fell out of the top N and is now\n      // coming back\n\n      if (groupMap.size() < topNGroups) {\n\n        // Still in startup transient: we have not\n        // seen enough unique groups to start pruning them;\n        // just keep collecting them\n\n        // Add a new CollectedSearchGroup:\n        CollectedSearchGroup sg = new CollectedSearchGroup();\n        sg.groupValue = ord == 0 ? null : new BytesRef(scratchBytesRef);\n        sg.comparatorSlot = groupMap.size();\n        sg.topDoc = docBase + doc;\n        for (FieldComparator fc : comparators) {\n          fc.copy(sg.comparatorSlot, doc);\n        }\n        groupMap.put(sg.groupValue, sg);\n\n        if (groupMap.size() == topNGroups) {\n          // End of startup transient: we now have max\n          // number of groups; from here on we will drop\n          // bottom group when we insert new one:\n          buildSortedSet();\n        }\n\n        return;\n      }\n\n      // We already tested that the document is competitive, so replace\n      // the bottom group with this new group.\n\n      // java 6-only: final CollectedSearchGroup bottomGroup = orderedGroups.pollLast();\n      final CollectedSearchGroup bottomGroup = orderedGroups.last();\n      orderedGroups.remove(bottomGroup);\n      assert orderedGroups.size() == topNGroups -1;\n\n      groupMap.remove(bottomGroup.groupValue);\n\n      // reuse the removed CollectedSearchGroup\n      if (br == null) {\n        bottomGroup.groupValue = null;\n      } else if (bottomGroup.groupValue != null) {\n        bottomGroup.groupValue.copy(br);\n      } else {\n        bottomGroup.groupValue = new BytesRef(br);\n      }\n      bottomGroup.topDoc = docBase + doc;\n\n      for (FieldComparator fc : comparators) {\n        fc.copy(bottomGroup.comparatorSlot, doc);\n      }\n\n      groupMap.put(bottomGroup.groupValue, bottomGroup);\n      orderedGroups.add(bottomGroup);\n      assert orderedGroups.size() == topNGroups;\n\n      final int lastComparatorSlot = orderedGroups.last().comparatorSlot;\n      for (FieldComparator fc : comparators) {\n        fc.setBottom(lastComparatorSlot);\n      }\n\n      return;\n    }\n\n    // Update existing group:\n    for (int compIDX = 0;; compIDX++) {\n      final FieldComparator fc = comparators[compIDX];\n      fc.copy(spareSlot, doc);\n\n      final int c = reversed[compIDX] * fc.compare(group.comparatorSlot, spareSlot);\n      if (c < 0) {\n        // Definitely not competitive.\n        return;\n      } else if (c > 0) {\n        // Definitely competitive; set remaining comparators:\n        for (int compIDX2=compIDX+1; compIDX2<comparators.length; compIDX2++) {\n          comparators[compIDX2].copy(spareSlot, doc);\n        }\n        break;\n      } else if (compIDX == compIDXEnd) {\n        // Here c=0. If we're at the last comparator, this doc is not\n        // competitive, since docs are visited in doc Id order, which means\n        // this doc cannot compete with any other document in the queue.\n        return;\n      }\n    }\n\n    // Remove before updating the group since lookup is done via comparators\n    // TODO: optimize this\n\n    final CollectedSearchGroup prevLast;\n    if (orderedGroups != null) {\n      prevLast = orderedGroups.last();\n      orderedGroups.remove(group);\n      assert orderedGroups.size() == topNGroups-1;\n    } else {\n      prevLast = null;\n    }\n\n    group.topDoc = docBase + doc;\n\n    // Swap slots\n    final int tmp = spareSlot;\n    spareSlot = group.comparatorSlot;\n    group.comparatorSlot = tmp;\n\n    // Re-add the changed group\n    if (orderedGroups != null) {\n      orderedGroups.add(group);\n      assert orderedGroups.size() == topNGroups;\n      final CollectedSearchGroup newLast = orderedGroups.last();\n      // If we changed the value of the last group, or changed which group was last, then update bottom:\n      if (group == newLast || prevLast != newLast) {\n        for (FieldComparator fc : comparators) {\n          fc.setBottom(newLast.comparatorSlot);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"c3a8a449466c1ff7ce2274fe73dab487256964b4":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","a7eeb270ab6ec07042d54fe23ad05cc7013c1552"],"a7eeb270ab6ec07042d54fe23ad05cc7013c1552":["307cff5af2b00f126fdf9d3435b75d5ed4d0f402"],"307cff5af2b00f126fdf9d3435b75d5ed4d0f402":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a3776dccca01c11e7046323cfad46a3b4a471233":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","a7eeb270ab6ec07042d54fe23ad05cc7013c1552"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"c03daa6ddcb4768a702115ec63799cab5fff3d92":["c3a8a449466c1ff7ce2274fe73dab487256964b4","1fa60a501961bce2ff07ee1cde7c78699025547e"],"1fa60a501961bce2ff07ee1cde7c78699025547e":["a7eeb270ab6ec07042d54fe23ad05cc7013c1552"],"1e7c99bd45fa88a3d93a03fdd773053bef72268e":["a3776dccca01c11e7046323cfad46a3b4a471233","1fa60a501961bce2ff07ee1cde7c78699025547e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["1fa60a501961bce2ff07ee1cde7c78699025547e"]},"commit2Childs":{"c3a8a449466c1ff7ce2274fe73dab487256964b4":["c03daa6ddcb4768a702115ec63799cab5fff3d92"],"a7eeb270ab6ec07042d54fe23ad05cc7013c1552":["c3a8a449466c1ff7ce2274fe73dab487256964b4","a3776dccca01c11e7046323cfad46a3b4a471233","1fa60a501961bce2ff07ee1cde7c78699025547e"],"307cff5af2b00f126fdf9d3435b75d5ed4d0f402":["a7eeb270ab6ec07042d54fe23ad05cc7013c1552"],"a3776dccca01c11e7046323cfad46a3b4a471233":["1e7c99bd45fa88a3d93a03fdd773053bef72268e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c3a8a449466c1ff7ce2274fe73dab487256964b4","307cff5af2b00f126fdf9d3435b75d5ed4d0f402","a3776dccca01c11e7046323cfad46a3b4a471233"],"c03daa6ddcb4768a702115ec63799cab5fff3d92":[],"1fa60a501961bce2ff07ee1cde7c78699025547e":["c03daa6ddcb4768a702115ec63799cab5fff3d92","1e7c99bd45fa88a3d93a03fdd773053bef72268e","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"1e7c99bd45fa88a3d93a03fdd773053bef72268e":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["c03daa6ddcb4768a702115ec63799cab5fff3d92","1e7c99bd45fa88a3d93a03fdd773053bef72268e","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}