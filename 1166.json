{"path":"modules/analysis/common/src/java/org/apache/lucene/analysis/standard/UAX29URLEmailTokenizer#populateAttributes(String).mjava","commits":[{"id":"351c452f1c3ded97338e6d3db2b585c5f89b0410","date":1291733593,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"modules/analysis/common/src/java/org/apache/lucene/analysis/standard/UAX29URLEmailTokenizer#populateAttributes(String).mjava","pathOld":"modules/analysis/common/src/java/org/apache/lucene/analysis/standard/UAX29Tokenizer#populateAttributes(String).mjava","sourceNew":"  /**\n   * Populates this TokenStream's CharTermAttribute and OffsetAttribute from\n   * the current match, the TypeAttribute from the passed-in tokenType, and\n   * the PositionIncrementAttribute to one, unless the immediately previous\n   * token(s) was/were skipped because maxTokenLength was exceeded, in which\n   * case the PositionIncrementAttribute is set to one plus the number of\n   * skipped overly long tokens. \n   * <p/> \n   * If maxTokenLength is exceeded, the CharTermAttribute is set back to empty\n   * and false is returned.\n   * \n   * @param tokenType The type of the matching token\n   * @return true there is a token available (not too long); false otherwise \n   */\n  private boolean populateAttributes(String tokenType) {\n    boolean isTokenAvailable = false;\n    if (yylength() > maxTokenLength) {\n      // When we skip a too-long token, we treat it like a stopword, introducing\n      // a position increment gap\n      ++posIncr;\n    } else {\n      termAtt.copyBuffer(zzBuffer, zzStartRead, yylength());\n      posIncrAtt.setPositionIncrement(posIncr);\n      offsetAtt.setOffset(correctOffset(yychar),\n                          correctOffset(yychar + yylength()));\n      typeAtt.setType(tokenType);\n      isTokenAvailable = true;\n    }\n    return isTokenAvailable;\n  }\n\n","sourceOld":"  /**\n   * Populates this TokenStream's CharTermAttribute and OffsetAttribute from\n   * the current match, the TypeAttribute from the passed-in tokenType, and\n   * the PositionIncrementAttribute to one, unless the immediately previous\n   * token(s) was/were skipped because maxTokenLength was exceeded, in which\n   * case the PositionIncrementAttribute is set to one plus the number of\n   * skipped overly long tokens. \n   * <p/> \n   * If maxTokenLength is exceeded, the CharTermAttribute is set back to empty\n   * and false is returned.\n   * \n   * @param tokenType The type of the matching token\n   * @return true there is a token available (not too long); false otherwise \n   */\n  private boolean populateAttributes(String tokenType) {\n    boolean isTokenAvailable = false;\n    if (yylength() > maxTokenLength) {\n      // When we skip a too-long token, we treat it like a stopword, introducing\n      // a position increment gap\n      ++posIncr;\n    } else {\n      termAtt.copyBuffer(zzBuffer, zzStartRead, yylength());\n      posIncrAtt.setPositionIncrement(posIncr);\n      offsetAtt.setOffset(correctOffset(yychar),\n                          correctOffset(yychar + yylength()));\n      typeAtt.setType(tokenType);\n      isTokenAvailable = true;\n    }\n    return isTokenAvailable;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d8c4bb144102e537495ae5b321f77a9898f7b0b8","date":1291834816,"type":1,"author":"Simon Willnauer","isMerge":true,"pathNew":"modules/analysis/common/src/java/org/apache/lucene/analysis/standard/UAX29URLEmailTokenizer#populateAttributes(String).mjava","pathOld":"modules/analysis/common/src/java/org/apache/lucene/analysis/standard/UAX29Tokenizer#populateAttributes(String).mjava","sourceNew":"  /**\n   * Populates this TokenStream's CharTermAttribute and OffsetAttribute from\n   * the current match, the TypeAttribute from the passed-in tokenType, and\n   * the PositionIncrementAttribute to one, unless the immediately previous\n   * token(s) was/were skipped because maxTokenLength was exceeded, in which\n   * case the PositionIncrementAttribute is set to one plus the number of\n   * skipped overly long tokens. \n   * <p/> \n   * If maxTokenLength is exceeded, the CharTermAttribute is set back to empty\n   * and false is returned.\n   * \n   * @param tokenType The type of the matching token\n   * @return true there is a token available (not too long); false otherwise \n   */\n  private boolean populateAttributes(String tokenType) {\n    boolean isTokenAvailable = false;\n    if (yylength() > maxTokenLength) {\n      // When we skip a too-long token, we treat it like a stopword, introducing\n      // a position increment gap\n      ++posIncr;\n    } else {\n      termAtt.copyBuffer(zzBuffer, zzStartRead, yylength());\n      posIncrAtt.setPositionIncrement(posIncr);\n      offsetAtt.setOffset(correctOffset(yychar),\n                          correctOffset(yychar + yylength()));\n      typeAtt.setType(tokenType);\n      isTokenAvailable = true;\n    }\n    return isTokenAvailable;\n  }\n\n","sourceOld":"  /**\n   * Populates this TokenStream's CharTermAttribute and OffsetAttribute from\n   * the current match, the TypeAttribute from the passed-in tokenType, and\n   * the PositionIncrementAttribute to one, unless the immediately previous\n   * token(s) was/were skipped because maxTokenLength was exceeded, in which\n   * case the PositionIncrementAttribute is set to one plus the number of\n   * skipped overly long tokens. \n   * <p/> \n   * If maxTokenLength is exceeded, the CharTermAttribute is set back to empty\n   * and false is returned.\n   * \n   * @param tokenType The type of the matching token\n   * @return true there is a token available (not too long); false otherwise \n   */\n  private boolean populateAttributes(String tokenType) {\n    boolean isTokenAvailable = false;\n    if (yylength() > maxTokenLength) {\n      // When we skip a too-long token, we treat it like a stopword, introducing\n      // a position increment gap\n      ++posIncr;\n    } else {\n      termAtt.copyBuffer(zzBuffer, zzStartRead, yylength());\n      posIncrAtt.setPositionIncrement(posIncr);\n      offsetAtt.setOffset(correctOffset(yychar),\n                          correctOffset(yychar + yylength()));\n      typeAtt.setType(tokenType);\n      isTokenAvailable = true;\n    }\n    return isTokenAvailable;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":0,"author":"Michael Busch","isMerge":true,"pathNew":"modules/analysis/common/src/java/org/apache/lucene/analysis/standard/UAX29URLEmailTokenizer#populateAttributes(String).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Populates this TokenStream's CharTermAttribute and OffsetAttribute from\n   * the current match, the TypeAttribute from the passed-in tokenType, and\n   * the PositionIncrementAttribute to one, unless the immediately previous\n   * token(s) was/were skipped because maxTokenLength was exceeded, in which\n   * case the PositionIncrementAttribute is set to one plus the number of\n   * skipped overly long tokens. \n   * <p/> \n   * If maxTokenLength is exceeded, the CharTermAttribute is set back to empty\n   * and false is returned.\n   * \n   * @param tokenType The type of the matching token\n   * @return true there is a token available (not too long); false otherwise \n   */\n  private boolean populateAttributes(String tokenType) {\n    boolean isTokenAvailable = false;\n    if (yylength() > maxTokenLength) {\n      // When we skip a too-long token, we treat it like a stopword, introducing\n      // a position increment gap\n      ++posIncr;\n    } else {\n      termAtt.copyBuffer(zzBuffer, zzStartRead, yylength());\n      posIncrAtt.setPositionIncrement(posIncr);\n      offsetAtt.setOffset(correctOffset(yychar),\n                          correctOffset(yychar + yylength()));\n      typeAtt.setType(tokenType);\n      isTokenAvailable = true;\n    }\n    return isTokenAvailable;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3f9c32789f4702d5cbb33bd153808068a4c43e3a","date":1312804679,"type":4,"author":"Robert Muir","isMerge":false,"pathNew":"/dev/null","pathOld":"modules/analysis/common/src/java/org/apache/lucene/analysis/standard/UAX29URLEmailTokenizer#populateAttributes(String).mjava","sourceNew":null,"sourceOld":"  /**\n   * Populates this TokenStream's CharTermAttribute and OffsetAttribute from\n   * the current match, the TypeAttribute from the passed-in tokenType, and\n   * the PositionIncrementAttribute to one, unless the immediately previous\n   * token(s) was/were skipped because maxTokenLength was exceeded, in which\n   * case the PositionIncrementAttribute is set to one plus the number of\n   * skipped overly long tokens. \n   * <p/> \n   * If maxTokenLength is exceeded, the CharTermAttribute is set back to empty\n   * and false is returned.\n   * \n   * @param tokenType The type of the matching token\n   * @return true there is a token available (not too long); false otherwise \n   */\n  private boolean populateAttributes(String tokenType) {\n    boolean isTokenAvailable = false;\n    if (yylength() > maxTokenLength) {\n      // When we skip a too-long token, we treat it like a stopword, introducing\n      // a position increment gap\n      ++posIncr;\n    } else {\n      termAtt.copyBuffer(zzBuffer, zzStartRead, yylength());\n      posIncrAtt.setPositionIncrement(posIncr);\n      offsetAtt.setOffset(correctOffset(yychar),\n                          correctOffset(yychar + yylength()));\n      typeAtt.setType(tokenType);\n      isTokenAvailable = true;\n    }\n    return isTokenAvailable;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"3f9c32789f4702d5cbb33bd153808068a4c43e3a":["351c452f1c3ded97338e6d3db2b585c5f89b0410"],"351c452f1c3ded97338e6d3db2b585c5f89b0410":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","351c452f1c3ded97338e6d3db2b585c5f89b0410"],"d8c4bb144102e537495ae5b321f77a9898f7b0b8":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","351c452f1c3ded97338e6d3db2b585c5f89b0410"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3f9c32789f4702d5cbb33bd153808068a4c43e3a"]},"commit2Childs":{"3f9c32789f4702d5cbb33bd153808068a4c43e3a":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"351c452f1c3ded97338e6d3db2b585c5f89b0410":["3f9c32789f4702d5cbb33bd153808068a4c43e3a","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","d8c4bb144102e537495ae5b321f77a9898f7b0b8"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["351c452f1c3ded97338e6d3db2b585c5f89b0410","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","d8c4bb144102e537495ae5b321f77a9898f7b0b8"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":[],"d8c4bb144102e537495ae5b321f77a9898f7b0b8":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","d8c4bb144102e537495ae5b321f77a9898f7b0b8","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}