{"path":"contrib/miscellaneous/src/java/org/apache/lucene/queryParser/analyzing/AnalyzingQueryParser#getWildcardQuery(String,String).mjava","commits":[{"id":"874880417e0b2612f777ecd0afe39e0d90486752","date":1123795738,"type":0,"author":"Daniel Naber","isMerge":false,"pathNew":"contrib/miscellaneous/src/java/org/apache/lucene/queryParser/analyzing/AnalyzingQueryParser#getWildcardQuery(String,String).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Called when parser\n   * parses an input term token that contains one or more wildcard\n   * characters (? and *), but is not a prefix term token (one\n   * that has just a single * character at the end)\n   * <p>\n   * Depending on analyzer and settings, a wildcard term may (most probably will)\n   * be lower-cased automatically. It <b>will</b> go through the default Analyzer.\n   * <p>\n   * Overrides super class, by passing terms through analyzer.\n   *\n   * @param  field   Name of the field query will use.\n   * @param  termStr Term token that contains one or more wild card\n   *                 characters (? or *), but is not simple prefix term\n   *\n   * @return Resulting {@link Query} built for the term\n   * @throws ParseException\n   */\n  protected Query getWildcardQuery(String field, String termStr) throws ParseException {\n    List tlist = new ArrayList();\n    List wlist = new ArrayList();\n    /* somewhat a hack: find/store wildcard chars\n     * in order to put them back after analyzing */\n    boolean isWithinToken = (!termStr.startsWith(\"?\") && !termStr.startsWith(\"*\"));\n    StringBuffer tmpBuffer = new StringBuffer();\n    char[] chars = termStr.toCharArray();\n    for (int i = 0; i < termStr.length(); i++) {\n      if (chars[i] == '?' || chars[i] == '*') {\n        if (isWithinToken) {\n          tlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = false;\n      } else {\n        if (!isWithinToken) {\n          wlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = true;\n      }\n      tmpBuffer.append(chars[i]);\n    }\n    if (isWithinToken) {\n      tlist.add(tmpBuffer.toString());\n    } else {\n      wlist.add(tmpBuffer.toString());\n    }\n\n    // get Analyzer from superclass and tokenize the term\n    TokenStream source = getAnalyzer().tokenStream(field, new StringReader(termStr));\n    org.apache.lucene.analysis.Token t;\n\n    int countTokens = 0;\n    while (true) {\n      try {\n        t = source.next();\n      } catch (IOException e) {\n        t = null;\n      }\n      if (t == null) {\n        break;\n      }\n      if (!\"\".equals(t.termText())) {\n        try {\n          tlist.set(countTokens++, t.termText());\n        } catch (IndexOutOfBoundsException ioobe) {\n          countTokens = -1;\n        }\n      }\n    }\n    try {\n      source.close();\n    } catch (IOException e) {\n      // ignore\n    }\n\n    if (countTokens != tlist.size()) {\n      /* this means that the analyzer used either added or consumed \n       * (common for a stemmer) tokens, and we can't build a WildcardQuery */\n      throw new ParseException(\"Cannot build WildcardQuery with analyzer \"\n          + getAnalyzer().getClass() + \" - tokens added or lost\");\n    }\n\n    if (tlist.size() == 0) {\n      return null;\n    } else if (tlist.size() == 1) {\n      if (wlist != null && wlist.size() == 1) {\n        /* if wlist contains one wildcard, it must be at the end, because:\n         * 1) wildcards are not allowed in 1st position of a term by QueryParser\n         * 2) if wildcard was *not* in end, there would be *two* or more tokens */\n        return super.getWildcardQuery(field, (String) tlist.get(0)\n            + (((String) wlist.get(0)).toString()));\n      } else {\n        /* we should never get here! if so, this method was called\n         * with a termStr containing no wildcard ... */\n        throw new IllegalArgumentException(\"getWildcardQuery called without wildcard\");\n      }\n    } else {\n      /* the term was tokenized, let's rebuild to one token\n       * with wildcards put back in postion */\n      StringBuffer sb = new StringBuffer();\n      for (int i = 0; i < tlist.size(); i++) {\n        sb.append((String) tlist.get(i));\n        if (wlist != null && wlist.size() > i) {\n          sb.append((String) wlist.get(i));\n        }\n      }\n      return super.getWildcardQuery(field, sb.toString());\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["046829b17e246624c179b94d5a20cb53fa945e87"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"10c49614cb8b943c412debb24ccb614128394470","date":1178343409,"type":3,"author":"Doron Cohen","isMerge":false,"pathNew":"contrib/miscellaneous/src/java/org/apache/lucene/queryParser/analyzing/AnalyzingQueryParser#getWildcardQuery(String,String).mjava","pathOld":"contrib/miscellaneous/src/java/org/apache/lucene/queryParser/analyzing/AnalyzingQueryParser#getWildcardQuery(String,String).mjava","sourceNew":"  /**\n   * Called when parser\n   * parses an input term token that contains one or more wildcard\n   * characters (like <code>*</code>), but is not a prefix term token (one\n   * that has just a single * character at the end).\n   * <p>\n   * Example: will be called for <code>H?user</code> or for <code>H*user</code> \n   * but not for <code>*user</code>.\n   * <p>\n   * Depending on analyzer and settings, a wildcard term may (most probably will)\n   * be lower-cased automatically. It <b>will</b> go through the default Analyzer.\n   * <p>\n   * Overrides super class, by passing terms through analyzer.\n   *\n   * @param  field   Name of the field query will use.\n   * @param  termStr Term token that contains one or more wild card\n   *                 characters (? or *), but is not simple prefix term\n   *\n   * @return Resulting {@link Query} built for the term\n   * @throws ParseException\n   */\n  protected Query getWildcardQuery(String field, String termStr) throws ParseException {\n    List tlist = new ArrayList();\n    List wlist = new ArrayList();\n    /* somewhat a hack: find/store wildcard chars\n     * in order to put them back after analyzing */\n    boolean isWithinToken = (!termStr.startsWith(\"?\") && !termStr.startsWith(\"*\"));\n    StringBuffer tmpBuffer = new StringBuffer();\n    char[] chars = termStr.toCharArray();\n    for (int i = 0; i < termStr.length(); i++) {\n      if (chars[i] == '?' || chars[i] == '*') {\n        if (isWithinToken) {\n          tlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = false;\n      } else {\n        if (!isWithinToken) {\n          wlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = true;\n      }\n      tmpBuffer.append(chars[i]);\n    }\n    if (isWithinToken) {\n      tlist.add(tmpBuffer.toString());\n    } else {\n      wlist.add(tmpBuffer.toString());\n    }\n\n    // get Analyzer from superclass and tokenize the term\n    TokenStream source = getAnalyzer().tokenStream(field, new StringReader(termStr));\n    org.apache.lucene.analysis.Token t;\n\n    int countTokens = 0;\n    while (true) {\n      try {\n        t = source.next();\n      } catch (IOException e) {\n        t = null;\n      }\n      if (t == null) {\n        break;\n      }\n      if (!\"\".equals(t.termText())) {\n        try {\n          tlist.set(countTokens++, t.termText());\n        } catch (IndexOutOfBoundsException ioobe) {\n          countTokens = -1;\n        }\n      }\n    }\n    try {\n      source.close();\n    } catch (IOException e) {\n      // ignore\n    }\n\n    if (countTokens != tlist.size()) {\n      /* this means that the analyzer used either added or consumed \n       * (common for a stemmer) tokens, and we can't build a WildcardQuery */\n      throw new ParseException(\"Cannot build WildcardQuery with analyzer \"\n          + getAnalyzer().getClass() + \" - tokens added or lost\");\n    }\n\n    if (tlist.size() == 0) {\n      return null;\n    } else if (tlist.size() == 1) {\n      if (wlist != null && wlist.size() == 1) {\n        /* if wlist contains one wildcard, it must be at the end, because:\n         * 1) wildcards are not allowed in 1st position of a term by QueryParser\n         * 2) if wildcard was *not* in end, there would be *two* or more tokens */\n        return super.getWildcardQuery(field, (String) tlist.get(0)\n            + (((String) wlist.get(0)).toString()));\n      } else {\n        /* we should never get here! if so, this method was called\n         * with a termStr containing no wildcard ... */\n        throw new IllegalArgumentException(\"getWildcardQuery called without wildcard\");\n      }\n    } else {\n      /* the term was tokenized, let's rebuild to one token\n       * with wildcards put back in postion */\n      StringBuffer sb = new StringBuffer();\n      for (int i = 0; i < tlist.size(); i++) {\n        sb.append((String) tlist.get(i));\n        if (wlist != null && wlist.size() > i) {\n          sb.append((String) wlist.get(i));\n        }\n      }\n      return super.getWildcardQuery(field, sb.toString());\n    }\n  }\n\n","sourceOld":"  /**\n   * Called when parser\n   * parses an input term token that contains one or more wildcard\n   * characters (? and *), but is not a prefix term token (one\n   * that has just a single * character at the end)\n   * <p>\n   * Depending on analyzer and settings, a wildcard term may (most probably will)\n   * be lower-cased automatically. It <b>will</b> go through the default Analyzer.\n   * <p>\n   * Overrides super class, by passing terms through analyzer.\n   *\n   * @param  field   Name of the field query will use.\n   * @param  termStr Term token that contains one or more wild card\n   *                 characters (? or *), but is not simple prefix term\n   *\n   * @return Resulting {@link Query} built for the term\n   * @throws ParseException\n   */\n  protected Query getWildcardQuery(String field, String termStr) throws ParseException {\n    List tlist = new ArrayList();\n    List wlist = new ArrayList();\n    /* somewhat a hack: find/store wildcard chars\n     * in order to put them back after analyzing */\n    boolean isWithinToken = (!termStr.startsWith(\"?\") && !termStr.startsWith(\"*\"));\n    StringBuffer tmpBuffer = new StringBuffer();\n    char[] chars = termStr.toCharArray();\n    for (int i = 0; i < termStr.length(); i++) {\n      if (chars[i] == '?' || chars[i] == '*') {\n        if (isWithinToken) {\n          tlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = false;\n      } else {\n        if (!isWithinToken) {\n          wlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = true;\n      }\n      tmpBuffer.append(chars[i]);\n    }\n    if (isWithinToken) {\n      tlist.add(tmpBuffer.toString());\n    } else {\n      wlist.add(tmpBuffer.toString());\n    }\n\n    // get Analyzer from superclass and tokenize the term\n    TokenStream source = getAnalyzer().tokenStream(field, new StringReader(termStr));\n    org.apache.lucene.analysis.Token t;\n\n    int countTokens = 0;\n    while (true) {\n      try {\n        t = source.next();\n      } catch (IOException e) {\n        t = null;\n      }\n      if (t == null) {\n        break;\n      }\n      if (!\"\".equals(t.termText())) {\n        try {\n          tlist.set(countTokens++, t.termText());\n        } catch (IndexOutOfBoundsException ioobe) {\n          countTokens = -1;\n        }\n      }\n    }\n    try {\n      source.close();\n    } catch (IOException e) {\n      // ignore\n    }\n\n    if (countTokens != tlist.size()) {\n      /* this means that the analyzer used either added or consumed \n       * (common for a stemmer) tokens, and we can't build a WildcardQuery */\n      throw new ParseException(\"Cannot build WildcardQuery with analyzer \"\n          + getAnalyzer().getClass() + \" - tokens added or lost\");\n    }\n\n    if (tlist.size() == 0) {\n      return null;\n    } else if (tlist.size() == 1) {\n      if (wlist != null && wlist.size() == 1) {\n        /* if wlist contains one wildcard, it must be at the end, because:\n         * 1) wildcards are not allowed in 1st position of a term by QueryParser\n         * 2) if wildcard was *not* in end, there would be *two* or more tokens */\n        return super.getWildcardQuery(field, (String) tlist.get(0)\n            + (((String) wlist.get(0)).toString()));\n      } else {\n        /* we should never get here! if so, this method was called\n         * with a termStr containing no wildcard ... */\n        throw new IllegalArgumentException(\"getWildcardQuery called without wildcard\");\n      }\n    } else {\n      /* the term was tokenized, let's rebuild to one token\n       * with wildcards put back in postion */\n      StringBuffer sb = new StringBuffer();\n      for (int i = 0; i < tlist.size(); i++) {\n        sb.append((String) tlist.get(i));\n        if (wlist != null && wlist.size() > i) {\n          sb.append((String) wlist.get(i));\n        }\n      }\n      return super.getWildcardQuery(field, sb.toString());\n    }\n  }\n\n","bugFix":null,"bugIntro":["046829b17e246624c179b94d5a20cb53fa945e87"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7e2cb543b41c145f33390f460ee743d6693c9c6c","date":1219243087,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"contrib/miscellaneous/src/java/org/apache/lucene/queryParser/analyzing/AnalyzingQueryParser#getWildcardQuery(String,String).mjava","pathOld":"contrib/miscellaneous/src/java/org/apache/lucene/queryParser/analyzing/AnalyzingQueryParser#getWildcardQuery(String,String).mjava","sourceNew":"  /**\n   * Called when parser\n   * parses an input term token that contains one or more wildcard\n   * characters (like <code>*</code>), but is not a prefix term token (one\n   * that has just a single * character at the end).\n   * <p>\n   * Example: will be called for <code>H?user</code> or for <code>H*user</code> \n   * but not for <code>*user</code>.\n   * <p>\n   * Depending on analyzer and settings, a wildcard term may (most probably will)\n   * be lower-cased automatically. It <b>will</b> go through the default Analyzer.\n   * <p>\n   * Overrides super class, by passing terms through analyzer.\n   *\n   * @param  field   Name of the field query will use.\n   * @param  termStr Term token that contains one or more wild card\n   *                 characters (? or *), but is not simple prefix term\n   *\n   * @return Resulting {@link Query} built for the term\n   * @throws ParseException\n   */\n  protected Query getWildcardQuery(String field, String termStr) throws ParseException {\n    List tlist = new ArrayList();\n    List wlist = new ArrayList();\n    /* somewhat a hack: find/store wildcard chars\n     * in order to put them back after analyzing */\n    boolean isWithinToken = (!termStr.startsWith(\"?\") && !termStr.startsWith(\"*\"));\n    StringBuffer tmpBuffer = new StringBuffer();\n    char[] chars = termStr.toCharArray();\n    for (int i = 0; i < termStr.length(); i++) {\n      if (chars[i] == '?' || chars[i] == '*') {\n        if (isWithinToken) {\n          tlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = false;\n      } else {\n        if (!isWithinToken) {\n          wlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = true;\n      }\n      tmpBuffer.append(chars[i]);\n    }\n    if (isWithinToken) {\n      tlist.add(tmpBuffer.toString());\n    } else {\n      wlist.add(tmpBuffer.toString());\n    }\n\n    // get Analyzer from superclass and tokenize the term\n    TokenStream source = getAnalyzer().tokenStream(field, new StringReader(termStr));\n    final Token reusableToken = new Token();\n    Token nextToken;\n\n    int countTokens = 0;\n    while (true) {\n      try {\n        nextToken = source.next(reusableToken);\n      } catch (IOException e) {\n        nextToken = null;\n      }\n      if (nextToken == null) {\n        break;\n      }\n      String term = nextToken.term();\n      if (!\"\".equals(term)) {\n        try {\n          tlist.set(countTokens++, term);\n        } catch (IndexOutOfBoundsException ioobe) {\n          countTokens = -1;\n        }\n      }\n    }\n    try {\n      source.close();\n    } catch (IOException e) {\n      // ignore\n    }\n\n    if (countTokens != tlist.size()) {\n      /* this means that the analyzer used either added or consumed \n       * (common for a stemmer) tokens, and we can't build a WildcardQuery */\n      throw new ParseException(\"Cannot build WildcardQuery with analyzer \"\n          + getAnalyzer().getClass() + \" - tokens added or lost\");\n    }\n\n    if (tlist.size() == 0) {\n      return null;\n    } else if (tlist.size() == 1) {\n      if (wlist != null && wlist.size() == 1) {\n        /* if wlist contains one wildcard, it must be at the end, because:\n         * 1) wildcards are not allowed in 1st position of a term by QueryParser\n         * 2) if wildcard was *not* in end, there would be *two* or more tokens */\n        return super.getWildcardQuery(field, (String) tlist.get(0)\n            + (((String) wlist.get(0)).toString()));\n      } else {\n        /* we should never get here! if so, this method was called\n         * with a termStr containing no wildcard ... */\n        throw new IllegalArgumentException(\"getWildcardQuery called without wildcard\");\n      }\n    } else {\n      /* the term was tokenized, let's rebuild to one token\n       * with wildcards put back in postion */\n      StringBuffer sb = new StringBuffer();\n      for (int i = 0; i < tlist.size(); i++) {\n        sb.append((String) tlist.get(i));\n        if (wlist != null && wlist.size() > i) {\n          sb.append((String) wlist.get(i));\n        }\n      }\n      return super.getWildcardQuery(field, sb.toString());\n    }\n  }\n\n","sourceOld":"  /**\n   * Called when parser\n   * parses an input term token that contains one or more wildcard\n   * characters (like <code>*</code>), but is not a prefix term token (one\n   * that has just a single * character at the end).\n   * <p>\n   * Example: will be called for <code>H?user</code> or for <code>H*user</code> \n   * but not for <code>*user</code>.\n   * <p>\n   * Depending on analyzer and settings, a wildcard term may (most probably will)\n   * be lower-cased automatically. It <b>will</b> go through the default Analyzer.\n   * <p>\n   * Overrides super class, by passing terms through analyzer.\n   *\n   * @param  field   Name of the field query will use.\n   * @param  termStr Term token that contains one or more wild card\n   *                 characters (? or *), but is not simple prefix term\n   *\n   * @return Resulting {@link Query} built for the term\n   * @throws ParseException\n   */\n  protected Query getWildcardQuery(String field, String termStr) throws ParseException {\n    List tlist = new ArrayList();\n    List wlist = new ArrayList();\n    /* somewhat a hack: find/store wildcard chars\n     * in order to put them back after analyzing */\n    boolean isWithinToken = (!termStr.startsWith(\"?\") && !termStr.startsWith(\"*\"));\n    StringBuffer tmpBuffer = new StringBuffer();\n    char[] chars = termStr.toCharArray();\n    for (int i = 0; i < termStr.length(); i++) {\n      if (chars[i] == '?' || chars[i] == '*') {\n        if (isWithinToken) {\n          tlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = false;\n      } else {\n        if (!isWithinToken) {\n          wlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = true;\n      }\n      tmpBuffer.append(chars[i]);\n    }\n    if (isWithinToken) {\n      tlist.add(tmpBuffer.toString());\n    } else {\n      wlist.add(tmpBuffer.toString());\n    }\n\n    // get Analyzer from superclass and tokenize the term\n    TokenStream source = getAnalyzer().tokenStream(field, new StringReader(termStr));\n    org.apache.lucene.analysis.Token t;\n\n    int countTokens = 0;\n    while (true) {\n      try {\n        t = source.next();\n      } catch (IOException e) {\n        t = null;\n      }\n      if (t == null) {\n        break;\n      }\n      if (!\"\".equals(t.termText())) {\n        try {\n          tlist.set(countTokens++, t.termText());\n        } catch (IndexOutOfBoundsException ioobe) {\n          countTokens = -1;\n        }\n      }\n    }\n    try {\n      source.close();\n    } catch (IOException e) {\n      // ignore\n    }\n\n    if (countTokens != tlist.size()) {\n      /* this means that the analyzer used either added or consumed \n       * (common for a stemmer) tokens, and we can't build a WildcardQuery */\n      throw new ParseException(\"Cannot build WildcardQuery with analyzer \"\n          + getAnalyzer().getClass() + \" - tokens added or lost\");\n    }\n\n    if (tlist.size() == 0) {\n      return null;\n    } else if (tlist.size() == 1) {\n      if (wlist != null && wlist.size() == 1) {\n        /* if wlist contains one wildcard, it must be at the end, because:\n         * 1) wildcards are not allowed in 1st position of a term by QueryParser\n         * 2) if wildcard was *not* in end, there would be *two* or more tokens */\n        return super.getWildcardQuery(field, (String) tlist.get(0)\n            + (((String) wlist.get(0)).toString()));\n      } else {\n        /* we should never get here! if so, this method was called\n         * with a termStr containing no wildcard ... */\n        throw new IllegalArgumentException(\"getWildcardQuery called without wildcard\");\n      }\n    } else {\n      /* the term was tokenized, let's rebuild to one token\n       * with wildcards put back in postion */\n      StringBuffer sb = new StringBuffer();\n      for (int i = 0; i < tlist.size(); i++) {\n        sb.append((String) tlist.get(i));\n        if (wlist != null && wlist.size() > i) {\n          sb.append((String) wlist.get(i));\n        }\n      }\n      return super.getWildcardQuery(field, sb.toString());\n    }\n  }\n\n","bugFix":null,"bugIntro":["046829b17e246624c179b94d5a20cb53fa945e87"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9b5756469957918cac40a831acec9cf01c8c2bb3","date":1249167152,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"contrib/miscellaneous/src/java/org/apache/lucene/queryParser/analyzing/AnalyzingQueryParser#getWildcardQuery(String,String).mjava","pathOld":"contrib/miscellaneous/src/java/org/apache/lucene/queryParser/analyzing/AnalyzingQueryParser#getWildcardQuery(String,String).mjava","sourceNew":"  /**\n   * Called when parser\n   * parses an input term token that contains one or more wildcard\n   * characters (like <code>*</code>), but is not a prefix term token (one\n   * that has just a single * character at the end).\n   * <p>\n   * Example: will be called for <code>H?user</code> or for <code>H*user</code> \n   * but not for <code>*user</code>.\n   * <p>\n   * Depending on analyzer and settings, a wildcard term may (most probably will)\n   * be lower-cased automatically. It <b>will</b> go through the default Analyzer.\n   * <p>\n   * Overrides super class, by passing terms through analyzer.\n   *\n   * @param  field   Name of the field query will use.\n   * @param  termStr Term token that contains one or more wild card\n   *                 characters (? or *), but is not simple prefix term\n   *\n   * @return Resulting {@link Query} built for the term\n   * @throws ParseException\n   */\n  protected Query getWildcardQuery(String field, String termStr) throws ParseException {\n    List tlist = new ArrayList();\n    List wlist = new ArrayList();\n    /* somewhat a hack: find/store wildcard chars\n     * in order to put them back after analyzing */\n    boolean isWithinToken = (!termStr.startsWith(\"?\") && !termStr.startsWith(\"*\"));\n    StringBuffer tmpBuffer = new StringBuffer();\n    char[] chars = termStr.toCharArray();\n    for (int i = 0; i < termStr.length(); i++) {\n      if (chars[i] == '?' || chars[i] == '*') {\n        if (isWithinToken) {\n          tlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = false;\n      } else {\n        if (!isWithinToken) {\n          wlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = true;\n      }\n      tmpBuffer.append(chars[i]);\n    }\n    if (isWithinToken) {\n      tlist.add(tmpBuffer.toString());\n    } else {\n      wlist.add(tmpBuffer.toString());\n    }\n\n    // get Analyzer from superclass and tokenize the term\n    TokenStream source = getAnalyzer().tokenStream(field, new StringReader(termStr));\n    TermAttribute termAtt = (TermAttribute) source.addAttribute(TermAttribute.class);\n    \n    int countTokens = 0;\n    while (true) {\n      try {\n        if (!source.incrementToken()) break;\n      } catch (IOException e) {\n        break;\n      }\n      String term = termAtt.term();\n      if (!\"\".equals(term)) {\n        try {\n          tlist.set(countTokens++, term);\n        } catch (IndexOutOfBoundsException ioobe) {\n          countTokens = -1;\n        }\n      }\n    }\n    try {\n      source.close();\n    } catch (IOException e) {\n      // ignore\n    }\n\n    if (countTokens != tlist.size()) {\n      /* this means that the analyzer used either added or consumed \n       * (common for a stemmer) tokens, and we can't build a WildcardQuery */\n      throw new ParseException(\"Cannot build WildcardQuery with analyzer \"\n          + getAnalyzer().getClass() + \" - tokens added or lost\");\n    }\n\n    if (tlist.size() == 0) {\n      return null;\n    } else if (tlist.size() == 1) {\n      if (wlist != null && wlist.size() == 1) {\n        /* if wlist contains one wildcard, it must be at the end, because:\n         * 1) wildcards are not allowed in 1st position of a term by QueryParser\n         * 2) if wildcard was *not* in end, there would be *two* or more tokens */\n        return super.getWildcardQuery(field, (String) tlist.get(0)\n            + (((String) wlist.get(0)).toString()));\n      } else {\n        /* we should never get here! if so, this method was called\n         * with a termStr containing no wildcard ... */\n        throw new IllegalArgumentException(\"getWildcardQuery called without wildcard\");\n      }\n    } else {\n      /* the term was tokenized, let's rebuild to one token\n       * with wildcards put back in postion */\n      StringBuffer sb = new StringBuffer();\n      for (int i = 0; i < tlist.size(); i++) {\n        sb.append((String) tlist.get(i));\n        if (wlist != null && wlist.size() > i) {\n          sb.append((String) wlist.get(i));\n        }\n      }\n      return super.getWildcardQuery(field, sb.toString());\n    }\n  }\n\n","sourceOld":"  /**\n   * Called when parser\n   * parses an input term token that contains one or more wildcard\n   * characters (like <code>*</code>), but is not a prefix term token (one\n   * that has just a single * character at the end).\n   * <p>\n   * Example: will be called for <code>H?user</code> or for <code>H*user</code> \n   * but not for <code>*user</code>.\n   * <p>\n   * Depending on analyzer and settings, a wildcard term may (most probably will)\n   * be lower-cased automatically. It <b>will</b> go through the default Analyzer.\n   * <p>\n   * Overrides super class, by passing terms through analyzer.\n   *\n   * @param  field   Name of the field query will use.\n   * @param  termStr Term token that contains one or more wild card\n   *                 characters (? or *), but is not simple prefix term\n   *\n   * @return Resulting {@link Query} built for the term\n   * @throws ParseException\n   */\n  protected Query getWildcardQuery(String field, String termStr) throws ParseException {\n    List tlist = new ArrayList();\n    List wlist = new ArrayList();\n    /* somewhat a hack: find/store wildcard chars\n     * in order to put them back after analyzing */\n    boolean isWithinToken = (!termStr.startsWith(\"?\") && !termStr.startsWith(\"*\"));\n    StringBuffer tmpBuffer = new StringBuffer();\n    char[] chars = termStr.toCharArray();\n    for (int i = 0; i < termStr.length(); i++) {\n      if (chars[i] == '?' || chars[i] == '*') {\n        if (isWithinToken) {\n          tlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = false;\n      } else {\n        if (!isWithinToken) {\n          wlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = true;\n      }\n      tmpBuffer.append(chars[i]);\n    }\n    if (isWithinToken) {\n      tlist.add(tmpBuffer.toString());\n    } else {\n      wlist.add(tmpBuffer.toString());\n    }\n\n    // get Analyzer from superclass and tokenize the term\n    TokenStream source = getAnalyzer().tokenStream(field, new StringReader(termStr));\n    final Token reusableToken = new Token();\n    Token nextToken;\n\n    int countTokens = 0;\n    while (true) {\n      try {\n        nextToken = source.next(reusableToken);\n      } catch (IOException e) {\n        nextToken = null;\n      }\n      if (nextToken == null) {\n        break;\n      }\n      String term = nextToken.term();\n      if (!\"\".equals(term)) {\n        try {\n          tlist.set(countTokens++, term);\n        } catch (IndexOutOfBoundsException ioobe) {\n          countTokens = -1;\n        }\n      }\n    }\n    try {\n      source.close();\n    } catch (IOException e) {\n      // ignore\n    }\n\n    if (countTokens != tlist.size()) {\n      /* this means that the analyzer used either added or consumed \n       * (common for a stemmer) tokens, and we can't build a WildcardQuery */\n      throw new ParseException(\"Cannot build WildcardQuery with analyzer \"\n          + getAnalyzer().getClass() + \" - tokens added or lost\");\n    }\n\n    if (tlist.size() == 0) {\n      return null;\n    } else if (tlist.size() == 1) {\n      if (wlist != null && wlist.size() == 1) {\n        /* if wlist contains one wildcard, it must be at the end, because:\n         * 1) wildcards are not allowed in 1st position of a term by QueryParser\n         * 2) if wildcard was *not* in end, there would be *two* or more tokens */\n        return super.getWildcardQuery(field, (String) tlist.get(0)\n            + (((String) wlist.get(0)).toString()));\n      } else {\n        /* we should never get here! if so, this method was called\n         * with a termStr containing no wildcard ... */\n        throw new IllegalArgumentException(\"getWildcardQuery called without wildcard\");\n      }\n    } else {\n      /* the term was tokenized, let's rebuild to one token\n       * with wildcards put back in postion */\n      StringBuffer sb = new StringBuffer();\n      for (int i = 0; i < tlist.size(); i++) {\n        sb.append((String) tlist.get(i));\n        if (wlist != null && wlist.size() > i) {\n          sb.append((String) wlist.get(i));\n        }\n      }\n      return super.getWildcardQuery(field, sb.toString());\n    }\n  }\n\n","bugFix":null,"bugIntro":["046829b17e246624c179b94d5a20cb53fa945e87"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"48bedd31c61edafb8baaff4bcbcac19449fb7c3a","date":1251468037,"type":5,"author":"Mark Robert Miller","isMerge":false,"pathNew":"contrib/misc/src/java/org/apache/lucene/queryParser/analyzing/AnalyzingQueryParser#getWildcardQuery(String,String).mjava","pathOld":"contrib/miscellaneous/src/java/org/apache/lucene/queryParser/analyzing/AnalyzingQueryParser#getWildcardQuery(String,String).mjava","sourceNew":"  /**\n   * Called when parser\n   * parses an input term token that contains one or more wildcard\n   * characters (like <code>*</code>), but is not a prefix term token (one\n   * that has just a single * character at the end).\n   * <p>\n   * Example: will be called for <code>H?user</code> or for <code>H*user</code> \n   * but not for <code>*user</code>.\n   * <p>\n   * Depending on analyzer and settings, a wildcard term may (most probably will)\n   * be lower-cased automatically. It <b>will</b> go through the default Analyzer.\n   * <p>\n   * Overrides super class, by passing terms through analyzer.\n   *\n   * @param  field   Name of the field query will use.\n   * @param  termStr Term token that contains one or more wild card\n   *                 characters (? or *), but is not simple prefix term\n   *\n   * @return Resulting {@link Query} built for the term\n   * @throws ParseException\n   */\n  protected Query getWildcardQuery(String field, String termStr) throws ParseException {\n    List tlist = new ArrayList();\n    List wlist = new ArrayList();\n    /* somewhat a hack: find/store wildcard chars\n     * in order to put them back after analyzing */\n    boolean isWithinToken = (!termStr.startsWith(\"?\") && !termStr.startsWith(\"*\"));\n    StringBuffer tmpBuffer = new StringBuffer();\n    char[] chars = termStr.toCharArray();\n    for (int i = 0; i < termStr.length(); i++) {\n      if (chars[i] == '?' || chars[i] == '*') {\n        if (isWithinToken) {\n          tlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = false;\n      } else {\n        if (!isWithinToken) {\n          wlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = true;\n      }\n      tmpBuffer.append(chars[i]);\n    }\n    if (isWithinToken) {\n      tlist.add(tmpBuffer.toString());\n    } else {\n      wlist.add(tmpBuffer.toString());\n    }\n\n    // get Analyzer from superclass and tokenize the term\n    TokenStream source = getAnalyzer().tokenStream(field, new StringReader(termStr));\n    TermAttribute termAtt = (TermAttribute) source.addAttribute(TermAttribute.class);\n    \n    int countTokens = 0;\n    while (true) {\n      try {\n        if (!source.incrementToken()) break;\n      } catch (IOException e) {\n        break;\n      }\n      String term = termAtt.term();\n      if (!\"\".equals(term)) {\n        try {\n          tlist.set(countTokens++, term);\n        } catch (IndexOutOfBoundsException ioobe) {\n          countTokens = -1;\n        }\n      }\n    }\n    try {\n      source.close();\n    } catch (IOException e) {\n      // ignore\n    }\n\n    if (countTokens != tlist.size()) {\n      /* this means that the analyzer used either added or consumed \n       * (common for a stemmer) tokens, and we can't build a WildcardQuery */\n      throw new ParseException(\"Cannot build WildcardQuery with analyzer \"\n          + getAnalyzer().getClass() + \" - tokens added or lost\");\n    }\n\n    if (tlist.size() == 0) {\n      return null;\n    } else if (tlist.size() == 1) {\n      if (wlist != null && wlist.size() == 1) {\n        /* if wlist contains one wildcard, it must be at the end, because:\n         * 1) wildcards are not allowed in 1st position of a term by QueryParser\n         * 2) if wildcard was *not* in end, there would be *two* or more tokens */\n        return super.getWildcardQuery(field, (String) tlist.get(0)\n            + (((String) wlist.get(0)).toString()));\n      } else {\n        /* we should never get here! if so, this method was called\n         * with a termStr containing no wildcard ... */\n        throw new IllegalArgumentException(\"getWildcardQuery called without wildcard\");\n      }\n    } else {\n      /* the term was tokenized, let's rebuild to one token\n       * with wildcards put back in postion */\n      StringBuffer sb = new StringBuffer();\n      for (int i = 0; i < tlist.size(); i++) {\n        sb.append((String) tlist.get(i));\n        if (wlist != null && wlist.size() > i) {\n          sb.append((String) wlist.get(i));\n        }\n      }\n      return super.getWildcardQuery(field, sb.toString());\n    }\n  }\n\n","sourceOld":"  /**\n   * Called when parser\n   * parses an input term token that contains one or more wildcard\n   * characters (like <code>*</code>), but is not a prefix term token (one\n   * that has just a single * character at the end).\n   * <p>\n   * Example: will be called for <code>H?user</code> or for <code>H*user</code> \n   * but not for <code>*user</code>.\n   * <p>\n   * Depending on analyzer and settings, a wildcard term may (most probably will)\n   * be lower-cased automatically. It <b>will</b> go through the default Analyzer.\n   * <p>\n   * Overrides super class, by passing terms through analyzer.\n   *\n   * @param  field   Name of the field query will use.\n   * @param  termStr Term token that contains one or more wild card\n   *                 characters (? or *), but is not simple prefix term\n   *\n   * @return Resulting {@link Query} built for the term\n   * @throws ParseException\n   */\n  protected Query getWildcardQuery(String field, String termStr) throws ParseException {\n    List tlist = new ArrayList();\n    List wlist = new ArrayList();\n    /* somewhat a hack: find/store wildcard chars\n     * in order to put them back after analyzing */\n    boolean isWithinToken = (!termStr.startsWith(\"?\") && !termStr.startsWith(\"*\"));\n    StringBuffer tmpBuffer = new StringBuffer();\n    char[] chars = termStr.toCharArray();\n    for (int i = 0; i < termStr.length(); i++) {\n      if (chars[i] == '?' || chars[i] == '*') {\n        if (isWithinToken) {\n          tlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = false;\n      } else {\n        if (!isWithinToken) {\n          wlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = true;\n      }\n      tmpBuffer.append(chars[i]);\n    }\n    if (isWithinToken) {\n      tlist.add(tmpBuffer.toString());\n    } else {\n      wlist.add(tmpBuffer.toString());\n    }\n\n    // get Analyzer from superclass and tokenize the term\n    TokenStream source = getAnalyzer().tokenStream(field, new StringReader(termStr));\n    TermAttribute termAtt = (TermAttribute) source.addAttribute(TermAttribute.class);\n    \n    int countTokens = 0;\n    while (true) {\n      try {\n        if (!source.incrementToken()) break;\n      } catch (IOException e) {\n        break;\n      }\n      String term = termAtt.term();\n      if (!\"\".equals(term)) {\n        try {\n          tlist.set(countTokens++, term);\n        } catch (IndexOutOfBoundsException ioobe) {\n          countTokens = -1;\n        }\n      }\n    }\n    try {\n      source.close();\n    } catch (IOException e) {\n      // ignore\n    }\n\n    if (countTokens != tlist.size()) {\n      /* this means that the analyzer used either added or consumed \n       * (common for a stemmer) tokens, and we can't build a WildcardQuery */\n      throw new ParseException(\"Cannot build WildcardQuery with analyzer \"\n          + getAnalyzer().getClass() + \" - tokens added or lost\");\n    }\n\n    if (tlist.size() == 0) {\n      return null;\n    } else if (tlist.size() == 1) {\n      if (wlist != null && wlist.size() == 1) {\n        /* if wlist contains one wildcard, it must be at the end, because:\n         * 1) wildcards are not allowed in 1st position of a term by QueryParser\n         * 2) if wildcard was *not* in end, there would be *two* or more tokens */\n        return super.getWildcardQuery(field, (String) tlist.get(0)\n            + (((String) wlist.get(0)).toString()));\n      } else {\n        /* we should never get here! if so, this method was called\n         * with a termStr containing no wildcard ... */\n        throw new IllegalArgumentException(\"getWildcardQuery called without wildcard\");\n      }\n    } else {\n      /* the term was tokenized, let's rebuild to one token\n       * with wildcards put back in postion */\n      StringBuffer sb = new StringBuffer();\n      for (int i = 0; i < tlist.size(); i++) {\n        sb.append((String) tlist.get(i));\n        if (wlist != null && wlist.size() > i) {\n          sb.append((String) wlist.get(i));\n        }\n      }\n      return super.getWildcardQuery(field, sb.toString());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"7e2cb543b41c145f33390f460ee743d6693c9c6c":["10c49614cb8b943c412debb24ccb614128394470"],"874880417e0b2612f777ecd0afe39e0d90486752":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"48bedd31c61edafb8baaff4bcbcac19449fb7c3a":["9b5756469957918cac40a831acec9cf01c8c2bb3"],"10c49614cb8b943c412debb24ccb614128394470":["874880417e0b2612f777ecd0afe39e0d90486752"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"9b5756469957918cac40a831acec9cf01c8c2bb3":["7e2cb543b41c145f33390f460ee743d6693c9c6c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["48bedd31c61edafb8baaff4bcbcac19449fb7c3a"]},"commit2Childs":{"7e2cb543b41c145f33390f460ee743d6693c9c6c":["9b5756469957918cac40a831acec9cf01c8c2bb3"],"874880417e0b2612f777ecd0afe39e0d90486752":["10c49614cb8b943c412debb24ccb614128394470"],"10c49614cb8b943c412debb24ccb614128394470":["7e2cb543b41c145f33390f460ee743d6693c9c6c"],"48bedd31c61edafb8baaff4bcbcac19449fb7c3a":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["874880417e0b2612f777ecd0afe39e0d90486752"],"9b5756469957918cac40a831acec9cf01c8c2bb3":["48bedd31c61edafb8baaff4bcbcac19449fb7c3a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}