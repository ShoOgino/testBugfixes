{"path":"contrib/memory/src/java/org/apache/lucene/index/memory/AnalyzerUtil#getMostFrequentTerms(Analyzer,String,int).mjava","commits":[{"id":"ea82415927cafd7c8b8bceca08f31a63db1cbdde","date":1133588579,"type":0,"author":"Wolfgang Hoschek","isMerge":false,"pathNew":"contrib/memory/src/java/org/apache/lucene/index/memory/AnalyzerUtil#getMostFrequentTerms(Analyzer,String,int).mjava","pathOld":"/dev/null","sourceNew":"\t/**\n\t * Returns (frequency:text) pairs for the top N distinct terms (aka words),\n\t * sorted descending by frequency (and ascending by term, if tied).\n\t * <p>\n\t * Example XQuery:\n\t * <pre>\n\t * declare namespace util = \"java:org.apache.lucene.index.memory.AnalyzerUtil\";\n\t * declare namespace analyzer = \"java:org.apache.lucene.index.memory.PatternAnalyzer\";\n\t * \n\t * for $pair in util:get-most-frequent-terms(\n\t *    analyzer:EXTENDED_ANALYZER(), doc(\"samples/shakespeare/othello.xml\"), 10)\n\t * return &lt;word word=\"{substring-after($pair, ':')}\" frequency=\"{substring-before($pair, ':')}\"/>\n\t * </pre>\n\t * \n\t * @param analyzer\n\t *            the analyzer to use for splitting text into terms (aka words)\n\t * @param text\n\t *            the text to analyze\n\t * @param limit\n\t *            the maximum number of pairs to return; zero indicates \n\t *            \"as many as possible\".\n\t * @return an array of (frequency:text) pairs in the form of (freq0:text0,\n\t *         freq1:text1, ..., freqN:textN). Each pair is a single string\n\t *         separated by a ':' delimiter.\n\t */\n\tpublic static String[] getMostFrequentTerms(Analyzer analyzer, String text, int limit) {\n\t\tif (analyzer == null) \n\t\t\tthrow new IllegalArgumentException(\"analyzer must not be null\");\n\t\tif (text == null) \n\t\t\tthrow new IllegalArgumentException(\"text must not be null\");\n\t\tif (limit <= 0) limit = Integer.MAX_VALUE;\n\t\t\n\t\t// compute frequencies of distinct terms\n\t\tHashMap map = new HashMap();\n\t\tTokenStream stream = analyzer.tokenStream(\"\", new StringReader(text));\n\t\ttry {\n\t\t\tToken token;\n\t\t\twhile ((token = stream.next()) != null) {\n\t\t\t\tMutableInteger freq = (MutableInteger) map.get(token.termText());\n\t\t\t\tif (freq == null) {\n\t\t\t\t\tfreq = new MutableInteger(1);\n\t\t\t\t\tmap.put(token.termText(), freq);\n\t\t\t\t} else {\n\t\t\t\t\tfreq.setValue(freq.intValue() + 1);\n\t\t\t\t}\n\t\t\t}\n\t\t} catch (IOException e) {\n\t\t\tthrow new RuntimeException(e);\n\t\t} finally {\n\t\t\ttry {\n\t\t\t\tstream.close();\n\t\t\t} catch (IOException e2) {\n\t\t\t\tthrow new RuntimeException(e2);\n\t\t\t}\n\t\t}\n\t\t\n\t\t// sort by frequency, text\n\t\tMap.Entry[] entries = new Map.Entry[map.size()];\n\t\tmap.entrySet().toArray(entries);\n\t\tArrays.sort(entries, new Comparator() {\n\t\t\tpublic int compare(Object o1, Object o2) {\n\t\t\t\tMap.Entry e1 = (Map.Entry) o1;\n\t\t\t\tMap.Entry e2 = (Map.Entry) o2;\n\t\t\t\tint f1 = ((MutableInteger) e1.getValue()).intValue();\n\t\t\t\tint f2 = ((MutableInteger) e2.getValue()).intValue();\n\t\t\t\tif (f2 - f1 != 0) return f2 - f1;\n\t\t\t\tString s1 = (String) e1.getKey();\n\t\t\t\tString s2 = (String) e2.getKey();\n\t\t\t\treturn s1.compareTo(s2);\n\t\t\t}\n\t\t});\n\t\t\n\t\t// return top N entries\n\t\tint size = Math.min(limit, entries.length);\n\t\tString[] pairs = new String[size];\n\t\tfor (int i=0; i < size; i++) {\n\t\t\tpairs[i] = entries[i].getValue() + \":\" + entries[i].getKey();\n\t\t}\n\t\treturn pairs;\n\t}\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"acdb560b7878968b4b295f01dae1b29d195d6175","date":1138325561,"type":3,"author":"Wolfgang Hoschek","isMerge":false,"pathNew":"contrib/memory/src/java/org/apache/lucene/index/memory/AnalyzerUtil#getMostFrequentTerms(Analyzer,String,int).mjava","pathOld":"contrib/memory/src/java/org/apache/lucene/index/memory/AnalyzerUtil#getMostFrequentTerms(Analyzer,String,int).mjava","sourceNew":"\t/**\n\t * Returns (frequency:term) pairs for the top N distinct terms (aka words),\n\t * sorted descending by frequency (and ascending by term, if tied).\n\t * <p>\n\t * Example XQuery:\n\t * <pre>\n\t * declare namespace util = \"java:org.apache.lucene.index.memory.AnalyzerUtil\";\n\t * declare namespace analyzer = \"java:org.apache.lucene.index.memory.PatternAnalyzer\";\n\t * \n\t * for $pair in util:get-most-frequent-terms(\n\t *    analyzer:EXTENDED_ANALYZER(), doc(\"samples/shakespeare/othello.xml\"), 10)\n\t * return &lt;word word=\"{substring-after($pair, ':')}\" frequency=\"{substring-before($pair, ':')}\"/>\n\t * </pre>\n\t * \n\t * @param analyzer\n\t *            the analyzer to use for splitting text into terms (aka words)\n\t * @param text\n\t *            the text to analyze\n\t * @param limit\n\t *            the maximum number of pairs to return; zero indicates \n\t *            \"as many as possible\".\n\t * @return an array of (frequency:term) pairs in the form of (freq0:term0,\n\t *         freq1:term1, ..., freqN:termN). Each pair is a single string\n\t *         separated by a ':' delimiter.\n\t */\n\tpublic static String[] getMostFrequentTerms(Analyzer analyzer, String text, int limit) {\n\t\tif (analyzer == null) \n\t\t\tthrow new IllegalArgumentException(\"analyzer must not be null\");\n\t\tif (text == null) \n\t\t\tthrow new IllegalArgumentException(\"text must not be null\");\n\t\tif (limit <= 0) limit = Integer.MAX_VALUE;\n\t\t\n\t\t// compute frequencies of distinct terms\n\t\tHashMap map = new HashMap();\n\t\tTokenStream stream = analyzer.tokenStream(\"\", new StringReader(text));\n\t\ttry {\n\t\t\tToken token;\n\t\t\twhile ((token = stream.next()) != null) {\n\t\t\t\tMutableInteger freq = (MutableInteger) map.get(token.termText());\n\t\t\t\tif (freq == null) {\n\t\t\t\t\tfreq = new MutableInteger(1);\n\t\t\t\t\tmap.put(token.termText(), freq);\n\t\t\t\t} else {\n\t\t\t\t\tfreq.setValue(freq.intValue() + 1);\n\t\t\t\t}\n\t\t\t}\n\t\t} catch (IOException e) {\n\t\t\tthrow new RuntimeException(e);\n\t\t} finally {\n\t\t\ttry {\n\t\t\t\tstream.close();\n\t\t\t} catch (IOException e2) {\n\t\t\t\tthrow new RuntimeException(e2);\n\t\t\t}\n\t\t}\n\t\t\n\t\t// sort by frequency, text\n\t\tMap.Entry[] entries = new Map.Entry[map.size()];\n\t\tmap.entrySet().toArray(entries);\n\t\tArrays.sort(entries, new Comparator() {\n\t\t\tpublic int compare(Object o1, Object o2) {\n\t\t\t\tMap.Entry e1 = (Map.Entry) o1;\n\t\t\t\tMap.Entry e2 = (Map.Entry) o2;\n\t\t\t\tint f1 = ((MutableInteger) e1.getValue()).intValue();\n\t\t\t\tint f2 = ((MutableInteger) e2.getValue()).intValue();\n\t\t\t\tif (f2 - f1 != 0) return f2 - f1;\n\t\t\t\tString s1 = (String) e1.getKey();\n\t\t\t\tString s2 = (String) e2.getKey();\n\t\t\t\treturn s1.compareTo(s2);\n\t\t\t}\n\t\t});\n\t\t\n\t\t// return top N entries\n\t\tint size = Math.min(limit, entries.length);\n\t\tString[] pairs = new String[size];\n\t\tfor (int i=0; i < size; i++) {\n\t\t\tpairs[i] = entries[i].getValue() + \":\" + entries[i].getKey();\n\t\t}\n\t\treturn pairs;\n\t}\n\n","sourceOld":"\t/**\n\t * Returns (frequency:text) pairs for the top N distinct terms (aka words),\n\t * sorted descending by frequency (and ascending by term, if tied).\n\t * <p>\n\t * Example XQuery:\n\t * <pre>\n\t * declare namespace util = \"java:org.apache.lucene.index.memory.AnalyzerUtil\";\n\t * declare namespace analyzer = \"java:org.apache.lucene.index.memory.PatternAnalyzer\";\n\t * \n\t * for $pair in util:get-most-frequent-terms(\n\t *    analyzer:EXTENDED_ANALYZER(), doc(\"samples/shakespeare/othello.xml\"), 10)\n\t * return &lt;word word=\"{substring-after($pair, ':')}\" frequency=\"{substring-before($pair, ':')}\"/>\n\t * </pre>\n\t * \n\t * @param analyzer\n\t *            the analyzer to use for splitting text into terms (aka words)\n\t * @param text\n\t *            the text to analyze\n\t * @param limit\n\t *            the maximum number of pairs to return; zero indicates \n\t *            \"as many as possible\".\n\t * @return an array of (frequency:text) pairs in the form of (freq0:text0,\n\t *         freq1:text1, ..., freqN:textN). Each pair is a single string\n\t *         separated by a ':' delimiter.\n\t */\n\tpublic static String[] getMostFrequentTerms(Analyzer analyzer, String text, int limit) {\n\t\tif (analyzer == null) \n\t\t\tthrow new IllegalArgumentException(\"analyzer must not be null\");\n\t\tif (text == null) \n\t\t\tthrow new IllegalArgumentException(\"text must not be null\");\n\t\tif (limit <= 0) limit = Integer.MAX_VALUE;\n\t\t\n\t\t// compute frequencies of distinct terms\n\t\tHashMap map = new HashMap();\n\t\tTokenStream stream = analyzer.tokenStream(\"\", new StringReader(text));\n\t\ttry {\n\t\t\tToken token;\n\t\t\twhile ((token = stream.next()) != null) {\n\t\t\t\tMutableInteger freq = (MutableInteger) map.get(token.termText());\n\t\t\t\tif (freq == null) {\n\t\t\t\t\tfreq = new MutableInteger(1);\n\t\t\t\t\tmap.put(token.termText(), freq);\n\t\t\t\t} else {\n\t\t\t\t\tfreq.setValue(freq.intValue() + 1);\n\t\t\t\t}\n\t\t\t}\n\t\t} catch (IOException e) {\n\t\t\tthrow new RuntimeException(e);\n\t\t} finally {\n\t\t\ttry {\n\t\t\t\tstream.close();\n\t\t\t} catch (IOException e2) {\n\t\t\t\tthrow new RuntimeException(e2);\n\t\t\t}\n\t\t}\n\t\t\n\t\t// sort by frequency, text\n\t\tMap.Entry[] entries = new Map.Entry[map.size()];\n\t\tmap.entrySet().toArray(entries);\n\t\tArrays.sort(entries, new Comparator() {\n\t\t\tpublic int compare(Object o1, Object o2) {\n\t\t\t\tMap.Entry e1 = (Map.Entry) o1;\n\t\t\t\tMap.Entry e2 = (Map.Entry) o2;\n\t\t\t\tint f1 = ((MutableInteger) e1.getValue()).intValue();\n\t\t\t\tint f2 = ((MutableInteger) e2.getValue()).intValue();\n\t\t\t\tif (f2 - f1 != 0) return f2 - f1;\n\t\t\t\tString s1 = (String) e1.getKey();\n\t\t\t\tString s2 = (String) e2.getKey();\n\t\t\t\treturn s1.compareTo(s2);\n\t\t\t}\n\t\t});\n\t\t\n\t\t// return top N entries\n\t\tint size = Math.min(limit, entries.length);\n\t\tString[] pairs = new String[size];\n\t\tfor (int i=0; i < size; i++) {\n\t\t\tpairs[i] = entries[i].getValue() + \":\" + entries[i].getKey();\n\t\t}\n\t\treturn pairs;\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7f68e24227d5556d33ee6d586fd9010cd9ff8bec","date":1150091176,"type":3,"author":"Otis Gospodnetic","isMerge":false,"pathNew":"contrib/memory/src/java/org/apache/lucene/index/memory/AnalyzerUtil#getMostFrequentTerms(Analyzer,String,int).mjava","pathOld":"contrib/memory/src/java/org/apache/lucene/index/memory/AnalyzerUtil#getMostFrequentTerms(Analyzer,String,int).mjava","sourceNew":"  /**\n   * Returns (frequency:term) pairs for the top N distinct terms (aka words),\n   * sorted descending by frequency (and ascending by term, if tied).\n   * <p>\n   * Example XQuery:\n   * <pre>\n   * declare namespace util = \"java:org.apache.lucene.index.memory.AnalyzerUtil\";\n   * declare namespace analyzer = \"java:org.apache.lucene.index.memory.PatternAnalyzer\";\n   * \n   * for $pair in util:get-most-frequent-terms(\n   *    analyzer:EXTENDED_ANALYZER(), doc(\"samples/shakespeare/othello.xml\"), 10)\n   * return &lt;word word=\"{substring-after($pair, ':')}\" frequency=\"{substring-before($pair, ':')}\"/>\n   * </pre>\n   * \n   * @param analyzer\n   *            the analyzer to use for splitting text into terms (aka words)\n   * @param text\n   *            the text to analyze\n   * @param limit\n   *            the maximum number of pairs to return; zero indicates \n   *            \"as many as possible\".\n   * @return an array of (frequency:term) pairs in the form of (freq0:term0,\n   *         freq1:term1, ..., freqN:termN). Each pair is a single string\n   *         separated by a ':' delimiter.\n   */\n  public static String[] getMostFrequentTerms(Analyzer analyzer, String text, int limit) {\n    if (analyzer == null) \n      throw new IllegalArgumentException(\"analyzer must not be null\");\n    if (text == null) \n      throw new IllegalArgumentException(\"text must not be null\");\n    if (limit <= 0) limit = Integer.MAX_VALUE;\n    \n    // compute frequencies of distinct terms\n    HashMap map = new HashMap();\n    TokenStream stream = analyzer.tokenStream(\"\", new StringReader(text));\n    try {\n      Token token;\n      while ((token = stream.next()) != null) {\n        MutableInteger freq = (MutableInteger) map.get(token.termText());\n        if (freq == null) {\n          freq = new MutableInteger(1);\n          map.put(token.termText(), freq);\n        } else {\n          freq.setValue(freq.intValue() + 1);\n        }\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    } finally {\n      try {\n        stream.close();\n      } catch (IOException e2) {\n        throw new RuntimeException(e2);\n      }\n    }\n    \n    // sort by frequency, text\n    Map.Entry[] entries = new Map.Entry[map.size()];\n    map.entrySet().toArray(entries);\n    Arrays.sort(entries, new Comparator() {\n      public int compare(Object o1, Object o2) {\n        Map.Entry e1 = (Map.Entry) o1;\n        Map.Entry e2 = (Map.Entry) o2;\n        int f1 = ((MutableInteger) e1.getValue()).intValue();\n        int f2 = ((MutableInteger) e2.getValue()).intValue();\n        if (f2 - f1 != 0) return f2 - f1;\n        String s1 = (String) e1.getKey();\n        String s2 = (String) e2.getKey();\n        return s1.compareTo(s2);\n      }\n    });\n    \n    // return top N entries\n    int size = Math.min(limit, entries.length);\n    String[] pairs = new String[size];\n    for (int i=0; i < size; i++) {\n      pairs[i] = entries[i].getValue() + \":\" + entries[i].getKey();\n    }\n    return pairs;\n  }\n\n","sourceOld":"\t/**\n\t * Returns (frequency:term) pairs for the top N distinct terms (aka words),\n\t * sorted descending by frequency (and ascending by term, if tied).\n\t * <p>\n\t * Example XQuery:\n\t * <pre>\n\t * declare namespace util = \"java:org.apache.lucene.index.memory.AnalyzerUtil\";\n\t * declare namespace analyzer = \"java:org.apache.lucene.index.memory.PatternAnalyzer\";\n\t * \n\t * for $pair in util:get-most-frequent-terms(\n\t *    analyzer:EXTENDED_ANALYZER(), doc(\"samples/shakespeare/othello.xml\"), 10)\n\t * return &lt;word word=\"{substring-after($pair, ':')}\" frequency=\"{substring-before($pair, ':')}\"/>\n\t * </pre>\n\t * \n\t * @param analyzer\n\t *            the analyzer to use for splitting text into terms (aka words)\n\t * @param text\n\t *            the text to analyze\n\t * @param limit\n\t *            the maximum number of pairs to return; zero indicates \n\t *            \"as many as possible\".\n\t * @return an array of (frequency:term) pairs in the form of (freq0:term0,\n\t *         freq1:term1, ..., freqN:termN). Each pair is a single string\n\t *         separated by a ':' delimiter.\n\t */\n\tpublic static String[] getMostFrequentTerms(Analyzer analyzer, String text, int limit) {\n\t\tif (analyzer == null) \n\t\t\tthrow new IllegalArgumentException(\"analyzer must not be null\");\n\t\tif (text == null) \n\t\t\tthrow new IllegalArgumentException(\"text must not be null\");\n\t\tif (limit <= 0) limit = Integer.MAX_VALUE;\n\t\t\n\t\t// compute frequencies of distinct terms\n\t\tHashMap map = new HashMap();\n\t\tTokenStream stream = analyzer.tokenStream(\"\", new StringReader(text));\n\t\ttry {\n\t\t\tToken token;\n\t\t\twhile ((token = stream.next()) != null) {\n\t\t\t\tMutableInteger freq = (MutableInteger) map.get(token.termText());\n\t\t\t\tif (freq == null) {\n\t\t\t\t\tfreq = new MutableInteger(1);\n\t\t\t\t\tmap.put(token.termText(), freq);\n\t\t\t\t} else {\n\t\t\t\t\tfreq.setValue(freq.intValue() + 1);\n\t\t\t\t}\n\t\t\t}\n\t\t} catch (IOException e) {\n\t\t\tthrow new RuntimeException(e);\n\t\t} finally {\n\t\t\ttry {\n\t\t\t\tstream.close();\n\t\t\t} catch (IOException e2) {\n\t\t\t\tthrow new RuntimeException(e2);\n\t\t\t}\n\t\t}\n\t\t\n\t\t// sort by frequency, text\n\t\tMap.Entry[] entries = new Map.Entry[map.size()];\n\t\tmap.entrySet().toArray(entries);\n\t\tArrays.sort(entries, new Comparator() {\n\t\t\tpublic int compare(Object o1, Object o2) {\n\t\t\t\tMap.Entry e1 = (Map.Entry) o1;\n\t\t\t\tMap.Entry e2 = (Map.Entry) o2;\n\t\t\t\tint f1 = ((MutableInteger) e1.getValue()).intValue();\n\t\t\t\tint f2 = ((MutableInteger) e2.getValue()).intValue();\n\t\t\t\tif (f2 - f1 != 0) return f2 - f1;\n\t\t\t\tString s1 = (String) e1.getKey();\n\t\t\t\tString s2 = (String) e2.getKey();\n\t\t\t\treturn s1.compareTo(s2);\n\t\t\t}\n\t\t});\n\t\t\n\t\t// return top N entries\n\t\tint size = Math.min(limit, entries.length);\n\t\tString[] pairs = new String[size];\n\t\tfor (int i=0; i < size; i++) {\n\t\t\tpairs[i] = entries[i].getValue() + \":\" + entries[i].getKey();\n\t\t}\n\t\treturn pairs;\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7e2cb543b41c145f33390f460ee743d6693c9c6c","date":1219243087,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"contrib/memory/src/java/org/apache/lucene/index/memory/AnalyzerUtil#getMostFrequentTerms(Analyzer,String,int).mjava","pathOld":"contrib/memory/src/java/org/apache/lucene/index/memory/AnalyzerUtil#getMostFrequentTerms(Analyzer,String,int).mjava","sourceNew":"  /**\n   * Returns (frequency:term) pairs for the top N distinct terms (aka words),\n   * sorted descending by frequency (and ascending by term, if tied).\n   * <p>\n   * Example XQuery:\n   * <pre>\n   * declare namespace util = \"java:org.apache.lucene.index.memory.AnalyzerUtil\";\n   * declare namespace analyzer = \"java:org.apache.lucene.index.memory.PatternAnalyzer\";\n   * \n   * for $pair in util:get-most-frequent-terms(\n   *    analyzer:EXTENDED_ANALYZER(), doc(\"samples/shakespeare/othello.xml\"), 10)\n   * return &lt;word word=\"{substring-after($pair, ':')}\" frequency=\"{substring-before($pair, ':')}\"/>\n   * </pre>\n   * \n   * @param analyzer\n   *            the analyzer to use for splitting text into terms (aka words)\n   * @param text\n   *            the text to analyze\n   * @param limit\n   *            the maximum number of pairs to return; zero indicates \n   *            \"as many as possible\".\n   * @return an array of (frequency:term) pairs in the form of (freq0:term0,\n   *         freq1:term1, ..., freqN:termN). Each pair is a single string\n   *         separated by a ':' delimiter.\n   */\n  public static String[] getMostFrequentTerms(Analyzer analyzer, String text, int limit) {\n    if (analyzer == null) \n      throw new IllegalArgumentException(\"analyzer must not be null\");\n    if (text == null) \n      throw new IllegalArgumentException(\"text must not be null\");\n    if (limit <= 0) limit = Integer.MAX_VALUE;\n    \n    // compute frequencies of distinct terms\n    HashMap map = new HashMap();\n    TokenStream stream = analyzer.tokenStream(\"\", new StringReader(text));\n    try {\n      final Token reusableToken = new Token();\n      for (Token nextToken = stream.next(reusableToken); nextToken != null; nextToken = stream.next(reusableToken)) {\n        MutableInteger freq = (MutableInteger) map.get(nextToken.term());\n        if (freq == null) {\n          freq = new MutableInteger(1);\n          map.put(nextToken.term(), freq);\n        } else {\n          freq.setValue(freq.intValue() + 1);\n        }\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    } finally {\n      try {\n        stream.close();\n      } catch (IOException e2) {\n        throw new RuntimeException(e2);\n      }\n    }\n    \n    // sort by frequency, text\n    Map.Entry[] entries = new Map.Entry[map.size()];\n    map.entrySet().toArray(entries);\n    Arrays.sort(entries, new Comparator() {\n      public int compare(Object o1, Object o2) {\n        Map.Entry e1 = (Map.Entry) o1;\n        Map.Entry e2 = (Map.Entry) o2;\n        int f1 = ((MutableInteger) e1.getValue()).intValue();\n        int f2 = ((MutableInteger) e2.getValue()).intValue();\n        if (f2 - f1 != 0) return f2 - f1;\n        String s1 = (String) e1.getKey();\n        String s2 = (String) e2.getKey();\n        return s1.compareTo(s2);\n      }\n    });\n    \n    // return top N entries\n    int size = Math.min(limit, entries.length);\n    String[] pairs = new String[size];\n    for (int i=0; i < size; i++) {\n      pairs[i] = entries[i].getValue() + \":\" + entries[i].getKey();\n    }\n    return pairs;\n  }\n\n","sourceOld":"  /**\n   * Returns (frequency:term) pairs for the top N distinct terms (aka words),\n   * sorted descending by frequency (and ascending by term, if tied).\n   * <p>\n   * Example XQuery:\n   * <pre>\n   * declare namespace util = \"java:org.apache.lucene.index.memory.AnalyzerUtil\";\n   * declare namespace analyzer = \"java:org.apache.lucene.index.memory.PatternAnalyzer\";\n   * \n   * for $pair in util:get-most-frequent-terms(\n   *    analyzer:EXTENDED_ANALYZER(), doc(\"samples/shakespeare/othello.xml\"), 10)\n   * return &lt;word word=\"{substring-after($pair, ':')}\" frequency=\"{substring-before($pair, ':')}\"/>\n   * </pre>\n   * \n   * @param analyzer\n   *            the analyzer to use for splitting text into terms (aka words)\n   * @param text\n   *            the text to analyze\n   * @param limit\n   *            the maximum number of pairs to return; zero indicates \n   *            \"as many as possible\".\n   * @return an array of (frequency:term) pairs in the form of (freq0:term0,\n   *         freq1:term1, ..., freqN:termN). Each pair is a single string\n   *         separated by a ':' delimiter.\n   */\n  public static String[] getMostFrequentTerms(Analyzer analyzer, String text, int limit) {\n    if (analyzer == null) \n      throw new IllegalArgumentException(\"analyzer must not be null\");\n    if (text == null) \n      throw new IllegalArgumentException(\"text must not be null\");\n    if (limit <= 0) limit = Integer.MAX_VALUE;\n    \n    // compute frequencies of distinct terms\n    HashMap map = new HashMap();\n    TokenStream stream = analyzer.tokenStream(\"\", new StringReader(text));\n    try {\n      Token token;\n      while ((token = stream.next()) != null) {\n        MutableInteger freq = (MutableInteger) map.get(token.termText());\n        if (freq == null) {\n          freq = new MutableInteger(1);\n          map.put(token.termText(), freq);\n        } else {\n          freq.setValue(freq.intValue() + 1);\n        }\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    } finally {\n      try {\n        stream.close();\n      } catch (IOException e2) {\n        throw new RuntimeException(e2);\n      }\n    }\n    \n    // sort by frequency, text\n    Map.Entry[] entries = new Map.Entry[map.size()];\n    map.entrySet().toArray(entries);\n    Arrays.sort(entries, new Comparator() {\n      public int compare(Object o1, Object o2) {\n        Map.Entry e1 = (Map.Entry) o1;\n        Map.Entry e2 = (Map.Entry) o2;\n        int f1 = ((MutableInteger) e1.getValue()).intValue();\n        int f2 = ((MutableInteger) e2.getValue()).intValue();\n        if (f2 - f1 != 0) return f2 - f1;\n        String s1 = (String) e1.getKey();\n        String s2 = (String) e2.getKey();\n        return s1.compareTo(s2);\n      }\n    });\n    \n    // return top N entries\n    int size = Math.min(limit, entries.length);\n    String[] pairs = new String[size];\n    for (int i=0; i < size; i++) {\n      pairs[i] = entries[i].getValue() + \":\" + entries[i].getKey();\n    }\n    return pairs;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9b5756469957918cac40a831acec9cf01c8c2bb3","date":1249167152,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"contrib/memory/src/java/org/apache/lucene/index/memory/AnalyzerUtil#getMostFrequentTerms(Analyzer,String,int).mjava","pathOld":"contrib/memory/src/java/org/apache/lucene/index/memory/AnalyzerUtil#getMostFrequentTerms(Analyzer,String,int).mjava","sourceNew":"  /**\n   * Returns (frequency:term) pairs for the top N distinct terms (aka words),\n   * sorted descending by frequency (and ascending by term, if tied).\n   * <p>\n   * Example XQuery:\n   * <pre>\n   * declare namespace util = \"java:org.apache.lucene.index.memory.AnalyzerUtil\";\n   * declare namespace analyzer = \"java:org.apache.lucene.index.memory.PatternAnalyzer\";\n   * \n   * for $pair in util:get-most-frequent-terms(\n   *    analyzer:EXTENDED_ANALYZER(), doc(\"samples/shakespeare/othello.xml\"), 10)\n   * return &lt;word word=\"{substring-after($pair, ':')}\" frequency=\"{substring-before($pair, ':')}\"/>\n   * </pre>\n   * \n   * @param analyzer\n   *            the analyzer to use for splitting text into terms (aka words)\n   * @param text\n   *            the text to analyze\n   * @param limit\n   *            the maximum number of pairs to return; zero indicates \n   *            \"as many as possible\".\n   * @return an array of (frequency:term) pairs in the form of (freq0:term0,\n   *         freq1:term1, ..., freqN:termN). Each pair is a single string\n   *         separated by a ':' delimiter.\n   */\n  public static String[] getMostFrequentTerms(Analyzer analyzer, String text, int limit) {\n    if (analyzer == null) \n      throw new IllegalArgumentException(\"analyzer must not be null\");\n    if (text == null) \n      throw new IllegalArgumentException(\"text must not be null\");\n    if (limit <= 0) limit = Integer.MAX_VALUE;\n    \n    // compute frequencies of distinct terms\n    HashMap map = new HashMap();\n    TokenStream stream = analyzer.tokenStream(\"\", new StringReader(text));\n    TermAttribute termAtt = (TermAttribute) stream.addAttribute(TermAttribute.class);\n    try {\n      while (stream.incrementToken()) {\n        MutableInteger freq = (MutableInteger) map.get(termAtt.term());\n        if (freq == null) {\n          freq = new MutableInteger(1);\n          map.put(termAtt.term(), freq);\n        } else {\n          freq.setValue(freq.intValue() + 1);\n        }\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    } finally {\n      try {\n        stream.close();\n      } catch (IOException e2) {\n        throw new RuntimeException(e2);\n      }\n    }\n    \n    // sort by frequency, text\n    Map.Entry[] entries = new Map.Entry[map.size()];\n    map.entrySet().toArray(entries);\n    Arrays.sort(entries, new Comparator() {\n      public int compare(Object o1, Object o2) {\n        Map.Entry e1 = (Map.Entry) o1;\n        Map.Entry e2 = (Map.Entry) o2;\n        int f1 = ((MutableInteger) e1.getValue()).intValue();\n        int f2 = ((MutableInteger) e2.getValue()).intValue();\n        if (f2 - f1 != 0) return f2 - f1;\n        String s1 = (String) e1.getKey();\n        String s2 = (String) e2.getKey();\n        return s1.compareTo(s2);\n      }\n    });\n    \n    // return top N entries\n    int size = Math.min(limit, entries.length);\n    String[] pairs = new String[size];\n    for (int i=0; i < size; i++) {\n      pairs[i] = entries[i].getValue() + \":\" + entries[i].getKey();\n    }\n    return pairs;\n  }\n\n","sourceOld":"  /**\n   * Returns (frequency:term) pairs for the top N distinct terms (aka words),\n   * sorted descending by frequency (and ascending by term, if tied).\n   * <p>\n   * Example XQuery:\n   * <pre>\n   * declare namespace util = \"java:org.apache.lucene.index.memory.AnalyzerUtil\";\n   * declare namespace analyzer = \"java:org.apache.lucene.index.memory.PatternAnalyzer\";\n   * \n   * for $pair in util:get-most-frequent-terms(\n   *    analyzer:EXTENDED_ANALYZER(), doc(\"samples/shakespeare/othello.xml\"), 10)\n   * return &lt;word word=\"{substring-after($pair, ':')}\" frequency=\"{substring-before($pair, ':')}\"/>\n   * </pre>\n   * \n   * @param analyzer\n   *            the analyzer to use for splitting text into terms (aka words)\n   * @param text\n   *            the text to analyze\n   * @param limit\n   *            the maximum number of pairs to return; zero indicates \n   *            \"as many as possible\".\n   * @return an array of (frequency:term) pairs in the form of (freq0:term0,\n   *         freq1:term1, ..., freqN:termN). Each pair is a single string\n   *         separated by a ':' delimiter.\n   */\n  public static String[] getMostFrequentTerms(Analyzer analyzer, String text, int limit) {\n    if (analyzer == null) \n      throw new IllegalArgumentException(\"analyzer must not be null\");\n    if (text == null) \n      throw new IllegalArgumentException(\"text must not be null\");\n    if (limit <= 0) limit = Integer.MAX_VALUE;\n    \n    // compute frequencies of distinct terms\n    HashMap map = new HashMap();\n    TokenStream stream = analyzer.tokenStream(\"\", new StringReader(text));\n    try {\n      final Token reusableToken = new Token();\n      for (Token nextToken = stream.next(reusableToken); nextToken != null; nextToken = stream.next(reusableToken)) {\n        MutableInteger freq = (MutableInteger) map.get(nextToken.term());\n        if (freq == null) {\n          freq = new MutableInteger(1);\n          map.put(nextToken.term(), freq);\n        } else {\n          freq.setValue(freq.intValue() + 1);\n        }\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    } finally {\n      try {\n        stream.close();\n      } catch (IOException e2) {\n        throw new RuntimeException(e2);\n      }\n    }\n    \n    // sort by frequency, text\n    Map.Entry[] entries = new Map.Entry[map.size()];\n    map.entrySet().toArray(entries);\n    Arrays.sort(entries, new Comparator() {\n      public int compare(Object o1, Object o2) {\n        Map.Entry e1 = (Map.Entry) o1;\n        Map.Entry e2 = (Map.Entry) o2;\n        int f1 = ((MutableInteger) e1.getValue()).intValue();\n        int f2 = ((MutableInteger) e2.getValue()).intValue();\n        if (f2 - f1 != 0) return f2 - f1;\n        String s1 = (String) e1.getKey();\n        String s2 = (String) e2.getKey();\n        return s1.compareTo(s2);\n      }\n    });\n    \n    // return top N entries\n    int size = Math.min(limit, entries.length);\n    String[] pairs = new String[size];\n    for (int i=0; i < size; i++) {\n      pairs[i] = entries[i].getValue() + \":\" + entries[i].getKey();\n    }\n    return pairs;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8d78f014fded44fbde905f4f84cdc21907b371e8","date":1254383623,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"contrib/memory/src/java/org/apache/lucene/index/memory/AnalyzerUtil#getMostFrequentTerms(Analyzer,String,int).mjava","pathOld":"contrib/memory/src/java/org/apache/lucene/index/memory/AnalyzerUtil#getMostFrequentTerms(Analyzer,String,int).mjava","sourceNew":"  /**\n   * Returns (frequency:term) pairs for the top N distinct terms (aka words),\n   * sorted descending by frequency (and ascending by term, if tied).\n   * <p>\n   * Example XQuery:\n   * <pre>\n   * declare namespace util = \"java:org.apache.lucene.index.memory.AnalyzerUtil\";\n   * declare namespace analyzer = \"java:org.apache.lucene.index.memory.PatternAnalyzer\";\n   * \n   * for $pair in util:get-most-frequent-terms(\n   *    analyzer:EXTENDED_ANALYZER(), doc(\"samples/shakespeare/othello.xml\"), 10)\n   * return &lt;word word=\"{substring-after($pair, ':')}\" frequency=\"{substring-before($pair, ':')}\"/>\n   * </pre>\n   * \n   * @param analyzer\n   *            the analyzer to use for splitting text into terms (aka words)\n   * @param text\n   *            the text to analyze\n   * @param limit\n   *            the maximum number of pairs to return; zero indicates \n   *            \"as many as possible\".\n   * @return an array of (frequency:term) pairs in the form of (freq0:term0,\n   *         freq1:term1, ..., freqN:termN). Each pair is a single string\n   *         separated by a ':' delimiter.\n   */\n  public static String[] getMostFrequentTerms(Analyzer analyzer, String text, int limit) {\n    if (analyzer == null) \n      throw new IllegalArgumentException(\"analyzer must not be null\");\n    if (text == null) \n      throw new IllegalArgumentException(\"text must not be null\");\n    if (limit <= 0) limit = Integer.MAX_VALUE;\n    \n    // compute frequencies of distinct terms\n    HashMap map = new HashMap();\n    TokenStream stream = analyzer.tokenStream(\"\", new StringReader(text));\n    TermAttribute termAtt = stream.addAttribute(TermAttribute.class);\n    try {\n      while (stream.incrementToken()) {\n        MutableInteger freq = (MutableInteger) map.get(termAtt.term());\n        if (freq == null) {\n          freq = new MutableInteger(1);\n          map.put(termAtt.term(), freq);\n        } else {\n          freq.setValue(freq.intValue() + 1);\n        }\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    } finally {\n      try {\n        stream.close();\n      } catch (IOException e2) {\n        throw new RuntimeException(e2);\n      }\n    }\n    \n    // sort by frequency, text\n    Map.Entry[] entries = new Map.Entry[map.size()];\n    map.entrySet().toArray(entries);\n    Arrays.sort(entries, new Comparator() {\n      public int compare(Object o1, Object o2) {\n        Map.Entry e1 = (Map.Entry) o1;\n        Map.Entry e2 = (Map.Entry) o2;\n        int f1 = ((MutableInteger) e1.getValue()).intValue();\n        int f2 = ((MutableInteger) e2.getValue()).intValue();\n        if (f2 - f1 != 0) return f2 - f1;\n        String s1 = (String) e1.getKey();\n        String s2 = (String) e2.getKey();\n        return s1.compareTo(s2);\n      }\n    });\n    \n    // return top N entries\n    int size = Math.min(limit, entries.length);\n    String[] pairs = new String[size];\n    for (int i=0; i < size; i++) {\n      pairs[i] = entries[i].getValue() + \":\" + entries[i].getKey();\n    }\n    return pairs;\n  }\n\n","sourceOld":"  /**\n   * Returns (frequency:term) pairs for the top N distinct terms (aka words),\n   * sorted descending by frequency (and ascending by term, if tied).\n   * <p>\n   * Example XQuery:\n   * <pre>\n   * declare namespace util = \"java:org.apache.lucene.index.memory.AnalyzerUtil\";\n   * declare namespace analyzer = \"java:org.apache.lucene.index.memory.PatternAnalyzer\";\n   * \n   * for $pair in util:get-most-frequent-terms(\n   *    analyzer:EXTENDED_ANALYZER(), doc(\"samples/shakespeare/othello.xml\"), 10)\n   * return &lt;word word=\"{substring-after($pair, ':')}\" frequency=\"{substring-before($pair, ':')}\"/>\n   * </pre>\n   * \n   * @param analyzer\n   *            the analyzer to use for splitting text into terms (aka words)\n   * @param text\n   *            the text to analyze\n   * @param limit\n   *            the maximum number of pairs to return; zero indicates \n   *            \"as many as possible\".\n   * @return an array of (frequency:term) pairs in the form of (freq0:term0,\n   *         freq1:term1, ..., freqN:termN). Each pair is a single string\n   *         separated by a ':' delimiter.\n   */\n  public static String[] getMostFrequentTerms(Analyzer analyzer, String text, int limit) {\n    if (analyzer == null) \n      throw new IllegalArgumentException(\"analyzer must not be null\");\n    if (text == null) \n      throw new IllegalArgumentException(\"text must not be null\");\n    if (limit <= 0) limit = Integer.MAX_VALUE;\n    \n    // compute frequencies of distinct terms\n    HashMap map = new HashMap();\n    TokenStream stream = analyzer.tokenStream(\"\", new StringReader(text));\n    TermAttribute termAtt = (TermAttribute) stream.addAttribute(TermAttribute.class);\n    try {\n      while (stream.incrementToken()) {\n        MutableInteger freq = (MutableInteger) map.get(termAtt.term());\n        if (freq == null) {\n          freq = new MutableInteger(1);\n          map.put(termAtt.term(), freq);\n        } else {\n          freq.setValue(freq.intValue() + 1);\n        }\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    } finally {\n      try {\n        stream.close();\n      } catch (IOException e2) {\n        throw new RuntimeException(e2);\n      }\n    }\n    \n    // sort by frequency, text\n    Map.Entry[] entries = new Map.Entry[map.size()];\n    map.entrySet().toArray(entries);\n    Arrays.sort(entries, new Comparator() {\n      public int compare(Object o1, Object o2) {\n        Map.Entry e1 = (Map.Entry) o1;\n        Map.Entry e2 = (Map.Entry) o2;\n        int f1 = ((MutableInteger) e1.getValue()).intValue();\n        int f2 = ((MutableInteger) e2.getValue()).intValue();\n        if (f2 - f1 != 0) return f2 - f1;\n        String s1 = (String) e1.getKey();\n        String s2 = (String) e2.getKey();\n        return s1.compareTo(s2);\n      }\n    });\n    \n    // return top N entries\n    int size = Math.min(limit, entries.length);\n    String[] pairs = new String[size];\n    for (int i=0; i < size; i++) {\n      pairs[i] = entries[i].getValue() + \":\" + entries[i].getKey();\n    }\n    return pairs;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d68e5c46e6a5ebdf4dafec4a123344092b915cc0","date":1256752193,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"contrib/wordnet/src/java/org/apache/lucene/wordnet/AnalyzerUtil#getMostFrequentTerms(Analyzer,String,int).mjava","pathOld":"contrib/memory/src/java/org/apache/lucene/index/memory/AnalyzerUtil#getMostFrequentTerms(Analyzer,String,int).mjava","sourceNew":"  /**\n   * Returns (frequency:term) pairs for the top N distinct terms (aka words),\n   * sorted descending by frequency (and ascending by term, if tied).\n   * <p>\n   * Example XQuery:\n   * <pre>\n   * declare namespace util = \"java:org.apache.lucene.index.memory.AnalyzerUtil\";\n   * declare namespace analyzer = \"java:org.apache.lucene.index.memory.PatternAnalyzer\";\n   * \n   * for $pair in util:get-most-frequent-terms(\n   *    analyzer:EXTENDED_ANALYZER(), doc(\"samples/shakespeare/othello.xml\"), 10)\n   * return &lt;word word=\"{substring-after($pair, ':')}\" frequency=\"{substring-before($pair, ':')}\"/>\n   * </pre>\n   * \n   * @param analyzer\n   *            the analyzer to use for splitting text into terms (aka words)\n   * @param text\n   *            the text to analyze\n   * @param limit\n   *            the maximum number of pairs to return; zero indicates \n   *            \"as many as possible\".\n   * @return an array of (frequency:term) pairs in the form of (freq0:term0,\n   *         freq1:term1, ..., freqN:termN). Each pair is a single string\n   *         separated by a ':' delimiter.\n   */\n  public static String[] getMostFrequentTerms(Analyzer analyzer, String text, int limit) {\n    if (analyzer == null) \n      throw new IllegalArgumentException(\"analyzer must not be null\");\n    if (text == null) \n      throw new IllegalArgumentException(\"text must not be null\");\n    if (limit <= 0) limit = Integer.MAX_VALUE;\n    \n    // compute frequencies of distinct terms\n    HashMap map = new HashMap();\n    TokenStream stream = analyzer.tokenStream(\"\", new StringReader(text));\n    TermAttribute termAtt = stream.addAttribute(TermAttribute.class);\n    try {\n      while (stream.incrementToken()) {\n        MutableInteger freq = (MutableInteger) map.get(termAtt.term());\n        if (freq == null) {\n          freq = new MutableInteger(1);\n          map.put(termAtt.term(), freq);\n        } else {\n          freq.setValue(freq.intValue() + 1);\n        }\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    } finally {\n      try {\n        stream.close();\n      } catch (IOException e2) {\n        throw new RuntimeException(e2);\n      }\n    }\n    \n    // sort by frequency, text\n    Map.Entry[] entries = new Map.Entry[map.size()];\n    map.entrySet().toArray(entries);\n    Arrays.sort(entries, new Comparator() {\n      public int compare(Object o1, Object o2) {\n        Map.Entry e1 = (Map.Entry) o1;\n        Map.Entry e2 = (Map.Entry) o2;\n        int f1 = ((MutableInteger) e1.getValue()).intValue();\n        int f2 = ((MutableInteger) e2.getValue()).intValue();\n        if (f2 - f1 != 0) return f2 - f1;\n        String s1 = (String) e1.getKey();\n        String s2 = (String) e2.getKey();\n        return s1.compareTo(s2);\n      }\n    });\n    \n    // return top N entries\n    int size = Math.min(limit, entries.length);\n    String[] pairs = new String[size];\n    for (int i=0; i < size; i++) {\n      pairs[i] = entries[i].getValue() + \":\" + entries[i].getKey();\n    }\n    return pairs;\n  }\n\n","sourceOld":"  /**\n   * Returns (frequency:term) pairs for the top N distinct terms (aka words),\n   * sorted descending by frequency (and ascending by term, if tied).\n   * <p>\n   * Example XQuery:\n   * <pre>\n   * declare namespace util = \"java:org.apache.lucene.index.memory.AnalyzerUtil\";\n   * declare namespace analyzer = \"java:org.apache.lucene.index.memory.PatternAnalyzer\";\n   * \n   * for $pair in util:get-most-frequent-terms(\n   *    analyzer:EXTENDED_ANALYZER(), doc(\"samples/shakespeare/othello.xml\"), 10)\n   * return &lt;word word=\"{substring-after($pair, ':')}\" frequency=\"{substring-before($pair, ':')}\"/>\n   * </pre>\n   * \n   * @param analyzer\n   *            the analyzer to use for splitting text into terms (aka words)\n   * @param text\n   *            the text to analyze\n   * @param limit\n   *            the maximum number of pairs to return; zero indicates \n   *            \"as many as possible\".\n   * @return an array of (frequency:term) pairs in the form of (freq0:term0,\n   *         freq1:term1, ..., freqN:termN). Each pair is a single string\n   *         separated by a ':' delimiter.\n   */\n  public static String[] getMostFrequentTerms(Analyzer analyzer, String text, int limit) {\n    if (analyzer == null) \n      throw new IllegalArgumentException(\"analyzer must not be null\");\n    if (text == null) \n      throw new IllegalArgumentException(\"text must not be null\");\n    if (limit <= 0) limit = Integer.MAX_VALUE;\n    \n    // compute frequencies of distinct terms\n    HashMap map = new HashMap();\n    TokenStream stream = analyzer.tokenStream(\"\", new StringReader(text));\n    TermAttribute termAtt = stream.addAttribute(TermAttribute.class);\n    try {\n      while (stream.incrementToken()) {\n        MutableInteger freq = (MutableInteger) map.get(termAtt.term());\n        if (freq == null) {\n          freq = new MutableInteger(1);\n          map.put(termAtt.term(), freq);\n        } else {\n          freq.setValue(freq.intValue() + 1);\n        }\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    } finally {\n      try {\n        stream.close();\n      } catch (IOException e2) {\n        throw new RuntimeException(e2);\n      }\n    }\n    \n    // sort by frequency, text\n    Map.Entry[] entries = new Map.Entry[map.size()];\n    map.entrySet().toArray(entries);\n    Arrays.sort(entries, new Comparator() {\n      public int compare(Object o1, Object o2) {\n        Map.Entry e1 = (Map.Entry) o1;\n        Map.Entry e2 = (Map.Entry) o2;\n        int f1 = ((MutableInteger) e1.getValue()).intValue();\n        int f2 = ((MutableInteger) e2.getValue()).intValue();\n        if (f2 - f1 != 0) return f2 - f1;\n        String s1 = (String) e1.getKey();\n        String s2 = (String) e2.getKey();\n        return s1.compareTo(s2);\n      }\n    });\n    \n    // return top N entries\n    int size = Math.min(limit, entries.length);\n    String[] pairs = new String[size];\n    for (int i=0; i < size; i++) {\n      pairs[i] = entries[i].getValue() + \":\" + entries[i].getKey();\n    }\n    return pairs;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"7e2cb543b41c145f33390f460ee743d6693c9c6c":["7f68e24227d5556d33ee6d586fd9010cd9ff8bec"],"acdb560b7878968b4b295f01dae1b29d195d6175":["ea82415927cafd7c8b8bceca08f31a63db1cbdde"],"ea82415927cafd7c8b8bceca08f31a63db1cbdde":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"9b5756469957918cac40a831acec9cf01c8c2bb3":["7e2cb543b41c145f33390f460ee743d6693c9c6c"],"7f68e24227d5556d33ee6d586fd9010cd9ff8bec":["acdb560b7878968b4b295f01dae1b29d195d6175"],"8d78f014fded44fbde905f4f84cdc21907b371e8":["9b5756469957918cac40a831acec9cf01c8c2bb3"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["d68e5c46e6a5ebdf4dafec4a123344092b915cc0"],"d68e5c46e6a5ebdf4dafec4a123344092b915cc0":["8d78f014fded44fbde905f4f84cdc21907b371e8"]},"commit2Childs":{"7e2cb543b41c145f33390f460ee743d6693c9c6c":["9b5756469957918cac40a831acec9cf01c8c2bb3"],"acdb560b7878968b4b295f01dae1b29d195d6175":["7f68e24227d5556d33ee6d586fd9010cd9ff8bec"],"ea82415927cafd7c8b8bceca08f31a63db1cbdde":["acdb560b7878968b4b295f01dae1b29d195d6175"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["ea82415927cafd7c8b8bceca08f31a63db1cbdde"],"7f68e24227d5556d33ee6d586fd9010cd9ff8bec":["7e2cb543b41c145f33390f460ee743d6693c9c6c"],"9b5756469957918cac40a831acec9cf01c8c2bb3":["8d78f014fded44fbde905f4f84cdc21907b371e8"],"8d78f014fded44fbde905f4f84cdc21907b371e8":["d68e5c46e6a5ebdf4dafec4a123344092b915cc0"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"d68e5c46e6a5ebdf4dafec4a123344092b915cc0":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}