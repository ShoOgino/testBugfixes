{"path":"lucene/src/java/org/apache/lucene/search/MultiPhraseQuery.MultiPhraseWeight#scorer(IndexReader,boolean,boolean).mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/search/MultiPhraseQuery.MultiPhraseWeight#scorer(IndexReader,boolean,boolean).mjava","pathOld":"src/java/org/apache/lucene/search/MultiPhraseQuery.MultiPhraseWeight#scorer(IndexReader,boolean,boolean).mjava","sourceNew":"    @Override\n    public Scorer scorer(IndexReader reader, boolean scoreDocsInOrder, boolean topScorer) throws IOException {\n      if (termArrays.size() == 0)                  // optimize zero-term case\n        return null;\n\n      TermPositions[] tps = new TermPositions[termArrays.size()];\n      for (int i=0; i<tps.length; i++) {\n        Term[] terms = termArrays.get(i);\n\n        TermPositions p;\n        if (terms.length > 1)\n          p = new MultipleTermPositions(reader, terms);\n        else\n          p = reader.termPositions(terms[0]);\n\n        if (p == null)\n          return null;\n\n        tps[i] = p;\n      }\n\n      if (slop == 0)\n        return new ExactPhraseScorer(this, tps, getPositions(), similarity,\n                                     reader.norms(field));\n      else\n        return new SloppyPhraseScorer(this, tps, getPositions(), similarity,\n                                      slop, reader.norms(field));\n    }\n\n","sourceOld":"    @Override\n    public Scorer scorer(IndexReader reader, boolean scoreDocsInOrder, boolean topScorer) throws IOException {\n      if (termArrays.size() == 0)                  // optimize zero-term case\n        return null;\n\n      TermPositions[] tps = new TermPositions[termArrays.size()];\n      for (int i=0; i<tps.length; i++) {\n        Term[] terms = termArrays.get(i);\n\n        TermPositions p;\n        if (terms.length > 1)\n          p = new MultipleTermPositions(reader, terms);\n        else\n          p = reader.termPositions(terms[0]);\n\n        if (p == null)\n          return null;\n\n        tps[i] = p;\n      }\n\n      if (slop == 0)\n        return new ExactPhraseScorer(this, tps, getPositions(), similarity,\n                                     reader.norms(field));\n      else\n        return new SloppyPhraseScorer(this, tps, getPositions(), similarity,\n                                      slop, reader.norms(field));\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"955c32f886db6f6356c9fcdea6b1f1cb4effda24","date":1270581567,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/search/MultiPhraseQuery.MultiPhraseWeight#scorer(IndexReader,boolean,boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/MultiPhraseQuery.MultiPhraseWeight#scorer(IndexReader,boolean,boolean).mjava","sourceNew":"    @Override\n    public Scorer scorer(IndexReader reader, boolean scoreDocsInOrder, boolean topScorer) throws IOException {\n      if (termArrays.size() == 0)                  // optimize zero-term case\n        return null;\n\n      DocsAndPositionsEnum[] postings = new DocsAndPositionsEnum[termArrays.size()];\n      for (int i=0; i<postings.length; i++) {\n        Term[] terms = termArrays.get(i);\n\n        final DocsAndPositionsEnum postingsEnum;\n        if (terms.length > 1) {\n          postingsEnum = new UnionDocsAndPositionsEnum(reader, terms);\n        } else {\n          postingsEnum = reader.termPositionsEnum(MultiFields.getDeletedDocs(reader),\n                                                  terms[0].field(),\n                                                  new BytesRef(terms[0].text()));\n        }\n\n        if (postingsEnum == null) {\n          return null;\n        }\n\n        postings[i] = postingsEnum;\n      }\n\n      if (slop == 0)\n        return new ExactPhraseScorer(this, postings, getPositions(), similarity,\n                                     reader.norms(field));\n      else\n        return new SloppyPhraseScorer(this, postings, getPositions(), similarity,\n                                      slop, reader.norms(field));\n    }\n\n","sourceOld":"    @Override\n    public Scorer scorer(IndexReader reader, boolean scoreDocsInOrder, boolean topScorer) throws IOException {\n      if (termArrays.size() == 0)                  // optimize zero-term case\n        return null;\n\n      TermPositions[] tps = new TermPositions[termArrays.size()];\n      for (int i=0; i<tps.length; i++) {\n        Term[] terms = termArrays.get(i);\n\n        TermPositions p;\n        if (terms.length > 1)\n          p = new MultipleTermPositions(reader, terms);\n        else\n          p = reader.termPositions(terms[0]);\n\n        if (p == null)\n          return null;\n\n        tps[i] = p;\n      }\n\n      if (slop == 0)\n        return new ExactPhraseScorer(this, tps, getPositions(), similarity,\n                                     reader.norms(field));\n      else\n        return new SloppyPhraseScorer(this, tps, getPositions(), similarity,\n                                      slop, reader.norms(field));\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"953de31d76c9d58f1e3f4e41ff8a48a1529226de","date":1277371072,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/search/MultiPhraseQuery.MultiPhraseWeight#scorer(IndexReader,boolean,boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/MultiPhraseQuery.MultiPhraseWeight#scorer(IndexReader,boolean,boolean).mjava","sourceNew":"    @Override\n    public Scorer scorer(IndexReader reader, boolean scoreDocsInOrder, boolean topScorer) throws IOException {\n      if (termArrays.size() == 0)                  // optimize zero-term case\n        return null;\n\n      final Bits delDocs = MultiFields.getDeletedDocs(reader);\n      \n      PhraseQuery.PostingsAndFreq[] postingsFreqs = new PhraseQuery.PostingsAndFreq[termArrays.size()];\n\n      for (int i=0; i<postingsFreqs.length; i++) {\n        Term[] terms = termArrays.get(i);\n\n        final DocsAndPositionsEnum postingsEnum;\n        int docFreq;\n\n        if (terms.length > 1) {\n          postingsEnum = new UnionDocsAndPositionsEnum(reader, terms);\n\n          // coarse -- this overcounts since a given doc can\n          // have more than one terms:\n          docFreq = 0;\n          for(int j=0;j<terms.length;j++) {\n            docFreq += reader.docFreq(terms[i]);\n          }\n        } else {\n          final BytesRef text = new BytesRef(terms[0].text());\n          postingsEnum = reader.termPositionsEnum(delDocs,\n                                                  terms[0].field(),\n                                                  text);\n\n          if (postingsEnum == null) {\n            if (MultiFields.getTermDocsEnum(reader, delDocs, terms[0].field(), text) != null) {\n              // term does exist, but has no positions\n              throw new IllegalStateException(\"field \\\"\" + terms[0].field() + \"\\\" was indexed with Field.omitTermFreqAndPositions=true; cannot run PhraseQuery (term=\" + terms[0].text() + \")\");\n            } else {\n              // term does not exist\n              return null;\n            }\n          }\n\n          docFreq = reader.docFreq(terms[0].field(), text);\n        }\n\n        postingsFreqs[i] = new PhraseQuery.PostingsAndFreq(postingsEnum, docFreq, positions.get(i).intValue());\n      }\n\n      // sort by increasing docFreq order\n      if (slop == 0) {\n        Arrays.sort(postingsFreqs);\n      }\n\n      if (slop == 0) {\n        ExactPhraseScorer s = new ExactPhraseScorer(this, postingsFreqs, similarity,\n                                                    reader.norms(field));\n        if (s.noDocs) {\n          return null;\n        } else {\n          return s;\n        }\n      } else {\n        return new SloppyPhraseScorer(this, postingsFreqs, similarity,\n                                      slop, reader.norms(field));\n      }\n    }\n\n","sourceOld":"    @Override\n    public Scorer scorer(IndexReader reader, boolean scoreDocsInOrder, boolean topScorer) throws IOException {\n      if (termArrays.size() == 0)                  // optimize zero-term case\n        return null;\n\n      DocsAndPositionsEnum[] postings = new DocsAndPositionsEnum[termArrays.size()];\n      for (int i=0; i<postings.length; i++) {\n        Term[] terms = termArrays.get(i);\n\n        final DocsAndPositionsEnum postingsEnum;\n        if (terms.length > 1) {\n          postingsEnum = new UnionDocsAndPositionsEnum(reader, terms);\n        } else {\n          postingsEnum = reader.termPositionsEnum(MultiFields.getDeletedDocs(reader),\n                                                  terms[0].field(),\n                                                  new BytesRef(terms[0].text()));\n        }\n\n        if (postingsEnum == null) {\n          return null;\n        }\n\n        postings[i] = postingsEnum;\n      }\n\n      if (slop == 0)\n        return new ExactPhraseScorer(this, postings, getPositions(), similarity,\n                                     reader.norms(field));\n      else\n        return new SloppyPhraseScorer(this, postings, getPositions(), similarity,\n                                      slop, reader.norms(field));\n    }\n\n","bugFix":null,"bugIntro":["2ac7b588a949391edf21dd63c943990a9c3aec5f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5f4e87790277826a2aea119328600dfb07761f32","date":1279827275,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/search/MultiPhraseQuery.MultiPhraseWeight#scorer(IndexReader,boolean,boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/MultiPhraseQuery.MultiPhraseWeight#scorer(IndexReader,boolean,boolean).mjava","sourceNew":"    @Override\n    public Scorer scorer(IndexReader reader, boolean scoreDocsInOrder, boolean topScorer) throws IOException {\n      if (termArrays.size() == 0)                  // optimize zero-term case\n        return null;\n\n      final Bits delDocs = MultiFields.getDeletedDocs(reader);\n      \n      PhraseQuery.PostingsAndFreq[] postingsFreqs = new PhraseQuery.PostingsAndFreq[termArrays.size()];\n\n      for (int i=0; i<postingsFreqs.length; i++) {\n        Term[] terms = termArrays.get(i);\n\n        final DocsAndPositionsEnum postingsEnum;\n        int docFreq;\n\n        if (terms.length > 1) {\n          postingsEnum = new UnionDocsAndPositionsEnum(reader, terms);\n\n          // coarse -- this overcounts since a given doc can\n          // have more than one terms:\n          docFreq = 0;\n          for(int j=0;j<terms.length;j++) {\n            docFreq += reader.docFreq(terms[i]);\n          }\n        } else {\n          final BytesRef text = new BytesRef(terms[0].text());\n          postingsEnum = reader.termPositionsEnum(delDocs,\n                                                  terms[0].field(),\n                                                  text);\n\n          if (postingsEnum == null) {\n            if (MultiFields.getTermDocsEnum(reader, delDocs, terms[0].field(), text) != null) {\n              // term does exist, but has no positions\n              throw new IllegalStateException(\"field \\\"\" + terms[0].field() + \"\\\" was indexed with Field.omitTermFreqAndPositions=true; cannot run PhraseQuery (term=\" + terms[0].text() + \")\");\n            } else {\n              // term does not exist\n              return null;\n            }\n          }\n\n          docFreq = reader.docFreq(terms[0].field(), text);\n        }\n\n        postingsFreqs[i] = new PhraseQuery.PostingsAndFreq(postingsEnum, docFreq, positions.get(i).intValue());\n      }\n\n      // sort by increasing docFreq order\n      if (slop == 0) {\n        Arrays.sort(postingsFreqs);\n      }\n\n      if (slop == 0) {\n        ExactPhraseScorer s = new ExactPhraseScorer(this, postingsFreqs, similarity,\n                                                    reader.norms(field));\n        if (s.noDocs) {\n          return null;\n        } else {\n          return s;\n        }\n      } else {\n        return new SloppyPhraseScorer(this, postingsFreqs, similarity,\n                                      slop, reader.norms(field));\n      }\n    }\n\n","sourceOld":"    @Override\n    public Scorer scorer(IndexReader reader, boolean scoreDocsInOrder, boolean topScorer) throws IOException {\n      if (termArrays.size() == 0)                  // optimize zero-term case\n        return null;\n\n      DocsAndPositionsEnum[] postings = new DocsAndPositionsEnum[termArrays.size()];\n      for (int i=0; i<postings.length; i++) {\n        Term[] terms = termArrays.get(i);\n\n        final DocsAndPositionsEnum postingsEnum;\n        if (terms.length > 1) {\n          postingsEnum = new UnionDocsAndPositionsEnum(reader, terms);\n        } else {\n          postingsEnum = reader.termPositionsEnum(MultiFields.getDeletedDocs(reader),\n                                                  terms[0].field(),\n                                                  new BytesRef(terms[0].text()));\n        }\n\n        if (postingsEnum == null) {\n          return null;\n        }\n\n        postings[i] = postingsEnum;\n      }\n\n      if (slop == 0)\n        return new ExactPhraseScorer(this, postings, getPositions(), similarity,\n                                     reader.norms(field));\n      else\n        return new SloppyPhraseScorer(this, postings, getPositions(), similarity,\n                                      slop, reader.norms(field));\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2ac7b588a949391edf21dd63c943990a9c3aec5f","date":1280514460,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/search/MultiPhraseQuery.MultiPhraseWeight#scorer(IndexReader,boolean,boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/MultiPhraseQuery.MultiPhraseWeight#scorer(IndexReader,boolean,boolean).mjava","sourceNew":"    @Override\n    public Scorer scorer(IndexReader reader, boolean scoreDocsInOrder, boolean topScorer) throws IOException {\n      if (termArrays.size() == 0)                  // optimize zero-term case\n        return null;\n\n      final Bits delDocs = MultiFields.getDeletedDocs(reader);\n      \n      PhraseQuery.PostingsAndFreq[] postingsFreqs = new PhraseQuery.PostingsAndFreq[termArrays.size()];\n\n      for (int pos=0; pos<postingsFreqs.length; pos++) {\n        Term[] terms = termArrays.get(pos);\n\n        final DocsAndPositionsEnum postingsEnum;\n        int docFreq;\n\n        if (terms.length > 1) {\n          postingsEnum = new UnionDocsAndPositionsEnum(reader, terms);\n\n          // coarse -- this overcounts since a given doc can\n          // have more than one terms:\n          docFreq = 0;\n          for(int termIdx=0;termIdx<terms.length;termIdx++) {\n            docFreq += reader.docFreq(terms[termIdx]);\n          }\n        } else {\n          final BytesRef text = new BytesRef(terms[0].text());\n          postingsEnum = reader.termPositionsEnum(delDocs,\n                                                  terms[0].field(),\n                                                  text);\n\n          if (postingsEnum == null) {\n            if (MultiFields.getTermDocsEnum(reader, delDocs, terms[0].field(), text) != null) {\n              // term does exist, but has no positions\n              throw new IllegalStateException(\"field \\\"\" + terms[0].field() + \"\\\" was indexed with Field.omitTermFreqAndPositions=true; cannot run PhraseQuery (term=\" + terms[0].text() + \")\");\n            } else {\n              // term does not exist\n              return null;\n            }\n          }\n\n          docFreq = reader.docFreq(terms[0].field(), text);\n        }\n\n        postingsFreqs[pos] = new PhraseQuery.PostingsAndFreq(postingsEnum, docFreq, positions.get(pos).intValue());\n      }\n\n      // sort by increasing docFreq order\n      if (slop == 0) {\n        Arrays.sort(postingsFreqs);\n      }\n\n      if (slop == 0) {\n        ExactPhraseScorer s = new ExactPhraseScorer(this, postingsFreqs, similarity,\n                                                    reader.norms(field));\n        if (s.noDocs) {\n          return null;\n        } else {\n          return s;\n        }\n      } else {\n        return new SloppyPhraseScorer(this, postingsFreqs, similarity,\n                                      slop, reader.norms(field));\n      }\n    }\n\n","sourceOld":"    @Override\n    public Scorer scorer(IndexReader reader, boolean scoreDocsInOrder, boolean topScorer) throws IOException {\n      if (termArrays.size() == 0)                  // optimize zero-term case\n        return null;\n\n      final Bits delDocs = MultiFields.getDeletedDocs(reader);\n      \n      PhraseQuery.PostingsAndFreq[] postingsFreqs = new PhraseQuery.PostingsAndFreq[termArrays.size()];\n\n      for (int i=0; i<postingsFreqs.length; i++) {\n        Term[] terms = termArrays.get(i);\n\n        final DocsAndPositionsEnum postingsEnum;\n        int docFreq;\n\n        if (terms.length > 1) {\n          postingsEnum = new UnionDocsAndPositionsEnum(reader, terms);\n\n          // coarse -- this overcounts since a given doc can\n          // have more than one terms:\n          docFreq = 0;\n          for(int j=0;j<terms.length;j++) {\n            docFreq += reader.docFreq(terms[i]);\n          }\n        } else {\n          final BytesRef text = new BytesRef(terms[0].text());\n          postingsEnum = reader.termPositionsEnum(delDocs,\n                                                  terms[0].field(),\n                                                  text);\n\n          if (postingsEnum == null) {\n            if (MultiFields.getTermDocsEnum(reader, delDocs, terms[0].field(), text) != null) {\n              // term does exist, but has no positions\n              throw new IllegalStateException(\"field \\\"\" + terms[0].field() + \"\\\" was indexed with Field.omitTermFreqAndPositions=true; cannot run PhraseQuery (term=\" + terms[0].text() + \")\");\n            } else {\n              // term does not exist\n              return null;\n            }\n          }\n\n          docFreq = reader.docFreq(terms[0].field(), text);\n        }\n\n        postingsFreqs[i] = new PhraseQuery.PostingsAndFreq(postingsEnum, docFreq, positions.get(i).intValue());\n      }\n\n      // sort by increasing docFreq order\n      if (slop == 0) {\n        Arrays.sort(postingsFreqs);\n      }\n\n      if (slop == 0) {\n        ExactPhraseScorer s = new ExactPhraseScorer(this, postingsFreqs, similarity,\n                                                    reader.norms(field));\n        if (s.noDocs) {\n          return null;\n        } else {\n          return s;\n        }\n      } else {\n        return new SloppyPhraseScorer(this, postingsFreqs, similarity,\n                                      slop, reader.norms(field));\n      }\n    }\n\n","bugFix":["20645c714ca2a7b7707c2707d58ee9fa384c7362","953de31d76c9d58f1e3f4e41ff8a48a1529226de"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0d302ba328993a5b449c2e0b3b5e15ae53e45879","date":1281609097,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/search/MultiPhraseQuery.MultiPhraseWeight#scorer(IndexReader,boolean,boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/MultiPhraseQuery.MultiPhraseWeight#scorer(IndexReader,boolean,boolean).mjava","sourceNew":"    @Override\n    public Scorer scorer(IndexReader reader, boolean scoreDocsInOrder, boolean topScorer) throws IOException {\n      if (termArrays.size() == 0)                  // optimize zero-term case\n        return null;\n\n      final Bits delDocs = reader.getDeletedDocs();\n      \n      PhraseQuery.PostingsAndFreq[] postingsFreqs = new PhraseQuery.PostingsAndFreq[termArrays.size()];\n\n      for (int pos=0; pos<postingsFreqs.length; pos++) {\n        Term[] terms = termArrays.get(pos);\n\n        final DocsAndPositionsEnum postingsEnum;\n        int docFreq;\n\n        if (terms.length > 1) {\n          postingsEnum = new UnionDocsAndPositionsEnum(reader, terms);\n\n          // coarse -- this overcounts since a given doc can\n          // have more than one terms:\n          docFreq = 0;\n          for(int termIdx=0;termIdx<terms.length;termIdx++) {\n            docFreq += reader.docFreq(terms[termIdx]);\n          }\n        } else {\n          final Term term = terms[0];\n          postingsEnum = reader.termPositionsEnum(delDocs,\n                                                  term.field(),\n                                                  term.bytes());\n\n          if (postingsEnum == null) {\n            if (reader.termDocsEnum(delDocs, term.field(), term.bytes()) != null) {\n              // term does exist, but has no positions\n              throw new IllegalStateException(\"field \\\"\" + term.field() + \"\\\" was indexed with Field.omitTermFreqAndPositions=true; cannot run PhraseQuery (term=\" + term.text() + \")\");\n            } else {\n              // term does not exist\n              return null;\n            }\n          }\n\n          docFreq = reader.docFreq(term.field(), term.bytes());\n        }\n\n        postingsFreqs[pos] = new PhraseQuery.PostingsAndFreq(postingsEnum, docFreq, positions.get(pos).intValue());\n      }\n\n      // sort by increasing docFreq order\n      if (slop == 0) {\n        Arrays.sort(postingsFreqs);\n      }\n\n      if (slop == 0) {\n        ExactPhraseScorer s = new ExactPhraseScorer(this, postingsFreqs, similarity,\n                                                    reader.norms(field));\n        if (s.noDocs) {\n          return null;\n        } else {\n          return s;\n        }\n      } else {\n        return new SloppyPhraseScorer(this, postingsFreqs, similarity,\n                                      slop, reader.norms(field));\n      }\n    }\n\n","sourceOld":"    @Override\n    public Scorer scorer(IndexReader reader, boolean scoreDocsInOrder, boolean topScorer) throws IOException {\n      if (termArrays.size() == 0)                  // optimize zero-term case\n        return null;\n\n      final Bits delDocs = MultiFields.getDeletedDocs(reader);\n      \n      PhraseQuery.PostingsAndFreq[] postingsFreqs = new PhraseQuery.PostingsAndFreq[termArrays.size()];\n\n      for (int pos=0; pos<postingsFreqs.length; pos++) {\n        Term[] terms = termArrays.get(pos);\n\n        final DocsAndPositionsEnum postingsEnum;\n        int docFreq;\n\n        if (terms.length > 1) {\n          postingsEnum = new UnionDocsAndPositionsEnum(reader, terms);\n\n          // coarse -- this overcounts since a given doc can\n          // have more than one terms:\n          docFreq = 0;\n          for(int termIdx=0;termIdx<terms.length;termIdx++) {\n            docFreq += reader.docFreq(terms[termIdx]);\n          }\n        } else {\n          final BytesRef text = new BytesRef(terms[0].text());\n          postingsEnum = reader.termPositionsEnum(delDocs,\n                                                  terms[0].field(),\n                                                  text);\n\n          if (postingsEnum == null) {\n            if (MultiFields.getTermDocsEnum(reader, delDocs, terms[0].field(), text) != null) {\n              // term does exist, but has no positions\n              throw new IllegalStateException(\"field \\\"\" + terms[0].field() + \"\\\" was indexed with Field.omitTermFreqAndPositions=true; cannot run PhraseQuery (term=\" + terms[0].text() + \")\");\n            } else {\n              // term does not exist\n              return null;\n            }\n          }\n\n          docFreq = reader.docFreq(terms[0].field(), text);\n        }\n\n        postingsFreqs[pos] = new PhraseQuery.PostingsAndFreq(postingsEnum, docFreq, positions.get(pos).intValue());\n      }\n\n      // sort by increasing docFreq order\n      if (slop == 0) {\n        Arrays.sort(postingsFreqs);\n      }\n\n      if (slop == 0) {\n        ExactPhraseScorer s = new ExactPhraseScorer(this, postingsFreqs, similarity,\n                                                    reader.norms(field));\n        if (s.noDocs) {\n          return null;\n        } else {\n          return s;\n        }\n      } else {\n        return new SloppyPhraseScorer(this, postingsFreqs, similarity,\n                                      slop, reader.norms(field));\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae7aa98ce0c64f3b2b81087d14ff9ae992b4903b","date":1288192616,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/search/MultiPhraseQuery.MultiPhraseWeight#scorer(IndexReader,boolean,boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/MultiPhraseQuery.MultiPhraseWeight#scorer(IndexReader,boolean,boolean).mjava","sourceNew":"    @Override\n    public Scorer scorer(IndexReader reader, boolean scoreDocsInOrder, boolean topScorer) throws IOException {\n      if (termArrays.size() == 0)                  // optimize zero-term case\n        return null;\n\n      final Bits delDocs = reader.getDeletedDocs();\n      \n      PhraseQuery.PostingsAndFreq[] postingsFreqs = new PhraseQuery.PostingsAndFreq[termArrays.size()];\n\n      for (int pos=0; pos<postingsFreqs.length; pos++) {\n        Term[] terms = termArrays.get(pos);\n\n        final DocsAndPositionsEnum postingsEnum;\n        int docFreq;\n\n        if (terms.length > 1) {\n          postingsEnum = new UnionDocsAndPositionsEnum(reader, terms);\n\n          // coarse -- this overcounts since a given doc can\n          // have more than one terms:\n          docFreq = 0;\n          for(int termIdx=0;termIdx<terms.length;termIdx++) {\n            docFreq += reader.docFreq(terms[termIdx]);\n          }\n        } else {\n          final Term term = terms[0];\n          postingsEnum = reader.termPositionsEnum(delDocs,\n                                                  term.field(),\n                                                  term.bytes());\n\n          if (postingsEnum == null) {\n            if (reader.termDocsEnum(delDocs, term.field(), term.bytes()) != null) {\n              // term does exist, but has no positions\n              throw new IllegalStateException(\"field \\\"\" + term.field() + \"\\\" was indexed with Field.omitTermFreqAndPositions=true; cannot run PhraseQuery (term=\" + term.text() + \")\");\n            } else {\n              // term does not exist\n              return null;\n            }\n          }\n\n          docFreq = reader.docFreq(term.field(), term.bytes());\n        }\n\n        postingsFreqs[pos] = new PhraseQuery.PostingsAndFreq(postingsEnum, docFreq, positions.get(pos).intValue());\n      }\n\n      // sort by increasing docFreq order\n      if (slop == 0) {\n        ArrayUtil.quickSort(postingsFreqs);\n      }\n\n      if (slop == 0) {\n        ExactPhraseScorer s = new ExactPhraseScorer(this, postingsFreqs, similarity,\n                                                    reader.norms(field));\n        if (s.noDocs) {\n          return null;\n        } else {\n          return s;\n        }\n      } else {\n        return new SloppyPhraseScorer(this, postingsFreqs, similarity,\n                                      slop, reader.norms(field));\n      }\n    }\n\n","sourceOld":"    @Override\n    public Scorer scorer(IndexReader reader, boolean scoreDocsInOrder, boolean topScorer) throws IOException {\n      if (termArrays.size() == 0)                  // optimize zero-term case\n        return null;\n\n      final Bits delDocs = reader.getDeletedDocs();\n      \n      PhraseQuery.PostingsAndFreq[] postingsFreqs = new PhraseQuery.PostingsAndFreq[termArrays.size()];\n\n      for (int pos=0; pos<postingsFreqs.length; pos++) {\n        Term[] terms = termArrays.get(pos);\n\n        final DocsAndPositionsEnum postingsEnum;\n        int docFreq;\n\n        if (terms.length > 1) {\n          postingsEnum = new UnionDocsAndPositionsEnum(reader, terms);\n\n          // coarse -- this overcounts since a given doc can\n          // have more than one terms:\n          docFreq = 0;\n          for(int termIdx=0;termIdx<terms.length;termIdx++) {\n            docFreq += reader.docFreq(terms[termIdx]);\n          }\n        } else {\n          final Term term = terms[0];\n          postingsEnum = reader.termPositionsEnum(delDocs,\n                                                  term.field(),\n                                                  term.bytes());\n\n          if (postingsEnum == null) {\n            if (reader.termDocsEnum(delDocs, term.field(), term.bytes()) != null) {\n              // term does exist, but has no positions\n              throw new IllegalStateException(\"field \\\"\" + term.field() + \"\\\" was indexed with Field.omitTermFreqAndPositions=true; cannot run PhraseQuery (term=\" + term.text() + \")\");\n            } else {\n              // term does not exist\n              return null;\n            }\n          }\n\n          docFreq = reader.docFreq(term.field(), term.bytes());\n        }\n\n        postingsFreqs[pos] = new PhraseQuery.PostingsAndFreq(postingsEnum, docFreq, positions.get(pos).intValue());\n      }\n\n      // sort by increasing docFreq order\n      if (slop == 0) {\n        Arrays.sort(postingsFreqs);\n      }\n\n      if (slop == 0) {\n        ExactPhraseScorer s = new ExactPhraseScorer(this, postingsFreqs, similarity,\n                                                    reader.norms(field));\n        if (s.noDocs) {\n          return null;\n        } else {\n          return s;\n        }\n      } else {\n        return new SloppyPhraseScorer(this, postingsFreqs, similarity,\n                                      slop, reader.norms(field));\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ca0ffea399542e8aac8ed7608f34f8ec4cb8904d","date":1288424244,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/search/MultiPhraseQuery.MultiPhraseWeight#scorer(IndexReader,boolean,boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/MultiPhraseQuery.MultiPhraseWeight#scorer(IndexReader,boolean,boolean).mjava","sourceNew":"    @Override\n    public Scorer scorer(IndexReader reader, boolean scoreDocsInOrder, boolean topScorer) throws IOException {\n      if (termArrays.size() == 0)                  // optimize zero-term case\n        return null;\n\n      final Bits delDocs = reader.getDeletedDocs();\n      \n      PhraseQuery.PostingsAndFreq[] postingsFreqs = new PhraseQuery.PostingsAndFreq[termArrays.size()];\n\n      for (int pos=0; pos<postingsFreqs.length; pos++) {\n        Term[] terms = termArrays.get(pos);\n\n        final DocsAndPositionsEnum postingsEnum;\n        int docFreq;\n\n        if (terms.length > 1) {\n          postingsEnum = new UnionDocsAndPositionsEnum(reader, terms);\n\n          // coarse -- this overcounts since a given doc can\n          // have more than one terms:\n          docFreq = 0;\n          for(int termIdx=0;termIdx<terms.length;termIdx++) {\n            docFreq += reader.docFreq(terms[termIdx]);\n          }\n        } else {\n          final Term term = terms[0];\n          postingsEnum = reader.termPositionsEnum(delDocs,\n                                                  term.field(),\n                                                  term.bytes());\n\n          if (postingsEnum == null) {\n            if (reader.termDocsEnum(delDocs, term.field(), term.bytes()) != null) {\n              // term does exist, but has no positions\n              throw new IllegalStateException(\"field \\\"\" + term.field() + \"\\\" was indexed with Field.omitTermFreqAndPositions=true; cannot run PhraseQuery (term=\" + term.text() + \")\");\n            } else {\n              // term does not exist\n              return null;\n            }\n          }\n\n          docFreq = reader.docFreq(term.field(), term.bytes());\n        }\n\n        postingsFreqs[pos] = new PhraseQuery.PostingsAndFreq(postingsEnum, docFreq, positions.get(pos).intValue());\n      }\n\n      // sort by increasing docFreq order\n      if (slop == 0) {\n        ArrayUtil.quickSort(postingsFreqs);\n      }\n\n      if (slop == 0) {\n        ExactPhraseScorer s = new ExactPhraseScorer(this, postingsFreqs, similarity,\n                                                    reader.norms(field));\n        if (s.noDocs) {\n          return null;\n        } else {\n          return s;\n        }\n      } else {\n        return new SloppyPhraseScorer(this, postingsFreqs, similarity,\n                                      slop, reader.norms(field));\n      }\n    }\n\n","sourceOld":"    @Override\n    public Scorer scorer(IndexReader reader, boolean scoreDocsInOrder, boolean topScorer) throws IOException {\n      if (termArrays.size() == 0)                  // optimize zero-term case\n        return null;\n\n      final Bits delDocs = reader.getDeletedDocs();\n      \n      PhraseQuery.PostingsAndFreq[] postingsFreqs = new PhraseQuery.PostingsAndFreq[termArrays.size()];\n\n      for (int pos=0; pos<postingsFreqs.length; pos++) {\n        Term[] terms = termArrays.get(pos);\n\n        final DocsAndPositionsEnum postingsEnum;\n        int docFreq;\n\n        if (terms.length > 1) {\n          postingsEnum = new UnionDocsAndPositionsEnum(reader, terms);\n\n          // coarse -- this overcounts since a given doc can\n          // have more than one terms:\n          docFreq = 0;\n          for(int termIdx=0;termIdx<terms.length;termIdx++) {\n            docFreq += reader.docFreq(terms[termIdx]);\n          }\n        } else {\n          final Term term = terms[0];\n          postingsEnum = reader.termPositionsEnum(delDocs,\n                                                  term.field(),\n                                                  term.bytes());\n\n          if (postingsEnum == null) {\n            if (reader.termDocsEnum(delDocs, term.field(), term.bytes()) != null) {\n              // term does exist, but has no positions\n              throw new IllegalStateException(\"field \\\"\" + term.field() + \"\\\" was indexed with Field.omitTermFreqAndPositions=true; cannot run PhraseQuery (term=\" + term.text() + \")\");\n            } else {\n              // term does not exist\n              return null;\n            }\n          }\n\n          docFreq = reader.docFreq(term.field(), term.bytes());\n        }\n\n        postingsFreqs[pos] = new PhraseQuery.PostingsAndFreq(postingsEnum, docFreq, positions.get(pos).intValue());\n      }\n\n      // sort by increasing docFreq order\n      if (slop == 0) {\n        Arrays.sort(postingsFreqs);\n      }\n\n      if (slop == 0) {\n        ExactPhraseScorer s = new ExactPhraseScorer(this, postingsFreqs, similarity,\n                                                    reader.norms(field));\n        if (s.noDocs) {\n          return null;\n        } else {\n          return s;\n        }\n      } else {\n        return new SloppyPhraseScorer(this, postingsFreqs, similarity,\n                                      slop, reader.norms(field));\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/search/MultiPhraseQuery.MultiPhraseWeight#scorer(IndexReader,boolean,boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/MultiPhraseQuery.MultiPhraseWeight#scorer(IndexReader,boolean,boolean).mjava","sourceNew":"    @Override\n    public Scorer scorer(IndexReader reader, boolean scoreDocsInOrder, boolean topScorer) throws IOException {\n      if (termArrays.size() == 0)                  // optimize zero-term case\n        return null;\n\n      final Bits delDocs = reader.getDeletedDocs();\n      \n      PhraseQuery.PostingsAndFreq[] postingsFreqs = new PhraseQuery.PostingsAndFreq[termArrays.size()];\n\n      for (int pos=0; pos<postingsFreqs.length; pos++) {\n        Term[] terms = termArrays.get(pos);\n\n        final DocsAndPositionsEnum postingsEnum;\n        int docFreq;\n\n        if (terms.length > 1) {\n          postingsEnum = new UnionDocsAndPositionsEnum(reader, terms);\n\n          // coarse -- this overcounts since a given doc can\n          // have more than one terms:\n          docFreq = 0;\n          for(int termIdx=0;termIdx<terms.length;termIdx++) {\n            docFreq += reader.docFreq(terms[termIdx]);\n          }\n        } else {\n          final Term term = terms[0];\n          postingsEnum = reader.termPositionsEnum(delDocs,\n                                                  term.field(),\n                                                  term.bytes());\n\n          if (postingsEnum == null) {\n            if (reader.termDocsEnum(delDocs, term.field(), term.bytes()) != null) {\n              // term does exist, but has no positions\n              throw new IllegalStateException(\"field \\\"\" + term.field() + \"\\\" was indexed with Field.omitTermFreqAndPositions=true; cannot run PhraseQuery (term=\" + term.text() + \")\");\n            } else {\n              // term does not exist\n              return null;\n            }\n          }\n\n          docFreq = reader.docFreq(term.field(), term.bytes());\n        }\n\n        postingsFreqs[pos] = new PhraseQuery.PostingsAndFreq(postingsEnum, docFreq, positions.get(pos).intValue());\n      }\n\n      // sort by increasing docFreq order\n      if (slop == 0) {\n        ArrayUtil.quickSort(postingsFreqs);\n      }\n\n      if (slop == 0) {\n        ExactPhraseScorer s = new ExactPhraseScorer(this, postingsFreqs, similarity,\n                                                    reader.norms(field));\n        if (s.noDocs) {\n          return null;\n        } else {\n          return s;\n        }\n      } else {\n        return new SloppyPhraseScorer(this, postingsFreqs, similarity,\n                                      slop, reader.norms(field));\n      }\n    }\n\n","sourceOld":"    @Override\n    public Scorer scorer(IndexReader reader, boolean scoreDocsInOrder, boolean topScorer) throws IOException {\n      if (termArrays.size() == 0)                  // optimize zero-term case\n        return null;\n\n      final Bits delDocs = MultiFields.getDeletedDocs(reader);\n      \n      PhraseQuery.PostingsAndFreq[] postingsFreqs = new PhraseQuery.PostingsAndFreq[termArrays.size()];\n\n      for (int i=0; i<postingsFreqs.length; i++) {\n        Term[] terms = termArrays.get(i);\n\n        final DocsAndPositionsEnum postingsEnum;\n        int docFreq;\n\n        if (terms.length > 1) {\n          postingsEnum = new UnionDocsAndPositionsEnum(reader, terms);\n\n          // coarse -- this overcounts since a given doc can\n          // have more than one terms:\n          docFreq = 0;\n          for(int j=0;j<terms.length;j++) {\n            docFreq += reader.docFreq(terms[i]);\n          }\n        } else {\n          final BytesRef text = new BytesRef(terms[0].text());\n          postingsEnum = reader.termPositionsEnum(delDocs,\n                                                  terms[0].field(),\n                                                  text);\n\n          if (postingsEnum == null) {\n            if (MultiFields.getTermDocsEnum(reader, delDocs, terms[0].field(), text) != null) {\n              // term does exist, but has no positions\n              throw new IllegalStateException(\"field \\\"\" + terms[0].field() + \"\\\" was indexed with Field.omitTermFreqAndPositions=true; cannot run PhraseQuery (term=\" + terms[0].text() + \")\");\n            } else {\n              // term does not exist\n              return null;\n            }\n          }\n\n          docFreq = reader.docFreq(terms[0].field(), text);\n        }\n\n        postingsFreqs[i] = new PhraseQuery.PostingsAndFreq(postingsEnum, docFreq, positions.get(i).intValue());\n      }\n\n      // sort by increasing docFreq order\n      if (slop == 0) {\n        Arrays.sort(postingsFreqs);\n      }\n\n      if (slop == 0) {\n        ExactPhraseScorer s = new ExactPhraseScorer(this, postingsFreqs, similarity,\n                                                    reader.norms(field));\n        if (s.noDocs) {\n          return null;\n        } else {\n          return s;\n        }\n      } else {\n        return new SloppyPhraseScorer(this, postingsFreqs, similarity,\n                                      slop, reader.norms(field));\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2dadf0f3286a34a0fee6e788ffce88624bf2984e","date":1294260428,"type":5,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/search/MultiPhraseQuery.MultiPhraseWeight#scorer(ReaderContext,boolean,boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/MultiPhraseQuery.MultiPhraseWeight#scorer(IndexReader,boolean,boolean).mjava","sourceNew":"    @Override\n    public Scorer scorer(ReaderContext context, boolean scoreDocsInOrder, boolean topScorer) throws IOException {\n      if (termArrays.size() == 0)                  // optimize zero-term case\n        return null;\n      final IndexReader reader = context.reader;\n      final Bits delDocs = reader.getDeletedDocs();\n      \n      PhraseQuery.PostingsAndFreq[] postingsFreqs = new PhraseQuery.PostingsAndFreq[termArrays.size()];\n\n      for (int pos=0; pos<postingsFreqs.length; pos++) {\n        Term[] terms = termArrays.get(pos);\n\n        final DocsAndPositionsEnum postingsEnum;\n        int docFreq;\n\n        if (terms.length > 1) {\n          postingsEnum = new UnionDocsAndPositionsEnum(reader, terms);\n\n          // coarse -- this overcounts since a given doc can\n          // have more than one terms:\n          docFreq = 0;\n          for(int termIdx=0;termIdx<terms.length;termIdx++) {\n            docFreq += reader.docFreq(terms[termIdx]);\n          }\n        } else {\n          final Term term = terms[0];\n          postingsEnum = reader.termPositionsEnum(delDocs,\n                                                  term.field(),\n                                                  term.bytes());\n\n          if (postingsEnum == null) {\n            if (reader.termDocsEnum(delDocs, term.field(), term.bytes()) != null) {\n              // term does exist, but has no positions\n              throw new IllegalStateException(\"field \\\"\" + term.field() + \"\\\" was indexed with Field.omitTermFreqAndPositions=true; cannot run PhraseQuery (term=\" + term.text() + \")\");\n            } else {\n              // term does not exist\n              return null;\n            }\n          }\n\n          docFreq = reader.docFreq(term.field(), term.bytes());\n        }\n\n        postingsFreqs[pos] = new PhraseQuery.PostingsAndFreq(postingsEnum, docFreq, positions.get(pos).intValue());\n      }\n\n      // sort by increasing docFreq order\n      if (slop == 0) {\n        ArrayUtil.quickSort(postingsFreqs);\n      }\n\n      if (slop == 0) {\n        ExactPhraseScorer s = new ExactPhraseScorer(this, postingsFreqs, similarity,\n            reader.norms(field));\n        if (s.noDocs) {\n          return null;\n        } else {\n          return s;\n        }\n      } else {\n        return new SloppyPhraseScorer(this, postingsFreqs, similarity,\n                                      slop, reader.norms(field));\n      }\n    }\n\n","sourceOld":"    @Override\n    public Scorer scorer(IndexReader reader, boolean scoreDocsInOrder, boolean topScorer) throws IOException {\n      if (termArrays.size() == 0)                  // optimize zero-term case\n        return null;\n\n      final Bits delDocs = reader.getDeletedDocs();\n      \n      PhraseQuery.PostingsAndFreq[] postingsFreqs = new PhraseQuery.PostingsAndFreq[termArrays.size()];\n\n      for (int pos=0; pos<postingsFreqs.length; pos++) {\n        Term[] terms = termArrays.get(pos);\n\n        final DocsAndPositionsEnum postingsEnum;\n        int docFreq;\n\n        if (terms.length > 1) {\n          postingsEnum = new UnionDocsAndPositionsEnum(reader, terms);\n\n          // coarse -- this overcounts since a given doc can\n          // have more than one terms:\n          docFreq = 0;\n          for(int termIdx=0;termIdx<terms.length;termIdx++) {\n            docFreq += reader.docFreq(terms[termIdx]);\n          }\n        } else {\n          final Term term = terms[0];\n          postingsEnum = reader.termPositionsEnum(delDocs,\n                                                  term.field(),\n                                                  term.bytes());\n\n          if (postingsEnum == null) {\n            if (reader.termDocsEnum(delDocs, term.field(), term.bytes()) != null) {\n              // term does exist, but has no positions\n              throw new IllegalStateException(\"field \\\"\" + term.field() + \"\\\" was indexed with Field.omitTermFreqAndPositions=true; cannot run PhraseQuery (term=\" + term.text() + \")\");\n            } else {\n              // term does not exist\n              return null;\n            }\n          }\n\n          docFreq = reader.docFreq(term.field(), term.bytes());\n        }\n\n        postingsFreqs[pos] = new PhraseQuery.PostingsAndFreq(postingsEnum, docFreq, positions.get(pos).intValue());\n      }\n\n      // sort by increasing docFreq order\n      if (slop == 0) {\n        ArrayUtil.quickSort(postingsFreqs);\n      }\n\n      if (slop == 0) {\n        ExactPhraseScorer s = new ExactPhraseScorer(this, postingsFreqs, similarity,\n                                                    reader.norms(field));\n        if (s.noDocs) {\n          return null;\n        } else {\n          return s;\n        }\n      } else {\n        return new SloppyPhraseScorer(this, postingsFreqs, similarity,\n                                      slop, reader.norms(field));\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"868da859b43505d9d2a023bfeae6dd0c795f5295","date":1294948401,"type":4,"author":"Michael Busch","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/src/java/org/apache/lucene/search/MultiPhraseQuery.MultiPhraseWeight#scorer(IndexReader,boolean,boolean).mjava","sourceNew":null,"sourceOld":"    @Override\n    public Scorer scorer(IndexReader reader, boolean scoreDocsInOrder, boolean topScorer) throws IOException {\n      if (termArrays.size() == 0)                  // optimize zero-term case\n        return null;\n\n      final Bits delDocs = reader.getDeletedDocs();\n      \n      PhraseQuery.PostingsAndFreq[] postingsFreqs = new PhraseQuery.PostingsAndFreq[termArrays.size()];\n\n      for (int pos=0; pos<postingsFreqs.length; pos++) {\n        Term[] terms = termArrays.get(pos);\n\n        final DocsAndPositionsEnum postingsEnum;\n        int docFreq;\n\n        if (terms.length > 1) {\n          postingsEnum = new UnionDocsAndPositionsEnum(reader, terms);\n\n          // coarse -- this overcounts since a given doc can\n          // have more than one terms:\n          docFreq = 0;\n          for(int termIdx=0;termIdx<terms.length;termIdx++) {\n            docFreq += reader.docFreq(terms[termIdx]);\n          }\n        } else {\n          final Term term = terms[0];\n          postingsEnum = reader.termPositionsEnum(delDocs,\n                                                  term.field(),\n                                                  term.bytes());\n\n          if (postingsEnum == null) {\n            if (reader.termDocsEnum(delDocs, term.field(), term.bytes()) != null) {\n              // term does exist, but has no positions\n              throw new IllegalStateException(\"field \\\"\" + term.field() + \"\\\" was indexed with Field.omitTermFreqAndPositions=true; cannot run PhraseQuery (term=\" + term.text() + \")\");\n            } else {\n              // term does not exist\n              return null;\n            }\n          }\n\n          docFreq = reader.docFreq(term.field(), term.bytes());\n        }\n\n        postingsFreqs[pos] = new PhraseQuery.PostingsAndFreq(postingsEnum, docFreq, positions.get(pos).intValue());\n      }\n\n      // sort by increasing docFreq order\n      if (slop == 0) {\n        ArrayUtil.quickSort(postingsFreqs);\n      }\n\n      if (slop == 0) {\n        ExactPhraseScorer s = new ExactPhraseScorer(this, postingsFreqs, similarity,\n                                                    reader.norms(field));\n        if (s.noDocs) {\n          return null;\n        } else {\n          return s;\n        }\n      } else {\n        return new SloppyPhraseScorer(this, postingsFreqs, similarity,\n                                      slop, reader.norms(field));\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"29ef99d61cda9641b6250bf9567329a6e65f901d","date":1297244127,"type":4,"author":"Simon Willnauer","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/src/java/org/apache/lucene/search/MultiPhraseQuery.MultiPhraseWeight#scorer(IndexReader,boolean,boolean).mjava","sourceNew":null,"sourceOld":"    @Override\n    public Scorer scorer(IndexReader reader, boolean scoreDocsInOrder, boolean topScorer) throws IOException {\n      if (termArrays.size() == 0)                  // optimize zero-term case\n        return null;\n\n      final Bits delDocs = reader.getDeletedDocs();\n      \n      PhraseQuery.PostingsAndFreq[] postingsFreqs = new PhraseQuery.PostingsAndFreq[termArrays.size()];\n\n      for (int pos=0; pos<postingsFreqs.length; pos++) {\n        Term[] terms = termArrays.get(pos);\n\n        final DocsAndPositionsEnum postingsEnum;\n        int docFreq;\n\n        if (terms.length > 1) {\n          postingsEnum = new UnionDocsAndPositionsEnum(reader, terms);\n\n          // coarse -- this overcounts since a given doc can\n          // have more than one terms:\n          docFreq = 0;\n          for(int termIdx=0;termIdx<terms.length;termIdx++) {\n            docFreq += reader.docFreq(terms[termIdx]);\n          }\n        } else {\n          final Term term = terms[0];\n          postingsEnum = reader.termPositionsEnum(delDocs,\n                                                  term.field(),\n                                                  term.bytes());\n\n          if (postingsEnum == null) {\n            if (reader.termDocsEnum(delDocs, term.field(), term.bytes()) != null) {\n              // term does exist, but has no positions\n              throw new IllegalStateException(\"field \\\"\" + term.field() + \"\\\" was indexed with Field.omitTermFreqAndPositions=true; cannot run PhraseQuery (term=\" + term.text() + \")\");\n            } else {\n              // term does not exist\n              return null;\n            }\n          }\n\n          docFreq = reader.docFreq(term.field(), term.bytes());\n        }\n\n        postingsFreqs[pos] = new PhraseQuery.PostingsAndFreq(postingsEnum, docFreq, positions.get(pos).intValue());\n      }\n\n      // sort by increasing docFreq order\n      if (slop == 0) {\n        ArrayUtil.quickSort(postingsFreqs);\n      }\n\n      if (slop == 0) {\n        ExactPhraseScorer s = new ExactPhraseScorer(this, postingsFreqs, similarity,\n                                                    reader.norms(field));\n        if (s.noDocs) {\n          return null;\n        } else {\n          return s;\n        }\n      } else {\n        return new SloppyPhraseScorer(this, postingsFreqs, similarity,\n                                      slop, reader.norms(field));\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"2ac7b588a949391edf21dd63c943990a9c3aec5f":["953de31d76c9d58f1e3f4e41ff8a48a1529226de"],"955c32f886db6f6356c9fcdea6b1f1cb4effda24":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"0d302ba328993a5b449c2e0b3b5e15ae53e45879":["2ac7b588a949391edf21dd63c943990a9c3aec5f"],"5f4e87790277826a2aea119328600dfb07761f32":["955c32f886db6f6356c9fcdea6b1f1cb4effda24","953de31d76c9d58f1e3f4e41ff8a48a1529226de"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["5f4e87790277826a2aea119328600dfb07761f32","ae7aa98ce0c64f3b2b81087d14ff9ae992b4903b"],"953de31d76c9d58f1e3f4e41ff8a48a1529226de":["955c32f886db6f6356c9fcdea6b1f1cb4effda24"],"ae7aa98ce0c64f3b2b81087d14ff9ae992b4903b":["0d302ba328993a5b449c2e0b3b5e15ae53e45879"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["ca0ffea399542e8aac8ed7608f34f8ec4cb8904d","2dadf0f3286a34a0fee6e788ffce88624bf2984e"],"2dadf0f3286a34a0fee6e788ffce88624bf2984e":["ae7aa98ce0c64f3b2b81087d14ff9ae992b4903b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"ca0ffea399542e8aac8ed7608f34f8ec4cb8904d":["0d302ba328993a5b449c2e0b3b5e15ae53e45879","ae7aa98ce0c64f3b2b81087d14ff9ae992b4903b"],"868da859b43505d9d2a023bfeae6dd0c795f5295":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","2dadf0f3286a34a0fee6e788ffce88624bf2984e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["2dadf0f3286a34a0fee6e788ffce88624bf2984e"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"2ac7b588a949391edf21dd63c943990a9c3aec5f":["0d302ba328993a5b449c2e0b3b5e15ae53e45879"],"955c32f886db6f6356c9fcdea6b1f1cb4effda24":["5f4e87790277826a2aea119328600dfb07761f32","953de31d76c9d58f1e3f4e41ff8a48a1529226de"],"0d302ba328993a5b449c2e0b3b5e15ae53e45879":["ae7aa98ce0c64f3b2b81087d14ff9ae992b4903b","ca0ffea399542e8aac8ed7608f34f8ec4cb8904d"],"5f4e87790277826a2aea119328600dfb07761f32":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["868da859b43505d9d2a023bfeae6dd0c795f5295"],"953de31d76c9d58f1e3f4e41ff8a48a1529226de":["2ac7b588a949391edf21dd63c943990a9c3aec5f","5f4e87790277826a2aea119328600dfb07761f32"],"ae7aa98ce0c64f3b2b81087d14ff9ae992b4903b":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","2dadf0f3286a34a0fee6e788ffce88624bf2984e","ca0ffea399542e8aac8ed7608f34f8ec4cb8904d"],"29ef99d61cda9641b6250bf9567329a6e65f901d":[],"2dadf0f3286a34a0fee6e788ffce88624bf2984e":["29ef99d61cda9641b6250bf9567329a6e65f901d","868da859b43505d9d2a023bfeae6dd0c795f5295","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"ca0ffea399542e8aac8ed7608f34f8ec4cb8904d":["29ef99d61cda9641b6250bf9567329a6e65f901d"],"868da859b43505d9d2a023bfeae6dd0c795f5295":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["955c32f886db6f6356c9fcdea6b1f1cb4effda24"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["29ef99d61cda9641b6250bf9567329a6e65f901d","868da859b43505d9d2a023bfeae6dd0c795f5295","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}