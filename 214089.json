{"path":"lucene/src/test/org/apache/lucene/store/TestNRTCachingDirectory#testNRTAndCommit().mjava","commits":[{"id":"df16fc2e9b615e0138edac46655ae628f5d098ad","date":1320876869,"type":1,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/store/TestNRTCachingDirectory#testNRTAndCommit().mjava","pathOld":"lucene/contrib/misc/src/test/org/apache/lucene/store/TestNRTCachingDirectory#testNRTAndCommit().mjava","sourceNew":"  public void testNRTAndCommit() throws Exception {\n    Directory dir = newDirectory();\n    NRTCachingDirectory cachedDir = new NRTCachingDirectory(dir, 2.0, 25.0);\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n    RandomIndexWriter w = new RandomIndexWriter(random, cachedDir, conf);\n    final LineFileDocs docs = new LineFileDocs(random);    \n    final int numDocs = _TestUtil.nextInt(random, 100, 400);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: numDocs=\" + numDocs);\n    }\n\n    final List<BytesRef> ids = new ArrayList<BytesRef>();\n    IndexReader r = null;\n    for(int docCount=0;docCount<numDocs;docCount++) {\n      final Document doc = docs.nextDoc();\n      ids.add(new BytesRef(doc.get(\"docid\")));\n      w.addDocument(doc);\n      if (random.nextInt(20) == 17) {\n        if (r == null) {\n          r = IndexReader.open(w.w, false);\n        } else {\n          final IndexReader r2 = IndexReader.openIfChanged(r);\n          if (r2 != null) {\n            r.close();\n            r = r2;\n          }\n        }\n        assertEquals(1+docCount, r.numDocs());\n        final IndexSearcher s = new IndexSearcher(r);\n        // Just make sure search can run; we can't assert\n        // totHits since it could be 0\n        TopDocs hits = s.search(new TermQuery(new Term(\"body\", \"the\")), 10);\n        // System.out.println(\"tot hits \" + hits.totalHits);\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    // Close should force cache to clear since all files are sync'd\n    w.close();\n\n    final String[] cachedFiles = cachedDir.listCachedFiles();\n    for(String file : cachedFiles) {\n      System.out.println(\"FAIL: cached file \" + file + \" remains after sync\");\n    }\n    assertEquals(0, cachedFiles.length);\n    \n    r = IndexReader.open(dir);\n    for(BytesRef id : ids) {\n      assertEquals(1, r.docFreq(\"docid\", id));\n    }\n    r.close();\n    cachedDir.close();\n  }\n\n","sourceOld":"  public void testNRTAndCommit() throws Exception {\n    Directory dir = newDirectory();\n    NRTCachingDirectory cachedDir = new NRTCachingDirectory(dir, 2.0, 25.0);\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n    RandomIndexWriter w = new RandomIndexWriter(random, cachedDir, conf);\n    final LineFileDocs docs = new LineFileDocs(random);    \n    final int numDocs = _TestUtil.nextInt(random, 100, 400);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: numDocs=\" + numDocs);\n    }\n\n    final List<BytesRef> ids = new ArrayList<BytesRef>();\n    IndexReader r = null;\n    for(int docCount=0;docCount<numDocs;docCount++) {\n      final Document doc = docs.nextDoc();\n      ids.add(new BytesRef(doc.get(\"docid\")));\n      w.addDocument(doc);\n      if (random.nextInt(20) == 17) {\n        if (r == null) {\n          r = IndexReader.open(w.w, false);\n        } else {\n          final IndexReader r2 = IndexReader.openIfChanged(r);\n          if (r2 != null) {\n            r.close();\n            r = r2;\n          }\n        }\n        assertEquals(1+docCount, r.numDocs());\n        final IndexSearcher s = new IndexSearcher(r);\n        // Just make sure search can run; we can't assert\n        // totHits since it could be 0\n        TopDocs hits = s.search(new TermQuery(new Term(\"body\", \"the\")), 10);\n        // System.out.println(\"tot hits \" + hits.totalHits);\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    // Close should force cache to clear since all files are sync'd\n    w.close();\n\n    final String[] cachedFiles = cachedDir.listCachedFiles();\n    for(String file : cachedFiles) {\n      System.out.println(\"FAIL: cached file \" + file + \" remains after sync\");\n    }\n    assertEquals(0, cachedFiles.length);\n    \n    r = IndexReader.open(dir);\n    for(BytesRef id : ids) {\n      assertEquals(1, r.docFreq(\"docid\", id));\n    }\n    r.close();\n    cachedDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a2ec9a9068164200de82395f0e8537a9d9302f3f","date":1327856476,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/store/TestNRTCachingDirectory#testNRTAndCommit().mjava","pathOld":"lucene/src/test/org/apache/lucene/store/TestNRTCachingDirectory#testNRTAndCommit().mjava","sourceNew":"  public void testNRTAndCommit() throws Exception {\n    Directory dir = newDirectory();\n    NRTCachingDirectory cachedDir = new NRTCachingDirectory(dir, 2.0, 25.0);\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n    RandomIndexWriter w = new RandomIndexWriter(random, cachedDir, conf);\n    final LineFileDocs docs = new LineFileDocs(random);    \n    final int numDocs = _TestUtil.nextInt(random, 100, 400);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: numDocs=\" + numDocs);\n    }\n\n    final List<BytesRef> ids = new ArrayList<BytesRef>();\n    DirectoryReader r = null;\n    for(int docCount=0;docCount<numDocs;docCount++) {\n      final Document doc = docs.nextDoc();\n      ids.add(new BytesRef(doc.get(\"docid\")));\n      w.addDocument(doc);\n      if (random.nextInt(20) == 17) {\n        if (r == null) {\n          r = IndexReader.open(w.w, false);\n        } else {\n          final DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n          if (r2 != null) {\n            r.close();\n            r = r2;\n          }\n        }\n        assertEquals(1+docCount, r.numDocs());\n        final IndexSearcher s = new IndexSearcher(r);\n        // Just make sure search can run; we can't assert\n        // totHits since it could be 0\n        TopDocs hits = s.search(new TermQuery(new Term(\"body\", \"the\")), 10);\n        // System.out.println(\"tot hits \" + hits.totalHits);\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    // Close should force cache to clear since all files are sync'd\n    w.close();\n\n    final String[] cachedFiles = cachedDir.listCachedFiles();\n    for(String file : cachedFiles) {\n      System.out.println(\"FAIL: cached file \" + file + \" remains after sync\");\n    }\n    assertEquals(0, cachedFiles.length);\n    \n    r = IndexReader.open(dir);\n    for(BytesRef id : ids) {\n      assertEquals(1, r.docFreq(\"docid\", id));\n    }\n    r.close();\n    cachedDir.close();\n  }\n\n","sourceOld":"  public void testNRTAndCommit() throws Exception {\n    Directory dir = newDirectory();\n    NRTCachingDirectory cachedDir = new NRTCachingDirectory(dir, 2.0, 25.0);\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n    RandomIndexWriter w = new RandomIndexWriter(random, cachedDir, conf);\n    final LineFileDocs docs = new LineFileDocs(random);    \n    final int numDocs = _TestUtil.nextInt(random, 100, 400);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: numDocs=\" + numDocs);\n    }\n\n    final List<BytesRef> ids = new ArrayList<BytesRef>();\n    IndexReader r = null;\n    for(int docCount=0;docCount<numDocs;docCount++) {\n      final Document doc = docs.nextDoc();\n      ids.add(new BytesRef(doc.get(\"docid\")));\n      w.addDocument(doc);\n      if (random.nextInt(20) == 17) {\n        if (r == null) {\n          r = IndexReader.open(w.w, false);\n        } else {\n          final IndexReader r2 = IndexReader.openIfChanged(r);\n          if (r2 != null) {\n            r.close();\n            r = r2;\n          }\n        }\n        assertEquals(1+docCount, r.numDocs());\n        final IndexSearcher s = new IndexSearcher(r);\n        // Just make sure search can run; we can't assert\n        // totHits since it could be 0\n        TopDocs hits = s.search(new TermQuery(new Term(\"body\", \"the\")), 10);\n        // System.out.println(\"tot hits \" + hits.totalHits);\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    // Close should force cache to clear since all files are sync'd\n    w.close();\n\n    final String[] cachedFiles = cachedDir.listCachedFiles();\n    for(String file : cachedFiles) {\n      System.out.println(\"FAIL: cached file \" + file + \" remains after sync\");\n    }\n    assertEquals(0, cachedFiles.length);\n    \n    r = IndexReader.open(dir);\n    for(BytesRef id : ids) {\n      assertEquals(1, r.docFreq(\"docid\", id));\n    }\n    r.close();\n    cachedDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5cab9a86bd67202d20b6adc463008c8e982b070a","date":1327966443,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/store/TestNRTCachingDirectory#testNRTAndCommit().mjava","pathOld":"lucene/src/test/org/apache/lucene/store/TestNRTCachingDirectory#testNRTAndCommit().mjava","sourceNew":"  public void testNRTAndCommit() throws Exception {\n    Directory dir = newDirectory();\n    NRTCachingDirectory cachedDir = new NRTCachingDirectory(dir, 2.0, 25.0);\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n    RandomIndexWriter w = new RandomIndexWriter(random, cachedDir, conf);\n    final LineFileDocs docs = new LineFileDocs(random);    \n    final int numDocs = _TestUtil.nextInt(random, 100, 400);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: numDocs=\" + numDocs);\n    }\n\n    final List<BytesRef> ids = new ArrayList<BytesRef>();\n    DirectoryReader r = null;\n    for(int docCount=0;docCount<numDocs;docCount++) {\n      final Document doc = docs.nextDoc();\n      ids.add(new BytesRef(doc.get(\"docid\")));\n      w.addDocument(doc);\n      if (random.nextInt(20) == 17) {\n        if (r == null) {\n          r = IndexReader.open(w.w, false);\n        } else {\n          final DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n          if (r2 != null) {\n            r.close();\n            r = r2;\n          }\n        }\n        assertEquals(1+docCount, r.numDocs());\n        final IndexSearcher s = new IndexSearcher(r);\n        // Just make sure search can run; we can't assert\n        // totHits since it could be 0\n        TopDocs hits = s.search(new TermQuery(new Term(\"body\", \"the\")), 10);\n        // System.out.println(\"tot hits \" + hits.totalHits);\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    // Close should force cache to clear since all files are sync'd\n    w.close();\n\n    final String[] cachedFiles = cachedDir.listCachedFiles();\n    for(String file : cachedFiles) {\n      System.out.println(\"FAIL: cached file \" + file + \" remains after sync\");\n    }\n    assertEquals(0, cachedFiles.length);\n    \n    r = IndexReader.open(dir);\n    for(BytesRef id : ids) {\n      assertEquals(1, r.docFreq(\"docid\", id));\n    }\n    r.close();\n    cachedDir.close();\n  }\n\n","sourceOld":"  public void testNRTAndCommit() throws Exception {\n    Directory dir = newDirectory();\n    NRTCachingDirectory cachedDir = new NRTCachingDirectory(dir, 2.0, 25.0);\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n    RandomIndexWriter w = new RandomIndexWriter(random, cachedDir, conf);\n    final LineFileDocs docs = new LineFileDocs(random);    \n    final int numDocs = _TestUtil.nextInt(random, 100, 400);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: numDocs=\" + numDocs);\n    }\n\n    final List<BytesRef> ids = new ArrayList<BytesRef>();\n    IndexReader r = null;\n    for(int docCount=0;docCount<numDocs;docCount++) {\n      final Document doc = docs.nextDoc();\n      ids.add(new BytesRef(doc.get(\"docid\")));\n      w.addDocument(doc);\n      if (random.nextInt(20) == 17) {\n        if (r == null) {\n          r = IndexReader.open(w.w, false);\n        } else {\n          final IndexReader r2 = IndexReader.openIfChanged(r);\n          if (r2 != null) {\n            r.close();\n            r = r2;\n          }\n        }\n        assertEquals(1+docCount, r.numDocs());\n        final IndexSearcher s = new IndexSearcher(r);\n        // Just make sure search can run; we can't assert\n        // totHits since it could be 0\n        TopDocs hits = s.search(new TermQuery(new Term(\"body\", \"the\")), 10);\n        // System.out.println(\"tot hits \" + hits.totalHits);\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    // Close should force cache to clear since all files are sync'd\n    w.close();\n\n    final String[] cachedFiles = cachedDir.listCachedFiles();\n    for(String file : cachedFiles) {\n      System.out.println(\"FAIL: cached file \" + file + \" remains after sync\");\n    }\n    assertEquals(0, cachedFiles.length);\n    \n    r = IndexReader.open(dir);\n    for(BytesRef id : ids) {\n      assertEquals(1, r.docFreq(\"docid\", id));\n    }\n    r.close();\n    cachedDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/store/TestNRTCachingDirectory#testNRTAndCommit().mjava","pathOld":"lucene/src/test/org/apache/lucene/store/TestNRTCachingDirectory#testNRTAndCommit().mjava","sourceNew":"  public void testNRTAndCommit() throws Exception {\n    Directory dir = newDirectory();\n    NRTCachingDirectory cachedDir = new NRTCachingDirectory(dir, 2.0, 25.0);\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n    RandomIndexWriter w = new RandomIndexWriter(random, cachedDir, conf);\n    final LineFileDocs docs = new LineFileDocs(random);    \n    final int numDocs = _TestUtil.nextInt(random, 100, 400);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: numDocs=\" + numDocs);\n    }\n\n    final List<BytesRef> ids = new ArrayList<BytesRef>();\n    DirectoryReader r = null;\n    for(int docCount=0;docCount<numDocs;docCount++) {\n      final Document doc = docs.nextDoc();\n      ids.add(new BytesRef(doc.get(\"docid\")));\n      w.addDocument(doc);\n      if (random.nextInt(20) == 17) {\n        if (r == null) {\n          r = IndexReader.open(w.w, false);\n        } else {\n          final DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n          if (r2 != null) {\n            r.close();\n            r = r2;\n          }\n        }\n        assertEquals(1+docCount, r.numDocs());\n        final IndexSearcher s = new IndexSearcher(r);\n        // Just make sure search can run; we can't assert\n        // totHits since it could be 0\n        TopDocs hits = s.search(new TermQuery(new Term(\"body\", \"the\")), 10);\n        // System.out.println(\"tot hits \" + hits.totalHits);\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    // Close should force cache to clear since all files are sync'd\n    w.close();\n\n    final String[] cachedFiles = cachedDir.listCachedFiles();\n    for(String file : cachedFiles) {\n      System.out.println(\"FAIL: cached file \" + file + \" remains after sync\");\n    }\n    assertEquals(0, cachedFiles.length);\n    \n    r = IndexReader.open(dir);\n    for(BytesRef id : ids) {\n      assertEquals(1, r.docFreq(\"docid\", id));\n    }\n    r.close();\n    cachedDir.close();\n  }\n\n","sourceOld":"  public void testNRTAndCommit() throws Exception {\n    Directory dir = newDirectory();\n    NRTCachingDirectory cachedDir = new NRTCachingDirectory(dir, 2.0, 25.0);\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n    RandomIndexWriter w = new RandomIndexWriter(random, cachedDir, conf);\n    final LineFileDocs docs = new LineFileDocs(random);    \n    final int numDocs = _TestUtil.nextInt(random, 100, 400);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: numDocs=\" + numDocs);\n    }\n\n    final List<BytesRef> ids = new ArrayList<BytesRef>();\n    DirectoryReader r = null;\n    for(int docCount=0;docCount<numDocs;docCount++) {\n      final Document doc = docs.nextDoc();\n      ids.add(new BytesRef(doc.get(\"docid\")));\n      w.addDocument(doc);\n      if (random.nextInt(20) == 17) {\n        if (r == null) {\n          r = IndexReader.open(w.w, false);\n        } else {\n          final DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n          if (r2 != null) {\n            r.close();\n            r = r2;\n          }\n        }\n        assertEquals(1+docCount, r.numDocs());\n        final IndexSearcher s = new IndexSearcher(r);\n        // Just make sure search can run; we can't assert\n        // totHits since it could be 0\n        TopDocs hits = s.search(new TermQuery(new Term(\"body\", \"the\")), 10);\n        // System.out.println(\"tot hits \" + hits.totalHits);\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    // Close should force cache to clear since all files are sync'd\n    w.close();\n\n    final String[] cachedFiles = cachedDir.listCachedFiles();\n    for(String file : cachedFiles) {\n      System.out.println(\"FAIL: cached file \" + file + \" remains after sync\");\n    }\n    assertEquals(0, cachedFiles.length);\n    \n    r = IndexReader.open(dir);\n    for(BytesRef id : ids) {\n      assertEquals(1, r.docFreq(\"docid\", id));\n    }\n    r.close();\n    cachedDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"df16fc2e9b615e0138edac46655ae628f5d098ad":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["5cab9a86bd67202d20b6adc463008c8e982b070a"],"a2ec9a9068164200de82395f0e8537a9d9302f3f":["df16fc2e9b615e0138edac46655ae628f5d098ad"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"5cab9a86bd67202d20b6adc463008c8e982b070a":["df16fc2e9b615e0138edac46655ae628f5d098ad","a2ec9a9068164200de82395f0e8537a9d9302f3f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"]},"commit2Childs":{"df16fc2e9b615e0138edac46655ae628f5d098ad":["a2ec9a9068164200de82395f0e8537a9d9302f3f","5cab9a86bd67202d20b6adc463008c8e982b070a"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a2ec9a9068164200de82395f0e8537a9d9302f3f":["5cab9a86bd67202d20b6adc463008c8e982b070a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["df16fc2e9b615e0138edac46655ae628f5d098ad"],"5cab9a86bd67202d20b6adc463008c8e982b070a":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}