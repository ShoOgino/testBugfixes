{"path":"lucene/suggest/src/test/org/apache/lucene/search/suggest/document/TestSuggestField#testRandom().mjava","commits":[{"id":"902a92b60648a8925bfd9bb53a78669cd2ea98fd","date":1487797466,"type":0,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/document/TestSuggestField#testRandom().mjava","pathOld":"/dev/null","sourceNew":"  public void testRandom() throws Exception {\n    int numDigits = TestUtil.nextInt(random(), 1, 6);\n    Set<String> keys = new HashSet<>();\n    int keyCount = TestUtil.nextInt(random(), 1, 20);\n    if (numDigits == 1) {\n      keyCount = Math.min(9, keyCount);\n    }\n    while (keys.size() < keyCount) {\n      keys.add(randomSimpleString(numDigits, 10));\n    }\n    List<String> keysList = new ArrayList<>(keys);\n\n    Analyzer analyzer = new MockAnalyzer(random());\n    IndexWriterConfig iwc = iwcWithSuggestField(analyzer, \"suggest_field\");\n    // we rely on docID order:\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n    int docCount = TestUtil.nextInt(random(), 1, 200);\n    Entry[] docs = new Entry[docCount];\n    for(int i=0;i<docCount;i++) {\n      int weight = random().nextInt(40);\n      String key = keysList.get(random().nextInt(keyCount));\n      //System.out.println(\"KEY: \" + key);\n      docs[i] = new Entry(key, null, weight, i);\n      Document doc = new Document();\n      doc.add(new SuggestField(\"suggest_field\", key, weight));\n      iw.addDocument(doc);\n      if (usually()) {\n        iw.commit();\n      }\n    }\n\n    DirectoryReader reader = iw.getReader();\n    SuggestIndexSearcher searcher = new SuggestIndexSearcher(reader);\n\n    int iters = atLeast(200);\n    for(int iter=0;iter<iters;iter++) {\n      String prefix = randomSimpleString(numDigits, 2);\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      // slow but hopefully correct suggester:\n      List<Entry> expected = new ArrayList<>();\n      for(Entry doc : docs) {\n        if (doc.output.startsWith(prefix)) {\n          expected.add(doc);\n        }\n      }\n      Collections.sort(expected,\n                       new Comparator<Entry>() {\n                         @Override\n                         public int compare(Entry a, Entry b) {\n                           // sort by higher score:\n                           int cmp = Float.compare(b.value, a.value);\n                           if (cmp == 0) {\n                             // tie break by smaller docID:\n                             cmp = Integer.compare(a.id, b.id);\n                           }\n                           return cmp;\n                         }\n                       });\n\n      boolean dedup = random().nextBoolean();\n      if (dedup) {\n        List<Entry> deduped = new ArrayList<>();\n        Set<String> seen = new HashSet<>();\n        for(Entry entry : expected) {\n          if (seen.contains(entry.output) == false) {\n            seen.add(entry.output);\n            deduped.add(entry);\n          }\n        }\n        expected = deduped;\n      }\n\n      // TODO: re-enable this, except something is buggy about tie breaks at the topN threshold now:\n      //int topN = TestUtil.nextInt(random(), 1, docCount+10);\n      int topN = docCount;\n      \n      if (VERBOSE) {\n        if (dedup) {\n          System.out.println(\"  expected (dedup'd) topN=\" + topN + \":\");\n        } else {\n          System.out.println(\"  expected topN=\" + topN + \":\");\n        }\n        for(int i=0;i<expected.size();i++) {\n          if (i >= topN) {\n            System.out.println(\"    leftover: \" + i + \": \" + expected.get(i));\n          } else {\n            System.out.println(\"    \" + i + \": \" + expected.get(i));\n          }\n        }\n      }\n      expected = expected.subList(0, Math.min(topN, expected.size()));\n      \n      PrefixCompletionQuery query = new PrefixCompletionQuery(analyzer, new Term(\"suggest_field\", prefix));\n      TopSuggestDocsCollector collector = new TopSuggestDocsCollector(topN, dedup);\n      searcher.suggest(query, collector);\n      TopSuggestDocs actual = collector.get();\n      if (VERBOSE) {\n        System.out.println(\"  actual:\");\n        SuggestScoreDoc[] suggestScoreDocs = (SuggestScoreDoc[]) actual.scoreDocs;\n        for(int i=0;i<suggestScoreDocs.length;i++) {\n          System.out.println(\"    \" + i + \": \" + suggestScoreDocs[i]);\n        }\n      }\n\n      assertSuggestions(actual, expected.toArray(new Entry[expected.size()]));\n    }\n    \n    reader.close();\n    iw.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ba1db4d0b783c960c8176aef0d38ffccb14ec50a","date":1543422733,"type":3,"author":"Jim Ferenczi","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/document/TestSuggestField#testRandom().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/document/TestSuggestField#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n    int numDigits = TestUtil.nextInt(random(), 1, 6);\n    Set<String> keys = new HashSet<>();\n    int keyCount = TestUtil.nextInt(random(), 1, 20);\n    if (numDigits == 1) {\n      keyCount = Math.min(9, keyCount);\n    }\n    while (keys.size() < keyCount) {\n      keys.add(randomSimpleString(numDigits, 10));\n    }\n    List<String> keysList = new ArrayList<>(keys);\n\n    Analyzer analyzer = new MockAnalyzer(random());\n    IndexWriterConfig iwc = iwcWithSuggestField(analyzer, \"suggest_field\");\n    // we rely on docID order:\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n    int docCount = TestUtil.nextInt(random(), 1, 200);\n    Entry[] docs = new Entry[docCount];\n    for(int i=0;i<docCount;i++) {\n      int weight = random().nextInt(40);\n      String key = keysList.get(random().nextInt(keyCount));\n      //System.out.println(\"KEY: \" + key);\n      docs[i] = new Entry(key, null, weight, i);\n      Document doc = new Document();\n      doc.add(new SuggestField(\"suggest_field\", key, weight));\n      iw.addDocument(doc);\n      if (usually()) {\n        iw.commit();\n      }\n    }\n\n    DirectoryReader reader = iw.getReader();\n    SuggestIndexSearcher searcher = new SuggestIndexSearcher(reader);\n\n    int iters = atLeast(200);\n    for(int iter=0;iter<iters;iter++) {\n      String prefix = randomSimpleString(numDigits, 2);\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      // slow but hopefully correct suggester:\n      List<Entry> expected = new ArrayList<>();\n      for(Entry doc : docs) {\n        if (doc.output.startsWith(prefix)) {\n          expected.add(doc);\n        }\n      }\n      Collections.sort(expected,\n          (a, b) -> {\n            // sort by higher score:\n            int cmp = Float.compare(b.value, a.value);\n            if (cmp == 0) {\n              // tie break by completion key\n              cmp = Lookup.CHARSEQUENCE_COMPARATOR.compare(a.output, b.output);\n              if (cmp == 0) {\n                // prefer smaller doc id, in case of a tie\n                cmp = Integer.compare(a.id, b.id);\n              }\n            }\n            return cmp;\n          });\n\n      boolean dedup = random().nextBoolean();\n      if (dedup) {\n        List<Entry> deduped = new ArrayList<>();\n        Set<String> seen = new HashSet<>();\n        for(Entry entry : expected) {\n          if (seen.contains(entry.output) == false) {\n            seen.add(entry.output);\n            deduped.add(entry);\n          }\n        }\n        expected = deduped;\n      }\n\n      // TODO: re-enable this, except something is buggy about tie breaks at the topN threshold now:\n      //int topN = TestUtil.nextInt(random(), 1, docCount+10);\n      int topN = docCount;\n      \n      if (VERBOSE) {\n        if (dedup) {\n          System.out.println(\"  expected (dedup'd) topN=\" + topN + \":\");\n        } else {\n          System.out.println(\"  expected topN=\" + topN + \":\");\n        }\n        for(int i=0;i<expected.size();i++) {\n          if (i >= topN) {\n            System.out.println(\"    leftover: \" + i + \": \" + expected.get(i));\n          } else {\n            System.out.println(\"    \" + i + \": \" + expected.get(i));\n          }\n        }\n      }\n      expected = expected.subList(0, Math.min(topN, expected.size()));\n      \n      PrefixCompletionQuery query = new PrefixCompletionQuery(analyzer, new Term(\"suggest_field\", prefix));\n      TopSuggestDocsCollector collector = new TopSuggestDocsCollector(topN, dedup);\n      searcher.suggest(query, collector);\n      TopSuggestDocs actual = collector.get();\n      if (VERBOSE) {\n        System.out.println(\"  actual:\");\n        SuggestScoreDoc[] suggestScoreDocs = (SuggestScoreDoc[]) actual.scoreDocs;\n        for(int i=0;i<suggestScoreDocs.length;i++) {\n          System.out.println(\"    \" + i + \": \" + suggestScoreDocs[i]);\n        }\n      }\n\n      assertSuggestions(actual, expected.toArray(new Entry[expected.size()]));\n    }\n    \n    reader.close();\n    iw.close();\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n    int numDigits = TestUtil.nextInt(random(), 1, 6);\n    Set<String> keys = new HashSet<>();\n    int keyCount = TestUtil.nextInt(random(), 1, 20);\n    if (numDigits == 1) {\n      keyCount = Math.min(9, keyCount);\n    }\n    while (keys.size() < keyCount) {\n      keys.add(randomSimpleString(numDigits, 10));\n    }\n    List<String> keysList = new ArrayList<>(keys);\n\n    Analyzer analyzer = new MockAnalyzer(random());\n    IndexWriterConfig iwc = iwcWithSuggestField(analyzer, \"suggest_field\");\n    // we rely on docID order:\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n    int docCount = TestUtil.nextInt(random(), 1, 200);\n    Entry[] docs = new Entry[docCount];\n    for(int i=0;i<docCount;i++) {\n      int weight = random().nextInt(40);\n      String key = keysList.get(random().nextInt(keyCount));\n      //System.out.println(\"KEY: \" + key);\n      docs[i] = new Entry(key, null, weight, i);\n      Document doc = new Document();\n      doc.add(new SuggestField(\"suggest_field\", key, weight));\n      iw.addDocument(doc);\n      if (usually()) {\n        iw.commit();\n      }\n    }\n\n    DirectoryReader reader = iw.getReader();\n    SuggestIndexSearcher searcher = new SuggestIndexSearcher(reader);\n\n    int iters = atLeast(200);\n    for(int iter=0;iter<iters;iter++) {\n      String prefix = randomSimpleString(numDigits, 2);\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      // slow but hopefully correct suggester:\n      List<Entry> expected = new ArrayList<>();\n      for(Entry doc : docs) {\n        if (doc.output.startsWith(prefix)) {\n          expected.add(doc);\n        }\n      }\n      Collections.sort(expected,\n                       new Comparator<Entry>() {\n                         @Override\n                         public int compare(Entry a, Entry b) {\n                           // sort by higher score:\n                           int cmp = Float.compare(b.value, a.value);\n                           if (cmp == 0) {\n                             // tie break by smaller docID:\n                             cmp = Integer.compare(a.id, b.id);\n                           }\n                           return cmp;\n                         }\n                       });\n\n      boolean dedup = random().nextBoolean();\n      if (dedup) {\n        List<Entry> deduped = new ArrayList<>();\n        Set<String> seen = new HashSet<>();\n        for(Entry entry : expected) {\n          if (seen.contains(entry.output) == false) {\n            seen.add(entry.output);\n            deduped.add(entry);\n          }\n        }\n        expected = deduped;\n      }\n\n      // TODO: re-enable this, except something is buggy about tie breaks at the topN threshold now:\n      //int topN = TestUtil.nextInt(random(), 1, docCount+10);\n      int topN = docCount;\n      \n      if (VERBOSE) {\n        if (dedup) {\n          System.out.println(\"  expected (dedup'd) topN=\" + topN + \":\");\n        } else {\n          System.out.println(\"  expected topN=\" + topN + \":\");\n        }\n        for(int i=0;i<expected.size();i++) {\n          if (i >= topN) {\n            System.out.println(\"    leftover: \" + i + \": \" + expected.get(i));\n          } else {\n            System.out.println(\"    \" + i + \": \" + expected.get(i));\n          }\n        }\n      }\n      expected = expected.subList(0, Math.min(topN, expected.size()));\n      \n      PrefixCompletionQuery query = new PrefixCompletionQuery(analyzer, new Term(\"suggest_field\", prefix));\n      TopSuggestDocsCollector collector = new TopSuggestDocsCollector(topN, dedup);\n      searcher.suggest(query, collector);\n      TopSuggestDocs actual = collector.get();\n      if (VERBOSE) {\n        System.out.println(\"  actual:\");\n        SuggestScoreDoc[] suggestScoreDocs = (SuggestScoreDoc[]) actual.scoreDocs;\n        for(int i=0;i<suggestScoreDocs.length;i++) {\n          System.out.println(\"    \" + i + \": \" + suggestScoreDocs[i]);\n        }\n      }\n\n      assertSuggestions(actual, expected.toArray(new Entry[expected.size()]));\n    }\n    \n    reader.close();\n    iw.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"ba1db4d0b783c960c8176aef0d38ffccb14ec50a":["902a92b60648a8925bfd9bb53a78669cd2ea98fd"],"902a92b60648a8925bfd9bb53a78669cd2ea98fd":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["ba1db4d0b783c960c8176aef0d38ffccb14ec50a"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["902a92b60648a8925bfd9bb53a78669cd2ea98fd"],"ba1db4d0b783c960c8176aef0d38ffccb14ec50a":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"902a92b60648a8925bfd9bb53a78669cd2ea98fd":["ba1db4d0b783c960c8176aef0d38ffccb14ec50a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}