{"path":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsReader#BlockTermsReader(TermsIndexReaderBase,Directory,FieldInfos,String,PostingsReaderBase,int,Comparator[BytesRef],int,String).mjava","commits":[{"id":"b1add9ddc0005b07550d4350720aac22dc9886b3","date":1295549635,"type":1,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsReader#BlockTermsReader(TermsIndexReaderBase,Directory,FieldInfos,String,PostingsReaderBase,int,Comparator[BytesRef],int,String).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/PrefixCodedTermsReader#PrefixCodedTermsReader(TermsIndexReaderBase,Directory,FieldInfos,String,PostingsReaderBase,int,Comparator[BytesRef],int,String).mjava","sourceNew":"  public BlockTermsReader(TermsIndexReaderBase indexReader, Directory dir, FieldInfos fieldInfos, String segment, PostingsReaderBase postingsReader, int readBufferSize,\n                          Comparator<BytesRef> termComp, int termsCacheSize, String codecId)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n    termsCache = new DoubleBarrelLRUCache<FieldAndTerm,BlockTermState>(termsCacheSize);\n\n    this.termComp = termComp;\n    this.segment = segment;\n    in = dir.openInput(IndexFileNames.segmentFileName(segment, codecId, BlockTermsWriter.TERMS_EXTENSION),\n                       readBufferSize);\n\n    boolean success = false;\n    try {\n      readHeader(in);\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n\n      final int numFields = in.readVInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numTerms = in.readVLong();\n        assert numTerms >= 0;\n        final long termsStartPointer = in.readVLong();\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        final long sumTotalTermFreq = fieldInfo.omitTermFreqAndPositions ? -1 : in.readVLong();\n        assert !fields.containsKey(fieldInfo.name);\n        fields.put(fieldInfo.name, new FieldReader(fieldInfo, numTerms, termsStartPointer, sumTotalTermFreq));\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        in.close();\n      }\n    }\n\n    this.indexReader = indexReader;\n  }\n\n","sourceOld":"  public PrefixCodedTermsReader(TermsIndexReaderBase indexReader, Directory dir, FieldInfos fieldInfos, String segment, PostingsReaderBase postingsReader, int readBufferSize,\n                                 Comparator<BytesRef> termComp, int termsCacheSize, String codecId)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n    termsCache = new DoubleBarrelLRUCache<FieldAndTerm,PrefixCodedTermState>(termsCacheSize);\n\n    this.termComp = termComp;\n    \n    in = dir.openInput(IndexFileNames.segmentFileName(segment, codecId, PrefixCodedTermsWriter.TERMS_EXTENSION),\n                       readBufferSize);\n\n    boolean success = false;\n    try {\n      readHeader(in);\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n\n      final int numFields = in.readVInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numTerms = in.readVLong();\n        assert numTerms >= 0;\n        final long termsStartPointer = in.readVLong();\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        final long sumTotalTermFreq = fieldInfo.omitTermFreqAndPositions ? -1 : in.readVLong();\n        assert !fields.containsKey(fieldInfo.name);\n        fields.put(fieldInfo.name, new FieldReader(fieldInfo, numTerms, termsStartPointer, sumTotalTermFreq));\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        in.close();\n      }\n    }\n\n    this.indexReader = indexReader;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fd1bfe3cedf815c14939d170d53031c88eb5c444","date":1295896578,"type":0,"author":"Michael Busch","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsReader#BlockTermsReader(TermsIndexReaderBase,Directory,FieldInfos,String,PostingsReaderBase,int,Comparator[BytesRef],int,String).mjava","pathOld":"/dev/null","sourceNew":"  public BlockTermsReader(TermsIndexReaderBase indexReader, Directory dir, FieldInfos fieldInfos, String segment, PostingsReaderBase postingsReader, int readBufferSize,\n                          Comparator<BytesRef> termComp, int termsCacheSize, String codecId)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n    termsCache = new DoubleBarrelLRUCache<FieldAndTerm,BlockTermState>(termsCacheSize);\n\n    this.termComp = termComp;\n    this.segment = segment;\n    in = dir.openInput(IndexFileNames.segmentFileName(segment, codecId, BlockTermsWriter.TERMS_EXTENSION),\n                       readBufferSize);\n\n    boolean success = false;\n    try {\n      readHeader(in);\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n\n      final int numFields = in.readVInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numTerms = in.readVLong();\n        assert numTerms >= 0;\n        final long termsStartPointer = in.readVLong();\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        final long sumTotalTermFreq = fieldInfo.omitTermFreqAndPositions ? -1 : in.readVLong();\n        assert !fields.containsKey(fieldInfo.name);\n        fields.put(fieldInfo.name, new FieldReader(fieldInfo, numTerms, termsStartPointer, sumTotalTermFreq));\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        in.close();\n      }\n    }\n\n    this.indexReader = indexReader;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"69a6d2d525aeab53c867ed26934185e5bb627d0e","date":1296516902,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsReader#BlockTermsReader(TermsIndexReaderBase,Directory,FieldInfos,String,PostingsReaderBase,int,Comparator[BytesRef],int,String).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsReader#BlockTermsReader(TermsIndexReaderBase,Directory,FieldInfos,String,PostingsReaderBase,int,Comparator[BytesRef],int,String).mjava","sourceNew":"  public BlockTermsReader(TermsIndexReaderBase indexReader, Directory dir, FieldInfos fieldInfos, String segment, PostingsReaderBase postingsReader, int readBufferSize,\n                          Comparator<BytesRef> termComp, int termsCacheSize, String codecId)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n    termsCache = new DoubleBarrelLRUCache<FieldAndTerm,BlockTermState>(termsCacheSize);\n\n    this.termComp = termComp;\n    //this.segment = segment;\n    in = dir.openInput(IndexFileNames.segmentFileName(segment, codecId, BlockTermsWriter.TERMS_EXTENSION),\n                       readBufferSize);\n\n    boolean success = false;\n    try {\n      readHeader(in);\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n\n      final int numFields = in.readVInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numTerms = in.readVLong();\n        assert numTerms >= 0;\n        final long termsStartPointer = in.readVLong();\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        final long sumTotalTermFreq = fieldInfo.omitTermFreqAndPositions ? -1 : in.readVLong();\n        assert !fields.containsKey(fieldInfo.name);\n        fields.put(fieldInfo.name, new FieldReader(fieldInfo, numTerms, termsStartPointer, sumTotalTermFreq));\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        in.close();\n      }\n    }\n\n    this.indexReader = indexReader;\n  }\n\n","sourceOld":"  public BlockTermsReader(TermsIndexReaderBase indexReader, Directory dir, FieldInfos fieldInfos, String segment, PostingsReaderBase postingsReader, int readBufferSize,\n                          Comparator<BytesRef> termComp, int termsCacheSize, String codecId)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n    termsCache = new DoubleBarrelLRUCache<FieldAndTerm,BlockTermState>(termsCacheSize);\n\n    this.termComp = termComp;\n    this.segment = segment;\n    in = dir.openInput(IndexFileNames.segmentFileName(segment, codecId, BlockTermsWriter.TERMS_EXTENSION),\n                       readBufferSize);\n\n    boolean success = false;\n    try {\n      readHeader(in);\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n\n      final int numFields = in.readVInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numTerms = in.readVLong();\n        assert numTerms >= 0;\n        final long termsStartPointer = in.readVLong();\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        final long sumTotalTermFreq = fieldInfo.omitTermFreqAndPositions ? -1 : in.readVLong();\n        assert !fields.containsKey(fieldInfo.name);\n        fields.put(fieldInfo.name, new FieldReader(fieldInfo, numTerms, termsStartPointer, sumTotalTermFreq));\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        in.close();\n      }\n    }\n\n    this.indexReader = indexReader;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"29ef99d61cda9641b6250bf9567329a6e65f901d","date":1297244127,"type":0,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsReader#BlockTermsReader(TermsIndexReaderBase,Directory,FieldInfos,String,PostingsReaderBase,int,Comparator[BytesRef],int,String).mjava","pathOld":"/dev/null","sourceNew":"  public BlockTermsReader(TermsIndexReaderBase indexReader, Directory dir, FieldInfos fieldInfos, String segment, PostingsReaderBase postingsReader, int readBufferSize,\n                          Comparator<BytesRef> termComp, int termsCacheSize, String codecId)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n    termsCache = new DoubleBarrelLRUCache<FieldAndTerm,BlockTermState>(termsCacheSize);\n\n    this.termComp = termComp;\n    //this.segment = segment;\n    in = dir.openInput(IndexFileNames.segmentFileName(segment, codecId, BlockTermsWriter.TERMS_EXTENSION),\n                       readBufferSize);\n\n    boolean success = false;\n    try {\n      readHeader(in);\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n\n      final int numFields = in.readVInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numTerms = in.readVLong();\n        assert numTerms >= 0;\n        final long termsStartPointer = in.readVLong();\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        final long sumTotalTermFreq = fieldInfo.omitTermFreqAndPositions ? -1 : in.readVLong();\n        assert !fields.containsKey(fieldInfo.name);\n        fields.put(fieldInfo.name, new FieldReader(fieldInfo, numTerms, termsStartPointer, sumTotalTermFreq));\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        in.close();\n      }\n    }\n\n    this.indexReader = indexReader;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4fd64b6aa64934b0e35d9ec3e6c5a5c60ffc1762","date":1297938719,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsReader#BlockTermsReader(TermsIndexReaderBase,Directory,FieldInfos,String,PostingsReaderBase,int,int,String).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsReader#BlockTermsReader(TermsIndexReaderBase,Directory,FieldInfos,String,PostingsReaderBase,int,Comparator[BytesRef],int,String).mjava","sourceNew":"  public BlockTermsReader(TermsIndexReaderBase indexReader, Directory dir, FieldInfos fieldInfos, String segment, PostingsReaderBase postingsReader, int readBufferSize,\n                          int termsCacheSize, String codecId)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n    termsCache = new DoubleBarrelLRUCache<FieldAndTerm,BlockTermState>(termsCacheSize);\n\n    //this.segment = segment;\n    in = dir.openInput(IndexFileNames.segmentFileName(segment, codecId, BlockTermsWriter.TERMS_EXTENSION),\n                       readBufferSize);\n\n    boolean success = false;\n    try {\n      readHeader(in);\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n\n      final int numFields = in.readVInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numTerms = in.readVLong();\n        assert numTerms >= 0;\n        final long termsStartPointer = in.readVLong();\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        final long sumTotalTermFreq = fieldInfo.omitTermFreqAndPositions ? -1 : in.readVLong();\n        assert !fields.containsKey(fieldInfo.name);\n        fields.put(fieldInfo.name, new FieldReader(fieldInfo, numTerms, termsStartPointer, sumTotalTermFreq));\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        in.close();\n      }\n    }\n\n    this.indexReader = indexReader;\n  }\n\n","sourceOld":"  public BlockTermsReader(TermsIndexReaderBase indexReader, Directory dir, FieldInfos fieldInfos, String segment, PostingsReaderBase postingsReader, int readBufferSize,\n                          Comparator<BytesRef> termComp, int termsCacheSize, String codecId)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n    termsCache = new DoubleBarrelLRUCache<FieldAndTerm,BlockTermState>(termsCacheSize);\n\n    this.termComp = termComp;\n    //this.segment = segment;\n    in = dir.openInput(IndexFileNames.segmentFileName(segment, codecId, BlockTermsWriter.TERMS_EXTENSION),\n                       readBufferSize);\n\n    boolean success = false;\n    try {\n      readHeader(in);\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n\n      final int numFields = in.readVInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numTerms = in.readVLong();\n        assert numTerms >= 0;\n        final long termsStartPointer = in.readVLong();\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        final long sumTotalTermFreq = fieldInfo.omitTermFreqAndPositions ? -1 : in.readVLong();\n        assert !fields.containsKey(fieldInfo.name);\n        fields.put(fieldInfo.name, new FieldReader(fieldInfo, numTerms, termsStartPointer, sumTotalTermFreq));\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        in.close();\n      }\n    }\n\n    this.indexReader = indexReader;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f1bdbf92da222965b46c0a942c3857ba56e5c638","date":1298297608,"type":5,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsReader#BlockTermsReader(TermsIndexReaderBase,Directory,FieldInfos,String,PostingsReaderBase,int,int,String).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsReader#BlockTermsReader(TermsIndexReaderBase,Directory,FieldInfos,String,PostingsReaderBase,int,Comparator[BytesRef],int,String).mjava","sourceNew":"  public BlockTermsReader(TermsIndexReaderBase indexReader, Directory dir, FieldInfos fieldInfos, String segment, PostingsReaderBase postingsReader, int readBufferSize,\n                          int termsCacheSize, String codecId)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n    termsCache = new DoubleBarrelLRUCache<FieldAndTerm,BlockTermState>(termsCacheSize);\n\n    //this.segment = segment;\n    in = dir.openInput(IndexFileNames.segmentFileName(segment, codecId, BlockTermsWriter.TERMS_EXTENSION),\n                       readBufferSize);\n\n    boolean success = false;\n    try {\n      readHeader(in);\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n\n      final int numFields = in.readVInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numTerms = in.readVLong();\n        assert numTerms >= 0;\n        final long termsStartPointer = in.readVLong();\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        final long sumTotalTermFreq = fieldInfo.omitTermFreqAndPositions ? -1 : in.readVLong();\n        assert !fields.containsKey(fieldInfo.name);\n        fields.put(fieldInfo.name, new FieldReader(fieldInfo, numTerms, termsStartPointer, sumTotalTermFreq));\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        in.close();\n      }\n    }\n\n    this.indexReader = indexReader;\n  }\n\n","sourceOld":"  public BlockTermsReader(TermsIndexReaderBase indexReader, Directory dir, FieldInfos fieldInfos, String segment, PostingsReaderBase postingsReader, int readBufferSize,\n                          Comparator<BytesRef> termComp, int termsCacheSize, String codecId)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n    termsCache = new DoubleBarrelLRUCache<FieldAndTerm,BlockTermState>(termsCacheSize);\n\n    this.termComp = termComp;\n    //this.segment = segment;\n    in = dir.openInput(IndexFileNames.segmentFileName(segment, codecId, BlockTermsWriter.TERMS_EXTENSION),\n                       readBufferSize);\n\n    boolean success = false;\n    try {\n      readHeader(in);\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n\n      final int numFields = in.readVInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numTerms = in.readVLong();\n        assert numTerms >= 0;\n        final long termsStartPointer = in.readVLong();\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        final long sumTotalTermFreq = fieldInfo.omitTermFreqAndPositions ? -1 : in.readVLong();\n        assert !fields.containsKey(fieldInfo.name);\n        fields.put(fieldInfo.name, new FieldReader(fieldInfo, numTerms, termsStartPointer, sumTotalTermFreq));\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        in.close();\n      }\n    }\n\n    this.indexReader = indexReader;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bde51b089eb7f86171eb3406e38a274743f9b7ac","date":1298336439,"type":5,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsReader#BlockTermsReader(TermsIndexReaderBase,Directory,FieldInfos,String,PostingsReaderBase,int,int,String).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsReader#BlockTermsReader(TermsIndexReaderBase,Directory,FieldInfos,String,PostingsReaderBase,int,Comparator[BytesRef],int,String).mjava","sourceNew":"  public BlockTermsReader(TermsIndexReaderBase indexReader, Directory dir, FieldInfos fieldInfos, String segment, PostingsReaderBase postingsReader, int readBufferSize,\n                          int termsCacheSize, String codecId)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n    termsCache = new DoubleBarrelLRUCache<FieldAndTerm,BlockTermState>(termsCacheSize);\n\n    //this.segment = segment;\n    in = dir.openInput(IndexFileNames.segmentFileName(segment, codecId, BlockTermsWriter.TERMS_EXTENSION),\n                       readBufferSize);\n\n    boolean success = false;\n    try {\n      readHeader(in);\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n\n      final int numFields = in.readVInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numTerms = in.readVLong();\n        assert numTerms >= 0;\n        final long termsStartPointer = in.readVLong();\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        final long sumTotalTermFreq = fieldInfo.omitTermFreqAndPositions ? -1 : in.readVLong();\n        assert !fields.containsKey(fieldInfo.name);\n        fields.put(fieldInfo.name, new FieldReader(fieldInfo, numTerms, termsStartPointer, sumTotalTermFreq));\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        in.close();\n      }\n    }\n\n    this.indexReader = indexReader;\n  }\n\n","sourceOld":"  public BlockTermsReader(TermsIndexReaderBase indexReader, Directory dir, FieldInfos fieldInfos, String segment, PostingsReaderBase postingsReader, int readBufferSize,\n                          Comparator<BytesRef> termComp, int termsCacheSize, String codecId)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n    termsCache = new DoubleBarrelLRUCache<FieldAndTerm,BlockTermState>(termsCacheSize);\n\n    this.termComp = termComp;\n    this.segment = segment;\n    in = dir.openInput(IndexFileNames.segmentFileName(segment, codecId, BlockTermsWriter.TERMS_EXTENSION),\n                       readBufferSize);\n\n    boolean success = false;\n    try {\n      readHeader(in);\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n\n      final int numFields = in.readVInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numTerms = in.readVLong();\n        assert numTerms >= 0;\n        final long termsStartPointer = in.readVLong();\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        final long sumTotalTermFreq = fieldInfo.omitTermFreqAndPositions ? -1 : in.readVLong();\n        assert !fields.containsKey(fieldInfo.name);\n        fields.put(fieldInfo.name, new FieldReader(fieldInfo, numTerms, termsStartPointer, sumTotalTermFreq));\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        in.close();\n      }\n    }\n\n    this.indexReader = indexReader;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"fd1bfe3cedf815c14939d170d53031c88eb5c444":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"f1bdbf92da222965b46c0a942c3857ba56e5c638":["29ef99d61cda9641b6250bf9567329a6e65f901d","4fd64b6aa64934b0e35d9ec3e6c5a5c60ffc1762"],"4fd64b6aa64934b0e35d9ec3e6c5a5c60ffc1762":["69a6d2d525aeab53c867ed26934185e5bb627d0e"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","69a6d2d525aeab53c867ed26934185e5bb627d0e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"69a6d2d525aeab53c867ed26934185e5bb627d0e":["b1add9ddc0005b07550d4350720aac22dc9886b3"],"b1add9ddc0005b07550d4350720aac22dc9886b3":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["fd1bfe3cedf815c14939d170d53031c88eb5c444","4fd64b6aa64934b0e35d9ec3e6c5a5c60ffc1762"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["4fd64b6aa64934b0e35d9ec3e6c5a5c60ffc1762"]},"commit2Childs":{"fd1bfe3cedf815c14939d170d53031c88eb5c444":["bde51b089eb7f86171eb3406e38a274743f9b7ac"],"f1bdbf92da222965b46c0a942c3857ba56e5c638":[],"29ef99d61cda9641b6250bf9567329a6e65f901d":["f1bdbf92da222965b46c0a942c3857ba56e5c638"],"4fd64b6aa64934b0e35d9ec3e6c5a5c60ffc1762":["f1bdbf92da222965b46c0a942c3857ba56e5c638","bde51b089eb7f86171eb3406e38a274743f9b7ac","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["fd1bfe3cedf815c14939d170d53031c88eb5c444","29ef99d61cda9641b6250bf9567329a6e65f901d","b1add9ddc0005b07550d4350720aac22dc9886b3"],"69a6d2d525aeab53c867ed26934185e5bb627d0e":["4fd64b6aa64934b0e35d9ec3e6c5a5c60ffc1762","29ef99d61cda9641b6250bf9567329a6e65f901d"],"b1add9ddc0005b07550d4350720aac22dc9886b3":["69a6d2d525aeab53c867ed26934185e5bb627d0e"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["f1bdbf92da222965b46c0a942c3857ba56e5c638","bde51b089eb7f86171eb3406e38a274743f9b7ac","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}