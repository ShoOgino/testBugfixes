{"path":"lucene/analysis/common/src/test/org/apache/lucene/analysis/synonym/TestSynonymMapFilter#testRandom().mjava","commits":[{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/synonym/TestSynonymMapFilter#testRandom().mjava","pathOld":"modules/analysis/common/src/test/org/apache/lucene/analysis/synonym/TestSynonymMapFilter#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n    \n    final int alphabetSize = _TestUtil.nextInt(random(), 2, 7);\n\n    final int docLen = atLeast(3000);\n    //final int docLen = 50;\n\n    final String document = getRandomString('a', alphabetSize, docLen);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: doc=\" + document);\n    }\n\n    final int numSyn = atLeast(5);\n    //final int numSyn = 2;\n\n    final Map<String,OneSyn> synMap = new HashMap<String,OneSyn>();\n    final List<OneSyn> syns = new ArrayList<OneSyn>();\n    final boolean dedup = random().nextBoolean();\n    if (VERBOSE) {\n      System.out.println(\"  dedup=\" + dedup);\n    }\n    b = new SynonymMap.Builder(dedup);\n    for(int synIDX=0;synIDX<numSyn;synIDX++) {\n      final String synIn = getRandomString('a', alphabetSize, _TestUtil.nextInt(random(), 1, 5)).trim();\n      OneSyn s = synMap.get(synIn);\n      if (s == null) {\n        s = new OneSyn();\n        s.in = synIn;\n        syns.add(s);\n        s.out = new ArrayList<String>();\n        synMap.put(synIn, s);\n        s.keepOrig = random().nextBoolean();\n      }\n      final String synOut = getRandomString('0', 10, _TestUtil.nextInt(random(), 1, 5)).trim();\n      s.out.add(synOut);\n      add(synIn, synOut, s.keepOrig);\n      if (VERBOSE) {\n        System.out.println(\"  syns[\" + synIDX + \"] = \" + s.in + \" -> \" + s.out + \" keepOrig=\" + s.keepOrig);\n      }\n    }\n\n    tokensIn = new MockTokenizer(new StringReader(\"a\"),\n                                 MockTokenizer.WHITESPACE,\n                                 true);\n    tokensIn.reset();\n    assertTrue(tokensIn.incrementToken());\n    assertFalse(tokensIn.incrementToken());\n    tokensIn.end();\n    tokensIn.close();\n\n    tokensOut = new SynonymFilter(tokensIn,\n                                     b.build(),\n                                     true);\n    termAtt = tokensOut.addAttribute(CharTermAttribute.class);\n    posIncrAtt = tokensOut.addAttribute(PositionIncrementAttribute.class);\n    posLenAtt = tokensOut.addAttribute(PositionLengthAttribute.class);\n    offsetAtt = tokensOut.addAttribute(OffsetAttribute.class);\n\n    if (dedup) {\n      pruneDups(syns);\n    }\n\n    final String expected = slowSynMatcher(document, syns, 5);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: expected=\" + expected);\n    }\n\n    verify(document, expected);\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n    \n    final int alphabetSize = _TestUtil.nextInt(random(), 2, 7);\n\n    final int docLen = atLeast(3000);\n    //final int docLen = 50;\n\n    final String document = getRandomString('a', alphabetSize, docLen);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: doc=\" + document);\n    }\n\n    final int numSyn = atLeast(5);\n    //final int numSyn = 2;\n\n    final Map<String,OneSyn> synMap = new HashMap<String,OneSyn>();\n    final List<OneSyn> syns = new ArrayList<OneSyn>();\n    final boolean dedup = random().nextBoolean();\n    if (VERBOSE) {\n      System.out.println(\"  dedup=\" + dedup);\n    }\n    b = new SynonymMap.Builder(dedup);\n    for(int synIDX=0;synIDX<numSyn;synIDX++) {\n      final String synIn = getRandomString('a', alphabetSize, _TestUtil.nextInt(random(), 1, 5)).trim();\n      OneSyn s = synMap.get(synIn);\n      if (s == null) {\n        s = new OneSyn();\n        s.in = synIn;\n        syns.add(s);\n        s.out = new ArrayList<String>();\n        synMap.put(synIn, s);\n        s.keepOrig = random().nextBoolean();\n      }\n      final String synOut = getRandomString('0', 10, _TestUtil.nextInt(random(), 1, 5)).trim();\n      s.out.add(synOut);\n      add(synIn, synOut, s.keepOrig);\n      if (VERBOSE) {\n        System.out.println(\"  syns[\" + synIDX + \"] = \" + s.in + \" -> \" + s.out + \" keepOrig=\" + s.keepOrig);\n      }\n    }\n\n    tokensIn = new MockTokenizer(new StringReader(\"a\"),\n                                 MockTokenizer.WHITESPACE,\n                                 true);\n    tokensIn.reset();\n    assertTrue(tokensIn.incrementToken());\n    assertFalse(tokensIn.incrementToken());\n    tokensIn.end();\n    tokensIn.close();\n\n    tokensOut = new SynonymFilter(tokensIn,\n                                     b.build(),\n                                     true);\n    termAtt = tokensOut.addAttribute(CharTermAttribute.class);\n    posIncrAtt = tokensOut.addAttribute(PositionIncrementAttribute.class);\n    posLenAtt = tokensOut.addAttribute(PositionLengthAttribute.class);\n    offsetAtt = tokensOut.addAttribute(OffsetAttribute.class);\n\n    if (dedup) {\n      pruneDups(syns);\n    }\n\n    final String expected = slowSynMatcher(document, syns, 5);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: expected=\" + expected);\n    }\n\n    verify(document, expected);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae889fd5c8a69f6b5d130d3c895bfa5b04d07338","date":1389274049,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/synonym/TestSynonymMapFilter#testRandom().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/synonym/TestSynonymMapFilter#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n    \n    final int alphabetSize = _TestUtil.nextInt(random(), 2, 7);\n\n    final int docLen = atLeast(3000);\n    //final int docLen = 50;\n\n    final String document = getRandomString('a', alphabetSize, docLen);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: doc=\" + document);\n    }\n\n    final int numSyn = atLeast(5);\n    //final int numSyn = 2;\n\n    final Map<String,OneSyn> synMap = new HashMap<String,OneSyn>();\n    final List<OneSyn> syns = new ArrayList<OneSyn>();\n    final boolean dedup = random().nextBoolean();\n    if (VERBOSE) {\n      System.out.println(\"  dedup=\" + dedup);\n    }\n    b = new SynonymMap.Builder(dedup);\n    for(int synIDX=0;synIDX<numSyn;synIDX++) {\n      final String synIn = getRandomString('a', alphabetSize, _TestUtil.nextInt(random(), 1, 5)).trim();\n      OneSyn s = synMap.get(synIn);\n      if (s == null) {\n        s = new OneSyn();\n        s.in = synIn;\n        syns.add(s);\n        s.out = new ArrayList<String>();\n        synMap.put(synIn, s);\n        s.keepOrig = random().nextBoolean();\n      }\n      final String synOut = getRandomString('0', 10, _TestUtil.nextInt(random(), 1, 5)).trim();\n      s.out.add(synOut);\n      add(synIn, synOut, s.keepOrig);\n      if (VERBOSE) {\n        System.out.println(\"  syns[\" + synIDX + \"] = \" + s.in + \" -> \" + s.out + \" keepOrig=\" + s.keepOrig);\n      }\n    }\n\n    tokensIn = new MockTokenizer(MockTokenizer.WHITESPACE,\n                                 true);\n    tokensIn.setReader(new StringReader(\"a\"));\n    tokensIn.reset();\n    assertTrue(tokensIn.incrementToken());\n    assertFalse(tokensIn.incrementToken());\n    tokensIn.end();\n    tokensIn.close();\n\n    tokensOut = new SynonymFilter(tokensIn,\n                                     b.build(),\n                                     true);\n    termAtt = tokensOut.addAttribute(CharTermAttribute.class);\n    posIncrAtt = tokensOut.addAttribute(PositionIncrementAttribute.class);\n    posLenAtt = tokensOut.addAttribute(PositionLengthAttribute.class);\n    offsetAtt = tokensOut.addAttribute(OffsetAttribute.class);\n\n    if (dedup) {\n      pruneDups(syns);\n    }\n\n    final String expected = slowSynMatcher(document, syns, 5);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: expected=\" + expected);\n    }\n\n    verify(document, expected);\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n    \n    final int alphabetSize = _TestUtil.nextInt(random(), 2, 7);\n\n    final int docLen = atLeast(3000);\n    //final int docLen = 50;\n\n    final String document = getRandomString('a', alphabetSize, docLen);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: doc=\" + document);\n    }\n\n    final int numSyn = atLeast(5);\n    //final int numSyn = 2;\n\n    final Map<String,OneSyn> synMap = new HashMap<String,OneSyn>();\n    final List<OneSyn> syns = new ArrayList<OneSyn>();\n    final boolean dedup = random().nextBoolean();\n    if (VERBOSE) {\n      System.out.println(\"  dedup=\" + dedup);\n    }\n    b = new SynonymMap.Builder(dedup);\n    for(int synIDX=0;synIDX<numSyn;synIDX++) {\n      final String synIn = getRandomString('a', alphabetSize, _TestUtil.nextInt(random(), 1, 5)).trim();\n      OneSyn s = synMap.get(synIn);\n      if (s == null) {\n        s = new OneSyn();\n        s.in = synIn;\n        syns.add(s);\n        s.out = new ArrayList<String>();\n        synMap.put(synIn, s);\n        s.keepOrig = random().nextBoolean();\n      }\n      final String synOut = getRandomString('0', 10, _TestUtil.nextInt(random(), 1, 5)).trim();\n      s.out.add(synOut);\n      add(synIn, synOut, s.keepOrig);\n      if (VERBOSE) {\n        System.out.println(\"  syns[\" + synIDX + \"] = \" + s.in + \" -> \" + s.out + \" keepOrig=\" + s.keepOrig);\n      }\n    }\n\n    tokensIn = new MockTokenizer(new StringReader(\"a\"),\n                                 MockTokenizer.WHITESPACE,\n                                 true);\n    tokensIn.reset();\n    assertTrue(tokensIn.incrementToken());\n    assertFalse(tokensIn.incrementToken());\n    tokensIn.end();\n    tokensIn.close();\n\n    tokensOut = new SynonymFilter(tokensIn,\n                                     b.build(),\n                                     true);\n    termAtt = tokensOut.addAttribute(CharTermAttribute.class);\n    posIncrAtt = tokensOut.addAttribute(PositionIncrementAttribute.class);\n    posLenAtt = tokensOut.addAttribute(PositionLengthAttribute.class);\n    offsetAtt = tokensOut.addAttribute(OffsetAttribute.class);\n\n    if (dedup) {\n      pruneDups(syns);\n    }\n\n    final String expected = slowSynMatcher(document, syns, 5);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: expected=\" + expected);\n    }\n\n    verify(document, expected);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6613659748fe4411a7dcf85266e55db1f95f7315","date":1392773913,"type":3,"author":"Benson Margulies","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/synonym/TestSynonymMapFilter#testRandom().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/synonym/TestSynonymMapFilter#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n    \n    final int alphabetSize = TestUtil.nextInt(random(), 2, 7);\n\n    final int docLen = atLeast(3000);\n    //final int docLen = 50;\n\n    final String document = getRandomString('a', alphabetSize, docLen);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: doc=\" + document);\n    }\n\n    final int numSyn = atLeast(5);\n    //final int numSyn = 2;\n\n    final Map<String,OneSyn> synMap = new HashMap<String,OneSyn>();\n    final List<OneSyn> syns = new ArrayList<OneSyn>();\n    final boolean dedup = random().nextBoolean();\n    if (VERBOSE) {\n      System.out.println(\"  dedup=\" + dedup);\n    }\n    b = new SynonymMap.Builder(dedup);\n    for(int synIDX=0;synIDX<numSyn;synIDX++) {\n      final String synIn = getRandomString('a', alphabetSize, TestUtil.nextInt(random(), 1, 5)).trim();\n      OneSyn s = synMap.get(synIn);\n      if (s == null) {\n        s = new OneSyn();\n        s.in = synIn;\n        syns.add(s);\n        s.out = new ArrayList<String>();\n        synMap.put(synIn, s);\n        s.keepOrig = random().nextBoolean();\n      }\n      final String synOut = getRandomString('0', 10, TestUtil.nextInt(random(), 1, 5)).trim();\n      s.out.add(synOut);\n      add(synIn, synOut, s.keepOrig);\n      if (VERBOSE) {\n        System.out.println(\"  syns[\" + synIDX + \"] = \" + s.in + \" -> \" + s.out + \" keepOrig=\" + s.keepOrig);\n      }\n    }\n\n    tokensIn = new MockTokenizer(MockTokenizer.WHITESPACE,\n                                 true);\n    tokensIn.setReader(new StringReader(\"a\"));\n    tokensIn.reset();\n    assertTrue(tokensIn.incrementToken());\n    assertFalse(tokensIn.incrementToken());\n    tokensIn.end();\n    tokensIn.close();\n\n    tokensOut = new SynonymFilter(tokensIn,\n                                     b.build(),\n                                     true);\n    termAtt = tokensOut.addAttribute(CharTermAttribute.class);\n    posIncrAtt = tokensOut.addAttribute(PositionIncrementAttribute.class);\n    posLenAtt = tokensOut.addAttribute(PositionLengthAttribute.class);\n    offsetAtt = tokensOut.addAttribute(OffsetAttribute.class);\n\n    if (dedup) {\n      pruneDups(syns);\n    }\n\n    final String expected = slowSynMatcher(document, syns, 5);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: expected=\" + expected);\n    }\n\n    verify(document, expected);\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n    \n    final int alphabetSize = _TestUtil.nextInt(random(), 2, 7);\n\n    final int docLen = atLeast(3000);\n    //final int docLen = 50;\n\n    final String document = getRandomString('a', alphabetSize, docLen);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: doc=\" + document);\n    }\n\n    final int numSyn = atLeast(5);\n    //final int numSyn = 2;\n\n    final Map<String,OneSyn> synMap = new HashMap<String,OneSyn>();\n    final List<OneSyn> syns = new ArrayList<OneSyn>();\n    final boolean dedup = random().nextBoolean();\n    if (VERBOSE) {\n      System.out.println(\"  dedup=\" + dedup);\n    }\n    b = new SynonymMap.Builder(dedup);\n    for(int synIDX=0;synIDX<numSyn;synIDX++) {\n      final String synIn = getRandomString('a', alphabetSize, _TestUtil.nextInt(random(), 1, 5)).trim();\n      OneSyn s = synMap.get(synIn);\n      if (s == null) {\n        s = new OneSyn();\n        s.in = synIn;\n        syns.add(s);\n        s.out = new ArrayList<String>();\n        synMap.put(synIn, s);\n        s.keepOrig = random().nextBoolean();\n      }\n      final String synOut = getRandomString('0', 10, _TestUtil.nextInt(random(), 1, 5)).trim();\n      s.out.add(synOut);\n      add(synIn, synOut, s.keepOrig);\n      if (VERBOSE) {\n        System.out.println(\"  syns[\" + synIDX + \"] = \" + s.in + \" -> \" + s.out + \" keepOrig=\" + s.keepOrig);\n      }\n    }\n\n    tokensIn = new MockTokenizer(MockTokenizer.WHITESPACE,\n                                 true);\n    tokensIn.setReader(new StringReader(\"a\"));\n    tokensIn.reset();\n    assertTrue(tokensIn.incrementToken());\n    assertFalse(tokensIn.incrementToken());\n    tokensIn.end();\n    tokensIn.close();\n\n    tokensOut = new SynonymFilter(tokensIn,\n                                     b.build(),\n                                     true);\n    termAtt = tokensOut.addAttribute(CharTermAttribute.class);\n    posIncrAtt = tokensOut.addAttribute(PositionIncrementAttribute.class);\n    posLenAtt = tokensOut.addAttribute(PositionLengthAttribute.class);\n    offsetAtt = tokensOut.addAttribute(OffsetAttribute.class);\n\n    if (dedup) {\n      pruneDups(syns);\n    }\n\n    final String expected = slowSynMatcher(document, syns, 5);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: expected=\" + expected);\n    }\n\n    verify(document, expected);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/synonym/TestSynonymMapFilter#testRandom().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/synonym/TestSynonymMapFilter#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n    \n    final int alphabetSize = TestUtil.nextInt(random(), 2, 7);\n\n    final int docLen = atLeast(3000);\n    //final int docLen = 50;\n\n    final String document = getRandomString('a', alphabetSize, docLen);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: doc=\" + document);\n    }\n\n    final int numSyn = atLeast(5);\n    //final int numSyn = 2;\n\n    final Map<String,OneSyn> synMap = new HashMap<>();\n    final List<OneSyn> syns = new ArrayList<>();\n    final boolean dedup = random().nextBoolean();\n    if (VERBOSE) {\n      System.out.println(\"  dedup=\" + dedup);\n    }\n    b = new SynonymMap.Builder(dedup);\n    for(int synIDX=0;synIDX<numSyn;synIDX++) {\n      final String synIn = getRandomString('a', alphabetSize, TestUtil.nextInt(random(), 1, 5)).trim();\n      OneSyn s = synMap.get(synIn);\n      if (s == null) {\n        s = new OneSyn();\n        s.in = synIn;\n        syns.add(s);\n        s.out = new ArrayList<>();\n        synMap.put(synIn, s);\n        s.keepOrig = random().nextBoolean();\n      }\n      final String synOut = getRandomString('0', 10, TestUtil.nextInt(random(), 1, 5)).trim();\n      s.out.add(synOut);\n      add(synIn, synOut, s.keepOrig);\n      if (VERBOSE) {\n        System.out.println(\"  syns[\" + synIDX + \"] = \" + s.in + \" -> \" + s.out + \" keepOrig=\" + s.keepOrig);\n      }\n    }\n\n    tokensIn = new MockTokenizer(MockTokenizer.WHITESPACE,\n                                 true);\n    tokensIn.setReader(new StringReader(\"a\"));\n    tokensIn.reset();\n    assertTrue(tokensIn.incrementToken());\n    assertFalse(tokensIn.incrementToken());\n    tokensIn.end();\n    tokensIn.close();\n\n    tokensOut = new SynonymFilter(tokensIn,\n                                     b.build(),\n                                     true);\n    termAtt = tokensOut.addAttribute(CharTermAttribute.class);\n    posIncrAtt = tokensOut.addAttribute(PositionIncrementAttribute.class);\n    posLenAtt = tokensOut.addAttribute(PositionLengthAttribute.class);\n    offsetAtt = tokensOut.addAttribute(OffsetAttribute.class);\n\n    if (dedup) {\n      pruneDups(syns);\n    }\n\n    final String expected = slowSynMatcher(document, syns, 5);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: expected=\" + expected);\n    }\n\n    verify(document, expected);\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n    \n    final int alphabetSize = TestUtil.nextInt(random(), 2, 7);\n\n    final int docLen = atLeast(3000);\n    //final int docLen = 50;\n\n    final String document = getRandomString('a', alphabetSize, docLen);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: doc=\" + document);\n    }\n\n    final int numSyn = atLeast(5);\n    //final int numSyn = 2;\n\n    final Map<String,OneSyn> synMap = new HashMap<String,OneSyn>();\n    final List<OneSyn> syns = new ArrayList<OneSyn>();\n    final boolean dedup = random().nextBoolean();\n    if (VERBOSE) {\n      System.out.println(\"  dedup=\" + dedup);\n    }\n    b = new SynonymMap.Builder(dedup);\n    for(int synIDX=0;synIDX<numSyn;synIDX++) {\n      final String synIn = getRandomString('a', alphabetSize, TestUtil.nextInt(random(), 1, 5)).trim();\n      OneSyn s = synMap.get(synIn);\n      if (s == null) {\n        s = new OneSyn();\n        s.in = synIn;\n        syns.add(s);\n        s.out = new ArrayList<String>();\n        synMap.put(synIn, s);\n        s.keepOrig = random().nextBoolean();\n      }\n      final String synOut = getRandomString('0', 10, TestUtil.nextInt(random(), 1, 5)).trim();\n      s.out.add(synOut);\n      add(synIn, synOut, s.keepOrig);\n      if (VERBOSE) {\n        System.out.println(\"  syns[\" + synIDX + \"] = \" + s.in + \" -> \" + s.out + \" keepOrig=\" + s.keepOrig);\n      }\n    }\n\n    tokensIn = new MockTokenizer(MockTokenizer.WHITESPACE,\n                                 true);\n    tokensIn.setReader(new StringReader(\"a\"));\n    tokensIn.reset();\n    assertTrue(tokensIn.incrementToken());\n    assertFalse(tokensIn.incrementToken());\n    tokensIn.end();\n    tokensIn.close();\n\n    tokensOut = new SynonymFilter(tokensIn,\n                                     b.build(),\n                                     true);\n    termAtt = tokensOut.addAttribute(CharTermAttribute.class);\n    posIncrAtt = tokensOut.addAttribute(PositionIncrementAttribute.class);\n    posLenAtt = tokensOut.addAttribute(PositionLengthAttribute.class);\n    offsetAtt = tokensOut.addAttribute(OffsetAttribute.class);\n\n    if (dedup) {\n      pruneDups(syns);\n    }\n\n    final String expected = slowSynMatcher(document, syns, 5);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: expected=\" + expected);\n    }\n\n    verify(document, expected);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["6613659748fe4411a7dcf85266e55db1f95f7315"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"ae889fd5c8a69f6b5d130d3c895bfa5b04d07338":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"6613659748fe4411a7dcf85266e55db1f95f7315":["ae889fd5c8a69f6b5d130d3c895bfa5b04d07338"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"]},"commit2Childs":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["ae889fd5c8a69f6b5d130d3c895bfa5b04d07338"],"ae889fd5c8a69f6b5d130d3c895bfa5b04d07338":["6613659748fe4411a7dcf85266e55db1f95f7315"],"6613659748fe4411a7dcf85266e55db1f95f7315":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}