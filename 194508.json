{"path":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal().mjava","commits":[{"id":"b47e1512544568a22b82c96169d466fae8a4b79e","date":1354519309,"type":1,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommit(Map[String,String]).mjava","sourceNew":"  private void prepareCommitInternal() throws IOException {\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (hitOOM) {\n        throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot commit\");\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      assert testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            anySegmentsFlushed = docWriter.flushAllThreads();\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount;\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(directory, false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"prepareCommit\");\n      }\n \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            deleter.decRef(filesToCommit);\n            filesToCommit = null;\n          }\n        }\n      }\n\n      startCommit(toCommit);\n    }\n  }\n\n","sourceOld":"  /** <p>Expert: prepare for commit, specifying\n   *  commitUserData Map (String -> String).  This does the\n   *  first phase of 2-phase commit. This method does all\n   *  steps necessary to commit changes since this writer\n   *  was opened: flushes pending added and deleted docs,\n   *  syncs the index files, writes most of next segments_N\n   *  file.  After calling this you must call either {@link\n   *  #commit()} to finish the commit, or {@link\n   *  #rollback()} to revert the commit and undo all changes\n   *  done since the writer was opened.</p>\n   *\n   *  <p>You can also just call {@link #commit(Map)} directly\n   *  without prepareCommit first in which case that method\n   *  will internally call prepareCommit.\n   *\n   *  <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   *  you should immediately close the writer.  See <a\n   *  href=\"#OOME\">above</a> for details.</p>\n   *\n   *  @param commitUserData Opaque Map (String->String)\n   *  that's recorded into the segments file in the index,\n   *  and retrievable by {@link\n   *  IndexCommit#getUserData}.  Note that when\n   *  IndexWriter commits itself during {@link #close}, the\n   *  commitUserData is unchanged (just carried over from\n   *  the prior commit).  If this is null then the previous\n   *  commitUserData is kept.  Also, the commitUserData will\n   *  only \"stick\" if there are actually changes in the\n   *  index to commit.\n   */\n  public final void prepareCommit(Map<String,String> commitUserData) throws IOException {\n    ensureOpen(false);\n\n    synchronized(commitLock) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (hitOOM) {\n        throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot commit\");\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      assert testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            anySegmentsFlushed = docWriter.flushAllThreads();\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount;\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(directory, false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"prepareCommit\");\n      }\n \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            deleter.decRef(filesToCommit);\n            filesToCommit = null;\n          }\n        }\n      }\n\n      startCommit(toCommit, commitUserData);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"407687e67faf6e1f02a211ca078d8e3eed631027","date":1355157407,"type":0,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal().mjava","pathOld":"/dev/null","sourceNew":"  private void prepareCommitInternal() throws IOException {\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (hitOOM) {\n        throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot commit\");\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      assert testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            anySegmentsFlushed = docWriter.flushAllThreads();\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount;\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(directory, false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"prepareCommit\");\n      }\n \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            deleter.decRef(filesToCommit);\n            filesToCommit = null;\n          }\n        }\n      }\n\n      startCommit(toCommit);\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7af110b00ea8df9429309d83e38e0533d82e144f","date":1376924768,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal().mjava","sourceNew":"  private void prepareCommitInternal() throws IOException {\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (hitOOM) {\n        throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot commit\");\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      assert testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            anySegmentsFlushed = docWriter.flushAllThreads(this);\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            processEvents(false, true);\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount;\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(directory, false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"prepareCommit\");\n      }\n     \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            deleter.decRef(filesToCommit);\n            filesToCommit = null;\n          }\n        }\n      }\n      \n      startCommit(toCommit);\n    }\n  }\n\n","sourceOld":"  private void prepareCommitInternal() throws IOException {\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (hitOOM) {\n        throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot commit\");\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      assert testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            anySegmentsFlushed = docWriter.flushAllThreads();\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount;\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(directory, false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"prepareCommit\");\n      }\n \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            deleter.decRef(filesToCommit);\n            filesToCommit = null;\n          }\n        }\n      }\n\n      startCommit(toCommit);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"31d4861802ca404d78ca1d15f4550eec415b9199","date":1376947894,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal().mjava","sourceNew":"  private void prepareCommitInternal() throws IOException {\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (hitOOM) {\n        throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot commit\");\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      assert testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            anySegmentsFlushed = docWriter.flushAllThreads(this);\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            processEvents(false, true);\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount;\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(directory, false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"prepareCommit\");\n      }\n     \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            deleter.decRef(filesToCommit);\n            filesToCommit = null;\n          }\n        }\n      }\n      \n      startCommit(toCommit);\n    }\n  }\n\n","sourceOld":"  private void prepareCommitInternal() throws IOException {\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (hitOOM) {\n        throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot commit\");\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      assert testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            anySegmentsFlushed = docWriter.flushAllThreads();\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount;\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(directory, false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"prepareCommit\");\n      }\n \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            deleter.decRef(filesToCommit);\n            filesToCommit = null;\n          }\n        }\n      }\n\n      startCommit(toCommit);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3dffec77fb8f7d0e9ca4869dddd6af94528b4576","date":1377875202,"type":3,"author":"Han Jiang","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal().mjava","sourceNew":"  private void prepareCommitInternal() throws IOException {\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (hitOOM) {\n        throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot commit\");\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      assert testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            anySegmentsFlushed = docWriter.flushAllThreads(this);\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            processEvents(false, true);\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount;\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(directory, false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"prepareCommit\");\n      }\n     \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            deleter.decRef(filesToCommit);\n            filesToCommit = null;\n          }\n        }\n      }\n      \n      startCommit(toCommit);\n    }\n  }\n\n","sourceOld":"  private void prepareCommitInternal() throws IOException {\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (hitOOM) {\n        throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot commit\");\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      assert testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            anySegmentsFlushed = docWriter.flushAllThreads();\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount;\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(directory, false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"prepareCommit\");\n      }\n \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            deleter.decRef(filesToCommit);\n            filesToCommit = null;\n          }\n        }\n      }\n\n      startCommit(toCommit);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cd4e13d997cf4fb810398a20a299c2c5a9f6b796","date":1395594336,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal().mjava","sourceNew":"  private void prepareCommitInternal() throws IOException {\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (hitOOM) {\n        throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot commit\");\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      assert testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            anySegmentsFlushed = docWriter.flushAllThreads(this);\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            processEvents(false, true);\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount;\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(directory, false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"prepareCommit\");\n      }\n     \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        startCommit(toCommit);\n        success = true;\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRef(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private void prepareCommitInternal() throws IOException {\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (hitOOM) {\n        throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot commit\");\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      assert testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            anySegmentsFlushed = docWriter.flushAllThreads(this);\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            processEvents(false, true);\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount;\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(directory, false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"prepareCommit\");\n      }\n     \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            deleter.decRef(filesToCommit);\n            filesToCommit = null;\n          }\n        }\n      }\n      \n      startCommit(toCommit);\n    }\n  }\n\n","bugFix":null,"bugIntro":["cefe924a3b76c22b7df9a075329750871699af6b"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"203d65f24251ea8106efd122cca89a2a91205ae4","date":1398262565,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal().mjava","sourceNew":"  private void prepareCommitInternal() throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (hitOOM) {\n        throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot commit\");\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      assert testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            anySegmentsFlushed = docWriter.flushAllThreads(this);\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            processEvents(false, true);\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount;\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(directory, false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"prepareCommit\");\n      }\n     \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        startCommit(toCommit);\n        success = true;\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRef(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private void prepareCommitInternal() throws IOException {\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (hitOOM) {\n        throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot commit\");\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      assert testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            anySegmentsFlushed = docWriter.flushAllThreads(this);\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            processEvents(false, true);\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount;\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(directory, false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"prepareCommit\");\n      }\n     \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        startCommit(toCommit);\n        success = true;\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRef(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c0cd85fde84cb318b4dc97710dcf15e2959a1bbe","date":1398844771,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal().mjava","sourceNew":"  private void prepareCommitInternal() throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (hitOOM) {\n        throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot commit\");\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      assert testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            anySegmentsFlushed = docWriter.flushAllThreads(this);\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            processEvents(false, true);\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount;\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(directory, false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"prepareCommit\");\n      }\n     \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        startCommit(toCommit);\n        success = true;\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRef(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private void prepareCommitInternal() throws IOException {\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (hitOOM) {\n        throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot commit\");\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      assert testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            anySegmentsFlushed = docWriter.flushAllThreads(this);\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            processEvents(false, true);\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount;\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(directory, false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"prepareCommit\");\n      }\n     \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        startCommit(toCommit);\n        success = true;\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRef(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ee59f646cf24586a449cad77391a60a3ac8d8959","date":1408015131,"type":5,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal(MergePolicy).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal().mjava","sourceNew":"  private void prepareCommitInternal(MergePolicy mergePolicy) throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (hitOOM) {\n        throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot commit\");\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      assert testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            anySegmentsFlushed = docWriter.flushAllThreads(this);\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            processEvents(false, true);\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount;\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(directory, false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"prepareCommit\");\n      }\n     \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(mergePolicy, MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        startCommit(toCommit);\n        success = true;\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRef(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private void prepareCommitInternal() throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (hitOOM) {\n        throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot commit\");\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      assert testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            anySegmentsFlushed = docWriter.flushAllThreads(this);\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            processEvents(false, true);\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount;\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(directory, false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"prepareCommit\");\n      }\n     \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        startCommit(toCommit);\n        success = true;\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRef(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f4363cd33f6eff7fb4753574a441e2d18c1022a4","date":1498067235,"type":1,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal(boolean[]).mjava","sourceNew":"  private long prepareCommitInternal() throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy);\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anyChanges = false;\n      long seqNo;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads();\n            if (seqNo < 0) {\n              anyChanges = true;\n              seqNo = -seqNo;\n            }\n            if (anyChanges == false) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n\n            // cannot pass triggerMerges=true here else it can lead to deadlock:\n            processEvents(false, false);\n            \n            flushSuccess = true;\n\n            applyAllDeletesAndUpdates();\n\n            synchronized(this) {\n\n              readerPool.commit(segmentInfos);\n\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              if (commitUserData != null) {\n                Map<String,String> userData = new HashMap<>();\n                for(Map.Entry<String,String> ent : commitUserData) {\n                  userData.put(ent.getKey(), ent.getValue());\n                }\n                segmentInfos.setUserData(userData, false);\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false); \n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(this, flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (AbortingException | VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n\n        // dead code but javac disagrees:\n        seqNo = -1;\n      }\n     \n      boolean success = false;\n      try {\n        if (anyChanges) {\n          maybeMerge.set(true);\n        }\n        startCommit(toCommit);\n        success = true;\n        if (pendingCommit == null) {\n          return -1;\n        } else {\n          return seqNo;\n        }\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRefWhileHandlingException(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private long prepareCommitInternal(boolean[] doMaybeMerge) throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy);\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n      long seqNo;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads();\n            if (seqNo < 0) {\n              anySegmentsFlushed = true;\n              seqNo = -seqNo;\n            }\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            processEvents(false, true);\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              if (commitUserData != null) {\n                Map<String,String> userData = new HashMap<>();\n                for(Map.Entry<String,String> ent : commitUserData) {\n                  userData.put(ent.getKey(), ent.getValue());\n                }\n                segmentInfos.setUserData(userData, false);\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false); \n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(this, flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (AbortingException | VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n\n        // dead code but javac disagrees:\n        seqNo = -1;\n      }\n     \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          doMaybeMerge[0] = true;\n        }\n        startCommit(toCommit);\n        success = true;\n        if (pendingCommit == null) {\n          return -1;\n        } else {\n          return seqNo;\n        }\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRefWhileHandlingException(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b7dfa64bc2074fb87d0ca70095a644c1ead107e1","date":1498356339,"type":1,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal(boolean[]).mjava","sourceNew":"  private long prepareCommitInternal() throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy);\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anyChanges = false;\n      long seqNo;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads();\n            if (seqNo < 0) {\n              anyChanges = true;\n              seqNo = -seqNo;\n            }\n            if (anyChanges == false) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n\n            // cannot pass triggerMerges=true here else it can lead to deadlock:\n            processEvents(false, false);\n            \n            flushSuccess = true;\n\n            applyAllDeletesAndUpdates();\n\n            synchronized(this) {\n\n              readerPool.commit(segmentInfos);\n\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              if (commitUserData != null) {\n                Map<String,String> userData = new HashMap<>();\n                for(Map.Entry<String,String> ent : commitUserData) {\n                  userData.put(ent.getKey(), ent.getValue());\n                }\n                segmentInfos.setUserData(userData, false);\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false); \n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(this, flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (AbortingException | VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n\n        // dead code but javac disagrees:\n        seqNo = -1;\n      }\n     \n      boolean success = false;\n      try {\n        if (anyChanges) {\n          maybeMerge.set(true);\n        }\n        startCommit(toCommit);\n        success = true;\n        if (pendingCommit == null) {\n          return -1;\n        } else {\n          return seqNo;\n        }\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRefWhileHandlingException(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private long prepareCommitInternal(boolean[] doMaybeMerge) throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy);\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n      long seqNo;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads();\n            if (seqNo < 0) {\n              anySegmentsFlushed = true;\n              seqNo = -seqNo;\n            }\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            processEvents(false, true);\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              if (commitUserData != null) {\n                Map<String,String> userData = new HashMap<>();\n                for(Map.Entry<String,String> ent : commitUserData) {\n                  userData.put(ent.getKey(), ent.getValue());\n                }\n                segmentInfos.setUserData(userData, false);\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false); \n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(this, flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (AbortingException | VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n\n        // dead code but javac disagrees:\n        seqNo = -1;\n      }\n     \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          doMaybeMerge[0] = true;\n        }\n        startCommit(toCommit);\n        success = true;\n        if (pendingCommit == null) {\n          return -1;\n        } else {\n          return seqNo;\n        }\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRefWhileHandlingException(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"28288370235ed02234a64753cdbf0c6ec096304a","date":1498726817,"type":0,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal().mjava","pathOld":"/dev/null","sourceNew":"  private long prepareCommitInternal() throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy);\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anyChanges = false;\n      long seqNo;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads();\n            if (seqNo < 0) {\n              anyChanges = true;\n              seqNo = -seqNo;\n            }\n            if (anyChanges == false) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n\n            // cannot pass triggerMerges=true here else it can lead to deadlock:\n            processEvents(false, false);\n            \n            flushSuccess = true;\n\n            applyAllDeletesAndUpdates();\n\n            synchronized(this) {\n\n              readerPool.commit(segmentInfos);\n\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              if (commitUserData != null) {\n                Map<String,String> userData = new HashMap<>();\n                for(Map.Entry<String,String> ent : commitUserData) {\n                  userData.put(ent.getKey(), ent.getValue());\n                }\n                segmentInfos.setUserData(userData, false);\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false); \n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(this, flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (AbortingException | VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n\n        // dead code but javac disagrees:\n        seqNo = -1;\n      }\n     \n      boolean success = false;\n      try {\n        if (anyChanges) {\n          maybeMerge.set(true);\n        }\n        startCommit(toCommit);\n        success = true;\n        if (pendingCommit == null) {\n          return -1;\n        } else {\n          return seqNo;\n        }\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRefWhileHandlingException(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"845b760a99e5f369fcd0a5d723a87b8def6a3f56","date":1521117993,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal().mjava","sourceNew":"  private long prepareCommitInternal() throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy.get() != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy.get());\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anyChanges = false;\n      long seqNo;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads();\n            if (seqNo < 0) {\n              anyChanges = true;\n              seqNo = -seqNo;\n            }\n            if (anyChanges == false) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n\n            // cannot pass triggerMerges=true here else it can lead to deadlock:\n            processEvents(false);\n            \n            flushSuccess = true;\n\n            applyAllDeletesAndUpdates();\n\n            synchronized(this) {\n\n              readerPool.commit(segmentInfos);\n\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              if (commitUserData != null) {\n                Map<String,String> userData = new HashMap<>();\n                for(Map.Entry<String,String> ent : commitUserData) {\n                  userData.put(ent.getKey(), ent.getValue());\n                }\n                segmentInfos.setUserData(userData, false);\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false); \n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(this, flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n        throw tragedy;\n      } finally {\n        maybeCloseOnTragicEvent();\n      }\n     \n      boolean success = false;\n      try {\n        if (anyChanges) {\n          maybeMerge.set(true);\n        }\n        startCommit(toCommit);\n        success = true;\n        if (pendingCommit == null) {\n          return -1;\n        } else {\n          return seqNo;\n        }\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRefWhileHandlingException(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private long prepareCommitInternal() throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy);\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anyChanges = false;\n      long seqNo;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads();\n            if (seqNo < 0) {\n              anyChanges = true;\n              seqNo = -seqNo;\n            }\n            if (anyChanges == false) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n\n            // cannot pass triggerMerges=true here else it can lead to deadlock:\n            processEvents(false, false);\n            \n            flushSuccess = true;\n\n            applyAllDeletesAndUpdates();\n\n            synchronized(this) {\n\n              readerPool.commit(segmentInfos);\n\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              if (commitUserData != null) {\n                Map<String,String> userData = new HashMap<>();\n                for(Map.Entry<String,String> ent : commitUserData) {\n                  userData.put(ent.getKey(), ent.getValue());\n                }\n                segmentInfos.setUserData(userData, false);\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false); \n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(this, flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (AbortingException | VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n\n        // dead code but javac disagrees:\n        seqNo = -1;\n      }\n     \n      boolean success = false;\n      try {\n        if (anyChanges) {\n          maybeMerge.set(true);\n        }\n        startCommit(toCommit);\n        success = true;\n        if (pendingCommit == null) {\n          return -1;\n        } else {\n          return seqNo;\n        }\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRefWhileHandlingException(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bb04d6a79e860154f2a1c519790fc42f5a792915","date":1521621668,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal().mjava","sourceNew":"  private long prepareCommitInternal() throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy.get() != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy.get());\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anyChanges = false;\n      long seqNo;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads();\n            if (seqNo < 0) {\n              anyChanges = true;\n              seqNo = -seqNo;\n            }\n            if (anyChanges == false) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n\n            // cannot pass triggerMerges=true here else it can lead to deadlock:\n            processEvents(false);\n            \n            flushSuccess = true;\n\n            applyAllDeletesAndUpdates();\n\n            synchronized(this) {\n\n              readerPool.commit(segmentInfos);\n\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              if (commitUserData != null) {\n                Map<String,String> userData = new HashMap<>();\n                for(Map.Entry<String,String> ent : commitUserData) {\n                  userData.put(ent.getKey(), ent.getValue());\n                }\n                segmentInfos.setUserData(userData, false);\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false); \n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(this, flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n        throw tragedy;\n      } finally {\n        maybeCloseOnTragicEvent();\n      }\n     \n      try {\n        if (anyChanges) {\n          maybeMerge.set(true);\n        }\n        startCommit(toCommit);\n        if (pendingCommit == null) {\n          return -1;\n        } else {\n          return seqNo;\n        }\n      } catch (Throwable t) {\n        synchronized (this) {\n          if (filesToCommit != null) {\n            try {\n              deleter.decRef(filesToCommit);\n            } catch (Throwable t1) {\n              t.addSuppressed(t1);\n            } finally {\n              filesToCommit = null;\n            }\n          }\n        }\n        throw t;\n      }\n    }\n  }\n\n","sourceOld":"  private long prepareCommitInternal() throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy.get() != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy.get());\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anyChanges = false;\n      long seqNo;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads();\n            if (seqNo < 0) {\n              anyChanges = true;\n              seqNo = -seqNo;\n            }\n            if (anyChanges == false) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n\n            // cannot pass triggerMerges=true here else it can lead to deadlock:\n            processEvents(false);\n            \n            flushSuccess = true;\n\n            applyAllDeletesAndUpdates();\n\n            synchronized(this) {\n\n              readerPool.commit(segmentInfos);\n\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              if (commitUserData != null) {\n                Map<String,String> userData = new HashMap<>();\n                for(Map.Entry<String,String> ent : commitUserData) {\n                  userData.put(ent.getKey(), ent.getValue());\n                }\n                segmentInfos.setUserData(userData, false);\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false); \n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(this, flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n        throw tragedy;\n      } finally {\n        maybeCloseOnTragicEvent();\n      }\n     \n      boolean success = false;\n      try {\n        if (anyChanges) {\n          maybeMerge.set(true);\n        }\n        startCommit(toCommit);\n        success = true;\n        if (pendingCommit == null) {\n          return -1;\n        } else {\n          return seqNo;\n        }\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRefWhileHandlingException(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6815b5b5d6334b2245dd7be2f8b6cca949bf7f43","date":1521731438,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal().mjava","sourceNew":"  private long prepareCommitInternal() throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy.get() != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy.get());\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anyChanges = false;\n      long seqNo;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads();\n            if (seqNo < 0) {\n              anyChanges = true;\n              seqNo = -seqNo;\n            }\n            if (anyChanges == false) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n\n            // cannot pass triggerMerges=true here else it can lead to deadlock:\n            processEvents(false);\n            \n            flushSuccess = true;\n\n            applyAllDeletesAndUpdates();\n\n            synchronized(this) {\n\n              readerPool.commit(segmentInfos);\n\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              if (commitUserData != null) {\n                Map<String,String> userData = new HashMap<>();\n                for(Map.Entry<String,String> ent : commitUserData) {\n                  userData.put(ent.getKey(), ent.getValue());\n                }\n                segmentInfos.setUserData(userData, false);\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false); \n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(this, flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n        throw tragedy;\n      } finally {\n        maybeCloseOnTragicEvent();\n      }\n     \n      try {\n        if (anyChanges) {\n          maybeMerge.set(true);\n        }\n        startCommit(toCommit);\n        if (pendingCommit == null) {\n          return -1;\n        } else {\n          return seqNo;\n        }\n      } catch (Throwable t) {\n        synchronized (this) {\n          if (filesToCommit != null) {\n            try {\n              deleter.decRef(filesToCommit);\n            } catch (Throwable t1) {\n              t.addSuppressed(t1);\n            } finally {\n              filesToCommit = null;\n            }\n          }\n        }\n        throw t;\n      }\n    }\n  }\n\n","sourceOld":"  private long prepareCommitInternal() throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy.get() != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy.get());\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anyChanges = false;\n      long seqNo;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads();\n            if (seqNo < 0) {\n              anyChanges = true;\n              seqNo = -seqNo;\n            }\n            if (anyChanges == false) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n\n            // cannot pass triggerMerges=true here else it can lead to deadlock:\n            processEvents(false);\n            \n            flushSuccess = true;\n\n            applyAllDeletesAndUpdates();\n\n            synchronized(this) {\n\n              readerPool.commit(segmentInfos);\n\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              if (commitUserData != null) {\n                Map<String,String> userData = new HashMap<>();\n                for(Map.Entry<String,String> ent : commitUserData) {\n                  userData.put(ent.getKey(), ent.getValue());\n                }\n                segmentInfos.setUserData(userData, false);\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false); \n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(this, flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n        throw tragedy;\n      } finally {\n        maybeCloseOnTragicEvent();\n      }\n     \n      boolean success = false;\n      try {\n        if (anyChanges) {\n          maybeMerge.set(true);\n        }\n        startCommit(toCommit);\n        success = true;\n        if (pendingCommit == null) {\n          return -1;\n        } else {\n          return seqNo;\n        }\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRefWhileHandlingException(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"15e716649e2bd79a98b5e68c464154ea4c44677a","date":1523975212,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal().mjava","sourceNew":"  private long prepareCommitInternal() throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy.get() != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy.get());\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anyChanges = false;\n      long seqNo;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads();\n            if (seqNo < 0) {\n              anyChanges = true;\n              seqNo = -seqNo;\n            }\n            if (anyChanges == false) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n\n            // cannot pass triggerMerges=true here else it can lead to deadlock:\n            processEvents(false);\n            \n            flushSuccess = true;\n\n            applyAllDeletesAndUpdates();\n            synchronized(this) {\n\n              readerPool.commit(segmentInfos);\n\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              if (commitUserData != null) {\n                Map<String,String> userData = new HashMap<>();\n                for(Map.Entry<String,String> ent : commitUserData) {\n                  userData.put(ent.getKey(), ent.getValue());\n                }\n                segmentInfos.setUserData(userData, false);\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false); \n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(this, flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n        throw tragedy;\n      } finally {\n        maybeCloseOnTragicEvent();\n      }\n     \n      try {\n        if (anyChanges) {\n          maybeMerge.set(true);\n        }\n        startCommit(toCommit);\n        if (pendingCommit == null) {\n          return -1;\n        } else {\n          return seqNo;\n        }\n      } catch (Throwable t) {\n        synchronized (this) {\n          if (filesToCommit != null) {\n            try {\n              deleter.decRef(filesToCommit);\n            } catch (Throwable t1) {\n              t.addSuppressed(t1);\n            } finally {\n              filesToCommit = null;\n            }\n          }\n        }\n        throw t;\n      }\n    }\n  }\n\n","sourceOld":"  private long prepareCommitInternal() throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy.get() != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy.get());\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anyChanges = false;\n      long seqNo;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads();\n            if (seqNo < 0) {\n              anyChanges = true;\n              seqNo = -seqNo;\n            }\n            if (anyChanges == false) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n\n            // cannot pass triggerMerges=true here else it can lead to deadlock:\n            processEvents(false);\n            \n            flushSuccess = true;\n\n            applyAllDeletesAndUpdates();\n\n            synchronized(this) {\n\n              readerPool.commit(segmentInfos);\n\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              if (commitUserData != null) {\n                Map<String,String> userData = new HashMap<>();\n                for(Map.Entry<String,String> ent : commitUserData) {\n                  userData.put(ent.getKey(), ent.getValue());\n                }\n                segmentInfos.setUserData(userData, false);\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false); \n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(this, flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n        throw tragedy;\n      } finally {\n        maybeCloseOnTragicEvent();\n      }\n     \n      try {\n        if (anyChanges) {\n          maybeMerge.set(true);\n        }\n        startCommit(toCommit);\n        if (pendingCommit == null) {\n          return -1;\n        } else {\n          return seqNo;\n        }\n      } catch (Throwable t) {\n        synchronized (this) {\n          if (filesToCommit != null) {\n            try {\n              deleter.decRef(filesToCommit);\n            } catch (Throwable t1) {\n              t.addSuppressed(t1);\n            } finally {\n              filesToCommit = null;\n            }\n          }\n        }\n        throw t;\n      }\n    }\n  }\n\n","bugFix":["f4363cd33f6eff7fb4753574a441e2d18c1022a4"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1926100d9b67becc9701c54266fee3ba7878a5f0","date":1524472150,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal().mjava","sourceNew":"  private long prepareCommitInternal() throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy.get() != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy.get());\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anyChanges = false;\n      long seqNo;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads();\n            if (seqNo < 0) {\n              anyChanges = true;\n              seqNo = -seqNo;\n            }\n            if (anyChanges == false) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n\n            // cannot pass triggerMerges=true here else it can lead to deadlock:\n            processEvents(false);\n            \n            flushSuccess = true;\n\n            applyAllDeletesAndUpdates();\n            synchronized(this) {\n\n              if (readerPool.commit(segmentInfos)) {\n                checkpointNoSIS();\n              }\n\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              if (commitUserData != null) {\n                Map<String,String> userData = new HashMap<>();\n                for(Map.Entry<String,String> ent : commitUserData) {\n                  userData.put(ent.getKey(), ent.getValue());\n                }\n                segmentInfos.setUserData(userData, false);\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false); \n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(this, flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n        throw tragedy;\n      } finally {\n        maybeCloseOnTragicEvent();\n      }\n     \n      try {\n        if (anyChanges) {\n          maybeMerge.set(true);\n        }\n        startCommit(toCommit);\n        if (pendingCommit == null) {\n          return -1;\n        } else {\n          return seqNo;\n        }\n      } catch (Throwable t) {\n        synchronized (this) {\n          if (filesToCommit != null) {\n            try {\n              deleter.decRef(filesToCommit);\n            } catch (Throwable t1) {\n              t.addSuppressed(t1);\n            } finally {\n              filesToCommit = null;\n            }\n          }\n        }\n        throw t;\n      }\n    }\n  }\n\n","sourceOld":"  private long prepareCommitInternal() throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy.get() != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy.get());\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anyChanges = false;\n      long seqNo;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads();\n            if (seqNo < 0) {\n              anyChanges = true;\n              seqNo = -seqNo;\n            }\n            if (anyChanges == false) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n\n            // cannot pass triggerMerges=true here else it can lead to deadlock:\n            processEvents(false);\n            \n            flushSuccess = true;\n\n            applyAllDeletesAndUpdates();\n            synchronized(this) {\n\n              readerPool.commit(segmentInfos);\n\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              if (commitUserData != null) {\n                Map<String,String> userData = new HashMap<>();\n                for(Map.Entry<String,String> ent : commitUserData) {\n                  userData.put(ent.getKey(), ent.getValue());\n                }\n                segmentInfos.setUserData(userData, false);\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false); \n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(this, flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n        throw tragedy;\n      } finally {\n        maybeCloseOnTragicEvent();\n      }\n     \n      try {\n        if (anyChanges) {\n          maybeMerge.set(true);\n        }\n        startCommit(toCommit);\n        if (pendingCommit == null) {\n          return -1;\n        } else {\n          return seqNo;\n        }\n      } catch (Throwable t) {\n        synchronized (this) {\n          if (filesToCommit != null) {\n            try {\n              deleter.decRef(filesToCommit);\n            } catch (Throwable t1) {\n              t.addSuppressed(t1);\n            } finally {\n              filesToCommit = null;\n            }\n          }\n        }\n        throw t;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["f372764a5bd3ebacde5b99ee3303153eb5ec0d2f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"86a2e8a56b368d37ef3ba7180541fa317d6fd6c7","date":1524496660,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal().mjava","sourceNew":"  private long prepareCommitInternal() throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy.get() != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy.get());\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anyChanges = false;\n      long seqNo;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads(this);\n            if (seqNo < 0) {\n              anyChanges = true;\n              seqNo = -seqNo;\n            }\n            if (anyChanges == false) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n\n            // cannot pass triggerMerges=true here else it can lead to deadlock:\n            processEvents(false);\n            \n            flushSuccess = true;\n\n            applyAllDeletesAndUpdates();\n            synchronized(this) {\n\n              if (readerPool.commit(segmentInfos)) {\n                checkpointNoSIS();\n              }\n\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              if (commitUserData != null) {\n                Map<String,String> userData = new HashMap<>();\n                for(Map.Entry<String,String> ent : commitUserData) {\n                  userData.put(ent.getKey(), ent.getValue());\n                }\n                segmentInfos.setUserData(userData, false);\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false); \n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(this, flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n        throw tragedy;\n      } finally {\n        maybeCloseOnTragicEvent();\n      }\n     \n      try {\n        if (anyChanges) {\n          maybeMerge.set(true);\n        }\n        startCommit(toCommit);\n        if (pendingCommit == null) {\n          return -1;\n        } else {\n          return seqNo;\n        }\n      } catch (Throwable t) {\n        synchronized (this) {\n          if (filesToCommit != null) {\n            try {\n              deleter.decRef(filesToCommit);\n            } catch (Throwable t1) {\n              t.addSuppressed(t1);\n            } finally {\n              filesToCommit = null;\n            }\n          }\n        }\n        throw t;\n      }\n    }\n  }\n\n","sourceOld":"  private long prepareCommitInternal() throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy.get() != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy.get());\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anyChanges = false;\n      long seqNo;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads();\n            if (seqNo < 0) {\n              anyChanges = true;\n              seqNo = -seqNo;\n            }\n            if (anyChanges == false) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n\n            // cannot pass triggerMerges=true here else it can lead to deadlock:\n            processEvents(false);\n            \n            flushSuccess = true;\n\n            applyAllDeletesAndUpdates();\n            synchronized(this) {\n\n              if (readerPool.commit(segmentInfos)) {\n                checkpointNoSIS();\n              }\n\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              if (commitUserData != null) {\n                Map<String,String> userData = new HashMap<>();\n                for(Map.Entry<String,String> ent : commitUserData) {\n                  userData.put(ent.getKey(), ent.getValue());\n                }\n                segmentInfos.setUserData(userData, false);\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false); \n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(this, flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n        throw tragedy;\n      } finally {\n        maybeCloseOnTragicEvent();\n      }\n     \n      try {\n        if (anyChanges) {\n          maybeMerge.set(true);\n        }\n        startCommit(toCommit);\n        if (pendingCommit == null) {\n          return -1;\n        } else {\n          return seqNo;\n        }\n      } catch (Throwable t) {\n        synchronized (this) {\n          if (filesToCommit != null) {\n            try {\n              deleter.decRef(filesToCommit);\n            } catch (Throwable t1) {\n              t.addSuppressed(t1);\n            } finally {\n              filesToCommit = null;\n            }\n          }\n        }\n        throw t;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6b8498afacfc8322268ca0d659d274fcce08d557","date":1524577248,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal().mjava","sourceNew":"  private long prepareCommitInternal() throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy.get() != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy.get());\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anyChanges = false;\n      long seqNo;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads();\n            if (seqNo < 0) {\n              anyChanges = true;\n              seqNo = -seqNo;\n            }\n            if (anyChanges == false) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            publishFlushedSegments(true);\n            // cannot pass triggerMerges=true here else it can lead to deadlock:\n            processEvents(false);\n            \n            flushSuccess = true;\n\n            applyAllDeletesAndUpdates();\n            synchronized(this) {\n\n              if (readerPool.commit(segmentInfos)) {\n                checkpointNoSIS();\n              }\n\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              if (commitUserData != null) {\n                Map<String,String> userData = new HashMap<>();\n                for(Map.Entry<String,String> ent : commitUserData) {\n                  userData.put(ent.getKey(), ent.getValue());\n                }\n                segmentInfos.setUserData(userData, false);\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false); \n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            assert holdsFullFlushLock();\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n        throw tragedy;\n      } finally {\n        maybeCloseOnTragicEvent();\n      }\n     \n      try {\n        if (anyChanges) {\n          maybeMerge.set(true);\n        }\n        startCommit(toCommit);\n        if (pendingCommit == null) {\n          return -1;\n        } else {\n          return seqNo;\n        }\n      } catch (Throwable t) {\n        synchronized (this) {\n          if (filesToCommit != null) {\n            try {\n              deleter.decRef(filesToCommit);\n            } catch (Throwable t1) {\n              t.addSuppressed(t1);\n            } finally {\n              filesToCommit = null;\n            }\n          }\n        }\n        throw t;\n      }\n    }\n  }\n\n","sourceOld":"  private long prepareCommitInternal() throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy.get() != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy.get());\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anyChanges = false;\n      long seqNo;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads(this);\n            if (seqNo < 0) {\n              anyChanges = true;\n              seqNo = -seqNo;\n            }\n            if (anyChanges == false) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n\n            // cannot pass triggerMerges=true here else it can lead to deadlock:\n            processEvents(false);\n            \n            flushSuccess = true;\n\n            applyAllDeletesAndUpdates();\n            synchronized(this) {\n\n              if (readerPool.commit(segmentInfos)) {\n                checkpointNoSIS();\n              }\n\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              if (commitUserData != null) {\n                Map<String,String> userData = new HashMap<>();\n                for(Map.Entry<String,String> ent : commitUserData) {\n                  userData.put(ent.getKey(), ent.getValue());\n                }\n                segmentInfos.setUserData(userData, false);\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false); \n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(this, flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n        throw tragedy;\n      } finally {\n        maybeCloseOnTragicEvent();\n      }\n     \n      try {\n        if (anyChanges) {\n          maybeMerge.set(true);\n        }\n        startCommit(toCommit);\n        if (pendingCommit == null) {\n          return -1;\n        } else {\n          return seqNo;\n        }\n      } catch (Throwable t) {\n        synchronized (this) {\n          if (filesToCommit != null) {\n            try {\n              deleter.decRef(filesToCommit);\n            } catch (Throwable t1) {\n              t.addSuppressed(t1);\n            } finally {\n              filesToCommit = null;\n            }\n          }\n        }\n        throw t;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f372764a5bd3ebacde5b99ee3303153eb5ec0d2f","date":1525347515,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal().mjava","sourceNew":"  private long prepareCommitInternal() throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy.get() != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy.get());\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anyChanges = false;\n      long seqNo;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads();\n            if (seqNo < 0) {\n              anyChanges = true;\n              seqNo = -seqNo;\n            }\n            if (anyChanges == false) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            publishFlushedSegments(true);\n            // cannot pass triggerMerges=true here else it can lead to deadlock:\n            processEvents(false);\n            \n            flushSuccess = true;\n\n            applyAllDeletesAndUpdates();\n            synchronized(this) {\n              writeReaderPool(true);\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              if (commitUserData != null) {\n                Map<String,String> userData = new HashMap<>();\n                for(Map.Entry<String,String> ent : commitUserData) {\n                  userData.put(ent.getKey(), ent.getValue());\n                }\n                segmentInfos.setUserData(userData, false);\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false); \n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            assert holdsFullFlushLock();\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n        throw tragedy;\n      } finally {\n        maybeCloseOnTragicEvent();\n      }\n     \n      try {\n        if (anyChanges) {\n          maybeMerge.set(true);\n        }\n        startCommit(toCommit);\n        if (pendingCommit == null) {\n          return -1;\n        } else {\n          return seqNo;\n        }\n      } catch (Throwable t) {\n        synchronized (this) {\n          if (filesToCommit != null) {\n            try {\n              deleter.decRef(filesToCommit);\n            } catch (Throwable t1) {\n              t.addSuppressed(t1);\n            } finally {\n              filesToCommit = null;\n            }\n          }\n        }\n        throw t;\n      }\n    }\n  }\n\n","sourceOld":"  private long prepareCommitInternal() throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy.get() != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy.get());\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anyChanges = false;\n      long seqNo;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads();\n            if (seqNo < 0) {\n              anyChanges = true;\n              seqNo = -seqNo;\n            }\n            if (anyChanges == false) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            publishFlushedSegments(true);\n            // cannot pass triggerMerges=true here else it can lead to deadlock:\n            processEvents(false);\n            \n            flushSuccess = true;\n\n            applyAllDeletesAndUpdates();\n            synchronized(this) {\n\n              if (readerPool.commit(segmentInfos)) {\n                checkpointNoSIS();\n              }\n\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              if (commitUserData != null) {\n                Map<String,String> userData = new HashMap<>();\n                for(Map.Entry<String,String> ent : commitUserData) {\n                  userData.put(ent.getKey(), ent.getValue());\n                }\n                segmentInfos.setUserData(userData, false);\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false); \n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            assert holdsFullFlushLock();\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n        throw tragedy;\n      } finally {\n        maybeCloseOnTragicEvent();\n      }\n     \n      try {\n        if (anyChanges) {\n          maybeMerge.set(true);\n        }\n        startCommit(toCommit);\n        if (pendingCommit == null) {\n          return -1;\n        } else {\n          return seqNo;\n        }\n      } catch (Throwable t) {\n        synchronized (this) {\n          if (filesToCommit != null) {\n            try {\n              deleter.decRef(filesToCommit);\n            } catch (Throwable t1) {\n              t.addSuppressed(t1);\n            } finally {\n              filesToCommit = null;\n            }\n          }\n        }\n        throw t;\n      }\n    }\n  }\n\n","bugFix":["1926100d9b67becc9701c54266fee3ba7878a5f0","f241b963c5bcd6c2293a928059dd2d64988a6042"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"81819c5a4a660afd353042c67106e682bb877cf1","date":1583169587,"type":3,"author":"msfroh","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal().mjava","sourceNew":"  private long prepareCommitInternal() throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy.get() != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy.get());\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anyChanges = false;\n      long seqNo;\n      List<MergePolicy.OneMerge> commitMerges = null;\n      AtomicReference<CountDownLatch> mergeAwaitLatchRef = null;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads();\n            if (seqNo < 0) {\n              anyChanges = true;\n              seqNo = -seqNo;\n            }\n            if (anyChanges == false) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            publishFlushedSegments(true);\n            // cannot pass triggerMerges=true here else it can lead to deadlock:\n            processEvents(false);\n            \n            flushSuccess = true;\n\n            applyAllDeletesAndUpdates();\n            synchronized(this) {\n              writeReaderPool(true);\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              if (commitUserData != null) {\n                Map<String,String> userData = new HashMap<>();\n                for(Map.Entry<String,String> ent : commitUserData) {\n                  userData.put(ent.getKey(), ent.getValue());\n                }\n                segmentInfos.setUserData(userData, false);\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              if (anyChanges) {\n                // Find any merges that can execute on commit (per MergePolicy).\n                MergePolicy.MergeSpecification mergeSpec =\n                    config.getMergePolicy().findFullFlushMerges(MergeTrigger.COMMIT, segmentInfos, this);\n                if (mergeSpec != null && mergeSpec.merges.size() > 0) {\n                  int mergeCount = mergeSpec.merges.size();\n                  commitMerges = new ArrayList<>(mergeCount);\n                  mergeAwaitLatchRef = new AtomicReference<>(new CountDownLatch(mergeCount));\n                  for (MergePolicy.OneMerge oneMerge : mergeSpec.merges) {\n                    MergePolicy.OneMerge trackedMerge =\n                        updateSegmentInfosOnMergeFinish(oneMerge, toCommit, mergeAwaitLatchRef);\n                    if (registerMerge(trackedMerge) == false) {\n                      throw new IllegalStateException(\"MergePolicy \" + config.getMergePolicy().getClass() +\n                          \" returned merging segments from findFullFlushMerges\");\n                    }\n                    commitMerges.add(trackedMerge);\n                  }\n                  if (infoStream.isEnabled(\"IW\")) {\n                    infoStream.message(\"IW\", \"Registered \" + mergeCount + \" commit merges\");\n                    infoStream.message(\"IW\", \"Before executing commit merges, had \" + toCommit.size() + \" segments\");\n                  }\n                }\n              }\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              deleter.incRef(toCommit.files(false));\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            assert holdsFullFlushLock();\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n        throw tragedy;\n      } finally {\n        maybeCloseOnTragicEvent();\n      }\n\n      if (mergeAwaitLatchRef != null) {\n        CountDownLatch mergeAwaitLatch = mergeAwaitLatchRef.get();\n        // If we found and registered any merges above, within the flushLock, then we want to ensure that they\n        // complete execution. Note that since we released the lock, other merges may have been scheduled. We will\n        // block until  the merges that we registered complete. As they complete, they will update toCommit to\n        // replace merged segments with the result of each merge.\n        config.getIndexWriterEvents().beginMergeOnCommit();\n        mergeScheduler.merge(this, MergeTrigger.COMMIT, true);\n        long mergeWaitStart = System.nanoTime();\n        int abandonedCount = 0;\n        long waitTimeMillis = (long) (config.getMaxCommitMergeWaitSeconds() * 1000.0);\n        try {\n          if (mergeAwaitLatch.await(waitTimeMillis, TimeUnit.MILLISECONDS) == false) {\n            synchronized (this) {\n              // Need to do this in a synchronized block, to make sure none of our commit merges are currently\n              // executing mergeFinished (since mergeFinished itself is called from within the IndexWriter lock).\n              // After we clear the value from mergeAwaitLatchRef, the merges we schedule will still execute as\n              // usual, but when they finish, they won't attempt to update toCommit or modify segment reference\n              // counts.\n              mergeAwaitLatchRef.set(null);\n              for (MergePolicy.OneMerge commitMerge : commitMerges) {\n                if (runningMerges.contains(commitMerge) || pendingMerges.contains(commitMerge)) {\n                  abandonedCount++;\n                }\n              }\n            }\n          }\n        } catch (InterruptedException e) {\n          Thread.interrupted();\n          throw new IOException(\"Interrupted waiting for merges\");\n        } finally {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", String.format(Locale.ROOT, \"Waited %.1f ms for commit merges\",\n                (System.nanoTime() - mergeWaitStart)/1_000_000.0));\n            infoStream.message(\"IW\", \"After executing commit merges, had \" + toCommit.size() + \" segments\");\n            if (abandonedCount > 0) {\n              infoStream.message(\"IW\", \"Abandoned \" + abandonedCount + \" commit merges after \" + waitTimeMillis + \" ms\");\n            }\n          }\n          if (abandonedCount > 0) {\n            config.getIndexWriterEvents().abandonedMergesOnCommit(abandonedCount);\n          }\n          config.getIndexWriterEvents().finishMergeOnCommit();\n        }\n      }\n      filesToCommit = toCommit.files(false);\n     \n      try {\n        if (anyChanges) {\n          maybeMerge.set(true);\n        }\n        startCommit(toCommit);\n        if (pendingCommit == null) {\n          return -1;\n        } else {\n          return seqNo;\n        }\n      } catch (Throwable t) {\n        synchronized (this) {\n          if (filesToCommit != null) {\n            try {\n              deleter.decRef(filesToCommit);\n            } catch (Throwable t1) {\n              t.addSuppressed(t1);\n            } finally {\n              filesToCommit = null;\n            }\n          }\n        }\n        throw t;\n      }\n    }\n  }\n\n","sourceOld":"  private long prepareCommitInternal() throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy.get() != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy.get());\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anyChanges = false;\n      long seqNo;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads();\n            if (seqNo < 0) {\n              anyChanges = true;\n              seqNo = -seqNo;\n            }\n            if (anyChanges == false) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            publishFlushedSegments(true);\n            // cannot pass triggerMerges=true here else it can lead to deadlock:\n            processEvents(false);\n            \n            flushSuccess = true;\n\n            applyAllDeletesAndUpdates();\n            synchronized(this) {\n              writeReaderPool(true);\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              if (commitUserData != null) {\n                Map<String,String> userData = new HashMap<>();\n                for(Map.Entry<String,String> ent : commitUserData) {\n                  userData.put(ent.getKey(), ent.getValue());\n                }\n                segmentInfos.setUserData(userData, false);\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false); \n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            assert holdsFullFlushLock();\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n        throw tragedy;\n      } finally {\n        maybeCloseOnTragicEvent();\n      }\n     \n      try {\n        if (anyChanges) {\n          maybeMerge.set(true);\n        }\n        startCommit(toCommit);\n        if (pendingCommit == null) {\n          return -1;\n        } else {\n          return seqNo;\n        }\n      } catch (Throwable t) {\n        synchronized (this) {\n          if (filesToCommit != null) {\n            try {\n              deleter.decRef(filesToCommit);\n            } catch (Throwable t1) {\n              t.addSuppressed(t1);\n            } finally {\n              filesToCommit = null;\n            }\n          }\n        }\n        throw t;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0a0fba1d4c4dd09bd1f7d6779090d0942bf071d0","date":1583191752,"type":3,"author":"msfroh","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal().mjava","sourceNew":"  private long prepareCommitInternal() throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy.get() != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy.get());\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anyChanges = false;\n      long seqNo;\n      List<MergePolicy.OneMerge> commitMerges = null;\n      AtomicReference<CountDownLatch> mergeAwaitLatchRef = null;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads();\n            if (seqNo < 0) {\n              anyChanges = true;\n              seqNo = -seqNo;\n            }\n            if (anyChanges == false) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            publishFlushedSegments(true);\n            // cannot pass triggerMerges=true here else it can lead to deadlock:\n            processEvents(false);\n            \n            flushSuccess = true;\n\n            applyAllDeletesAndUpdates();\n            synchronized(this) {\n              writeReaderPool(true);\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              if (commitUserData != null) {\n                Map<String,String> userData = new HashMap<>();\n                for(Map.Entry<String,String> ent : commitUserData) {\n                  userData.put(ent.getKey(), ent.getValue());\n                }\n                segmentInfos.setUserData(userData, false);\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              if (anyChanges) {\n                // Find any merges that can execute on commit (per MergePolicy).\n                MergePolicy.MergeSpecification mergeSpec =\n                    config.getMergePolicy().findFullFlushMerges(MergeTrigger.COMMIT, segmentInfos, this);\n                if (mergeSpec != null && mergeSpec.merges.size() > 0) {\n                  int mergeCount = mergeSpec.merges.size();\n                  commitMerges = new ArrayList<>(mergeCount);\n                  mergeAwaitLatchRef = new AtomicReference<>(new CountDownLatch(mergeCount));\n                  for (MergePolicy.OneMerge oneMerge : mergeSpec.merges) {\n                    MergePolicy.OneMerge trackedMerge =\n                        updateSegmentInfosOnMergeFinish(oneMerge, toCommit, mergeAwaitLatchRef);\n                    if (registerMerge(trackedMerge) == false) {\n                      throw new IllegalStateException(\"MergePolicy \" + config.getMergePolicy().getClass() +\n                          \" returned merging segments from findFullFlushMerges\");\n                    }\n                    commitMerges.add(trackedMerge);\n                  }\n                  if (infoStream.isEnabled(\"IW\")) {\n                    infoStream.message(\"IW\", \"Registered \" + mergeCount + \" commit merges\");\n                    infoStream.message(\"IW\", \"Before executing commit merges, had \" + toCommit.size() + \" segments\");\n                  }\n                }\n              }\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              deleter.incRef(toCommit.files(false));\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            assert holdsFullFlushLock();\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n        throw tragedy;\n      } finally {\n        maybeCloseOnTragicEvent();\n      }\n\n      if (mergeAwaitLatchRef != null) {\n        CountDownLatch mergeAwaitLatch = mergeAwaitLatchRef.get();\n        // If we found and registered any merges above, within the flushLock, then we want to ensure that they\n        // complete execution. Note that since we released the lock, other merges may have been scheduled. We will\n        // block until  the merges that we registered complete. As they complete, they will update toCommit to\n        // replace merged segments with the result of each merge.\n        config.getIndexWriterEvents().beginMergeOnCommit();\n        mergeScheduler.merge(this, MergeTrigger.COMMIT, true);\n        long mergeWaitStart = System.nanoTime();\n        int abandonedCount = 0;\n        long waitTimeMillis = (long) (config.getMaxCommitMergeWaitSeconds() * 1000.0);\n        try {\n          if (mergeAwaitLatch.await(waitTimeMillis, TimeUnit.MILLISECONDS) == false) {\n            synchronized (this) {\n              // Need to do this in a synchronized block, to make sure none of our commit merges are currently\n              // executing mergeFinished (since mergeFinished itself is called from within the IndexWriter lock).\n              // After we clear the value from mergeAwaitLatchRef, the merges we schedule will still execute as\n              // usual, but when they finish, they won't attempt to update toCommit or modify segment reference\n              // counts.\n              mergeAwaitLatchRef.set(null);\n              for (MergePolicy.OneMerge commitMerge : commitMerges) {\n                if (runningMerges.contains(commitMerge) || pendingMerges.contains(commitMerge)) {\n                  abandonedCount++;\n                }\n              }\n            }\n          }\n        } catch (InterruptedException ie) {\n          throw new ThreadInterruptedException(ie);\n        } finally {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", String.format(Locale.ROOT, \"Waited %.1f ms for commit merges\",\n                (System.nanoTime() - mergeWaitStart)/1_000_000.0));\n            infoStream.message(\"IW\", \"After executing commit merges, had \" + toCommit.size() + \" segments\");\n            if (abandonedCount > 0) {\n              infoStream.message(\"IW\", \"Abandoned \" + abandonedCount + \" commit merges after \" + waitTimeMillis + \" ms\");\n            }\n          }\n          if (abandonedCount > 0) {\n            config.getIndexWriterEvents().abandonedMergesOnCommit(abandonedCount);\n          }\n          config.getIndexWriterEvents().finishMergeOnCommit();\n        }\n      }\n      filesToCommit = toCommit.files(false);\n     \n      try {\n        if (anyChanges) {\n          maybeMerge.set(true);\n        }\n        startCommit(toCommit);\n        if (pendingCommit == null) {\n          return -1;\n        } else {\n          return seqNo;\n        }\n      } catch (Throwable t) {\n        synchronized (this) {\n          if (filesToCommit != null) {\n            try {\n              deleter.decRef(filesToCommit);\n            } catch (Throwable t1) {\n              t.addSuppressed(t1);\n            } finally {\n              filesToCommit = null;\n            }\n          }\n        }\n        throw t;\n      }\n    }\n  }\n\n","sourceOld":"  private long prepareCommitInternal() throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy.get() != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy.get());\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anyChanges = false;\n      long seqNo;\n      List<MergePolicy.OneMerge> commitMerges = null;\n      AtomicReference<CountDownLatch> mergeAwaitLatchRef = null;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads();\n            if (seqNo < 0) {\n              anyChanges = true;\n              seqNo = -seqNo;\n            }\n            if (anyChanges == false) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            publishFlushedSegments(true);\n            // cannot pass triggerMerges=true here else it can lead to deadlock:\n            processEvents(false);\n            \n            flushSuccess = true;\n\n            applyAllDeletesAndUpdates();\n            synchronized(this) {\n              writeReaderPool(true);\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              if (commitUserData != null) {\n                Map<String,String> userData = new HashMap<>();\n                for(Map.Entry<String,String> ent : commitUserData) {\n                  userData.put(ent.getKey(), ent.getValue());\n                }\n                segmentInfos.setUserData(userData, false);\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              if (anyChanges) {\n                // Find any merges that can execute on commit (per MergePolicy).\n                MergePolicy.MergeSpecification mergeSpec =\n                    config.getMergePolicy().findFullFlushMerges(MergeTrigger.COMMIT, segmentInfos, this);\n                if (mergeSpec != null && mergeSpec.merges.size() > 0) {\n                  int mergeCount = mergeSpec.merges.size();\n                  commitMerges = new ArrayList<>(mergeCount);\n                  mergeAwaitLatchRef = new AtomicReference<>(new CountDownLatch(mergeCount));\n                  for (MergePolicy.OneMerge oneMerge : mergeSpec.merges) {\n                    MergePolicy.OneMerge trackedMerge =\n                        updateSegmentInfosOnMergeFinish(oneMerge, toCommit, mergeAwaitLatchRef);\n                    if (registerMerge(trackedMerge) == false) {\n                      throw new IllegalStateException(\"MergePolicy \" + config.getMergePolicy().getClass() +\n                          \" returned merging segments from findFullFlushMerges\");\n                    }\n                    commitMerges.add(trackedMerge);\n                  }\n                  if (infoStream.isEnabled(\"IW\")) {\n                    infoStream.message(\"IW\", \"Registered \" + mergeCount + \" commit merges\");\n                    infoStream.message(\"IW\", \"Before executing commit merges, had \" + toCommit.size() + \" segments\");\n                  }\n                }\n              }\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              deleter.incRef(toCommit.files(false));\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            assert holdsFullFlushLock();\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n        throw tragedy;\n      } finally {\n        maybeCloseOnTragicEvent();\n      }\n\n      if (mergeAwaitLatchRef != null) {\n        CountDownLatch mergeAwaitLatch = mergeAwaitLatchRef.get();\n        // If we found and registered any merges above, within the flushLock, then we want to ensure that they\n        // complete execution. Note that since we released the lock, other merges may have been scheduled. We will\n        // block until  the merges that we registered complete. As they complete, they will update toCommit to\n        // replace merged segments with the result of each merge.\n        config.getIndexWriterEvents().beginMergeOnCommit();\n        mergeScheduler.merge(this, MergeTrigger.COMMIT, true);\n        long mergeWaitStart = System.nanoTime();\n        int abandonedCount = 0;\n        long waitTimeMillis = (long) (config.getMaxCommitMergeWaitSeconds() * 1000.0);\n        try {\n          if (mergeAwaitLatch.await(waitTimeMillis, TimeUnit.MILLISECONDS) == false) {\n            synchronized (this) {\n              // Need to do this in a synchronized block, to make sure none of our commit merges are currently\n              // executing mergeFinished (since mergeFinished itself is called from within the IndexWriter lock).\n              // After we clear the value from mergeAwaitLatchRef, the merges we schedule will still execute as\n              // usual, but when they finish, they won't attempt to update toCommit or modify segment reference\n              // counts.\n              mergeAwaitLatchRef.set(null);\n              for (MergePolicy.OneMerge commitMerge : commitMerges) {\n                if (runningMerges.contains(commitMerge) || pendingMerges.contains(commitMerge)) {\n                  abandonedCount++;\n                }\n              }\n            }\n          }\n        } catch (InterruptedException e) {\n          Thread.interrupted();\n          throw new IOException(\"Interrupted waiting for merges\");\n        } finally {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", String.format(Locale.ROOT, \"Waited %.1f ms for commit merges\",\n                (System.nanoTime() - mergeWaitStart)/1_000_000.0));\n            infoStream.message(\"IW\", \"After executing commit merges, had \" + toCommit.size() + \" segments\");\n            if (abandonedCount > 0) {\n              infoStream.message(\"IW\", \"Abandoned \" + abandonedCount + \" commit merges after \" + waitTimeMillis + \" ms\");\n            }\n          }\n          if (abandonedCount > 0) {\n            config.getIndexWriterEvents().abandonedMergesOnCommit(abandonedCount);\n          }\n          config.getIndexWriterEvents().finishMergeOnCommit();\n        }\n      }\n      filesToCommit = toCommit.files(false);\n     \n      try {\n        if (anyChanges) {\n          maybeMerge.set(true);\n        }\n        startCommit(toCommit);\n        if (pendingCommit == null) {\n          return -1;\n        } else {\n          return seqNo;\n        }\n      } catch (Throwable t) {\n        synchronized (this) {\n          if (filesToCommit != null) {\n            try {\n              deleter.decRef(filesToCommit);\n            } catch (Throwable t1) {\n              t.addSuppressed(t1);\n            } finally {\n              filesToCommit = null;\n            }\n          }\n        }\n        throw t;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ba192a321314de8edbe20b279eee9c471b16b48b","date":1583706474,"type":3,"author":"Michael Sokolov","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal().mjava","sourceNew":"  private long prepareCommitInternal() throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy.get() != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy.get());\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anyChanges = false;\n      long seqNo;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads();\n            if (seqNo < 0) {\n              anyChanges = true;\n              seqNo = -seqNo;\n            }\n            if (anyChanges == false) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            publishFlushedSegments(true);\n            // cannot pass triggerMerges=true here else it can lead to deadlock:\n            processEvents(false);\n            \n            flushSuccess = true;\n\n            applyAllDeletesAndUpdates();\n            synchronized(this) {\n              writeReaderPool(true);\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              if (commitUserData != null) {\n                Map<String,String> userData = new HashMap<>();\n                for(Map.Entry<String,String> ent : commitUserData) {\n                  userData.put(ent.getKey(), ent.getValue());\n                }\n                segmentInfos.setUserData(userData, false);\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false); \n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            assert holdsFullFlushLock();\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n        throw tragedy;\n      } finally {\n        maybeCloseOnTragicEvent();\n      }\n     \n      try {\n        if (anyChanges) {\n          maybeMerge.set(true);\n        }\n        startCommit(toCommit);\n        if (pendingCommit == null) {\n          return -1;\n        } else {\n          return seqNo;\n        }\n      } catch (Throwable t) {\n        synchronized (this) {\n          if (filesToCommit != null) {\n            try {\n              deleter.decRef(filesToCommit);\n            } catch (Throwable t1) {\n              t.addSuppressed(t1);\n            } finally {\n              filesToCommit = null;\n            }\n          }\n        }\n        throw t;\n      }\n    }\n  }\n\n","sourceOld":"  private long prepareCommitInternal() throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy.get() != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy.get());\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anyChanges = false;\n      long seqNo;\n      List<MergePolicy.OneMerge> commitMerges = null;\n      AtomicReference<CountDownLatch> mergeAwaitLatchRef = null;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads();\n            if (seqNo < 0) {\n              anyChanges = true;\n              seqNo = -seqNo;\n            }\n            if (anyChanges == false) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            publishFlushedSegments(true);\n            // cannot pass triggerMerges=true here else it can lead to deadlock:\n            processEvents(false);\n            \n            flushSuccess = true;\n\n            applyAllDeletesAndUpdates();\n            synchronized(this) {\n              writeReaderPool(true);\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              if (commitUserData != null) {\n                Map<String,String> userData = new HashMap<>();\n                for(Map.Entry<String,String> ent : commitUserData) {\n                  userData.put(ent.getKey(), ent.getValue());\n                }\n                segmentInfos.setUserData(userData, false);\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              if (anyChanges) {\n                // Find any merges that can execute on commit (per MergePolicy).\n                MergePolicy.MergeSpecification mergeSpec =\n                    config.getMergePolicy().findFullFlushMerges(MergeTrigger.COMMIT, segmentInfos, this);\n                if (mergeSpec != null && mergeSpec.merges.size() > 0) {\n                  int mergeCount = mergeSpec.merges.size();\n                  commitMerges = new ArrayList<>(mergeCount);\n                  mergeAwaitLatchRef = new AtomicReference<>(new CountDownLatch(mergeCount));\n                  for (MergePolicy.OneMerge oneMerge : mergeSpec.merges) {\n                    MergePolicy.OneMerge trackedMerge =\n                        updateSegmentInfosOnMergeFinish(oneMerge, toCommit, mergeAwaitLatchRef);\n                    if (registerMerge(trackedMerge) == false) {\n                      throw new IllegalStateException(\"MergePolicy \" + config.getMergePolicy().getClass() +\n                          \" returned merging segments from findFullFlushMerges\");\n                    }\n                    commitMerges.add(trackedMerge);\n                  }\n                  if (infoStream.isEnabled(\"IW\")) {\n                    infoStream.message(\"IW\", \"Registered \" + mergeCount + \" commit merges\");\n                    infoStream.message(\"IW\", \"Before executing commit merges, had \" + toCommit.size() + \" segments\");\n                  }\n                }\n              }\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              deleter.incRef(toCommit.files(false));\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            assert holdsFullFlushLock();\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n        throw tragedy;\n      } finally {\n        maybeCloseOnTragicEvent();\n      }\n\n      if (mergeAwaitLatchRef != null) {\n        CountDownLatch mergeAwaitLatch = mergeAwaitLatchRef.get();\n        // If we found and registered any merges above, within the flushLock, then we want to ensure that they\n        // complete execution. Note that since we released the lock, other merges may have been scheduled. We will\n        // block until  the merges that we registered complete. As they complete, they will update toCommit to\n        // replace merged segments with the result of each merge.\n        config.getIndexWriterEvents().beginMergeOnCommit();\n        mergeScheduler.merge(this, MergeTrigger.COMMIT, true);\n        long mergeWaitStart = System.nanoTime();\n        int abandonedCount = 0;\n        long waitTimeMillis = (long) (config.getMaxCommitMergeWaitSeconds() * 1000.0);\n        try {\n          if (mergeAwaitLatch.await(waitTimeMillis, TimeUnit.MILLISECONDS) == false) {\n            synchronized (this) {\n              // Need to do this in a synchronized block, to make sure none of our commit merges are currently\n              // executing mergeFinished (since mergeFinished itself is called from within the IndexWriter lock).\n              // After we clear the value from mergeAwaitLatchRef, the merges we schedule will still execute as\n              // usual, but when they finish, they won't attempt to update toCommit or modify segment reference\n              // counts.\n              mergeAwaitLatchRef.set(null);\n              for (MergePolicy.OneMerge commitMerge : commitMerges) {\n                if (runningMerges.contains(commitMerge) || pendingMerges.contains(commitMerge)) {\n                  abandonedCount++;\n                }\n              }\n            }\n          }\n        } catch (InterruptedException ie) {\n          throw new ThreadInterruptedException(ie);\n        } finally {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", String.format(Locale.ROOT, \"Waited %.1f ms for commit merges\",\n                (System.nanoTime() - mergeWaitStart)/1_000_000.0));\n            infoStream.message(\"IW\", \"After executing commit merges, had \" + toCommit.size() + \" segments\");\n            if (abandonedCount > 0) {\n              infoStream.message(\"IW\", \"Abandoned \" + abandonedCount + \" commit merges after \" + waitTimeMillis + \" ms\");\n            }\n          }\n          if (abandonedCount > 0) {\n            config.getIndexWriterEvents().abandonedMergesOnCommit(abandonedCount);\n          }\n          config.getIndexWriterEvents().finishMergeOnCommit();\n        }\n      }\n      filesToCommit = toCommit.files(false);\n     \n      try {\n        if (anyChanges) {\n          maybeMerge.set(true);\n        }\n        startCommit(toCommit);\n        if (pendingCommit == null) {\n          return -1;\n        } else {\n          return seqNo;\n        }\n      } catch (Throwable t) {\n        synchronized (this) {\n          if (filesToCommit != null) {\n            try {\n              deleter.decRef(filesToCommit);\n            } catch (Throwable t1) {\n              t.addSuppressed(t1);\n            } finally {\n              filesToCommit = null;\n            }\n          }\n        }\n        throw t;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8a428f5314daaabf8eab7c50bdc3bc14e6cd1aa2","date":1588002560,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal().mjava","sourceNew":"  private long prepareCommitInternal() throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy.get() != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy.get());\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anyChanges = false;\n      long seqNo;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads();\n            if (seqNo < 0) {\n              anyChanges = true;\n              seqNo = -seqNo;\n            }\n            if (anyChanges == false) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            publishFlushedSegments(true);\n            // cannot pass triggerMerges=true here else it can lead to deadlock:\n            processEvents(false);\n            \n            flushSuccess = true;\n\n            applyAllDeletesAndUpdates();\n            synchronized(this) {\n              writeReaderPool(true);\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              if (commitUserData != null) {\n                Map<String,String> userData = new HashMap<>();\n                for(Map.Entry<String,String> ent : commitUserData) {\n                  userData.put(ent.getKey(), ent.getValue());\n                }\n                segmentInfos.setUserData(userData, false);\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false); \n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            assert Thread.holdsLock(fullFlushLock);\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n        throw tragedy;\n      } finally {\n        maybeCloseOnTragicEvent();\n      }\n     \n      try {\n        if (anyChanges) {\n          maybeMerge.set(true);\n        }\n        startCommit(toCommit);\n        if (pendingCommit == null) {\n          return -1;\n        } else {\n          return seqNo;\n        }\n      } catch (Throwable t) {\n        synchronized (this) {\n          if (filesToCommit != null) {\n            try {\n              deleter.decRef(filesToCommit);\n            } catch (Throwable t1) {\n              t.addSuppressed(t1);\n            } finally {\n              filesToCommit = null;\n            }\n          }\n        }\n        throw t;\n      }\n    }\n  }\n\n","sourceOld":"  private long prepareCommitInternal() throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy.get() != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy.get());\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anyChanges = false;\n      long seqNo;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads();\n            if (seqNo < 0) {\n              anyChanges = true;\n              seqNo = -seqNo;\n            }\n            if (anyChanges == false) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            publishFlushedSegments(true);\n            // cannot pass triggerMerges=true here else it can lead to deadlock:\n            processEvents(false);\n            \n            flushSuccess = true;\n\n            applyAllDeletesAndUpdates();\n            synchronized(this) {\n              writeReaderPool(true);\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              if (commitUserData != null) {\n                Map<String,String> userData = new HashMap<>();\n                for(Map.Entry<String,String> ent : commitUserData) {\n                  userData.put(ent.getKey(), ent.getValue());\n                }\n                segmentInfos.setUserData(userData, false);\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false); \n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            assert holdsFullFlushLock();\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n        throw tragedy;\n      } finally {\n        maybeCloseOnTragicEvent();\n      }\n     \n      try {\n        if (anyChanges) {\n          maybeMerge.set(true);\n        }\n        startCommit(toCommit);\n        if (pendingCommit == null) {\n          return -1;\n        } else {\n          return seqNo;\n        }\n      } catch (Throwable t) {\n        synchronized (this) {\n          if (filesToCommit != null) {\n            try {\n              deleter.decRef(filesToCommit);\n            } catch (Throwable t1) {\n              t.addSuppressed(t1);\n            } finally {\n              filesToCommit = null;\n            }\n          }\n        }\n        throw t;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fe39f1a106531207c028defebbc9eb5bb489ac50","date":1592513789,"type":3,"author":"Michael Sokolov","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal().mjava","sourceNew":"  private long prepareCommitInternal() throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy.get() != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy.get());\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anyChanges = false;\n      long seqNo;\n      MergePolicy.MergeSpecification onCommitMerges = null;\n      AtomicBoolean includeInCommit = new AtomicBoolean(true);\n      final long maxCommitMergeWaitSeconds = config.getMaxCommitMergeWaitSeconds();\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads();\n            if (seqNo < 0) {\n              anyChanges = true;\n              seqNo = -seqNo;\n            }\n            if (anyChanges == false) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            publishFlushedSegments(true);\n            // cannot pass triggerMerges=true here else it can lead to deadlock:\n            processEvents(false);\n            \n            flushSuccess = true;\n\n            applyAllDeletesAndUpdates();\n            synchronized(this) {\n              writeReaderPool(true);\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              if (commitUserData != null) {\n                Map<String,String> userData = new HashMap<>();\n                for(Map.Entry<String,String> ent : commitUserData) {\n                  userData.put(ent.getKey(), ent.getValue());\n                }\n                segmentInfos.setUserData(userData, false);\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              if (anyChanges && maxCommitMergeWaitSeconds > 0) {\n                SegmentInfos committingSegmentInfos = toCommit;\n                onCommitMerges = updatePendingMerges(new OneMergeWrappingMergePolicy(config.getMergePolicy(), toWrap ->\n                    new MergePolicy.OneMerge(toWrap.segments) {\n                      @Override\n                      public void mergeFinished(boolean committed) throws IOException {\n                        assert Thread.holdsLock(IndexWriter.this);\n                        if (committed && includeInCommit.get()) {\n                          deleter.incRef(info.files());\n                          Set<String> mergedSegmentNames = new HashSet<>();\n                          for (SegmentCommitInfo sci : segments) {\n                            mergedSegmentNames.add(sci.info.name);\n                          }\n                          List<SegmentCommitInfo> toCommitMergedAwaySegments = new ArrayList<>();\n                          for (SegmentCommitInfo sci : committingSegmentInfos) {\n                            if (mergedSegmentNames.contains(sci.info.name)) {\n                              toCommitMergedAwaySegments.add(sci);\n                              deleter.decRef(sci.files());\n                            }\n                          }\n                          // Construct a OneMerge that applies to toCommit\n                          MergePolicy.OneMerge applicableMerge = new MergePolicy.OneMerge(toCommitMergedAwaySegments);\n                          applicableMerge.info = info.clone();\n                          long segmentCounter = Long.parseLong(info.info.name.substring(1), Character.MAX_RADIX);\n                          committingSegmentInfos.counter = Math.max(committingSegmentInfos.counter, segmentCounter + 1);\n                          committingSegmentInfos.applyMergeChanges(applicableMerge, false);\n                        }\n                        toWrap.mergeFinished(committed);\n                        super.mergeFinished(committed);\n                      }\n\n                      @Override\n                      public CodecReader wrapForMerge(CodecReader reader) throws IOException {\n                        return toWrap.wrapForMerge(reader);\n                      }\n                    }\n                ), MergeTrigger.COMMIT, UNBOUNDED_MAX_MERGE_SEGMENTS);\n              }\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              deleter.incRef(toCommit.files(false));\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            assert Thread.holdsLock(fullFlushLock);\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n        throw tragedy;\n      } finally {\n        maybeCloseOnTragicEvent();\n      }\n\n      if (onCommitMerges != null) {\n        mergeScheduler.merge(mergeSource, MergeTrigger.COMMIT);\n        onCommitMerges.await(maxCommitMergeWaitSeconds, TimeUnit.SECONDS);\n        synchronized (this) {\n          // we need to call this under lock since mergeFinished above is also called under the IW lock\n          includeInCommit.set(false);\n        }\n      }\n      filesToCommit = toCommit.files(false);\n      try {\n        if (anyChanges) {\n          maybeMerge.set(true);\n        }\n        startCommit(toCommit);\n        if (pendingCommit == null) {\n          return -1;\n        } else {\n          return seqNo;\n        }\n      } catch (Throwable t) {\n        synchronized (this) {\n          if (filesToCommit != null) {\n            try {\n              deleter.decRef(filesToCommit);\n            } catch (Throwable t1) {\n              t.addSuppressed(t1);\n            } finally {\n              filesToCommit = null;\n            }\n          }\n        }\n        throw t;\n      }\n    }\n  }\n\n","sourceOld":"  private long prepareCommitInternal() throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy.get() != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy.get());\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anyChanges = false;\n      long seqNo;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads();\n            if (seqNo < 0) {\n              anyChanges = true;\n              seqNo = -seqNo;\n            }\n            if (anyChanges == false) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            publishFlushedSegments(true);\n            // cannot pass triggerMerges=true here else it can lead to deadlock:\n            processEvents(false);\n            \n            flushSuccess = true;\n\n            applyAllDeletesAndUpdates();\n            synchronized(this) {\n              writeReaderPool(true);\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              if (commitUserData != null) {\n                Map<String,String> userData = new HashMap<>();\n                for(Map.Entry<String,String> ent : commitUserData) {\n                  userData.put(ent.getKey(), ent.getValue());\n                }\n                segmentInfos.setUserData(userData, false);\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false); \n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            assert Thread.holdsLock(fullFlushLock);\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n        throw tragedy;\n      } finally {\n        maybeCloseOnTragicEvent();\n      }\n     \n      try {\n        if (anyChanges) {\n          maybeMerge.set(true);\n        }\n        startCommit(toCommit);\n        if (pendingCommit == null) {\n          return -1;\n        } else {\n          return seqNo;\n        }\n      } catch (Throwable t) {\n        synchronized (this) {\n          if (filesToCommit != null) {\n            try {\n              deleter.decRef(filesToCommit);\n            } catch (Throwable t1) {\n              t.addSuppressed(t1);\n            } finally {\n              filesToCommit = null;\n            }\n          }\n        }\n        throw t;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1182fe36fb5df768dc2da53f6d5338cbc07268ae","date":1592861749,"type":3,"author":"Michael Sokolov","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal().mjava","sourceNew":"  private long prepareCommitInternal() throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy.get() != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy.get());\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anyChanges = false;\n      long seqNo;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads();\n            if (seqNo < 0) {\n              anyChanges = true;\n              seqNo = -seqNo;\n            }\n            if (anyChanges == false) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            publishFlushedSegments(true);\n            // cannot pass triggerMerges=true here else it can lead to deadlock:\n            processEvents(false);\n            \n            flushSuccess = true;\n\n            applyAllDeletesAndUpdates();\n            synchronized(this) {\n              writeReaderPool(true);\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              if (commitUserData != null) {\n                Map<String,String> userData = new HashMap<>();\n                for(Map.Entry<String,String> ent : commitUserData) {\n                  userData.put(ent.getKey(), ent.getValue());\n                }\n                segmentInfos.setUserData(userData, false);\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false); \n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            assert Thread.holdsLock(fullFlushLock);\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n        throw tragedy;\n      } finally {\n        maybeCloseOnTragicEvent();\n      }\n     \n      try {\n        if (anyChanges) {\n          maybeMerge.set(true);\n        }\n        startCommit(toCommit);\n        if (pendingCommit == null) {\n          return -1;\n        } else {\n          return seqNo;\n        }\n      } catch (Throwable t) {\n        synchronized (this) {\n          if (filesToCommit != null) {\n            try {\n              deleter.decRef(filesToCommit);\n            } catch (Throwable t1) {\n              t.addSuppressed(t1);\n            } finally {\n              filesToCommit = null;\n            }\n          }\n        }\n        throw t;\n      }\n    }\n  }\n\n","sourceOld":"  private long prepareCommitInternal() throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy.get() != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy.get());\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anyChanges = false;\n      long seqNo;\n      MergePolicy.MergeSpecification onCommitMerges = null;\n      AtomicBoolean includeInCommit = new AtomicBoolean(true);\n      final long maxCommitMergeWaitSeconds = config.getMaxCommitMergeWaitSeconds();\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads();\n            if (seqNo < 0) {\n              anyChanges = true;\n              seqNo = -seqNo;\n            }\n            if (anyChanges == false) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            publishFlushedSegments(true);\n            // cannot pass triggerMerges=true here else it can lead to deadlock:\n            processEvents(false);\n            \n            flushSuccess = true;\n\n            applyAllDeletesAndUpdates();\n            synchronized(this) {\n              writeReaderPool(true);\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              if (commitUserData != null) {\n                Map<String,String> userData = new HashMap<>();\n                for(Map.Entry<String,String> ent : commitUserData) {\n                  userData.put(ent.getKey(), ent.getValue());\n                }\n                segmentInfos.setUserData(userData, false);\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              if (anyChanges && maxCommitMergeWaitSeconds > 0) {\n                SegmentInfos committingSegmentInfos = toCommit;\n                onCommitMerges = updatePendingMerges(new OneMergeWrappingMergePolicy(config.getMergePolicy(), toWrap ->\n                    new MergePolicy.OneMerge(toWrap.segments) {\n                      @Override\n                      public void mergeFinished(boolean committed) throws IOException {\n                        assert Thread.holdsLock(IndexWriter.this);\n                        if (committed && includeInCommit.get()) {\n                          deleter.incRef(info.files());\n                          Set<String> mergedSegmentNames = new HashSet<>();\n                          for (SegmentCommitInfo sci : segments) {\n                            mergedSegmentNames.add(sci.info.name);\n                          }\n                          List<SegmentCommitInfo> toCommitMergedAwaySegments = new ArrayList<>();\n                          for (SegmentCommitInfo sci : committingSegmentInfos) {\n                            if (mergedSegmentNames.contains(sci.info.name)) {\n                              toCommitMergedAwaySegments.add(sci);\n                              deleter.decRef(sci.files());\n                            }\n                          }\n                          // Construct a OneMerge that applies to toCommit\n                          MergePolicy.OneMerge applicableMerge = new MergePolicy.OneMerge(toCommitMergedAwaySegments);\n                          applicableMerge.info = info.clone();\n                          long segmentCounter = Long.parseLong(info.info.name.substring(1), Character.MAX_RADIX);\n                          committingSegmentInfos.counter = Math.max(committingSegmentInfos.counter, segmentCounter + 1);\n                          committingSegmentInfos.applyMergeChanges(applicableMerge, false);\n                        }\n                        toWrap.mergeFinished(committed);\n                        super.mergeFinished(committed);\n                      }\n\n                      @Override\n                      public CodecReader wrapForMerge(CodecReader reader) throws IOException {\n                        return toWrap.wrapForMerge(reader);\n                      }\n                    }\n                ), MergeTrigger.COMMIT, UNBOUNDED_MAX_MERGE_SEGMENTS);\n              }\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              deleter.incRef(toCommit.files(false));\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            assert Thread.holdsLock(fullFlushLock);\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n        throw tragedy;\n      } finally {\n        maybeCloseOnTragicEvent();\n      }\n\n      if (onCommitMerges != null) {\n        mergeScheduler.merge(mergeSource, MergeTrigger.COMMIT);\n        onCommitMerges.await(maxCommitMergeWaitSeconds, TimeUnit.SECONDS);\n        synchronized (this) {\n          // we need to call this under lock since mergeFinished above is also called under the IW lock\n          includeInCommit.set(false);\n        }\n      }\n      filesToCommit = toCommit.files(false);\n      try {\n        if (anyChanges) {\n          maybeMerge.set(true);\n        }\n        startCommit(toCommit);\n        if (pendingCommit == null) {\n          return -1;\n        } else {\n          return seqNo;\n        }\n      } catch (Throwable t) {\n        synchronized (this) {\n          if (filesToCommit != null) {\n            try {\n              deleter.decRef(filesToCommit);\n            } catch (Throwable t1) {\n              t.addSuppressed(t1);\n            } finally {\n              filesToCommit = null;\n            }\n          }\n        }\n        throw t;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c2a23476693f2bd9a4b44cc3187c429a2e21dac2","date":1593289545,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal().mjava","sourceNew":"  private long prepareCommitInternal() throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy.get() != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy.get());\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anyChanges = false;\n      long seqNo;\n      MergePolicy.MergeSpecification onCommitMerges = null;\n      AtomicBoolean includeInCommit = new AtomicBoolean(true);\n      final long maxCommitMergeWaitMillis = config.getMaxCommitMergeWaitMillis();\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads();\n            if (seqNo < 0) {\n              anyChanges = true;\n              seqNo = -seqNo;\n            }\n            if (anyChanges == false) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            publishFlushedSegments(true);\n            // cannot pass triggerMerges=true here else it can lead to deadlock:\n            processEvents(false);\n            \n            flushSuccess = true;\n\n            applyAllDeletesAndUpdates();\n            synchronized(this) {\n              writeReaderPool(true);\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              if (commitUserData != null) {\n                Map<String,String> userData = new HashMap<>();\n                for(Map.Entry<String,String> ent : commitUserData) {\n                  userData.put(ent.getKey(), ent.getValue());\n                }\n                segmentInfos.setUserData(userData, false);\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n              pendingCommitChangeCount = changeCount.get();\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.\n              deleter.incRef(toCommit.files(false));\n              if (anyChanges && maxCommitMergeWaitMillis > 0) {\n                // we can safely call prepareOnCommitMerge since writeReaderPool(true) above wrote all\n                // necessary files to disk and checkpointed them.\n                onCommitMerges = prepareOnCommitMerge(toCommit, includeInCommit);\n              }\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            assert Thread.holdsLock(fullFlushLock);\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n        throw tragedy;\n      } finally {\n        maybeCloseOnTragicEvent();\n      }\n\n      if (onCommitMerges != null) {\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"now run merges during commit: \" + onCommitMerges.segString(directory));\n        }\n        mergeScheduler.merge(mergeSource, MergeTrigger.COMMIT);\n        onCommitMerges.await(maxCommitMergeWaitMillis, TimeUnit.MILLISECONDS);\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"done waiting for merges during commit\");\n        }\n        synchronized (this) {\n          // we need to call this under lock since mergeFinished above is also called under the IW lock\n          includeInCommit.set(false);\n        }\n      }\n      // do this after handling any onCommitMerges since the files will have changed if any merges\n      // did complete\n      filesToCommit = toCommit.files(false);\n      try {\n        if (anyChanges) {\n          maybeMerge.set(true);\n        }\n        startCommit(toCommit);\n        if (pendingCommit == null) {\n          return -1;\n        } else {\n          return seqNo;\n        }\n      } catch (Throwable t) {\n        synchronized (this) {\n          if (filesToCommit != null) {\n            try {\n              deleter.decRef(filesToCommit);\n            } catch (Throwable t1) {\n              t.addSuppressed(t1);\n            } finally {\n              filesToCommit = null;\n            }\n          }\n        }\n        throw t;\n      }\n    }\n  }\n\n","sourceOld":"  private long prepareCommitInternal() throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy.get() != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy.get());\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anyChanges = false;\n      long seqNo;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads();\n            if (seqNo < 0) {\n              anyChanges = true;\n              seqNo = -seqNo;\n            }\n            if (anyChanges == false) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            publishFlushedSegments(true);\n            // cannot pass triggerMerges=true here else it can lead to deadlock:\n            processEvents(false);\n            \n            flushSuccess = true;\n\n            applyAllDeletesAndUpdates();\n            synchronized(this) {\n              writeReaderPool(true);\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              if (commitUserData != null) {\n                Map<String,String> userData = new HashMap<>();\n                for(Map.Entry<String,String> ent : commitUserData) {\n                  userData.put(ent.getKey(), ent.getValue());\n                }\n                segmentInfos.setUserData(userData, false);\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false); \n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            assert Thread.holdsLock(fullFlushLock);\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n        throw tragedy;\n      } finally {\n        maybeCloseOnTragicEvent();\n      }\n     \n      try {\n        if (anyChanges) {\n          maybeMerge.set(true);\n        }\n        startCommit(toCommit);\n        if (pendingCommit == null) {\n          return -1;\n        } else {\n          return seqNo;\n        }\n      } catch (Throwable t) {\n        synchronized (this) {\n          if (filesToCommit != null) {\n            try {\n              deleter.decRef(filesToCommit);\n            } catch (Throwable t1) {\n              t.addSuppressed(t1);\n            } finally {\n              filesToCommit = null;\n            }\n          }\n        }\n        throw t;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3f354ba79a5a3e8491ec2953f14f365a02c058ac","date":1598293148,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal().mjava","sourceNew":"  private long prepareCommitInternal() throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy.get() != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy.get());\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anyChanges = false;\n      long seqNo;\n      MergePolicy.MergeSpecification pointInTimeMerges = null;\n      AtomicBoolean stopAddingMergedSegments = new AtomicBoolean(false);\n      final long maxCommitMergeWaitMillis = config.getMaxFullFlushMergeWaitMillis();\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads();\n            if (seqNo < 0) {\n              anyChanges = true;\n              seqNo = -seqNo;\n            }\n            if (anyChanges == false) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            publishFlushedSegments(true);\n            // cannot pass triggerMerges=true here else it can lead to deadlock:\n            processEvents(false);\n            \n            flushSuccess = true;\n\n            applyAllDeletesAndUpdates();\n            synchronized(this) {\n              writeReaderPool(true);\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              if (commitUserData != null) {\n                Map<String,String> userData = new HashMap<>();\n                for(Map.Entry<String,String> ent : commitUserData) {\n                  userData.put(ent.getKey(), ent.getValue());\n                }\n                segmentInfos.setUserData(userData, false);\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n              pendingCommitChangeCount = changeCount.get();\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.\n              deleter.incRef(toCommit.files(false));\n              if (anyChanges && maxCommitMergeWaitMillis > 0) {\n                // we can safely call preparePointInTimeMerge since writeReaderPool(true) above wrote all\n                // necessary files to disk and checkpointed them.\n                pointInTimeMerges = preparePointInTimeMerge(toCommit, stopAddingMergedSegments::get, MergeTrigger.COMMIT, sci->{});\n              }\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            assert Thread.holdsLock(fullFlushLock);\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n        throw tragedy;\n      } finally {\n        maybeCloseOnTragicEvent();\n      }\n\n      if (pointInTimeMerges != null) {\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"now run merges during commit: \" + pointInTimeMerges.segString(directory));\n        }\n        mergeScheduler.merge(mergeSource, MergeTrigger.COMMIT);\n        pointInTimeMerges.await(maxCommitMergeWaitMillis, TimeUnit.MILLISECONDS);\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"done waiting for merges during commit\");\n        }\n        synchronized (this) {\n          // we need to call this under lock since mergeFinished above is also called under the IW lock\n          stopAddingMergedSegments.set(true);\n        }\n      }\n      // do this after handling any pointInTimeMerges since the files will have changed if any merges\n      // did complete\n      filesToCommit = toCommit.files(false);\n      try {\n        if (anyChanges) {\n          maybeMerge.set(true);\n        }\n        startCommit(toCommit);\n        if (pendingCommit == null) {\n          return -1;\n        } else {\n          return seqNo;\n        }\n      } catch (Throwable t) {\n        synchronized (this) {\n          if (filesToCommit != null) {\n            try {\n              deleter.decRef(filesToCommit);\n            } catch (Throwable t1) {\n              t.addSuppressed(t1);\n            } finally {\n              filesToCommit = null;\n            }\n          }\n        }\n        throw t;\n      }\n    }\n  }\n\n","sourceOld":"  private long prepareCommitInternal() throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy.get() != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy.get());\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anyChanges = false;\n      long seqNo;\n      MergePolicy.MergeSpecification onCommitMerges = null;\n      AtomicBoolean includeInCommit = new AtomicBoolean(true);\n      final long maxCommitMergeWaitMillis = config.getMaxCommitMergeWaitMillis();\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads();\n            if (seqNo < 0) {\n              anyChanges = true;\n              seqNo = -seqNo;\n            }\n            if (anyChanges == false) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            publishFlushedSegments(true);\n            // cannot pass triggerMerges=true here else it can lead to deadlock:\n            processEvents(false);\n            \n            flushSuccess = true;\n\n            applyAllDeletesAndUpdates();\n            synchronized(this) {\n              writeReaderPool(true);\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              if (commitUserData != null) {\n                Map<String,String> userData = new HashMap<>();\n                for(Map.Entry<String,String> ent : commitUserData) {\n                  userData.put(ent.getKey(), ent.getValue());\n                }\n                segmentInfos.setUserData(userData, false);\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n              pendingCommitChangeCount = changeCount.get();\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.\n              deleter.incRef(toCommit.files(false));\n              if (anyChanges && maxCommitMergeWaitMillis > 0) {\n                // we can safely call prepareOnCommitMerge since writeReaderPool(true) above wrote all\n                // necessary files to disk and checkpointed them.\n                onCommitMerges = prepareOnCommitMerge(toCommit, includeInCommit);\n              }\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            assert Thread.holdsLock(fullFlushLock);\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n        throw tragedy;\n      } finally {\n        maybeCloseOnTragicEvent();\n      }\n\n      if (onCommitMerges != null) {\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"now run merges during commit: \" + onCommitMerges.segString(directory));\n        }\n        mergeScheduler.merge(mergeSource, MergeTrigger.COMMIT);\n        onCommitMerges.await(maxCommitMergeWaitMillis, TimeUnit.MILLISECONDS);\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"done waiting for merges during commit\");\n        }\n        synchronized (this) {\n          // we need to call this under lock since mergeFinished above is also called under the IW lock\n          includeInCommit.set(false);\n        }\n      }\n      // do this after handling any onCommitMerges since the files will have changed if any merges\n      // did complete\n      filesToCommit = toCommit.files(false);\n      try {\n        if (anyChanges) {\n          maybeMerge.set(true);\n        }\n        startCommit(toCommit);\n        if (pendingCommit == null) {\n          return -1;\n        } else {\n          return seqNo;\n        }\n      } catch (Throwable t) {\n        synchronized (this) {\n          if (filesToCommit != null) {\n            try {\n              deleter.decRef(filesToCommit);\n            } catch (Throwable t1) {\n              t.addSuppressed(t1);\n            } finally {\n              filesToCommit = null;\n            }\n          }\n        }\n        throw t;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"ba192a321314de8edbe20b279eee9c471b16b48b":["0a0fba1d4c4dd09bd1f7d6779090d0942bf071d0"],"6815b5b5d6334b2245dd7be2f8b6cca949bf7f43":["845b760a99e5f369fcd0a5d723a87b8def6a3f56","bb04d6a79e860154f2a1c519790fc42f5a792915"],"845b760a99e5f369fcd0a5d723a87b8def6a3f56":["28288370235ed02234a64753cdbf0c6ec096304a"],"7af110b00ea8df9429309d83e38e0533d82e144f":["b47e1512544568a22b82c96169d466fae8a4b79e"],"f372764a5bd3ebacde5b99ee3303153eb5ec0d2f":["6b8498afacfc8322268ca0d659d274fcce08d557"],"86a2e8a56b368d37ef3ba7180541fa317d6fd6c7":["1926100d9b67becc9701c54266fee3ba7878a5f0"],"ee59f646cf24586a449cad77391a60a3ac8d8959":["203d65f24251ea8106efd122cca89a2a91205ae4"],"f4363cd33f6eff7fb4753574a441e2d18c1022a4":["ee59f646cf24586a449cad77391a60a3ac8d8959"],"6b8498afacfc8322268ca0d659d274fcce08d557":["86a2e8a56b368d37ef3ba7180541fa317d6fd6c7"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"bb04d6a79e860154f2a1c519790fc42f5a792915":["845b760a99e5f369fcd0a5d723a87b8def6a3f56"],"81819c5a4a660afd353042c67106e682bb877cf1":["f372764a5bd3ebacde5b99ee3303153eb5ec0d2f"],"203d65f24251ea8106efd122cca89a2a91205ae4":["cd4e13d997cf4fb810398a20a299c2c5a9f6b796"],"c0cd85fde84cb318b4dc97710dcf15e2959a1bbe":["cd4e13d997cf4fb810398a20a299c2c5a9f6b796","203d65f24251ea8106efd122cca89a2a91205ae4"],"cd4e13d997cf4fb810398a20a299c2c5a9f6b796":["7af110b00ea8df9429309d83e38e0533d82e144f"],"3dffec77fb8f7d0e9ca4869dddd6af94528b4576":["b47e1512544568a22b82c96169d466fae8a4b79e","7af110b00ea8df9429309d83e38e0533d82e144f"],"31d4861802ca404d78ca1d15f4550eec415b9199":["b47e1512544568a22b82c96169d466fae8a4b79e","7af110b00ea8df9429309d83e38e0533d82e144f"],"407687e67faf6e1f02a211ca078d8e3eed631027":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","b47e1512544568a22b82c96169d466fae8a4b79e"],"0a0fba1d4c4dd09bd1f7d6779090d0942bf071d0":["81819c5a4a660afd353042c67106e682bb877cf1"],"fe39f1a106531207c028defebbc9eb5bb489ac50":["8a428f5314daaabf8eab7c50bdc3bc14e6cd1aa2"],"1926100d9b67becc9701c54266fee3ba7878a5f0":["15e716649e2bd79a98b5e68c464154ea4c44677a"],"b7dfa64bc2074fb87d0ca70095a644c1ead107e1":["ee59f646cf24586a449cad77391a60a3ac8d8959","f4363cd33f6eff7fb4753574a441e2d18c1022a4"],"28288370235ed02234a64753cdbf0c6ec096304a":["ee59f646cf24586a449cad77391a60a3ac8d8959","f4363cd33f6eff7fb4753574a441e2d18c1022a4"],"c2a23476693f2bd9a4b44cc3187c429a2e21dac2":["1182fe36fb5df768dc2da53f6d5338cbc07268ae"],"8a428f5314daaabf8eab7c50bdc3bc14e6cd1aa2":["ba192a321314de8edbe20b279eee9c471b16b48b"],"15e716649e2bd79a98b5e68c464154ea4c44677a":["6815b5b5d6334b2245dd7be2f8b6cca949bf7f43"],"b47e1512544568a22b82c96169d466fae8a4b79e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"1182fe36fb5df768dc2da53f6d5338cbc07268ae":["fe39f1a106531207c028defebbc9eb5bb489ac50"],"3f354ba79a5a3e8491ec2953f14f365a02c058ac":["c2a23476693f2bd9a4b44cc3187c429a2e21dac2"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3f354ba79a5a3e8491ec2953f14f365a02c058ac"]},"commit2Childs":{"ba192a321314de8edbe20b279eee9c471b16b48b":["8a428f5314daaabf8eab7c50bdc3bc14e6cd1aa2"],"6815b5b5d6334b2245dd7be2f8b6cca949bf7f43":["15e716649e2bd79a98b5e68c464154ea4c44677a"],"845b760a99e5f369fcd0a5d723a87b8def6a3f56":["6815b5b5d6334b2245dd7be2f8b6cca949bf7f43","bb04d6a79e860154f2a1c519790fc42f5a792915"],"7af110b00ea8df9429309d83e38e0533d82e144f":["cd4e13d997cf4fb810398a20a299c2c5a9f6b796","3dffec77fb8f7d0e9ca4869dddd6af94528b4576","31d4861802ca404d78ca1d15f4550eec415b9199"],"f372764a5bd3ebacde5b99ee3303153eb5ec0d2f":["81819c5a4a660afd353042c67106e682bb877cf1"],"86a2e8a56b368d37ef3ba7180541fa317d6fd6c7":["6b8498afacfc8322268ca0d659d274fcce08d557"],"ee59f646cf24586a449cad77391a60a3ac8d8959":["f4363cd33f6eff7fb4753574a441e2d18c1022a4","b7dfa64bc2074fb87d0ca70095a644c1ead107e1","28288370235ed02234a64753cdbf0c6ec096304a"],"f4363cd33f6eff7fb4753574a441e2d18c1022a4":["b7dfa64bc2074fb87d0ca70095a644c1ead107e1","28288370235ed02234a64753cdbf0c6ec096304a"],"6b8498afacfc8322268ca0d659d274fcce08d557":["f372764a5bd3ebacde5b99ee3303153eb5ec0d2f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["407687e67faf6e1f02a211ca078d8e3eed631027","b47e1512544568a22b82c96169d466fae8a4b79e"],"bb04d6a79e860154f2a1c519790fc42f5a792915":["6815b5b5d6334b2245dd7be2f8b6cca949bf7f43"],"81819c5a4a660afd353042c67106e682bb877cf1":["0a0fba1d4c4dd09bd1f7d6779090d0942bf071d0"],"203d65f24251ea8106efd122cca89a2a91205ae4":["ee59f646cf24586a449cad77391a60a3ac8d8959","c0cd85fde84cb318b4dc97710dcf15e2959a1bbe"],"c0cd85fde84cb318b4dc97710dcf15e2959a1bbe":[],"cd4e13d997cf4fb810398a20a299c2c5a9f6b796":["203d65f24251ea8106efd122cca89a2a91205ae4","c0cd85fde84cb318b4dc97710dcf15e2959a1bbe"],"3dffec77fb8f7d0e9ca4869dddd6af94528b4576":[],"31d4861802ca404d78ca1d15f4550eec415b9199":[],"407687e67faf6e1f02a211ca078d8e3eed631027":[],"0a0fba1d4c4dd09bd1f7d6779090d0942bf071d0":["ba192a321314de8edbe20b279eee9c471b16b48b"],"1926100d9b67becc9701c54266fee3ba7878a5f0":["86a2e8a56b368d37ef3ba7180541fa317d6fd6c7"],"fe39f1a106531207c028defebbc9eb5bb489ac50":["1182fe36fb5df768dc2da53f6d5338cbc07268ae"],"b7dfa64bc2074fb87d0ca70095a644c1ead107e1":[],"28288370235ed02234a64753cdbf0c6ec096304a":["845b760a99e5f369fcd0a5d723a87b8def6a3f56"],"c2a23476693f2bd9a4b44cc3187c429a2e21dac2":["3f354ba79a5a3e8491ec2953f14f365a02c058ac"],"8a428f5314daaabf8eab7c50bdc3bc14e6cd1aa2":["fe39f1a106531207c028defebbc9eb5bb489ac50"],"15e716649e2bd79a98b5e68c464154ea4c44677a":["1926100d9b67becc9701c54266fee3ba7878a5f0"],"b47e1512544568a22b82c96169d466fae8a4b79e":["7af110b00ea8df9429309d83e38e0533d82e144f","3dffec77fb8f7d0e9ca4869dddd6af94528b4576","31d4861802ca404d78ca1d15f4550eec415b9199","407687e67faf6e1f02a211ca078d8e3eed631027"],"1182fe36fb5df768dc2da53f6d5338cbc07268ae":["c2a23476693f2bd9a4b44cc3187c429a2e21dac2"],"3f354ba79a5a3e8491ec2953f14f365a02c058ac":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["c0cd85fde84cb318b4dc97710dcf15e2959a1bbe","3dffec77fb8f7d0e9ca4869dddd6af94528b4576","31d4861802ca404d78ca1d15f4550eec415b9199","407687e67faf6e1f02a211ca078d8e3eed631027","b7dfa64bc2074fb87d0ca70095a644c1ead107e1","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}