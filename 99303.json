{"path":"lucene/src/test/org/apache/lucene/search/TestPhrasePrefixQuery#testPhrasePrefix().mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPhrasePrefixQuery#testPhrasePrefix().mjava","pathOld":"src/test/org/apache/lucene/search/TestPhrasePrefixQuery#testPhrasePrefix().mjava","sourceNew":"    /**\n     *\n     */\n    public void testPhrasePrefix()\n        throws IOException\n    {\n        RAMDirectory indexStore = new RAMDirectory();\n        IndexWriter writer = new IndexWriter(indexStore, new IndexWriterConfig(TEST_VERSION_CURRENT, new SimpleAnalyzer(TEST_VERSION_CURRENT)));\n        Document doc1 = new Document();\n        Document doc2 = new Document();\n        Document doc3 = new Document();\n        Document doc4 = new Document();\n        Document doc5 = new Document();\n        doc1.add(new Field(\"body\", \"blueberry pie\", Field.Store.YES, Field.Index.ANALYZED));\n        doc2.add(new Field(\"body\", \"blueberry strudel\", Field.Store.YES, Field.Index.ANALYZED));\n        doc3.add(new Field(\"body\", \"blueberry pizza\", Field.Store.YES, Field.Index.ANALYZED));\n        doc4.add(new Field(\"body\", \"blueberry chewing gum\", Field.Store.YES, Field.Index.ANALYZED));\n        doc5.add(new Field(\"body\", \"piccadilly circus\", Field.Store.YES, Field.Index.ANALYZED));\n        writer.addDocument(doc1);\n        writer.addDocument(doc2);\n        writer.addDocument(doc3);\n        writer.addDocument(doc4);\n        writer.addDocument(doc5);\n        writer.optimize();\n        writer.close();\n\n        IndexSearcher searcher = new IndexSearcher(indexStore, true);\n\n        //PhrasePrefixQuery query1 = new PhrasePrefixQuery();\n        MultiPhraseQuery query1 = new MultiPhraseQuery();\n        //PhrasePrefixQuery query2 = new PhrasePrefixQuery();\n        MultiPhraseQuery query2 = new MultiPhraseQuery();\n        query1.add(new Term(\"body\", \"blueberry\"));\n        query2.add(new Term(\"body\", \"strawberry\"));\n\n        LinkedList<Term> termsWithPrefix = new LinkedList<Term>();\n        IndexReader ir = IndexReader.open(indexStore, true);\n\n        // this TermEnum gives \"piccadilly\", \"pie\" and \"pizza\".\n        String prefix = \"pi\";\n        TermEnum te = ir.terms(new Term(\"body\", prefix + \"*\"));\n        do {\n            if (te.term().text().startsWith(prefix))\n            {\n                termsWithPrefix.add(te.term());\n            }\n        } while (te.next());\n\n        query1.add(termsWithPrefix.toArray(new Term[0]));\n        query2.add(termsWithPrefix.toArray(new Term[0]));\n\n        ScoreDoc[] result;\n        result = searcher.search(query1, null, 1000).scoreDocs;\n        assertEquals(2, result.length);\n\n        result = searcher.search(query2, null, 1000).scoreDocs;\n        assertEquals(0, result.length);\n    }\n\n","sourceOld":"    /**\n     *\n     */\n    public void testPhrasePrefix()\n        throws IOException\n    {\n        RAMDirectory indexStore = new RAMDirectory();\n        IndexWriter writer = new IndexWriter(indexStore, new IndexWriterConfig(TEST_VERSION_CURRENT, new SimpleAnalyzer(TEST_VERSION_CURRENT)));\n        Document doc1 = new Document();\n        Document doc2 = new Document();\n        Document doc3 = new Document();\n        Document doc4 = new Document();\n        Document doc5 = new Document();\n        doc1.add(new Field(\"body\", \"blueberry pie\", Field.Store.YES, Field.Index.ANALYZED));\n        doc2.add(new Field(\"body\", \"blueberry strudel\", Field.Store.YES, Field.Index.ANALYZED));\n        doc3.add(new Field(\"body\", \"blueberry pizza\", Field.Store.YES, Field.Index.ANALYZED));\n        doc4.add(new Field(\"body\", \"blueberry chewing gum\", Field.Store.YES, Field.Index.ANALYZED));\n        doc5.add(new Field(\"body\", \"piccadilly circus\", Field.Store.YES, Field.Index.ANALYZED));\n        writer.addDocument(doc1);\n        writer.addDocument(doc2);\n        writer.addDocument(doc3);\n        writer.addDocument(doc4);\n        writer.addDocument(doc5);\n        writer.optimize();\n        writer.close();\n\n        IndexSearcher searcher = new IndexSearcher(indexStore, true);\n\n        //PhrasePrefixQuery query1 = new PhrasePrefixQuery();\n        MultiPhraseQuery query1 = new MultiPhraseQuery();\n        //PhrasePrefixQuery query2 = new PhrasePrefixQuery();\n        MultiPhraseQuery query2 = new MultiPhraseQuery();\n        query1.add(new Term(\"body\", \"blueberry\"));\n        query2.add(new Term(\"body\", \"strawberry\"));\n\n        LinkedList<Term> termsWithPrefix = new LinkedList<Term>();\n        IndexReader ir = IndexReader.open(indexStore, true);\n\n        // this TermEnum gives \"piccadilly\", \"pie\" and \"pizza\".\n        String prefix = \"pi\";\n        TermEnum te = ir.terms(new Term(\"body\", prefix + \"*\"));\n        do {\n            if (te.term().text().startsWith(prefix))\n            {\n                termsWithPrefix.add(te.term());\n            }\n        } while (te.next());\n\n        query1.add(termsWithPrefix.toArray(new Term[0]));\n        query2.add(termsWithPrefix.toArray(new Term[0]));\n\n        ScoreDoc[] result;\n        result = searcher.search(query1, null, 1000).scoreDocs;\n        assertEquals(2, result.length);\n\n        result = searcher.search(query2, null, 1000).scoreDocs;\n        assertEquals(0, result.length);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d572389229127c297dd1fa5ce4758e1cec41e799","date":1273610938,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPhrasePrefixQuery#testPhrasePrefix().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPhrasePrefixQuery#testPhrasePrefix().mjava","sourceNew":"    /**\n     *\n     */\n    public void testPhrasePrefix()\n        throws IOException\n    {\n        RAMDirectory indexStore = new RAMDirectory();\n        IndexWriter writer = new IndexWriter(indexStore, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n        Document doc1 = new Document();\n        Document doc2 = new Document();\n        Document doc3 = new Document();\n        Document doc4 = new Document();\n        Document doc5 = new Document();\n        doc1.add(new Field(\"body\", \"blueberry pie\", Field.Store.YES, Field.Index.ANALYZED));\n        doc2.add(new Field(\"body\", \"blueberry strudel\", Field.Store.YES, Field.Index.ANALYZED));\n        doc3.add(new Field(\"body\", \"blueberry pizza\", Field.Store.YES, Field.Index.ANALYZED));\n        doc4.add(new Field(\"body\", \"blueberry chewing gum\", Field.Store.YES, Field.Index.ANALYZED));\n        doc5.add(new Field(\"body\", \"piccadilly circus\", Field.Store.YES, Field.Index.ANALYZED));\n        writer.addDocument(doc1);\n        writer.addDocument(doc2);\n        writer.addDocument(doc3);\n        writer.addDocument(doc4);\n        writer.addDocument(doc5);\n        writer.optimize();\n        writer.close();\n\n        IndexSearcher searcher = new IndexSearcher(indexStore, true);\n\n        //PhrasePrefixQuery query1 = new PhrasePrefixQuery();\n        MultiPhraseQuery query1 = new MultiPhraseQuery();\n        //PhrasePrefixQuery query2 = new PhrasePrefixQuery();\n        MultiPhraseQuery query2 = new MultiPhraseQuery();\n        query1.add(new Term(\"body\", \"blueberry\"));\n        query2.add(new Term(\"body\", \"strawberry\"));\n\n        LinkedList<Term> termsWithPrefix = new LinkedList<Term>();\n        IndexReader ir = IndexReader.open(indexStore, true);\n\n        // this TermEnum gives \"piccadilly\", \"pie\" and \"pizza\".\n        String prefix = \"pi\";\n        TermEnum te = ir.terms(new Term(\"body\", prefix + \"*\"));\n        do {\n            if (te.term().text().startsWith(prefix))\n            {\n                termsWithPrefix.add(te.term());\n            }\n        } while (te.next());\n\n        query1.add(termsWithPrefix.toArray(new Term[0]));\n        query2.add(termsWithPrefix.toArray(new Term[0]));\n\n        ScoreDoc[] result;\n        result = searcher.search(query1, null, 1000).scoreDocs;\n        assertEquals(2, result.length);\n\n        result = searcher.search(query2, null, 1000).scoreDocs;\n        assertEquals(0, result.length);\n    }\n\n","sourceOld":"    /**\n     *\n     */\n    public void testPhrasePrefix()\n        throws IOException\n    {\n        RAMDirectory indexStore = new RAMDirectory();\n        IndexWriter writer = new IndexWriter(indexStore, new IndexWriterConfig(TEST_VERSION_CURRENT, new SimpleAnalyzer(TEST_VERSION_CURRENT)));\n        Document doc1 = new Document();\n        Document doc2 = new Document();\n        Document doc3 = new Document();\n        Document doc4 = new Document();\n        Document doc5 = new Document();\n        doc1.add(new Field(\"body\", \"blueberry pie\", Field.Store.YES, Field.Index.ANALYZED));\n        doc2.add(new Field(\"body\", \"blueberry strudel\", Field.Store.YES, Field.Index.ANALYZED));\n        doc3.add(new Field(\"body\", \"blueberry pizza\", Field.Store.YES, Field.Index.ANALYZED));\n        doc4.add(new Field(\"body\", \"blueberry chewing gum\", Field.Store.YES, Field.Index.ANALYZED));\n        doc5.add(new Field(\"body\", \"piccadilly circus\", Field.Store.YES, Field.Index.ANALYZED));\n        writer.addDocument(doc1);\n        writer.addDocument(doc2);\n        writer.addDocument(doc3);\n        writer.addDocument(doc4);\n        writer.addDocument(doc5);\n        writer.optimize();\n        writer.close();\n\n        IndexSearcher searcher = new IndexSearcher(indexStore, true);\n\n        //PhrasePrefixQuery query1 = new PhrasePrefixQuery();\n        MultiPhraseQuery query1 = new MultiPhraseQuery();\n        //PhrasePrefixQuery query2 = new PhrasePrefixQuery();\n        MultiPhraseQuery query2 = new MultiPhraseQuery();\n        query1.add(new Term(\"body\", \"blueberry\"));\n        query2.add(new Term(\"body\", \"strawberry\"));\n\n        LinkedList<Term> termsWithPrefix = new LinkedList<Term>();\n        IndexReader ir = IndexReader.open(indexStore, true);\n\n        // this TermEnum gives \"piccadilly\", \"pie\" and \"pizza\".\n        String prefix = \"pi\";\n        TermEnum te = ir.terms(new Term(\"body\", prefix + \"*\"));\n        do {\n            if (te.term().text().startsWith(prefix))\n            {\n                termsWithPrefix.add(te.term());\n            }\n        } while (te.next());\n\n        query1.add(termsWithPrefix.toArray(new Term[0]));\n        query2.add(termsWithPrefix.toArray(new Term[0]));\n\n        ScoreDoc[] result;\n        result = searcher.search(query1, null, 1000).scoreDocs;\n        assertEquals(2, result.length);\n\n        result = searcher.search(query2, null, 1000).scoreDocs;\n        assertEquals(0, result.length);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"28427ef110c4c5bf5b4057731b83110bd1e13724","date":1276701452,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPhrasePrefixQuery#testPhrasePrefix().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPhrasePrefixQuery#testPhrasePrefix().mjava","sourceNew":"    /**\n     *\n     */\n    public void testPhrasePrefix()\n        throws IOException\n    {\n        RAMDirectory indexStore = new RAMDirectory();\n        IndexWriter writer = new IndexWriter(indexStore, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n        Document doc1 = new Document();\n        Document doc2 = new Document();\n        Document doc3 = new Document();\n        Document doc4 = new Document();\n        Document doc5 = new Document();\n        doc1.add(new Field(\"body\", \"blueberry pie\", Field.Store.YES, Field.Index.ANALYZED));\n        doc2.add(new Field(\"body\", \"blueberry strudel\", Field.Store.YES, Field.Index.ANALYZED));\n        doc3.add(new Field(\"body\", \"blueberry pizza\", Field.Store.YES, Field.Index.ANALYZED));\n        doc4.add(new Field(\"body\", \"blueberry chewing gum\", Field.Store.YES, Field.Index.ANALYZED));\n        doc5.add(new Field(\"body\", \"piccadilly circus\", Field.Store.YES, Field.Index.ANALYZED));\n        writer.addDocument(doc1);\n        writer.addDocument(doc2);\n        writer.addDocument(doc3);\n        writer.addDocument(doc4);\n        writer.addDocument(doc5);\n        writer.optimize();\n        writer.close();\n\n        IndexSearcher searcher = new IndexSearcher(indexStore, true);\n\n        //PhrasePrefixQuery query1 = new PhrasePrefixQuery();\n        MultiPhraseQuery query1 = new MultiPhraseQuery();\n        //PhrasePrefixQuery query2 = new PhrasePrefixQuery();\n        MultiPhraseQuery query2 = new MultiPhraseQuery();\n        query1.add(new Term(\"body\", \"blueberry\"));\n        query2.add(new Term(\"body\", \"strawberry\"));\n\n        LinkedList<Term> termsWithPrefix = new LinkedList<Term>();\n        IndexReader ir = IndexReader.open(indexStore, true);\n\n        // this TermEnum gives \"piccadilly\", \"pie\" and \"pizza\".\n        String prefix = \"pi\";\n        TermsEnum te = MultiFields.getFields(ir).terms(\"body\").iterator();\n        te.seek(new BytesRef(prefix));\n        do {\n            String s = te.term().utf8ToString();\n            if (s.startsWith(prefix)) {\n              termsWithPrefix.add(new Term(\"body\", s));\n            } else {\n              break;\n            }\n        } while (te.next() != null);\n\n        query1.add(termsWithPrefix.toArray(new Term[0]));\n        query2.add(termsWithPrefix.toArray(new Term[0]));\n\n        ScoreDoc[] result;\n        result = searcher.search(query1, null, 1000).scoreDocs;\n        assertEquals(2, result.length);\n\n        result = searcher.search(query2, null, 1000).scoreDocs;\n        assertEquals(0, result.length);\n    }\n\n","sourceOld":"    /**\n     *\n     */\n    public void testPhrasePrefix()\n        throws IOException\n    {\n        RAMDirectory indexStore = new RAMDirectory();\n        IndexWriter writer = new IndexWriter(indexStore, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n        Document doc1 = new Document();\n        Document doc2 = new Document();\n        Document doc3 = new Document();\n        Document doc4 = new Document();\n        Document doc5 = new Document();\n        doc1.add(new Field(\"body\", \"blueberry pie\", Field.Store.YES, Field.Index.ANALYZED));\n        doc2.add(new Field(\"body\", \"blueberry strudel\", Field.Store.YES, Field.Index.ANALYZED));\n        doc3.add(new Field(\"body\", \"blueberry pizza\", Field.Store.YES, Field.Index.ANALYZED));\n        doc4.add(new Field(\"body\", \"blueberry chewing gum\", Field.Store.YES, Field.Index.ANALYZED));\n        doc5.add(new Field(\"body\", \"piccadilly circus\", Field.Store.YES, Field.Index.ANALYZED));\n        writer.addDocument(doc1);\n        writer.addDocument(doc2);\n        writer.addDocument(doc3);\n        writer.addDocument(doc4);\n        writer.addDocument(doc5);\n        writer.optimize();\n        writer.close();\n\n        IndexSearcher searcher = new IndexSearcher(indexStore, true);\n\n        //PhrasePrefixQuery query1 = new PhrasePrefixQuery();\n        MultiPhraseQuery query1 = new MultiPhraseQuery();\n        //PhrasePrefixQuery query2 = new PhrasePrefixQuery();\n        MultiPhraseQuery query2 = new MultiPhraseQuery();\n        query1.add(new Term(\"body\", \"blueberry\"));\n        query2.add(new Term(\"body\", \"strawberry\"));\n\n        LinkedList<Term> termsWithPrefix = new LinkedList<Term>();\n        IndexReader ir = IndexReader.open(indexStore, true);\n\n        // this TermEnum gives \"piccadilly\", \"pie\" and \"pizza\".\n        String prefix = \"pi\";\n        TermEnum te = ir.terms(new Term(\"body\", prefix + \"*\"));\n        do {\n            if (te.term().text().startsWith(prefix))\n            {\n                termsWithPrefix.add(te.term());\n            }\n        } while (te.next());\n\n        query1.add(termsWithPrefix.toArray(new Term[0]));\n        query2.add(termsWithPrefix.toArray(new Term[0]));\n\n        ScoreDoc[] result;\n        result = searcher.search(query1, null, 1000).scoreDocs;\n        assertEquals(2, result.length);\n\n        result = searcher.search(query2, null, 1000).scoreDocs;\n        assertEquals(0, result.length);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c084e47df29de3330311d69dabf515ceaa989512","date":1279030906,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPhrasePrefixQuery#testPhrasePrefix().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPhrasePrefixQuery#testPhrasePrefix().mjava","sourceNew":"  /**\n     *\n     */\n  public void testPhrasePrefix() throws IOException {\n    RAMDirectory indexStore = new RAMDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), indexStore,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n    Document doc1 = new Document();\n    Document doc2 = new Document();\n    Document doc3 = new Document();\n    Document doc4 = new Document();\n    Document doc5 = new Document();\n    doc1.add(new Field(\"body\", \"blueberry pie\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc2.add(new Field(\"body\", \"blueberry strudel\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc3.add(new Field(\"body\", \"blueberry pizza\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc4.add(new Field(\"body\", \"blueberry chewing gum\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc5.add(new Field(\"body\", \"piccadilly circus\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    writer.addDocument(doc1);\n    writer.addDocument(doc2);\n    writer.addDocument(doc3);\n    writer.addDocument(doc4);\n    writer.addDocument(doc5);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    IndexSearcher searcher = new IndexSearcher(reader);\n    \n    // PhrasePrefixQuery query1 = new PhrasePrefixQuery();\n    MultiPhraseQuery query1 = new MultiPhraseQuery();\n    // PhrasePrefixQuery query2 = new PhrasePrefixQuery();\n    MultiPhraseQuery query2 = new MultiPhraseQuery();\n    query1.add(new Term(\"body\", \"blueberry\"));\n    query2.add(new Term(\"body\", \"strawberry\"));\n    \n    LinkedList<Term> termsWithPrefix = new LinkedList<Term>();\n    \n    // this TermEnum gives \"piccadilly\", \"pie\" and \"pizza\".\n    String prefix = \"pi\";\n    TermsEnum te = MultiFields.getFields(reader).terms(\"body\").iterator();\n    te.seek(new BytesRef(prefix));\n    do {\n      String s = te.term().utf8ToString();\n      if (s.startsWith(prefix)) {\n        termsWithPrefix.add(new Term(\"body\", s));\n      } else {\n        break;\n      }\n    } while (te.next() != null);\n    \n    query1.add(termsWithPrefix.toArray(new Term[0]));\n    query2.add(termsWithPrefix.toArray(new Term[0]));\n    \n    ScoreDoc[] result;\n    result = searcher.search(query1, null, 1000).scoreDocs;\n    assertEquals(2, result.length);\n    \n    result = searcher.search(query2, null, 1000).scoreDocs;\n    assertEquals(0, result.length);\n    searcher.close();\n    reader.close();\n    indexStore.close();\n  }\n\n","sourceOld":"    /**\n     *\n     */\n    public void testPhrasePrefix()\n        throws IOException\n    {\n        RAMDirectory indexStore = new RAMDirectory();\n        IndexWriter writer = new IndexWriter(indexStore, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n        Document doc1 = new Document();\n        Document doc2 = new Document();\n        Document doc3 = new Document();\n        Document doc4 = new Document();\n        Document doc5 = new Document();\n        doc1.add(new Field(\"body\", \"blueberry pie\", Field.Store.YES, Field.Index.ANALYZED));\n        doc2.add(new Field(\"body\", \"blueberry strudel\", Field.Store.YES, Field.Index.ANALYZED));\n        doc3.add(new Field(\"body\", \"blueberry pizza\", Field.Store.YES, Field.Index.ANALYZED));\n        doc4.add(new Field(\"body\", \"blueberry chewing gum\", Field.Store.YES, Field.Index.ANALYZED));\n        doc5.add(new Field(\"body\", \"piccadilly circus\", Field.Store.YES, Field.Index.ANALYZED));\n        writer.addDocument(doc1);\n        writer.addDocument(doc2);\n        writer.addDocument(doc3);\n        writer.addDocument(doc4);\n        writer.addDocument(doc5);\n        writer.optimize();\n        writer.close();\n\n        IndexSearcher searcher = new IndexSearcher(indexStore, true);\n\n        //PhrasePrefixQuery query1 = new PhrasePrefixQuery();\n        MultiPhraseQuery query1 = new MultiPhraseQuery();\n        //PhrasePrefixQuery query2 = new PhrasePrefixQuery();\n        MultiPhraseQuery query2 = new MultiPhraseQuery();\n        query1.add(new Term(\"body\", \"blueberry\"));\n        query2.add(new Term(\"body\", \"strawberry\"));\n\n        LinkedList<Term> termsWithPrefix = new LinkedList<Term>();\n        IndexReader ir = IndexReader.open(indexStore, true);\n\n        // this TermEnum gives \"piccadilly\", \"pie\" and \"pizza\".\n        String prefix = \"pi\";\n        TermsEnum te = MultiFields.getFields(ir).terms(\"body\").iterator();\n        te.seek(new BytesRef(prefix));\n        do {\n            String s = te.term().utf8ToString();\n            if (s.startsWith(prefix)) {\n              termsWithPrefix.add(new Term(\"body\", s));\n            } else {\n              break;\n            }\n        } while (te.next() != null);\n\n        query1.add(termsWithPrefix.toArray(new Term[0]));\n        query2.add(termsWithPrefix.toArray(new Term[0]));\n\n        ScoreDoc[] result;\n        result = searcher.search(query1, null, 1000).scoreDocs;\n        assertEquals(2, result.length);\n\n        result = searcher.search(query2, null, 1000).scoreDocs;\n        assertEquals(0, result.length);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5f4e87790277826a2aea119328600dfb07761f32","date":1279827275,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPhrasePrefixQuery#testPhrasePrefix().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPhrasePrefixQuery#testPhrasePrefix().mjava","sourceNew":"  /**\n     *\n     */\n  public void testPhrasePrefix() throws IOException {\n    RAMDirectory indexStore = new RAMDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), indexStore,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n    Document doc1 = new Document();\n    Document doc2 = new Document();\n    Document doc3 = new Document();\n    Document doc4 = new Document();\n    Document doc5 = new Document();\n    doc1.add(new Field(\"body\", \"blueberry pie\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc2.add(new Field(\"body\", \"blueberry strudel\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc3.add(new Field(\"body\", \"blueberry pizza\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc4.add(new Field(\"body\", \"blueberry chewing gum\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc5.add(new Field(\"body\", \"piccadilly circus\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    writer.addDocument(doc1);\n    writer.addDocument(doc2);\n    writer.addDocument(doc3);\n    writer.addDocument(doc4);\n    writer.addDocument(doc5);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    IndexSearcher searcher = new IndexSearcher(reader);\n    \n    // PhrasePrefixQuery query1 = new PhrasePrefixQuery();\n    MultiPhraseQuery query1 = new MultiPhraseQuery();\n    // PhrasePrefixQuery query2 = new PhrasePrefixQuery();\n    MultiPhraseQuery query2 = new MultiPhraseQuery();\n    query1.add(new Term(\"body\", \"blueberry\"));\n    query2.add(new Term(\"body\", \"strawberry\"));\n    \n    LinkedList<Term> termsWithPrefix = new LinkedList<Term>();\n    \n    // this TermEnum gives \"piccadilly\", \"pie\" and \"pizza\".\n    String prefix = \"pi\";\n    TermsEnum te = MultiFields.getFields(reader).terms(\"body\").iterator();\n    te.seek(new BytesRef(prefix));\n    do {\n      String s = te.term().utf8ToString();\n      if (s.startsWith(prefix)) {\n        termsWithPrefix.add(new Term(\"body\", s));\n      } else {\n        break;\n      }\n    } while (te.next() != null);\n    \n    query1.add(termsWithPrefix.toArray(new Term[0]));\n    query2.add(termsWithPrefix.toArray(new Term[0]));\n    \n    ScoreDoc[] result;\n    result = searcher.search(query1, null, 1000).scoreDocs;\n    assertEquals(2, result.length);\n    \n    result = searcher.search(query2, null, 1000).scoreDocs;\n    assertEquals(0, result.length);\n    searcher.close();\n    reader.close();\n    indexStore.close();\n  }\n\n","sourceOld":"    /**\n     *\n     */\n    public void testPhrasePrefix()\n        throws IOException\n    {\n        RAMDirectory indexStore = new RAMDirectory();\n        IndexWriter writer = new IndexWriter(indexStore, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n        Document doc1 = new Document();\n        Document doc2 = new Document();\n        Document doc3 = new Document();\n        Document doc4 = new Document();\n        Document doc5 = new Document();\n        doc1.add(new Field(\"body\", \"blueberry pie\", Field.Store.YES, Field.Index.ANALYZED));\n        doc2.add(new Field(\"body\", \"blueberry strudel\", Field.Store.YES, Field.Index.ANALYZED));\n        doc3.add(new Field(\"body\", \"blueberry pizza\", Field.Store.YES, Field.Index.ANALYZED));\n        doc4.add(new Field(\"body\", \"blueberry chewing gum\", Field.Store.YES, Field.Index.ANALYZED));\n        doc5.add(new Field(\"body\", \"piccadilly circus\", Field.Store.YES, Field.Index.ANALYZED));\n        writer.addDocument(doc1);\n        writer.addDocument(doc2);\n        writer.addDocument(doc3);\n        writer.addDocument(doc4);\n        writer.addDocument(doc5);\n        writer.optimize();\n        writer.close();\n\n        IndexSearcher searcher = new IndexSearcher(indexStore, true);\n\n        //PhrasePrefixQuery query1 = new PhrasePrefixQuery();\n        MultiPhraseQuery query1 = new MultiPhraseQuery();\n        //PhrasePrefixQuery query2 = new PhrasePrefixQuery();\n        MultiPhraseQuery query2 = new MultiPhraseQuery();\n        query1.add(new Term(\"body\", \"blueberry\"));\n        query2.add(new Term(\"body\", \"strawberry\"));\n\n        LinkedList<Term> termsWithPrefix = new LinkedList<Term>();\n        IndexReader ir = IndexReader.open(indexStore, true);\n\n        // this TermEnum gives \"piccadilly\", \"pie\" and \"pizza\".\n        String prefix = \"pi\";\n        TermEnum te = ir.terms(new Term(\"body\", prefix + \"*\"));\n        do {\n            if (te.term().text().startsWith(prefix))\n            {\n                termsWithPrefix.add(te.term());\n            }\n        } while (te.next());\n\n        query1.add(termsWithPrefix.toArray(new Term[0]));\n        query2.add(termsWithPrefix.toArray(new Term[0]));\n\n        ScoreDoc[] result;\n        result = searcher.search(query1, null, 1000).scoreDocs;\n        assertEquals(2, result.length);\n\n        result = searcher.search(query2, null, 1000).scoreDocs;\n        assertEquals(0, result.length);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"15bbd254c1506df5299c4df8c148262c7bd6301e","date":1279913113,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPhrasePrefixQuery#testPhrasePrefix().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPhrasePrefixQuery#testPhrasePrefix().mjava","sourceNew":"  /**\n     *\n     */\n  public void testPhrasePrefix() throws IOException {\n    RAMDirectory indexStore = new RAMDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), indexStore);\n    Document doc1 = new Document();\n    Document doc2 = new Document();\n    Document doc3 = new Document();\n    Document doc4 = new Document();\n    Document doc5 = new Document();\n    doc1.add(new Field(\"body\", \"blueberry pie\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc2.add(new Field(\"body\", \"blueberry strudel\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc3.add(new Field(\"body\", \"blueberry pizza\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc4.add(new Field(\"body\", \"blueberry chewing gum\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc5.add(new Field(\"body\", \"piccadilly circus\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    writer.addDocument(doc1);\n    writer.addDocument(doc2);\n    writer.addDocument(doc3);\n    writer.addDocument(doc4);\n    writer.addDocument(doc5);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    IndexSearcher searcher = new IndexSearcher(reader);\n    \n    // PhrasePrefixQuery query1 = new PhrasePrefixQuery();\n    MultiPhraseQuery query1 = new MultiPhraseQuery();\n    // PhrasePrefixQuery query2 = new PhrasePrefixQuery();\n    MultiPhraseQuery query2 = new MultiPhraseQuery();\n    query1.add(new Term(\"body\", \"blueberry\"));\n    query2.add(new Term(\"body\", \"strawberry\"));\n    \n    LinkedList<Term> termsWithPrefix = new LinkedList<Term>();\n    \n    // this TermEnum gives \"piccadilly\", \"pie\" and \"pizza\".\n    String prefix = \"pi\";\n    TermsEnum te = MultiFields.getFields(reader).terms(\"body\").iterator();\n    te.seek(new BytesRef(prefix));\n    do {\n      String s = te.term().utf8ToString();\n      if (s.startsWith(prefix)) {\n        termsWithPrefix.add(new Term(\"body\", s));\n      } else {\n        break;\n      }\n    } while (te.next() != null);\n    \n    query1.add(termsWithPrefix.toArray(new Term[0]));\n    query2.add(termsWithPrefix.toArray(new Term[0]));\n    \n    ScoreDoc[] result;\n    result = searcher.search(query1, null, 1000).scoreDocs;\n    assertEquals(2, result.length);\n    \n    result = searcher.search(query2, null, 1000).scoreDocs;\n    assertEquals(0, result.length);\n    searcher.close();\n    reader.close();\n    indexStore.close();\n  }\n\n","sourceOld":"  /**\n     *\n     */\n  public void testPhrasePrefix() throws IOException {\n    RAMDirectory indexStore = new RAMDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), indexStore,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n    Document doc1 = new Document();\n    Document doc2 = new Document();\n    Document doc3 = new Document();\n    Document doc4 = new Document();\n    Document doc5 = new Document();\n    doc1.add(new Field(\"body\", \"blueberry pie\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc2.add(new Field(\"body\", \"blueberry strudel\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc3.add(new Field(\"body\", \"blueberry pizza\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc4.add(new Field(\"body\", \"blueberry chewing gum\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc5.add(new Field(\"body\", \"piccadilly circus\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    writer.addDocument(doc1);\n    writer.addDocument(doc2);\n    writer.addDocument(doc3);\n    writer.addDocument(doc4);\n    writer.addDocument(doc5);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    IndexSearcher searcher = new IndexSearcher(reader);\n    \n    // PhrasePrefixQuery query1 = new PhrasePrefixQuery();\n    MultiPhraseQuery query1 = new MultiPhraseQuery();\n    // PhrasePrefixQuery query2 = new PhrasePrefixQuery();\n    MultiPhraseQuery query2 = new MultiPhraseQuery();\n    query1.add(new Term(\"body\", \"blueberry\"));\n    query2.add(new Term(\"body\", \"strawberry\"));\n    \n    LinkedList<Term> termsWithPrefix = new LinkedList<Term>();\n    \n    // this TermEnum gives \"piccadilly\", \"pie\" and \"pizza\".\n    String prefix = \"pi\";\n    TermsEnum te = MultiFields.getFields(reader).terms(\"body\").iterator();\n    te.seek(new BytesRef(prefix));\n    do {\n      String s = te.term().utf8ToString();\n      if (s.startsWith(prefix)) {\n        termsWithPrefix.add(new Term(\"body\", s));\n      } else {\n        break;\n      }\n    } while (te.next() != null);\n    \n    query1.add(termsWithPrefix.toArray(new Term[0]));\n    query2.add(termsWithPrefix.toArray(new Term[0]));\n    \n    ScoreDoc[] result;\n    result = searcher.search(query1, null, 1000).scoreDocs;\n    assertEquals(2, result.length);\n    \n    result = searcher.search(query2, null, 1000).scoreDocs;\n    assertEquals(0, result.length);\n    searcher.close();\n    reader.close();\n    indexStore.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4b103252dee6afa1b6d7a622c773d178788eb85a","date":1280180143,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPhrasePrefixQuery#testPhrasePrefix().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPhrasePrefixQuery#testPhrasePrefix().mjava","sourceNew":"  /**\n     *\n     */\n  public void testPhrasePrefix() throws IOException {\n    RAMDirectory indexStore = new RAMDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), indexStore);\n    Document doc1 = new Document();\n    Document doc2 = new Document();\n    Document doc3 = new Document();\n    Document doc4 = new Document();\n    Document doc5 = new Document();\n    doc1.add(new Field(\"body\", \"blueberry pie\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc2.add(new Field(\"body\", \"blueberry strudel\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc3.add(new Field(\"body\", \"blueberry pizza\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc4.add(new Field(\"body\", \"blueberry chewing gum\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc5.add(new Field(\"body\", \"piccadilly circus\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    writer.addDocument(doc1);\n    writer.addDocument(doc2);\n    writer.addDocument(doc3);\n    writer.addDocument(doc4);\n    writer.addDocument(doc5);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    IndexSearcher searcher = new IndexSearcher(reader);\n    \n    // PhrasePrefixQuery query1 = new PhrasePrefixQuery();\n    MultiPhraseQuery query1 = new MultiPhraseQuery();\n    // PhrasePrefixQuery query2 = new PhrasePrefixQuery();\n    MultiPhraseQuery query2 = new MultiPhraseQuery();\n    query1.add(new Term(\"body\", \"blueberry\"));\n    query2.add(new Term(\"body\", \"strawberry\"));\n    \n    LinkedList<Term> termsWithPrefix = new LinkedList<Term>();\n    \n    // this TermEnum gives \"piccadilly\", \"pie\" and \"pizza\".\n    String prefix = \"pi\";\n    TermsEnum te = MultiFields.getFields(reader).terms(\"body\").iterator();\n    te.seek(new BytesRef(prefix));\n    do {\n      String s = te.term().utf8ToString();\n      if (s.startsWith(prefix)) {\n        termsWithPrefix.add(new Term(\"body\", s));\n      } else {\n        break;\n      }\n    } while (te.next() != null);\n    \n    query1.add(termsWithPrefix.toArray(new Term[0]));\n    query2.add(termsWithPrefix.toArray(new Term[0]));\n    \n    ScoreDoc[] result;\n    result = searcher.search(query1, null, 1000).scoreDocs;\n    assertEquals(2, result.length);\n    \n    result = searcher.search(query2, null, 1000).scoreDocs;\n    assertEquals(0, result.length);\n    searcher.close();\n    reader.close();\n    indexStore.close();\n  }\n\n","sourceOld":"  /**\n     *\n     */\n  public void testPhrasePrefix() throws IOException {\n    RAMDirectory indexStore = new RAMDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), indexStore,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n    Document doc1 = new Document();\n    Document doc2 = new Document();\n    Document doc3 = new Document();\n    Document doc4 = new Document();\n    Document doc5 = new Document();\n    doc1.add(new Field(\"body\", \"blueberry pie\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc2.add(new Field(\"body\", \"blueberry strudel\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc3.add(new Field(\"body\", \"blueberry pizza\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc4.add(new Field(\"body\", \"blueberry chewing gum\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc5.add(new Field(\"body\", \"piccadilly circus\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    writer.addDocument(doc1);\n    writer.addDocument(doc2);\n    writer.addDocument(doc3);\n    writer.addDocument(doc4);\n    writer.addDocument(doc5);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    IndexSearcher searcher = new IndexSearcher(reader);\n    \n    // PhrasePrefixQuery query1 = new PhrasePrefixQuery();\n    MultiPhraseQuery query1 = new MultiPhraseQuery();\n    // PhrasePrefixQuery query2 = new PhrasePrefixQuery();\n    MultiPhraseQuery query2 = new MultiPhraseQuery();\n    query1.add(new Term(\"body\", \"blueberry\"));\n    query2.add(new Term(\"body\", \"strawberry\"));\n    \n    LinkedList<Term> termsWithPrefix = new LinkedList<Term>();\n    \n    // this TermEnum gives \"piccadilly\", \"pie\" and \"pizza\".\n    String prefix = \"pi\";\n    TermsEnum te = MultiFields.getFields(reader).terms(\"body\").iterator();\n    te.seek(new BytesRef(prefix));\n    do {\n      String s = te.term().utf8ToString();\n      if (s.startsWith(prefix)) {\n        termsWithPrefix.add(new Term(\"body\", s));\n      } else {\n        break;\n      }\n    } while (te.next() != null);\n    \n    query1.add(termsWithPrefix.toArray(new Term[0]));\n    query2.add(termsWithPrefix.toArray(new Term[0]));\n    \n    ScoreDoc[] result;\n    result = searcher.search(query1, null, 1000).scoreDocs;\n    assertEquals(2, result.length);\n    \n    result = searcher.search(query2, null, 1000).scoreDocs;\n    assertEquals(0, result.length);\n    searcher.close();\n    reader.close();\n    indexStore.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3242a09f703274d3b9283f2064a1a33064b53a1b","date":1280263474,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPhrasePrefixQuery#testPhrasePrefix().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPhrasePrefixQuery#testPhrasePrefix().mjava","sourceNew":"  /**\n     *\n     */\n  public void testPhrasePrefix() throws IOException {\n    RAMDirectory indexStore = new RAMDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), indexStore);\n    Document doc1 = new Document();\n    Document doc2 = new Document();\n    Document doc3 = new Document();\n    Document doc4 = new Document();\n    Document doc5 = new Document();\n    doc1.add(new Field(\"body\", \"blueberry pie\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc2.add(new Field(\"body\", \"blueberry strudel\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc3.add(new Field(\"body\", \"blueberry pizza\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc4.add(new Field(\"body\", \"blueberry chewing gum\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc5.add(new Field(\"body\", \"piccadilly circus\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    writer.addDocument(doc1);\n    writer.addDocument(doc2);\n    writer.addDocument(doc3);\n    writer.addDocument(doc4);\n    writer.addDocument(doc5);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    IndexSearcher searcher = new IndexSearcher(reader);\n    \n    // PhrasePrefixQuery query1 = new PhrasePrefixQuery();\n    MultiPhraseQuery query1 = new MultiPhraseQuery();\n    // PhrasePrefixQuery query2 = new PhrasePrefixQuery();\n    MultiPhraseQuery query2 = new MultiPhraseQuery();\n    query1.add(new Term(\"body\", \"blueberry\"));\n    query2.add(new Term(\"body\", \"strawberry\"));\n    \n    LinkedList<Term> termsWithPrefix = new LinkedList<Term>();\n    \n    // this TermEnum gives \"piccadilly\", \"pie\" and \"pizza\".\n    String prefix = \"pi\";\n    TermsEnum te = MultiFields.getFields(reader).terms(\"body\").iterator();\n    te.seek(new BytesRef(prefix));\n    do {\n      String s = te.term().utf8ToString();\n      if (s.startsWith(prefix)) {\n        termsWithPrefix.add(new Term(\"body\", s));\n      } else {\n        break;\n      }\n    } while (te.next() != null);\n    \n    query1.add(termsWithPrefix.toArray(new Term[0]));\n    query2.add(termsWithPrefix.toArray(new Term[0]));\n    \n    ScoreDoc[] result;\n    result = searcher.search(query1, null, 1000).scoreDocs;\n    assertEquals(2, result.length);\n    \n    result = searcher.search(query2, null, 1000).scoreDocs;\n    assertEquals(0, result.length);\n    searcher.close();\n    reader.close();\n    indexStore.close();\n  }\n\n","sourceOld":"  /**\n     *\n     */\n  public void testPhrasePrefix() throws IOException {\n    RAMDirectory indexStore = new RAMDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), indexStore,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n    Document doc1 = new Document();\n    Document doc2 = new Document();\n    Document doc3 = new Document();\n    Document doc4 = new Document();\n    Document doc5 = new Document();\n    doc1.add(new Field(\"body\", \"blueberry pie\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc2.add(new Field(\"body\", \"blueberry strudel\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc3.add(new Field(\"body\", \"blueberry pizza\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc4.add(new Field(\"body\", \"blueberry chewing gum\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc5.add(new Field(\"body\", \"piccadilly circus\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    writer.addDocument(doc1);\n    writer.addDocument(doc2);\n    writer.addDocument(doc3);\n    writer.addDocument(doc4);\n    writer.addDocument(doc5);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    IndexSearcher searcher = new IndexSearcher(reader);\n    \n    // PhrasePrefixQuery query1 = new PhrasePrefixQuery();\n    MultiPhraseQuery query1 = new MultiPhraseQuery();\n    // PhrasePrefixQuery query2 = new PhrasePrefixQuery();\n    MultiPhraseQuery query2 = new MultiPhraseQuery();\n    query1.add(new Term(\"body\", \"blueberry\"));\n    query2.add(new Term(\"body\", \"strawberry\"));\n    \n    LinkedList<Term> termsWithPrefix = new LinkedList<Term>();\n    \n    // this TermEnum gives \"piccadilly\", \"pie\" and \"pizza\".\n    String prefix = \"pi\";\n    TermsEnum te = MultiFields.getFields(reader).terms(\"body\").iterator();\n    te.seek(new BytesRef(prefix));\n    do {\n      String s = te.term().utf8ToString();\n      if (s.startsWith(prefix)) {\n        termsWithPrefix.add(new Term(\"body\", s));\n      } else {\n        break;\n      }\n    } while (te.next() != null);\n    \n    query1.add(termsWithPrefix.toArray(new Term[0]));\n    query2.add(termsWithPrefix.toArray(new Term[0]));\n    \n    ScoreDoc[] result;\n    result = searcher.search(query1, null, 1000).scoreDocs;\n    assertEquals(2, result.length);\n    \n    result = searcher.search(query2, null, 1000).scoreDocs;\n    assertEquals(0, result.length);\n    searcher.close();\n    reader.close();\n    indexStore.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1a2e46fd1b7cbc52d7d6461a6ef99e7107ae2a9c","date":1281477834,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPhrasePrefixQuery#testPhrasePrefix().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPhrasePrefixQuery#testPhrasePrefix().mjava","sourceNew":"  /**\n     *\n     */\n  public void testPhrasePrefix() throws IOException {\n    MockRAMDirectory indexStore = new MockRAMDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), indexStore);\n    Document doc1 = new Document();\n    Document doc2 = new Document();\n    Document doc3 = new Document();\n    Document doc4 = new Document();\n    Document doc5 = new Document();\n    doc1.add(new Field(\"body\", \"blueberry pie\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc2.add(new Field(\"body\", \"blueberry strudel\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc3.add(new Field(\"body\", \"blueberry pizza\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc4.add(new Field(\"body\", \"blueberry chewing gum\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc5.add(new Field(\"body\", \"piccadilly circus\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    writer.addDocument(doc1);\n    writer.addDocument(doc2);\n    writer.addDocument(doc3);\n    writer.addDocument(doc4);\n    writer.addDocument(doc5);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    IndexSearcher searcher = new IndexSearcher(reader);\n    \n    // PhrasePrefixQuery query1 = new PhrasePrefixQuery();\n    MultiPhraseQuery query1 = new MultiPhraseQuery();\n    // PhrasePrefixQuery query2 = new PhrasePrefixQuery();\n    MultiPhraseQuery query2 = new MultiPhraseQuery();\n    query1.add(new Term(\"body\", \"blueberry\"));\n    query2.add(new Term(\"body\", \"strawberry\"));\n    \n    LinkedList<Term> termsWithPrefix = new LinkedList<Term>();\n    \n    // this TermEnum gives \"piccadilly\", \"pie\" and \"pizza\".\n    String prefix = \"pi\";\n    TermsEnum te = MultiFields.getFields(reader).terms(\"body\").iterator();\n    te.seek(new BytesRef(prefix));\n    do {\n      String s = te.term().utf8ToString();\n      if (s.startsWith(prefix)) {\n        termsWithPrefix.add(new Term(\"body\", s));\n      } else {\n        break;\n      }\n    } while (te.next() != null);\n    \n    query1.add(termsWithPrefix.toArray(new Term[0]));\n    query2.add(termsWithPrefix.toArray(new Term[0]));\n    \n    ScoreDoc[] result;\n    result = searcher.search(query1, null, 1000).scoreDocs;\n    assertEquals(2, result.length);\n    \n    result = searcher.search(query2, null, 1000).scoreDocs;\n    assertEquals(0, result.length);\n    searcher.close();\n    reader.close();\n    indexStore.close();\n  }\n\n","sourceOld":"  /**\n     *\n     */\n  public void testPhrasePrefix() throws IOException {\n    RAMDirectory indexStore = new RAMDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), indexStore);\n    Document doc1 = new Document();\n    Document doc2 = new Document();\n    Document doc3 = new Document();\n    Document doc4 = new Document();\n    Document doc5 = new Document();\n    doc1.add(new Field(\"body\", \"blueberry pie\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc2.add(new Field(\"body\", \"blueberry strudel\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc3.add(new Field(\"body\", \"blueberry pizza\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc4.add(new Field(\"body\", \"blueberry chewing gum\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc5.add(new Field(\"body\", \"piccadilly circus\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    writer.addDocument(doc1);\n    writer.addDocument(doc2);\n    writer.addDocument(doc3);\n    writer.addDocument(doc4);\n    writer.addDocument(doc5);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    IndexSearcher searcher = new IndexSearcher(reader);\n    \n    // PhrasePrefixQuery query1 = new PhrasePrefixQuery();\n    MultiPhraseQuery query1 = new MultiPhraseQuery();\n    // PhrasePrefixQuery query2 = new PhrasePrefixQuery();\n    MultiPhraseQuery query2 = new MultiPhraseQuery();\n    query1.add(new Term(\"body\", \"blueberry\"));\n    query2.add(new Term(\"body\", \"strawberry\"));\n    \n    LinkedList<Term> termsWithPrefix = new LinkedList<Term>();\n    \n    // this TermEnum gives \"piccadilly\", \"pie\" and \"pizza\".\n    String prefix = \"pi\";\n    TermsEnum te = MultiFields.getFields(reader).terms(\"body\").iterator();\n    te.seek(new BytesRef(prefix));\n    do {\n      String s = te.term().utf8ToString();\n      if (s.startsWith(prefix)) {\n        termsWithPrefix.add(new Term(\"body\", s));\n      } else {\n        break;\n      }\n    } while (te.next() != null);\n    \n    query1.add(termsWithPrefix.toArray(new Term[0]));\n    query2.add(termsWithPrefix.toArray(new Term[0]));\n    \n    ScoreDoc[] result;\n    result = searcher.search(query1, null, 1000).scoreDocs;\n    assertEquals(2, result.length);\n    \n    result = searcher.search(query2, null, 1000).scoreDocs;\n    assertEquals(0, result.length);\n    searcher.close();\n    reader.close();\n    indexStore.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c","date":1281646583,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPhrasePrefixQuery#testPhrasePrefix().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPhrasePrefixQuery#testPhrasePrefix().mjava","sourceNew":"  /**\n     *\n     */\n  public void testPhrasePrefix() throws IOException {\n    Random random = newRandom();\n    MockRAMDirectory indexStore = newDirectory(random);\n    RandomIndexWriter writer = new RandomIndexWriter(random, indexStore);\n    Document doc1 = new Document();\n    Document doc2 = new Document();\n    Document doc3 = new Document();\n    Document doc4 = new Document();\n    Document doc5 = new Document();\n    doc1.add(new Field(\"body\", \"blueberry pie\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc2.add(new Field(\"body\", \"blueberry strudel\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc3.add(new Field(\"body\", \"blueberry pizza\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc4.add(new Field(\"body\", \"blueberry chewing gum\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc5.add(new Field(\"body\", \"piccadilly circus\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    writer.addDocument(doc1);\n    writer.addDocument(doc2);\n    writer.addDocument(doc3);\n    writer.addDocument(doc4);\n    writer.addDocument(doc5);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    IndexSearcher searcher = new IndexSearcher(reader);\n    \n    // PhrasePrefixQuery query1 = new PhrasePrefixQuery();\n    MultiPhraseQuery query1 = new MultiPhraseQuery();\n    // PhrasePrefixQuery query2 = new PhrasePrefixQuery();\n    MultiPhraseQuery query2 = new MultiPhraseQuery();\n    query1.add(new Term(\"body\", \"blueberry\"));\n    query2.add(new Term(\"body\", \"strawberry\"));\n    \n    LinkedList<Term> termsWithPrefix = new LinkedList<Term>();\n    \n    // this TermEnum gives \"piccadilly\", \"pie\" and \"pizza\".\n    String prefix = \"pi\";\n    TermsEnum te = MultiFields.getFields(reader).terms(\"body\").iterator();\n    te.seek(new BytesRef(prefix));\n    do {\n      String s = te.term().utf8ToString();\n      if (s.startsWith(prefix)) {\n        termsWithPrefix.add(new Term(\"body\", s));\n      } else {\n        break;\n      }\n    } while (te.next() != null);\n    \n    query1.add(termsWithPrefix.toArray(new Term[0]));\n    query2.add(termsWithPrefix.toArray(new Term[0]));\n    \n    ScoreDoc[] result;\n    result = searcher.search(query1, null, 1000).scoreDocs;\n    assertEquals(2, result.length);\n    \n    result = searcher.search(query2, null, 1000).scoreDocs;\n    assertEquals(0, result.length);\n    searcher.close();\n    reader.close();\n    indexStore.close();\n  }\n\n","sourceOld":"  /**\n     *\n     */\n  public void testPhrasePrefix() throws IOException {\n    MockRAMDirectory indexStore = new MockRAMDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), indexStore);\n    Document doc1 = new Document();\n    Document doc2 = new Document();\n    Document doc3 = new Document();\n    Document doc4 = new Document();\n    Document doc5 = new Document();\n    doc1.add(new Field(\"body\", \"blueberry pie\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc2.add(new Field(\"body\", \"blueberry strudel\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc3.add(new Field(\"body\", \"blueberry pizza\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc4.add(new Field(\"body\", \"blueberry chewing gum\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc5.add(new Field(\"body\", \"piccadilly circus\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    writer.addDocument(doc1);\n    writer.addDocument(doc2);\n    writer.addDocument(doc3);\n    writer.addDocument(doc4);\n    writer.addDocument(doc5);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    IndexSearcher searcher = new IndexSearcher(reader);\n    \n    // PhrasePrefixQuery query1 = new PhrasePrefixQuery();\n    MultiPhraseQuery query1 = new MultiPhraseQuery();\n    // PhrasePrefixQuery query2 = new PhrasePrefixQuery();\n    MultiPhraseQuery query2 = new MultiPhraseQuery();\n    query1.add(new Term(\"body\", \"blueberry\"));\n    query2.add(new Term(\"body\", \"strawberry\"));\n    \n    LinkedList<Term> termsWithPrefix = new LinkedList<Term>();\n    \n    // this TermEnum gives \"piccadilly\", \"pie\" and \"pizza\".\n    String prefix = \"pi\";\n    TermsEnum te = MultiFields.getFields(reader).terms(\"body\").iterator();\n    te.seek(new BytesRef(prefix));\n    do {\n      String s = te.term().utf8ToString();\n      if (s.startsWith(prefix)) {\n        termsWithPrefix.add(new Term(\"body\", s));\n      } else {\n        break;\n      }\n    } while (te.next() != null);\n    \n    query1.add(termsWithPrefix.toArray(new Term[0]));\n    query2.add(termsWithPrefix.toArray(new Term[0]));\n    \n    ScoreDoc[] result;\n    result = searcher.search(query1, null, 1000).scoreDocs;\n    assertEquals(2, result.length);\n    \n    result = searcher.search(query2, null, 1000).scoreDocs;\n    assertEquals(0, result.length);\n    searcher.close();\n    reader.close();\n    indexStore.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a05409176bd65129d67a785ee70e881e238a9aef","date":1282582843,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPhrasePrefixQuery#testPhrasePrefix().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPhrasePrefixQuery#testPhrasePrefix().mjava","sourceNew":"  /**\n     *\n     */\n  public void testPhrasePrefix() throws IOException {\n    Random random = newRandom();\n    Directory indexStore = newDirectory(random);\n    RandomIndexWriter writer = new RandomIndexWriter(random, indexStore);\n    Document doc1 = new Document();\n    Document doc2 = new Document();\n    Document doc3 = new Document();\n    Document doc4 = new Document();\n    Document doc5 = new Document();\n    doc1.add(new Field(\"body\", \"blueberry pie\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc2.add(new Field(\"body\", \"blueberry strudel\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc3.add(new Field(\"body\", \"blueberry pizza\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc4.add(new Field(\"body\", \"blueberry chewing gum\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc5.add(new Field(\"body\", \"piccadilly circus\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    writer.addDocument(doc1);\n    writer.addDocument(doc2);\n    writer.addDocument(doc3);\n    writer.addDocument(doc4);\n    writer.addDocument(doc5);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    IndexSearcher searcher = new IndexSearcher(reader);\n    \n    // PhrasePrefixQuery query1 = new PhrasePrefixQuery();\n    MultiPhraseQuery query1 = new MultiPhraseQuery();\n    // PhrasePrefixQuery query2 = new PhrasePrefixQuery();\n    MultiPhraseQuery query2 = new MultiPhraseQuery();\n    query1.add(new Term(\"body\", \"blueberry\"));\n    query2.add(new Term(\"body\", \"strawberry\"));\n    \n    LinkedList<Term> termsWithPrefix = new LinkedList<Term>();\n    \n    // this TermEnum gives \"piccadilly\", \"pie\" and \"pizza\".\n    String prefix = \"pi\";\n    TermsEnum te = MultiFields.getFields(reader).terms(\"body\").iterator();\n    te.seek(new BytesRef(prefix));\n    do {\n      String s = te.term().utf8ToString();\n      if (s.startsWith(prefix)) {\n        termsWithPrefix.add(new Term(\"body\", s));\n      } else {\n        break;\n      }\n    } while (te.next() != null);\n    \n    query1.add(termsWithPrefix.toArray(new Term[0]));\n    query2.add(termsWithPrefix.toArray(new Term[0]));\n    \n    ScoreDoc[] result;\n    result = searcher.search(query1, null, 1000).scoreDocs;\n    assertEquals(2, result.length);\n    \n    result = searcher.search(query2, null, 1000).scoreDocs;\n    assertEquals(0, result.length);\n    searcher.close();\n    reader.close();\n    indexStore.close();\n  }\n\n","sourceOld":"  /**\n     *\n     */\n  public void testPhrasePrefix() throws IOException {\n    Random random = newRandom();\n    MockRAMDirectory indexStore = newDirectory(random);\n    RandomIndexWriter writer = new RandomIndexWriter(random, indexStore);\n    Document doc1 = new Document();\n    Document doc2 = new Document();\n    Document doc3 = new Document();\n    Document doc4 = new Document();\n    Document doc5 = new Document();\n    doc1.add(new Field(\"body\", \"blueberry pie\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc2.add(new Field(\"body\", \"blueberry strudel\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc3.add(new Field(\"body\", \"blueberry pizza\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc4.add(new Field(\"body\", \"blueberry chewing gum\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc5.add(new Field(\"body\", \"piccadilly circus\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    writer.addDocument(doc1);\n    writer.addDocument(doc2);\n    writer.addDocument(doc3);\n    writer.addDocument(doc4);\n    writer.addDocument(doc5);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    IndexSearcher searcher = new IndexSearcher(reader);\n    \n    // PhrasePrefixQuery query1 = new PhrasePrefixQuery();\n    MultiPhraseQuery query1 = new MultiPhraseQuery();\n    // PhrasePrefixQuery query2 = new PhrasePrefixQuery();\n    MultiPhraseQuery query2 = new MultiPhraseQuery();\n    query1.add(new Term(\"body\", \"blueberry\"));\n    query2.add(new Term(\"body\", \"strawberry\"));\n    \n    LinkedList<Term> termsWithPrefix = new LinkedList<Term>();\n    \n    // this TermEnum gives \"piccadilly\", \"pie\" and \"pizza\".\n    String prefix = \"pi\";\n    TermsEnum te = MultiFields.getFields(reader).terms(\"body\").iterator();\n    te.seek(new BytesRef(prefix));\n    do {\n      String s = te.term().utf8ToString();\n      if (s.startsWith(prefix)) {\n        termsWithPrefix.add(new Term(\"body\", s));\n      } else {\n        break;\n      }\n    } while (te.next() != null);\n    \n    query1.add(termsWithPrefix.toArray(new Term[0]));\n    query2.add(termsWithPrefix.toArray(new Term[0]));\n    \n    ScoreDoc[] result;\n    result = searcher.search(query1, null, 1000).scoreDocs;\n    assertEquals(2, result.length);\n    \n    result = searcher.search(query2, null, 1000).scoreDocs;\n    assertEquals(0, result.length);\n    searcher.close();\n    reader.close();\n    indexStore.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1f653cfcf159baeaafe5d01682a911e95bba4012","date":1284122058,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPhrasePrefixQuery#testPhrasePrefix().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPhrasePrefixQuery#testPhrasePrefix().mjava","sourceNew":"  /**\n     *\n     */\n  public void testPhrasePrefix() throws IOException {\n    Directory indexStore = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, indexStore);\n    Document doc1 = new Document();\n    Document doc2 = new Document();\n    Document doc3 = new Document();\n    Document doc4 = new Document();\n    Document doc5 = new Document();\n    doc1.add(new Field(\"body\", \"blueberry pie\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc2.add(new Field(\"body\", \"blueberry strudel\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc3.add(new Field(\"body\", \"blueberry pizza\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc4.add(new Field(\"body\", \"blueberry chewing gum\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc5.add(new Field(\"body\", \"piccadilly circus\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    writer.addDocument(doc1);\n    writer.addDocument(doc2);\n    writer.addDocument(doc3);\n    writer.addDocument(doc4);\n    writer.addDocument(doc5);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    IndexSearcher searcher = new IndexSearcher(reader);\n    \n    // PhrasePrefixQuery query1 = new PhrasePrefixQuery();\n    MultiPhraseQuery query1 = new MultiPhraseQuery();\n    // PhrasePrefixQuery query2 = new PhrasePrefixQuery();\n    MultiPhraseQuery query2 = new MultiPhraseQuery();\n    query1.add(new Term(\"body\", \"blueberry\"));\n    query2.add(new Term(\"body\", \"strawberry\"));\n    \n    LinkedList<Term> termsWithPrefix = new LinkedList<Term>();\n    \n    // this TermEnum gives \"piccadilly\", \"pie\" and \"pizza\".\n    String prefix = \"pi\";\n    TermsEnum te = MultiFields.getFields(reader).terms(\"body\").iterator();\n    te.seek(new BytesRef(prefix));\n    do {\n      String s = te.term().utf8ToString();\n      if (s.startsWith(prefix)) {\n        termsWithPrefix.add(new Term(\"body\", s));\n      } else {\n        break;\n      }\n    } while (te.next() != null);\n    \n    query1.add(termsWithPrefix.toArray(new Term[0]));\n    query2.add(termsWithPrefix.toArray(new Term[0]));\n    \n    ScoreDoc[] result;\n    result = searcher.search(query1, null, 1000).scoreDocs;\n    assertEquals(2, result.length);\n    \n    result = searcher.search(query2, null, 1000).scoreDocs;\n    assertEquals(0, result.length);\n    searcher.close();\n    reader.close();\n    indexStore.close();\n  }\n\n","sourceOld":"  /**\n     *\n     */\n  public void testPhrasePrefix() throws IOException {\n    Random random = newRandom();\n    Directory indexStore = newDirectory(random);\n    RandomIndexWriter writer = new RandomIndexWriter(random, indexStore);\n    Document doc1 = new Document();\n    Document doc2 = new Document();\n    Document doc3 = new Document();\n    Document doc4 = new Document();\n    Document doc5 = new Document();\n    doc1.add(new Field(\"body\", \"blueberry pie\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc2.add(new Field(\"body\", \"blueberry strudel\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc3.add(new Field(\"body\", \"blueberry pizza\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc4.add(new Field(\"body\", \"blueberry chewing gum\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc5.add(new Field(\"body\", \"piccadilly circus\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    writer.addDocument(doc1);\n    writer.addDocument(doc2);\n    writer.addDocument(doc3);\n    writer.addDocument(doc4);\n    writer.addDocument(doc5);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    IndexSearcher searcher = new IndexSearcher(reader);\n    \n    // PhrasePrefixQuery query1 = new PhrasePrefixQuery();\n    MultiPhraseQuery query1 = new MultiPhraseQuery();\n    // PhrasePrefixQuery query2 = new PhrasePrefixQuery();\n    MultiPhraseQuery query2 = new MultiPhraseQuery();\n    query1.add(new Term(\"body\", \"blueberry\"));\n    query2.add(new Term(\"body\", \"strawberry\"));\n    \n    LinkedList<Term> termsWithPrefix = new LinkedList<Term>();\n    \n    // this TermEnum gives \"piccadilly\", \"pie\" and \"pizza\".\n    String prefix = \"pi\";\n    TermsEnum te = MultiFields.getFields(reader).terms(\"body\").iterator();\n    te.seek(new BytesRef(prefix));\n    do {\n      String s = te.term().utf8ToString();\n      if (s.startsWith(prefix)) {\n        termsWithPrefix.add(new Term(\"body\", s));\n      } else {\n        break;\n      }\n    } while (te.next() != null);\n    \n    query1.add(termsWithPrefix.toArray(new Term[0]));\n    query2.add(termsWithPrefix.toArray(new Term[0]));\n    \n    ScoreDoc[] result;\n    result = searcher.search(query1, null, 1000).scoreDocs;\n    assertEquals(2, result.length);\n    \n    result = searcher.search(query2, null, 1000).scoreDocs;\n    assertEquals(0, result.length);\n    searcher.close();\n    reader.close();\n    indexStore.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"132903c28af3aa6f67284b78de91c0f0a99488c2","date":1284282129,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPhrasePrefixQuery#testPhrasePrefix().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPhrasePrefixQuery#testPhrasePrefix().mjava","sourceNew":"  /**\n     *\n     */\n  public void testPhrasePrefix() throws IOException {\n    Directory indexStore = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, indexStore);\n    Document doc1 = new Document();\n    Document doc2 = new Document();\n    Document doc3 = new Document();\n    Document doc4 = new Document();\n    Document doc5 = new Document();\n    doc1.add(newField(\"body\", \"blueberry pie\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc2.add(newField(\"body\", \"blueberry strudel\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc3.add(newField(\"body\", \"blueberry pizza\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc4.add(newField(\"body\", \"blueberry chewing gum\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc5.add(newField(\"body\", \"piccadilly circus\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    writer.addDocument(doc1);\n    writer.addDocument(doc2);\n    writer.addDocument(doc3);\n    writer.addDocument(doc4);\n    writer.addDocument(doc5);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    IndexSearcher searcher = new IndexSearcher(reader);\n    \n    // PhrasePrefixQuery query1 = new PhrasePrefixQuery();\n    MultiPhraseQuery query1 = new MultiPhraseQuery();\n    // PhrasePrefixQuery query2 = new PhrasePrefixQuery();\n    MultiPhraseQuery query2 = new MultiPhraseQuery();\n    query1.add(new Term(\"body\", \"blueberry\"));\n    query2.add(new Term(\"body\", \"strawberry\"));\n    \n    LinkedList<Term> termsWithPrefix = new LinkedList<Term>();\n    \n    // this TermEnum gives \"piccadilly\", \"pie\" and \"pizza\".\n    String prefix = \"pi\";\n    TermsEnum te = MultiFields.getFields(reader).terms(\"body\").iterator();\n    te.seek(new BytesRef(prefix));\n    do {\n      String s = te.term().utf8ToString();\n      if (s.startsWith(prefix)) {\n        termsWithPrefix.add(new Term(\"body\", s));\n      } else {\n        break;\n      }\n    } while (te.next() != null);\n    \n    query1.add(termsWithPrefix.toArray(new Term[0]));\n    query2.add(termsWithPrefix.toArray(new Term[0]));\n    \n    ScoreDoc[] result;\n    result = searcher.search(query1, null, 1000).scoreDocs;\n    assertEquals(2, result.length);\n    \n    result = searcher.search(query2, null, 1000).scoreDocs;\n    assertEquals(0, result.length);\n    searcher.close();\n    reader.close();\n    indexStore.close();\n  }\n\n","sourceOld":"  /**\n     *\n     */\n  public void testPhrasePrefix() throws IOException {\n    Directory indexStore = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, indexStore);\n    Document doc1 = new Document();\n    Document doc2 = new Document();\n    Document doc3 = new Document();\n    Document doc4 = new Document();\n    Document doc5 = new Document();\n    doc1.add(new Field(\"body\", \"blueberry pie\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc2.add(new Field(\"body\", \"blueberry strudel\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc3.add(new Field(\"body\", \"blueberry pizza\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc4.add(new Field(\"body\", \"blueberry chewing gum\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc5.add(new Field(\"body\", \"piccadilly circus\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    writer.addDocument(doc1);\n    writer.addDocument(doc2);\n    writer.addDocument(doc3);\n    writer.addDocument(doc4);\n    writer.addDocument(doc5);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    IndexSearcher searcher = new IndexSearcher(reader);\n    \n    // PhrasePrefixQuery query1 = new PhrasePrefixQuery();\n    MultiPhraseQuery query1 = new MultiPhraseQuery();\n    // PhrasePrefixQuery query2 = new PhrasePrefixQuery();\n    MultiPhraseQuery query2 = new MultiPhraseQuery();\n    query1.add(new Term(\"body\", \"blueberry\"));\n    query2.add(new Term(\"body\", \"strawberry\"));\n    \n    LinkedList<Term> termsWithPrefix = new LinkedList<Term>();\n    \n    // this TermEnum gives \"piccadilly\", \"pie\" and \"pizza\".\n    String prefix = \"pi\";\n    TermsEnum te = MultiFields.getFields(reader).terms(\"body\").iterator();\n    te.seek(new BytesRef(prefix));\n    do {\n      String s = te.term().utf8ToString();\n      if (s.startsWith(prefix)) {\n        termsWithPrefix.add(new Term(\"body\", s));\n      } else {\n        break;\n      }\n    } while (te.next() != null);\n    \n    query1.add(termsWithPrefix.toArray(new Term[0]));\n    query2.add(termsWithPrefix.toArray(new Term[0]));\n    \n    ScoreDoc[] result;\n    result = searcher.search(query1, null, 1000).scoreDocs;\n    assertEquals(2, result.length);\n    \n    result = searcher.search(query2, null, 1000).scoreDocs;\n    assertEquals(0, result.length);\n    searcher.close();\n    reader.close();\n    indexStore.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPhrasePrefixQuery#testPhrasePrefix().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPhrasePrefixQuery#testPhrasePrefix().mjava","sourceNew":"  /**\n     *\n     */\n  public void testPhrasePrefix() throws IOException {\n    Directory indexStore = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, indexStore);\n    Document doc1 = new Document();\n    Document doc2 = new Document();\n    Document doc3 = new Document();\n    Document doc4 = new Document();\n    Document doc5 = new Document();\n    doc1.add(newField(\"body\", \"blueberry pie\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc2.add(newField(\"body\", \"blueberry strudel\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc3.add(newField(\"body\", \"blueberry pizza\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc4.add(newField(\"body\", \"blueberry chewing gum\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc5.add(newField(\"body\", \"piccadilly circus\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    writer.addDocument(doc1);\n    writer.addDocument(doc2);\n    writer.addDocument(doc3);\n    writer.addDocument(doc4);\n    writer.addDocument(doc5);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    IndexSearcher searcher = new IndexSearcher(reader);\n    \n    // PhrasePrefixQuery query1 = new PhrasePrefixQuery();\n    MultiPhraseQuery query1 = new MultiPhraseQuery();\n    // PhrasePrefixQuery query2 = new PhrasePrefixQuery();\n    MultiPhraseQuery query2 = new MultiPhraseQuery();\n    query1.add(new Term(\"body\", \"blueberry\"));\n    query2.add(new Term(\"body\", \"strawberry\"));\n    \n    LinkedList<Term> termsWithPrefix = new LinkedList<Term>();\n    \n    // this TermEnum gives \"piccadilly\", \"pie\" and \"pizza\".\n    String prefix = \"pi\";\n    TermsEnum te = MultiFields.getFields(reader).terms(\"body\").iterator();\n    te.seek(new BytesRef(prefix));\n    do {\n      String s = te.term().utf8ToString();\n      if (s.startsWith(prefix)) {\n        termsWithPrefix.add(new Term(\"body\", s));\n      } else {\n        break;\n      }\n    } while (te.next() != null);\n    \n    query1.add(termsWithPrefix.toArray(new Term[0]));\n    query2.add(termsWithPrefix.toArray(new Term[0]));\n    \n    ScoreDoc[] result;\n    result = searcher.search(query1, null, 1000).scoreDocs;\n    assertEquals(2, result.length);\n    \n    result = searcher.search(query2, null, 1000).scoreDocs;\n    assertEquals(0, result.length);\n    searcher.close();\n    reader.close();\n    indexStore.close();\n  }\n\n","sourceOld":"  /**\n     *\n     */\n  public void testPhrasePrefix() throws IOException {\n    RAMDirectory indexStore = new RAMDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(newRandom(), indexStore);\n    Document doc1 = new Document();\n    Document doc2 = new Document();\n    Document doc3 = new Document();\n    Document doc4 = new Document();\n    Document doc5 = new Document();\n    doc1.add(new Field(\"body\", \"blueberry pie\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc2.add(new Field(\"body\", \"blueberry strudel\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc3.add(new Field(\"body\", \"blueberry pizza\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc4.add(new Field(\"body\", \"blueberry chewing gum\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc5.add(new Field(\"body\", \"piccadilly circus\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    writer.addDocument(doc1);\n    writer.addDocument(doc2);\n    writer.addDocument(doc3);\n    writer.addDocument(doc4);\n    writer.addDocument(doc5);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    IndexSearcher searcher = new IndexSearcher(reader);\n    \n    // PhrasePrefixQuery query1 = new PhrasePrefixQuery();\n    MultiPhraseQuery query1 = new MultiPhraseQuery();\n    // PhrasePrefixQuery query2 = new PhrasePrefixQuery();\n    MultiPhraseQuery query2 = new MultiPhraseQuery();\n    query1.add(new Term(\"body\", \"blueberry\"));\n    query2.add(new Term(\"body\", \"strawberry\"));\n    \n    LinkedList<Term> termsWithPrefix = new LinkedList<Term>();\n    \n    // this TermEnum gives \"piccadilly\", \"pie\" and \"pizza\".\n    String prefix = \"pi\";\n    TermsEnum te = MultiFields.getFields(reader).terms(\"body\").iterator();\n    te.seek(new BytesRef(prefix));\n    do {\n      String s = te.term().utf8ToString();\n      if (s.startsWith(prefix)) {\n        termsWithPrefix.add(new Term(\"body\", s));\n      } else {\n        break;\n      }\n    } while (te.next() != null);\n    \n    query1.add(termsWithPrefix.toArray(new Term[0]));\n    query2.add(termsWithPrefix.toArray(new Term[0]));\n    \n    ScoreDoc[] result;\n    result = searcher.search(query1, null, 1000).scoreDocs;\n    assertEquals(2, result.length);\n    \n    result = searcher.search(query2, null, 1000).scoreDocs;\n    assertEquals(0, result.length);\n    searcher.close();\n    reader.close();\n    indexStore.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"790e1fde4caa765b3faaad3fbcd25c6973450336","date":1296689245,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPhrasePrefixQuery#testPhrasePrefix().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPhrasePrefixQuery#testPhrasePrefix().mjava","sourceNew":"  /**\n     *\n     */\n  public void testPhrasePrefix() throws IOException {\n    Directory indexStore = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, indexStore);\n    Document doc1 = new Document();\n    Document doc2 = new Document();\n    Document doc3 = new Document();\n    Document doc4 = new Document();\n    Document doc5 = new Document();\n    doc1.add(newField(\"body\", \"blueberry pie\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc2.add(newField(\"body\", \"blueberry strudel\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc3.add(newField(\"body\", \"blueberry pizza\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc4.add(newField(\"body\", \"blueberry chewing gum\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc5.add(newField(\"body\", \"piccadilly circus\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    writer.addDocument(doc1);\n    writer.addDocument(doc2);\n    writer.addDocument(doc3);\n    writer.addDocument(doc4);\n    writer.addDocument(doc5);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    IndexSearcher searcher = newSearcher(reader);\n    \n    // PhrasePrefixQuery query1 = new PhrasePrefixQuery();\n    MultiPhraseQuery query1 = new MultiPhraseQuery();\n    // PhrasePrefixQuery query2 = new PhrasePrefixQuery();\n    MultiPhraseQuery query2 = new MultiPhraseQuery();\n    query1.add(new Term(\"body\", \"blueberry\"));\n    query2.add(new Term(\"body\", \"strawberry\"));\n    \n    LinkedList<Term> termsWithPrefix = new LinkedList<Term>();\n    \n    // this TermEnum gives \"piccadilly\", \"pie\" and \"pizza\".\n    String prefix = \"pi\";\n    TermsEnum te = MultiFields.getFields(reader).terms(\"body\").iterator();\n    te.seek(new BytesRef(prefix));\n    do {\n      String s = te.term().utf8ToString();\n      if (s.startsWith(prefix)) {\n        termsWithPrefix.add(new Term(\"body\", s));\n      } else {\n        break;\n      }\n    } while (te.next() != null);\n    \n    query1.add(termsWithPrefix.toArray(new Term[0]));\n    query2.add(termsWithPrefix.toArray(new Term[0]));\n    \n    ScoreDoc[] result;\n    result = searcher.search(query1, null, 1000).scoreDocs;\n    assertEquals(2, result.length);\n    \n    result = searcher.search(query2, null, 1000).scoreDocs;\n    assertEquals(0, result.length);\n    searcher.close();\n    reader.close();\n    indexStore.close();\n  }\n\n","sourceOld":"  /**\n     *\n     */\n  public void testPhrasePrefix() throws IOException {\n    Directory indexStore = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, indexStore);\n    Document doc1 = new Document();\n    Document doc2 = new Document();\n    Document doc3 = new Document();\n    Document doc4 = new Document();\n    Document doc5 = new Document();\n    doc1.add(newField(\"body\", \"blueberry pie\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc2.add(newField(\"body\", \"blueberry strudel\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc3.add(newField(\"body\", \"blueberry pizza\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc4.add(newField(\"body\", \"blueberry chewing gum\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc5.add(newField(\"body\", \"piccadilly circus\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    writer.addDocument(doc1);\n    writer.addDocument(doc2);\n    writer.addDocument(doc3);\n    writer.addDocument(doc4);\n    writer.addDocument(doc5);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    IndexSearcher searcher = new IndexSearcher(reader);\n    \n    // PhrasePrefixQuery query1 = new PhrasePrefixQuery();\n    MultiPhraseQuery query1 = new MultiPhraseQuery();\n    // PhrasePrefixQuery query2 = new PhrasePrefixQuery();\n    MultiPhraseQuery query2 = new MultiPhraseQuery();\n    query1.add(new Term(\"body\", \"blueberry\"));\n    query2.add(new Term(\"body\", \"strawberry\"));\n    \n    LinkedList<Term> termsWithPrefix = new LinkedList<Term>();\n    \n    // this TermEnum gives \"piccadilly\", \"pie\" and \"pizza\".\n    String prefix = \"pi\";\n    TermsEnum te = MultiFields.getFields(reader).terms(\"body\").iterator();\n    te.seek(new BytesRef(prefix));\n    do {\n      String s = te.term().utf8ToString();\n      if (s.startsWith(prefix)) {\n        termsWithPrefix.add(new Term(\"body\", s));\n      } else {\n        break;\n      }\n    } while (te.next() != null);\n    \n    query1.add(termsWithPrefix.toArray(new Term[0]));\n    query2.add(termsWithPrefix.toArray(new Term[0]));\n    \n    ScoreDoc[] result;\n    result = searcher.search(query1, null, 1000).scoreDocs;\n    assertEquals(2, result.length);\n    \n    result = searcher.search(query2, null, 1000).scoreDocs;\n    assertEquals(0, result.length);\n    searcher.close();\n    reader.close();\n    indexStore.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"29ef99d61cda9641b6250bf9567329a6e65f901d","date":1297244127,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPhrasePrefixQuery#testPhrasePrefix().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPhrasePrefixQuery#testPhrasePrefix().mjava","sourceNew":"  /**\n     *\n     */\n  public void testPhrasePrefix() throws IOException {\n    Directory indexStore = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, indexStore);\n    Document doc1 = new Document();\n    Document doc2 = new Document();\n    Document doc3 = new Document();\n    Document doc4 = new Document();\n    Document doc5 = new Document();\n    doc1.add(newField(\"body\", \"blueberry pie\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc2.add(newField(\"body\", \"blueberry strudel\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc3.add(newField(\"body\", \"blueberry pizza\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc4.add(newField(\"body\", \"blueberry chewing gum\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc5.add(newField(\"body\", \"piccadilly circus\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    writer.addDocument(doc1);\n    writer.addDocument(doc2);\n    writer.addDocument(doc3);\n    writer.addDocument(doc4);\n    writer.addDocument(doc5);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    IndexSearcher searcher = newSearcher(reader);\n    \n    // PhrasePrefixQuery query1 = new PhrasePrefixQuery();\n    MultiPhraseQuery query1 = new MultiPhraseQuery();\n    // PhrasePrefixQuery query2 = new PhrasePrefixQuery();\n    MultiPhraseQuery query2 = new MultiPhraseQuery();\n    query1.add(new Term(\"body\", \"blueberry\"));\n    query2.add(new Term(\"body\", \"strawberry\"));\n    \n    LinkedList<Term> termsWithPrefix = new LinkedList<Term>();\n    \n    // this TermEnum gives \"piccadilly\", \"pie\" and \"pizza\".\n    String prefix = \"pi\";\n    TermsEnum te = MultiFields.getFields(reader).terms(\"body\").iterator();\n    te.seek(new BytesRef(prefix));\n    do {\n      String s = te.term().utf8ToString();\n      if (s.startsWith(prefix)) {\n        termsWithPrefix.add(new Term(\"body\", s));\n      } else {\n        break;\n      }\n    } while (te.next() != null);\n    \n    query1.add(termsWithPrefix.toArray(new Term[0]));\n    query2.add(termsWithPrefix.toArray(new Term[0]));\n    \n    ScoreDoc[] result;\n    result = searcher.search(query1, null, 1000).scoreDocs;\n    assertEquals(2, result.length);\n    \n    result = searcher.search(query2, null, 1000).scoreDocs;\n    assertEquals(0, result.length);\n    searcher.close();\n    reader.close();\n    indexStore.close();\n  }\n\n","sourceOld":"  /**\n     *\n     */\n  public void testPhrasePrefix() throws IOException {\n    Directory indexStore = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, indexStore);\n    Document doc1 = new Document();\n    Document doc2 = new Document();\n    Document doc3 = new Document();\n    Document doc4 = new Document();\n    Document doc5 = new Document();\n    doc1.add(newField(\"body\", \"blueberry pie\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc2.add(newField(\"body\", \"blueberry strudel\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc3.add(newField(\"body\", \"blueberry pizza\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc4.add(newField(\"body\", \"blueberry chewing gum\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc5.add(newField(\"body\", \"piccadilly circus\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    writer.addDocument(doc1);\n    writer.addDocument(doc2);\n    writer.addDocument(doc3);\n    writer.addDocument(doc4);\n    writer.addDocument(doc5);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    IndexSearcher searcher = new IndexSearcher(reader);\n    \n    // PhrasePrefixQuery query1 = new PhrasePrefixQuery();\n    MultiPhraseQuery query1 = new MultiPhraseQuery();\n    // PhrasePrefixQuery query2 = new PhrasePrefixQuery();\n    MultiPhraseQuery query2 = new MultiPhraseQuery();\n    query1.add(new Term(\"body\", \"blueberry\"));\n    query2.add(new Term(\"body\", \"strawberry\"));\n    \n    LinkedList<Term> termsWithPrefix = new LinkedList<Term>();\n    \n    // this TermEnum gives \"piccadilly\", \"pie\" and \"pizza\".\n    String prefix = \"pi\";\n    TermsEnum te = MultiFields.getFields(reader).terms(\"body\").iterator();\n    te.seek(new BytesRef(prefix));\n    do {\n      String s = te.term().utf8ToString();\n      if (s.startsWith(prefix)) {\n        termsWithPrefix.add(new Term(\"body\", s));\n      } else {\n        break;\n      }\n    } while (te.next() != null);\n    \n    query1.add(termsWithPrefix.toArray(new Term[0]));\n    query2.add(termsWithPrefix.toArray(new Term[0]));\n    \n    ScoreDoc[] result;\n    result = searcher.search(query1, null, 1000).scoreDocs;\n    assertEquals(2, result.length);\n    \n    result = searcher.search(query2, null, 1000).scoreDocs;\n    assertEquals(0, result.length);\n    searcher.close();\n    reader.close();\n    indexStore.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bde51b089eb7f86171eb3406e38a274743f9b7ac","date":1298336439,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPhrasePrefixQuery#testPhrasePrefix().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPhrasePrefixQuery#testPhrasePrefix().mjava","sourceNew":"  /**\n     *\n     */\n  public void testPhrasePrefix() throws IOException {\n    Directory indexStore = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, indexStore);\n    Document doc1 = new Document();\n    Document doc2 = new Document();\n    Document doc3 = new Document();\n    Document doc4 = new Document();\n    Document doc5 = new Document();\n    doc1.add(newField(\"body\", \"blueberry pie\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc2.add(newField(\"body\", \"blueberry strudel\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc3.add(newField(\"body\", \"blueberry pizza\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc4.add(newField(\"body\", \"blueberry chewing gum\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc5.add(newField(\"body\", \"piccadilly circus\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    writer.addDocument(doc1);\n    writer.addDocument(doc2);\n    writer.addDocument(doc3);\n    writer.addDocument(doc4);\n    writer.addDocument(doc5);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    IndexSearcher searcher = newSearcher(reader);\n    \n    // PhrasePrefixQuery query1 = new PhrasePrefixQuery();\n    MultiPhraseQuery query1 = new MultiPhraseQuery();\n    // PhrasePrefixQuery query2 = new PhrasePrefixQuery();\n    MultiPhraseQuery query2 = new MultiPhraseQuery();\n    query1.add(new Term(\"body\", \"blueberry\"));\n    query2.add(new Term(\"body\", \"strawberry\"));\n    \n    LinkedList<Term> termsWithPrefix = new LinkedList<Term>();\n    \n    // this TermEnum gives \"piccadilly\", \"pie\" and \"pizza\".\n    String prefix = \"pi\";\n    TermsEnum te = MultiFields.getFields(reader).terms(\"body\").iterator();\n    te.seek(new BytesRef(prefix));\n    do {\n      String s = te.term().utf8ToString();\n      if (s.startsWith(prefix)) {\n        termsWithPrefix.add(new Term(\"body\", s));\n      } else {\n        break;\n      }\n    } while (te.next() != null);\n    \n    query1.add(termsWithPrefix.toArray(new Term[0]));\n    query2.add(termsWithPrefix.toArray(new Term[0]));\n    \n    ScoreDoc[] result;\n    result = searcher.search(query1, null, 1000).scoreDocs;\n    assertEquals(2, result.length);\n    \n    result = searcher.search(query2, null, 1000).scoreDocs;\n    assertEquals(0, result.length);\n    searcher.close();\n    reader.close();\n    indexStore.close();\n  }\n\n","sourceOld":"  /**\n     *\n     */\n  public void testPhrasePrefix() throws IOException {\n    Directory indexStore = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, indexStore);\n    Document doc1 = new Document();\n    Document doc2 = new Document();\n    Document doc3 = new Document();\n    Document doc4 = new Document();\n    Document doc5 = new Document();\n    doc1.add(newField(\"body\", \"blueberry pie\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc2.add(newField(\"body\", \"blueberry strudel\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc3.add(newField(\"body\", \"blueberry pizza\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc4.add(newField(\"body\", \"blueberry chewing gum\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc5.add(newField(\"body\", \"piccadilly circus\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    writer.addDocument(doc1);\n    writer.addDocument(doc2);\n    writer.addDocument(doc3);\n    writer.addDocument(doc4);\n    writer.addDocument(doc5);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    IndexSearcher searcher = new IndexSearcher(reader);\n    \n    // PhrasePrefixQuery query1 = new PhrasePrefixQuery();\n    MultiPhraseQuery query1 = new MultiPhraseQuery();\n    // PhrasePrefixQuery query2 = new PhrasePrefixQuery();\n    MultiPhraseQuery query2 = new MultiPhraseQuery();\n    query1.add(new Term(\"body\", \"blueberry\"));\n    query2.add(new Term(\"body\", \"strawberry\"));\n    \n    LinkedList<Term> termsWithPrefix = new LinkedList<Term>();\n    \n    // this TermEnum gives \"piccadilly\", \"pie\" and \"pizza\".\n    String prefix = \"pi\";\n    TermsEnum te = MultiFields.getFields(reader).terms(\"body\").iterator();\n    te.seek(new BytesRef(prefix));\n    do {\n      String s = te.term().utf8ToString();\n      if (s.startsWith(prefix)) {\n        termsWithPrefix.add(new Term(\"body\", s));\n      } else {\n        break;\n      }\n    } while (te.next() != null);\n    \n    query1.add(termsWithPrefix.toArray(new Term[0]));\n    query2.add(termsWithPrefix.toArray(new Term[0]));\n    \n    ScoreDoc[] result;\n    result = searcher.search(query1, null, 1000).scoreDocs;\n    assertEquals(2, result.length);\n    \n    result = searcher.search(query2, null, 1000).scoreDocs;\n    assertEquals(0, result.length);\n    searcher.close();\n    reader.close();\n    indexStore.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fd9cc9d77712aba3662f24632df7539ab75e3667","date":1309095238,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPhrasePrefixQuery#testPhrasePrefix().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPhrasePrefixQuery#testPhrasePrefix().mjava","sourceNew":"  /**\n     *\n     */\n  public void testPhrasePrefix() throws IOException {\n    Directory indexStore = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, indexStore);\n    Document doc1 = new Document();\n    Document doc2 = new Document();\n    Document doc3 = new Document();\n    Document doc4 = new Document();\n    Document doc5 = new Document();\n    doc1.add(newField(\"body\", \"blueberry pie\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc2.add(newField(\"body\", \"blueberry strudel\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc3.add(newField(\"body\", \"blueberry pizza\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc4.add(newField(\"body\", \"blueberry chewing gum\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc5.add(newField(\"body\", \"piccadilly circus\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    writer.addDocument(doc1);\n    writer.addDocument(doc2);\n    writer.addDocument(doc3);\n    writer.addDocument(doc4);\n    writer.addDocument(doc5);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    IndexSearcher searcher = newSearcher(reader);\n    \n    // PhrasePrefixQuery query1 = new PhrasePrefixQuery();\n    MultiPhraseQuery query1 = new MultiPhraseQuery();\n    // PhrasePrefixQuery query2 = new PhrasePrefixQuery();\n    MultiPhraseQuery query2 = new MultiPhraseQuery();\n    query1.add(new Term(\"body\", \"blueberry\"));\n    query2.add(new Term(\"body\", \"strawberry\"));\n    \n    LinkedList<Term> termsWithPrefix = new LinkedList<Term>();\n    \n    // this TermEnum gives \"piccadilly\", \"pie\" and \"pizza\".\n    String prefix = \"pi\";\n    TermsEnum te = MultiFields.getFields(reader).terms(\"body\").iterator();\n    te.seekCeil(new BytesRef(prefix));\n    do {\n      String s = te.term().utf8ToString();\n      if (s.startsWith(prefix)) {\n        termsWithPrefix.add(new Term(\"body\", s));\n      } else {\n        break;\n      }\n    } while (te.next() != null);\n    \n    query1.add(termsWithPrefix.toArray(new Term[0]));\n    query2.add(termsWithPrefix.toArray(new Term[0]));\n    \n    ScoreDoc[] result;\n    result = searcher.search(query1, null, 1000).scoreDocs;\n    assertEquals(2, result.length);\n    \n    result = searcher.search(query2, null, 1000).scoreDocs;\n    assertEquals(0, result.length);\n    searcher.close();\n    reader.close();\n    indexStore.close();\n  }\n\n","sourceOld":"  /**\n     *\n     */\n  public void testPhrasePrefix() throws IOException {\n    Directory indexStore = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, indexStore);\n    Document doc1 = new Document();\n    Document doc2 = new Document();\n    Document doc3 = new Document();\n    Document doc4 = new Document();\n    Document doc5 = new Document();\n    doc1.add(newField(\"body\", \"blueberry pie\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc2.add(newField(\"body\", \"blueberry strudel\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc3.add(newField(\"body\", \"blueberry pizza\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc4.add(newField(\"body\", \"blueberry chewing gum\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc5.add(newField(\"body\", \"piccadilly circus\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    writer.addDocument(doc1);\n    writer.addDocument(doc2);\n    writer.addDocument(doc3);\n    writer.addDocument(doc4);\n    writer.addDocument(doc5);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    IndexSearcher searcher = newSearcher(reader);\n    \n    // PhrasePrefixQuery query1 = new PhrasePrefixQuery();\n    MultiPhraseQuery query1 = new MultiPhraseQuery();\n    // PhrasePrefixQuery query2 = new PhrasePrefixQuery();\n    MultiPhraseQuery query2 = new MultiPhraseQuery();\n    query1.add(new Term(\"body\", \"blueberry\"));\n    query2.add(new Term(\"body\", \"strawberry\"));\n    \n    LinkedList<Term> termsWithPrefix = new LinkedList<Term>();\n    \n    // this TermEnum gives \"piccadilly\", \"pie\" and \"pizza\".\n    String prefix = \"pi\";\n    TermsEnum te = MultiFields.getFields(reader).terms(\"body\").iterator();\n    te.seek(new BytesRef(prefix));\n    do {\n      String s = te.term().utf8ToString();\n      if (s.startsWith(prefix)) {\n        termsWithPrefix.add(new Term(\"body\", s));\n      } else {\n        break;\n      }\n    } while (te.next() != null);\n    \n    query1.add(termsWithPrefix.toArray(new Term[0]));\n    query2.add(termsWithPrefix.toArray(new Term[0]));\n    \n    ScoreDoc[] result;\n    result = searcher.search(query1, null, 1000).scoreDocs;\n    assertEquals(2, result.length);\n    \n    result = searcher.search(query2, null, 1000).scoreDocs;\n    assertEquals(0, result.length);\n    searcher.close();\n    reader.close();\n    indexStore.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2553b00f699380c64959ccb27991289aae87be2e","date":1309290151,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPhrasePrefixQuery#testPhrasePrefix().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPhrasePrefixQuery#testPhrasePrefix().mjava","sourceNew":"  /**\n     *\n     */\n  public void testPhrasePrefix() throws IOException {\n    Directory indexStore = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, indexStore);\n    Document doc1 = new Document();\n    Document doc2 = new Document();\n    Document doc3 = new Document();\n    Document doc4 = new Document();\n    Document doc5 = new Document();\n    doc1.add(newField(\"body\", \"blueberry pie\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc2.add(newField(\"body\", \"blueberry strudel\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc3.add(newField(\"body\", \"blueberry pizza\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc4.add(newField(\"body\", \"blueberry chewing gum\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc5.add(newField(\"body\", \"piccadilly circus\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    writer.addDocument(doc1);\n    writer.addDocument(doc2);\n    writer.addDocument(doc3);\n    writer.addDocument(doc4);\n    writer.addDocument(doc5);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    IndexSearcher searcher = newSearcher(reader);\n    \n    // PhrasePrefixQuery query1 = new PhrasePrefixQuery();\n    MultiPhraseQuery query1 = new MultiPhraseQuery();\n    // PhrasePrefixQuery query2 = new PhrasePrefixQuery();\n    MultiPhraseQuery query2 = new MultiPhraseQuery();\n    query1.add(new Term(\"body\", \"blueberry\"));\n    query2.add(new Term(\"body\", \"strawberry\"));\n    \n    LinkedList<Term> termsWithPrefix = new LinkedList<Term>();\n    \n    // this TermEnum gives \"piccadilly\", \"pie\" and \"pizza\".\n    String prefix = \"pi\";\n    TermsEnum te = MultiFields.getFields(reader).terms(\"body\").iterator();\n    te.seekCeil(new BytesRef(prefix));\n    do {\n      String s = te.term().utf8ToString();\n      if (s.startsWith(prefix)) {\n        termsWithPrefix.add(new Term(\"body\", s));\n      } else {\n        break;\n      }\n    } while (te.next() != null);\n    \n    query1.add(termsWithPrefix.toArray(new Term[0]));\n    query2.add(termsWithPrefix.toArray(new Term[0]));\n    \n    ScoreDoc[] result;\n    result = searcher.search(query1, null, 1000).scoreDocs;\n    assertEquals(2, result.length);\n    \n    result = searcher.search(query2, null, 1000).scoreDocs;\n    assertEquals(0, result.length);\n    searcher.close();\n    reader.close();\n    indexStore.close();\n  }\n\n","sourceOld":"  /**\n     *\n     */\n  public void testPhrasePrefix() throws IOException {\n    Directory indexStore = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, indexStore);\n    Document doc1 = new Document();\n    Document doc2 = new Document();\n    Document doc3 = new Document();\n    Document doc4 = new Document();\n    Document doc5 = new Document();\n    doc1.add(newField(\"body\", \"blueberry pie\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc2.add(newField(\"body\", \"blueberry strudel\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc3.add(newField(\"body\", \"blueberry pizza\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc4.add(newField(\"body\", \"blueberry chewing gum\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc5.add(newField(\"body\", \"piccadilly circus\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    writer.addDocument(doc1);\n    writer.addDocument(doc2);\n    writer.addDocument(doc3);\n    writer.addDocument(doc4);\n    writer.addDocument(doc5);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    IndexSearcher searcher = newSearcher(reader);\n    \n    // PhrasePrefixQuery query1 = new PhrasePrefixQuery();\n    MultiPhraseQuery query1 = new MultiPhraseQuery();\n    // PhrasePrefixQuery query2 = new PhrasePrefixQuery();\n    MultiPhraseQuery query2 = new MultiPhraseQuery();\n    query1.add(new Term(\"body\", \"blueberry\"));\n    query2.add(new Term(\"body\", \"strawberry\"));\n    \n    LinkedList<Term> termsWithPrefix = new LinkedList<Term>();\n    \n    // this TermEnum gives \"piccadilly\", \"pie\" and \"pizza\".\n    String prefix = \"pi\";\n    TermsEnum te = MultiFields.getFields(reader).terms(\"body\").iterator();\n    te.seek(new BytesRef(prefix));\n    do {\n      String s = te.term().utf8ToString();\n      if (s.startsWith(prefix)) {\n        termsWithPrefix.add(new Term(\"body\", s));\n      } else {\n        break;\n      }\n    } while (te.next() != null);\n    \n    query1.add(termsWithPrefix.toArray(new Term[0]));\n    query2.add(termsWithPrefix.toArray(new Term[0]));\n    \n    ScoreDoc[] result;\n    result = searcher.search(query1, null, 1000).scoreDocs;\n    assertEquals(2, result.length);\n    \n    result = searcher.search(query2, null, 1000).scoreDocs;\n    assertEquals(0, result.length);\n    searcher.close();\n    reader.close();\n    indexStore.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d083e83f225b11e5fdd900e83d26ddb385b6955c","date":1310029438,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPhrasePrefixQuery#testPhrasePrefix().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPhrasePrefixQuery#testPhrasePrefix().mjava","sourceNew":"  /**\n     *\n     */\n  public void testPhrasePrefix() throws IOException {\n    Directory indexStore = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, indexStore);\n    Document doc1 = new Document();\n    Document doc2 = new Document();\n    Document doc3 = new Document();\n    Document doc4 = new Document();\n    Document doc5 = new Document();\n    doc1.add(newField(\"body\", \"blueberry pie\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc2.add(newField(\"body\", \"blueberry strudel\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc3.add(newField(\"body\", \"blueberry pizza\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc4.add(newField(\"body\", \"blueberry chewing gum\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc5.add(newField(\"body\", \"piccadilly circus\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    writer.addDocument(doc1);\n    writer.addDocument(doc2);\n    writer.addDocument(doc3);\n    writer.addDocument(doc4);\n    writer.addDocument(doc5);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    IndexSearcher searcher = newSearcher(reader);\n    \n    // PhrasePrefixQuery query1 = new PhrasePrefixQuery();\n    MultiPhraseQuery query1 = new MultiPhraseQuery();\n    // PhrasePrefixQuery query2 = new PhrasePrefixQuery();\n    MultiPhraseQuery query2 = new MultiPhraseQuery();\n    query1.add(new Term(\"body\", \"blueberry\"));\n    query2.add(new Term(\"body\", \"strawberry\"));\n    \n    LinkedList<Term> termsWithPrefix = new LinkedList<Term>();\n    \n    // this TermEnum gives \"piccadilly\", \"pie\" and \"pizza\".\n    String prefix = \"pi\";\n    TermsEnum te = MultiFields.getFields(reader).terms(\"body\").iterator();\n    te.seekCeil(new BytesRef(prefix));\n    do {\n      String s = te.term().utf8ToString();\n      if (s.startsWith(prefix)) {\n        termsWithPrefix.add(new Term(\"body\", s));\n      } else {\n        break;\n      }\n    } while (te.next() != null);\n    \n    query1.add(termsWithPrefix.toArray(new Term[0]));\n    query2.add(termsWithPrefix.toArray(new Term[0]));\n    \n    ScoreDoc[] result;\n    result = searcher.search(query1, null, 1000).scoreDocs;\n    assertEquals(2, result.length);\n    \n    result = searcher.search(query2, null, 1000).scoreDocs;\n    assertEquals(0, result.length);\n    searcher.close();\n    reader.close();\n    indexStore.close();\n  }\n\n","sourceOld":"  /**\n     *\n     */\n  public void testPhrasePrefix() throws IOException {\n    Directory indexStore = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, indexStore);\n    Document doc1 = new Document();\n    Document doc2 = new Document();\n    Document doc3 = new Document();\n    Document doc4 = new Document();\n    Document doc5 = new Document();\n    doc1.add(newField(\"body\", \"blueberry pie\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc2.add(newField(\"body\", \"blueberry strudel\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc3.add(newField(\"body\", \"blueberry pizza\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc4.add(newField(\"body\", \"blueberry chewing gum\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc5.add(newField(\"body\", \"piccadilly circus\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    writer.addDocument(doc1);\n    writer.addDocument(doc2);\n    writer.addDocument(doc3);\n    writer.addDocument(doc4);\n    writer.addDocument(doc5);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    IndexSearcher searcher = newSearcher(reader);\n    \n    // PhrasePrefixQuery query1 = new PhrasePrefixQuery();\n    MultiPhraseQuery query1 = new MultiPhraseQuery();\n    // PhrasePrefixQuery query2 = new PhrasePrefixQuery();\n    MultiPhraseQuery query2 = new MultiPhraseQuery();\n    query1.add(new Term(\"body\", \"blueberry\"));\n    query2.add(new Term(\"body\", \"strawberry\"));\n    \n    LinkedList<Term> termsWithPrefix = new LinkedList<Term>();\n    \n    // this TermEnum gives \"piccadilly\", \"pie\" and \"pizza\".\n    String prefix = \"pi\";\n    TermsEnum te = MultiFields.getFields(reader).terms(\"body\").iterator();\n    te.seek(new BytesRef(prefix));\n    do {\n      String s = te.term().utf8ToString();\n      if (s.startsWith(prefix)) {\n        termsWithPrefix.add(new Term(\"body\", s));\n      } else {\n        break;\n      }\n    } while (te.next() != null);\n    \n    query1.add(termsWithPrefix.toArray(new Term[0]));\n    query2.add(termsWithPrefix.toArray(new Term[0]));\n    \n    ScoreDoc[] result;\n    result = searcher.search(query1, null, 1000).scoreDocs;\n    assertEquals(2, result.length);\n    \n    result = searcher.search(query2, null, 1000).scoreDocs;\n    assertEquals(0, result.length);\n    searcher.close();\n    reader.close();\n    indexStore.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1509f151d7692d84fae414b2b799ac06ba60fcb4","date":1314451621,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPhrasePrefixQuery#testPhrasePrefix().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPhrasePrefixQuery#testPhrasePrefix().mjava","sourceNew":"  /**\n     *\n     */\n  public void testPhrasePrefix() throws IOException {\n    Directory indexStore = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, indexStore);\n    Document doc1 = new Document();\n    Document doc2 = new Document();\n    Document doc3 = new Document();\n    Document doc4 = new Document();\n    Document doc5 = new Document();\n    doc1.add(newField(\"body\", \"blueberry pie\", TextField.TYPE_STORED));\n    doc2.add(newField(\"body\", \"blueberry strudel\", TextField.TYPE_STORED));\n    doc3.add(newField(\"body\", \"blueberry pizza\", TextField.TYPE_STORED));\n    doc4.add(newField(\"body\", \"blueberry chewing gum\", TextField.TYPE_STORED));\n    doc5.add(newField(\"body\", \"piccadilly circus\", TextField.TYPE_STORED));\n    writer.addDocument(doc1);\n    writer.addDocument(doc2);\n    writer.addDocument(doc3);\n    writer.addDocument(doc4);\n    writer.addDocument(doc5);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    IndexSearcher searcher = newSearcher(reader);\n    \n    // PhrasePrefixQuery query1 = new PhrasePrefixQuery();\n    MultiPhraseQuery query1 = new MultiPhraseQuery();\n    // PhrasePrefixQuery query2 = new PhrasePrefixQuery();\n    MultiPhraseQuery query2 = new MultiPhraseQuery();\n    query1.add(new Term(\"body\", \"blueberry\"));\n    query2.add(new Term(\"body\", \"strawberry\"));\n    \n    LinkedList<Term> termsWithPrefix = new LinkedList<Term>();\n    \n    // this TermEnum gives \"piccadilly\", \"pie\" and \"pizza\".\n    String prefix = \"pi\";\n    TermsEnum te = MultiFields.getFields(reader).terms(\"body\").iterator();\n    te.seekCeil(new BytesRef(prefix));\n    do {\n      String s = te.term().utf8ToString();\n      if (s.startsWith(prefix)) {\n        termsWithPrefix.add(new Term(\"body\", s));\n      } else {\n        break;\n      }\n    } while (te.next() != null);\n    \n    query1.add(termsWithPrefix.toArray(new Term[0]));\n    query2.add(termsWithPrefix.toArray(new Term[0]));\n    \n    ScoreDoc[] result;\n    result = searcher.search(query1, null, 1000).scoreDocs;\n    assertEquals(2, result.length);\n    \n    result = searcher.search(query2, null, 1000).scoreDocs;\n    assertEquals(0, result.length);\n    searcher.close();\n    reader.close();\n    indexStore.close();\n  }\n\n","sourceOld":"  /**\n     *\n     */\n  public void testPhrasePrefix() throws IOException {\n    Directory indexStore = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, indexStore);\n    Document doc1 = new Document();\n    Document doc2 = new Document();\n    Document doc3 = new Document();\n    Document doc4 = new Document();\n    Document doc5 = new Document();\n    doc1.add(newField(\"body\", \"blueberry pie\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc2.add(newField(\"body\", \"blueberry strudel\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc3.add(newField(\"body\", \"blueberry pizza\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc4.add(newField(\"body\", \"blueberry chewing gum\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    doc5.add(newField(\"body\", \"piccadilly circus\", Field.Store.YES,\n        Field.Index.ANALYZED));\n    writer.addDocument(doc1);\n    writer.addDocument(doc2);\n    writer.addDocument(doc3);\n    writer.addDocument(doc4);\n    writer.addDocument(doc5);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    IndexSearcher searcher = newSearcher(reader);\n    \n    // PhrasePrefixQuery query1 = new PhrasePrefixQuery();\n    MultiPhraseQuery query1 = new MultiPhraseQuery();\n    // PhrasePrefixQuery query2 = new PhrasePrefixQuery();\n    MultiPhraseQuery query2 = new MultiPhraseQuery();\n    query1.add(new Term(\"body\", \"blueberry\"));\n    query2.add(new Term(\"body\", \"strawberry\"));\n    \n    LinkedList<Term> termsWithPrefix = new LinkedList<Term>();\n    \n    // this TermEnum gives \"piccadilly\", \"pie\" and \"pizza\".\n    String prefix = \"pi\";\n    TermsEnum te = MultiFields.getFields(reader).terms(\"body\").iterator();\n    te.seekCeil(new BytesRef(prefix));\n    do {\n      String s = te.term().utf8ToString();\n      if (s.startsWith(prefix)) {\n        termsWithPrefix.add(new Term(\"body\", s));\n      } else {\n        break;\n      }\n    } while (te.next() != null);\n    \n    query1.add(termsWithPrefix.toArray(new Term[0]));\n    query2.add(termsWithPrefix.toArray(new Term[0]));\n    \n    ScoreDoc[] result;\n    result = searcher.search(query1, null, 1000).scoreDocs;\n    assertEquals(2, result.length);\n    \n    result = searcher.search(query2, null, 1000).scoreDocs;\n    assertEquals(0, result.length);\n    searcher.close();\n    reader.close();\n    indexStore.close();\n  }\n\n","bugFix":null,"bugIntro":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3cc749c053615f5871f3b95715fe292f34e70a53","date":1321470575,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPhrasePrefixQuery#testPhrasePrefix().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPhrasePrefixQuery#testPhrasePrefix().mjava","sourceNew":"  /**\n     *\n     */\n  public void testPhrasePrefix() throws IOException {\n    Directory indexStore = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, indexStore);\n    Document doc1 = new Document();\n    Document doc2 = new Document();\n    Document doc3 = new Document();\n    Document doc4 = new Document();\n    Document doc5 = new Document();\n    doc1.add(newField(\"body\", \"blueberry pie\", TextField.TYPE_STORED));\n    doc2.add(newField(\"body\", \"blueberry strudel\", TextField.TYPE_STORED));\n    doc3.add(newField(\"body\", \"blueberry pizza\", TextField.TYPE_STORED));\n    doc4.add(newField(\"body\", \"blueberry chewing gum\", TextField.TYPE_STORED));\n    doc5.add(newField(\"body\", \"piccadilly circus\", TextField.TYPE_STORED));\n    writer.addDocument(doc1);\n    writer.addDocument(doc2);\n    writer.addDocument(doc3);\n    writer.addDocument(doc4);\n    writer.addDocument(doc5);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    IndexSearcher searcher = newSearcher(reader);\n    \n    // PhrasePrefixQuery query1 = new PhrasePrefixQuery();\n    MultiPhraseQuery query1 = new MultiPhraseQuery();\n    // PhrasePrefixQuery query2 = new PhrasePrefixQuery();\n    MultiPhraseQuery query2 = new MultiPhraseQuery();\n    query1.add(new Term(\"body\", \"blueberry\"));\n    query2.add(new Term(\"body\", \"strawberry\"));\n    \n    LinkedList<Term> termsWithPrefix = new LinkedList<Term>();\n    \n    // this TermEnum gives \"piccadilly\", \"pie\" and \"pizza\".\n    String prefix = \"pi\";\n    TermsEnum te = MultiFields.getFields(reader).terms(\"body\").iterator(null);\n    te.seekCeil(new BytesRef(prefix));\n    do {\n      String s = te.term().utf8ToString();\n      if (s.startsWith(prefix)) {\n        termsWithPrefix.add(new Term(\"body\", s));\n      } else {\n        break;\n      }\n    } while (te.next() != null);\n    \n    query1.add(termsWithPrefix.toArray(new Term[0]));\n    query2.add(termsWithPrefix.toArray(new Term[0]));\n    \n    ScoreDoc[] result;\n    result = searcher.search(query1, null, 1000).scoreDocs;\n    assertEquals(2, result.length);\n    \n    result = searcher.search(query2, null, 1000).scoreDocs;\n    assertEquals(0, result.length);\n    searcher.close();\n    reader.close();\n    indexStore.close();\n  }\n\n","sourceOld":"  /**\n     *\n     */\n  public void testPhrasePrefix() throws IOException {\n    Directory indexStore = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, indexStore);\n    Document doc1 = new Document();\n    Document doc2 = new Document();\n    Document doc3 = new Document();\n    Document doc4 = new Document();\n    Document doc5 = new Document();\n    doc1.add(newField(\"body\", \"blueberry pie\", TextField.TYPE_STORED));\n    doc2.add(newField(\"body\", \"blueberry strudel\", TextField.TYPE_STORED));\n    doc3.add(newField(\"body\", \"blueberry pizza\", TextField.TYPE_STORED));\n    doc4.add(newField(\"body\", \"blueberry chewing gum\", TextField.TYPE_STORED));\n    doc5.add(newField(\"body\", \"piccadilly circus\", TextField.TYPE_STORED));\n    writer.addDocument(doc1);\n    writer.addDocument(doc2);\n    writer.addDocument(doc3);\n    writer.addDocument(doc4);\n    writer.addDocument(doc5);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    IndexSearcher searcher = newSearcher(reader);\n    \n    // PhrasePrefixQuery query1 = new PhrasePrefixQuery();\n    MultiPhraseQuery query1 = new MultiPhraseQuery();\n    // PhrasePrefixQuery query2 = new PhrasePrefixQuery();\n    MultiPhraseQuery query2 = new MultiPhraseQuery();\n    query1.add(new Term(\"body\", \"blueberry\"));\n    query2.add(new Term(\"body\", \"strawberry\"));\n    \n    LinkedList<Term> termsWithPrefix = new LinkedList<Term>();\n    \n    // this TermEnum gives \"piccadilly\", \"pie\" and \"pizza\".\n    String prefix = \"pi\";\n    TermsEnum te = MultiFields.getFields(reader).terms(\"body\").iterator();\n    te.seekCeil(new BytesRef(prefix));\n    do {\n      String s = te.term().utf8ToString();\n      if (s.startsWith(prefix)) {\n        termsWithPrefix.add(new Term(\"body\", s));\n      } else {\n        break;\n      }\n    } while (te.next() != null);\n    \n    query1.add(termsWithPrefix.toArray(new Term[0]));\n    query2.add(termsWithPrefix.toArray(new Term[0]));\n    \n    ScoreDoc[] result;\n    result = searcher.search(query1, null, 1000).scoreDocs;\n    assertEquals(2, result.length);\n    \n    result = searcher.search(query2, null, 1000).scoreDocs;\n    assertEquals(0, result.length);\n    searcher.close();\n    reader.close();\n    indexStore.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0e7c2454a6a8237bfd0e953f5b940838408c9055","date":1323649300,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPhrasePrefixQuery#testPhrasePrefix().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPhrasePrefixQuery#testPhrasePrefix().mjava","sourceNew":"  /**\n     *\n     */\n  public void testPhrasePrefix() throws IOException {\n    Directory indexStore = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, indexStore);\n    Document doc1 = new Document();\n    Document doc2 = new Document();\n    Document doc3 = new Document();\n    Document doc4 = new Document();\n    Document doc5 = new Document();\n    doc1.add(newField(\"body\", \"blueberry pie\", TextField.TYPE_STORED));\n    doc2.add(newField(\"body\", \"blueberry strudel\", TextField.TYPE_STORED));\n    doc3.add(newField(\"body\", \"blueberry pizza\", TextField.TYPE_STORED));\n    doc4.add(newField(\"body\", \"blueberry chewing gum\", TextField.TYPE_STORED));\n    doc5.add(newField(\"body\", \"piccadilly circus\", TextField.TYPE_STORED));\n    writer.addDocument(doc1);\n    writer.addDocument(doc2);\n    writer.addDocument(doc3);\n    writer.addDocument(doc4);\n    writer.addDocument(doc5);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    IndexSearcher searcher = newSearcher(reader);\n    \n    // PhrasePrefixQuery query1 = new PhrasePrefixQuery();\n    MultiPhraseQuery query1 = new MultiPhraseQuery();\n    // PhrasePrefixQuery query2 = new PhrasePrefixQuery();\n    MultiPhraseQuery query2 = new MultiPhraseQuery();\n    query1.add(new Term(\"body\", \"blueberry\"));\n    query2.add(new Term(\"body\", \"strawberry\"));\n    \n    LinkedList<Term> termsWithPrefix = new LinkedList<Term>();\n    \n    // this TermEnum gives \"piccadilly\", \"pie\" and \"pizza\".\n    String prefix = \"pi\";\n    TermsEnum te = MultiFields.getFields(reader).terms(\"body\").iterator(null);\n    te.seekCeil(new BytesRef(prefix));\n    do {\n      String s = te.term().utf8ToString();\n      if (s.startsWith(prefix)) {\n        termsWithPrefix.add(new Term(\"body\", s));\n      } else {\n        break;\n      }\n    } while (te.next() != null);\n    \n    query1.add(termsWithPrefix.toArray(new Term[0]));\n    query2.add(termsWithPrefix.toArray(new Term[0]));\n    \n    ScoreDoc[] result;\n    result = searcher.search(query1, null, 1000).scoreDocs;\n    assertEquals(2, result.length);\n    \n    result = searcher.search(query2, null, 1000).scoreDocs;\n    assertEquals(0, result.length);\n    reader.close();\n    indexStore.close();\n  }\n\n","sourceOld":"  /**\n     *\n     */\n  public void testPhrasePrefix() throws IOException {\n    Directory indexStore = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, indexStore);\n    Document doc1 = new Document();\n    Document doc2 = new Document();\n    Document doc3 = new Document();\n    Document doc4 = new Document();\n    Document doc5 = new Document();\n    doc1.add(newField(\"body\", \"blueberry pie\", TextField.TYPE_STORED));\n    doc2.add(newField(\"body\", \"blueberry strudel\", TextField.TYPE_STORED));\n    doc3.add(newField(\"body\", \"blueberry pizza\", TextField.TYPE_STORED));\n    doc4.add(newField(\"body\", \"blueberry chewing gum\", TextField.TYPE_STORED));\n    doc5.add(newField(\"body\", \"piccadilly circus\", TextField.TYPE_STORED));\n    writer.addDocument(doc1);\n    writer.addDocument(doc2);\n    writer.addDocument(doc3);\n    writer.addDocument(doc4);\n    writer.addDocument(doc5);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    IndexSearcher searcher = newSearcher(reader);\n    \n    // PhrasePrefixQuery query1 = new PhrasePrefixQuery();\n    MultiPhraseQuery query1 = new MultiPhraseQuery();\n    // PhrasePrefixQuery query2 = new PhrasePrefixQuery();\n    MultiPhraseQuery query2 = new MultiPhraseQuery();\n    query1.add(new Term(\"body\", \"blueberry\"));\n    query2.add(new Term(\"body\", \"strawberry\"));\n    \n    LinkedList<Term> termsWithPrefix = new LinkedList<Term>();\n    \n    // this TermEnum gives \"piccadilly\", \"pie\" and \"pizza\".\n    String prefix = \"pi\";\n    TermsEnum te = MultiFields.getFields(reader).terms(\"body\").iterator(null);\n    te.seekCeil(new BytesRef(prefix));\n    do {\n      String s = te.term().utf8ToString();\n      if (s.startsWith(prefix)) {\n        termsWithPrefix.add(new Term(\"body\", s));\n      } else {\n        break;\n      }\n    } while (te.next() != null);\n    \n    query1.add(termsWithPrefix.toArray(new Term[0]));\n    query2.add(termsWithPrefix.toArray(new Term[0]));\n    \n    ScoreDoc[] result;\n    result = searcher.search(query1, null, 1000).scoreDocs;\n    assertEquals(2, result.length);\n    \n    result = searcher.search(query2, null, 1000).scoreDocs;\n    assertEquals(0, result.length);\n    searcher.close();\n    reader.close();\n    indexStore.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"93ccd971aca7fb61b7f1b946e44714cfc80bfc7c","date":1323720782,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPhrasePrefixQuery#testPhrasePrefix().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPhrasePrefixQuery#testPhrasePrefix().mjava","sourceNew":"  /**\n     *\n     */\n  public void testPhrasePrefix() throws IOException {\n    Directory indexStore = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, indexStore);\n    Document doc1 = new Document();\n    Document doc2 = new Document();\n    Document doc3 = new Document();\n    Document doc4 = new Document();\n    Document doc5 = new Document();\n    doc1.add(newField(\"body\", \"blueberry pie\", TextField.TYPE_STORED));\n    doc2.add(newField(\"body\", \"blueberry strudel\", TextField.TYPE_STORED));\n    doc3.add(newField(\"body\", \"blueberry pizza\", TextField.TYPE_STORED));\n    doc4.add(newField(\"body\", \"blueberry chewing gum\", TextField.TYPE_STORED));\n    doc5.add(newField(\"body\", \"piccadilly circus\", TextField.TYPE_STORED));\n    writer.addDocument(doc1);\n    writer.addDocument(doc2);\n    writer.addDocument(doc3);\n    writer.addDocument(doc4);\n    writer.addDocument(doc5);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    IndexSearcher searcher = newSearcher(reader);\n    \n    // PhrasePrefixQuery query1 = new PhrasePrefixQuery();\n    MultiPhraseQuery query1 = new MultiPhraseQuery();\n    // PhrasePrefixQuery query2 = new PhrasePrefixQuery();\n    MultiPhraseQuery query2 = new MultiPhraseQuery();\n    query1.add(new Term(\"body\", \"blueberry\"));\n    query2.add(new Term(\"body\", \"strawberry\"));\n    \n    LinkedList<Term> termsWithPrefix = new LinkedList<Term>();\n    \n    // this TermEnum gives \"piccadilly\", \"pie\" and \"pizza\".\n    String prefix = \"pi\";\n    TermsEnum te = MultiFields.getFields(reader).terms(\"body\").iterator(null);\n    te.seekCeil(new BytesRef(prefix));\n    do {\n      String s = te.term().utf8ToString();\n      if (s.startsWith(prefix)) {\n        termsWithPrefix.add(new Term(\"body\", s));\n      } else {\n        break;\n      }\n    } while (te.next() != null);\n    \n    query1.add(termsWithPrefix.toArray(new Term[0]));\n    query2.add(termsWithPrefix.toArray(new Term[0]));\n    \n    ScoreDoc[] result;\n    result = searcher.search(query1, null, 1000).scoreDocs;\n    assertEquals(2, result.length);\n    \n    result = searcher.search(query2, null, 1000).scoreDocs;\n    assertEquals(0, result.length);\n    reader.close();\n    indexStore.close();\n  }\n\n","sourceOld":"  /**\n     *\n     */\n  public void testPhrasePrefix() throws IOException {\n    Directory indexStore = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, indexStore);\n    Document doc1 = new Document();\n    Document doc2 = new Document();\n    Document doc3 = new Document();\n    Document doc4 = new Document();\n    Document doc5 = new Document();\n    doc1.add(newField(\"body\", \"blueberry pie\", TextField.TYPE_STORED));\n    doc2.add(newField(\"body\", \"blueberry strudel\", TextField.TYPE_STORED));\n    doc3.add(newField(\"body\", \"blueberry pizza\", TextField.TYPE_STORED));\n    doc4.add(newField(\"body\", \"blueberry chewing gum\", TextField.TYPE_STORED));\n    doc5.add(newField(\"body\", \"piccadilly circus\", TextField.TYPE_STORED));\n    writer.addDocument(doc1);\n    writer.addDocument(doc2);\n    writer.addDocument(doc3);\n    writer.addDocument(doc4);\n    writer.addDocument(doc5);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    IndexSearcher searcher = newSearcher(reader);\n    \n    // PhrasePrefixQuery query1 = new PhrasePrefixQuery();\n    MultiPhraseQuery query1 = new MultiPhraseQuery();\n    // PhrasePrefixQuery query2 = new PhrasePrefixQuery();\n    MultiPhraseQuery query2 = new MultiPhraseQuery();\n    query1.add(new Term(\"body\", \"blueberry\"));\n    query2.add(new Term(\"body\", \"strawberry\"));\n    \n    LinkedList<Term> termsWithPrefix = new LinkedList<Term>();\n    \n    // this TermEnum gives \"piccadilly\", \"pie\" and \"pizza\".\n    String prefix = \"pi\";\n    TermsEnum te = MultiFields.getFields(reader).terms(\"body\").iterator(null);\n    te.seekCeil(new BytesRef(prefix));\n    do {\n      String s = te.term().utf8ToString();\n      if (s.startsWith(prefix)) {\n        termsWithPrefix.add(new Term(\"body\", s));\n      } else {\n        break;\n      }\n    } while (te.next() != null);\n    \n    query1.add(termsWithPrefix.toArray(new Term[0]));\n    query2.add(termsWithPrefix.toArray(new Term[0]));\n    \n    ScoreDoc[] result;\n    result = searcher.search(query1, null, 1000).scoreDocs;\n    assertEquals(2, result.length);\n    \n    result = searcher.search(query2, null, 1000).scoreDocs;\n    assertEquals(0, result.length);\n    searcher.close();\n    reader.close();\n    indexStore.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestPhrasePrefixQuery#testPhrasePrefix().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPhrasePrefixQuery#testPhrasePrefix().mjava","sourceNew":"  /**\n     *\n     */\n  public void testPhrasePrefix() throws IOException {\n    Directory indexStore = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, indexStore);\n    Document doc1 = new Document();\n    Document doc2 = new Document();\n    Document doc3 = new Document();\n    Document doc4 = new Document();\n    Document doc5 = new Document();\n    doc1.add(newField(\"body\", \"blueberry pie\", TextField.TYPE_STORED));\n    doc2.add(newField(\"body\", \"blueberry strudel\", TextField.TYPE_STORED));\n    doc3.add(newField(\"body\", \"blueberry pizza\", TextField.TYPE_STORED));\n    doc4.add(newField(\"body\", \"blueberry chewing gum\", TextField.TYPE_STORED));\n    doc5.add(newField(\"body\", \"piccadilly circus\", TextField.TYPE_STORED));\n    writer.addDocument(doc1);\n    writer.addDocument(doc2);\n    writer.addDocument(doc3);\n    writer.addDocument(doc4);\n    writer.addDocument(doc5);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    IndexSearcher searcher = newSearcher(reader);\n    \n    // PhrasePrefixQuery query1 = new PhrasePrefixQuery();\n    MultiPhraseQuery query1 = new MultiPhraseQuery();\n    // PhrasePrefixQuery query2 = new PhrasePrefixQuery();\n    MultiPhraseQuery query2 = new MultiPhraseQuery();\n    query1.add(new Term(\"body\", \"blueberry\"));\n    query2.add(new Term(\"body\", \"strawberry\"));\n    \n    LinkedList<Term> termsWithPrefix = new LinkedList<Term>();\n    \n    // this TermEnum gives \"piccadilly\", \"pie\" and \"pizza\".\n    String prefix = \"pi\";\n    TermsEnum te = MultiFields.getFields(reader).terms(\"body\").iterator(null);\n    te.seekCeil(new BytesRef(prefix));\n    do {\n      String s = te.term().utf8ToString();\n      if (s.startsWith(prefix)) {\n        termsWithPrefix.add(new Term(\"body\", s));\n      } else {\n        break;\n      }\n    } while (te.next() != null);\n    \n    query1.add(termsWithPrefix.toArray(new Term[0]));\n    query2.add(termsWithPrefix.toArray(new Term[0]));\n    \n    ScoreDoc[] result;\n    result = searcher.search(query1, null, 1000).scoreDocs;\n    assertEquals(2, result.length);\n    \n    result = searcher.search(query2, null, 1000).scoreDocs;\n    assertEquals(0, result.length);\n    reader.close();\n    indexStore.close();\n  }\n\n","sourceOld":"  /**\n     *\n     */\n  public void testPhrasePrefix() throws IOException {\n    Directory indexStore = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, indexStore);\n    Document doc1 = new Document();\n    Document doc2 = new Document();\n    Document doc3 = new Document();\n    Document doc4 = new Document();\n    Document doc5 = new Document();\n    doc1.add(newField(\"body\", \"blueberry pie\", TextField.TYPE_STORED));\n    doc2.add(newField(\"body\", \"blueberry strudel\", TextField.TYPE_STORED));\n    doc3.add(newField(\"body\", \"blueberry pizza\", TextField.TYPE_STORED));\n    doc4.add(newField(\"body\", \"blueberry chewing gum\", TextField.TYPE_STORED));\n    doc5.add(newField(\"body\", \"piccadilly circus\", TextField.TYPE_STORED));\n    writer.addDocument(doc1);\n    writer.addDocument(doc2);\n    writer.addDocument(doc3);\n    writer.addDocument(doc4);\n    writer.addDocument(doc5);\n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    IndexSearcher searcher = newSearcher(reader);\n    \n    // PhrasePrefixQuery query1 = new PhrasePrefixQuery();\n    MultiPhraseQuery query1 = new MultiPhraseQuery();\n    // PhrasePrefixQuery query2 = new PhrasePrefixQuery();\n    MultiPhraseQuery query2 = new MultiPhraseQuery();\n    query1.add(new Term(\"body\", \"blueberry\"));\n    query2.add(new Term(\"body\", \"strawberry\"));\n    \n    LinkedList<Term> termsWithPrefix = new LinkedList<Term>();\n    \n    // this TermEnum gives \"piccadilly\", \"pie\" and \"pizza\".\n    String prefix = \"pi\";\n    TermsEnum te = MultiFields.getFields(reader).terms(\"body\").iterator(null);\n    te.seekCeil(new BytesRef(prefix));\n    do {\n      String s = te.term().utf8ToString();\n      if (s.startsWith(prefix)) {\n        termsWithPrefix.add(new Term(\"body\", s));\n      } else {\n        break;\n      }\n    } while (te.next() != null);\n    \n    query1.add(termsWithPrefix.toArray(new Term[0]));\n    query2.add(termsWithPrefix.toArray(new Term[0]));\n    \n    ScoreDoc[] result;\n    result = searcher.search(query1, null, 1000).scoreDocs;\n    assertEquals(2, result.length);\n    \n    result = searcher.search(query2, null, 1000).scoreDocs;\n    assertEquals(0, result.length);\n    reader.close();\n    indexStore.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["0e7c2454a6a8237bfd0e953f5b940838408c9055"],"93ccd971aca7fb61b7f1b946e44714cfc80bfc7c":["3cc749c053615f5871f3b95715fe292f34e70a53","0e7c2454a6a8237bfd0e953f5b940838408c9055"],"15bbd254c1506df5299c4df8c148262c7bd6301e":["c084e47df29de3330311d69dabf515ceaa989512"],"132903c28af3aa6f67284b78de91c0f0a99488c2":["1f653cfcf159baeaafe5d01682a911e95bba4012"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["3242a09f703274d3b9283f2064a1a33064b53a1b","132903c28af3aa6f67284b78de91c0f0a99488c2"],"c084e47df29de3330311d69dabf515ceaa989512":["28427ef110c4c5bf5b4057731b83110bd1e13724"],"0e7c2454a6a8237bfd0e953f5b940838408c9055":["3cc749c053615f5871f3b95715fe292f34e70a53"],"1f653cfcf159baeaafe5d01682a911e95bba4012":["a05409176bd65129d67a785ee70e881e238a9aef"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["132903c28af3aa6f67284b78de91c0f0a99488c2","790e1fde4caa765b3faaad3fbcd25c6973450336"],"1a2e46fd1b7cbc52d7d6461a6ef99e7107ae2a9c":["4b103252dee6afa1b6d7a622c773d178788eb85a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a05409176bd65129d67a785ee70e881e238a9aef":["ab9633cb67e3c0aec3c066147a23a957d6e7ad8c"],"28427ef110c4c5bf5b4057731b83110bd1e13724":["d572389229127c297dd1fa5ce4758e1cec41e799"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["fd9cc9d77712aba3662f24632df7539ab75e3667"],"fd9cc9d77712aba3662f24632df7539ab75e3667":["790e1fde4caa765b3faaad3fbcd25c6973450336"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","790e1fde4caa765b3faaad3fbcd25c6973450336"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"3242a09f703274d3b9283f2064a1a33064b53a1b":["5f4e87790277826a2aea119328600dfb07761f32","4b103252dee6afa1b6d7a622c773d178788eb85a"],"4b103252dee6afa1b6d7a622c773d178788eb85a":["c084e47df29de3330311d69dabf515ceaa989512","15bbd254c1506df5299c4df8c148262c7bd6301e"],"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c":["1a2e46fd1b7cbc52d7d6461a6ef99e7107ae2a9c"],"3cc749c053615f5871f3b95715fe292f34e70a53":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"d572389229127c297dd1fa5ce4758e1cec41e799":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"5f4e87790277826a2aea119328600dfb07761f32":["d572389229127c297dd1fa5ce4758e1cec41e799","c084e47df29de3330311d69dabf515ceaa989512"],"2553b00f699380c64959ccb27991289aae87be2e":["790e1fde4caa765b3faaad3fbcd25c6973450336","fd9cc9d77712aba3662f24632df7539ab75e3667"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":["790e1fde4caa765b3faaad3fbcd25c6973450336","fd9cc9d77712aba3662f24632df7539ab75e3667"],"790e1fde4caa765b3faaad3fbcd25c6973450336":["132903c28af3aa6f67284b78de91c0f0a99488c2"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"]},"commit2Childs":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"93ccd971aca7fb61b7f1b946e44714cfc80bfc7c":[],"15bbd254c1506df5299c4df8c148262c7bd6301e":["4b103252dee6afa1b6d7a622c773d178788eb85a"],"132903c28af3aa6f67284b78de91c0f0a99488c2":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","29ef99d61cda9641b6250bf9567329a6e65f901d","790e1fde4caa765b3faaad3fbcd25c6973450336"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["bde51b089eb7f86171eb3406e38a274743f9b7ac"],"c084e47df29de3330311d69dabf515ceaa989512":["15bbd254c1506df5299c4df8c148262c7bd6301e","4b103252dee6afa1b6d7a622c773d178788eb85a","5f4e87790277826a2aea119328600dfb07761f32"],"0e7c2454a6a8237bfd0e953f5b940838408c9055":["3a119bbc8703c10faa329ec201c654b3a35a1e3e","93ccd971aca7fb61b7f1b946e44714cfc80bfc7c"],"1f653cfcf159baeaafe5d01682a911e95bba4012":["132903c28af3aa6f67284b78de91c0f0a99488c2"],"29ef99d61cda9641b6250bf9567329a6e65f901d":[],"1a2e46fd1b7cbc52d7d6461a6ef99e7107ae2a9c":["ab9633cb67e3c0aec3c066147a23a957d6e7ad8c"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"28427ef110c4c5bf5b4057731b83110bd1e13724":["c084e47df29de3330311d69dabf515ceaa989512"],"a05409176bd65129d67a785ee70e881e238a9aef":["1f653cfcf159baeaafe5d01682a911e95bba4012"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["3cc749c053615f5871f3b95715fe292f34e70a53"],"fd9cc9d77712aba3662f24632df7539ab75e3667":["1509f151d7692d84fae414b2b799ac06ba60fcb4","2553b00f699380c64959ccb27991289aae87be2e","d083e83f225b11e5fdd900e83d26ddb385b6955c"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["d572389229127c297dd1fa5ce4758e1cec41e799"],"3242a09f703274d3b9283f2064a1a33064b53a1b":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"4b103252dee6afa1b6d7a622c773d178788eb85a":["1a2e46fd1b7cbc52d7d6461a6ef99e7107ae2a9c","3242a09f703274d3b9283f2064a1a33064b53a1b"],"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c":["a05409176bd65129d67a785ee70e881e238a9aef"],"3cc749c053615f5871f3b95715fe292f34e70a53":["93ccd971aca7fb61b7f1b946e44714cfc80bfc7c","0e7c2454a6a8237bfd0e953f5b940838408c9055"],"d572389229127c297dd1fa5ce4758e1cec41e799":["28427ef110c4c5bf5b4057731b83110bd1e13724","5f4e87790277826a2aea119328600dfb07761f32"],"5f4e87790277826a2aea119328600dfb07761f32":["3242a09f703274d3b9283f2064a1a33064b53a1b"],"2553b00f699380c64959ccb27991289aae87be2e":[],"d083e83f225b11e5fdd900e83d26ddb385b6955c":[],"790e1fde4caa765b3faaad3fbcd25c6973450336":["29ef99d61cda9641b6250bf9567329a6e65f901d","fd9cc9d77712aba3662f24632df7539ab75e3667","bde51b089eb7f86171eb3406e38a274743f9b7ac","2553b00f699380c64959ccb27991289aae87be2e","d083e83f225b11e5fdd900e83d26ddb385b6955c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["93ccd971aca7fb61b7f1b946e44714cfc80bfc7c","29ef99d61cda9641b6250bf9567329a6e65f901d","bde51b089eb7f86171eb3406e38a274743f9b7ac","2553b00f699380c64959ccb27991289aae87be2e","d083e83f225b11e5fdd900e83d26ddb385b6955c","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}