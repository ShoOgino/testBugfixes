{"path":"solr/core/src/test/org/apache/solr/handler/TestHdfsBackupRestoreCore#test().mjava","commits":[{"id":"a51ab9b1f1b896f06b7ba61672f0fca2a4fce43b","date":1466705968,"type":0,"author":"Varun Thacker","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/handler/TestHdfsBackupRestoreCore#test().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void test() throws Exception {\n    CloudSolrClient solrClient = cluster.getSolrClient();\n    String collectionName = \"HdfsBackupRestore\";\n    CollectionAdminRequest.Create create =\n        CollectionAdminRequest.createCollection(collectionName, \"conf1\", 1, 1);\n    create.process(solrClient);\n\n    int nDocs = BackupRestoreUtils.indexDocs(solrClient, collectionName, docsSeed);\n\n    DocCollection collectionState = solrClient.getZkStateReader().getClusterState().getCollection(collectionName);\n    assertEquals(1, collectionState.getActiveSlices().size());\n    Slice shard = collectionState.getActiveSlices().iterator().next();\n    assertEquals(1, shard.getReplicas().size());\n    Replica replica = shard.getReplicas().iterator().next();\n\n    String replicaBaseUrl = replica.getStr(BASE_URL_PROP);\n    String coreName = replica.getStr(ZkStateReader.CORE_NAME_PROP);\n    String backupName = TestUtil.randomSimpleString(random(), 1, 5);\n\n    boolean testViaReplicationHandler = random().nextBoolean();\n    String baseUrl = cluster.getJettySolrRunners().get(0).getBaseUrl().toString();\n\n    try (SolrClient masterClient = getHttpSolrClient(replicaBaseUrl)) {\n      // Create a backup.\n      if (testViaReplicationHandler) {\n        log.info(\"Running Backup/restore via replication handler\");\n        runReplicationHandlerCommand(baseUrl, coreName, ReplicationHandler.CMD_BACKUP, \"hdfs\", backupName);\n        CheckBackupStatus checkBackupStatus = new CheckBackupStatus((HttpSolrClient) masterClient, coreName, null);\n        while (!checkBackupStatus.success) {\n          checkBackupStatus.fetchStatus();\n          Thread.sleep(1000);\n        }\n      } else {\n        log.info(\"Running Backup/restore via core admin api\");\n        runCoreAdminCommand(replicaBaseUrl, coreName, CoreAdminAction.BACKUPCORE.toString(), \"hdfs\", backupName);\n      }\n\n      int numRestoreTests = nDocs > 0 ? TestUtil.nextInt(random(), 1, 5) : 1;\n      for (int attempts=0; attempts<numRestoreTests; attempts++) {\n        //Modify existing index before we call restore.\n        if (nDocs > 0) {\n          //Delete a few docs\n          int numDeletes = TestUtil.nextInt(random(), 1, nDocs);\n          for(int i=0; i<numDeletes; i++) {\n            masterClient.deleteByQuery(collectionName, \"id:\" + i);\n          }\n          masterClient.commit(collectionName);\n\n          //Add a few more\n          int moreAdds = TestUtil.nextInt(random(), 1, 100);\n          for (int i=0; i<moreAdds; i++) {\n            SolrInputDocument doc = new SolrInputDocument();\n            doc.addField(\"id\", i + nDocs);\n            doc.addField(\"name\", \"name = \" + (i + nDocs));\n            masterClient.add(collectionName, doc);\n          }\n          //Purposely not calling commit once in a while. There can be some docs which are not committed\n          if (usually()) {\n            masterClient.commit(collectionName);\n          }\n        }\n        // Snapshooter prefixes \"snapshot.\" to the backup name.\n        if (testViaReplicationHandler) {\n          // Snapshooter prefixes \"snapshot.\" to the backup name.\n          runReplicationHandlerCommand(baseUrl, coreName, ReplicationHandler.CMD_RESTORE, \"hdfs\", backupName);\n          while (!TestRestoreCore.fetchRestoreStatus(baseUrl, coreName)) {\n            Thread.sleep(1000);\n          }\n        } else {\n          runCoreAdminCommand(replicaBaseUrl, coreName, CoreAdminAction.RESTORECORE.toString(), \"hdfs\", \"snapshot.\" + backupName);\n        }\n        //See if restore was successful by checking if all the docs are present again\n        BackupRestoreUtils.verifyDocs(nDocs, masterClient, coreName);\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["add53de9835b2cd1a7a80b4e0036afee171c9fdf"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"91e2345fb81b6c1c7faefa550ee5eaafadc54486","date":1469730189,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/handler/TestHdfsBackupRestoreCore#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/handler/TestHdfsBackupRestoreCore#test().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n    CloudSolrClient solrClient = cluster.getSolrClient();\n    String collectionName = \"HdfsBackupRestore\";\n    CollectionAdminRequest.Create create =\n        CollectionAdminRequest.createCollection(collectionName, \"conf1\", 1, 1);\n    create.process(solrClient);\n\n    int nDocs = BackupRestoreUtils.indexDocs(solrClient, collectionName, docsSeed);\n\n    DocCollection collectionState = solrClient.getZkStateReader().getClusterState().getCollection(collectionName);\n    assertEquals(1, collectionState.getActiveSlices().size());\n    Slice shard = collectionState.getActiveSlices().iterator().next();\n    assertEquals(1, shard.getReplicas().size());\n    Replica replica = shard.getReplicas().iterator().next();\n\n    String replicaBaseUrl = replica.getStr(BASE_URL_PROP);\n    String coreName = replica.getStr(ZkStateReader.CORE_NAME_PROP);\n    String backupName = TestUtil.randomSimpleString(random(), 1, 5);\n\n    boolean testViaReplicationHandler = random().nextBoolean();\n    String baseUrl = cluster.getJettySolrRunners().get(0).getBaseUrl().toString();\n\n    try (SolrClient masterClient = getHttpSolrClient(replicaBaseUrl)) {\n      // Create a backup.\n      if (testViaReplicationHandler) {\n        log.info(\"Running Backup via replication handler\");\n        BackupRestoreUtils.runReplicationHandlerCommand(baseUrl, coreName, ReplicationHandler.CMD_BACKUP, \"hdfs\", backupName);\n        CheckBackupStatus checkBackupStatus = new CheckBackupStatus((HttpSolrClient) masterClient, coreName, null);\n        while (!checkBackupStatus.success) {\n          checkBackupStatus.fetchStatus();\n          Thread.sleep(1000);\n        }\n      } else {\n        log.info(\"Running Backup via core admin api\");\n        Map<String,String> params = new HashMap<>();\n        params.put(\"name\", backupName);\n        params.put(CoreAdminParams.BACKUP_REPOSITORY, \"hdfs\");\n        BackupRestoreUtils.runCoreAdminCommand(replicaBaseUrl, coreName, CoreAdminAction.BACKUPCORE.toString(), params);\n      }\n\n      int numRestoreTests = nDocs > 0 ? TestUtil.nextInt(random(), 1, 5) : 1;\n      for (int attempts=0; attempts<numRestoreTests; attempts++) {\n        //Modify existing index before we call restore.\n        if (nDocs > 0) {\n          //Delete a few docs\n          int numDeletes = TestUtil.nextInt(random(), 1, nDocs);\n          for(int i=0; i<numDeletes; i++) {\n            masterClient.deleteByQuery(collectionName, \"id:\" + i);\n          }\n          masterClient.commit(collectionName);\n\n          //Add a few more\n          int moreAdds = TestUtil.nextInt(random(), 1, 100);\n          for (int i=0; i<moreAdds; i++) {\n            SolrInputDocument doc = new SolrInputDocument();\n            doc.addField(\"id\", i + nDocs);\n            doc.addField(\"name\", \"name = \" + (i + nDocs));\n            masterClient.add(collectionName, doc);\n          }\n          //Purposely not calling commit once in a while. There can be some docs which are not committed\n          if (usually()) {\n            masterClient.commit(collectionName);\n          }\n        }\n        // Snapshooter prefixes \"snapshot.\" to the backup name.\n        if (testViaReplicationHandler) {\n          log.info(\"Running Restore via replication handler\");\n          // Snapshooter prefixes \"snapshot.\" to the backup name.\n          BackupRestoreUtils.runReplicationHandlerCommand(baseUrl, coreName, ReplicationHandler.CMD_RESTORE, \"hdfs\", backupName);\n          while (!TestRestoreCore.fetchRestoreStatus(baseUrl, coreName)) {\n            Thread.sleep(1000);\n          }\n        } else {\n          log.info(\"Running Restore via core admin api\");\n          Map<String,String> params = new HashMap<>();\n          params.put(\"name\", \"snapshot.\" + backupName);\n          params.put(CoreAdminParams.BACKUP_REPOSITORY, \"hdfs\");\n          BackupRestoreUtils.runCoreAdminCommand(replicaBaseUrl, coreName, CoreAdminAction.RESTORECORE.toString(), params);\n        }\n        //See if restore was successful by checking if all the docs are present again\n        BackupRestoreUtils.verifyDocs(nDocs, masterClient, coreName);\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n    CloudSolrClient solrClient = cluster.getSolrClient();\n    String collectionName = \"HdfsBackupRestore\";\n    CollectionAdminRequest.Create create =\n        CollectionAdminRequest.createCollection(collectionName, \"conf1\", 1, 1);\n    create.process(solrClient);\n\n    int nDocs = BackupRestoreUtils.indexDocs(solrClient, collectionName, docsSeed);\n\n    DocCollection collectionState = solrClient.getZkStateReader().getClusterState().getCollection(collectionName);\n    assertEquals(1, collectionState.getActiveSlices().size());\n    Slice shard = collectionState.getActiveSlices().iterator().next();\n    assertEquals(1, shard.getReplicas().size());\n    Replica replica = shard.getReplicas().iterator().next();\n\n    String replicaBaseUrl = replica.getStr(BASE_URL_PROP);\n    String coreName = replica.getStr(ZkStateReader.CORE_NAME_PROP);\n    String backupName = TestUtil.randomSimpleString(random(), 1, 5);\n\n    boolean testViaReplicationHandler = random().nextBoolean();\n    String baseUrl = cluster.getJettySolrRunners().get(0).getBaseUrl().toString();\n\n    try (SolrClient masterClient = getHttpSolrClient(replicaBaseUrl)) {\n      // Create a backup.\n      if (testViaReplicationHandler) {\n        log.info(\"Running Backup/restore via replication handler\");\n        runReplicationHandlerCommand(baseUrl, coreName, ReplicationHandler.CMD_BACKUP, \"hdfs\", backupName);\n        CheckBackupStatus checkBackupStatus = new CheckBackupStatus((HttpSolrClient) masterClient, coreName, null);\n        while (!checkBackupStatus.success) {\n          checkBackupStatus.fetchStatus();\n          Thread.sleep(1000);\n        }\n      } else {\n        log.info(\"Running Backup/restore via core admin api\");\n        runCoreAdminCommand(replicaBaseUrl, coreName, CoreAdminAction.BACKUPCORE.toString(), \"hdfs\", backupName);\n      }\n\n      int numRestoreTests = nDocs > 0 ? TestUtil.nextInt(random(), 1, 5) : 1;\n      for (int attempts=0; attempts<numRestoreTests; attempts++) {\n        //Modify existing index before we call restore.\n        if (nDocs > 0) {\n          //Delete a few docs\n          int numDeletes = TestUtil.nextInt(random(), 1, nDocs);\n          for(int i=0; i<numDeletes; i++) {\n            masterClient.deleteByQuery(collectionName, \"id:\" + i);\n          }\n          masterClient.commit(collectionName);\n\n          //Add a few more\n          int moreAdds = TestUtil.nextInt(random(), 1, 100);\n          for (int i=0; i<moreAdds; i++) {\n            SolrInputDocument doc = new SolrInputDocument();\n            doc.addField(\"id\", i + nDocs);\n            doc.addField(\"name\", \"name = \" + (i + nDocs));\n            masterClient.add(collectionName, doc);\n          }\n          //Purposely not calling commit once in a while. There can be some docs which are not committed\n          if (usually()) {\n            masterClient.commit(collectionName);\n          }\n        }\n        // Snapshooter prefixes \"snapshot.\" to the backup name.\n        if (testViaReplicationHandler) {\n          // Snapshooter prefixes \"snapshot.\" to the backup name.\n          runReplicationHandlerCommand(baseUrl, coreName, ReplicationHandler.CMD_RESTORE, \"hdfs\", backupName);\n          while (!TestRestoreCore.fetchRestoreStatus(baseUrl, coreName)) {\n            Thread.sleep(1000);\n          }\n        } else {\n          runCoreAdminCommand(replicaBaseUrl, coreName, CoreAdminAction.RESTORECORE.toString(), \"hdfs\", \"snapshot.\" + backupName);\n        }\n        //See if restore was successful by checking if all the docs are present again\n        BackupRestoreUtils.verifyDocs(nDocs, masterClient, coreName);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3b013574eedcdbac35dc7e35b0ee616ffc38895d","date":1470897818,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/handler/TestHdfsBackupRestoreCore#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/handler/TestHdfsBackupRestoreCore#test().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n    CloudSolrClient solrClient = cluster.getSolrClient();\n    String collectionName = \"HdfsBackupRestore\";\n    CollectionAdminRequest.Create create =\n        CollectionAdminRequest.createCollection(collectionName, \"conf1\", 1, 1);\n    create.process(solrClient);\n\n    int nDocs = BackupRestoreUtils.indexDocs(solrClient, collectionName, docsSeed);\n\n    DocCollection collectionState = solrClient.getZkStateReader().getClusterState().getCollection(collectionName);\n    assertEquals(1, collectionState.getActiveSlices().size());\n    Slice shard = collectionState.getActiveSlices().iterator().next();\n    assertEquals(1, shard.getReplicas().size());\n    Replica replica = shard.getReplicas().iterator().next();\n\n    String replicaBaseUrl = replica.getStr(BASE_URL_PROP);\n    String coreName = replica.getStr(ZkStateReader.CORE_NAME_PROP);\n    String backupName = TestUtil.randomSimpleString(random(), 1, 5);\n\n    boolean testViaReplicationHandler = random().nextBoolean();\n    String baseUrl = cluster.getJettySolrRunners().get(0).getBaseUrl().toString();\n\n    try (SolrClient masterClient = getHttpSolrClient(replicaBaseUrl)) {\n      // Create a backup.\n      if (testViaReplicationHandler) {\n        log.info(\"Running Backup via replication handler\");\n        BackupRestoreUtils.runReplicationHandlerCommand(baseUrl, coreName, ReplicationHandler.CMD_BACKUP, \"hdfs\", backupName);\n        CheckBackupStatus checkBackupStatus = new CheckBackupStatus((HttpSolrClient) masterClient, coreName, null);\n        while (!checkBackupStatus.success) {\n          checkBackupStatus.fetchStatus();\n          Thread.sleep(1000);\n        }\n      } else {\n        log.info(\"Running Backup via core admin api\");\n        Map<String,String> params = new HashMap<>();\n        params.put(\"name\", backupName);\n        params.put(CoreAdminParams.BACKUP_REPOSITORY, \"hdfs\");\n        BackupRestoreUtils.runCoreAdminCommand(replicaBaseUrl, coreName, CoreAdminAction.BACKUPCORE.toString(), params);\n      }\n\n      int numRestoreTests = nDocs > 0 ? TestUtil.nextInt(random(), 1, 5) : 1;\n      for (int attempts=0; attempts<numRestoreTests; attempts++) {\n        //Modify existing index before we call restore.\n        if (nDocs > 0) {\n          //Delete a few docs\n          int numDeletes = TestUtil.nextInt(random(), 1, nDocs);\n          for(int i=0; i<numDeletes; i++) {\n            masterClient.deleteByQuery(collectionName, \"id:\" + i);\n          }\n          masterClient.commit(collectionName);\n\n          //Add a few more\n          int moreAdds = TestUtil.nextInt(random(), 1, 100);\n          for (int i=0; i<moreAdds; i++) {\n            SolrInputDocument doc = new SolrInputDocument();\n            doc.addField(\"id\", i + nDocs);\n            doc.addField(\"name\", \"name = \" + (i + nDocs));\n            masterClient.add(collectionName, doc);\n          }\n          //Purposely not calling commit once in a while. There can be some docs which are not committed\n          if (usually()) {\n            masterClient.commit(collectionName);\n          }\n        }\n        // Snapshooter prefixes \"snapshot.\" to the backup name.\n        if (testViaReplicationHandler) {\n          log.info(\"Running Restore via replication handler\");\n          // Snapshooter prefixes \"snapshot.\" to the backup name.\n          BackupRestoreUtils.runReplicationHandlerCommand(baseUrl, coreName, ReplicationHandler.CMD_RESTORE, \"hdfs\", backupName);\n          while (!TestRestoreCore.fetchRestoreStatus(baseUrl, coreName)) {\n            Thread.sleep(1000);\n          }\n        } else {\n          log.info(\"Running Restore via core admin api\");\n          Map<String,String> params = new HashMap<>();\n          params.put(\"name\", \"snapshot.\" + backupName);\n          params.put(CoreAdminParams.BACKUP_REPOSITORY, \"hdfs\");\n          BackupRestoreUtils.runCoreAdminCommand(replicaBaseUrl, coreName, CoreAdminAction.RESTORECORE.toString(), params);\n        }\n        //See if restore was successful by checking if all the docs are present again\n        BackupRestoreUtils.verifyDocs(nDocs, masterClient, coreName);\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n    CloudSolrClient solrClient = cluster.getSolrClient();\n    String collectionName = \"HdfsBackupRestore\";\n    CollectionAdminRequest.Create create =\n        CollectionAdminRequest.createCollection(collectionName, \"conf1\", 1, 1);\n    create.process(solrClient);\n\n    int nDocs = BackupRestoreUtils.indexDocs(solrClient, collectionName, docsSeed);\n\n    DocCollection collectionState = solrClient.getZkStateReader().getClusterState().getCollection(collectionName);\n    assertEquals(1, collectionState.getActiveSlices().size());\n    Slice shard = collectionState.getActiveSlices().iterator().next();\n    assertEquals(1, shard.getReplicas().size());\n    Replica replica = shard.getReplicas().iterator().next();\n\n    String replicaBaseUrl = replica.getStr(BASE_URL_PROP);\n    String coreName = replica.getStr(ZkStateReader.CORE_NAME_PROP);\n    String backupName = TestUtil.randomSimpleString(random(), 1, 5);\n\n    boolean testViaReplicationHandler = random().nextBoolean();\n    String baseUrl = cluster.getJettySolrRunners().get(0).getBaseUrl().toString();\n\n    try (SolrClient masterClient = getHttpSolrClient(replicaBaseUrl)) {\n      // Create a backup.\n      if (testViaReplicationHandler) {\n        log.info(\"Running Backup/restore via replication handler\");\n        runReplicationHandlerCommand(baseUrl, coreName, ReplicationHandler.CMD_BACKUP, \"hdfs\", backupName);\n        CheckBackupStatus checkBackupStatus = new CheckBackupStatus((HttpSolrClient) masterClient, coreName, null);\n        while (!checkBackupStatus.success) {\n          checkBackupStatus.fetchStatus();\n          Thread.sleep(1000);\n        }\n      } else {\n        log.info(\"Running Backup/restore via core admin api\");\n        runCoreAdminCommand(replicaBaseUrl, coreName, CoreAdminAction.BACKUPCORE.toString(), \"hdfs\", backupName);\n      }\n\n      int numRestoreTests = nDocs > 0 ? TestUtil.nextInt(random(), 1, 5) : 1;\n      for (int attempts=0; attempts<numRestoreTests; attempts++) {\n        //Modify existing index before we call restore.\n        if (nDocs > 0) {\n          //Delete a few docs\n          int numDeletes = TestUtil.nextInt(random(), 1, nDocs);\n          for(int i=0; i<numDeletes; i++) {\n            masterClient.deleteByQuery(collectionName, \"id:\" + i);\n          }\n          masterClient.commit(collectionName);\n\n          //Add a few more\n          int moreAdds = TestUtil.nextInt(random(), 1, 100);\n          for (int i=0; i<moreAdds; i++) {\n            SolrInputDocument doc = new SolrInputDocument();\n            doc.addField(\"id\", i + nDocs);\n            doc.addField(\"name\", \"name = \" + (i + nDocs));\n            masterClient.add(collectionName, doc);\n          }\n          //Purposely not calling commit once in a while. There can be some docs which are not committed\n          if (usually()) {\n            masterClient.commit(collectionName);\n          }\n        }\n        // Snapshooter prefixes \"snapshot.\" to the backup name.\n        if (testViaReplicationHandler) {\n          // Snapshooter prefixes \"snapshot.\" to the backup name.\n          runReplicationHandlerCommand(baseUrl, coreName, ReplicationHandler.CMD_RESTORE, \"hdfs\", backupName);\n          while (!TestRestoreCore.fetchRestoreStatus(baseUrl, coreName)) {\n            Thread.sleep(1000);\n          }\n        } else {\n          runCoreAdminCommand(replicaBaseUrl, coreName, CoreAdminAction.RESTORECORE.toString(), \"hdfs\", \"snapshot.\" + backupName);\n        }\n        //See if restore was successful by checking if all the docs are present again\n        BackupRestoreUtils.verifyDocs(nDocs, masterClient, coreName);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":0,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/handler/TestHdfsBackupRestoreCore#test().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void test() throws Exception {\n    CloudSolrClient solrClient = cluster.getSolrClient();\n    String collectionName = \"HdfsBackupRestore\";\n    CollectionAdminRequest.Create create =\n        CollectionAdminRequest.createCollection(collectionName, \"conf1\", 1, 1);\n    create.process(solrClient);\n\n    int nDocs = BackupRestoreUtils.indexDocs(solrClient, collectionName, docsSeed);\n\n    DocCollection collectionState = solrClient.getZkStateReader().getClusterState().getCollection(collectionName);\n    assertEquals(1, collectionState.getActiveSlices().size());\n    Slice shard = collectionState.getActiveSlices().iterator().next();\n    assertEquals(1, shard.getReplicas().size());\n    Replica replica = shard.getReplicas().iterator().next();\n\n    String replicaBaseUrl = replica.getStr(BASE_URL_PROP);\n    String coreName = replica.getStr(ZkStateReader.CORE_NAME_PROP);\n    String backupName = TestUtil.randomSimpleString(random(), 1, 5);\n\n    boolean testViaReplicationHandler = random().nextBoolean();\n    String baseUrl = cluster.getJettySolrRunners().get(0).getBaseUrl().toString();\n\n    try (SolrClient masterClient = getHttpSolrClient(replicaBaseUrl)) {\n      // Create a backup.\n      if (testViaReplicationHandler) {\n        log.info(\"Running Backup via replication handler\");\n        BackupRestoreUtils.runReplicationHandlerCommand(baseUrl, coreName, ReplicationHandler.CMD_BACKUP, \"hdfs\", backupName);\n        CheckBackupStatus checkBackupStatus = new CheckBackupStatus((HttpSolrClient) masterClient, coreName, null);\n        while (!checkBackupStatus.success) {\n          checkBackupStatus.fetchStatus();\n          Thread.sleep(1000);\n        }\n      } else {\n        log.info(\"Running Backup via core admin api\");\n        Map<String,String> params = new HashMap<>();\n        params.put(\"name\", backupName);\n        params.put(CoreAdminParams.BACKUP_REPOSITORY, \"hdfs\");\n        BackupRestoreUtils.runCoreAdminCommand(replicaBaseUrl, coreName, CoreAdminAction.BACKUPCORE.toString(), params);\n      }\n\n      int numRestoreTests = nDocs > 0 ? TestUtil.nextInt(random(), 1, 5) : 1;\n      for (int attempts=0; attempts<numRestoreTests; attempts++) {\n        //Modify existing index before we call restore.\n        if (nDocs > 0) {\n          //Delete a few docs\n          int numDeletes = TestUtil.nextInt(random(), 1, nDocs);\n          for(int i=0; i<numDeletes; i++) {\n            masterClient.deleteByQuery(collectionName, \"id:\" + i);\n          }\n          masterClient.commit(collectionName);\n\n          //Add a few more\n          int moreAdds = TestUtil.nextInt(random(), 1, 100);\n          for (int i=0; i<moreAdds; i++) {\n            SolrInputDocument doc = new SolrInputDocument();\n            doc.addField(\"id\", i + nDocs);\n            doc.addField(\"name\", \"name = \" + (i + nDocs));\n            masterClient.add(collectionName, doc);\n          }\n          //Purposely not calling commit once in a while. There can be some docs which are not committed\n          if (usually()) {\n            masterClient.commit(collectionName);\n          }\n        }\n        // Snapshooter prefixes \"snapshot.\" to the backup name.\n        if (testViaReplicationHandler) {\n          log.info(\"Running Restore via replication handler\");\n          // Snapshooter prefixes \"snapshot.\" to the backup name.\n          BackupRestoreUtils.runReplicationHandlerCommand(baseUrl, coreName, ReplicationHandler.CMD_RESTORE, \"hdfs\", backupName);\n          while (!TestRestoreCore.fetchRestoreStatus(baseUrl, coreName)) {\n            Thread.sleep(1000);\n          }\n        } else {\n          log.info(\"Running Restore via core admin api\");\n          Map<String,String> params = new HashMap<>();\n          params.put(\"name\", \"snapshot.\" + backupName);\n          params.put(CoreAdminParams.BACKUP_REPOSITORY, \"hdfs\");\n          BackupRestoreUtils.runCoreAdminCommand(replicaBaseUrl, coreName, CoreAdminAction.RESTORECORE.toString(), params);\n        }\n        //See if restore was successful by checking if all the docs are present again\n        BackupRestoreUtils.verifyDocs(nDocs, masterClient, coreName);\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f5b22bbf58be28e93a9545e12da1c0506e3e59fd","date":1477405317,"type":3,"author":"markrmiller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/handler/TestHdfsBackupRestoreCore#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/handler/TestHdfsBackupRestoreCore#test().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n    CloudSolrClient solrClient = cluster.getSolrClient();\n    String collectionName = \"HdfsBackupRestore\";\n    CollectionAdminRequest.Create create =\n        CollectionAdminRequest.createCollection(collectionName, \"conf1\", 1, 1);\n    create.process(solrClient);\n\n    int nDocs = BackupRestoreUtils.indexDocs(solrClient, collectionName, docsSeed);\n\n    DocCollection collectionState = solrClient.getZkStateReader().getClusterState().getCollection(collectionName);\n    assertEquals(1, collectionState.getActiveSlices().size());\n    Slice shard = collectionState.getActiveSlices().iterator().next();\n    assertEquals(1, shard.getReplicas().size());\n    Replica replica = shard.getReplicas().iterator().next();\n\n    String replicaBaseUrl = replica.getStr(BASE_URL_PROP);\n    String coreName = replica.getStr(ZkStateReader.CORE_NAME_PROP);\n    String backupName = TestUtil.randomSimpleString(random(), 1, 5);\n\n    boolean testViaReplicationHandler = random().nextBoolean();\n    String baseUrl = cluster.getJettySolrRunners().get(0).getBaseUrl().toString();\n\n    try (SolrClient masterClient = getHttpSolrClient(replicaBaseUrl)) {\n      // Create a backup.\n      if (testViaReplicationHandler) {\n        log.info(\"Running Backup via replication handler\");\n        BackupRestoreUtils.runReplicationHandlerCommand(baseUrl, coreName, ReplicationHandler.CMD_BACKUP, \"hdfs\", backupName);\n        CheckBackupStatus checkBackupStatus = new CheckBackupStatus((HttpSolrClient) masterClient, coreName, null);\n        while (!checkBackupStatus.success) {\n          checkBackupStatus.fetchStatus();\n          Thread.sleep(1000);\n        }\n      } else {\n        log.info(\"Running Backup via core admin api\");\n        Map<String,String> params = new HashMap<>();\n        params.put(\"name\", backupName);\n        params.put(CoreAdminParams.BACKUP_REPOSITORY, \"hdfs\");\n        BackupRestoreUtils.runCoreAdminCommand(replicaBaseUrl, coreName, CoreAdminAction.BACKUPCORE.toString(), params);\n      }\n\n      int numRestoreTests = nDocs > 0 ? TestUtil.nextInt(random(), 1, 5) : 1;\n      for (int attempts=0; attempts<numRestoreTests; attempts++) {\n        //Modify existing index before we call restore.\n        if (nDocs > 0) {\n          //Delete a few docs\n          int numDeletes = TestUtil.nextInt(random(), 1, nDocs);\n          for(int i=0; i<numDeletes; i++) {\n            masterClient.deleteByQuery(collectionName, \"id:\" + i);\n          }\n          masterClient.commit(collectionName);\n\n          //Add a few more\n          int moreAdds = TestUtil.nextInt(random(), 1, 100);\n          for (int i=0; i<moreAdds; i++) {\n            SolrInputDocument doc = new SolrInputDocument();\n            doc.addField(\"id\", i + nDocs);\n            doc.addField(\"name\", \"name = \" + (i + nDocs));\n            masterClient.add(collectionName, doc);\n          }\n          //Purposely not calling commit once in a while. There can be some docs which are not committed\n          if (usually()) {\n            masterClient.commit(collectionName);\n          }\n        }\n        // Snapshooter prefixes \"snapshot.\" to the backup name.\n        if (testViaReplicationHandler) {\n          log.info(\"Running Restore via replication handler\");\n          // Snapshooter prefixes \"snapshot.\" to the backup name.\n          BackupRestoreUtils.runReplicationHandlerCommand(baseUrl, coreName, ReplicationHandler.CMD_RESTORE, \"hdfs\", backupName);\n          while (!TestRestoreCore.fetchRestoreStatus(baseUrl, coreName)) {\n            Thread.sleep(1000);\n          }\n        } else {\n          log.info(\"Running Restore via core admin api\");\n          Map<String,String> params = new HashMap<>();\n          params.put(\"name\", \"snapshot.\" + backupName);\n          params.put(CoreAdminParams.BACKUP_REPOSITORY, \"hdfs\");\n          BackupRestoreUtils.runCoreAdminCommand(replicaBaseUrl, coreName, CoreAdminAction.RESTORECORE.toString(), params);\n        }\n        //See if restore was successful by checking if all the docs are present again\n        BackupRestoreUtils.verifyDocs(nDocs, masterClient, coreName);\n\n        // Verify the permissions for the backup folder.\n        FileStatus status = fs.getFileStatus(new org.apache.hadoop.fs.Path(\"/backup/snapshot.\"+backupName));\n        FsPermission perm = status.getPermission();\n        assertEquals(FsAction.ALL, perm.getUserAction());\n        assertEquals(FsAction.ALL, perm.getGroupAction());\n        assertEquals(FsAction.ALL, perm.getOtherAction());\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n    CloudSolrClient solrClient = cluster.getSolrClient();\n    String collectionName = \"HdfsBackupRestore\";\n    CollectionAdminRequest.Create create =\n        CollectionAdminRequest.createCollection(collectionName, \"conf1\", 1, 1);\n    create.process(solrClient);\n\n    int nDocs = BackupRestoreUtils.indexDocs(solrClient, collectionName, docsSeed);\n\n    DocCollection collectionState = solrClient.getZkStateReader().getClusterState().getCollection(collectionName);\n    assertEquals(1, collectionState.getActiveSlices().size());\n    Slice shard = collectionState.getActiveSlices().iterator().next();\n    assertEquals(1, shard.getReplicas().size());\n    Replica replica = shard.getReplicas().iterator().next();\n\n    String replicaBaseUrl = replica.getStr(BASE_URL_PROP);\n    String coreName = replica.getStr(ZkStateReader.CORE_NAME_PROP);\n    String backupName = TestUtil.randomSimpleString(random(), 1, 5);\n\n    boolean testViaReplicationHandler = random().nextBoolean();\n    String baseUrl = cluster.getJettySolrRunners().get(0).getBaseUrl().toString();\n\n    try (SolrClient masterClient = getHttpSolrClient(replicaBaseUrl)) {\n      // Create a backup.\n      if (testViaReplicationHandler) {\n        log.info(\"Running Backup via replication handler\");\n        BackupRestoreUtils.runReplicationHandlerCommand(baseUrl, coreName, ReplicationHandler.CMD_BACKUP, \"hdfs\", backupName);\n        CheckBackupStatus checkBackupStatus = new CheckBackupStatus((HttpSolrClient) masterClient, coreName, null);\n        while (!checkBackupStatus.success) {\n          checkBackupStatus.fetchStatus();\n          Thread.sleep(1000);\n        }\n      } else {\n        log.info(\"Running Backup via core admin api\");\n        Map<String,String> params = new HashMap<>();\n        params.put(\"name\", backupName);\n        params.put(CoreAdminParams.BACKUP_REPOSITORY, \"hdfs\");\n        BackupRestoreUtils.runCoreAdminCommand(replicaBaseUrl, coreName, CoreAdminAction.BACKUPCORE.toString(), params);\n      }\n\n      int numRestoreTests = nDocs > 0 ? TestUtil.nextInt(random(), 1, 5) : 1;\n      for (int attempts=0; attempts<numRestoreTests; attempts++) {\n        //Modify existing index before we call restore.\n        if (nDocs > 0) {\n          //Delete a few docs\n          int numDeletes = TestUtil.nextInt(random(), 1, nDocs);\n          for(int i=0; i<numDeletes; i++) {\n            masterClient.deleteByQuery(collectionName, \"id:\" + i);\n          }\n          masterClient.commit(collectionName);\n\n          //Add a few more\n          int moreAdds = TestUtil.nextInt(random(), 1, 100);\n          for (int i=0; i<moreAdds; i++) {\n            SolrInputDocument doc = new SolrInputDocument();\n            doc.addField(\"id\", i + nDocs);\n            doc.addField(\"name\", \"name = \" + (i + nDocs));\n            masterClient.add(collectionName, doc);\n          }\n          //Purposely not calling commit once in a while. There can be some docs which are not committed\n          if (usually()) {\n            masterClient.commit(collectionName);\n          }\n        }\n        // Snapshooter prefixes \"snapshot.\" to the backup name.\n        if (testViaReplicationHandler) {\n          log.info(\"Running Restore via replication handler\");\n          // Snapshooter prefixes \"snapshot.\" to the backup name.\n          BackupRestoreUtils.runReplicationHandlerCommand(baseUrl, coreName, ReplicationHandler.CMD_RESTORE, \"hdfs\", backupName);\n          while (!TestRestoreCore.fetchRestoreStatus(baseUrl, coreName)) {\n            Thread.sleep(1000);\n          }\n        } else {\n          log.info(\"Running Restore via core admin api\");\n          Map<String,String> params = new HashMap<>();\n          params.put(\"name\", \"snapshot.\" + backupName);\n          params.put(CoreAdminParams.BACKUP_REPOSITORY, \"hdfs\");\n          BackupRestoreUtils.runCoreAdminCommand(replicaBaseUrl, coreName, CoreAdminAction.RESTORECORE.toString(), params);\n        }\n        //See if restore was successful by checking if all the docs are present again\n        BackupRestoreUtils.verifyDocs(nDocs, masterClient, coreName);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"60b61628d1912768f51eccaa8ead5a5a32ab34c6","date":1477427681,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/handler/TestHdfsBackupRestoreCore#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/handler/TestHdfsBackupRestoreCore#test().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n    CloudSolrClient solrClient = cluster.getSolrClient();\n    String collectionName = \"HdfsBackupRestore\";\n    CollectionAdminRequest.Create create =\n        CollectionAdminRequest.createCollection(collectionName, \"conf1\", 1, 1);\n    create.process(solrClient);\n\n    int nDocs = BackupRestoreUtils.indexDocs(solrClient, collectionName, docsSeed);\n\n    DocCollection collectionState = solrClient.getZkStateReader().getClusterState().getCollection(collectionName);\n    assertEquals(1, collectionState.getActiveSlices().size());\n    Slice shard = collectionState.getActiveSlices().iterator().next();\n    assertEquals(1, shard.getReplicas().size());\n    Replica replica = shard.getReplicas().iterator().next();\n\n    String replicaBaseUrl = replica.getStr(BASE_URL_PROP);\n    String coreName = replica.getStr(ZkStateReader.CORE_NAME_PROP);\n    String backupName = TestUtil.randomSimpleString(random(), 1, 5);\n\n    boolean testViaReplicationHandler = random().nextBoolean();\n    String baseUrl = cluster.getJettySolrRunners().get(0).getBaseUrl().toString();\n\n    try (SolrClient masterClient = getHttpSolrClient(replicaBaseUrl)) {\n      // Create a backup.\n      if (testViaReplicationHandler) {\n        log.info(\"Running Backup via replication handler\");\n        BackupRestoreUtils.runReplicationHandlerCommand(baseUrl, coreName, ReplicationHandler.CMD_BACKUP, \"hdfs\", backupName);\n        CheckBackupStatus checkBackupStatus = new CheckBackupStatus((HttpSolrClient) masterClient, coreName, null);\n        while (!checkBackupStatus.success) {\n          checkBackupStatus.fetchStatus();\n          Thread.sleep(1000);\n        }\n      } else {\n        log.info(\"Running Backup via core admin api\");\n        Map<String,String> params = new HashMap<>();\n        params.put(\"name\", backupName);\n        params.put(CoreAdminParams.BACKUP_REPOSITORY, \"hdfs\");\n        BackupRestoreUtils.runCoreAdminCommand(replicaBaseUrl, coreName, CoreAdminAction.BACKUPCORE.toString(), params);\n      }\n\n      int numRestoreTests = nDocs > 0 ? TestUtil.nextInt(random(), 1, 5) : 1;\n      for (int attempts=0; attempts<numRestoreTests; attempts++) {\n        //Modify existing index before we call restore.\n        if (nDocs > 0) {\n          //Delete a few docs\n          int numDeletes = TestUtil.nextInt(random(), 1, nDocs);\n          for(int i=0; i<numDeletes; i++) {\n            masterClient.deleteByQuery(collectionName, \"id:\" + i);\n          }\n          masterClient.commit(collectionName);\n\n          //Add a few more\n          int moreAdds = TestUtil.nextInt(random(), 1, 100);\n          for (int i=0; i<moreAdds; i++) {\n            SolrInputDocument doc = new SolrInputDocument();\n            doc.addField(\"id\", i + nDocs);\n            doc.addField(\"name\", \"name = \" + (i + nDocs));\n            masterClient.add(collectionName, doc);\n          }\n          //Purposely not calling commit once in a while. There can be some docs which are not committed\n          if (usually()) {\n            masterClient.commit(collectionName);\n          }\n        }\n        // Snapshooter prefixes \"snapshot.\" to the backup name.\n        if (testViaReplicationHandler) {\n          log.info(\"Running Restore via replication handler\");\n          // Snapshooter prefixes \"snapshot.\" to the backup name.\n          BackupRestoreUtils.runReplicationHandlerCommand(baseUrl, coreName, ReplicationHandler.CMD_RESTORE, \"hdfs\", backupName);\n          while (!TestRestoreCore.fetchRestoreStatus(baseUrl, coreName)) {\n            Thread.sleep(1000);\n          }\n        } else {\n          log.info(\"Running Restore via core admin api\");\n          Map<String,String> params = new HashMap<>();\n          params.put(\"name\", \"snapshot.\" + backupName);\n          params.put(CoreAdminParams.BACKUP_REPOSITORY, \"hdfs\");\n          BackupRestoreUtils.runCoreAdminCommand(replicaBaseUrl, coreName, CoreAdminAction.RESTORECORE.toString(), params);\n        }\n        //See if restore was successful by checking if all the docs are present again\n        BackupRestoreUtils.verifyDocs(nDocs, masterClient, coreName);\n\n        // Verify the permissions for the backup folder.\n        FileStatus status = fs.getFileStatus(new org.apache.hadoop.fs.Path(\"/backup/snapshot.\"+backupName));\n        FsPermission perm = status.getPermission();\n        assertEquals(FsAction.ALL, perm.getUserAction());\n        assertEquals(FsAction.ALL, perm.getGroupAction());\n        assertEquals(FsAction.ALL, perm.getOtherAction());\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n    CloudSolrClient solrClient = cluster.getSolrClient();\n    String collectionName = \"HdfsBackupRestore\";\n    CollectionAdminRequest.Create create =\n        CollectionAdminRequest.createCollection(collectionName, \"conf1\", 1, 1);\n    create.process(solrClient);\n\n    int nDocs = BackupRestoreUtils.indexDocs(solrClient, collectionName, docsSeed);\n\n    DocCollection collectionState = solrClient.getZkStateReader().getClusterState().getCollection(collectionName);\n    assertEquals(1, collectionState.getActiveSlices().size());\n    Slice shard = collectionState.getActiveSlices().iterator().next();\n    assertEquals(1, shard.getReplicas().size());\n    Replica replica = shard.getReplicas().iterator().next();\n\n    String replicaBaseUrl = replica.getStr(BASE_URL_PROP);\n    String coreName = replica.getStr(ZkStateReader.CORE_NAME_PROP);\n    String backupName = TestUtil.randomSimpleString(random(), 1, 5);\n\n    boolean testViaReplicationHandler = random().nextBoolean();\n    String baseUrl = cluster.getJettySolrRunners().get(0).getBaseUrl().toString();\n\n    try (SolrClient masterClient = getHttpSolrClient(replicaBaseUrl)) {\n      // Create a backup.\n      if (testViaReplicationHandler) {\n        log.info(\"Running Backup via replication handler\");\n        BackupRestoreUtils.runReplicationHandlerCommand(baseUrl, coreName, ReplicationHandler.CMD_BACKUP, \"hdfs\", backupName);\n        CheckBackupStatus checkBackupStatus = new CheckBackupStatus((HttpSolrClient) masterClient, coreName, null);\n        while (!checkBackupStatus.success) {\n          checkBackupStatus.fetchStatus();\n          Thread.sleep(1000);\n        }\n      } else {\n        log.info(\"Running Backup via core admin api\");\n        Map<String,String> params = new HashMap<>();\n        params.put(\"name\", backupName);\n        params.put(CoreAdminParams.BACKUP_REPOSITORY, \"hdfs\");\n        BackupRestoreUtils.runCoreAdminCommand(replicaBaseUrl, coreName, CoreAdminAction.BACKUPCORE.toString(), params);\n      }\n\n      int numRestoreTests = nDocs > 0 ? TestUtil.nextInt(random(), 1, 5) : 1;\n      for (int attempts=0; attempts<numRestoreTests; attempts++) {\n        //Modify existing index before we call restore.\n        if (nDocs > 0) {\n          //Delete a few docs\n          int numDeletes = TestUtil.nextInt(random(), 1, nDocs);\n          for(int i=0; i<numDeletes; i++) {\n            masterClient.deleteByQuery(collectionName, \"id:\" + i);\n          }\n          masterClient.commit(collectionName);\n\n          //Add a few more\n          int moreAdds = TestUtil.nextInt(random(), 1, 100);\n          for (int i=0; i<moreAdds; i++) {\n            SolrInputDocument doc = new SolrInputDocument();\n            doc.addField(\"id\", i + nDocs);\n            doc.addField(\"name\", \"name = \" + (i + nDocs));\n            masterClient.add(collectionName, doc);\n          }\n          //Purposely not calling commit once in a while. There can be some docs which are not committed\n          if (usually()) {\n            masterClient.commit(collectionName);\n          }\n        }\n        // Snapshooter prefixes \"snapshot.\" to the backup name.\n        if (testViaReplicationHandler) {\n          log.info(\"Running Restore via replication handler\");\n          // Snapshooter prefixes \"snapshot.\" to the backup name.\n          BackupRestoreUtils.runReplicationHandlerCommand(baseUrl, coreName, ReplicationHandler.CMD_RESTORE, \"hdfs\", backupName);\n          while (!TestRestoreCore.fetchRestoreStatus(baseUrl, coreName)) {\n            Thread.sleep(1000);\n          }\n        } else {\n          log.info(\"Running Restore via core admin api\");\n          Map<String,String> params = new HashMap<>();\n          params.put(\"name\", \"snapshot.\" + backupName);\n          params.put(CoreAdminParams.BACKUP_REPOSITORY, \"hdfs\");\n          BackupRestoreUtils.runCoreAdminCommand(replicaBaseUrl, coreName, CoreAdminAction.RESTORECORE.toString(), params);\n        }\n        //See if restore was successful by checking if all the docs are present again\n        BackupRestoreUtils.verifyDocs(nDocs, masterClient, coreName);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"80d0e6d59ae23f4a6f30eaf40bfb40742300287f","date":1477598926,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/handler/TestHdfsBackupRestoreCore#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/handler/TestHdfsBackupRestoreCore#test().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n    CloudSolrClient solrClient = cluster.getSolrClient();\n    String collectionName = \"HdfsBackupRestore\";\n    CollectionAdminRequest.Create create =\n        CollectionAdminRequest.createCollection(collectionName, \"conf1\", 1, 1);\n    create.process(solrClient);\n\n    int nDocs = BackupRestoreUtils.indexDocs(solrClient, collectionName, docsSeed);\n\n    DocCollection collectionState = solrClient.getZkStateReader().getClusterState().getCollection(collectionName);\n    assertEquals(1, collectionState.getActiveSlices().size());\n    Slice shard = collectionState.getActiveSlices().iterator().next();\n    assertEquals(1, shard.getReplicas().size());\n    Replica replica = shard.getReplicas().iterator().next();\n\n    String replicaBaseUrl = replica.getStr(BASE_URL_PROP);\n    String coreName = replica.getStr(ZkStateReader.CORE_NAME_PROP);\n    String backupName = TestUtil.randomSimpleString(random(), 1, 5);\n\n    boolean testViaReplicationHandler = random().nextBoolean();\n    String baseUrl = cluster.getJettySolrRunners().get(0).getBaseUrl().toString();\n\n    try (SolrClient masterClient = getHttpSolrClient(replicaBaseUrl)) {\n      // Create a backup.\n      if (testViaReplicationHandler) {\n        log.info(\"Running Backup via replication handler\");\n        BackupRestoreUtils.runReplicationHandlerCommand(baseUrl, coreName, ReplicationHandler.CMD_BACKUP, \"hdfs\", backupName);\n        CheckBackupStatus checkBackupStatus = new CheckBackupStatus((HttpSolrClient) masterClient, coreName, null);\n        while (!checkBackupStatus.success) {\n          checkBackupStatus.fetchStatus();\n          Thread.sleep(1000);\n        }\n      } else {\n        log.info(\"Running Backup via core admin api\");\n        Map<String,String> params = new HashMap<>();\n        params.put(\"name\", backupName);\n        params.put(CoreAdminParams.BACKUP_REPOSITORY, \"hdfs\");\n        BackupRestoreUtils.runCoreAdminCommand(replicaBaseUrl, coreName, CoreAdminAction.BACKUPCORE.toString(), params);\n      }\n\n      int numRestoreTests = nDocs > 0 ? TestUtil.nextInt(random(), 1, 5) : 1;\n      for (int attempts=0; attempts<numRestoreTests; attempts++) {\n        //Modify existing index before we call restore.\n        if (nDocs > 0) {\n          //Delete a few docs\n          int numDeletes = TestUtil.nextInt(random(), 1, nDocs);\n          for(int i=0; i<numDeletes; i++) {\n            masterClient.deleteByQuery(collectionName, \"id:\" + i);\n          }\n          masterClient.commit(collectionName);\n\n          //Add a few more\n          int moreAdds = TestUtil.nextInt(random(), 1, 100);\n          for (int i=0; i<moreAdds; i++) {\n            SolrInputDocument doc = new SolrInputDocument();\n            doc.addField(\"id\", i + nDocs);\n            doc.addField(\"name\", \"name = \" + (i + nDocs));\n            masterClient.add(collectionName, doc);\n          }\n          //Purposely not calling commit once in a while. There can be some docs which are not committed\n          if (usually()) {\n            masterClient.commit(collectionName);\n          }\n        }\n        // Snapshooter prefixes \"snapshot.\" to the backup name.\n        if (testViaReplicationHandler) {\n          log.info(\"Running Restore via replication handler\");\n          // Snapshooter prefixes \"snapshot.\" to the backup name.\n          BackupRestoreUtils.runReplicationHandlerCommand(baseUrl, coreName, ReplicationHandler.CMD_RESTORE, \"hdfs\", backupName);\n          while (!TestRestoreCore.fetchRestoreStatus(baseUrl, coreName)) {\n            Thread.sleep(1000);\n          }\n        } else {\n          log.info(\"Running Restore via core admin api\");\n          Map<String,String> params = new HashMap<>();\n          params.put(\"name\", \"snapshot.\" + backupName);\n          params.put(CoreAdminParams.BACKUP_REPOSITORY, \"hdfs\");\n          BackupRestoreUtils.runCoreAdminCommand(replicaBaseUrl, coreName, CoreAdminAction.RESTORECORE.toString(), params);\n        }\n        //See if restore was successful by checking if all the docs are present again\n        BackupRestoreUtils.verifyDocs(nDocs, masterClient, coreName);\n\n        // Verify the permissions for the backup folder.\n        FileStatus status = fs.getFileStatus(new org.apache.hadoop.fs.Path(\"/backup/snapshot.\"+backupName));\n        FsPermission perm = status.getPermission();\n        assertEquals(FsAction.ALL, perm.getUserAction());\n        assertEquals(FsAction.ALL, perm.getGroupAction());\n        assertEquals(FsAction.ALL, perm.getOtherAction());\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n    CloudSolrClient solrClient = cluster.getSolrClient();\n    String collectionName = \"HdfsBackupRestore\";\n    CollectionAdminRequest.Create create =\n        CollectionAdminRequest.createCollection(collectionName, \"conf1\", 1, 1);\n    create.process(solrClient);\n\n    int nDocs = BackupRestoreUtils.indexDocs(solrClient, collectionName, docsSeed);\n\n    DocCollection collectionState = solrClient.getZkStateReader().getClusterState().getCollection(collectionName);\n    assertEquals(1, collectionState.getActiveSlices().size());\n    Slice shard = collectionState.getActiveSlices().iterator().next();\n    assertEquals(1, shard.getReplicas().size());\n    Replica replica = shard.getReplicas().iterator().next();\n\n    String replicaBaseUrl = replica.getStr(BASE_URL_PROP);\n    String coreName = replica.getStr(ZkStateReader.CORE_NAME_PROP);\n    String backupName = TestUtil.randomSimpleString(random(), 1, 5);\n\n    boolean testViaReplicationHandler = random().nextBoolean();\n    String baseUrl = cluster.getJettySolrRunners().get(0).getBaseUrl().toString();\n\n    try (SolrClient masterClient = getHttpSolrClient(replicaBaseUrl)) {\n      // Create a backup.\n      if (testViaReplicationHandler) {\n        log.info(\"Running Backup via replication handler\");\n        BackupRestoreUtils.runReplicationHandlerCommand(baseUrl, coreName, ReplicationHandler.CMD_BACKUP, \"hdfs\", backupName);\n        CheckBackupStatus checkBackupStatus = new CheckBackupStatus((HttpSolrClient) masterClient, coreName, null);\n        while (!checkBackupStatus.success) {\n          checkBackupStatus.fetchStatus();\n          Thread.sleep(1000);\n        }\n      } else {\n        log.info(\"Running Backup via core admin api\");\n        Map<String,String> params = new HashMap<>();\n        params.put(\"name\", backupName);\n        params.put(CoreAdminParams.BACKUP_REPOSITORY, \"hdfs\");\n        BackupRestoreUtils.runCoreAdminCommand(replicaBaseUrl, coreName, CoreAdminAction.BACKUPCORE.toString(), params);\n      }\n\n      int numRestoreTests = nDocs > 0 ? TestUtil.nextInt(random(), 1, 5) : 1;\n      for (int attempts=0; attempts<numRestoreTests; attempts++) {\n        //Modify existing index before we call restore.\n        if (nDocs > 0) {\n          //Delete a few docs\n          int numDeletes = TestUtil.nextInt(random(), 1, nDocs);\n          for(int i=0; i<numDeletes; i++) {\n            masterClient.deleteByQuery(collectionName, \"id:\" + i);\n          }\n          masterClient.commit(collectionName);\n\n          //Add a few more\n          int moreAdds = TestUtil.nextInt(random(), 1, 100);\n          for (int i=0; i<moreAdds; i++) {\n            SolrInputDocument doc = new SolrInputDocument();\n            doc.addField(\"id\", i + nDocs);\n            doc.addField(\"name\", \"name = \" + (i + nDocs));\n            masterClient.add(collectionName, doc);\n          }\n          //Purposely not calling commit once in a while. There can be some docs which are not committed\n          if (usually()) {\n            masterClient.commit(collectionName);\n          }\n        }\n        // Snapshooter prefixes \"snapshot.\" to the backup name.\n        if (testViaReplicationHandler) {\n          log.info(\"Running Restore via replication handler\");\n          // Snapshooter prefixes \"snapshot.\" to the backup name.\n          BackupRestoreUtils.runReplicationHandlerCommand(baseUrl, coreName, ReplicationHandler.CMD_RESTORE, \"hdfs\", backupName);\n          while (!TestRestoreCore.fetchRestoreStatus(baseUrl, coreName)) {\n            Thread.sleep(1000);\n          }\n        } else {\n          log.info(\"Running Restore via core admin api\");\n          Map<String,String> params = new HashMap<>();\n          params.put(\"name\", \"snapshot.\" + backupName);\n          params.put(CoreAdminParams.BACKUP_REPOSITORY, \"hdfs\");\n          BackupRestoreUtils.runCoreAdminCommand(replicaBaseUrl, coreName, CoreAdminAction.RESTORECORE.toString(), params);\n        }\n        //See if restore was successful by checking if all the docs are present again\n        BackupRestoreUtils.verifyDocs(nDocs, masterClient, coreName);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"add53de9835b2cd1a7a80b4e0036afee171c9fdf","date":1552937136,"type":3,"author":"Kevin Risden","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/handler/TestHdfsBackupRestoreCore#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/handler/TestHdfsBackupRestoreCore#test().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n    CloudSolrClient solrClient = cluster.getSolrClient();\n    String collectionName = \"HdfsBackupRestore\";\n    CollectionAdminRequest.Create create =\n        CollectionAdminRequest.createCollection(collectionName, \"conf1\", 1, 1);\n    create.process(solrClient);\n\n    int nDocs = BackupRestoreUtils.indexDocs(solrClient, collectionName, docsSeed);\n\n    DocCollection collectionState = solrClient.getZkStateReader().getClusterState().getCollection(collectionName);\n    assertEquals(1, collectionState.getActiveSlices().size());\n    Slice shard = collectionState.getActiveSlices().iterator().next();\n    assertEquals(1, shard.getReplicas().size());\n    Replica replica = shard.getReplicas().iterator().next();\n\n    String replicaBaseUrl = replica.getStr(BASE_URL_PROP);\n    String coreName = replica.getStr(ZkStateReader.CORE_NAME_PROP);\n    String backupName = TestUtil.randomSimpleString(random(), 1, 5);\n\n    boolean testViaReplicationHandler = random().nextBoolean();\n    String baseUrl = cluster.getJettySolrRunners().get(0).getBaseUrl().toString();\n\n    try (HttpSolrClient masterClient = getHttpSolrClient(replicaBaseUrl)) {\n      // Create a backup.\n      if (testViaReplicationHandler) {\n        log.info(\"Running Backup via replication handler\");\n        BackupRestoreUtils.runReplicationHandlerCommand(baseUrl, coreName, ReplicationHandler.CMD_BACKUP, \"hdfs\", backupName);\n        CheckBackupStatus checkBackupStatus = new CheckBackupStatus(masterClient, coreName, null);\n        while (!checkBackupStatus.success) {\n          checkBackupStatus.fetchStatus();\n          Thread.sleep(1000);\n        }\n      } else {\n        log.info(\"Running Backup via core admin api\");\n        Map<String,String> params = new HashMap<>();\n        params.put(\"name\", backupName);\n        params.put(CoreAdminParams.BACKUP_REPOSITORY, \"hdfs\");\n        BackupRestoreUtils.runCoreAdminCommand(replicaBaseUrl, coreName, CoreAdminAction.BACKUPCORE.toString(), params);\n      }\n\n      int numRestoreTests = nDocs > 0 ? TestUtil.nextInt(random(), 1, 5) : 1;\n      for (int attempts=0; attempts<numRestoreTests; attempts++) {\n        //Modify existing index before we call restore.\n        if (nDocs > 0) {\n          //Delete a few docs\n          int numDeletes = TestUtil.nextInt(random(), 1, nDocs);\n          for(int i=0; i<numDeletes; i++) {\n            masterClient.deleteByQuery(collectionName, \"id:\" + i);\n          }\n          masterClient.commit(collectionName);\n\n          //Add a few more\n          int moreAdds = TestUtil.nextInt(random(), 1, 100);\n          for (int i=0; i<moreAdds; i++) {\n            SolrInputDocument doc = new SolrInputDocument();\n            doc.addField(\"id\", i + nDocs);\n            doc.addField(\"name\", \"name = \" + (i + nDocs));\n            masterClient.add(collectionName, doc);\n          }\n          //Purposely not calling commit once in a while. There can be some docs which are not committed\n          if (usually()) {\n            masterClient.commit(collectionName);\n          }\n        }\n        // Snapshooter prefixes \"snapshot.\" to the backup name.\n        if (testViaReplicationHandler) {\n          log.info(\"Running Restore via replication handler\");\n          // Snapshooter prefixes \"snapshot.\" to the backup name.\n          BackupRestoreUtils.runReplicationHandlerCommand(baseUrl, coreName, ReplicationHandler.CMD_RESTORE, \"hdfs\", backupName);\n          while (!TestRestoreCore.fetchRestoreStatus(baseUrl, coreName)) {\n            Thread.sleep(1000);\n          }\n        } else {\n          log.info(\"Running Restore via core admin api\");\n          Map<String,String> params = new HashMap<>();\n          params.put(\"name\", \"snapshot.\" + backupName);\n          params.put(CoreAdminParams.BACKUP_REPOSITORY, \"hdfs\");\n          BackupRestoreUtils.runCoreAdminCommand(replicaBaseUrl, coreName, CoreAdminAction.RESTORECORE.toString(), params);\n        }\n        //See if restore was successful by checking if all the docs are present again\n        BackupRestoreUtils.verifyDocs(nDocs, masterClient, coreName);\n\n        // Verify the permissions for the backup folder.\n        FileStatus status = fs.getFileStatus(new org.apache.hadoop.fs.Path(\"/backup/snapshot.\"+backupName));\n        FsPermission perm = status.getPermission();\n        assertEquals(FsAction.ALL, perm.getUserAction());\n        assertEquals(FsAction.ALL, perm.getGroupAction());\n        assertEquals(FsAction.ALL, perm.getOtherAction());\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n    CloudSolrClient solrClient = cluster.getSolrClient();\n    String collectionName = \"HdfsBackupRestore\";\n    CollectionAdminRequest.Create create =\n        CollectionAdminRequest.createCollection(collectionName, \"conf1\", 1, 1);\n    create.process(solrClient);\n\n    int nDocs = BackupRestoreUtils.indexDocs(solrClient, collectionName, docsSeed);\n\n    DocCollection collectionState = solrClient.getZkStateReader().getClusterState().getCollection(collectionName);\n    assertEquals(1, collectionState.getActiveSlices().size());\n    Slice shard = collectionState.getActiveSlices().iterator().next();\n    assertEquals(1, shard.getReplicas().size());\n    Replica replica = shard.getReplicas().iterator().next();\n\n    String replicaBaseUrl = replica.getStr(BASE_URL_PROP);\n    String coreName = replica.getStr(ZkStateReader.CORE_NAME_PROP);\n    String backupName = TestUtil.randomSimpleString(random(), 1, 5);\n\n    boolean testViaReplicationHandler = random().nextBoolean();\n    String baseUrl = cluster.getJettySolrRunners().get(0).getBaseUrl().toString();\n\n    try (SolrClient masterClient = getHttpSolrClient(replicaBaseUrl)) {\n      // Create a backup.\n      if (testViaReplicationHandler) {\n        log.info(\"Running Backup via replication handler\");\n        BackupRestoreUtils.runReplicationHandlerCommand(baseUrl, coreName, ReplicationHandler.CMD_BACKUP, \"hdfs\", backupName);\n        CheckBackupStatus checkBackupStatus = new CheckBackupStatus((HttpSolrClient) masterClient, coreName, null);\n        while (!checkBackupStatus.success) {\n          checkBackupStatus.fetchStatus();\n          Thread.sleep(1000);\n        }\n      } else {\n        log.info(\"Running Backup via core admin api\");\n        Map<String,String> params = new HashMap<>();\n        params.put(\"name\", backupName);\n        params.put(CoreAdminParams.BACKUP_REPOSITORY, \"hdfs\");\n        BackupRestoreUtils.runCoreAdminCommand(replicaBaseUrl, coreName, CoreAdminAction.BACKUPCORE.toString(), params);\n      }\n\n      int numRestoreTests = nDocs > 0 ? TestUtil.nextInt(random(), 1, 5) : 1;\n      for (int attempts=0; attempts<numRestoreTests; attempts++) {\n        //Modify existing index before we call restore.\n        if (nDocs > 0) {\n          //Delete a few docs\n          int numDeletes = TestUtil.nextInt(random(), 1, nDocs);\n          for(int i=0; i<numDeletes; i++) {\n            masterClient.deleteByQuery(collectionName, \"id:\" + i);\n          }\n          masterClient.commit(collectionName);\n\n          //Add a few more\n          int moreAdds = TestUtil.nextInt(random(), 1, 100);\n          for (int i=0; i<moreAdds; i++) {\n            SolrInputDocument doc = new SolrInputDocument();\n            doc.addField(\"id\", i + nDocs);\n            doc.addField(\"name\", \"name = \" + (i + nDocs));\n            masterClient.add(collectionName, doc);\n          }\n          //Purposely not calling commit once in a while. There can be some docs which are not committed\n          if (usually()) {\n            masterClient.commit(collectionName);\n          }\n        }\n        // Snapshooter prefixes \"snapshot.\" to the backup name.\n        if (testViaReplicationHandler) {\n          log.info(\"Running Restore via replication handler\");\n          // Snapshooter prefixes \"snapshot.\" to the backup name.\n          BackupRestoreUtils.runReplicationHandlerCommand(baseUrl, coreName, ReplicationHandler.CMD_RESTORE, \"hdfs\", backupName);\n          while (!TestRestoreCore.fetchRestoreStatus(baseUrl, coreName)) {\n            Thread.sleep(1000);\n          }\n        } else {\n          log.info(\"Running Restore via core admin api\");\n          Map<String,String> params = new HashMap<>();\n          params.put(\"name\", \"snapshot.\" + backupName);\n          params.put(CoreAdminParams.BACKUP_REPOSITORY, \"hdfs\");\n          BackupRestoreUtils.runCoreAdminCommand(replicaBaseUrl, coreName, CoreAdminAction.RESTORECORE.toString(), params);\n        }\n        //See if restore was successful by checking if all the docs are present again\n        BackupRestoreUtils.verifyDocs(nDocs, masterClient, coreName);\n\n        // Verify the permissions for the backup folder.\n        FileStatus status = fs.getFileStatus(new org.apache.hadoop.fs.Path(\"/backup/snapshot.\"+backupName));\n        FsPermission perm = status.getPermission();\n        assertEquals(FsAction.ALL, perm.getUserAction());\n        assertEquals(FsAction.ALL, perm.getGroupAction());\n        assertEquals(FsAction.ALL, perm.getOtherAction());\n      }\n    }\n  }\n\n","bugFix":["a51ab9b1f1b896f06b7ba61672f0fca2a4fce43b"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ec54bd926c45854b5a1599685b0f7d2bfbfe177f","date":1573838246,"type":3,"author":"Chris Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/handler/TestHdfsBackupRestoreCore#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/handler/TestHdfsBackupRestoreCore#test().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n    CloudSolrClient solrClient = cluster.getSolrClient();\n    String collectionName = \"HdfsBackupRestore\";\n    CollectionAdminRequest.Create create =\n        CollectionAdminRequest.createCollection(collectionName, \"conf1\", 1, 1);\n    create.process(solrClient);\n\n    int nDocs = BackupRestoreUtils.indexDocs(solrClient, collectionName, docsSeed);\n\n    DocCollection collectionState = solrClient.getZkStateReader().getClusterState().getCollection(collectionName);\n    assertEquals(1, collectionState.getActiveSlices().size());\n    Slice shard = collectionState.getActiveSlices().iterator().next();\n    assertEquals(1, shard.getReplicas().size());\n    Replica replica = shard.getReplicas().iterator().next();\n\n    String replicaBaseUrl = replica.getStr(BASE_URL_PROP);\n    String coreName = replica.getStr(ZkStateReader.CORE_NAME_PROP);\n    String backupName = TestUtil.randomSimpleString(random(), 1, 5);\n\n    boolean testViaReplicationHandler = random().nextBoolean();\n    String baseUrl = cluster.getJettySolrRunners().get(0).getBaseUrl().toString();\n\n    try (HttpSolrClient masterClient = getHttpSolrClient(replicaBaseUrl)) {\n      // Create a backup.\n      if (testViaReplicationHandler) {\n        log.info(\"Running Backup via replication handler\");\n        BackupRestoreUtils.runReplicationHandlerCommand(baseUrl, coreName, ReplicationHandler.CMD_BACKUP, \"hdfs\", backupName);\n        final BackupStatusChecker backupStatus\n          = new BackupStatusChecker(masterClient, \"/\" + coreName + \"/replication\");\n        backupStatus.waitForBackupSuccess(backupName, 30);\n      } else {\n        log.info(\"Running Backup via core admin api\");\n        Map<String,String> params = new HashMap<>();\n        params.put(\"name\", backupName);\n        params.put(CoreAdminParams.BACKUP_REPOSITORY, \"hdfs\");\n        BackupRestoreUtils.runCoreAdminCommand(replicaBaseUrl, coreName, CoreAdminAction.BACKUPCORE.toString(), params);\n      }\n\n      int numRestoreTests = nDocs > 0 ? TestUtil.nextInt(random(), 1, 5) : 1;\n      for (int attempts=0; attempts<numRestoreTests; attempts++) {\n        //Modify existing index before we call restore.\n        if (nDocs > 0) {\n          //Delete a few docs\n          int numDeletes = TestUtil.nextInt(random(), 1, nDocs);\n          for(int i=0; i<numDeletes; i++) {\n            masterClient.deleteByQuery(collectionName, \"id:\" + i);\n          }\n          masterClient.commit(collectionName);\n\n          //Add a few more\n          int moreAdds = TestUtil.nextInt(random(), 1, 100);\n          for (int i=0; i<moreAdds; i++) {\n            SolrInputDocument doc = new SolrInputDocument();\n            doc.addField(\"id\", i + nDocs);\n            doc.addField(\"name\", \"name = \" + (i + nDocs));\n            masterClient.add(collectionName, doc);\n          }\n          //Purposely not calling commit once in a while. There can be some docs which are not committed\n          if (usually()) {\n            masterClient.commit(collectionName);\n          }\n        }\n        // Snapshooter prefixes \"snapshot.\" to the backup name.\n        if (testViaReplicationHandler) {\n          log.info(\"Running Restore via replication handler\");\n          // Snapshooter prefixes \"snapshot.\" to the backup name.\n          BackupRestoreUtils.runReplicationHandlerCommand(baseUrl, coreName, ReplicationHandler.CMD_RESTORE, \"hdfs\", backupName);\n          while (!TestRestoreCore.fetchRestoreStatus(baseUrl, coreName)) {\n            Thread.sleep(1000);\n          }\n        } else {\n          log.info(\"Running Restore via core admin api\");\n          Map<String,String> params = new HashMap<>();\n          params.put(\"name\", \"snapshot.\" + backupName);\n          params.put(CoreAdminParams.BACKUP_REPOSITORY, \"hdfs\");\n          BackupRestoreUtils.runCoreAdminCommand(replicaBaseUrl, coreName, CoreAdminAction.RESTORECORE.toString(), params);\n        }\n        //See if restore was successful by checking if all the docs are present again\n        BackupRestoreUtils.verifyDocs(nDocs, masterClient, coreName);\n\n        // Verify the permissions for the backup folder.\n        FileStatus status = fs.getFileStatus(new org.apache.hadoop.fs.Path(\"/backup/snapshot.\"+backupName));\n        FsPermission perm = status.getPermission();\n        assertEquals(FsAction.ALL, perm.getUserAction());\n        assertEquals(FsAction.ALL, perm.getGroupAction());\n        assertEquals(FsAction.ALL, perm.getOtherAction());\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n    CloudSolrClient solrClient = cluster.getSolrClient();\n    String collectionName = \"HdfsBackupRestore\";\n    CollectionAdminRequest.Create create =\n        CollectionAdminRequest.createCollection(collectionName, \"conf1\", 1, 1);\n    create.process(solrClient);\n\n    int nDocs = BackupRestoreUtils.indexDocs(solrClient, collectionName, docsSeed);\n\n    DocCollection collectionState = solrClient.getZkStateReader().getClusterState().getCollection(collectionName);\n    assertEquals(1, collectionState.getActiveSlices().size());\n    Slice shard = collectionState.getActiveSlices().iterator().next();\n    assertEquals(1, shard.getReplicas().size());\n    Replica replica = shard.getReplicas().iterator().next();\n\n    String replicaBaseUrl = replica.getStr(BASE_URL_PROP);\n    String coreName = replica.getStr(ZkStateReader.CORE_NAME_PROP);\n    String backupName = TestUtil.randomSimpleString(random(), 1, 5);\n\n    boolean testViaReplicationHandler = random().nextBoolean();\n    String baseUrl = cluster.getJettySolrRunners().get(0).getBaseUrl().toString();\n\n    try (HttpSolrClient masterClient = getHttpSolrClient(replicaBaseUrl)) {\n      // Create a backup.\n      if (testViaReplicationHandler) {\n        log.info(\"Running Backup via replication handler\");\n        BackupRestoreUtils.runReplicationHandlerCommand(baseUrl, coreName, ReplicationHandler.CMD_BACKUP, \"hdfs\", backupName);\n        CheckBackupStatus checkBackupStatus = new CheckBackupStatus(masterClient, coreName, null);\n        while (!checkBackupStatus.success) {\n          checkBackupStatus.fetchStatus();\n          Thread.sleep(1000);\n        }\n      } else {\n        log.info(\"Running Backup via core admin api\");\n        Map<String,String> params = new HashMap<>();\n        params.put(\"name\", backupName);\n        params.put(CoreAdminParams.BACKUP_REPOSITORY, \"hdfs\");\n        BackupRestoreUtils.runCoreAdminCommand(replicaBaseUrl, coreName, CoreAdminAction.BACKUPCORE.toString(), params);\n      }\n\n      int numRestoreTests = nDocs > 0 ? TestUtil.nextInt(random(), 1, 5) : 1;\n      for (int attempts=0; attempts<numRestoreTests; attempts++) {\n        //Modify existing index before we call restore.\n        if (nDocs > 0) {\n          //Delete a few docs\n          int numDeletes = TestUtil.nextInt(random(), 1, nDocs);\n          for(int i=0; i<numDeletes; i++) {\n            masterClient.deleteByQuery(collectionName, \"id:\" + i);\n          }\n          masterClient.commit(collectionName);\n\n          //Add a few more\n          int moreAdds = TestUtil.nextInt(random(), 1, 100);\n          for (int i=0; i<moreAdds; i++) {\n            SolrInputDocument doc = new SolrInputDocument();\n            doc.addField(\"id\", i + nDocs);\n            doc.addField(\"name\", \"name = \" + (i + nDocs));\n            masterClient.add(collectionName, doc);\n          }\n          //Purposely not calling commit once in a while. There can be some docs which are not committed\n          if (usually()) {\n            masterClient.commit(collectionName);\n          }\n        }\n        // Snapshooter prefixes \"snapshot.\" to the backup name.\n        if (testViaReplicationHandler) {\n          log.info(\"Running Restore via replication handler\");\n          // Snapshooter prefixes \"snapshot.\" to the backup name.\n          BackupRestoreUtils.runReplicationHandlerCommand(baseUrl, coreName, ReplicationHandler.CMD_RESTORE, \"hdfs\", backupName);\n          while (!TestRestoreCore.fetchRestoreStatus(baseUrl, coreName)) {\n            Thread.sleep(1000);\n          }\n        } else {\n          log.info(\"Running Restore via core admin api\");\n          Map<String,String> params = new HashMap<>();\n          params.put(\"name\", \"snapshot.\" + backupName);\n          params.put(CoreAdminParams.BACKUP_REPOSITORY, \"hdfs\");\n          BackupRestoreUtils.runCoreAdminCommand(replicaBaseUrl, coreName, CoreAdminAction.RESTORECORE.toString(), params);\n        }\n        //See if restore was successful by checking if all the docs are present again\n        BackupRestoreUtils.verifyDocs(nDocs, masterClient, coreName);\n\n        // Verify the permissions for the backup folder.\n        FileStatus status = fs.getFileStatus(new org.apache.hadoop.fs.Path(\"/backup/snapshot.\"+backupName));\n        FsPermission perm = status.getPermission();\n        assertEquals(FsAction.ALL, perm.getUserAction());\n        assertEquals(FsAction.ALL, perm.getGroupAction());\n        assertEquals(FsAction.ALL, perm.getOtherAction());\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"65a5d87a40f9143cd55be76eb1dde1b32a8dae5e","date":1596664368,"type":3,"author":"Marcus","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/handler/TestHdfsBackupRestoreCore#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/handler/TestHdfsBackupRestoreCore#test().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n    CloudSolrClient solrClient = cluster.getSolrClient();\n    String collectionName = \"HdfsBackupRestore\";\n    CollectionAdminRequest.Create create =\n        CollectionAdminRequest.createCollection(collectionName, \"conf1\", 1, 1);\n    create.process(solrClient);\n\n    int nDocs = BackupRestoreUtils.indexDocs(solrClient, collectionName, docsSeed);\n\n    DocCollection collectionState = solrClient.getZkStateReader().getClusterState().getCollection(collectionName);\n    assertEquals(1, collectionState.getActiveSlices().size());\n    Slice shard = collectionState.getActiveSlices().iterator().next();\n    assertEquals(1, shard.getReplicas().size());\n    Replica replica = shard.getReplicas().iterator().next();\n\n    String replicaBaseUrl = replica.getStr(BASE_URL_PROP);\n    String coreName = replica.getStr(ZkStateReader.CORE_NAME_PROP);\n    String backupName = TestUtil.randomSimpleString(random(), 1, 5);\n\n    boolean testViaReplicationHandler = random().nextBoolean();\n    String baseUrl = cluster.getJettySolrRunners().get(0).getBaseUrl().toString();\n\n    try (HttpSolrClient leaderClient = getHttpSolrClient(replicaBaseUrl)) {\n      // Create a backup.\n      if (testViaReplicationHandler) {\n        log.info(\"Running Backup via replication handler\");\n        BackupRestoreUtils.runReplicationHandlerCommand(baseUrl, coreName, ReplicationHandler.CMD_BACKUP, \"hdfs\", backupName);\n        final BackupStatusChecker backupStatus\n          = new BackupStatusChecker(leaderClient, \"/\" + coreName + \"/replication\");\n        backupStatus.waitForBackupSuccess(backupName, 30);\n      } else {\n        log.info(\"Running Backup via core admin api\");\n        Map<String,String> params = new HashMap<>();\n        params.put(\"name\", backupName);\n        params.put(CoreAdminParams.BACKUP_REPOSITORY, \"hdfs\");\n        BackupRestoreUtils.runCoreAdminCommand(replicaBaseUrl, coreName, CoreAdminAction.BACKUPCORE.toString(), params);\n      }\n\n      int numRestoreTests = nDocs > 0 ? TestUtil.nextInt(random(), 1, 5) : 1;\n      for (int attempts=0; attempts<numRestoreTests; attempts++) {\n        //Modify existing index before we call restore.\n        if (nDocs > 0) {\n          //Delete a few docs\n          int numDeletes = TestUtil.nextInt(random(), 1, nDocs);\n          for(int i=0; i<numDeletes; i++) {\n            leaderClient.deleteByQuery(collectionName, \"id:\" + i);\n          }\n          leaderClient.commit(collectionName);\n\n          //Add a few more\n          int moreAdds = TestUtil.nextInt(random(), 1, 100);\n          for (int i=0; i<moreAdds; i++) {\n            SolrInputDocument doc = new SolrInputDocument();\n            doc.addField(\"id\", i + nDocs);\n            doc.addField(\"name\", \"name = \" + (i + nDocs));\n            leaderClient.add(collectionName, doc);\n          }\n          //Purposely not calling commit once in a while. There can be some docs which are not committed\n          if (usually()) {\n            leaderClient.commit(collectionName);\n          }\n        }\n        // Snapshooter prefixes \"snapshot.\" to the backup name.\n        if (testViaReplicationHandler) {\n          log.info(\"Running Restore via replication handler\");\n          // Snapshooter prefixes \"snapshot.\" to the backup name.\n          BackupRestoreUtils.runReplicationHandlerCommand(baseUrl, coreName, ReplicationHandler.CMD_RESTORE, \"hdfs\", backupName);\n          while (!TestRestoreCore.fetchRestoreStatus(baseUrl, coreName)) {\n            Thread.sleep(1000);\n          }\n        } else {\n          log.info(\"Running Restore via core admin api\");\n          Map<String,String> params = new HashMap<>();\n          params.put(\"name\", \"snapshot.\" + backupName);\n          params.put(CoreAdminParams.BACKUP_REPOSITORY, \"hdfs\");\n          BackupRestoreUtils.runCoreAdminCommand(replicaBaseUrl, coreName, CoreAdminAction.RESTORECORE.toString(), params);\n        }\n        //See if restore was successful by checking if all the docs are present again\n        BackupRestoreUtils.verifyDocs(nDocs, leaderClient, coreName);\n\n        // Verify the permissions for the backup folder.\n        FileStatus status = fs.getFileStatus(new org.apache.hadoop.fs.Path(\"/backup/snapshot.\"+backupName));\n        FsPermission perm = status.getPermission();\n        assertEquals(FsAction.ALL, perm.getUserAction());\n        assertEquals(FsAction.ALL, perm.getGroupAction());\n        assertEquals(FsAction.ALL, perm.getOtherAction());\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n    CloudSolrClient solrClient = cluster.getSolrClient();\n    String collectionName = \"HdfsBackupRestore\";\n    CollectionAdminRequest.Create create =\n        CollectionAdminRequest.createCollection(collectionName, \"conf1\", 1, 1);\n    create.process(solrClient);\n\n    int nDocs = BackupRestoreUtils.indexDocs(solrClient, collectionName, docsSeed);\n\n    DocCollection collectionState = solrClient.getZkStateReader().getClusterState().getCollection(collectionName);\n    assertEquals(1, collectionState.getActiveSlices().size());\n    Slice shard = collectionState.getActiveSlices().iterator().next();\n    assertEquals(1, shard.getReplicas().size());\n    Replica replica = shard.getReplicas().iterator().next();\n\n    String replicaBaseUrl = replica.getStr(BASE_URL_PROP);\n    String coreName = replica.getStr(ZkStateReader.CORE_NAME_PROP);\n    String backupName = TestUtil.randomSimpleString(random(), 1, 5);\n\n    boolean testViaReplicationHandler = random().nextBoolean();\n    String baseUrl = cluster.getJettySolrRunners().get(0).getBaseUrl().toString();\n\n    try (HttpSolrClient masterClient = getHttpSolrClient(replicaBaseUrl)) {\n      // Create a backup.\n      if (testViaReplicationHandler) {\n        log.info(\"Running Backup via replication handler\");\n        BackupRestoreUtils.runReplicationHandlerCommand(baseUrl, coreName, ReplicationHandler.CMD_BACKUP, \"hdfs\", backupName);\n        final BackupStatusChecker backupStatus\n          = new BackupStatusChecker(masterClient, \"/\" + coreName + \"/replication\");\n        backupStatus.waitForBackupSuccess(backupName, 30);\n      } else {\n        log.info(\"Running Backup via core admin api\");\n        Map<String,String> params = new HashMap<>();\n        params.put(\"name\", backupName);\n        params.put(CoreAdminParams.BACKUP_REPOSITORY, \"hdfs\");\n        BackupRestoreUtils.runCoreAdminCommand(replicaBaseUrl, coreName, CoreAdminAction.BACKUPCORE.toString(), params);\n      }\n\n      int numRestoreTests = nDocs > 0 ? TestUtil.nextInt(random(), 1, 5) : 1;\n      for (int attempts=0; attempts<numRestoreTests; attempts++) {\n        //Modify existing index before we call restore.\n        if (nDocs > 0) {\n          //Delete a few docs\n          int numDeletes = TestUtil.nextInt(random(), 1, nDocs);\n          for(int i=0; i<numDeletes; i++) {\n            masterClient.deleteByQuery(collectionName, \"id:\" + i);\n          }\n          masterClient.commit(collectionName);\n\n          //Add a few more\n          int moreAdds = TestUtil.nextInt(random(), 1, 100);\n          for (int i=0; i<moreAdds; i++) {\n            SolrInputDocument doc = new SolrInputDocument();\n            doc.addField(\"id\", i + nDocs);\n            doc.addField(\"name\", \"name = \" + (i + nDocs));\n            masterClient.add(collectionName, doc);\n          }\n          //Purposely not calling commit once in a while. There can be some docs which are not committed\n          if (usually()) {\n            masterClient.commit(collectionName);\n          }\n        }\n        // Snapshooter prefixes \"snapshot.\" to the backup name.\n        if (testViaReplicationHandler) {\n          log.info(\"Running Restore via replication handler\");\n          // Snapshooter prefixes \"snapshot.\" to the backup name.\n          BackupRestoreUtils.runReplicationHandlerCommand(baseUrl, coreName, ReplicationHandler.CMD_RESTORE, \"hdfs\", backupName);\n          while (!TestRestoreCore.fetchRestoreStatus(baseUrl, coreName)) {\n            Thread.sleep(1000);\n          }\n        } else {\n          log.info(\"Running Restore via core admin api\");\n          Map<String,String> params = new HashMap<>();\n          params.put(\"name\", \"snapshot.\" + backupName);\n          params.put(CoreAdminParams.BACKUP_REPOSITORY, \"hdfs\");\n          BackupRestoreUtils.runCoreAdminCommand(replicaBaseUrl, coreName, CoreAdminAction.RESTORECORE.toString(), params);\n        }\n        //See if restore was successful by checking if all the docs are present again\n        BackupRestoreUtils.verifyDocs(nDocs, masterClient, coreName);\n\n        // Verify the permissions for the backup folder.\n        FileStatus status = fs.getFileStatus(new org.apache.hadoop.fs.Path(\"/backup/snapshot.\"+backupName));\n        FsPermission perm = status.getPermission();\n        assertEquals(FsAction.ALL, perm.getUserAction());\n        assertEquals(FsAction.ALL, perm.getGroupAction());\n        assertEquals(FsAction.ALL, perm.getOtherAction());\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"60b61628d1912768f51eccaa8ead5a5a32ab34c6":["91e2345fb81b6c1c7faefa550ee5eaafadc54486","f5b22bbf58be28e93a9545e12da1c0506e3e59fd"],"65a5d87a40f9143cd55be76eb1dde1b32a8dae5e":["ec54bd926c45854b5a1599685b0f7d2bfbfe177f"],"f5b22bbf58be28e93a9545e12da1c0506e3e59fd":["91e2345fb81b6c1c7faefa550ee5eaafadc54486"],"ec54bd926c45854b5a1599685b0f7d2bfbfe177f":["add53de9835b2cd1a7a80b4e0036afee171c9fdf"],"a51ab9b1f1b896f06b7ba61672f0fca2a4fce43b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"80d0e6d59ae23f4a6f30eaf40bfb40742300287f":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","60b61628d1912768f51eccaa8ead5a5a32ab34c6"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","91e2345fb81b6c1c7faefa550ee5eaafadc54486"],"3b013574eedcdbac35dc7e35b0ee616ffc38895d":["a51ab9b1f1b896f06b7ba61672f0fca2a4fce43b","91e2345fb81b6c1c7faefa550ee5eaafadc54486"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["65a5d87a40f9143cd55be76eb1dde1b32a8dae5e"],"add53de9835b2cd1a7a80b4e0036afee171c9fdf":["60b61628d1912768f51eccaa8ead5a5a32ab34c6"],"91e2345fb81b6c1c7faefa550ee5eaafadc54486":["a51ab9b1f1b896f06b7ba61672f0fca2a4fce43b"]},"commit2Childs":{"60b61628d1912768f51eccaa8ead5a5a32ab34c6":["80d0e6d59ae23f4a6f30eaf40bfb40742300287f","add53de9835b2cd1a7a80b4e0036afee171c9fdf"],"65a5d87a40f9143cd55be76eb1dde1b32a8dae5e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"f5b22bbf58be28e93a9545e12da1c0506e3e59fd":["60b61628d1912768f51eccaa8ead5a5a32ab34c6"],"ec54bd926c45854b5a1599685b0f7d2bfbfe177f":["65a5d87a40f9143cd55be76eb1dde1b32a8dae5e"],"a51ab9b1f1b896f06b7ba61672f0fca2a4fce43b":["3b013574eedcdbac35dc7e35b0ee616ffc38895d","91e2345fb81b6c1c7faefa550ee5eaafadc54486"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["a51ab9b1f1b896f06b7ba61672f0fca2a4fce43b","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"80d0e6d59ae23f4a6f30eaf40bfb40742300287f":[],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["80d0e6d59ae23f4a6f30eaf40bfb40742300287f"],"3b013574eedcdbac35dc7e35b0ee616ffc38895d":[],"91e2345fb81b6c1c7faefa550ee5eaafadc54486":["60b61628d1912768f51eccaa8ead5a5a32ab34c6","f5b22bbf58be28e93a9545e12da1c0506e3e59fd","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","3b013574eedcdbac35dc7e35b0ee616ffc38895d"],"add53de9835b2cd1a7a80b4e0036afee171c9fdf":["ec54bd926c45854b5a1599685b0f7d2bfbfe177f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["80d0e6d59ae23f4a6f30eaf40bfb40742300287f","3b013574eedcdbac35dc7e35b0ee616ffc38895d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}