{"path":"lucene/contrib/queryparser/src/java/org/apache/lucene/queryParser/analyzing/AnalyzingQueryParser#getWildcardQuery(String,String).mjava","commits":[{"id":"36f91bf9cfc9d0c3155edab43359e7670ea8a5af","date":1269580873,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/queryparser/src/java/org/apache/lucene/queryParser/analyzing/AnalyzingQueryParser#getWildcardQuery(String,String).mjava","pathOld":"lucene/contrib/misc/src/java/org/apache/lucene/queryParser/analyzing/AnalyzingQueryParser#getWildcardQuery(String,String).mjava","sourceNew":"  /**\n   * Called when parser\n   * parses an input term token that contains one or more wildcard\n   * characters (like <code>*</code>), but is not a prefix term token (one\n   * that has just a single * character at the end).\n   * <p>\n   * Example: will be called for <code>H?user</code> or for <code>H*user</code> \n   * but not for <code>*user</code>.\n   * <p>\n   * Depending on analyzer and settings, a wildcard term may (most probably will)\n   * be lower-cased automatically. It <b>will</b> go through the default Analyzer.\n   * <p>\n   * Overrides super class, by passing terms through analyzer.\n   *\n   * @param  field   Name of the field query will use.\n   * @param  termStr Term token that contains one or more wild card\n   *                 characters (? or *), but is not simple prefix term\n   *\n   * @return Resulting {@link Query} built for the term\n   * @throws ParseException\n   */\n  @Override\n  protected Query getWildcardQuery(String field, String termStr) throws ParseException {\n    List<String> tlist = new ArrayList<String>();\n    List<String> wlist = new ArrayList<String>();\n    /* somewhat a hack: find/store wildcard chars\n     * in order to put them back after analyzing */\n    boolean isWithinToken = (!termStr.startsWith(\"?\") && !termStr.startsWith(\"*\"));\n    StringBuilder tmpBuffer = new StringBuilder();\n    char[] chars = termStr.toCharArray();\n    for (int i = 0; i < termStr.length(); i++) {\n      if (chars[i] == '?' || chars[i] == '*') {\n        if (isWithinToken) {\n          tlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = false;\n      } else {\n        if (!isWithinToken) {\n          wlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = true;\n      }\n      tmpBuffer.append(chars[i]);\n    }\n    if (isWithinToken) {\n      tlist.add(tmpBuffer.toString());\n    } else {\n      wlist.add(tmpBuffer.toString());\n    }\n\n    // get Analyzer from superclass and tokenize the term\n    TokenStream source = getAnalyzer().tokenStream(field, new StringReader(termStr));\n    TermAttribute termAtt = source.addAttribute(TermAttribute.class);\n    \n    int countTokens = 0;\n    while (true) {\n      try {\n        if (!source.incrementToken()) break;\n      } catch (IOException e) {\n        break;\n      }\n      String term = termAtt.term();\n      if (!\"\".equals(term)) {\n        try {\n          tlist.set(countTokens++, term);\n        } catch (IndexOutOfBoundsException ioobe) {\n          countTokens = -1;\n        }\n      }\n    }\n    try {\n      source.close();\n    } catch (IOException e) {\n      // ignore\n    }\n\n    if (countTokens != tlist.size()) {\n      /* this means that the analyzer used either added or consumed \n       * (common for a stemmer) tokens, and we can't build a WildcardQuery */\n      throw new ParseException(\"Cannot build WildcardQuery with analyzer \"\n          + getAnalyzer().getClass() + \" - tokens added or lost\");\n    }\n\n    if (tlist.size() == 0) {\n      return null;\n    } else if (tlist.size() == 1) {\n      if (wlist != null && wlist.size() == 1) {\n        /* if wlist contains one wildcard, it must be at the end, because:\n         * 1) wildcards are not allowed in 1st position of a term by QueryParser\n         * 2) if wildcard was *not* in end, there would be *two* or more tokens */\n        return super.getWildcardQuery(field, tlist.get(0)\n            + wlist.get(0).toString());\n      } else {\n        /* we should never get here! if so, this method was called\n         * with a termStr containing no wildcard ... */\n        throw new IllegalArgumentException(\"getWildcardQuery called without wildcard\");\n      }\n    } else {\n      /* the term was tokenized, let's rebuild to one token\n       * with wildcards put back in postion */\n      StringBuilder sb = new StringBuilder();\n      for (int i = 0; i < tlist.size(); i++) {\n        sb.append( tlist.get(i));\n        if (wlist != null && wlist.size() > i) {\n          sb.append(wlist.get(i));\n        }\n      }\n      return super.getWildcardQuery(field, sb.toString());\n    }\n  }\n\n","sourceOld":"  /**\n   * Called when parser\n   * parses an input term token that contains one or more wildcard\n   * characters (like <code>*</code>), but is not a prefix term token (one\n   * that has just a single * character at the end).\n   * <p>\n   * Example: will be called for <code>H?user</code> or for <code>H*user</code> \n   * but not for <code>*user</code>.\n   * <p>\n   * Depending on analyzer and settings, a wildcard term may (most probably will)\n   * be lower-cased automatically. It <b>will</b> go through the default Analyzer.\n   * <p>\n   * Overrides super class, by passing terms through analyzer.\n   *\n   * @param  field   Name of the field query will use.\n   * @param  termStr Term token that contains one or more wild card\n   *                 characters (? or *), but is not simple prefix term\n   *\n   * @return Resulting {@link Query} built for the term\n   * @throws ParseException\n   */\n  @Override\n  protected Query getWildcardQuery(String field, String termStr) throws ParseException {\n    List<String> tlist = new ArrayList<String>();\n    List<String> wlist = new ArrayList<String>();\n    /* somewhat a hack: find/store wildcard chars\n     * in order to put them back after analyzing */\n    boolean isWithinToken = (!termStr.startsWith(\"?\") && !termStr.startsWith(\"*\"));\n    StringBuilder tmpBuffer = new StringBuilder();\n    char[] chars = termStr.toCharArray();\n    for (int i = 0; i < termStr.length(); i++) {\n      if (chars[i] == '?' || chars[i] == '*') {\n        if (isWithinToken) {\n          tlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = false;\n      } else {\n        if (!isWithinToken) {\n          wlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = true;\n      }\n      tmpBuffer.append(chars[i]);\n    }\n    if (isWithinToken) {\n      tlist.add(tmpBuffer.toString());\n    } else {\n      wlist.add(tmpBuffer.toString());\n    }\n\n    // get Analyzer from superclass and tokenize the term\n    TokenStream source = getAnalyzer().tokenStream(field, new StringReader(termStr));\n    TermAttribute termAtt = source.addAttribute(TermAttribute.class);\n    \n    int countTokens = 0;\n    while (true) {\n      try {\n        if (!source.incrementToken()) break;\n      } catch (IOException e) {\n        break;\n      }\n      String term = termAtt.term();\n      if (!\"\".equals(term)) {\n        try {\n          tlist.set(countTokens++, term);\n        } catch (IndexOutOfBoundsException ioobe) {\n          countTokens = -1;\n        }\n      }\n    }\n    try {\n      source.close();\n    } catch (IOException e) {\n      // ignore\n    }\n\n    if (countTokens != tlist.size()) {\n      /* this means that the analyzer used either added or consumed \n       * (common for a stemmer) tokens, and we can't build a WildcardQuery */\n      throw new ParseException(\"Cannot build WildcardQuery with analyzer \"\n          + getAnalyzer().getClass() + \" - tokens added or lost\");\n    }\n\n    if (tlist.size() == 0) {\n      return null;\n    } else if (tlist.size() == 1) {\n      if (wlist != null && wlist.size() == 1) {\n        /* if wlist contains one wildcard, it must be at the end, because:\n         * 1) wildcards are not allowed in 1st position of a term by QueryParser\n         * 2) if wildcard was *not* in end, there would be *two* or more tokens */\n        return super.getWildcardQuery(field, tlist.get(0)\n            + wlist.get(0).toString());\n      } else {\n        /* we should never get here! if so, this method was called\n         * with a termStr containing no wildcard ... */\n        throw new IllegalArgumentException(\"getWildcardQuery called without wildcard\");\n      }\n    } else {\n      /* the term was tokenized, let's rebuild to one token\n       * with wildcards put back in postion */\n      StringBuilder sb = new StringBuilder();\n      for (int i = 0; i < tlist.size(); i++) {\n        sb.append( tlist.get(i));\n        if (wlist != null && wlist.size() > i) {\n          sb.append(wlist.get(i));\n        }\n      }\n      return super.getWildcardQuery(field, sb.toString());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a7347509fad0711ac30cb15a746e9a3830a38ebd","date":1275388513,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/queryparser/src/java/org/apache/lucene/queryParser/analyzing/AnalyzingQueryParser#getWildcardQuery(String,String).mjava","pathOld":"lucene/contrib/queryparser/src/java/org/apache/lucene/queryParser/analyzing/AnalyzingQueryParser#getWildcardQuery(String,String).mjava","sourceNew":"  /**\n   * Called when parser\n   * parses an input term token that contains one or more wildcard\n   * characters (like <code>*</code>), but is not a prefix term token (one\n   * that has just a single * character at the end).\n   * <p>\n   * Example: will be called for <code>H?user</code> or for <code>H*user</code> \n   * but not for <code>*user</code>.\n   * <p>\n   * Depending on analyzer and settings, a wildcard term may (most probably will)\n   * be lower-cased automatically. It <b>will</b> go through the default Analyzer.\n   * <p>\n   * Overrides super class, by passing terms through analyzer.\n   *\n   * @param  field   Name of the field query will use.\n   * @param  termStr Term token that contains one or more wild card\n   *                 characters (? or *), but is not simple prefix term\n   *\n   * @return Resulting {@link Query} built for the term\n   * @throws ParseException\n   */\n  @Override\n  protected Query getWildcardQuery(String field, String termStr) throws ParseException {\n    List<String> tlist = new ArrayList<String>();\n    List<String> wlist = new ArrayList<String>();\n    /* somewhat a hack: find/store wildcard chars\n     * in order to put them back after analyzing */\n    boolean isWithinToken = (!termStr.startsWith(\"?\") && !termStr.startsWith(\"*\"));\n    StringBuilder tmpBuffer = new StringBuilder();\n    char[] chars = termStr.toCharArray();\n    for (int i = 0; i < termStr.length(); i++) {\n      if (chars[i] == '?' || chars[i] == '*') {\n        if (isWithinToken) {\n          tlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = false;\n      } else {\n        if (!isWithinToken) {\n          wlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = true;\n      }\n      tmpBuffer.append(chars[i]);\n    }\n    if (isWithinToken) {\n      tlist.add(tmpBuffer.toString());\n    } else {\n      wlist.add(tmpBuffer.toString());\n    }\n\n    // get Analyzer from superclass and tokenize the term\n    TokenStream source = getAnalyzer().tokenStream(field, new StringReader(termStr));\n    CharTermAttribute termAtt = source.addAttribute(CharTermAttribute.class);\n    \n    int countTokens = 0;\n    while (true) {\n      try {\n        if (!source.incrementToken()) break;\n      } catch (IOException e) {\n        break;\n      }\n      String term = termAtt.toString();\n      if (!\"\".equals(term)) {\n        try {\n          tlist.set(countTokens++, term);\n        } catch (IndexOutOfBoundsException ioobe) {\n          countTokens = -1;\n        }\n      }\n    }\n    try {\n      source.close();\n    } catch (IOException e) {\n      // ignore\n    }\n\n    if (countTokens != tlist.size()) {\n      /* this means that the analyzer used either added or consumed \n       * (common for a stemmer) tokens, and we can't build a WildcardQuery */\n      throw new ParseException(\"Cannot build WildcardQuery with analyzer \"\n          + getAnalyzer().getClass() + \" - tokens added or lost\");\n    }\n\n    if (tlist.size() == 0) {\n      return null;\n    } else if (tlist.size() == 1) {\n      if (wlist != null && wlist.size() == 1) {\n        /* if wlist contains one wildcard, it must be at the end, because:\n         * 1) wildcards are not allowed in 1st position of a term by QueryParser\n         * 2) if wildcard was *not* in end, there would be *two* or more tokens */\n        return super.getWildcardQuery(field, tlist.get(0)\n            + wlist.get(0).toString());\n      } else {\n        /* we should never get here! if so, this method was called\n         * with a termStr containing no wildcard ... */\n        throw new IllegalArgumentException(\"getWildcardQuery called without wildcard\");\n      }\n    } else {\n      /* the term was tokenized, let's rebuild to one token\n       * with wildcards put back in postion */\n      StringBuilder sb = new StringBuilder();\n      for (int i = 0; i < tlist.size(); i++) {\n        sb.append( tlist.get(i));\n        if (wlist != null && wlist.size() > i) {\n          sb.append(wlist.get(i));\n        }\n      }\n      return super.getWildcardQuery(field, sb.toString());\n    }\n  }\n\n","sourceOld":"  /**\n   * Called when parser\n   * parses an input term token that contains one or more wildcard\n   * characters (like <code>*</code>), but is not a prefix term token (one\n   * that has just a single * character at the end).\n   * <p>\n   * Example: will be called for <code>H?user</code> or for <code>H*user</code> \n   * but not for <code>*user</code>.\n   * <p>\n   * Depending on analyzer and settings, a wildcard term may (most probably will)\n   * be lower-cased automatically. It <b>will</b> go through the default Analyzer.\n   * <p>\n   * Overrides super class, by passing terms through analyzer.\n   *\n   * @param  field   Name of the field query will use.\n   * @param  termStr Term token that contains one or more wild card\n   *                 characters (? or *), but is not simple prefix term\n   *\n   * @return Resulting {@link Query} built for the term\n   * @throws ParseException\n   */\n  @Override\n  protected Query getWildcardQuery(String field, String termStr) throws ParseException {\n    List<String> tlist = new ArrayList<String>();\n    List<String> wlist = new ArrayList<String>();\n    /* somewhat a hack: find/store wildcard chars\n     * in order to put them back after analyzing */\n    boolean isWithinToken = (!termStr.startsWith(\"?\") && !termStr.startsWith(\"*\"));\n    StringBuilder tmpBuffer = new StringBuilder();\n    char[] chars = termStr.toCharArray();\n    for (int i = 0; i < termStr.length(); i++) {\n      if (chars[i] == '?' || chars[i] == '*') {\n        if (isWithinToken) {\n          tlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = false;\n      } else {\n        if (!isWithinToken) {\n          wlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = true;\n      }\n      tmpBuffer.append(chars[i]);\n    }\n    if (isWithinToken) {\n      tlist.add(tmpBuffer.toString());\n    } else {\n      wlist.add(tmpBuffer.toString());\n    }\n\n    // get Analyzer from superclass and tokenize the term\n    TokenStream source = getAnalyzer().tokenStream(field, new StringReader(termStr));\n    TermAttribute termAtt = source.addAttribute(TermAttribute.class);\n    \n    int countTokens = 0;\n    while (true) {\n      try {\n        if (!source.incrementToken()) break;\n      } catch (IOException e) {\n        break;\n      }\n      String term = termAtt.term();\n      if (!\"\".equals(term)) {\n        try {\n          tlist.set(countTokens++, term);\n        } catch (IndexOutOfBoundsException ioobe) {\n          countTokens = -1;\n        }\n      }\n    }\n    try {\n      source.close();\n    } catch (IOException e) {\n      // ignore\n    }\n\n    if (countTokens != tlist.size()) {\n      /* this means that the analyzer used either added or consumed \n       * (common for a stemmer) tokens, and we can't build a WildcardQuery */\n      throw new ParseException(\"Cannot build WildcardQuery with analyzer \"\n          + getAnalyzer().getClass() + \" - tokens added or lost\");\n    }\n\n    if (tlist.size() == 0) {\n      return null;\n    } else if (tlist.size() == 1) {\n      if (wlist != null && wlist.size() == 1) {\n        /* if wlist contains one wildcard, it must be at the end, because:\n         * 1) wildcards are not allowed in 1st position of a term by QueryParser\n         * 2) if wildcard was *not* in end, there would be *two* or more tokens */\n        return super.getWildcardQuery(field, tlist.get(0)\n            + wlist.get(0).toString());\n      } else {\n        /* we should never get here! if so, this method was called\n         * with a termStr containing no wildcard ... */\n        throw new IllegalArgumentException(\"getWildcardQuery called without wildcard\");\n      }\n    } else {\n      /* the term was tokenized, let's rebuild to one token\n       * with wildcards put back in postion */\n      StringBuilder sb = new StringBuilder();\n      for (int i = 0; i < tlist.size(); i++) {\n        sb.append( tlist.get(i));\n        if (wlist != null && wlist.size() > i) {\n          sb.append(wlist.get(i));\n        }\n      }\n      return super.getWildcardQuery(field, sb.toString());\n    }\n  }\n\n","bugFix":null,"bugIntro":["046829b17e246624c179b94d5a20cb53fa945e87"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e2efdd13c0f37dbe4a292a6f98ddcf8e8f872ac4","date":1305207152,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/queryparser/src/java/org/apache/lucene/queryParser/analyzing/AnalyzingQueryParser#getWildcardQuery(String,String).mjava","pathOld":"lucene/contrib/queryparser/src/java/org/apache/lucene/queryParser/analyzing/AnalyzingQueryParser#getWildcardQuery(String,String).mjava","sourceNew":"  /**\n   * Called when parser\n   * parses an input term token that contains one or more wildcard\n   * characters (like <code>*</code>), but is not a prefix term token (one\n   * that has just a single * character at the end).\n   * <p>\n   * Example: will be called for <code>H?user</code> or for <code>H*user</code> \n   * but not for <code>*user</code>.\n   * <p>\n   * Depending on analyzer and settings, a wildcard term may (most probably will)\n   * be lower-cased automatically. It <b>will</b> go through the default Analyzer.\n   * <p>\n   * Overrides super class, by passing terms through analyzer.\n   *\n   * @param  field   Name of the field query will use.\n   * @param  termStr Term token that contains one or more wild card\n   *                 characters (? or *), but is not simple prefix term\n   *\n   * @return Resulting {@link Query} built for the term\n   * @throws ParseException\n   */\n  @Override\n  protected Query getWildcardQuery(String field, String termStr) throws ParseException {\n    List<String> tlist = new ArrayList<String>();\n    List<String> wlist = new ArrayList<String>();\n    /* somewhat a hack: find/store wildcard chars\n     * in order to put them back after analyzing */\n    boolean isWithinToken = (!termStr.startsWith(\"?\") && !termStr.startsWith(\"*\"));\n    StringBuilder tmpBuffer = new StringBuilder();\n    char[] chars = termStr.toCharArray();\n    for (int i = 0; i < termStr.length(); i++) {\n      if (chars[i] == '?' || chars[i] == '*') {\n        if (isWithinToken) {\n          tlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = false;\n      } else {\n        if (!isWithinToken) {\n          wlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = true;\n      }\n      tmpBuffer.append(chars[i]);\n    }\n    if (isWithinToken) {\n      tlist.add(tmpBuffer.toString());\n    } else {\n      wlist.add(tmpBuffer.toString());\n    }\n\n    // get Analyzer from superclass and tokenize the term\n    TokenStream source = getAnalyzer().tokenStream(field, new StringReader(termStr));\n    CharTermAttribute termAtt = source.addAttribute(CharTermAttribute.class);\n    \n    int countTokens = 0;\n    try {\n      source.reset();\n    } catch (IOException e1) {\n      throw new RuntimeException(e1);\n    }\n    while (true) {\n      try {\n        if (!source.incrementToken()) break;\n      } catch (IOException e) {\n        break;\n      }\n      String term = termAtt.toString();\n      if (!\"\".equals(term)) {\n        try {\n          tlist.set(countTokens++, term);\n        } catch (IndexOutOfBoundsException ioobe) {\n          countTokens = -1;\n        }\n      }\n    }\n    try {\n      source.end();\n      source.close();\n    } catch (IOException e) {\n      // ignore\n    }\n\n    if (countTokens != tlist.size()) {\n      /* this means that the analyzer used either added or consumed \n       * (common for a stemmer) tokens, and we can't build a WildcardQuery */\n      throw new ParseException(\"Cannot build WildcardQuery with analyzer \"\n          + getAnalyzer().getClass() + \" - tokens added or lost\");\n    }\n\n    if (tlist.size() == 0) {\n      return null;\n    } else if (tlist.size() == 1) {\n      if (wlist != null && wlist.size() == 1) {\n        /* if wlist contains one wildcard, it must be at the end, because:\n         * 1) wildcards are not allowed in 1st position of a term by QueryParser\n         * 2) if wildcard was *not* in end, there would be *two* or more tokens */\n        return super.getWildcardQuery(field, tlist.get(0)\n            + wlist.get(0).toString());\n      } else {\n        /* we should never get here! if so, this method was called\n         * with a termStr containing no wildcard ... */\n        throw new IllegalArgumentException(\"getWildcardQuery called without wildcard\");\n      }\n    } else {\n      /* the term was tokenized, let's rebuild to one token\n       * with wildcards put back in postion */\n      StringBuilder sb = new StringBuilder();\n      for (int i = 0; i < tlist.size(); i++) {\n        sb.append( tlist.get(i));\n        if (wlist != null && wlist.size() > i) {\n          sb.append(wlist.get(i));\n        }\n      }\n      return super.getWildcardQuery(field, sb.toString());\n    }\n  }\n\n","sourceOld":"  /**\n   * Called when parser\n   * parses an input term token that contains one or more wildcard\n   * characters (like <code>*</code>), but is not a prefix term token (one\n   * that has just a single * character at the end).\n   * <p>\n   * Example: will be called for <code>H?user</code> or for <code>H*user</code> \n   * but not for <code>*user</code>.\n   * <p>\n   * Depending on analyzer and settings, a wildcard term may (most probably will)\n   * be lower-cased automatically. It <b>will</b> go through the default Analyzer.\n   * <p>\n   * Overrides super class, by passing terms through analyzer.\n   *\n   * @param  field   Name of the field query will use.\n   * @param  termStr Term token that contains one or more wild card\n   *                 characters (? or *), but is not simple prefix term\n   *\n   * @return Resulting {@link Query} built for the term\n   * @throws ParseException\n   */\n  @Override\n  protected Query getWildcardQuery(String field, String termStr) throws ParseException {\n    List<String> tlist = new ArrayList<String>();\n    List<String> wlist = new ArrayList<String>();\n    /* somewhat a hack: find/store wildcard chars\n     * in order to put them back after analyzing */\n    boolean isWithinToken = (!termStr.startsWith(\"?\") && !termStr.startsWith(\"*\"));\n    StringBuilder tmpBuffer = new StringBuilder();\n    char[] chars = termStr.toCharArray();\n    for (int i = 0; i < termStr.length(); i++) {\n      if (chars[i] == '?' || chars[i] == '*') {\n        if (isWithinToken) {\n          tlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = false;\n      } else {\n        if (!isWithinToken) {\n          wlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = true;\n      }\n      tmpBuffer.append(chars[i]);\n    }\n    if (isWithinToken) {\n      tlist.add(tmpBuffer.toString());\n    } else {\n      wlist.add(tmpBuffer.toString());\n    }\n\n    // get Analyzer from superclass and tokenize the term\n    TokenStream source = getAnalyzer().tokenStream(field, new StringReader(termStr));\n    CharTermAttribute termAtt = source.addAttribute(CharTermAttribute.class);\n    \n    int countTokens = 0;\n    while (true) {\n      try {\n        if (!source.incrementToken()) break;\n      } catch (IOException e) {\n        break;\n      }\n      String term = termAtt.toString();\n      if (!\"\".equals(term)) {\n        try {\n          tlist.set(countTokens++, term);\n        } catch (IndexOutOfBoundsException ioobe) {\n          countTokens = -1;\n        }\n      }\n    }\n    try {\n      source.close();\n    } catch (IOException e) {\n      // ignore\n    }\n\n    if (countTokens != tlist.size()) {\n      /* this means that the analyzer used either added or consumed \n       * (common for a stemmer) tokens, and we can't build a WildcardQuery */\n      throw new ParseException(\"Cannot build WildcardQuery with analyzer \"\n          + getAnalyzer().getClass() + \" - tokens added or lost\");\n    }\n\n    if (tlist.size() == 0) {\n      return null;\n    } else if (tlist.size() == 1) {\n      if (wlist != null && wlist.size() == 1) {\n        /* if wlist contains one wildcard, it must be at the end, because:\n         * 1) wildcards are not allowed in 1st position of a term by QueryParser\n         * 2) if wildcard was *not* in end, there would be *two* or more tokens */\n        return super.getWildcardQuery(field, tlist.get(0)\n            + wlist.get(0).toString());\n      } else {\n        /* we should never get here! if so, this method was called\n         * with a termStr containing no wildcard ... */\n        throw new IllegalArgumentException(\"getWildcardQuery called without wildcard\");\n      }\n    } else {\n      /* the term was tokenized, let's rebuild to one token\n       * with wildcards put back in postion */\n      StringBuilder sb = new StringBuilder();\n      for (int i = 0; i < tlist.size(); i++) {\n        sb.append( tlist.get(i));\n        if (wlist != null && wlist.size() > i) {\n          sb.append(wlist.get(i));\n        }\n      }\n      return super.getWildcardQuery(field, sb.toString());\n    }\n  }\n\n","bugFix":null,"bugIntro":["046829b17e246624c179b94d5a20cb53fa945e87"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c700f8d0842d3e52bb2bdfbfdc046a137e836edb","date":1305285499,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/contrib/queryparser/src/java/org/apache/lucene/queryParser/analyzing/AnalyzingQueryParser#getWildcardQuery(String,String).mjava","pathOld":"lucene/contrib/queryparser/src/java/org/apache/lucene/queryParser/analyzing/AnalyzingQueryParser#getWildcardQuery(String,String).mjava","sourceNew":"  /**\n   * Called when parser\n   * parses an input term token that contains one or more wildcard\n   * characters (like <code>*</code>), but is not a prefix term token (one\n   * that has just a single * character at the end).\n   * <p>\n   * Example: will be called for <code>H?user</code> or for <code>H*user</code> \n   * but not for <code>*user</code>.\n   * <p>\n   * Depending on analyzer and settings, a wildcard term may (most probably will)\n   * be lower-cased automatically. It <b>will</b> go through the default Analyzer.\n   * <p>\n   * Overrides super class, by passing terms through analyzer.\n   *\n   * @param  field   Name of the field query will use.\n   * @param  termStr Term token that contains one or more wild card\n   *                 characters (? or *), but is not simple prefix term\n   *\n   * @return Resulting {@link Query} built for the term\n   * @throws ParseException\n   */\n  @Override\n  protected Query getWildcardQuery(String field, String termStr) throws ParseException {\n    List<String> tlist = new ArrayList<String>();\n    List<String> wlist = new ArrayList<String>();\n    /* somewhat a hack: find/store wildcard chars\n     * in order to put them back after analyzing */\n    boolean isWithinToken = (!termStr.startsWith(\"?\") && !termStr.startsWith(\"*\"));\n    StringBuilder tmpBuffer = new StringBuilder();\n    char[] chars = termStr.toCharArray();\n    for (int i = 0; i < termStr.length(); i++) {\n      if (chars[i] == '?' || chars[i] == '*') {\n        if (isWithinToken) {\n          tlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = false;\n      } else {\n        if (!isWithinToken) {\n          wlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = true;\n      }\n      tmpBuffer.append(chars[i]);\n    }\n    if (isWithinToken) {\n      tlist.add(tmpBuffer.toString());\n    } else {\n      wlist.add(tmpBuffer.toString());\n    }\n\n    // get Analyzer from superclass and tokenize the term\n    TokenStream source = getAnalyzer().tokenStream(field, new StringReader(termStr));\n    CharTermAttribute termAtt = source.addAttribute(CharTermAttribute.class);\n    \n    int countTokens = 0;\n    try {\n      source.reset();\n    } catch (IOException e1) {\n      throw new RuntimeException(e1);\n    }\n    while (true) {\n      try {\n        if (!source.incrementToken()) break;\n      } catch (IOException e) {\n        break;\n      }\n      String term = termAtt.toString();\n      if (!\"\".equals(term)) {\n        try {\n          tlist.set(countTokens++, term);\n        } catch (IndexOutOfBoundsException ioobe) {\n          countTokens = -1;\n        }\n      }\n    }\n    try {\n      source.end();\n      source.close();\n    } catch (IOException e) {\n      // ignore\n    }\n\n    if (countTokens != tlist.size()) {\n      /* this means that the analyzer used either added or consumed \n       * (common for a stemmer) tokens, and we can't build a WildcardQuery */\n      throw new ParseException(\"Cannot build WildcardQuery with analyzer \"\n          + getAnalyzer().getClass() + \" - tokens added or lost\");\n    }\n\n    if (tlist.size() == 0) {\n      return null;\n    } else if (tlist.size() == 1) {\n      if (wlist != null && wlist.size() == 1) {\n        /* if wlist contains one wildcard, it must be at the end, because:\n         * 1) wildcards are not allowed in 1st position of a term by QueryParser\n         * 2) if wildcard was *not* in end, there would be *two* or more tokens */\n        return super.getWildcardQuery(field, tlist.get(0)\n            + wlist.get(0).toString());\n      } else {\n        /* we should never get here! if so, this method was called\n         * with a termStr containing no wildcard ... */\n        throw new IllegalArgumentException(\"getWildcardQuery called without wildcard\");\n      }\n    } else {\n      /* the term was tokenized, let's rebuild to one token\n       * with wildcards put back in postion */\n      StringBuilder sb = new StringBuilder();\n      for (int i = 0; i < tlist.size(); i++) {\n        sb.append( tlist.get(i));\n        if (wlist != null && wlist.size() > i) {\n          sb.append(wlist.get(i));\n        }\n      }\n      return super.getWildcardQuery(field, sb.toString());\n    }\n  }\n\n","sourceOld":"  /**\n   * Called when parser\n   * parses an input term token that contains one or more wildcard\n   * characters (like <code>*</code>), but is not a prefix term token (one\n   * that has just a single * character at the end).\n   * <p>\n   * Example: will be called for <code>H?user</code> or for <code>H*user</code> \n   * but not for <code>*user</code>.\n   * <p>\n   * Depending on analyzer and settings, a wildcard term may (most probably will)\n   * be lower-cased automatically. It <b>will</b> go through the default Analyzer.\n   * <p>\n   * Overrides super class, by passing terms through analyzer.\n   *\n   * @param  field   Name of the field query will use.\n   * @param  termStr Term token that contains one or more wild card\n   *                 characters (? or *), but is not simple prefix term\n   *\n   * @return Resulting {@link Query} built for the term\n   * @throws ParseException\n   */\n  @Override\n  protected Query getWildcardQuery(String field, String termStr) throws ParseException {\n    List<String> tlist = new ArrayList<String>();\n    List<String> wlist = new ArrayList<String>();\n    /* somewhat a hack: find/store wildcard chars\n     * in order to put them back after analyzing */\n    boolean isWithinToken = (!termStr.startsWith(\"?\") && !termStr.startsWith(\"*\"));\n    StringBuilder tmpBuffer = new StringBuilder();\n    char[] chars = termStr.toCharArray();\n    for (int i = 0; i < termStr.length(); i++) {\n      if (chars[i] == '?' || chars[i] == '*') {\n        if (isWithinToken) {\n          tlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = false;\n      } else {\n        if (!isWithinToken) {\n          wlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = true;\n      }\n      tmpBuffer.append(chars[i]);\n    }\n    if (isWithinToken) {\n      tlist.add(tmpBuffer.toString());\n    } else {\n      wlist.add(tmpBuffer.toString());\n    }\n\n    // get Analyzer from superclass and tokenize the term\n    TokenStream source = getAnalyzer().tokenStream(field, new StringReader(termStr));\n    CharTermAttribute termAtt = source.addAttribute(CharTermAttribute.class);\n    \n    int countTokens = 0;\n    while (true) {\n      try {\n        if (!source.incrementToken()) break;\n      } catch (IOException e) {\n        break;\n      }\n      String term = termAtt.toString();\n      if (!\"\".equals(term)) {\n        try {\n          tlist.set(countTokens++, term);\n        } catch (IndexOutOfBoundsException ioobe) {\n          countTokens = -1;\n        }\n      }\n    }\n    try {\n      source.close();\n    } catch (IOException e) {\n      // ignore\n    }\n\n    if (countTokens != tlist.size()) {\n      /* this means that the analyzer used either added or consumed \n       * (common for a stemmer) tokens, and we can't build a WildcardQuery */\n      throw new ParseException(\"Cannot build WildcardQuery with analyzer \"\n          + getAnalyzer().getClass() + \" - tokens added or lost\");\n    }\n\n    if (tlist.size() == 0) {\n      return null;\n    } else if (tlist.size() == 1) {\n      if (wlist != null && wlist.size() == 1) {\n        /* if wlist contains one wildcard, it must be at the end, because:\n         * 1) wildcards are not allowed in 1st position of a term by QueryParser\n         * 2) if wildcard was *not* in end, there would be *two* or more tokens */\n        return super.getWildcardQuery(field, tlist.get(0)\n            + wlist.get(0).toString());\n      } else {\n        /* we should never get here! if so, this method was called\n         * with a termStr containing no wildcard ... */\n        throw new IllegalArgumentException(\"getWildcardQuery called without wildcard\");\n      }\n    } else {\n      /* the term was tokenized, let's rebuild to one token\n       * with wildcards put back in postion */\n      StringBuilder sb = new StringBuilder();\n      for (int i = 0; i < tlist.size(); i++) {\n        sb.append( tlist.get(i));\n        if (wlist != null && wlist.size() > i) {\n          sb.append(wlist.get(i));\n        }\n      }\n      return super.getWildcardQuery(field, sb.toString());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"00746ad002a54281629e3b6f3eb39833a33f093e","date":1305306799,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/queryparser/src/java/org/apache/lucene/queryParser/analyzing/AnalyzingQueryParser#getWildcardQuery(String,String).mjava","pathOld":"lucene/contrib/queryparser/src/java/org/apache/lucene/queryParser/analyzing/AnalyzingQueryParser#getWildcardQuery(String,String).mjava","sourceNew":"  /**\n   * Called when parser\n   * parses an input term token that contains one or more wildcard\n   * characters (like <code>*</code>), but is not a prefix term token (one\n   * that has just a single * character at the end).\n   * <p>\n   * Example: will be called for <code>H?user</code> or for <code>H*user</code> \n   * but not for <code>*user</code>.\n   * <p>\n   * Depending on analyzer and settings, a wildcard term may (most probably will)\n   * be lower-cased automatically. It <b>will</b> go through the default Analyzer.\n   * <p>\n   * Overrides super class, by passing terms through analyzer.\n   *\n   * @param  field   Name of the field query will use.\n   * @param  termStr Term token that contains one or more wild card\n   *                 characters (? or *), but is not simple prefix term\n   *\n   * @return Resulting {@link Query} built for the term\n   * @throws ParseException\n   */\n  @Override\n  protected Query getWildcardQuery(String field, String termStr) throws ParseException {\n    List<String> tlist = new ArrayList<String>();\n    List<String> wlist = new ArrayList<String>();\n    /* somewhat a hack: find/store wildcard chars\n     * in order to put them back after analyzing */\n    boolean isWithinToken = (!termStr.startsWith(\"?\") && !termStr.startsWith(\"*\"));\n    StringBuilder tmpBuffer = new StringBuilder();\n    char[] chars = termStr.toCharArray();\n    for (int i = 0; i < termStr.length(); i++) {\n      if (chars[i] == '?' || chars[i] == '*') {\n        if (isWithinToken) {\n          tlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = false;\n      } else {\n        if (!isWithinToken) {\n          wlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = true;\n      }\n      tmpBuffer.append(chars[i]);\n    }\n    if (isWithinToken) {\n      tlist.add(tmpBuffer.toString());\n    } else {\n      wlist.add(tmpBuffer.toString());\n    }\n\n    // get Analyzer from superclass and tokenize the term\n    TokenStream source;\n    \n    int countTokens = 0;\n    try {\n      source = getAnalyzer().reusableTokenStream(field, new StringReader(termStr));\n      source.reset();\n    } catch (IOException e1) {\n      throw new RuntimeException(e1);\n    }\n    CharTermAttribute termAtt = source.addAttribute(CharTermAttribute.class);\n    while (true) {\n      try {\n        if (!source.incrementToken()) break;\n      } catch (IOException e) {\n        break;\n      }\n      String term = termAtt.toString();\n      if (!\"\".equals(term)) {\n        try {\n          tlist.set(countTokens++, term);\n        } catch (IndexOutOfBoundsException ioobe) {\n          countTokens = -1;\n        }\n      }\n    }\n    try {\n      source.end();\n      source.close();\n    } catch (IOException e) {\n      // ignore\n    }\n\n    if (countTokens != tlist.size()) {\n      /* this means that the analyzer used either added or consumed \n       * (common for a stemmer) tokens, and we can't build a WildcardQuery */\n      throw new ParseException(\"Cannot build WildcardQuery with analyzer \"\n          + getAnalyzer().getClass() + \" - tokens added or lost\");\n    }\n\n    if (tlist.size() == 0) {\n      return null;\n    } else if (tlist.size() == 1) {\n      if (wlist != null && wlist.size() == 1) {\n        /* if wlist contains one wildcard, it must be at the end, because:\n         * 1) wildcards are not allowed in 1st position of a term by QueryParser\n         * 2) if wildcard was *not* in end, there would be *two* or more tokens */\n        return super.getWildcardQuery(field, tlist.get(0)\n            + wlist.get(0).toString());\n      } else {\n        /* we should never get here! if so, this method was called\n         * with a termStr containing no wildcard ... */\n        throw new IllegalArgumentException(\"getWildcardQuery called without wildcard\");\n      }\n    } else {\n      /* the term was tokenized, let's rebuild to one token\n       * with wildcards put back in postion */\n      StringBuilder sb = new StringBuilder();\n      for (int i = 0; i < tlist.size(); i++) {\n        sb.append( tlist.get(i));\n        if (wlist != null && wlist.size() > i) {\n          sb.append(wlist.get(i));\n        }\n      }\n      return super.getWildcardQuery(field, sb.toString());\n    }\n  }\n\n","sourceOld":"  /**\n   * Called when parser\n   * parses an input term token that contains one or more wildcard\n   * characters (like <code>*</code>), but is not a prefix term token (one\n   * that has just a single * character at the end).\n   * <p>\n   * Example: will be called for <code>H?user</code> or for <code>H*user</code> \n   * but not for <code>*user</code>.\n   * <p>\n   * Depending on analyzer and settings, a wildcard term may (most probably will)\n   * be lower-cased automatically. It <b>will</b> go through the default Analyzer.\n   * <p>\n   * Overrides super class, by passing terms through analyzer.\n   *\n   * @param  field   Name of the field query will use.\n   * @param  termStr Term token that contains one or more wild card\n   *                 characters (? or *), but is not simple prefix term\n   *\n   * @return Resulting {@link Query} built for the term\n   * @throws ParseException\n   */\n  @Override\n  protected Query getWildcardQuery(String field, String termStr) throws ParseException {\n    List<String> tlist = new ArrayList<String>();\n    List<String> wlist = new ArrayList<String>();\n    /* somewhat a hack: find/store wildcard chars\n     * in order to put them back after analyzing */\n    boolean isWithinToken = (!termStr.startsWith(\"?\") && !termStr.startsWith(\"*\"));\n    StringBuilder tmpBuffer = new StringBuilder();\n    char[] chars = termStr.toCharArray();\n    for (int i = 0; i < termStr.length(); i++) {\n      if (chars[i] == '?' || chars[i] == '*') {\n        if (isWithinToken) {\n          tlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = false;\n      } else {\n        if (!isWithinToken) {\n          wlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = true;\n      }\n      tmpBuffer.append(chars[i]);\n    }\n    if (isWithinToken) {\n      tlist.add(tmpBuffer.toString());\n    } else {\n      wlist.add(tmpBuffer.toString());\n    }\n\n    // get Analyzer from superclass and tokenize the term\n    TokenStream source = getAnalyzer().tokenStream(field, new StringReader(termStr));\n    CharTermAttribute termAtt = source.addAttribute(CharTermAttribute.class);\n    \n    int countTokens = 0;\n    try {\n      source.reset();\n    } catch (IOException e1) {\n      throw new RuntimeException(e1);\n    }\n    while (true) {\n      try {\n        if (!source.incrementToken()) break;\n      } catch (IOException e) {\n        break;\n      }\n      String term = termAtt.toString();\n      if (!\"\".equals(term)) {\n        try {\n          tlist.set(countTokens++, term);\n        } catch (IndexOutOfBoundsException ioobe) {\n          countTokens = -1;\n        }\n      }\n    }\n    try {\n      source.end();\n      source.close();\n    } catch (IOException e) {\n      // ignore\n    }\n\n    if (countTokens != tlist.size()) {\n      /* this means that the analyzer used either added or consumed \n       * (common for a stemmer) tokens, and we can't build a WildcardQuery */\n      throw new ParseException(\"Cannot build WildcardQuery with analyzer \"\n          + getAnalyzer().getClass() + \" - tokens added or lost\");\n    }\n\n    if (tlist.size() == 0) {\n      return null;\n    } else if (tlist.size() == 1) {\n      if (wlist != null && wlist.size() == 1) {\n        /* if wlist contains one wildcard, it must be at the end, because:\n         * 1) wildcards are not allowed in 1st position of a term by QueryParser\n         * 2) if wildcard was *not* in end, there would be *two* or more tokens */\n        return super.getWildcardQuery(field, tlist.get(0)\n            + wlist.get(0).toString());\n      } else {\n        /* we should never get here! if so, this method was called\n         * with a termStr containing no wildcard ... */\n        throw new IllegalArgumentException(\"getWildcardQuery called without wildcard\");\n      }\n    } else {\n      /* the term was tokenized, let's rebuild to one token\n       * with wildcards put back in postion */\n      StringBuilder sb = new StringBuilder();\n      for (int i = 0; i < tlist.size(); i++) {\n        sb.append( tlist.get(i));\n        if (wlist != null && wlist.size() > i) {\n          sb.append(wlist.get(i));\n        }\n      }\n      return super.getWildcardQuery(field, sb.toString());\n    }\n  }\n\n","bugFix":null,"bugIntro":["046829b17e246624c179b94d5a20cb53fa945e87"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c3a8a449466c1ff7ce2274fe73dab487256964b4","date":1305735867,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/contrib/queryparser/src/java/org/apache/lucene/queryParser/analyzing/AnalyzingQueryParser#getWildcardQuery(String,String).mjava","pathOld":"lucene/contrib/queryparser/src/java/org/apache/lucene/queryParser/analyzing/AnalyzingQueryParser#getWildcardQuery(String,String).mjava","sourceNew":"  /**\n   * Called when parser\n   * parses an input term token that contains one or more wildcard\n   * characters (like <code>*</code>), but is not a prefix term token (one\n   * that has just a single * character at the end).\n   * <p>\n   * Example: will be called for <code>H?user</code> or for <code>H*user</code> \n   * but not for <code>*user</code>.\n   * <p>\n   * Depending on analyzer and settings, a wildcard term may (most probably will)\n   * be lower-cased automatically. It <b>will</b> go through the default Analyzer.\n   * <p>\n   * Overrides super class, by passing terms through analyzer.\n   *\n   * @param  field   Name of the field query will use.\n   * @param  termStr Term token that contains one or more wild card\n   *                 characters (? or *), but is not simple prefix term\n   *\n   * @return Resulting {@link Query} built for the term\n   * @throws ParseException\n   */\n  @Override\n  protected Query getWildcardQuery(String field, String termStr) throws ParseException {\n    List<String> tlist = new ArrayList<String>();\n    List<String> wlist = new ArrayList<String>();\n    /* somewhat a hack: find/store wildcard chars\n     * in order to put them back after analyzing */\n    boolean isWithinToken = (!termStr.startsWith(\"?\") && !termStr.startsWith(\"*\"));\n    StringBuilder tmpBuffer = new StringBuilder();\n    char[] chars = termStr.toCharArray();\n    for (int i = 0; i < termStr.length(); i++) {\n      if (chars[i] == '?' || chars[i] == '*') {\n        if (isWithinToken) {\n          tlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = false;\n      } else {\n        if (!isWithinToken) {\n          wlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = true;\n      }\n      tmpBuffer.append(chars[i]);\n    }\n    if (isWithinToken) {\n      tlist.add(tmpBuffer.toString());\n    } else {\n      wlist.add(tmpBuffer.toString());\n    }\n\n    // get Analyzer from superclass and tokenize the term\n    TokenStream source;\n    \n    int countTokens = 0;\n    try {\n      source = getAnalyzer().reusableTokenStream(field, new StringReader(termStr));\n      source.reset();\n    } catch (IOException e1) {\n      throw new RuntimeException(e1);\n    }\n    CharTermAttribute termAtt = source.addAttribute(CharTermAttribute.class);\n    while (true) {\n      try {\n        if (!source.incrementToken()) break;\n      } catch (IOException e) {\n        break;\n      }\n      String term = termAtt.toString();\n      if (!\"\".equals(term)) {\n        try {\n          tlist.set(countTokens++, term);\n        } catch (IndexOutOfBoundsException ioobe) {\n          countTokens = -1;\n        }\n      }\n    }\n    try {\n      source.end();\n      source.close();\n    } catch (IOException e) {\n      // ignore\n    }\n\n    if (countTokens != tlist.size()) {\n      /* this means that the analyzer used either added or consumed \n       * (common for a stemmer) tokens, and we can't build a WildcardQuery */\n      throw new ParseException(\"Cannot build WildcardQuery with analyzer \"\n          + getAnalyzer().getClass() + \" - tokens added or lost\");\n    }\n\n    if (tlist.size() == 0) {\n      return null;\n    } else if (tlist.size() == 1) {\n      if (wlist != null && wlist.size() == 1) {\n        /* if wlist contains one wildcard, it must be at the end, because:\n         * 1) wildcards are not allowed in 1st position of a term by QueryParser\n         * 2) if wildcard was *not* in end, there would be *two* or more tokens */\n        return super.getWildcardQuery(field, tlist.get(0)\n            + wlist.get(0).toString());\n      } else {\n        /* we should never get here! if so, this method was called\n         * with a termStr containing no wildcard ... */\n        throw new IllegalArgumentException(\"getWildcardQuery called without wildcard\");\n      }\n    } else {\n      /* the term was tokenized, let's rebuild to one token\n       * with wildcards put back in postion */\n      StringBuilder sb = new StringBuilder();\n      for (int i = 0; i < tlist.size(); i++) {\n        sb.append( tlist.get(i));\n        if (wlist != null && wlist.size() > i) {\n          sb.append(wlist.get(i));\n        }\n      }\n      return super.getWildcardQuery(field, sb.toString());\n    }\n  }\n\n","sourceOld":"  /**\n   * Called when parser\n   * parses an input term token that contains one or more wildcard\n   * characters (like <code>*</code>), but is not a prefix term token (one\n   * that has just a single * character at the end).\n   * <p>\n   * Example: will be called for <code>H?user</code> or for <code>H*user</code> \n   * but not for <code>*user</code>.\n   * <p>\n   * Depending on analyzer and settings, a wildcard term may (most probably will)\n   * be lower-cased automatically. It <b>will</b> go through the default Analyzer.\n   * <p>\n   * Overrides super class, by passing terms through analyzer.\n   *\n   * @param  field   Name of the field query will use.\n   * @param  termStr Term token that contains one or more wild card\n   *                 characters (? or *), but is not simple prefix term\n   *\n   * @return Resulting {@link Query} built for the term\n   * @throws ParseException\n   */\n  @Override\n  protected Query getWildcardQuery(String field, String termStr) throws ParseException {\n    List<String> tlist = new ArrayList<String>();\n    List<String> wlist = new ArrayList<String>();\n    /* somewhat a hack: find/store wildcard chars\n     * in order to put them back after analyzing */\n    boolean isWithinToken = (!termStr.startsWith(\"?\") && !termStr.startsWith(\"*\"));\n    StringBuilder tmpBuffer = new StringBuilder();\n    char[] chars = termStr.toCharArray();\n    for (int i = 0; i < termStr.length(); i++) {\n      if (chars[i] == '?' || chars[i] == '*') {\n        if (isWithinToken) {\n          tlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = false;\n      } else {\n        if (!isWithinToken) {\n          wlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = true;\n      }\n      tmpBuffer.append(chars[i]);\n    }\n    if (isWithinToken) {\n      tlist.add(tmpBuffer.toString());\n    } else {\n      wlist.add(tmpBuffer.toString());\n    }\n\n    // get Analyzer from superclass and tokenize the term\n    TokenStream source = getAnalyzer().tokenStream(field, new StringReader(termStr));\n    CharTermAttribute termAtt = source.addAttribute(CharTermAttribute.class);\n    \n    int countTokens = 0;\n    try {\n      source.reset();\n    } catch (IOException e1) {\n      throw new RuntimeException(e1);\n    }\n    while (true) {\n      try {\n        if (!source.incrementToken()) break;\n      } catch (IOException e) {\n        break;\n      }\n      String term = termAtt.toString();\n      if (!\"\".equals(term)) {\n        try {\n          tlist.set(countTokens++, term);\n        } catch (IndexOutOfBoundsException ioobe) {\n          countTokens = -1;\n        }\n      }\n    }\n    try {\n      source.end();\n      source.close();\n    } catch (IOException e) {\n      // ignore\n    }\n\n    if (countTokens != tlist.size()) {\n      /* this means that the analyzer used either added or consumed \n       * (common for a stemmer) tokens, and we can't build a WildcardQuery */\n      throw new ParseException(\"Cannot build WildcardQuery with analyzer \"\n          + getAnalyzer().getClass() + \" - tokens added or lost\");\n    }\n\n    if (tlist.size() == 0) {\n      return null;\n    } else if (tlist.size() == 1) {\n      if (wlist != null && wlist.size() == 1) {\n        /* if wlist contains one wildcard, it must be at the end, because:\n         * 1) wildcards are not allowed in 1st position of a term by QueryParser\n         * 2) if wildcard was *not* in end, there would be *two* or more tokens */\n        return super.getWildcardQuery(field, tlist.get(0)\n            + wlist.get(0).toString());\n      } else {\n        /* we should never get here! if so, this method was called\n         * with a termStr containing no wildcard ... */\n        throw new IllegalArgumentException(\"getWildcardQuery called without wildcard\");\n      }\n    } else {\n      /* the term was tokenized, let's rebuild to one token\n       * with wildcards put back in postion */\n      StringBuilder sb = new StringBuilder();\n      for (int i = 0; i < tlist.size(); i++) {\n        sb.append( tlist.get(i));\n        if (wlist != null && wlist.size() > i) {\n          sb.append(wlist.get(i));\n        }\n      }\n      return super.getWildcardQuery(field, sb.toString());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/contrib/queryparser/src/java/org/apache/lucene/queryParser/analyzing/AnalyzingQueryParser#getWildcardQuery(String,String).mjava","pathOld":"lucene/contrib/queryparser/src/java/org/apache/lucene/queryParser/analyzing/AnalyzingQueryParser#getWildcardQuery(String,String).mjava","sourceNew":"  /**\n   * Called when parser\n   * parses an input term token that contains one or more wildcard\n   * characters (like <code>*</code>), but is not a prefix term token (one\n   * that has just a single * character at the end).\n   * <p>\n   * Example: will be called for <code>H?user</code> or for <code>H*user</code> \n   * but not for <code>*user</code>.\n   * <p>\n   * Depending on analyzer and settings, a wildcard term may (most probably will)\n   * be lower-cased automatically. It <b>will</b> go through the default Analyzer.\n   * <p>\n   * Overrides super class, by passing terms through analyzer.\n   *\n   * @param  field   Name of the field query will use.\n   * @param  termStr Term token that contains one or more wild card\n   *                 characters (? or *), but is not simple prefix term\n   *\n   * @return Resulting {@link Query} built for the term\n   * @throws ParseException\n   */\n  @Override\n  protected Query getWildcardQuery(String field, String termStr) throws ParseException {\n    List<String> tlist = new ArrayList<String>();\n    List<String> wlist = new ArrayList<String>();\n    /* somewhat a hack: find/store wildcard chars\n     * in order to put them back after analyzing */\n    boolean isWithinToken = (!termStr.startsWith(\"?\") && !termStr.startsWith(\"*\"));\n    StringBuilder tmpBuffer = new StringBuilder();\n    char[] chars = termStr.toCharArray();\n    for (int i = 0; i < termStr.length(); i++) {\n      if (chars[i] == '?' || chars[i] == '*') {\n        if (isWithinToken) {\n          tlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = false;\n      } else {\n        if (!isWithinToken) {\n          wlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = true;\n      }\n      tmpBuffer.append(chars[i]);\n    }\n    if (isWithinToken) {\n      tlist.add(tmpBuffer.toString());\n    } else {\n      wlist.add(tmpBuffer.toString());\n    }\n\n    // get Analyzer from superclass and tokenize the term\n    TokenStream source;\n    \n    int countTokens = 0;\n    try {\n      source = getAnalyzer().reusableTokenStream(field, new StringReader(termStr));\n      source.reset();\n    } catch (IOException e1) {\n      throw new RuntimeException(e1);\n    }\n    CharTermAttribute termAtt = source.addAttribute(CharTermAttribute.class);\n    while (true) {\n      try {\n        if (!source.incrementToken()) break;\n      } catch (IOException e) {\n        break;\n      }\n      String term = termAtt.toString();\n      if (!\"\".equals(term)) {\n        try {\n          tlist.set(countTokens++, term);\n        } catch (IndexOutOfBoundsException ioobe) {\n          countTokens = -1;\n        }\n      }\n    }\n    try {\n      source.end();\n      source.close();\n    } catch (IOException e) {\n      // ignore\n    }\n\n    if (countTokens != tlist.size()) {\n      /* this means that the analyzer used either added or consumed \n       * (common for a stemmer) tokens, and we can't build a WildcardQuery */\n      throw new ParseException(\"Cannot build WildcardQuery with analyzer \"\n          + getAnalyzer().getClass() + \" - tokens added or lost\");\n    }\n\n    if (tlist.size() == 0) {\n      return null;\n    } else if (tlist.size() == 1) {\n      if (wlist != null && wlist.size() == 1) {\n        /* if wlist contains one wildcard, it must be at the end, because:\n         * 1) wildcards are not allowed in 1st position of a term by QueryParser\n         * 2) if wildcard was *not* in end, there would be *two* or more tokens */\n        return super.getWildcardQuery(field, tlist.get(0)\n            + wlist.get(0).toString());\n      } else {\n        /* we should never get here! if so, this method was called\n         * with a termStr containing no wildcard ... */\n        throw new IllegalArgumentException(\"getWildcardQuery called without wildcard\");\n      }\n    } else {\n      /* the term was tokenized, let's rebuild to one token\n       * with wildcards put back in postion */\n      StringBuilder sb = new StringBuilder();\n      for (int i = 0; i < tlist.size(); i++) {\n        sb.append( tlist.get(i));\n        if (wlist != null && wlist.size() > i) {\n          sb.append(wlist.get(i));\n        }\n      }\n      return super.getWildcardQuery(field, sb.toString());\n    }\n  }\n\n","sourceOld":"  /**\n   * Called when parser\n   * parses an input term token that contains one or more wildcard\n   * characters (like <code>*</code>), but is not a prefix term token (one\n   * that has just a single * character at the end).\n   * <p>\n   * Example: will be called for <code>H?user</code> or for <code>H*user</code> \n   * but not for <code>*user</code>.\n   * <p>\n   * Depending on analyzer and settings, a wildcard term may (most probably will)\n   * be lower-cased automatically. It <b>will</b> go through the default Analyzer.\n   * <p>\n   * Overrides super class, by passing terms through analyzer.\n   *\n   * @param  field   Name of the field query will use.\n   * @param  termStr Term token that contains one or more wild card\n   *                 characters (? or *), but is not simple prefix term\n   *\n   * @return Resulting {@link Query} built for the term\n   * @throws ParseException\n   */\n  @Override\n  protected Query getWildcardQuery(String field, String termStr) throws ParseException {\n    List<String> tlist = new ArrayList<String>();\n    List<String> wlist = new ArrayList<String>();\n    /* somewhat a hack: find/store wildcard chars\n     * in order to put them back after analyzing */\n    boolean isWithinToken = (!termStr.startsWith(\"?\") && !termStr.startsWith(\"*\"));\n    StringBuilder tmpBuffer = new StringBuilder();\n    char[] chars = termStr.toCharArray();\n    for (int i = 0; i < termStr.length(); i++) {\n      if (chars[i] == '?' || chars[i] == '*') {\n        if (isWithinToken) {\n          tlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = false;\n      } else {\n        if (!isWithinToken) {\n          wlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = true;\n      }\n      tmpBuffer.append(chars[i]);\n    }\n    if (isWithinToken) {\n      tlist.add(tmpBuffer.toString());\n    } else {\n      wlist.add(tmpBuffer.toString());\n    }\n\n    // get Analyzer from superclass and tokenize the term\n    TokenStream source = getAnalyzer().tokenStream(field, new StringReader(termStr));\n    CharTermAttribute termAtt = source.addAttribute(CharTermAttribute.class);\n    \n    int countTokens = 0;\n    while (true) {\n      try {\n        if (!source.incrementToken()) break;\n      } catch (IOException e) {\n        break;\n      }\n      String term = termAtt.toString();\n      if (!\"\".equals(term)) {\n        try {\n          tlist.set(countTokens++, term);\n        } catch (IndexOutOfBoundsException ioobe) {\n          countTokens = -1;\n        }\n      }\n    }\n    try {\n      source.close();\n    } catch (IOException e) {\n      // ignore\n    }\n\n    if (countTokens != tlist.size()) {\n      /* this means that the analyzer used either added or consumed \n       * (common for a stemmer) tokens, and we can't build a WildcardQuery */\n      throw new ParseException(\"Cannot build WildcardQuery with analyzer \"\n          + getAnalyzer().getClass() + \" - tokens added or lost\");\n    }\n\n    if (tlist.size() == 0) {\n      return null;\n    } else if (tlist.size() == 1) {\n      if (wlist != null && wlist.size() == 1) {\n        /* if wlist contains one wildcard, it must be at the end, because:\n         * 1) wildcards are not allowed in 1st position of a term by QueryParser\n         * 2) if wildcard was *not* in end, there would be *two* or more tokens */\n        return super.getWildcardQuery(field, tlist.get(0)\n            + wlist.get(0).toString());\n      } else {\n        /* we should never get here! if so, this method was called\n         * with a termStr containing no wildcard ... */\n        throw new IllegalArgumentException(\"getWildcardQuery called without wildcard\");\n      }\n    } else {\n      /* the term was tokenized, let's rebuild to one token\n       * with wildcards put back in postion */\n      StringBuilder sb = new StringBuilder();\n      for (int i = 0; i < tlist.size(); i++) {\n        sb.append( tlist.get(i));\n        if (wlist != null && wlist.size() > i) {\n          sb.append(wlist.get(i));\n        }\n      }\n      return super.getWildcardQuery(field, sb.toString());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a53a291ad9b1cc050d846b68758c061a55d52734","date":1310437344,"type":5,"author":"Christopher John Male","isMerge":false,"pathNew":"modules/queryparser/src/java/org/apache/lucene/queryparser/analyzing/AnalyzingQueryParser#getWildcardQuery(String,String).mjava","pathOld":"lucene/contrib/queryparser/src/java/org/apache/lucene/queryParser/analyzing/AnalyzingQueryParser#getWildcardQuery(String,String).mjava","sourceNew":"  /**\n   * Called when parser\n   * parses an input term token that contains one or more wildcard\n   * characters (like <code>*</code>), but is not a prefix term token (one\n   * that has just a single * character at the end).\n   * <p>\n   * Example: will be called for <code>H?user</code> or for <code>H*user</code> \n   * but not for <code>*user</code>.\n   * <p>\n   * Depending on analyzer and settings, a wildcard term may (most probably will)\n   * be lower-cased automatically. It <b>will</b> go through the default Analyzer.\n   * <p>\n   * Overrides super class, by passing terms through analyzer.\n   *\n   * @param  field   Name of the field query will use.\n   * @param  termStr Term token that contains one or more wild card\n   *                 characters (? or *), but is not simple prefix term\n   *\n   * @return Resulting {@link Query} built for the term\n   * @throws ParseException\n   */\n  @Override\n  protected Query getWildcardQuery(String field, String termStr) throws ParseException {\n    List<String> tlist = new ArrayList<String>();\n    List<String> wlist = new ArrayList<String>();\n    /* somewhat a hack: find/store wildcard chars\n     * in order to put them back after analyzing */\n    boolean isWithinToken = (!termStr.startsWith(\"?\") && !termStr.startsWith(\"*\"));\n    StringBuilder tmpBuffer = new StringBuilder();\n    char[] chars = termStr.toCharArray();\n    for (int i = 0; i < termStr.length(); i++) {\n      if (chars[i] == '?' || chars[i] == '*') {\n        if (isWithinToken) {\n          tlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = false;\n      } else {\n        if (!isWithinToken) {\n          wlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = true;\n      }\n      tmpBuffer.append(chars[i]);\n    }\n    if (isWithinToken) {\n      tlist.add(tmpBuffer.toString());\n    } else {\n      wlist.add(tmpBuffer.toString());\n    }\n\n    // get Analyzer from superclass and tokenize the term\n    TokenStream source;\n    \n    int countTokens = 0;\n    try {\n      source = getAnalyzer().reusableTokenStream(field, new StringReader(termStr));\n      source.reset();\n    } catch (IOException e1) {\n      throw new RuntimeException(e1);\n    }\n    CharTermAttribute termAtt = source.addAttribute(CharTermAttribute.class);\n    while (true) {\n      try {\n        if (!source.incrementToken()) break;\n      } catch (IOException e) {\n        break;\n      }\n      String term = termAtt.toString();\n      if (!\"\".equals(term)) {\n        try {\n          tlist.set(countTokens++, term);\n        } catch (IndexOutOfBoundsException ioobe) {\n          countTokens = -1;\n        }\n      }\n    }\n    try {\n      source.end();\n      source.close();\n    } catch (IOException e) {\n      // ignore\n    }\n\n    if (countTokens != tlist.size()) {\n      /* this means that the analyzer used either added or consumed \n       * (common for a stemmer) tokens, and we can't build a WildcardQuery */\n      throw new ParseException(\"Cannot build WildcardQuery with analyzer \"\n          + getAnalyzer().getClass() + \" - tokens added or lost\");\n    }\n\n    if (tlist.size() == 0) {\n      return null;\n    } else if (tlist.size() == 1) {\n      if (wlist != null && wlist.size() == 1) {\n        /* if wlist contains one wildcard, it must be at the end, because:\n         * 1) wildcards are not allowed in 1st position of a term by QueryParser\n         * 2) if wildcard was *not* in end, there would be *two* or more tokens */\n        return super.getWildcardQuery(field, tlist.get(0)\n            + wlist.get(0).toString());\n      } else {\n        /* we should never get here! if so, this method was called\n         * with a termStr containing no wildcard ... */\n        throw new IllegalArgumentException(\"getWildcardQuery called without wildcard\");\n      }\n    } else {\n      /* the term was tokenized, let's rebuild to one token\n       * with wildcards put back in postion */\n      StringBuilder sb = new StringBuilder();\n      for (int i = 0; i < tlist.size(); i++) {\n        sb.append( tlist.get(i));\n        if (wlist != null && wlist.size() > i) {\n          sb.append(wlist.get(i));\n        }\n      }\n      return super.getWildcardQuery(field, sb.toString());\n    }\n  }\n\n","sourceOld":"  /**\n   * Called when parser\n   * parses an input term token that contains one or more wildcard\n   * characters (like <code>*</code>), but is not a prefix term token (one\n   * that has just a single * character at the end).\n   * <p>\n   * Example: will be called for <code>H?user</code> or for <code>H*user</code> \n   * but not for <code>*user</code>.\n   * <p>\n   * Depending on analyzer and settings, a wildcard term may (most probably will)\n   * be lower-cased automatically. It <b>will</b> go through the default Analyzer.\n   * <p>\n   * Overrides super class, by passing terms through analyzer.\n   *\n   * @param  field   Name of the field query will use.\n   * @param  termStr Term token that contains one or more wild card\n   *                 characters (? or *), but is not simple prefix term\n   *\n   * @return Resulting {@link Query} built for the term\n   * @throws ParseException\n   */\n  @Override\n  protected Query getWildcardQuery(String field, String termStr) throws ParseException {\n    List<String> tlist = new ArrayList<String>();\n    List<String> wlist = new ArrayList<String>();\n    /* somewhat a hack: find/store wildcard chars\n     * in order to put them back after analyzing */\n    boolean isWithinToken = (!termStr.startsWith(\"?\") && !termStr.startsWith(\"*\"));\n    StringBuilder tmpBuffer = new StringBuilder();\n    char[] chars = termStr.toCharArray();\n    for (int i = 0; i < termStr.length(); i++) {\n      if (chars[i] == '?' || chars[i] == '*') {\n        if (isWithinToken) {\n          tlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = false;\n      } else {\n        if (!isWithinToken) {\n          wlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = true;\n      }\n      tmpBuffer.append(chars[i]);\n    }\n    if (isWithinToken) {\n      tlist.add(tmpBuffer.toString());\n    } else {\n      wlist.add(tmpBuffer.toString());\n    }\n\n    // get Analyzer from superclass and tokenize the term\n    TokenStream source;\n    \n    int countTokens = 0;\n    try {\n      source = getAnalyzer().reusableTokenStream(field, new StringReader(termStr));\n      source.reset();\n    } catch (IOException e1) {\n      throw new RuntimeException(e1);\n    }\n    CharTermAttribute termAtt = source.addAttribute(CharTermAttribute.class);\n    while (true) {\n      try {\n        if (!source.incrementToken()) break;\n      } catch (IOException e) {\n        break;\n      }\n      String term = termAtt.toString();\n      if (!\"\".equals(term)) {\n        try {\n          tlist.set(countTokens++, term);\n        } catch (IndexOutOfBoundsException ioobe) {\n          countTokens = -1;\n        }\n      }\n    }\n    try {\n      source.end();\n      source.close();\n    } catch (IOException e) {\n      // ignore\n    }\n\n    if (countTokens != tlist.size()) {\n      /* this means that the analyzer used either added or consumed \n       * (common for a stemmer) tokens, and we can't build a WildcardQuery */\n      throw new ParseException(\"Cannot build WildcardQuery with analyzer \"\n          + getAnalyzer().getClass() + \" - tokens added or lost\");\n    }\n\n    if (tlist.size() == 0) {\n      return null;\n    } else if (tlist.size() == 1) {\n      if (wlist != null && wlist.size() == 1) {\n        /* if wlist contains one wildcard, it must be at the end, because:\n         * 1) wildcards are not allowed in 1st position of a term by QueryParser\n         * 2) if wildcard was *not* in end, there would be *two* or more tokens */\n        return super.getWildcardQuery(field, tlist.get(0)\n            + wlist.get(0).toString());\n      } else {\n        /* we should never get here! if so, this method was called\n         * with a termStr containing no wildcard ... */\n        throw new IllegalArgumentException(\"getWildcardQuery called without wildcard\");\n      }\n    } else {\n      /* the term was tokenized, let's rebuild to one token\n       * with wildcards put back in postion */\n      StringBuilder sb = new StringBuilder();\n      for (int i = 0; i < tlist.size(); i++) {\n        sb.append( tlist.get(i));\n        if (wlist != null && wlist.size() > i) {\n          sb.append(wlist.get(i));\n        }\n      }\n      return super.getWildcardQuery(field, sb.toString());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"c3a8a449466c1ff7ce2274fe73dab487256964b4":["c700f8d0842d3e52bb2bdfbfdc046a137e836edb","00746ad002a54281629e3b6f3eb39833a33f093e"],"e2efdd13c0f37dbe4a292a6f98ddcf8e8f872ac4":["a7347509fad0711ac30cb15a746e9a3830a38ebd"],"36f91bf9cfc9d0c3155edab43359e7670ea8a5af":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a3776dccca01c11e7046323cfad46a3b4a471233":["a7347509fad0711ac30cb15a746e9a3830a38ebd","00746ad002a54281629e3b6f3eb39833a33f093e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"c700f8d0842d3e52bb2bdfbfdc046a137e836edb":["a7347509fad0711ac30cb15a746e9a3830a38ebd","e2efdd13c0f37dbe4a292a6f98ddcf8e8f872ac4"],"00746ad002a54281629e3b6f3eb39833a33f093e":["e2efdd13c0f37dbe4a292a6f98ddcf8e8f872ac4"],"a53a291ad9b1cc050d846b68758c061a55d52734":["00746ad002a54281629e3b6f3eb39833a33f093e"],"a7347509fad0711ac30cb15a746e9a3830a38ebd":["36f91bf9cfc9d0c3155edab43359e7670ea8a5af"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a53a291ad9b1cc050d846b68758c061a55d52734"]},"commit2Childs":{"c3a8a449466c1ff7ce2274fe73dab487256964b4":[],"e2efdd13c0f37dbe4a292a6f98ddcf8e8f872ac4":["c700f8d0842d3e52bb2bdfbfdc046a137e836edb","00746ad002a54281629e3b6f3eb39833a33f093e"],"36f91bf9cfc9d0c3155edab43359e7670ea8a5af":["a7347509fad0711ac30cb15a746e9a3830a38ebd"],"a3776dccca01c11e7046323cfad46a3b4a471233":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["36f91bf9cfc9d0c3155edab43359e7670ea8a5af"],"c700f8d0842d3e52bb2bdfbfdc046a137e836edb":["c3a8a449466c1ff7ce2274fe73dab487256964b4"],"00746ad002a54281629e3b6f3eb39833a33f093e":["c3a8a449466c1ff7ce2274fe73dab487256964b4","a3776dccca01c11e7046323cfad46a3b4a471233","a53a291ad9b1cc050d846b68758c061a55d52734"],"a53a291ad9b1cc050d846b68758c061a55d52734":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a7347509fad0711ac30cb15a746e9a3830a38ebd":["e2efdd13c0f37dbe4a292a6f98ddcf8e8f872ac4","a3776dccca01c11e7046323cfad46a3b4a471233","c700f8d0842d3e52bb2bdfbfdc046a137e836edb"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["c3a8a449466c1ff7ce2274fe73dab487256964b4","a3776dccca01c11e7046323cfad46a3b4a471233","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}