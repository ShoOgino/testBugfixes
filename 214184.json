{"path":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#parseAffix(TreeMap[String,List[Character]],String,LineNumberReader,String,Map[String,Integer]).mjava","commits":[{"id":"dc3f094cafa4a87b4066e1d6710fa4e6afe6260e","date":1393532367,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#parseAffix(TreeMap[String,List[Character]],String,LineNumberReader,String,Map[String,Integer]).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell2/Dictionary#parseAffix(TreeMap[String,List[Character]],String,LineNumberReader,String,Map[String,Integer]).mjava","sourceNew":"  /**\n   * Parses a specific affix rule putting the result into the provided affix map\n   * \n   * @param affixes Map where the result of the parsing will be put\n   * @param header Header line of the affix rule\n   * @param reader BufferedReader to read the content of the rule from\n   * @param conditionPattern {@link String#format(String, Object...)} pattern to be used to generate the condition regex\n   *                         pattern\n   * @param seenPatterns map from condition -> index of patterns, for deduplication.\n   * @throws IOException Can be thrown while reading the rule\n   */\n  private void parseAffix(TreeMap<String,List<Character>> affixes,\n                          String header,\n                          LineNumberReader reader,\n                          String conditionPattern,\n                          Map<String,Integer> seenPatterns) throws IOException, ParseException {\n    \n    BytesRef scratch = new BytesRef();\n    String args[] = header.split(\"\\\\s+\");\n\n    boolean crossProduct = args[2].equals(\"Y\");\n    \n    int numLines = Integer.parseInt(args[3]);\n    affixData = ArrayUtil.grow(affixData, (currentAffix << 3) + (numLines << 3));\n    ByteArrayDataOutput affixWriter = new ByteArrayDataOutput(affixData, currentAffix << 3, numLines << 3);\n    \n    for (int i = 0; i < numLines; i++) {\n      if (currentAffix > Short.MAX_VALUE) {\n        throw new UnsupportedOperationException(\"Too many affixes, please report this to dev@lucene.apache.org\");\n      }\n      assert affixWriter.getPosition() == currentAffix << 3;\n      String line = reader.readLine();\n      String ruleArgs[] = line.split(\"\\\\s+\");\n\n      if (ruleArgs.length < 5) {\n          throw new ParseException(\"The affix file contains a rule with less than five elements\", reader.getLineNumber());\n      }\n      \n      char flag = flagParsingStrategy.parseFlag(ruleArgs[1]);\n      String strip = ruleArgs[2].equals(\"0\") ? \"\" : ruleArgs[2];\n      String affixArg = ruleArgs[3];\n      char appendFlags[] = null;\n      \n      int flagSep = affixArg.lastIndexOf('/');\n      if (flagSep != -1) {\n        String flagPart = affixArg.substring(flagSep + 1);\n        affixArg = affixArg.substring(0, flagSep);\n\n        if (aliasCount > 0) {\n          flagPart = getAliasValue(Integer.parseInt(flagPart));\n        } \n        \n        appendFlags = flagParsingStrategy.parseFlags(flagPart);\n        Arrays.sort(appendFlags);\n      }\n\n      String condition = ruleArgs[4];\n      // at least the gascon affix file has this issue\n      if (condition.startsWith(\"[\") && !condition.endsWith(\"]\")) {\n        condition = condition + \"]\";\n      }\n      // \"dash hasn't got special meaning\" (we must escape it)\n      if (condition.indexOf('-') >= 0) {\n        condition = condition.replace(\"-\", \"\\\\-\");\n      }\n\n      String regex = String.format(Locale.ROOT, conditionPattern, condition);\n      \n      // deduplicate patterns\n      Integer patternIndex = seenPatterns.get(regex);\n      if (patternIndex == null) {\n        patternIndex = patterns.size();\n        seenPatterns.put(regex, patternIndex);\n        Pattern pattern = Pattern.compile(regex);\n        patterns.add(pattern);\n      }\n      \n      scratch.copyChars(strip);\n      int stripOrd = stripLookup.add(scratch);\n      if (stripOrd < 0) {\n        // already exists in our hash\n        stripOrd = (-stripOrd)-1;\n      }\n\n      if (appendFlags == null) {\n        appendFlags = NOFLAGS;\n      }\n      \n      final int hashCode = encodeFlagsWithHash(scratch, appendFlags);\n      int appendFlagsOrd = flagLookup.add(scratch, hashCode);\n      if (appendFlagsOrd < 0) {\n        // already exists in our hash\n        appendFlagsOrd = (-appendFlagsOrd)-1;\n      } else if (appendFlagsOrd > Short.MAX_VALUE) {\n        // this limit is probably flexible, but its a good sanity check too\n        throw new UnsupportedOperationException(\"Too many unique flags, please report this to dev@lucene.apache.org\");\n      }\n      \n      affixWriter.writeShort((short)flag);\n      affixWriter.writeShort((short)stripOrd);\n      // encode crossProduct into patternIndex\n      int patternOrd = patternIndex.intValue() << 1 | (crossProduct ? 1 : 0);\n      affixWriter.writeShort((short)patternOrd);\n      affixWriter.writeShort((short)appendFlagsOrd);\n      \n      List<Character> list = affixes.get(affixArg);\n      if (list == null) {\n        list = new ArrayList<Character>();\n        affixes.put(affixArg, list);\n      }\n      \n      list.add((char)currentAffix);\n      currentAffix++;\n    }\n  }\n\n","sourceOld":"  /**\n   * Parses a specific affix rule putting the result into the provided affix map\n   * \n   * @param affixes Map where the result of the parsing will be put\n   * @param header Header line of the affix rule\n   * @param reader BufferedReader to read the content of the rule from\n   * @param conditionPattern {@link String#format(String, Object...)} pattern to be used to generate the condition regex\n   *                         pattern\n   * @param seenPatterns map from condition -> index of patterns, for deduplication.\n   * @throws IOException Can be thrown while reading the rule\n   */\n  private void parseAffix(TreeMap<String,List<Character>> affixes,\n                          String header,\n                          LineNumberReader reader,\n                          String conditionPattern,\n                          Map<String,Integer> seenPatterns) throws IOException, ParseException {\n    \n    BytesRef scratch = new BytesRef();\n    String args[] = header.split(\"\\\\s+\");\n\n    boolean crossProduct = args[2].equals(\"Y\");\n    \n    int numLines = Integer.parseInt(args[3]);\n    affixData = ArrayUtil.grow(affixData, (currentAffix << 3) + (numLines << 3));\n    ByteArrayDataOutput affixWriter = new ByteArrayDataOutput(affixData, currentAffix << 3, numLines << 3);\n    \n    for (int i = 0; i < numLines; i++) {\n      if (currentAffix > Short.MAX_VALUE) {\n        throw new UnsupportedOperationException(\"Too many affixes, please report this to dev@lucene.apache.org\");\n      }\n      assert affixWriter.getPosition() == currentAffix << 3;\n      String line = reader.readLine();\n      String ruleArgs[] = line.split(\"\\\\s+\");\n\n      if (ruleArgs.length < 5) {\n          throw new ParseException(\"The affix file contains a rule with less than five elements\", reader.getLineNumber());\n      }\n      \n      char flag = flagParsingStrategy.parseFlag(ruleArgs[1]);\n      String strip = ruleArgs[2].equals(\"0\") ? \"\" : ruleArgs[2];\n      String affixArg = ruleArgs[3];\n      char appendFlags[] = null;\n      \n      int flagSep = affixArg.lastIndexOf('/');\n      if (flagSep != -1) {\n        String flagPart = affixArg.substring(flagSep + 1);\n        affixArg = affixArg.substring(0, flagSep);\n\n        if (aliasCount > 0) {\n          flagPart = getAliasValue(Integer.parseInt(flagPart));\n        } \n        \n        appendFlags = flagParsingStrategy.parseFlags(flagPart);\n        Arrays.sort(appendFlags);\n      }\n\n      String condition = ruleArgs[4];\n      // at least the gascon affix file has this issue\n      if (condition.startsWith(\"[\") && !condition.endsWith(\"]\")) {\n        condition = condition + \"]\";\n      }\n      // \"dash hasn't got special meaning\" (we must escape it)\n      if (condition.indexOf('-') >= 0) {\n        condition = condition.replace(\"-\", \"\\\\-\");\n      }\n\n      String regex = String.format(Locale.ROOT, conditionPattern, condition);\n      \n      // deduplicate patterns\n      Integer patternIndex = seenPatterns.get(regex);\n      if (patternIndex == null) {\n        patternIndex = patterns.size();\n        seenPatterns.put(regex, patternIndex);\n        Pattern pattern = Pattern.compile(regex);\n        patterns.add(pattern);\n      }\n      \n      scratch.copyChars(strip);\n      int stripOrd = stripLookup.add(scratch);\n      if (stripOrd < 0) {\n        // already exists in our hash\n        stripOrd = (-stripOrd)-1;\n      }\n\n      if (appendFlags == null) {\n        appendFlags = NOFLAGS;\n      }\n      \n      final int hashCode = encodeFlagsWithHash(scratch, appendFlags);\n      int appendFlagsOrd = flagLookup.add(scratch, hashCode);\n      if (appendFlagsOrd < 0) {\n        // already exists in our hash\n        appendFlagsOrd = (-appendFlagsOrd)-1;\n      } else if (appendFlagsOrd > Short.MAX_VALUE) {\n        // this limit is probably flexible, but its a good sanity check too\n        throw new UnsupportedOperationException(\"Too many unique flags, please report this to dev@lucene.apache.org\");\n      }\n      \n      affixWriter.writeShort((short)flag);\n      affixWriter.writeShort((short)stripOrd);\n      // encode crossProduct into patternIndex\n      int patternOrd = patternIndex.intValue() << 1 | (crossProduct ? 1 : 0);\n      affixWriter.writeShort((short)patternOrd);\n      affixWriter.writeShort((short)appendFlagsOrd);\n      \n      List<Character> list = affixes.get(affixArg);\n      if (list == null) {\n        list = new ArrayList<Character>();\n        affixes.put(affixArg, list);\n      }\n      \n      list.add((char)currentAffix);\n      currentAffix++;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ba791bce8103c79e38f957e9c5a53a75871bd918","date":1393539206,"type":1,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#parseAffix(TreeMap[String,List[Character]],String,LineNumberReader,String,Map[String,Integer]).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/HunspellDictionary#parseAffix(CharArrayMap[List[HunspellAffix]],String,LineNumberReader,String,boolean).mjava","sourceNew":"  /**\n   * Parses a specific affix rule putting the result into the provided affix map\n   * \n   * @param affixes Map where the result of the parsing will be put\n   * @param header Header line of the affix rule\n   * @param reader BufferedReader to read the content of the rule from\n   * @param conditionPattern {@link String#format(String, Object...)} pattern to be used to generate the condition regex\n   *                         pattern\n   * @param seenPatterns map from condition -> index of patterns, for deduplication.\n   * @throws IOException Can be thrown while reading the rule\n   */\n  private void parseAffix(TreeMap<String,List<Character>> affixes,\n                          String header,\n                          LineNumberReader reader,\n                          String conditionPattern,\n                          Map<String,Integer> seenPatterns) throws IOException, ParseException {\n    \n    BytesRef scratch = new BytesRef();\n    String args[] = header.split(\"\\\\s+\");\n\n    boolean crossProduct = args[2].equals(\"Y\");\n    \n    int numLines = Integer.parseInt(args[3]);\n    affixData = ArrayUtil.grow(affixData, (currentAffix << 3) + (numLines << 3));\n    ByteArrayDataOutput affixWriter = new ByteArrayDataOutput(affixData, currentAffix << 3, numLines << 3);\n    \n    for (int i = 0; i < numLines; i++) {\n      if (currentAffix > Short.MAX_VALUE) {\n        throw new UnsupportedOperationException(\"Too many affixes, please report this to dev@lucene.apache.org\");\n      }\n      assert affixWriter.getPosition() == currentAffix << 3;\n      String line = reader.readLine();\n      String ruleArgs[] = line.split(\"\\\\s+\");\n\n      if (ruleArgs.length < 5) {\n          throw new ParseException(\"The affix file contains a rule with less than five elements\", reader.getLineNumber());\n      }\n      \n      char flag = flagParsingStrategy.parseFlag(ruleArgs[1]);\n      String strip = ruleArgs[2].equals(\"0\") ? \"\" : ruleArgs[2];\n      String affixArg = ruleArgs[3];\n      char appendFlags[] = null;\n      \n      int flagSep = affixArg.lastIndexOf('/');\n      if (flagSep != -1) {\n        String flagPart = affixArg.substring(flagSep + 1);\n        affixArg = affixArg.substring(0, flagSep);\n\n        if (aliasCount > 0) {\n          flagPart = getAliasValue(Integer.parseInt(flagPart));\n        } \n        \n        appendFlags = flagParsingStrategy.parseFlags(flagPart);\n        Arrays.sort(appendFlags);\n      }\n\n      String condition = ruleArgs[4];\n      // at least the gascon affix file has this issue\n      if (condition.startsWith(\"[\") && !condition.endsWith(\"]\")) {\n        condition = condition + \"]\";\n      }\n      // \"dash hasn't got special meaning\" (we must escape it)\n      if (condition.indexOf('-') >= 0) {\n        condition = condition.replace(\"-\", \"\\\\-\");\n      }\n\n      String regex = String.format(Locale.ROOT, conditionPattern, condition);\n      \n      // deduplicate patterns\n      Integer patternIndex = seenPatterns.get(regex);\n      if (patternIndex == null) {\n        patternIndex = patterns.size();\n        seenPatterns.put(regex, patternIndex);\n        Pattern pattern = Pattern.compile(regex);\n        patterns.add(pattern);\n      }\n      \n      scratch.copyChars(strip);\n      int stripOrd = stripLookup.add(scratch);\n      if (stripOrd < 0) {\n        // already exists in our hash\n        stripOrd = (-stripOrd)-1;\n      }\n\n      if (appendFlags == null) {\n        appendFlags = NOFLAGS;\n      }\n      \n      final int hashCode = encodeFlagsWithHash(scratch, appendFlags);\n      int appendFlagsOrd = flagLookup.add(scratch, hashCode);\n      if (appendFlagsOrd < 0) {\n        // already exists in our hash\n        appendFlagsOrd = (-appendFlagsOrd)-1;\n      } else if (appendFlagsOrd > Short.MAX_VALUE) {\n        // this limit is probably flexible, but its a good sanity check too\n        throw new UnsupportedOperationException(\"Too many unique flags, please report this to dev@lucene.apache.org\");\n      }\n      \n      affixWriter.writeShort((short)flag);\n      affixWriter.writeShort((short)stripOrd);\n      // encode crossProduct into patternIndex\n      int patternOrd = patternIndex.intValue() << 1 | (crossProduct ? 1 : 0);\n      affixWriter.writeShort((short)patternOrd);\n      affixWriter.writeShort((short)appendFlagsOrd);\n      \n      List<Character> list = affixes.get(affixArg);\n      if (list == null) {\n        list = new ArrayList<Character>();\n        affixes.put(affixArg, list);\n      }\n      \n      list.add((char)currentAffix);\n      currentAffix++;\n    }\n  }\n\n","sourceOld":"  /**\n   * Parses a specific affix rule putting the result into the provided affix map\n   * \n   * @param affixes Map where the result of the parsing will be put\n   * @param header Header line of the affix rule\n   * @param reader BufferedReader to read the content of the rule from\n   * @param conditionPattern {@link String#format(String, Object...)} pattern to be used to generate the condition regex\n   *                         pattern\n   * @throws IOException Can be thrown while reading the rule\n   */\n  private void parseAffix(CharArrayMap<List<HunspellAffix>> affixes,\n                          String header,\n                          LineNumberReader reader,\n                          String conditionPattern,\n                          boolean strict) throws IOException, ParseException {\n    String args[] = header.split(\"\\\\s+\");\n\n    boolean crossProduct = args[2].equals(\"Y\");\n    \n    int numLines = Integer.parseInt(args[3]);\n    for (int i = 0; i < numLines; i++) {\n      String line = reader.readLine();\n      String ruleArgs[] = line.split(\"\\\\s+\");\n\n      if (ruleArgs.length < 5) {\n        if (strict) {\n          throw new ParseException(\"The affix file contains a rule with less than five elements\", reader.getLineNumber());\n        }\n        continue;\n      }\n\n      HunspellAffix affix = new HunspellAffix();\n      \n      affix.setFlag(flagParsingStrategy.parseFlag(ruleArgs[1]));\n      affix.setStrip(ruleArgs[2].equals(\"0\") ? \"\" : ruleArgs[2]);\n\n      String affixArg = ruleArgs[3];\n      \n      int flagSep = affixArg.lastIndexOf('/');\n      if (flagSep != -1) {\n        String flagPart = affixArg.substring(flagSep + 1);\n        \n        if (aliasCount > 0) {\n          flagPart = getAliasValue(Integer.parseInt(flagPart));\n        } \n        \n        char appendFlags[] = flagParsingStrategy.parseFlags(flagPart);\n        Arrays.sort(appendFlags);\n        affix.setAppendFlags(appendFlags);\n        affix.setAppend(affixArg.substring(0, flagSep));\n      } else {\n        affix.setAppend(affixArg);\n      }\n\n      String condition = ruleArgs[4];\n      affix.setCondition(condition, String.format(Locale.ROOT, conditionPattern, condition));\n      affix.setCrossProduct(crossProduct);\n      \n      List<HunspellAffix> list = affixes.get(affix.getAppend());\n      if (list == null) {\n        list = new ArrayList<HunspellAffix>();\n        affixes.put(affix.getAppend(), list);\n      }\n      \n      list.add(affix);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5ae9942cbee38a49d234c2f022e3a265133d1914","date":1393952688,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#parseAffix(TreeMap[String,List[Character]],String,LineNumberReader,String,Map[String,Integer]).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#parseAffix(TreeMap[String,List[Character]],String,LineNumberReader,String,Map[String,Integer]).mjava","sourceNew":"  /**\n   * Parses a specific affix rule putting the result into the provided affix map\n   * \n   * @param affixes Map where the result of the parsing will be put\n   * @param header Header line of the affix rule\n   * @param reader BufferedReader to read the content of the rule from\n   * @param conditionPattern {@link String#format(String, Object...)} pattern to be used to generate the condition regex\n   *                         pattern\n   * @param seenPatterns map from condition -> index of patterns, for deduplication.\n   * @throws IOException Can be thrown while reading the rule\n   */\n  private void parseAffix(TreeMap<String,List<Character>> affixes,\n                          String header,\n                          LineNumberReader reader,\n                          String conditionPattern,\n                          Map<String,Integer> seenPatterns) throws IOException, ParseException {\n    \n    BytesRef scratch = new BytesRef();\n    StringBuilder sb = new StringBuilder();\n    String args[] = header.split(\"\\\\s+\");\n\n    boolean crossProduct = args[2].equals(\"Y\");\n    \n    int numLines = Integer.parseInt(args[3]);\n    affixData = ArrayUtil.grow(affixData, (currentAffix << 3) + (numLines << 3));\n    ByteArrayDataOutput affixWriter = new ByteArrayDataOutput(affixData, currentAffix << 3, numLines << 3);\n    \n    for (int i = 0; i < numLines; i++) {\n      assert affixWriter.getPosition() == currentAffix << 3;\n      String line = reader.readLine();\n      String ruleArgs[] = line.split(\"\\\\s+\");\n\n      if (ruleArgs.length < 5) {\n          throw new ParseException(\"The affix file contains a rule with less than five elements\", reader.getLineNumber());\n      }\n      \n      char flag = flagParsingStrategy.parseFlag(ruleArgs[1]);\n      String strip = ruleArgs[2].equals(\"0\") ? \"\" : ruleArgs[2];\n      String affixArg = ruleArgs[3];\n      char appendFlags[] = null;\n      \n      int flagSep = affixArg.lastIndexOf('/');\n      if (flagSep != -1) {\n        String flagPart = affixArg.substring(flagSep + 1);\n        affixArg = affixArg.substring(0, flagSep);\n\n        if (aliasCount > 0) {\n          flagPart = getAliasValue(Integer.parseInt(flagPart));\n        } \n        \n        appendFlags = flagParsingStrategy.parseFlags(flagPart);\n        Arrays.sort(appendFlags);\n      }\n\n      String condition = ruleArgs[4];\n      // at least the gascon affix file has this issue\n      if (condition.startsWith(\"[\") && !condition.endsWith(\"]\")) {\n        condition = condition + \"]\";\n      }\n      // \"dash hasn't got special meaning\" (we must escape it)\n      if (condition.indexOf('-') >= 0) {\n        condition = condition.replace(\"-\", \"\\\\-\");\n      }\n\n      String regex = String.format(Locale.ROOT, conditionPattern, condition);\n      \n      // deduplicate patterns\n      Integer patternIndex = seenPatterns.get(regex);\n      if (patternIndex == null) {\n        patternIndex = patterns.size();\n        if (patternIndex > Short.MAX_VALUE) {\n          throw new UnsupportedOperationException(\"Too many patterns, please report this to dev@lucene.apache.org\");          \n        }\n        seenPatterns.put(regex, patternIndex);\n        Pattern pattern = Pattern.compile(regex);\n        patterns.add(pattern);\n      }\n      \n      scratch.copyChars(strip);\n      int stripOrd = stripLookup.add(scratch);\n      if (stripOrd < 0) {\n        // already exists in our hash\n        stripOrd = (-stripOrd)-1;\n      } else if (stripOrd > Character.MAX_VALUE) {\n        throw new UnsupportedOperationException(\"Too many unique strips, please report this to dev@lucene.apache.org\");\n      }\n\n      if (appendFlags == null) {\n        appendFlags = NOFLAGS;\n      }\n      \n      final int hashCode = encodeFlagsWithHash(scratch, appendFlags);\n      int appendFlagsOrd = flagLookup.add(scratch, hashCode);\n      if (appendFlagsOrd < 0) {\n        // already exists in our hash\n        appendFlagsOrd = (-appendFlagsOrd)-1;\n      } else if (appendFlagsOrd > Short.MAX_VALUE) {\n        // this limit is probably flexible, but its a good sanity check too\n        throw new UnsupportedOperationException(\"Too many unique append flags, please report this to dev@lucene.apache.org\");\n      }\n      \n      affixWriter.writeShort((short)flag);\n      affixWriter.writeShort((short)stripOrd);\n      // encode crossProduct into patternIndex\n      int patternOrd = patternIndex.intValue() << 1 | (crossProduct ? 1 : 0);\n      affixWriter.writeShort((short)patternOrd);\n      affixWriter.writeShort((short)appendFlagsOrd);\n      \n      if (needsInputCleaning) {\n        CharSequence cleaned = cleanInput(affixArg, sb);\n        affixArg = cleaned.toString();\n      }\n      \n      List<Character> list = affixes.get(affixArg);\n      if (list == null) {\n        list = new ArrayList<Character>();\n        affixes.put(affixArg, list);\n      }\n      \n      list.add((char)currentAffix);\n      currentAffix++;\n    }\n  }\n\n","sourceOld":"  /**\n   * Parses a specific affix rule putting the result into the provided affix map\n   * \n   * @param affixes Map where the result of the parsing will be put\n   * @param header Header line of the affix rule\n   * @param reader BufferedReader to read the content of the rule from\n   * @param conditionPattern {@link String#format(String, Object...)} pattern to be used to generate the condition regex\n   *                         pattern\n   * @param seenPatterns map from condition -> index of patterns, for deduplication.\n   * @throws IOException Can be thrown while reading the rule\n   */\n  private void parseAffix(TreeMap<String,List<Character>> affixes,\n                          String header,\n                          LineNumberReader reader,\n                          String conditionPattern,\n                          Map<String,Integer> seenPatterns) throws IOException, ParseException {\n    \n    BytesRef scratch = new BytesRef();\n    String args[] = header.split(\"\\\\s+\");\n\n    boolean crossProduct = args[2].equals(\"Y\");\n    \n    int numLines = Integer.parseInt(args[3]);\n    affixData = ArrayUtil.grow(affixData, (currentAffix << 3) + (numLines << 3));\n    ByteArrayDataOutput affixWriter = new ByteArrayDataOutput(affixData, currentAffix << 3, numLines << 3);\n    \n    for (int i = 0; i < numLines; i++) {\n      if (currentAffix > Short.MAX_VALUE) {\n        throw new UnsupportedOperationException(\"Too many affixes, please report this to dev@lucene.apache.org\");\n      }\n      assert affixWriter.getPosition() == currentAffix << 3;\n      String line = reader.readLine();\n      String ruleArgs[] = line.split(\"\\\\s+\");\n\n      if (ruleArgs.length < 5) {\n          throw new ParseException(\"The affix file contains a rule with less than five elements\", reader.getLineNumber());\n      }\n      \n      char flag = flagParsingStrategy.parseFlag(ruleArgs[1]);\n      String strip = ruleArgs[2].equals(\"0\") ? \"\" : ruleArgs[2];\n      String affixArg = ruleArgs[3];\n      char appendFlags[] = null;\n      \n      int flagSep = affixArg.lastIndexOf('/');\n      if (flagSep != -1) {\n        String flagPart = affixArg.substring(flagSep + 1);\n        affixArg = affixArg.substring(0, flagSep);\n\n        if (aliasCount > 0) {\n          flagPart = getAliasValue(Integer.parseInt(flagPart));\n        } \n        \n        appendFlags = flagParsingStrategy.parseFlags(flagPart);\n        Arrays.sort(appendFlags);\n      }\n\n      String condition = ruleArgs[4];\n      // at least the gascon affix file has this issue\n      if (condition.startsWith(\"[\") && !condition.endsWith(\"]\")) {\n        condition = condition + \"]\";\n      }\n      // \"dash hasn't got special meaning\" (we must escape it)\n      if (condition.indexOf('-') >= 0) {\n        condition = condition.replace(\"-\", \"\\\\-\");\n      }\n\n      String regex = String.format(Locale.ROOT, conditionPattern, condition);\n      \n      // deduplicate patterns\n      Integer patternIndex = seenPatterns.get(regex);\n      if (patternIndex == null) {\n        patternIndex = patterns.size();\n        seenPatterns.put(regex, patternIndex);\n        Pattern pattern = Pattern.compile(regex);\n        patterns.add(pattern);\n      }\n      \n      scratch.copyChars(strip);\n      int stripOrd = stripLookup.add(scratch);\n      if (stripOrd < 0) {\n        // already exists in our hash\n        stripOrd = (-stripOrd)-1;\n      }\n\n      if (appendFlags == null) {\n        appendFlags = NOFLAGS;\n      }\n      \n      final int hashCode = encodeFlagsWithHash(scratch, appendFlags);\n      int appendFlagsOrd = flagLookup.add(scratch, hashCode);\n      if (appendFlagsOrd < 0) {\n        // already exists in our hash\n        appendFlagsOrd = (-appendFlagsOrd)-1;\n      } else if (appendFlagsOrd > Short.MAX_VALUE) {\n        // this limit is probably flexible, but its a good sanity check too\n        throw new UnsupportedOperationException(\"Too many unique flags, please report this to dev@lucene.apache.org\");\n      }\n      \n      affixWriter.writeShort((short)flag);\n      affixWriter.writeShort((short)stripOrd);\n      // encode crossProduct into patternIndex\n      int patternOrd = patternIndex.intValue() << 1 | (crossProduct ? 1 : 0);\n      affixWriter.writeShort((short)patternOrd);\n      affixWriter.writeShort((short)appendFlagsOrd);\n      \n      List<Character> list = affixes.get(affixArg);\n      if (list == null) {\n        list = new ArrayList<Character>();\n        affixes.put(affixArg, list);\n      }\n      \n      list.add((char)currentAffix);\n      currentAffix++;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"96ea64d994d340044e0d57aeb6a5871539d10ca5","date":1394225445,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#parseAffix(TreeMap[String,List[Character]],String,LineNumberReader,String,Map[String,Integer]).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#parseAffix(TreeMap[String,List[Character]],String,LineNumberReader,String,Map[String,Integer]).mjava","sourceNew":"  /**\n   * Parses a specific affix rule putting the result into the provided affix map\n   * \n   * @param affixes Map where the result of the parsing will be put\n   * @param header Header line of the affix rule\n   * @param reader BufferedReader to read the content of the rule from\n   * @param conditionPattern {@link String#format(String, Object...)} pattern to be used to generate the condition regex\n   *                         pattern\n   * @param seenPatterns map from condition -> index of patterns, for deduplication.\n   * @throws IOException Can be thrown while reading the rule\n   */\n  private void parseAffix(TreeMap<String,List<Character>> affixes,\n                          String header,\n                          LineNumberReader reader,\n                          String conditionPattern,\n                          Map<String,Integer> seenPatterns) throws IOException, ParseException {\n    \n    BytesRef scratch = new BytesRef();\n    StringBuilder sb = new StringBuilder();\n    String args[] = header.split(\"\\\\s+\");\n\n    boolean crossProduct = args[2].equals(\"Y\");\n    \n    int numLines = Integer.parseInt(args[3]);\n    affixData = ArrayUtil.grow(affixData, (currentAffix << 3) + (numLines << 3));\n    ByteArrayDataOutput affixWriter = new ByteArrayDataOutput(affixData, currentAffix << 3, numLines << 3);\n    \n    for (int i = 0; i < numLines; i++) {\n      assert affixWriter.getPosition() == currentAffix << 3;\n      String line = reader.readLine();\n      String ruleArgs[] = line.split(\"\\\\s+\");\n\n      if (ruleArgs.length < 5) {\n          throw new ParseException(\"The affix file contains a rule with less than five elements\", reader.getLineNumber());\n      }\n      \n      char flag = flagParsingStrategy.parseFlag(ruleArgs[1]);\n      String strip = ruleArgs[2].equals(\"0\") ? \"\" : ruleArgs[2];\n      String affixArg = ruleArgs[3];\n      char appendFlags[] = null;\n      \n      int flagSep = affixArg.lastIndexOf('/');\n      if (flagSep != -1) {\n        String flagPart = affixArg.substring(flagSep + 1);\n        affixArg = affixArg.substring(0, flagSep);\n\n        if (aliasCount > 0) {\n          flagPart = getAliasValue(Integer.parseInt(flagPart));\n        } \n        \n        appendFlags = flagParsingStrategy.parseFlags(flagPart);\n        Arrays.sort(appendFlags);\n      }\n\n      String condition = ruleArgs[4];\n      // at least the gascon affix file has this issue\n      if (condition.startsWith(\"[\") && !condition.endsWith(\"]\")) {\n        condition = condition + \"]\";\n      }\n      // \"dash hasn't got special meaning\" (we must escape it)\n      if (condition.indexOf('-') >= 0) {\n        condition = condition.replace(\"-\", \"\\\\-\");\n      }\n\n      String regex = String.format(Locale.ROOT, conditionPattern, condition);\n      \n      // deduplicate patterns\n      Integer patternIndex = seenPatterns.get(regex);\n      if (patternIndex == null) {\n        patternIndex = patterns.size();\n        if (patternIndex > Short.MAX_VALUE) {\n          throw new UnsupportedOperationException(\"Too many patterns, please report this to dev@lucene.apache.org\");          \n        }\n        seenPatterns.put(regex, patternIndex);\n        Pattern pattern = Pattern.compile(regex);\n        patterns.add(pattern);\n      }\n      \n      scratch.copyChars(strip);\n      int stripOrd = stripLookup.add(scratch);\n      if (stripOrd < 0) {\n        // already exists in our hash\n        stripOrd = (-stripOrd)-1;\n      } else if (stripOrd > Character.MAX_VALUE) {\n        throw new UnsupportedOperationException(\"Too many unique strips, please report this to dev@lucene.apache.org\");\n      }\n\n      if (appendFlags == null) {\n        appendFlags = NOFLAGS;\n      }\n      \n      final int hashCode = encodeFlagsWithHash(scratch, appendFlags);\n      int appendFlagsOrd = flagLookup.add(scratch, hashCode);\n      if (appendFlagsOrd < 0) {\n        // already exists in our hash\n        appendFlagsOrd = (-appendFlagsOrd)-1;\n      } else if (appendFlagsOrd > Short.MAX_VALUE) {\n        // this limit is probably flexible, but its a good sanity check too\n        throw new UnsupportedOperationException(\"Too many unique append flags, please report this to dev@lucene.apache.org\");\n      }\n      \n      affixWriter.writeShort((short)flag);\n      affixWriter.writeShort((short)stripOrd);\n      // encode crossProduct into patternIndex\n      int patternOrd = patternIndex.intValue() << 1 | (crossProduct ? 1 : 0);\n      affixWriter.writeShort((short)patternOrd);\n      affixWriter.writeShort((short)appendFlagsOrd);\n      \n      if (needsInputCleaning) {\n        CharSequence cleaned = cleanInput(affixArg, sb);\n        affixArg = cleaned.toString();\n      }\n      \n      List<Character> list = affixes.get(affixArg);\n      if (list == null) {\n        list = new ArrayList<Character>();\n        affixes.put(affixArg, list);\n      }\n      \n      list.add((char)currentAffix);\n      currentAffix++;\n    }\n  }\n\n","sourceOld":"  /**\n   * Parses a specific affix rule putting the result into the provided affix map\n   * \n   * @param affixes Map where the result of the parsing will be put\n   * @param header Header line of the affix rule\n   * @param reader BufferedReader to read the content of the rule from\n   * @param conditionPattern {@link String#format(String, Object...)} pattern to be used to generate the condition regex\n   *                         pattern\n   * @param seenPatterns map from condition -> index of patterns, for deduplication.\n   * @throws IOException Can be thrown while reading the rule\n   */\n  private void parseAffix(TreeMap<String,List<Character>> affixes,\n                          String header,\n                          LineNumberReader reader,\n                          String conditionPattern,\n                          Map<String,Integer> seenPatterns) throws IOException, ParseException {\n    \n    BytesRef scratch = new BytesRef();\n    String args[] = header.split(\"\\\\s+\");\n\n    boolean crossProduct = args[2].equals(\"Y\");\n    \n    int numLines = Integer.parseInt(args[3]);\n    affixData = ArrayUtil.grow(affixData, (currentAffix << 3) + (numLines << 3));\n    ByteArrayDataOutput affixWriter = new ByteArrayDataOutput(affixData, currentAffix << 3, numLines << 3);\n    \n    for (int i = 0; i < numLines; i++) {\n      if (currentAffix > Short.MAX_VALUE) {\n        throw new UnsupportedOperationException(\"Too many affixes, please report this to dev@lucene.apache.org\");\n      }\n      assert affixWriter.getPosition() == currentAffix << 3;\n      String line = reader.readLine();\n      String ruleArgs[] = line.split(\"\\\\s+\");\n\n      if (ruleArgs.length < 5) {\n          throw new ParseException(\"The affix file contains a rule with less than five elements\", reader.getLineNumber());\n      }\n      \n      char flag = flagParsingStrategy.parseFlag(ruleArgs[1]);\n      String strip = ruleArgs[2].equals(\"0\") ? \"\" : ruleArgs[2];\n      String affixArg = ruleArgs[3];\n      char appendFlags[] = null;\n      \n      int flagSep = affixArg.lastIndexOf('/');\n      if (flagSep != -1) {\n        String flagPart = affixArg.substring(flagSep + 1);\n        affixArg = affixArg.substring(0, flagSep);\n\n        if (aliasCount > 0) {\n          flagPart = getAliasValue(Integer.parseInt(flagPart));\n        } \n        \n        appendFlags = flagParsingStrategy.parseFlags(flagPart);\n        Arrays.sort(appendFlags);\n      }\n\n      String condition = ruleArgs[4];\n      // at least the gascon affix file has this issue\n      if (condition.startsWith(\"[\") && !condition.endsWith(\"]\")) {\n        condition = condition + \"]\";\n      }\n      // \"dash hasn't got special meaning\" (we must escape it)\n      if (condition.indexOf('-') >= 0) {\n        condition = condition.replace(\"-\", \"\\\\-\");\n      }\n\n      String regex = String.format(Locale.ROOT, conditionPattern, condition);\n      \n      // deduplicate patterns\n      Integer patternIndex = seenPatterns.get(regex);\n      if (patternIndex == null) {\n        patternIndex = patterns.size();\n        seenPatterns.put(regex, patternIndex);\n        Pattern pattern = Pattern.compile(regex);\n        patterns.add(pattern);\n      }\n      \n      scratch.copyChars(strip);\n      int stripOrd = stripLookup.add(scratch);\n      if (stripOrd < 0) {\n        // already exists in our hash\n        stripOrd = (-stripOrd)-1;\n      }\n\n      if (appendFlags == null) {\n        appendFlags = NOFLAGS;\n      }\n      \n      final int hashCode = encodeFlagsWithHash(scratch, appendFlags);\n      int appendFlagsOrd = flagLookup.add(scratch, hashCode);\n      if (appendFlagsOrd < 0) {\n        // already exists in our hash\n        appendFlagsOrd = (-appendFlagsOrd)-1;\n      } else if (appendFlagsOrd > Short.MAX_VALUE) {\n        // this limit is probably flexible, but its a good sanity check too\n        throw new UnsupportedOperationException(\"Too many unique flags, please report this to dev@lucene.apache.org\");\n      }\n      \n      affixWriter.writeShort((short)flag);\n      affixWriter.writeShort((short)stripOrd);\n      // encode crossProduct into patternIndex\n      int patternOrd = patternIndex.intValue() << 1 | (crossProduct ? 1 : 0);\n      affixWriter.writeShort((short)patternOrd);\n      affixWriter.writeShort((short)appendFlagsOrd);\n      \n      List<Character> list = affixes.get(affixArg);\n      if (list == null) {\n        list = new ArrayList<Character>();\n        affixes.put(affixArg, list);\n      }\n      \n      list.add((char)currentAffix);\n      currentAffix++;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b6b9214e93abd5c360b7dc32483691d5555a9c7e","date":1394289706,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#parseAffix(TreeMap[String,List[Character]],String,LineNumberReader,String,Map[String,Integer]).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#parseAffix(TreeMap[String,List[Character]],String,LineNumberReader,String,Map[String,Integer]).mjava","sourceNew":"  /**\n   * Parses a specific affix rule putting the result into the provided affix map\n   * \n   * @param affixes Map where the result of the parsing will be put\n   * @param header Header line of the affix rule\n   * @param reader BufferedReader to read the content of the rule from\n   * @param conditionPattern {@link String#format(String, Object...)} pattern to be used to generate the condition regex\n   *                         pattern\n   * @param seenPatterns map from condition -> index of patterns, for deduplication.\n   * @throws IOException Can be thrown while reading the rule\n   */\n  private void parseAffix(TreeMap<String,List<Character>> affixes,\n                          String header,\n                          LineNumberReader reader,\n                          String conditionPattern,\n                          Map<String,Integer> seenPatterns) throws IOException, ParseException {\n    \n    BytesRef scratch = new BytesRef();\n    StringBuilder sb = new StringBuilder();\n    String args[] = header.split(\"\\\\s+\");\n\n    boolean crossProduct = args[2].equals(\"Y\");\n    \n    int numLines = Integer.parseInt(args[3]);\n    affixData = ArrayUtil.grow(affixData, (currentAffix << 3) + (numLines << 3));\n    ByteArrayDataOutput affixWriter = new ByteArrayDataOutput(affixData, currentAffix << 3, numLines << 3);\n    \n    for (int i = 0; i < numLines; i++) {\n      assert affixWriter.getPosition() == currentAffix << 3;\n      String line = reader.readLine();\n      String ruleArgs[] = line.split(\"\\\\s+\");\n\n      // from the manpage: PFX flag stripping prefix [condition [morphological_fields...]]\n      // condition is optional\n      if (ruleArgs.length < 4) {\n          throw new ParseException(\"The affix file contains a rule with less than four elements: \" + line, reader.getLineNumber());\n      }\n      \n      char flag = flagParsingStrategy.parseFlag(ruleArgs[1]);\n      String strip = ruleArgs[2].equals(\"0\") ? \"\" : ruleArgs[2];\n      String affixArg = ruleArgs[3];\n      char appendFlags[] = null;\n      \n      int flagSep = affixArg.lastIndexOf('/');\n      if (flagSep != -1) {\n        String flagPart = affixArg.substring(flagSep + 1);\n        affixArg = affixArg.substring(0, flagSep);\n\n        if (aliasCount > 0) {\n          flagPart = getAliasValue(Integer.parseInt(flagPart));\n        } \n        \n        appendFlags = flagParsingStrategy.parseFlags(flagPart);\n        Arrays.sort(appendFlags);\n      }\n\n      String condition = ruleArgs.length > 4 ? ruleArgs[4] : \".\";\n      // at least the gascon affix file has this issue\n      if (condition.startsWith(\"[\") && !condition.endsWith(\"]\")) {\n        condition = condition + \"]\";\n      }\n      // \"dash hasn't got special meaning\" (we must escape it)\n      if (condition.indexOf('-') >= 0) {\n        condition = condition.replace(\"-\", \"\\\\-\");\n      }\n\n      String regex = String.format(Locale.ROOT, conditionPattern, condition);\n      \n      // deduplicate patterns\n      Integer patternIndex = seenPatterns.get(regex);\n      if (patternIndex == null) {\n        patternIndex = patterns.size();\n        if (patternIndex > Short.MAX_VALUE) {\n          throw new UnsupportedOperationException(\"Too many patterns, please report this to dev@lucene.apache.org\");          \n        }\n        seenPatterns.put(regex, patternIndex);\n        Pattern pattern = Pattern.compile(regex);\n        patterns.add(pattern);\n      }\n      \n      scratch.copyChars(strip);\n      int stripOrd = stripLookup.add(scratch);\n      if (stripOrd < 0) {\n        // already exists in our hash\n        stripOrd = (-stripOrd)-1;\n      } else if (stripOrd > Character.MAX_VALUE) {\n        throw new UnsupportedOperationException(\"Too many unique strips, please report this to dev@lucene.apache.org\");\n      }\n\n      if (appendFlags == null) {\n        appendFlags = NOFLAGS;\n      }\n      \n      final int hashCode = encodeFlagsWithHash(scratch, appendFlags);\n      int appendFlagsOrd = flagLookup.add(scratch, hashCode);\n      if (appendFlagsOrd < 0) {\n        // already exists in our hash\n        appendFlagsOrd = (-appendFlagsOrd)-1;\n      } else if (appendFlagsOrd > Short.MAX_VALUE) {\n        // this limit is probably flexible, but its a good sanity check too\n        throw new UnsupportedOperationException(\"Too many unique append flags, please report this to dev@lucene.apache.org\");\n      }\n      \n      affixWriter.writeShort((short)flag);\n      affixWriter.writeShort((short)stripOrd);\n      // encode crossProduct into patternIndex\n      int patternOrd = patternIndex.intValue() << 1 | (crossProduct ? 1 : 0);\n      affixWriter.writeShort((short)patternOrd);\n      affixWriter.writeShort((short)appendFlagsOrd);\n      \n      if (needsInputCleaning) {\n        CharSequence cleaned = cleanInput(affixArg, sb);\n        affixArg = cleaned.toString();\n      }\n      \n      List<Character> list = affixes.get(affixArg);\n      if (list == null) {\n        list = new ArrayList<Character>();\n        affixes.put(affixArg, list);\n      }\n      \n      list.add((char)currentAffix);\n      currentAffix++;\n    }\n  }\n\n","sourceOld":"  /**\n   * Parses a specific affix rule putting the result into the provided affix map\n   * \n   * @param affixes Map where the result of the parsing will be put\n   * @param header Header line of the affix rule\n   * @param reader BufferedReader to read the content of the rule from\n   * @param conditionPattern {@link String#format(String, Object...)} pattern to be used to generate the condition regex\n   *                         pattern\n   * @param seenPatterns map from condition -> index of patterns, for deduplication.\n   * @throws IOException Can be thrown while reading the rule\n   */\n  private void parseAffix(TreeMap<String,List<Character>> affixes,\n                          String header,\n                          LineNumberReader reader,\n                          String conditionPattern,\n                          Map<String,Integer> seenPatterns) throws IOException, ParseException {\n    \n    BytesRef scratch = new BytesRef();\n    StringBuilder sb = new StringBuilder();\n    String args[] = header.split(\"\\\\s+\");\n\n    boolean crossProduct = args[2].equals(\"Y\");\n    \n    int numLines = Integer.parseInt(args[3]);\n    affixData = ArrayUtil.grow(affixData, (currentAffix << 3) + (numLines << 3));\n    ByteArrayDataOutput affixWriter = new ByteArrayDataOutput(affixData, currentAffix << 3, numLines << 3);\n    \n    for (int i = 0; i < numLines; i++) {\n      assert affixWriter.getPosition() == currentAffix << 3;\n      String line = reader.readLine();\n      String ruleArgs[] = line.split(\"\\\\s+\");\n\n      if (ruleArgs.length < 5) {\n          throw new ParseException(\"The affix file contains a rule with less than five elements\", reader.getLineNumber());\n      }\n      \n      char flag = flagParsingStrategy.parseFlag(ruleArgs[1]);\n      String strip = ruleArgs[2].equals(\"0\") ? \"\" : ruleArgs[2];\n      String affixArg = ruleArgs[3];\n      char appendFlags[] = null;\n      \n      int flagSep = affixArg.lastIndexOf('/');\n      if (flagSep != -1) {\n        String flagPart = affixArg.substring(flagSep + 1);\n        affixArg = affixArg.substring(0, flagSep);\n\n        if (aliasCount > 0) {\n          flagPart = getAliasValue(Integer.parseInt(flagPart));\n        } \n        \n        appendFlags = flagParsingStrategy.parseFlags(flagPart);\n        Arrays.sort(appendFlags);\n      }\n\n      String condition = ruleArgs[4];\n      // at least the gascon affix file has this issue\n      if (condition.startsWith(\"[\") && !condition.endsWith(\"]\")) {\n        condition = condition + \"]\";\n      }\n      // \"dash hasn't got special meaning\" (we must escape it)\n      if (condition.indexOf('-') >= 0) {\n        condition = condition.replace(\"-\", \"\\\\-\");\n      }\n\n      String regex = String.format(Locale.ROOT, conditionPattern, condition);\n      \n      // deduplicate patterns\n      Integer patternIndex = seenPatterns.get(regex);\n      if (patternIndex == null) {\n        patternIndex = patterns.size();\n        if (patternIndex > Short.MAX_VALUE) {\n          throw new UnsupportedOperationException(\"Too many patterns, please report this to dev@lucene.apache.org\");          \n        }\n        seenPatterns.put(regex, patternIndex);\n        Pattern pattern = Pattern.compile(regex);\n        patterns.add(pattern);\n      }\n      \n      scratch.copyChars(strip);\n      int stripOrd = stripLookup.add(scratch);\n      if (stripOrd < 0) {\n        // already exists in our hash\n        stripOrd = (-stripOrd)-1;\n      } else if (stripOrd > Character.MAX_VALUE) {\n        throw new UnsupportedOperationException(\"Too many unique strips, please report this to dev@lucene.apache.org\");\n      }\n\n      if (appendFlags == null) {\n        appendFlags = NOFLAGS;\n      }\n      \n      final int hashCode = encodeFlagsWithHash(scratch, appendFlags);\n      int appendFlagsOrd = flagLookup.add(scratch, hashCode);\n      if (appendFlagsOrd < 0) {\n        // already exists in our hash\n        appendFlagsOrd = (-appendFlagsOrd)-1;\n      } else if (appendFlagsOrd > Short.MAX_VALUE) {\n        // this limit is probably flexible, but its a good sanity check too\n        throw new UnsupportedOperationException(\"Too many unique append flags, please report this to dev@lucene.apache.org\");\n      }\n      \n      affixWriter.writeShort((short)flag);\n      affixWriter.writeShort((short)stripOrd);\n      // encode crossProduct into patternIndex\n      int patternOrd = patternIndex.intValue() << 1 | (crossProduct ? 1 : 0);\n      affixWriter.writeShort((short)patternOrd);\n      affixWriter.writeShort((short)appendFlagsOrd);\n      \n      if (needsInputCleaning) {\n        CharSequence cleaned = cleanInput(affixArg, sb);\n        affixArg = cleaned.toString();\n      }\n      \n      List<Character> list = affixes.get(affixArg);\n      if (list == null) {\n        list = new ArrayList<Character>();\n        affixes.put(affixArg, list);\n      }\n      \n      list.add((char)currentAffix);\n      currentAffix++;\n    }\n  }\n\n","bugFix":["c214bc712d04c78c4d434119d560d0a4dd2fce4f"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a58bbbe1c866963764d3f15d3a26a6a85f6c6af4","date":1394564625,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#parseAffix(TreeMap[String,List[Character]],String,LineNumberReader,String,Map[String,Integer]).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#parseAffix(TreeMap[String,List[Character]],String,LineNumberReader,String,Map[String,Integer]).mjava","sourceNew":"  /**\n   * Parses a specific affix rule putting the result into the provided affix map\n   * \n   * @param affixes Map where the result of the parsing will be put\n   * @param header Header line of the affix rule\n   * @param reader BufferedReader to read the content of the rule from\n   * @param conditionPattern {@link String#format(String, Object...)} pattern to be used to generate the condition regex\n   *                         pattern\n   * @param seenPatterns map from condition -> index of patterns, for deduplication.\n   * @throws IOException Can be thrown while reading the rule\n   */\n  private void parseAffix(TreeMap<String,List<Character>> affixes,\n                          String header,\n                          LineNumberReader reader,\n                          String conditionPattern,\n                          Map<String,Integer> seenPatterns) throws IOException, ParseException {\n    \n    BytesRef scratch = new BytesRef();\n    StringBuilder sb = new StringBuilder();\n    String args[] = header.split(\"\\\\s+\");\n\n    boolean crossProduct = args[2].equals(\"Y\");\n    \n    int numLines = Integer.parseInt(args[3]);\n    affixData = ArrayUtil.grow(affixData, (currentAffix << 3) + (numLines << 3));\n    ByteArrayDataOutput affixWriter = new ByteArrayDataOutput(affixData, currentAffix << 3, numLines << 3);\n    \n    for (int i = 0; i < numLines; i++) {\n      assert affixWriter.getPosition() == currentAffix << 3;\n      String line = reader.readLine();\n      String ruleArgs[] = line.split(\"\\\\s+\");\n\n      // from the manpage: PFX flag stripping prefix [condition [morphological_fields...]]\n      // condition is optional\n      if (ruleArgs.length < 4) {\n          throw new ParseException(\"The affix file contains a rule with less than four elements: \" + line, reader.getLineNumber());\n      }\n      \n      char flag = flagParsingStrategy.parseFlag(ruleArgs[1]);\n      String strip = ruleArgs[2].equals(\"0\") ? \"\" : ruleArgs[2];\n      String affixArg = ruleArgs[3];\n      char appendFlags[] = null;\n      \n      int flagSep = affixArg.lastIndexOf('/');\n      if (flagSep != -1) {\n        String flagPart = affixArg.substring(flagSep + 1);\n        affixArg = affixArg.substring(0, flagSep);\n\n        if (aliasCount > 0) {\n          flagPart = getAliasValue(Integer.parseInt(flagPart));\n        } \n        \n        appendFlags = flagParsingStrategy.parseFlags(flagPart);\n        Arrays.sort(appendFlags);\n      }\n\n      String condition = ruleArgs.length > 4 ? ruleArgs[4] : \".\";\n      // at least the gascon affix file has this issue\n      if (condition.startsWith(\"[\") && !condition.endsWith(\"]\")) {\n        condition = condition + \"]\";\n      }\n      // \"dash hasn't got special meaning\" (we must escape it)\n      if (condition.indexOf('-') >= 0) {\n        condition = condition.replace(\"-\", \"\\\\-\");\n      }\n\n      String regex = String.format(Locale.ROOT, conditionPattern, condition);\n      \n      // deduplicate patterns\n      Integer patternIndex = seenPatterns.get(regex);\n      if (patternIndex == null) {\n        patternIndex = patterns.size();\n        if (patternIndex > Short.MAX_VALUE) {\n          throw new UnsupportedOperationException(\"Too many patterns, please report this to dev@lucene.apache.org\");          \n        }\n        seenPatterns.put(regex, patternIndex);\n        Pattern pattern = Pattern.compile(regex);\n        patterns.add(pattern);\n      }\n      \n      scratch.copyChars(strip);\n      int stripOrd = stripLookup.add(scratch);\n      if (stripOrd < 0) {\n        // already exists in our hash\n        stripOrd = (-stripOrd)-1;\n      } else if (stripOrd > Character.MAX_VALUE) {\n        throw new UnsupportedOperationException(\"Too many unique strips, please report this to dev@lucene.apache.org\");\n      }\n\n      if (appendFlags == null) {\n        appendFlags = NOFLAGS;\n      }\n      \n      final int hashCode = encodeFlagsWithHash(scratch, appendFlags);\n      int appendFlagsOrd = flagLookup.add(scratch, hashCode);\n      if (appendFlagsOrd < 0) {\n        // already exists in our hash\n        appendFlagsOrd = (-appendFlagsOrd)-1;\n      } else if (appendFlagsOrd > Short.MAX_VALUE) {\n        // this limit is probably flexible, but its a good sanity check too\n        throw new UnsupportedOperationException(\"Too many unique append flags, please report this to dev@lucene.apache.org\");\n      }\n      \n      affixWriter.writeShort((short)flag);\n      affixWriter.writeShort((short)stripOrd);\n      // encode crossProduct into patternIndex\n      int patternOrd = patternIndex.intValue() << 1 | (crossProduct ? 1 : 0);\n      affixWriter.writeShort((short)patternOrd);\n      affixWriter.writeShort((short)appendFlagsOrd);\n      \n      if (needsInputCleaning) {\n        CharSequence cleaned = cleanInput(affixArg, sb);\n        affixArg = cleaned.toString();\n      }\n      \n      List<Character> list = affixes.get(affixArg);\n      if (list == null) {\n        list = new ArrayList<Character>();\n        affixes.put(affixArg, list);\n      }\n      \n      list.add((char)currentAffix);\n      currentAffix++;\n    }\n  }\n\n","sourceOld":"  /**\n   * Parses a specific affix rule putting the result into the provided affix map\n   * \n   * @param affixes Map where the result of the parsing will be put\n   * @param header Header line of the affix rule\n   * @param reader BufferedReader to read the content of the rule from\n   * @param conditionPattern {@link String#format(String, Object...)} pattern to be used to generate the condition regex\n   *                         pattern\n   * @param seenPatterns map from condition -> index of patterns, for deduplication.\n   * @throws IOException Can be thrown while reading the rule\n   */\n  private void parseAffix(TreeMap<String,List<Character>> affixes,\n                          String header,\n                          LineNumberReader reader,\n                          String conditionPattern,\n                          Map<String,Integer> seenPatterns) throws IOException, ParseException {\n    \n    BytesRef scratch = new BytesRef();\n    StringBuilder sb = new StringBuilder();\n    String args[] = header.split(\"\\\\s+\");\n\n    boolean crossProduct = args[2].equals(\"Y\");\n    \n    int numLines = Integer.parseInt(args[3]);\n    affixData = ArrayUtil.grow(affixData, (currentAffix << 3) + (numLines << 3));\n    ByteArrayDataOutput affixWriter = new ByteArrayDataOutput(affixData, currentAffix << 3, numLines << 3);\n    \n    for (int i = 0; i < numLines; i++) {\n      assert affixWriter.getPosition() == currentAffix << 3;\n      String line = reader.readLine();\n      String ruleArgs[] = line.split(\"\\\\s+\");\n\n      if (ruleArgs.length < 5) {\n          throw new ParseException(\"The affix file contains a rule with less than five elements\", reader.getLineNumber());\n      }\n      \n      char flag = flagParsingStrategy.parseFlag(ruleArgs[1]);\n      String strip = ruleArgs[2].equals(\"0\") ? \"\" : ruleArgs[2];\n      String affixArg = ruleArgs[3];\n      char appendFlags[] = null;\n      \n      int flagSep = affixArg.lastIndexOf('/');\n      if (flagSep != -1) {\n        String flagPart = affixArg.substring(flagSep + 1);\n        affixArg = affixArg.substring(0, flagSep);\n\n        if (aliasCount > 0) {\n          flagPart = getAliasValue(Integer.parseInt(flagPart));\n        } \n        \n        appendFlags = flagParsingStrategy.parseFlags(flagPart);\n        Arrays.sort(appendFlags);\n      }\n\n      String condition = ruleArgs[4];\n      // at least the gascon affix file has this issue\n      if (condition.startsWith(\"[\") && !condition.endsWith(\"]\")) {\n        condition = condition + \"]\";\n      }\n      // \"dash hasn't got special meaning\" (we must escape it)\n      if (condition.indexOf('-') >= 0) {\n        condition = condition.replace(\"-\", \"\\\\-\");\n      }\n\n      String regex = String.format(Locale.ROOT, conditionPattern, condition);\n      \n      // deduplicate patterns\n      Integer patternIndex = seenPatterns.get(regex);\n      if (patternIndex == null) {\n        patternIndex = patterns.size();\n        if (patternIndex > Short.MAX_VALUE) {\n          throw new UnsupportedOperationException(\"Too many patterns, please report this to dev@lucene.apache.org\");          \n        }\n        seenPatterns.put(regex, patternIndex);\n        Pattern pattern = Pattern.compile(regex);\n        patterns.add(pattern);\n      }\n      \n      scratch.copyChars(strip);\n      int stripOrd = stripLookup.add(scratch);\n      if (stripOrd < 0) {\n        // already exists in our hash\n        stripOrd = (-stripOrd)-1;\n      } else if (stripOrd > Character.MAX_VALUE) {\n        throw new UnsupportedOperationException(\"Too many unique strips, please report this to dev@lucene.apache.org\");\n      }\n\n      if (appendFlags == null) {\n        appendFlags = NOFLAGS;\n      }\n      \n      final int hashCode = encodeFlagsWithHash(scratch, appendFlags);\n      int appendFlagsOrd = flagLookup.add(scratch, hashCode);\n      if (appendFlagsOrd < 0) {\n        // already exists in our hash\n        appendFlagsOrd = (-appendFlagsOrd)-1;\n      } else if (appendFlagsOrd > Short.MAX_VALUE) {\n        // this limit is probably flexible, but its a good sanity check too\n        throw new UnsupportedOperationException(\"Too many unique append flags, please report this to dev@lucene.apache.org\");\n      }\n      \n      affixWriter.writeShort((short)flag);\n      affixWriter.writeShort((short)stripOrd);\n      // encode crossProduct into patternIndex\n      int patternOrd = patternIndex.intValue() << 1 | (crossProduct ? 1 : 0);\n      affixWriter.writeShort((short)patternOrd);\n      affixWriter.writeShort((short)appendFlagsOrd);\n      \n      if (needsInputCleaning) {\n        CharSequence cleaned = cleanInput(affixArg, sb);\n        affixArg = cleaned.toString();\n      }\n      \n      List<Character> list = affixes.get(affixArg);\n      if (list == null) {\n        list = new ArrayList<Character>();\n        affixes.put(affixArg, list);\n      }\n      \n      list.add((char)currentAffix);\n      currentAffix++;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"09fb4238d56f62faff1f0c866bee53facad482ec","date":1394631888,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#parseAffix(TreeMap[String,List[Character]],String,LineNumberReader,String,Map[String,Integer],Map[String,Integer]).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#parseAffix(TreeMap[String,List[Character]],String,LineNumberReader,String,Map[String,Integer]).mjava","sourceNew":"  /**\n   * Parses a specific affix rule putting the result into the provided affix map\n   * \n   * @param affixes Map where the result of the parsing will be put\n   * @param header Header line of the affix rule\n   * @param reader BufferedReader to read the content of the rule from\n   * @param conditionPattern {@link String#format(String, Object...)} pattern to be used to generate the condition regex\n   *                         pattern\n   * @param seenPatterns map from condition -> index of patterns, for deduplication.\n   * @throws IOException Can be thrown while reading the rule\n   */\n  private void parseAffix(TreeMap<String,List<Character>> affixes,\n                          String header,\n                          LineNumberReader reader,\n                          String conditionPattern,\n                          Map<String,Integer> seenPatterns,\n                          Map<String,Integer> seenStrips) throws IOException, ParseException {\n    \n    BytesRef scratch = new BytesRef();\n    StringBuilder sb = new StringBuilder();\n    String args[] = header.split(\"\\\\s+\");\n\n    boolean crossProduct = args[2].equals(\"Y\");\n    \n    int numLines = Integer.parseInt(args[3]);\n    affixData = ArrayUtil.grow(affixData, (currentAffix << 3) + (numLines << 3));\n    ByteArrayDataOutput affixWriter = new ByteArrayDataOutput(affixData, currentAffix << 3, numLines << 3);\n    \n    for (int i = 0; i < numLines; i++) {\n      assert affixWriter.getPosition() == currentAffix << 3;\n      String line = reader.readLine();\n      String ruleArgs[] = line.split(\"\\\\s+\");\n\n      // from the manpage: PFX flag stripping prefix [condition [morphological_fields...]]\n      // condition is optional\n      if (ruleArgs.length < 4) {\n          throw new ParseException(\"The affix file contains a rule with less than four elements: \" + line, reader.getLineNumber());\n      }\n      \n      char flag = flagParsingStrategy.parseFlag(ruleArgs[1]);\n      String strip = ruleArgs[2].equals(\"0\") ? \"\" : ruleArgs[2];\n      String affixArg = ruleArgs[3];\n      char appendFlags[] = null;\n      \n      int flagSep = affixArg.lastIndexOf('/');\n      if (flagSep != -1) {\n        String flagPart = affixArg.substring(flagSep + 1);\n        affixArg = affixArg.substring(0, flagSep);\n\n        if (aliasCount > 0) {\n          flagPart = getAliasValue(Integer.parseInt(flagPart));\n        } \n        \n        appendFlags = flagParsingStrategy.parseFlags(flagPart);\n        Arrays.sort(appendFlags);\n        twoStageAffix = true;\n      }\n      \n      // TODO: add test and fix zero-affix handling!\n\n      String condition = ruleArgs.length > 4 ? ruleArgs[4] : \".\";\n      // at least the gascon affix file has this issue\n      if (condition.startsWith(\"[\") && !condition.endsWith(\"]\")) {\n        condition = condition + \"]\";\n      }\n      // \"dash hasn't got special meaning\" (we must escape it)\n      if (condition.indexOf('-') >= 0) {\n        condition = condition.replace(\"-\", \"\\\\-\");\n      }\n\n      final String regex;\n      if (\".\".equals(condition)) {\n        regex = \".*\"; // Zero condition is indicated by dot\n      } else if (condition.equals(strip)) {\n        regex = \".*\"; // TODO: optimize this better:\n                      // if we remove 'strip' from condition, we don't have to append 'strip' to check it...!\n                      // but this is complicated...\n      } else {\n        regex = String.format(Locale.ROOT, conditionPattern, condition);\n      }\n      \n      // deduplicate patterns\n      Integer patternIndex = seenPatterns.get(regex);\n      if (patternIndex == null) {\n        patternIndex = patterns.size();\n        if (patternIndex > Short.MAX_VALUE) {\n          throw new UnsupportedOperationException(\"Too many patterns, please report this to dev@lucene.apache.org\");          \n        }\n        seenPatterns.put(regex, patternIndex);\n        CharacterRunAutomaton pattern = new CharacterRunAutomaton(new RegExp(regex, RegExp.NONE).toAutomaton());\n        patterns.add(pattern);\n      }\n      \n      Integer stripOrd = seenStrips.get(strip);\n      if (stripOrd == null) {\n        stripOrd = seenStrips.size();\n        seenStrips.put(strip, stripOrd);\n        if (stripOrd > Character.MAX_VALUE) {\n          throw new UnsupportedOperationException(\"Too many unique strips, please report this to dev@lucene.apache.org\");\n        }\n      }\n\n      if (appendFlags == null) {\n        appendFlags = NOFLAGS;\n      }\n      \n      final int hashCode = encodeFlagsWithHash(scratch, appendFlags);\n      int appendFlagsOrd = flagLookup.add(scratch, hashCode);\n      if (appendFlagsOrd < 0) {\n        // already exists in our hash\n        appendFlagsOrd = (-appendFlagsOrd)-1;\n      } else if (appendFlagsOrd > Short.MAX_VALUE) {\n        // this limit is probably flexible, but its a good sanity check too\n        throw new UnsupportedOperationException(\"Too many unique append flags, please report this to dev@lucene.apache.org\");\n      }\n      \n      affixWriter.writeShort((short)flag);\n      affixWriter.writeShort((short)stripOrd.intValue());\n      // encode crossProduct into patternIndex\n      int patternOrd = patternIndex.intValue() << 1 | (crossProduct ? 1 : 0);\n      affixWriter.writeShort((short)patternOrd);\n      affixWriter.writeShort((short)appendFlagsOrd);\n      \n      if (needsInputCleaning) {\n        CharSequence cleaned = cleanInput(affixArg, sb);\n        affixArg = cleaned.toString();\n      }\n      \n      List<Character> list = affixes.get(affixArg);\n      if (list == null) {\n        list = new ArrayList<Character>();\n        affixes.put(affixArg, list);\n      }\n      \n      list.add((char)currentAffix);\n      currentAffix++;\n    }\n  }\n\n","sourceOld":"  /**\n   * Parses a specific affix rule putting the result into the provided affix map\n   * \n   * @param affixes Map where the result of the parsing will be put\n   * @param header Header line of the affix rule\n   * @param reader BufferedReader to read the content of the rule from\n   * @param conditionPattern {@link String#format(String, Object...)} pattern to be used to generate the condition regex\n   *                         pattern\n   * @param seenPatterns map from condition -> index of patterns, for deduplication.\n   * @throws IOException Can be thrown while reading the rule\n   */\n  private void parseAffix(TreeMap<String,List<Character>> affixes,\n                          String header,\n                          LineNumberReader reader,\n                          String conditionPattern,\n                          Map<String,Integer> seenPatterns) throws IOException, ParseException {\n    \n    BytesRef scratch = new BytesRef();\n    StringBuilder sb = new StringBuilder();\n    String args[] = header.split(\"\\\\s+\");\n\n    boolean crossProduct = args[2].equals(\"Y\");\n    \n    int numLines = Integer.parseInt(args[3]);\n    affixData = ArrayUtil.grow(affixData, (currentAffix << 3) + (numLines << 3));\n    ByteArrayDataOutput affixWriter = new ByteArrayDataOutput(affixData, currentAffix << 3, numLines << 3);\n    \n    for (int i = 0; i < numLines; i++) {\n      assert affixWriter.getPosition() == currentAffix << 3;\n      String line = reader.readLine();\n      String ruleArgs[] = line.split(\"\\\\s+\");\n\n      // from the manpage: PFX flag stripping prefix [condition [morphological_fields...]]\n      // condition is optional\n      if (ruleArgs.length < 4) {\n          throw new ParseException(\"The affix file contains a rule with less than four elements: \" + line, reader.getLineNumber());\n      }\n      \n      char flag = flagParsingStrategy.parseFlag(ruleArgs[1]);\n      String strip = ruleArgs[2].equals(\"0\") ? \"\" : ruleArgs[2];\n      String affixArg = ruleArgs[3];\n      char appendFlags[] = null;\n      \n      int flagSep = affixArg.lastIndexOf('/');\n      if (flagSep != -1) {\n        String flagPart = affixArg.substring(flagSep + 1);\n        affixArg = affixArg.substring(0, flagSep);\n\n        if (aliasCount > 0) {\n          flagPart = getAliasValue(Integer.parseInt(flagPart));\n        } \n        \n        appendFlags = flagParsingStrategy.parseFlags(flagPart);\n        Arrays.sort(appendFlags);\n      }\n\n      String condition = ruleArgs.length > 4 ? ruleArgs[4] : \".\";\n      // at least the gascon affix file has this issue\n      if (condition.startsWith(\"[\") && !condition.endsWith(\"]\")) {\n        condition = condition + \"]\";\n      }\n      // \"dash hasn't got special meaning\" (we must escape it)\n      if (condition.indexOf('-') >= 0) {\n        condition = condition.replace(\"-\", \"\\\\-\");\n      }\n\n      String regex = String.format(Locale.ROOT, conditionPattern, condition);\n      \n      // deduplicate patterns\n      Integer patternIndex = seenPatterns.get(regex);\n      if (patternIndex == null) {\n        patternIndex = patterns.size();\n        if (patternIndex > Short.MAX_VALUE) {\n          throw new UnsupportedOperationException(\"Too many patterns, please report this to dev@lucene.apache.org\");          \n        }\n        seenPatterns.put(regex, patternIndex);\n        Pattern pattern = Pattern.compile(regex);\n        patterns.add(pattern);\n      }\n      \n      scratch.copyChars(strip);\n      int stripOrd = stripLookup.add(scratch);\n      if (stripOrd < 0) {\n        // already exists in our hash\n        stripOrd = (-stripOrd)-1;\n      } else if (stripOrd > Character.MAX_VALUE) {\n        throw new UnsupportedOperationException(\"Too many unique strips, please report this to dev@lucene.apache.org\");\n      }\n\n      if (appendFlags == null) {\n        appendFlags = NOFLAGS;\n      }\n      \n      final int hashCode = encodeFlagsWithHash(scratch, appendFlags);\n      int appendFlagsOrd = flagLookup.add(scratch, hashCode);\n      if (appendFlagsOrd < 0) {\n        // already exists in our hash\n        appendFlagsOrd = (-appendFlagsOrd)-1;\n      } else if (appendFlagsOrd > Short.MAX_VALUE) {\n        // this limit is probably flexible, but its a good sanity check too\n        throw new UnsupportedOperationException(\"Too many unique append flags, please report this to dev@lucene.apache.org\");\n      }\n      \n      affixWriter.writeShort((short)flag);\n      affixWriter.writeShort((short)stripOrd);\n      // encode crossProduct into patternIndex\n      int patternOrd = patternIndex.intValue() << 1 | (crossProduct ? 1 : 0);\n      affixWriter.writeShort((short)patternOrd);\n      affixWriter.writeShort((short)appendFlagsOrd);\n      \n      if (needsInputCleaning) {\n        CharSequence cleaned = cleanInput(affixArg, sb);\n        affixArg = cleaned.toString();\n      }\n      \n      List<Character> list = affixes.get(affixArg);\n      if (list == null) {\n        list = new ArrayList<Character>();\n        affixes.put(affixArg, list);\n      }\n      \n      list.add((char)currentAffix);\n      currentAffix++;\n    }\n  }\n\n","bugFix":null,"bugIntro":["5dc1f9b25a92ab637175c85b5338de21a939f56f"],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"96ea64d994d340044e0d57aeb6a5871539d10ca5":["ba791bce8103c79e38f957e9c5a53a75871bd918","5ae9942cbee38a49d234c2f022e3a265133d1914"],"ba791bce8103c79e38f957e9c5a53a75871bd918":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","dc3f094cafa4a87b4066e1d6710fa4e6afe6260e"],"dc3f094cafa4a87b4066e1d6710fa4e6afe6260e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a58bbbe1c866963764d3f15d3a26a6a85f6c6af4":["96ea64d994d340044e0d57aeb6a5871539d10ca5","b6b9214e93abd5c360b7dc32483691d5555a9c7e"],"5ae9942cbee38a49d234c2f022e3a265133d1914":["ba791bce8103c79e38f957e9c5a53a75871bd918"],"b6b9214e93abd5c360b7dc32483691d5555a9c7e":["5ae9942cbee38a49d234c2f022e3a265133d1914"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"09fb4238d56f62faff1f0c866bee53facad482ec":["b6b9214e93abd5c360b7dc32483691d5555a9c7e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["09fb4238d56f62faff1f0c866bee53facad482ec"]},"commit2Childs":{"96ea64d994d340044e0d57aeb6a5871539d10ca5":["a58bbbe1c866963764d3f15d3a26a6a85f6c6af4"],"ba791bce8103c79e38f957e9c5a53a75871bd918":["96ea64d994d340044e0d57aeb6a5871539d10ca5","5ae9942cbee38a49d234c2f022e3a265133d1914"],"dc3f094cafa4a87b4066e1d6710fa4e6afe6260e":["ba791bce8103c79e38f957e9c5a53a75871bd918"],"a58bbbe1c866963764d3f15d3a26a6a85f6c6af4":[],"5ae9942cbee38a49d234c2f022e3a265133d1914":["96ea64d994d340044e0d57aeb6a5871539d10ca5","b6b9214e93abd5c360b7dc32483691d5555a9c7e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["ba791bce8103c79e38f957e9c5a53a75871bd918","dc3f094cafa4a87b4066e1d6710fa4e6afe6260e"],"b6b9214e93abd5c360b7dc32483691d5555a9c7e":["a58bbbe1c866963764d3f15d3a26a6a85f6c6af4","09fb4238d56f62faff1f0c866bee53facad482ec"],"09fb4238d56f62faff1f0c866bee53facad482ec":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a58bbbe1c866963764d3f15d3a26a6a85f6c6af4","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}