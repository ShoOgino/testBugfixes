{"path":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter.PendingOutputs#add(char[],int,int,int,int).mjava","commits":[{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter.PendingOutputs#add(char[],int,int,int,int).mjava","pathOld":"modules/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter.PendingOutputs#add(char[],int,int,int,int).mjava","sourceNew":"    public void add(char[] output, int offset, int len, int endOffset, int posLength) {\n      if (count == outputs.length) {\n        final CharsRef[] next = new CharsRef[ArrayUtil.oversize(1+count, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];\n        System.arraycopy(outputs, 0, next, 0, count);\n        outputs = next;\n      }\n      if (count == endOffsets.length) {\n        final int[] next = new int[ArrayUtil.oversize(1+count, RamUsageEstimator.NUM_BYTES_INT)];\n        System.arraycopy(endOffsets, 0, next, 0, count);\n        endOffsets = next;\n      }\n      if (count == posLengths.length) {\n        final int[] next = new int[ArrayUtil.oversize(1+count, RamUsageEstimator.NUM_BYTES_INT)];\n        System.arraycopy(posLengths, 0, next, 0, count);\n        posLengths = next;\n      }\n      if (outputs[count] == null) {\n        outputs[count] = new CharsRef();\n      }\n      outputs[count].copyChars(output, offset, len);\n      // endOffset can be -1, in which case we should simply\n      // use the endOffset of the input token, or X >= 0, in\n      // which case we use X as the endOffset for this output\n      endOffsets[count] = endOffset;\n      posLengths[count] = posLength;\n      count++;\n    }\n\n","sourceOld":"    public void add(char[] output, int offset, int len, int endOffset, int posLength) {\n      if (count == outputs.length) {\n        final CharsRef[] next = new CharsRef[ArrayUtil.oversize(1+count, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];\n        System.arraycopy(outputs, 0, next, 0, count);\n        outputs = next;\n      }\n      if (count == endOffsets.length) {\n        final int[] next = new int[ArrayUtil.oversize(1+count, RamUsageEstimator.NUM_BYTES_INT)];\n        System.arraycopy(endOffsets, 0, next, 0, count);\n        endOffsets = next;\n      }\n      if (count == posLengths.length) {\n        final int[] next = new int[ArrayUtil.oversize(1+count, RamUsageEstimator.NUM_BYTES_INT)];\n        System.arraycopy(posLengths, 0, next, 0, count);\n        posLengths = next;\n      }\n      if (outputs[count] == null) {\n        outputs[count] = new CharsRef();\n      }\n      outputs[count].copyChars(output, offset, len);\n      // endOffset can be -1, in which case we should simply\n      // use the endOffset of the input token, or X >= 0, in\n      // which case we use X as the endOffset for this output\n      endOffsets[count] = endOffset;\n      posLengths[count] = posLength;\n      count++;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50","date":1407854805,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter.PendingOutputs#add(char[],int,int,int,int).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter.PendingOutputs#add(char[],int,int,int,int).mjava","sourceNew":"    public void add(char[] output, int offset, int len, int endOffset, int posLength) {\n      if (count == outputs.length) {\n        outputs = Arrays.copyOf(outputs, ArrayUtil.oversize(1+count, RamUsageEstimator.NUM_BYTES_OBJECT_REF));\n      }\n      if (count == endOffsets.length) {\n        final int[] next = new int[ArrayUtil.oversize(1+count, RamUsageEstimator.NUM_BYTES_INT)];\n        System.arraycopy(endOffsets, 0, next, 0, count);\n        endOffsets = next;\n      }\n      if (count == posLengths.length) {\n        final int[] next = new int[ArrayUtil.oversize(1+count, RamUsageEstimator.NUM_BYTES_INT)];\n        System.arraycopy(posLengths, 0, next, 0, count);\n        posLengths = next;\n      }\n      if (outputs[count] == null) {\n        outputs[count] = new CharsRefBuilder();\n      }\n      outputs[count].copyChars(output, offset, len);\n      // endOffset can be -1, in which case we should simply\n      // use the endOffset of the input token, or X >= 0, in\n      // which case we use X as the endOffset for this output\n      endOffsets[count] = endOffset;\n      posLengths[count] = posLength;\n      count++;\n    }\n\n","sourceOld":"    public void add(char[] output, int offset, int len, int endOffset, int posLength) {\n      if (count == outputs.length) {\n        final CharsRef[] next = new CharsRef[ArrayUtil.oversize(1+count, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];\n        System.arraycopy(outputs, 0, next, 0, count);\n        outputs = next;\n      }\n      if (count == endOffsets.length) {\n        final int[] next = new int[ArrayUtil.oversize(1+count, RamUsageEstimator.NUM_BYTES_INT)];\n        System.arraycopy(endOffsets, 0, next, 0, count);\n        endOffsets = next;\n      }\n      if (count == posLengths.length) {\n        final int[] next = new int[ArrayUtil.oversize(1+count, RamUsageEstimator.NUM_BYTES_INT)];\n        System.arraycopy(posLengths, 0, next, 0, count);\n        posLengths = next;\n      }\n      if (outputs[count] == null) {\n        outputs[count] = new CharsRef();\n      }\n      outputs[count].copyChars(output, offset, len);\n      // endOffset can be -1, in which case we should simply\n      // use the endOffset of the input token, or X >= 0, in\n      // which case we use X as the endOffset for this output\n      endOffsets[count] = endOffset;\n      posLengths[count] = posLength;\n      count++;\n    }\n\n","bugFix":["865b7d0f8430a08d385370b6b87a89a737aa6145"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f226a8b088dd9c8f6ab287a77237c4aa00a238e5","date":1456187572,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter.PendingOutputs#add(char[],int,int,int,int).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter.PendingOutputs#add(char[],int,int,int,int).mjava","sourceNew":"    public void add(char[] output, int offset, int len, int endOffset, int posLength) {\n      if (count == outputs.length) {\n        outputs = Arrays.copyOf(outputs, ArrayUtil.oversize(1+count, RamUsageEstimator.NUM_BYTES_OBJECT_REF));\n      }\n      if (count == endOffsets.length) {\n        final int[] next = new int[ArrayUtil.oversize(1+count, Integer.BYTES)];\n        System.arraycopy(endOffsets, 0, next, 0, count);\n        endOffsets = next;\n      }\n      if (count == posLengths.length) {\n        final int[] next = new int[ArrayUtil.oversize(1+count, Integer.BYTES)];\n        System.arraycopy(posLengths, 0, next, 0, count);\n        posLengths = next;\n      }\n      if (outputs[count] == null) {\n        outputs[count] = new CharsRefBuilder();\n      }\n      outputs[count].copyChars(output, offset, len);\n      // endOffset can be -1, in which case we should simply\n      // use the endOffset of the input token, or X >= 0, in\n      // which case we use X as the endOffset for this output\n      endOffsets[count] = endOffset;\n      posLengths[count] = posLength;\n      count++;\n    }\n\n","sourceOld":"    public void add(char[] output, int offset, int len, int endOffset, int posLength) {\n      if (count == outputs.length) {\n        outputs = Arrays.copyOf(outputs, ArrayUtil.oversize(1+count, RamUsageEstimator.NUM_BYTES_OBJECT_REF));\n      }\n      if (count == endOffsets.length) {\n        final int[] next = new int[ArrayUtil.oversize(1+count, RamUsageEstimator.NUM_BYTES_INT)];\n        System.arraycopy(endOffsets, 0, next, 0, count);\n        endOffsets = next;\n      }\n      if (count == posLengths.length) {\n        final int[] next = new int[ArrayUtil.oversize(1+count, RamUsageEstimator.NUM_BYTES_INT)];\n        System.arraycopy(posLengths, 0, next, 0, count);\n        posLengths = next;\n      }\n      if (outputs[count] == null) {\n        outputs[count] = new CharsRefBuilder();\n      }\n      outputs[count].copyChars(output, offset, len);\n      // endOffset can be -1, in which case we should simply\n      // use the endOffset of the input token, or X >= 0, in\n      // which case we use X as the endOffset for this output\n      endOffsets[count] = endOffset;\n      posLengths[count] = posLength;\n      count++;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"419a8f52c6635419beb951255cacbbb281044c57","date":1456189353,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter.PendingOutputs#add(char[],int,int,int,int).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter.PendingOutputs#add(char[],int,int,int,int).mjava","sourceNew":"    public void add(char[] output, int offset, int len, int endOffset, int posLength) {\n      if (count == outputs.length) {\n        outputs = Arrays.copyOf(outputs, ArrayUtil.oversize(1+count, RamUsageEstimator.NUM_BYTES_OBJECT_REF));\n      }\n      if (count == endOffsets.length) {\n        final int[] next = new int[ArrayUtil.oversize(1+count, Integer.BYTES)];\n        System.arraycopy(endOffsets, 0, next, 0, count);\n        endOffsets = next;\n      }\n      if (count == posLengths.length) {\n        final int[] next = new int[ArrayUtil.oversize(1+count, Integer.BYTES)];\n        System.arraycopy(posLengths, 0, next, 0, count);\n        posLengths = next;\n      }\n      if (outputs[count] == null) {\n        outputs[count] = new CharsRefBuilder();\n      }\n      outputs[count].copyChars(output, offset, len);\n      // endOffset can be -1, in which case we should simply\n      // use the endOffset of the input token, or X >= 0, in\n      // which case we use X as the endOffset for this output\n      endOffsets[count] = endOffset;\n      posLengths[count] = posLength;\n      count++;\n    }\n\n","sourceOld":"    public void add(char[] output, int offset, int len, int endOffset, int posLength) {\n      if (count == outputs.length) {\n        outputs = Arrays.copyOf(outputs, ArrayUtil.oversize(1+count, RamUsageEstimator.NUM_BYTES_OBJECT_REF));\n      }\n      if (count == endOffsets.length) {\n        final int[] next = new int[ArrayUtil.oversize(1+count, RamUsageEstimator.NUM_BYTES_INT)];\n        System.arraycopy(endOffsets, 0, next, 0, count);\n        endOffsets = next;\n      }\n      if (count == posLengths.length) {\n        final int[] next = new int[ArrayUtil.oversize(1+count, RamUsageEstimator.NUM_BYTES_INT)];\n        System.arraycopy(posLengths, 0, next, 0, count);\n        posLengths = next;\n      }\n      if (outputs[count] == null) {\n        outputs[count] = new CharsRefBuilder();\n      }\n      outputs[count].copyChars(output, offset, len);\n      // endOffset can be -1, in which case we should simply\n      // use the endOffset of the input token, or X >= 0, in\n      // which case we use X as the endOffset for this output\n      endOffsets[count] = endOffset;\n      posLengths[count] = posLength;\n      count++;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9798d0818e7a880546802b509792d3f3d57babd2","date":1528358901,"type":3,"author":"Nhat Nguyen","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter.PendingOutputs#add(char[],int,int,int,int).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter.PendingOutputs#add(char[],int,int,int,int).mjava","sourceNew":"    public void add(char[] output, int offset, int len, int endOffset, int posLength) {\n      if (count == outputs.length) {\n        outputs = ArrayUtil.grow(outputs, count+1);\n      }\n      if (count == endOffsets.length) {\n        final int[] next = new int[ArrayUtil.oversize(1+count, Integer.BYTES)];\n        System.arraycopy(endOffsets, 0, next, 0, count);\n        endOffsets = next;\n      }\n      if (count == posLengths.length) {\n        final int[] next = new int[ArrayUtil.oversize(1+count, Integer.BYTES)];\n        System.arraycopy(posLengths, 0, next, 0, count);\n        posLengths = next;\n      }\n      if (outputs[count] == null) {\n        outputs[count] = new CharsRefBuilder();\n      }\n      outputs[count].copyChars(output, offset, len);\n      // endOffset can be -1, in which case we should simply\n      // use the endOffset of the input token, or X >= 0, in\n      // which case we use X as the endOffset for this output\n      endOffsets[count] = endOffset;\n      posLengths[count] = posLength;\n      count++;\n    }\n\n","sourceOld":"    public void add(char[] output, int offset, int len, int endOffset, int posLength) {\n      if (count == outputs.length) {\n        outputs = Arrays.copyOf(outputs, ArrayUtil.oversize(1+count, RamUsageEstimator.NUM_BYTES_OBJECT_REF));\n      }\n      if (count == endOffsets.length) {\n        final int[] next = new int[ArrayUtil.oversize(1+count, Integer.BYTES)];\n        System.arraycopy(endOffsets, 0, next, 0, count);\n        endOffsets = next;\n      }\n      if (count == posLengths.length) {\n        final int[] next = new int[ArrayUtil.oversize(1+count, Integer.BYTES)];\n        System.arraycopy(posLengths, 0, next, 0, count);\n        posLengths = next;\n      }\n      if (outputs[count] == null) {\n        outputs[count] = new CharsRefBuilder();\n      }\n      outputs[count].copyChars(output, offset, len);\n      // endOffset can be -1, in which case we should simply\n      // use the endOffset of the input token, or X >= 0, in\n      // which case we use X as the endOffset for this output\n      endOffsets[count] = endOffset;\n      posLengths[count] = posLength;\n      count++;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b70042a8a492f7054d480ccdd2be9796510d4327","date":1528386658,"type":3,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter.PendingOutputs#add(char[],int,int,int,int).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter.PendingOutputs#add(char[],int,int,int,int).mjava","sourceNew":"    public void add(char[] output, int offset, int len, int endOffset, int posLength) {\n      if (count == outputs.length) {\n        outputs = ArrayUtil.grow(outputs, count+1);\n      }\n      if (count == endOffsets.length) {\n        final int[] next = new int[ArrayUtil.oversize(1+count, Integer.BYTES)];\n        System.arraycopy(endOffsets, 0, next, 0, count);\n        endOffsets = next;\n      }\n      if (count == posLengths.length) {\n        final int[] next = new int[ArrayUtil.oversize(1+count, Integer.BYTES)];\n        System.arraycopy(posLengths, 0, next, 0, count);\n        posLengths = next;\n      }\n      if (outputs[count] == null) {\n        outputs[count] = new CharsRefBuilder();\n      }\n      outputs[count].copyChars(output, offset, len);\n      // endOffset can be -1, in which case we should simply\n      // use the endOffset of the input token, or X >= 0, in\n      // which case we use X as the endOffset for this output\n      endOffsets[count] = endOffset;\n      posLengths[count] = posLength;\n      count++;\n    }\n\n","sourceOld":"    public void add(char[] output, int offset, int len, int endOffset, int posLength) {\n      if (count == outputs.length) {\n        outputs = Arrays.copyOf(outputs, ArrayUtil.oversize(1+count, RamUsageEstimator.NUM_BYTES_OBJECT_REF));\n      }\n      if (count == endOffsets.length) {\n        final int[] next = new int[ArrayUtil.oversize(1+count, Integer.BYTES)];\n        System.arraycopy(endOffsets, 0, next, 0, count);\n        endOffsets = next;\n      }\n      if (count == posLengths.length) {\n        final int[] next = new int[ArrayUtil.oversize(1+count, Integer.BYTES)];\n        System.arraycopy(posLengths, 0, next, 0, count);\n        posLengths = next;\n      }\n      if (outputs[count] == null) {\n        outputs[count] = new CharsRefBuilder();\n      }\n      outputs[count].copyChars(output, offset, len);\n      // endOffset can be -1, in which case we should simply\n      // use the endOffset of the input token, or X >= 0, in\n      // which case we use X as the endOffset for this output\n      endOffsets[count] = endOffset;\n      posLengths[count] = posLength;\n      count++;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26","date":1531589977,"type":3,"author":"Michael Braun","isMerge":true,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter.PendingOutputs#add(char[],int,int,int,int).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter.PendingOutputs#add(char[],int,int,int,int).mjava","sourceNew":"    public void add(char[] output, int offset, int len, int endOffset, int posLength) {\n      if (count == outputs.length) {\n        outputs = ArrayUtil.grow(outputs, count+1);\n      }\n      if (count == endOffsets.length) {\n        final int[] next = new int[ArrayUtil.oversize(1+count, Integer.BYTES)];\n        System.arraycopy(endOffsets, 0, next, 0, count);\n        endOffsets = next;\n      }\n      if (count == posLengths.length) {\n        final int[] next = new int[ArrayUtil.oversize(1+count, Integer.BYTES)];\n        System.arraycopy(posLengths, 0, next, 0, count);\n        posLengths = next;\n      }\n      if (outputs[count] == null) {\n        outputs[count] = new CharsRefBuilder();\n      }\n      outputs[count].copyChars(output, offset, len);\n      // endOffset can be -1, in which case we should simply\n      // use the endOffset of the input token, or X >= 0, in\n      // which case we use X as the endOffset for this output\n      endOffsets[count] = endOffset;\n      posLengths[count] = posLength;\n      count++;\n    }\n\n","sourceOld":"    public void add(char[] output, int offset, int len, int endOffset, int posLength) {\n      if (count == outputs.length) {\n        outputs = Arrays.copyOf(outputs, ArrayUtil.oversize(1+count, RamUsageEstimator.NUM_BYTES_OBJECT_REF));\n      }\n      if (count == endOffsets.length) {\n        final int[] next = new int[ArrayUtil.oversize(1+count, Integer.BYTES)];\n        System.arraycopy(endOffsets, 0, next, 0, count);\n        endOffsets = next;\n      }\n      if (count == posLengths.length) {\n        final int[] next = new int[ArrayUtil.oversize(1+count, Integer.BYTES)];\n        System.arraycopy(posLengths, 0, next, 0, count);\n        posLengths = next;\n      }\n      if (outputs[count] == null) {\n        outputs[count] = new CharsRefBuilder();\n      }\n      outputs[count].copyChars(output, offset, len);\n      // endOffset can be -1, in which case we should simply\n      // use the endOffset of the input token, or X >= 0, in\n      // which case we use X as the endOffset for this output\n      endOffsets[count] = endOffset;\n      posLengths[count] = posLength;\n      count++;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b70042a8a492f7054d480ccdd2be9796510d4327":["419a8f52c6635419beb951255cacbbb281044c57","9798d0818e7a880546802b509792d3f3d57babd2"],"419a8f52c6635419beb951255cacbbb281044c57":["7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50","f226a8b088dd9c8f6ab287a77237c4aa00a238e5"],"f226a8b088dd9c8f6ab287a77237c4aa00a238e5":["7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50"],"7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"9798d0818e7a880546802b509792d3f3d57babd2":["419a8f52c6635419beb951255cacbbb281044c57"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9798d0818e7a880546802b509792d3f3d57babd2"],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":["419a8f52c6635419beb951255cacbbb281044c57","9798d0818e7a880546802b509792d3f3d57babd2"]},"commit2Childs":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"b70042a8a492f7054d480ccdd2be9796510d4327":[],"419a8f52c6635419beb951255cacbbb281044c57":["b70042a8a492f7054d480ccdd2be9796510d4327","9798d0818e7a880546802b509792d3f3d57babd2","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"f226a8b088dd9c8f6ab287a77237c4aa00a238e5":["419a8f52c6635419beb951255cacbbb281044c57"],"7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50":["419a8f52c6635419beb951255cacbbb281044c57","f226a8b088dd9c8f6ab287a77237c4aa00a238e5"],"9798d0818e7a880546802b509792d3f3d57babd2":["b70042a8a492f7054d480ccdd2be9796510d4327","cd5edd1f2b162a5cfa08efd17851a07373a96817","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":[]},"heads":["b70042a8a492f7054d480ccdd2be9796510d4327","cd5edd1f2b162a5cfa08efd17851a07373a96817","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}