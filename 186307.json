{"path":"lucene/core/src/java/org/apache/lucene/index/ReadersAndLiveDocs#writeLiveDocs(Directory).mjava","commits":[{"id":"ae695f21c50b03702b5d0fa2543d5af844bb7cd3","date":1331554994,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/ReadersAndLiveDocs#writeLiveDocs(Directory).mjava","pathOld":"/dev/null","sourceNew":"  // Commit live docs to the directory (writes new\n  // _X_N.del files); returns true if it wrote the file\n  // and false if there were no new deletes to write:\n  public synchronized boolean writeLiveDocs(Directory dir) throws IOException {\n    //System.out.println(\"rld.writeLiveDocs seg=\" + info + \" pendingDelCount=\" + pendingDeleteCount);\n    if (pendingDeleteCount != 0) {\n      // We have new deletes\n      assert liveDocs.length() == info.docCount;\n\n      // Save in case we need to rollback on failure:\n      final SegmentInfo sav = (SegmentInfo) info.clone();\n      info.advanceDelGen();\n      info.setDelCount(info.getDelCount() + pendingDeleteCount);\n\n      // We can write directly to the actual name (vs to a\n      // .tmp & renaming it) because the file is not live\n      // until segments file is written:\n      boolean success = false;\n      try {\n        info.getCodec().liveDocsFormat().writeLiveDocs((MutableBits)liveDocs, dir, info, IOContext.DEFAULT);\n        success = true;\n      } finally {\n        if (!success) {\n          info.reset(sav);\n        }\n      }\n      pendingDeleteCount = 0;\n      return true;\n    } else {\n      return false;\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"38e3b736c7ca086d61b7dbb841c905ee115490da","date":1331657018,"type":0,"author":"Ryan McKinley","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/ReadersAndLiveDocs#writeLiveDocs(Directory).mjava","pathOld":"/dev/null","sourceNew":"  // Commit live docs to the directory (writes new\n  // _X_N.del files); returns true if it wrote the file\n  // and false if there were no new deletes to write:\n  public synchronized boolean writeLiveDocs(Directory dir) throws IOException {\n    //System.out.println(\"rld.writeLiveDocs seg=\" + info + \" pendingDelCount=\" + pendingDeleteCount);\n    if (pendingDeleteCount != 0) {\n      // We have new deletes\n      assert liveDocs.length() == info.docCount;\n\n      // Save in case we need to rollback on failure:\n      final SegmentInfo sav = (SegmentInfo) info.clone();\n      info.advanceDelGen();\n      info.setDelCount(info.getDelCount() + pendingDeleteCount);\n\n      // We can write directly to the actual name (vs to a\n      // .tmp & renaming it) because the file is not live\n      // until segments file is written:\n      boolean success = false;\n      try {\n        info.getCodec().liveDocsFormat().writeLiveDocs((MutableBits)liveDocs, dir, info, IOContext.DEFAULT);\n        success = true;\n      } finally {\n        if (!success) {\n          info.reset(sav);\n        }\n      }\n      pendingDeleteCount = 0;\n      return true;\n    } else {\n      return false;\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"399d5903979ca52514d2bc7e3a362e1c45885c94","date":1333042474,"type":3,"author":"Ryan McKinley","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/ReadersAndLiveDocs#writeLiveDocs(Directory).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/ReadersAndLiveDocs#writeLiveDocs(Directory).mjava","sourceNew":"  // Commit live docs to the directory (writes new\n  // _X_N.del files); returns true if it wrote the file\n  // and false if there were no new deletes to write:\n  public synchronized boolean writeLiveDocs(Directory dir) throws IOException {\n    //System.out.println(\"rld.writeLiveDocs seg=\" + info + \" pendingDelCount=\" + pendingDeleteCount);\n    if (pendingDeleteCount != 0) {\n      // We have new deletes\n      assert liveDocs.length() == info.docCount;\n\n      // Save in case we need to rollback on failure:\n      final SegmentInfo sav = info.clone();\n      info.advanceDelGen();\n      info.setDelCount(info.getDelCount() + pendingDeleteCount);\n\n      // We can write directly to the actual name (vs to a\n      // .tmp & renaming it) because the file is not live\n      // until segments file is written:\n      boolean success = false;\n      try {\n        info.getCodec().liveDocsFormat().writeLiveDocs((MutableBits)liveDocs, dir, info, IOContext.DEFAULT);\n        success = true;\n      } finally {\n        if (!success) {\n          info.reset(sav);\n        }\n      }\n      pendingDeleteCount = 0;\n      return true;\n    } else {\n      return false;\n    }\n  }\n\n","sourceOld":"  // Commit live docs to the directory (writes new\n  // _X_N.del files); returns true if it wrote the file\n  // and false if there were no new deletes to write:\n  public synchronized boolean writeLiveDocs(Directory dir) throws IOException {\n    //System.out.println(\"rld.writeLiveDocs seg=\" + info + \" pendingDelCount=\" + pendingDeleteCount);\n    if (pendingDeleteCount != 0) {\n      // We have new deletes\n      assert liveDocs.length() == info.docCount;\n\n      // Save in case we need to rollback on failure:\n      final SegmentInfo sav = (SegmentInfo) info.clone();\n      info.advanceDelGen();\n      info.setDelCount(info.getDelCount() + pendingDeleteCount);\n\n      // We can write directly to the actual name (vs to a\n      // .tmp & renaming it) because the file is not live\n      // until segments file is written:\n      boolean success = false;\n      try {\n        info.getCodec().liveDocsFormat().writeLiveDocs((MutableBits)liveDocs, dir, info, IOContext.DEFAULT);\n        success = true;\n      } finally {\n        if (!success) {\n          info.reset(sav);\n        }\n      }\n      pendingDeleteCount = 0;\n      return true;\n    } else {\n      return false;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f0b406f1c9ada78b8fe2b12dfa87e9f76d35618c","date":1337198060,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/ReadersAndLiveDocs#writeLiveDocs(Directory).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/ReadersAndLiveDocs#writeLiveDocs(Directory).mjava","sourceNew":"  // Commit live docs to the directory (writes new\n  // _X_N.del files); returns true if it wrote the file\n  // and false if there were no new deletes to write:\n  public synchronized boolean writeLiveDocs(Directory dir) throws IOException {\n    //System.out.println(\"rld.writeLiveDocs seg=\" + info + \" pendingDelCount=\" + pendingDeleteCount);\n    if (pendingDeleteCount != 0) {\n      // We have new deletes\n      assert liveDocs.length() == info.docCount;\n\n      // We can write directly to the actual name (vs to a\n      // .tmp & renaming it) because the file is not live\n      // until segments file is written:\n      info.getCodec().liveDocsFormat().writeLiveDocs((MutableBits)liveDocs, dir, info, pendingDeleteCount, IOContext.DEFAULT);\n\n      // If we hit an exc in the line above (eg disk full)\n      // then info remains pointing to the previous\n      // (successfully written) del docs:\n      info.advanceDelGen();\n      info.setDelCount(info.getDelCount() + pendingDeleteCount);\n\n      pendingDeleteCount = 0;\n      return true;\n    } else {\n      return false;\n    }\n  }\n\n","sourceOld":"  // Commit live docs to the directory (writes new\n  // _X_N.del files); returns true if it wrote the file\n  // and false if there were no new deletes to write:\n  public synchronized boolean writeLiveDocs(Directory dir) throws IOException {\n    //System.out.println(\"rld.writeLiveDocs seg=\" + info + \" pendingDelCount=\" + pendingDeleteCount);\n    if (pendingDeleteCount != 0) {\n      // We have new deletes\n      assert liveDocs.length() == info.docCount;\n\n      // Save in case we need to rollback on failure:\n      final SegmentInfo sav = info.clone();\n      info.advanceDelGen();\n      info.setDelCount(info.getDelCount() + pendingDeleteCount);\n\n      // We can write directly to the actual name (vs to a\n      // .tmp & renaming it) because the file is not live\n      // until segments file is written:\n      boolean success = false;\n      try {\n        info.getCodec().liveDocsFormat().writeLiveDocs((MutableBits)liveDocs, dir, info, IOContext.DEFAULT);\n        success = true;\n      } finally {\n        if (!success) {\n          info.reset(sav);\n        }\n      }\n      pendingDeleteCount = 0;\n      return true;\n    } else {\n      return false;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9d153abcf92dc5329d98571a8c3035df9bd80648","date":1337702630,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/ReadersAndLiveDocs#writeLiveDocs(Directory).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/ReadersAndLiveDocs#writeLiveDocs(Directory).mjava","sourceNew":"  // Commit live docs to the directory (writes new\n  // _X_N.del files); returns true if it wrote the file\n  // and false if there were no new deletes to write:\n  public synchronized boolean writeLiveDocs(Directory dir) throws IOException {\n    //System.out.println(\"rld.writeLiveDocs seg=\" + info + \" pendingDelCount=\" + pendingDeleteCount);\n    if (pendingDeleteCount != 0) {\n      // We have new deletes\n      assert liveDocs.length() == info.info.docCount;\n\n      // We can write directly to the actual name (vs to a\n      // .tmp & renaming it) because the file is not live\n      // until segments file is written:\n      info.info.getCodec().liveDocsFormat().writeLiveDocs((MutableBits)liveDocs, dir, info, pendingDeleteCount, IOContext.DEFAULT);\n\n      // If we hit an exc in the line above (eg disk full)\n      // then info remains pointing to the previous\n      // (successfully written) del docs:\n      info.advanceDelGen();\n      info.setDelCount(info.getDelCount() + pendingDeleteCount);\n\n      pendingDeleteCount = 0;\n      return true;\n    } else {\n      return false;\n    }\n  }\n\n","sourceOld":"  // Commit live docs to the directory (writes new\n  // _X_N.del files); returns true if it wrote the file\n  // and false if there were no new deletes to write:\n  public synchronized boolean writeLiveDocs(Directory dir) throws IOException {\n    //System.out.println(\"rld.writeLiveDocs seg=\" + info + \" pendingDelCount=\" + pendingDeleteCount);\n    if (pendingDeleteCount != 0) {\n      // We have new deletes\n      assert liveDocs.length() == info.docCount;\n\n      // We can write directly to the actual name (vs to a\n      // .tmp & renaming it) because the file is not live\n      // until segments file is written:\n      info.getCodec().liveDocsFormat().writeLiveDocs((MutableBits)liveDocs, dir, info, pendingDeleteCount, IOContext.DEFAULT);\n\n      // If we hit an exc in the line above (eg disk full)\n      // then info remains pointing to the previous\n      // (successfully written) del docs:\n      info.advanceDelGen();\n      info.setDelCount(info.getDelCount() + pendingDeleteCount);\n\n      pendingDeleteCount = 0;\n      return true;\n    } else {\n      return false;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"203d7d3cb7712e10ef33009a63247ae40c302d7a","date":1337798111,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/ReadersAndLiveDocs#writeLiveDocs(Directory).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/ReadersAndLiveDocs#writeLiveDocs(Directory).mjava","sourceNew":"  // Commit live docs to the directory (writes new\n  // _X_N.del files); returns true if it wrote the file\n  // and false if there were no new deletes to write:\n  public synchronized boolean writeLiveDocs(Directory dir) throws IOException {\n    //System.out.println(\"rld.writeLiveDocs seg=\" + info + \" pendingDelCount=\" + pendingDeleteCount);\n    if (pendingDeleteCount != 0) {\n      // We have new deletes\n      assert liveDocs.length() == info.info.getDocCount();\n\n      // We can write directly to the actual name (vs to a\n      // .tmp & renaming it) because the file is not live\n      // until segments file is written:\n      info.info.getCodec().liveDocsFormat().writeLiveDocs((MutableBits)liveDocs, dir, info, pendingDeleteCount, IOContext.DEFAULT);\n\n      // If we hit an exc in the line above (eg disk full)\n      // then info remains pointing to the previous\n      // (successfully written) del docs:\n      info.advanceDelGen();\n      info.setDelCount(info.getDelCount() + pendingDeleteCount);\n\n      pendingDeleteCount = 0;\n      return true;\n    } else {\n      return false;\n    }\n  }\n\n","sourceOld":"  // Commit live docs to the directory (writes new\n  // _X_N.del files); returns true if it wrote the file\n  // and false if there were no new deletes to write:\n  public synchronized boolean writeLiveDocs(Directory dir) throws IOException {\n    //System.out.println(\"rld.writeLiveDocs seg=\" + info + \" pendingDelCount=\" + pendingDeleteCount);\n    if (pendingDeleteCount != 0) {\n      // We have new deletes\n      assert liveDocs.length() == info.info.docCount;\n\n      // We can write directly to the actual name (vs to a\n      // .tmp & renaming it) because the file is not live\n      // until segments file is written:\n      info.info.getCodec().liveDocsFormat().writeLiveDocs((MutableBits)liveDocs, dir, info, pendingDeleteCount, IOContext.DEFAULT);\n\n      // If we hit an exc in the line above (eg disk full)\n      // then info remains pointing to the previous\n      // (successfully written) del docs:\n      info.advanceDelGen();\n      info.setDelCount(info.getDelCount() + pendingDeleteCount);\n\n      pendingDeleteCount = 0;\n      return true;\n    } else {\n      return false;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"615ddbd81799980d0fdd95e0238e1c498b6f47b0","date":1338233290,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/ReadersAndLiveDocs#writeLiveDocs(Directory).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/ReadersAndLiveDocs#writeLiveDocs(Directory).mjava","sourceNew":"  // Commit live docs to the directory (writes new\n  // _X_N.del files); returns true if it wrote the file\n  // and false if there were no new deletes to write:\n  public synchronized boolean writeLiveDocs(Directory dir) throws IOException {\n    //System.out.println(\"rld.writeLiveDocs seg=\" + info + \" pendingDelCount=\" + pendingDeleteCount);\n    if (pendingDeleteCount != 0) {\n      // We have new deletes\n      assert liveDocs.length() == info.info.getDocCount();\n\n      // We can write directly to the actual name (vs to a\n      // .tmp & renaming it) because the file is not live\n      // until segments file is written:\n      info.info.getCodec().liveDocsFormat().writeLiveDocs((MutableBits)liveDocs, dir, info, pendingDeleteCount, IOContext.DEFAULT);\n\n      // If we hit an exc in the line above (eg disk full)\n      // then info remains pointing to the previous\n      // (successfully written) del docs:\n      info.advanceDelGen();\n      info.setDelCount(info.getDelCount() + pendingDeleteCount);\n\n      pendingDeleteCount = 0;\n      return true;\n    } else {\n      return false;\n    }\n  }\n\n","sourceOld":"  // Commit live docs to the directory (writes new\n  // _X_N.del files); returns true if it wrote the file\n  // and false if there were no new deletes to write:\n  public synchronized boolean writeLiveDocs(Directory dir) throws IOException {\n    //System.out.println(\"rld.writeLiveDocs seg=\" + info + \" pendingDelCount=\" + pendingDeleteCount);\n    if (pendingDeleteCount != 0) {\n      // We have new deletes\n      assert liveDocs.length() == info.docCount;\n\n      // Save in case we need to rollback on failure:\n      final SegmentInfo sav = info.clone();\n      info.advanceDelGen();\n      info.setDelCount(info.getDelCount() + pendingDeleteCount);\n\n      // We can write directly to the actual name (vs to a\n      // .tmp & renaming it) because the file is not live\n      // until segments file is written:\n      boolean success = false;\n      try {\n        info.getCodec().liveDocsFormat().writeLiveDocs((MutableBits)liveDocs, dir, info, IOContext.DEFAULT);\n        success = true;\n      } finally {\n        if (!success) {\n          info.reset(sav);\n        }\n      }\n      pendingDeleteCount = 0;\n      return true;\n    } else {\n      return false;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"479fba77febd29e498fc4a430359e4cf88341da7","date":1357213856,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/ReadersAndLiveDocs#writeLiveDocs(Directory).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/ReadersAndLiveDocs#writeLiveDocs(Directory).mjava","sourceNew":"  // Commit live docs to the directory (writes new\n  // _X_N.del files); returns true if it wrote the file\n  // and false if there were no new deletes to write:\n  public synchronized boolean writeLiveDocs(Directory dir) throws IOException {\n    //System.out.println(\"rld.writeLiveDocs seg=\" + info + \" pendingDelCount=\" + pendingDeleteCount);\n    if (pendingDeleteCount != 0) {\n      // We have new deletes\n      assert liveDocs.length() == info.info.getDocCount();\n\n      // Do this so we can delete any created files on\n      // exception; this saves all codecs from having to do\n      // it:\n      TrackingDirectoryWrapper trackingDir = new TrackingDirectoryWrapper(dir);\n\n      // We can write directly to the actual name (vs to a\n      // .tmp & renaming it) because the file is not live\n      // until segments file is written:\n      boolean success = false;\n      try {\n        info.info.getCodec().liveDocsFormat().writeLiveDocs((MutableBits)liveDocs, trackingDir, info, pendingDeleteCount, IOContext.DEFAULT);\n        success = true;\n      } finally {\n        if (!success) {\n          // Advance only the nextWriteDelGen so that a 2nd\n          // attempt to write will write to a new file\n          info.advanceNextWriteDelGen();\n\n          // Delete any partially created file(s):\n          for(String fileName : trackingDir.getCreatedFiles()) {\n            try {\n              dir.deleteFile(fileName);\n            } catch (Throwable t) {\n              // Ignore so we throw only the first exc\n            }\n          }\n        }\n      }\n\n      // If we hit an exc in the line above (eg disk full)\n      // then info's delGen remains pointing to the previous\n      // (successfully written) del docs:\n      info.advanceDelGen();\n      info.setDelCount(info.getDelCount() + pendingDeleteCount);\n\n      pendingDeleteCount = 0;\n      return true;\n    } else {\n      return false;\n    }\n  }\n\n","sourceOld":"  // Commit live docs to the directory (writes new\n  // _X_N.del files); returns true if it wrote the file\n  // and false if there were no new deletes to write:\n  public synchronized boolean writeLiveDocs(Directory dir) throws IOException {\n    //System.out.println(\"rld.writeLiveDocs seg=\" + info + \" pendingDelCount=\" + pendingDeleteCount);\n    if (pendingDeleteCount != 0) {\n      // We have new deletes\n      assert liveDocs.length() == info.info.getDocCount();\n\n      // We can write directly to the actual name (vs to a\n      // .tmp & renaming it) because the file is not live\n      // until segments file is written:\n      info.info.getCodec().liveDocsFormat().writeLiveDocs((MutableBits)liveDocs, dir, info, pendingDeleteCount, IOContext.DEFAULT);\n\n      // If we hit an exc in the line above (eg disk full)\n      // then info remains pointing to the previous\n      // (successfully written) del docs:\n      info.advanceDelGen();\n      info.setDelCount(info.getDelCount() + pendingDeleteCount);\n\n      pendingDeleteCount = 0;\n      return true;\n    } else {\n      return false;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d3fcb70cf561547c7bb1506e0cf32ca7b1287064","date":1357616416,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/ReadersAndLiveDocs#writeLiveDocs(Directory).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/ReadersAndLiveDocs#writeLiveDocs(Directory).mjava","sourceNew":"  // Commit live docs to the directory (writes new\n  // _X_N.del files); returns true if it wrote the file\n  // and false if there were no new deletes to write:\n  public synchronized boolean writeLiveDocs(Directory dir) throws IOException {\n    //System.out.println(\"rld.writeLiveDocs seg=\" + info + \" pendingDelCount=\" + pendingDeleteCount);\n    if (pendingDeleteCount != 0) {\n      // We have new deletes\n      assert liveDocs.length() == info.info.getDocCount();\n\n      // Do this so we can delete any created files on\n      // exception; this saves all codecs from having to do\n      // it:\n      TrackingDirectoryWrapper trackingDir = new TrackingDirectoryWrapper(dir);\n\n      // We can write directly to the actual name (vs to a\n      // .tmp & renaming it) because the file is not live\n      // until segments file is written:\n      boolean success = false;\n      try {\n        info.info.getCodec().liveDocsFormat().writeLiveDocs((MutableBits)liveDocs, trackingDir, info, pendingDeleteCount, IOContext.DEFAULT);\n        success = true;\n      } finally {\n        if (!success) {\n          // Advance only the nextWriteDelGen so that a 2nd\n          // attempt to write will write to a new file\n          info.advanceNextWriteDelGen();\n\n          // Delete any partially created file(s):\n          for(String fileName : trackingDir.getCreatedFiles()) {\n            try {\n              dir.deleteFile(fileName);\n            } catch (Throwable t) {\n              // Ignore so we throw only the first exc\n            }\n          }\n        }\n      }\n\n      // If we hit an exc in the line above (eg disk full)\n      // then info's delGen remains pointing to the previous\n      // (successfully written) del docs:\n      info.advanceDelGen();\n      info.setDelCount(info.getDelCount() + pendingDeleteCount);\n\n      pendingDeleteCount = 0;\n      return true;\n    } else {\n      return false;\n    }\n  }\n\n","sourceOld":"  // Commit live docs to the directory (writes new\n  // _X_N.del files); returns true if it wrote the file\n  // and false if there were no new deletes to write:\n  public synchronized boolean writeLiveDocs(Directory dir) throws IOException {\n    //System.out.println(\"rld.writeLiveDocs seg=\" + info + \" pendingDelCount=\" + pendingDeleteCount);\n    if (pendingDeleteCount != 0) {\n      // We have new deletes\n      assert liveDocs.length() == info.info.getDocCount();\n\n      // We can write directly to the actual name (vs to a\n      // .tmp & renaming it) because the file is not live\n      // until segments file is written:\n      info.info.getCodec().liveDocsFormat().writeLiveDocs((MutableBits)liveDocs, dir, info, pendingDeleteCount, IOContext.DEFAULT);\n\n      // If we hit an exc in the line above (eg disk full)\n      // then info remains pointing to the previous\n      // (successfully written) del docs:\n      info.advanceDelGen();\n      info.setDelCount(info.getDelCount() + pendingDeleteCount);\n\n      pendingDeleteCount = 0;\n      return true;\n    } else {\n      return false;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e072d0b1fc19e0533d8ce432eed245196bca6fde","date":1379265112,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/ReadersAndLiveDocs#writeLiveDocs(Directory).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/ReadersAndLiveDocs#writeLiveDocs(Directory).mjava","sourceNew":"  // Commit live docs (writes new _X_N.del files) and field updates (writes new\n  // _X_N updates files) to the directory; returns true if it wrote any file\n  // and false if there were no new deletes or updates to write:\n  // TODO (DVU_RENAME) to writeDeletesAndUpdates\n  public synchronized boolean writeLiveDocs(Directory dir) throws IOException {\n    assert Thread.holdsLock(writer);\n    //System.out.println(\"rld.writeLiveDocs seg=\" + info + \" pendingDelCount=\" + pendingDeleteCount + \" numericUpdates=\" + numericUpdates);\n    final boolean hasFieldUpdates = hasFieldUpdates();\n    if (pendingDeleteCount == 0 && !hasFieldUpdates) {\n      return false;\n    }\n    \n    // We have new deletes or updates\n    if (pendingDeleteCount > 0) {\n      assert liveDocs.length() == info.info.getDocCount();\n    }\n    \n    // Do this so we can delete any created files on\n    // exception; this saves all codecs from having to do\n    // it:\n    TrackingDirectoryWrapper trackingDir = new TrackingDirectoryWrapper(dir);\n    \n    // We can write directly to the actual name (vs to a\n    // .tmp & renaming it) because the file is not live\n    // until segments file is written:\n    boolean success = false;\n    try {\n      Codec codec = info.info.getCodec();\n      if (pendingDeleteCount > 0) {\n        codec.liveDocsFormat().writeLiveDocs((MutableBits)liveDocs, trackingDir, info, pendingDeleteCount, IOContext.DEFAULT);\n      }\n      \n      // apply numeric updates if there are any\n      if (hasFieldUpdates) {\n        // reader could be null e.g. for a just merged segment (from\n        // IndexWriter.commitMergedDeletes).\n        final SegmentReader reader = this.reader == null ? new SegmentReader(info, IOContext.READONCE) : this.reader;\n        try {\n          // clone FieldInfos so that we can update their numericUpdatesGen\n          // separately from the reader's infos and write them to a new\n          // fieldInfos_gen file\n          FieldInfos.Builder builder = new FieldInfos.Builder(writer.globalFieldNumberMap);\n          // cannot use builder.add(reader.getFieldInfos()) because it does not clone FI.attributes\n          for (FieldInfo fi : reader.getFieldInfos()) {\n            FieldInfo clone = builder.add(fi);\n            // copy the stuff FieldInfos.Builder doesn't copy\n            if (fi.attributes() != null) {\n              for (Entry<String,String> e : fi.attributes().entrySet()) {\n                clone.putAttribute(e.getKey(), e.getValue());\n              }\n            }\n          }\n          // create new fields or update existing ones to have NumericDV type\n//          for (String f : numericUpdates.keySet()) {\n//            builder.addOrUpdate(f, NumericDocValuesField.TYPE);\n//          }\n          \n          final FieldInfos fieldInfos = builder.finish();\n          final long nextDocValuesGen = info.getNextDocValuesGen();\n          final String segmentSuffix = Long.toString(nextDocValuesGen, Character.MAX_RADIX);\n          final SegmentWriteState state = new SegmentWriteState(null, trackingDir, info.info, fieldInfos, null, IOContext.DEFAULT, segmentSuffix, true);\n          final DocValuesFormat docValuesFormat = codec.docValuesFormat();\n          final DocValuesConsumer fieldsConsumer = docValuesFormat.fieldsConsumer(state);\n          boolean fieldsConsumerSuccess = false;\n          try {\n            for (Entry<String,Map<Integer,Long>> e : numericUpdates.entrySet()) {\n              final String field = e.getKey();\n              final Map<Integer,Long> updates = e.getValue();\n              final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n\n              if (fieldInfo == null || fieldInfo.getDocValuesType() != DocValuesType.NUMERIC) {\n                throw new UnsupportedOperationException(\n                    \"cannot update docvalues in a segment with no docvalues field: segment=\" + info + \", field=\" + field);\n              }\n//              assert fieldInfo != null;\n\n              info.setDocValuesGen(fieldInfo.number, nextDocValuesGen);\n              \n              // write the numeric updates to a new gen'd docvalues file\n              fieldsConsumer.addNumericField(fieldInfo, new Iterable<Number>() {\n                @SuppressWarnings(\"synthetic-access\")\n                final NumericDocValues currentValues = reader.getNumericDocValues(field);\n                @Override\n                public Iterator<Number> iterator() {\n                  return new Iterator<Number>() {\n\n                    @SuppressWarnings(\"synthetic-access\")\n                    final int maxDoc = reader.maxDoc();\n                    int curDoc = -1;\n                    \n                    @Override\n                    public boolean hasNext() {\n                      return curDoc < maxDoc - 1;\n                    }\n\n                    @Override\n                    public Number next() {\n                      if (++curDoc >= maxDoc) {\n                        throw new NoSuchElementException(\"no more documents to return values for\");\n                      }\n                      Long updatedValue = updates.get(curDoc);\n                      if (updatedValue == null) {\n                        updatedValue = Long.valueOf(currentValues.get(curDoc));\n                      } else if (updatedValue == NumericUpdate.MISSING) {\n                        updatedValue = null;\n                      }\n                      return updatedValue;\n                    }\n\n                    @Override\n                    public void remove() {\n                      throw new UnsupportedOperationException(\"this iterator does not support removing elements\");\n                    }\n                    \n                  };\n                }\n              });\n            }\n            fieldsConsumerSuccess = true;\n          } finally {\n            if (fieldsConsumerSuccess) {\n              fieldsConsumer.close();\n            } else {\n              IOUtils.closeWhileHandlingException(fieldsConsumer);\n            }\n          }\n        } finally {\n          if (reader != this.reader) {\n            reader.close();\n          }\n        }\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        // Advance only the nextWriteDelGen so that a 2nd\n        // attempt to write will write to a new file\n        if (pendingDeleteCount > 0) {\n          info.advanceNextWriteDelGen();\n        }\n        \n        // Advance only the nextWriteDocValuesGen so that a 2nd\n        // attempt to write will write to a new file\n        if (hasFieldUpdates) {\n          info.advanceNextWriteDocValuesGen();\n        }\n        \n        // Delete any partially created file(s):\n        for (String fileName : trackingDir.getCreatedFiles()) {\n          try {\n            dir.deleteFile(fileName);\n          } catch (Throwable t) {\n            // Ignore so we throw only the first exc\n          }\n        }\n      }\n    }\n    \n    // If we hit an exc in the line above (eg disk full)\n    // then info's delGen remains pointing to the previous\n    // (successfully written) del docs:\n    if (pendingDeleteCount > 0) {\n      info.advanceDelGen();\n      info.setDelCount(info.getDelCount() + pendingDeleteCount);\n      pendingDeleteCount = 0;\n    }\n    \n    if (hasFieldUpdates) {\n      info.advanceDocValuesGen();\n      // copy all the updates to mergingUpdates, so they can later be applied to the merged segment\n      if (isMerging) {\n        copyUpdatesToMerging();\n      }\n      numericUpdates.clear();\n    }\n\n    info.addUpdatesFiles(trackingDir.getCreatedFiles());\n    \n    return true;\n  }\n\n","sourceOld":"  // Commit live docs to the directory (writes new\n  // _X_N.del files); returns true if it wrote the file\n  // and false if there were no new deletes to write:\n  public synchronized boolean writeLiveDocs(Directory dir) throws IOException {\n    //System.out.println(\"rld.writeLiveDocs seg=\" + info + \" pendingDelCount=\" + pendingDeleteCount);\n    if (pendingDeleteCount != 0) {\n      // We have new deletes\n      assert liveDocs.length() == info.info.getDocCount();\n\n      // Do this so we can delete any created files on\n      // exception; this saves all codecs from having to do\n      // it:\n      TrackingDirectoryWrapper trackingDir = new TrackingDirectoryWrapper(dir);\n\n      // We can write directly to the actual name (vs to a\n      // .tmp & renaming it) because the file is not live\n      // until segments file is written:\n      boolean success = false;\n      try {\n        info.info.getCodec().liveDocsFormat().writeLiveDocs((MutableBits)liveDocs, trackingDir, info, pendingDeleteCount, IOContext.DEFAULT);\n        success = true;\n      } finally {\n        if (!success) {\n          // Advance only the nextWriteDelGen so that a 2nd\n          // attempt to write will write to a new file\n          info.advanceNextWriteDelGen();\n\n          // Delete any partially created file(s):\n          for(String fileName : trackingDir.getCreatedFiles()) {\n            try {\n              dir.deleteFile(fileName);\n            } catch (Throwable t) {\n              // Ignore so we throw only the first exc\n            }\n          }\n        }\n      }\n\n      // If we hit an exc in the line above (eg disk full)\n      // then info's delGen remains pointing to the previous\n      // (successfully written) del docs:\n      info.advanceDelGen();\n      info.setDelCount(info.getDelCount() + pendingDeleteCount);\n\n      pendingDeleteCount = 0;\n      return true;\n    } else {\n      return false;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"75e4e08ceec867127dcd9913a5ebbc46cf85a28d","date":1379651991,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/ReadersAndLiveDocs#writeLiveDocs(Directory).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/ReadersAndLiveDocs#writeLiveDocs(Directory).mjava","sourceNew":"  // Commit live docs (writes new _X_N.del files) and field updates (writes new\n  // _X_N updates files) to the directory; returns true if it wrote any file\n  // and false if there were no new deletes or updates to write:\n  // TODO (DVU_RENAME) to writeDeletesAndUpdates\n  public synchronized boolean writeLiveDocs(Directory dir) throws IOException {\n    assert Thread.holdsLock(writer);\n    //System.out.println(\"rld.writeLiveDocs seg=\" + info + \" pendingDelCount=\" + pendingDeleteCount + \" numericUpdates=\" + numericUpdates);\n    final boolean hasFieldUpdates = hasFieldUpdates();\n    if (pendingDeleteCount == 0 && !hasFieldUpdates) {\n      return false;\n    }\n    \n    // We have new deletes or updates\n    if (pendingDeleteCount > 0) {\n      assert liveDocs.length() == info.info.getDocCount();\n    }\n    \n    // Do this so we can delete any created files on\n    // exception; this saves all codecs from having to do\n    // it:\n    TrackingDirectoryWrapper trackingDir = new TrackingDirectoryWrapper(dir);\n    \n    // We can write directly to the actual name (vs to a\n    // .tmp & renaming it) because the file is not live\n    // until segments file is written:\n    boolean success = false;\n    try {\n      Codec codec = info.info.getCodec();\n      if (pendingDeleteCount > 0) {\n        codec.liveDocsFormat().writeLiveDocs((MutableBits)liveDocs, trackingDir, info, pendingDeleteCount, IOContext.DEFAULT);\n      }\n      \n      // apply numeric updates if there are any\n      if (hasFieldUpdates) {\n        // reader could be null e.g. for a just merged segment (from\n        // IndexWriter.commitMergedDeletes).\n//        if (this.reader == null) System.out.println(\"[\" + Thread.currentThread().getName() + \"] RLD.writeLiveDocs: newSR \" + info);\n        final SegmentReader reader = this.reader == null ? new SegmentReader(info, IOContext.READONCE) : this.reader;\n        try {\n          // clone FieldInfos so that we can update their numericUpdatesGen\n          // separately from the reader's infos and write them to a new\n          // fieldInfos_gen file\n          FieldInfos.Builder builder = new FieldInfos.Builder(writer.globalFieldNumberMap);\n          // cannot use builder.add(reader.getFieldInfos()) because it does not clone FI.attributes\n          for (FieldInfo fi : reader.getFieldInfos()) {\n            FieldInfo clone = builder.add(fi);\n            // copy the stuff FieldInfos.Builder doesn't copy\n            if (fi.attributes() != null) {\n              for (Entry<String,String> e : fi.attributes().entrySet()) {\n                clone.putAttribute(e.getKey(), e.getValue());\n              }\n            }\n          }\n          // create new fields or update existing ones to have NumericDV type\n//          for (String f : numericUpdates.keySet()) {\n//            builder.addOrUpdate(f, NumericDocValuesField.TYPE);\n//          }\n          \n          final FieldInfos fieldInfos = builder.finish();\n          final long nextDocValuesGen = info.getNextDocValuesGen();\n          final String segmentSuffix = Long.toString(nextDocValuesGen, Character.MAX_RADIX);\n          final SegmentWriteState state = new SegmentWriteState(null, trackingDir, info.info, fieldInfos, null, IOContext.DEFAULT, segmentSuffix, true);\n          final DocValuesFormat docValuesFormat = codec.docValuesFormat();\n          final DocValuesConsumer fieldsConsumer = docValuesFormat.fieldsConsumer(state);\n          boolean fieldsConsumerSuccess = false;\n          try {\n//            System.out.println(\"[\" + Thread.currentThread().getName() + \"] RLD.writeLiveDocs: applying updates; seg=\" + info + \" updates=\" + numericUpdates);\n            for (Entry<String,Map<Integer,Long>> e : numericUpdates.entrySet()) {\n              final String field = e.getKey();\n              final Map<Integer,Long> updates = e.getValue();\n              final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n\n              if (fieldInfo == null || fieldInfo.getDocValuesType() != DocValuesType.NUMERIC) {\n                throw new UnsupportedOperationException(\n                    \"cannot update docvalues in a segment with no docvalues field: segment=\" + info + \", field=\" + field);\n              }\n//              assert fieldInfo != null;\n\n              info.setDocValuesGen(fieldInfo.number, nextDocValuesGen);\n              \n              // write the numeric updates to a new gen'd docvalues file\n              fieldsConsumer.addNumericField(fieldInfo, new Iterable<Number>() {\n                @SuppressWarnings(\"synthetic-access\")\n                final NumericDocValues currentValues = reader.getNumericDocValues(field);\n                @Override\n                public Iterator<Number> iterator() {\n                  return new Iterator<Number>() {\n\n                    @SuppressWarnings(\"synthetic-access\")\n                    final int maxDoc = reader.maxDoc();\n                    int curDoc = -1;\n                    \n                    @Override\n                    public boolean hasNext() {\n                      return curDoc < maxDoc - 1;\n                    }\n\n                    @Override\n                    public Number next() {\n                      if (++curDoc >= maxDoc) {\n                        throw new NoSuchElementException(\"no more documents to return values for\");\n                      }\n                      Long updatedValue = updates.get(curDoc);\n                      if (updatedValue == null) {\n                        updatedValue = Long.valueOf(currentValues.get(curDoc));\n                      } else if (updatedValue == NumericUpdate.MISSING) {\n                        updatedValue = null;\n                      }\n                      return updatedValue;\n                    }\n\n                    @Override\n                    public void remove() {\n                      throw new UnsupportedOperationException(\"this iterator does not support removing elements\");\n                    }\n                    \n                  };\n                }\n              });\n            }\n            fieldsConsumerSuccess = true;\n          } finally {\n            if (fieldsConsumerSuccess) {\n              fieldsConsumer.close();\n            } else {\n              IOUtils.closeWhileHandlingException(fieldsConsumer);\n            }\n          }\n        } finally {\n          if (reader != this.reader) {\n//            System.out.println(\"[\" + Thread.currentThread().getName() + \"] RLD.writeLiveDocs: closeReader \" + reader);\n            reader.close();\n          }\n        }\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        // Advance only the nextWriteDelGen so that a 2nd\n        // attempt to write will write to a new file\n        if (pendingDeleteCount > 0) {\n          info.advanceNextWriteDelGen();\n        }\n        \n        // Advance only the nextWriteDocValuesGen so that a 2nd\n        // attempt to write will write to a new file\n        if (hasFieldUpdates) {\n          info.advanceNextWriteDocValuesGen();\n        }\n        \n        // Delete any partially created file(s):\n        for (String fileName : trackingDir.getCreatedFiles()) {\n          try {\n            dir.deleteFile(fileName);\n          } catch (Throwable t) {\n            // Ignore so we throw only the first exc\n          }\n        }\n      }\n    }\n    \n    // If we hit an exc in the line above (eg disk full)\n    // then info's delGen remains pointing to the previous\n    // (successfully written) del docs:\n    if (pendingDeleteCount > 0) {\n      info.advanceDelGen();\n      info.setDelCount(info.getDelCount() + pendingDeleteCount);\n      pendingDeleteCount = 0;\n    }\n    \n    if (hasFieldUpdates) {\n      info.advanceDocValuesGen();\n      // copy all the updates to mergingUpdates, so they can later be applied to the merged segment\n      if (isMerging || true) {\n        copyUpdatesToMerging();\n      }\n      numericUpdates.clear();\n    }\n\n    info.addUpdatesFiles(trackingDir.getCreatedFiles());\n    \n    return true;\n  }\n\n","sourceOld":"  // Commit live docs (writes new _X_N.del files) and field updates (writes new\n  // _X_N updates files) to the directory; returns true if it wrote any file\n  // and false if there were no new deletes or updates to write:\n  // TODO (DVU_RENAME) to writeDeletesAndUpdates\n  public synchronized boolean writeLiveDocs(Directory dir) throws IOException {\n    assert Thread.holdsLock(writer);\n    //System.out.println(\"rld.writeLiveDocs seg=\" + info + \" pendingDelCount=\" + pendingDeleteCount + \" numericUpdates=\" + numericUpdates);\n    final boolean hasFieldUpdates = hasFieldUpdates();\n    if (pendingDeleteCount == 0 && !hasFieldUpdates) {\n      return false;\n    }\n    \n    // We have new deletes or updates\n    if (pendingDeleteCount > 0) {\n      assert liveDocs.length() == info.info.getDocCount();\n    }\n    \n    // Do this so we can delete any created files on\n    // exception; this saves all codecs from having to do\n    // it:\n    TrackingDirectoryWrapper trackingDir = new TrackingDirectoryWrapper(dir);\n    \n    // We can write directly to the actual name (vs to a\n    // .tmp & renaming it) because the file is not live\n    // until segments file is written:\n    boolean success = false;\n    try {\n      Codec codec = info.info.getCodec();\n      if (pendingDeleteCount > 0) {\n        codec.liveDocsFormat().writeLiveDocs((MutableBits)liveDocs, trackingDir, info, pendingDeleteCount, IOContext.DEFAULT);\n      }\n      \n      // apply numeric updates if there are any\n      if (hasFieldUpdates) {\n        // reader could be null e.g. for a just merged segment (from\n        // IndexWriter.commitMergedDeletes).\n        final SegmentReader reader = this.reader == null ? new SegmentReader(info, IOContext.READONCE) : this.reader;\n        try {\n          // clone FieldInfos so that we can update their numericUpdatesGen\n          // separately from the reader's infos and write them to a new\n          // fieldInfos_gen file\n          FieldInfos.Builder builder = new FieldInfos.Builder(writer.globalFieldNumberMap);\n          // cannot use builder.add(reader.getFieldInfos()) because it does not clone FI.attributes\n          for (FieldInfo fi : reader.getFieldInfos()) {\n            FieldInfo clone = builder.add(fi);\n            // copy the stuff FieldInfos.Builder doesn't copy\n            if (fi.attributes() != null) {\n              for (Entry<String,String> e : fi.attributes().entrySet()) {\n                clone.putAttribute(e.getKey(), e.getValue());\n              }\n            }\n          }\n          // create new fields or update existing ones to have NumericDV type\n//          for (String f : numericUpdates.keySet()) {\n//            builder.addOrUpdate(f, NumericDocValuesField.TYPE);\n//          }\n          \n          final FieldInfos fieldInfos = builder.finish();\n          final long nextDocValuesGen = info.getNextDocValuesGen();\n          final String segmentSuffix = Long.toString(nextDocValuesGen, Character.MAX_RADIX);\n          final SegmentWriteState state = new SegmentWriteState(null, trackingDir, info.info, fieldInfos, null, IOContext.DEFAULT, segmentSuffix, true);\n          final DocValuesFormat docValuesFormat = codec.docValuesFormat();\n          final DocValuesConsumer fieldsConsumer = docValuesFormat.fieldsConsumer(state);\n          boolean fieldsConsumerSuccess = false;\n          try {\n            for (Entry<String,Map<Integer,Long>> e : numericUpdates.entrySet()) {\n              final String field = e.getKey();\n              final Map<Integer,Long> updates = e.getValue();\n              final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n\n              if (fieldInfo == null || fieldInfo.getDocValuesType() != DocValuesType.NUMERIC) {\n                throw new UnsupportedOperationException(\n                    \"cannot update docvalues in a segment with no docvalues field: segment=\" + info + \", field=\" + field);\n              }\n//              assert fieldInfo != null;\n\n              info.setDocValuesGen(fieldInfo.number, nextDocValuesGen);\n              \n              // write the numeric updates to a new gen'd docvalues file\n              fieldsConsumer.addNumericField(fieldInfo, new Iterable<Number>() {\n                @SuppressWarnings(\"synthetic-access\")\n                final NumericDocValues currentValues = reader.getNumericDocValues(field);\n                @Override\n                public Iterator<Number> iterator() {\n                  return new Iterator<Number>() {\n\n                    @SuppressWarnings(\"synthetic-access\")\n                    final int maxDoc = reader.maxDoc();\n                    int curDoc = -1;\n                    \n                    @Override\n                    public boolean hasNext() {\n                      return curDoc < maxDoc - 1;\n                    }\n\n                    @Override\n                    public Number next() {\n                      if (++curDoc >= maxDoc) {\n                        throw new NoSuchElementException(\"no more documents to return values for\");\n                      }\n                      Long updatedValue = updates.get(curDoc);\n                      if (updatedValue == null) {\n                        updatedValue = Long.valueOf(currentValues.get(curDoc));\n                      } else if (updatedValue == NumericUpdate.MISSING) {\n                        updatedValue = null;\n                      }\n                      return updatedValue;\n                    }\n\n                    @Override\n                    public void remove() {\n                      throw new UnsupportedOperationException(\"this iterator does not support removing elements\");\n                    }\n                    \n                  };\n                }\n              });\n            }\n            fieldsConsumerSuccess = true;\n          } finally {\n            if (fieldsConsumerSuccess) {\n              fieldsConsumer.close();\n            } else {\n              IOUtils.closeWhileHandlingException(fieldsConsumer);\n            }\n          }\n        } finally {\n          if (reader != this.reader) {\n            reader.close();\n          }\n        }\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        // Advance only the nextWriteDelGen so that a 2nd\n        // attempt to write will write to a new file\n        if (pendingDeleteCount > 0) {\n          info.advanceNextWriteDelGen();\n        }\n        \n        // Advance only the nextWriteDocValuesGen so that a 2nd\n        // attempt to write will write to a new file\n        if (hasFieldUpdates) {\n          info.advanceNextWriteDocValuesGen();\n        }\n        \n        // Delete any partially created file(s):\n        for (String fileName : trackingDir.getCreatedFiles()) {\n          try {\n            dir.deleteFile(fileName);\n          } catch (Throwable t) {\n            // Ignore so we throw only the first exc\n          }\n        }\n      }\n    }\n    \n    // If we hit an exc in the line above (eg disk full)\n    // then info's delGen remains pointing to the previous\n    // (successfully written) del docs:\n    if (pendingDeleteCount > 0) {\n      info.advanceDelGen();\n      info.setDelCount(info.getDelCount() + pendingDeleteCount);\n      pendingDeleteCount = 0;\n    }\n    \n    if (hasFieldUpdates) {\n      info.advanceDocValuesGen();\n      // copy all the updates to mergingUpdates, so they can later be applied to the merged segment\n      if (isMerging) {\n        copyUpdatesToMerging();\n      }\n      numericUpdates.clear();\n    }\n\n    info.addUpdatesFiles(trackingDir.getCreatedFiles());\n    \n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f5b39aaa88608b25873a62fe4b2a5d8edf1a2966","date":1379652924,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/ReadersAndLiveDocs#writeLiveDocs(Directory).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/ReadersAndLiveDocs#writeLiveDocs(Directory).mjava","sourceNew":"  // Commit live docs (writes new _X_N.del files) and field updates (writes new\n  // _X_N updates files) to the directory; returns true if it wrote any file\n  // and false if there were no new deletes or updates to write:\n  // TODO (DVU_RENAME) to writeDeletesAndUpdates\n  public synchronized boolean writeLiveDocs(Directory dir) throws IOException {\n    assert Thread.holdsLock(writer);\n    //System.out.println(\"rld.writeLiveDocs seg=\" + info + \" pendingDelCount=\" + pendingDeleteCount + \" numericUpdates=\" + numericUpdates);\n    final boolean hasFieldUpdates = hasFieldUpdates();\n    if (pendingDeleteCount == 0 && !hasFieldUpdates) {\n      return false;\n    }\n    \n    // We have new deletes or updates\n    if (pendingDeleteCount > 0) {\n      assert liveDocs.length() == info.info.getDocCount();\n    }\n    \n    // Do this so we can delete any created files on\n    // exception; this saves all codecs from having to do\n    // it:\n    TrackingDirectoryWrapper trackingDir = new TrackingDirectoryWrapper(dir);\n    \n    // We can write directly to the actual name (vs to a\n    // .tmp & renaming it) because the file is not live\n    // until segments file is written:\n    boolean success = false;\n    try {\n      Codec codec = info.info.getCodec();\n      if (pendingDeleteCount > 0) {\n        codec.liveDocsFormat().writeLiveDocs((MutableBits)liveDocs, trackingDir, info, pendingDeleteCount, IOContext.DEFAULT);\n      }\n      \n      // apply numeric updates if there are any\n      if (hasFieldUpdates) {\n        // reader could be null e.g. for a just merged segment (from\n        // IndexWriter.commitMergedDeletes).\n//        if (this.reader == null) System.out.println(\"[\" + Thread.currentThread().getName() + \"] RLD.writeLiveDocs: newSR \" + info);\n        final SegmentReader reader = this.reader == null ? new SegmentReader(info, IOContext.READONCE) : this.reader;\n        try {\n          // clone FieldInfos so that we can update their numericUpdatesGen\n          // separately from the reader's infos and write them to a new\n          // fieldInfos_gen file\n          FieldInfos.Builder builder = new FieldInfos.Builder(writer.globalFieldNumberMap);\n          // cannot use builder.add(reader.getFieldInfos()) because it does not clone FI.attributes\n          for (FieldInfo fi : reader.getFieldInfos()) {\n            FieldInfo clone = builder.add(fi);\n            // copy the stuff FieldInfos.Builder doesn't copy\n            if (fi.attributes() != null) {\n              for (Entry<String,String> e : fi.attributes().entrySet()) {\n                clone.putAttribute(e.getKey(), e.getValue());\n              }\n            }\n          }\n          // create new fields or update existing ones to have NumericDV type\n//          for (String f : numericUpdates.keySet()) {\n//            builder.addOrUpdate(f, NumericDocValuesField.TYPE);\n//          }\n          \n          final FieldInfos fieldInfos = builder.finish();\n          final long nextDocValuesGen = info.getNextDocValuesGen();\n          final String segmentSuffix = Long.toString(nextDocValuesGen, Character.MAX_RADIX);\n          final SegmentWriteState state = new SegmentWriteState(null, trackingDir, info.info, fieldInfos, null, IOContext.DEFAULT, segmentSuffix, true);\n          final DocValuesFormat docValuesFormat = codec.docValuesFormat();\n          final DocValuesConsumer fieldsConsumer = docValuesFormat.fieldsConsumer(state);\n          boolean fieldsConsumerSuccess = false;\n          try {\n//            System.out.println(\"[\" + Thread.currentThread().getName() + \"] RLD.writeLiveDocs: applying updates; seg=\" + info + \" updates=\" + numericUpdates);\n            for (Entry<String,Map<Integer,Long>> e : numericUpdates.entrySet()) {\n              final String field = e.getKey();\n              final Map<Integer,Long> updates = e.getValue();\n              final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n\n              if (fieldInfo == null || fieldInfo.getDocValuesType() != DocValuesType.NUMERIC) {\n                throw new UnsupportedOperationException(\n                    \"cannot update docvalues in a segment with no docvalues field: segment=\" + info + \", field=\" + field);\n              }\n//              assert fieldInfo != null;\n\n              info.setDocValuesGen(fieldInfo.number, nextDocValuesGen);\n              \n              // write the numeric updates to a new gen'd docvalues file\n              fieldsConsumer.addNumericField(fieldInfo, new Iterable<Number>() {\n                @SuppressWarnings(\"synthetic-access\")\n                final NumericDocValues currentValues = reader.getNumericDocValues(field);\n                @Override\n                public Iterator<Number> iterator() {\n                  return new Iterator<Number>() {\n\n                    @SuppressWarnings(\"synthetic-access\")\n                    final int maxDoc = reader.maxDoc();\n                    int curDoc = -1;\n                    \n                    @Override\n                    public boolean hasNext() {\n                      return curDoc < maxDoc - 1;\n                    }\n\n                    @Override\n                    public Number next() {\n                      if (++curDoc >= maxDoc) {\n                        throw new NoSuchElementException(\"no more documents to return values for\");\n                      }\n                      Long updatedValue = updates.get(curDoc);\n                      if (updatedValue == null) {\n                        updatedValue = Long.valueOf(currentValues.get(curDoc));\n                      } else if (updatedValue == NumericUpdate.MISSING) {\n                        updatedValue = null;\n                      }\n                      return updatedValue;\n                    }\n\n                    @Override\n                    public void remove() {\n                      throw new UnsupportedOperationException(\"this iterator does not support removing elements\");\n                    }\n                    \n                  };\n                }\n              });\n            }\n            fieldsConsumerSuccess = true;\n          } finally {\n            if (fieldsConsumerSuccess) {\n              fieldsConsumer.close();\n            } else {\n              IOUtils.closeWhileHandlingException(fieldsConsumer);\n            }\n          }\n        } finally {\n          if (reader != this.reader) {\n//            System.out.println(\"[\" + Thread.currentThread().getName() + \"] RLD.writeLiveDocs: closeReader \" + reader);\n            reader.close();\n          }\n        }\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        // Advance only the nextWriteDelGen so that a 2nd\n        // attempt to write will write to a new file\n        if (pendingDeleteCount > 0) {\n          info.advanceNextWriteDelGen();\n        }\n        \n        // Advance only the nextWriteDocValuesGen so that a 2nd\n        // attempt to write will write to a new file\n        if (hasFieldUpdates) {\n          info.advanceNextWriteDocValuesGen();\n        }\n        \n        // Delete any partially created file(s):\n        for (String fileName : trackingDir.getCreatedFiles()) {\n          try {\n            dir.deleteFile(fileName);\n          } catch (Throwable t) {\n            // Ignore so we throw only the first exc\n          }\n        }\n      }\n    }\n    \n    // If we hit an exc in the line above (eg disk full)\n    // then info's delGen remains pointing to the previous\n    // (successfully written) del docs:\n    if (pendingDeleteCount > 0) {\n      info.advanceDelGen();\n      info.setDelCount(info.getDelCount() + pendingDeleteCount);\n      pendingDeleteCount = 0;\n    }\n    \n    if (hasFieldUpdates) {\n      info.advanceDocValuesGen();\n      // copy all the updates to mergingUpdates, so they can later be applied to the merged segment\n      if (isMerging) {\n        copyUpdatesToMerging();\n      }\n      numericUpdates.clear();\n    }\n\n    info.addUpdatesFiles(trackingDir.getCreatedFiles());\n    \n    return true;\n  }\n\n","sourceOld":"  // Commit live docs (writes new _X_N.del files) and field updates (writes new\n  // _X_N updates files) to the directory; returns true if it wrote any file\n  // and false if there were no new deletes or updates to write:\n  // TODO (DVU_RENAME) to writeDeletesAndUpdates\n  public synchronized boolean writeLiveDocs(Directory dir) throws IOException {\n    assert Thread.holdsLock(writer);\n    //System.out.println(\"rld.writeLiveDocs seg=\" + info + \" pendingDelCount=\" + pendingDeleteCount + \" numericUpdates=\" + numericUpdates);\n    final boolean hasFieldUpdates = hasFieldUpdates();\n    if (pendingDeleteCount == 0 && !hasFieldUpdates) {\n      return false;\n    }\n    \n    // We have new deletes or updates\n    if (pendingDeleteCount > 0) {\n      assert liveDocs.length() == info.info.getDocCount();\n    }\n    \n    // Do this so we can delete any created files on\n    // exception; this saves all codecs from having to do\n    // it:\n    TrackingDirectoryWrapper trackingDir = new TrackingDirectoryWrapper(dir);\n    \n    // We can write directly to the actual name (vs to a\n    // .tmp & renaming it) because the file is not live\n    // until segments file is written:\n    boolean success = false;\n    try {\n      Codec codec = info.info.getCodec();\n      if (pendingDeleteCount > 0) {\n        codec.liveDocsFormat().writeLiveDocs((MutableBits)liveDocs, trackingDir, info, pendingDeleteCount, IOContext.DEFAULT);\n      }\n      \n      // apply numeric updates if there are any\n      if (hasFieldUpdates) {\n        // reader could be null e.g. for a just merged segment (from\n        // IndexWriter.commitMergedDeletes).\n//        if (this.reader == null) System.out.println(\"[\" + Thread.currentThread().getName() + \"] RLD.writeLiveDocs: newSR \" + info);\n        final SegmentReader reader = this.reader == null ? new SegmentReader(info, IOContext.READONCE) : this.reader;\n        try {\n          // clone FieldInfos so that we can update their numericUpdatesGen\n          // separately from the reader's infos and write them to a new\n          // fieldInfos_gen file\n          FieldInfos.Builder builder = new FieldInfos.Builder(writer.globalFieldNumberMap);\n          // cannot use builder.add(reader.getFieldInfos()) because it does not clone FI.attributes\n          for (FieldInfo fi : reader.getFieldInfos()) {\n            FieldInfo clone = builder.add(fi);\n            // copy the stuff FieldInfos.Builder doesn't copy\n            if (fi.attributes() != null) {\n              for (Entry<String,String> e : fi.attributes().entrySet()) {\n                clone.putAttribute(e.getKey(), e.getValue());\n              }\n            }\n          }\n          // create new fields or update existing ones to have NumericDV type\n//          for (String f : numericUpdates.keySet()) {\n//            builder.addOrUpdate(f, NumericDocValuesField.TYPE);\n//          }\n          \n          final FieldInfos fieldInfos = builder.finish();\n          final long nextDocValuesGen = info.getNextDocValuesGen();\n          final String segmentSuffix = Long.toString(nextDocValuesGen, Character.MAX_RADIX);\n          final SegmentWriteState state = new SegmentWriteState(null, trackingDir, info.info, fieldInfos, null, IOContext.DEFAULT, segmentSuffix, true);\n          final DocValuesFormat docValuesFormat = codec.docValuesFormat();\n          final DocValuesConsumer fieldsConsumer = docValuesFormat.fieldsConsumer(state);\n          boolean fieldsConsumerSuccess = false;\n          try {\n//            System.out.println(\"[\" + Thread.currentThread().getName() + \"] RLD.writeLiveDocs: applying updates; seg=\" + info + \" updates=\" + numericUpdates);\n            for (Entry<String,Map<Integer,Long>> e : numericUpdates.entrySet()) {\n              final String field = e.getKey();\n              final Map<Integer,Long> updates = e.getValue();\n              final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n\n              if (fieldInfo == null || fieldInfo.getDocValuesType() != DocValuesType.NUMERIC) {\n                throw new UnsupportedOperationException(\n                    \"cannot update docvalues in a segment with no docvalues field: segment=\" + info + \", field=\" + field);\n              }\n//              assert fieldInfo != null;\n\n              info.setDocValuesGen(fieldInfo.number, nextDocValuesGen);\n              \n              // write the numeric updates to a new gen'd docvalues file\n              fieldsConsumer.addNumericField(fieldInfo, new Iterable<Number>() {\n                @SuppressWarnings(\"synthetic-access\")\n                final NumericDocValues currentValues = reader.getNumericDocValues(field);\n                @Override\n                public Iterator<Number> iterator() {\n                  return new Iterator<Number>() {\n\n                    @SuppressWarnings(\"synthetic-access\")\n                    final int maxDoc = reader.maxDoc();\n                    int curDoc = -1;\n                    \n                    @Override\n                    public boolean hasNext() {\n                      return curDoc < maxDoc - 1;\n                    }\n\n                    @Override\n                    public Number next() {\n                      if (++curDoc >= maxDoc) {\n                        throw new NoSuchElementException(\"no more documents to return values for\");\n                      }\n                      Long updatedValue = updates.get(curDoc);\n                      if (updatedValue == null) {\n                        updatedValue = Long.valueOf(currentValues.get(curDoc));\n                      } else if (updatedValue == NumericUpdate.MISSING) {\n                        updatedValue = null;\n                      }\n                      return updatedValue;\n                    }\n\n                    @Override\n                    public void remove() {\n                      throw new UnsupportedOperationException(\"this iterator does not support removing elements\");\n                    }\n                    \n                  };\n                }\n              });\n            }\n            fieldsConsumerSuccess = true;\n          } finally {\n            if (fieldsConsumerSuccess) {\n              fieldsConsumer.close();\n            } else {\n              IOUtils.closeWhileHandlingException(fieldsConsumer);\n            }\n          }\n        } finally {\n          if (reader != this.reader) {\n//            System.out.println(\"[\" + Thread.currentThread().getName() + \"] RLD.writeLiveDocs: closeReader \" + reader);\n            reader.close();\n          }\n        }\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        // Advance only the nextWriteDelGen so that a 2nd\n        // attempt to write will write to a new file\n        if (pendingDeleteCount > 0) {\n          info.advanceNextWriteDelGen();\n        }\n        \n        // Advance only the nextWriteDocValuesGen so that a 2nd\n        // attempt to write will write to a new file\n        if (hasFieldUpdates) {\n          info.advanceNextWriteDocValuesGen();\n        }\n        \n        // Delete any partially created file(s):\n        for (String fileName : trackingDir.getCreatedFiles()) {\n          try {\n            dir.deleteFile(fileName);\n          } catch (Throwable t) {\n            // Ignore so we throw only the first exc\n          }\n        }\n      }\n    }\n    \n    // If we hit an exc in the line above (eg disk full)\n    // then info's delGen remains pointing to the previous\n    // (successfully written) del docs:\n    if (pendingDeleteCount > 0) {\n      info.advanceDelGen();\n      info.setDelCount(info.getDelCount() + pendingDeleteCount);\n      pendingDeleteCount = 0;\n    }\n    \n    if (hasFieldUpdates) {\n      info.advanceDocValuesGen();\n      // copy all the updates to mergingUpdates, so they can later be applied to the merged segment\n      if (isMerging || true) {\n        copyUpdatesToMerging();\n      }\n      numericUpdates.clear();\n    }\n\n    info.addUpdatesFiles(trackingDir.getCreatedFiles());\n    \n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8435160e9702b19398118ddf76b61c846612b6a4","date":1380349140,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/ReadersAndLiveDocs#writeLiveDocs(Directory).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/ReadersAndLiveDocs#writeLiveDocs(Directory).mjava","sourceNew":"  // Commit live docs (writes new _X_N.del files) and field updates (writes new\n  // _X_N updates files) to the directory; returns true if it wrote any file\n  // and false if there were no new deletes or updates to write:\n  // TODO (DVU_RENAME) to writeDeletesAndUpdates\n  public synchronized boolean writeLiveDocs(Directory dir) throws IOException {\n    assert Thread.holdsLock(writer);\n    //System.out.println(\"rld.writeLiveDocs seg=\" + info + \" pendingDelCount=\" + pendingDeleteCount + \" numericUpdates=\" + numericUpdates);\n    final boolean hasFieldUpdates = hasFieldUpdates();\n    if (pendingDeleteCount == 0 && !hasFieldUpdates) {\n      return false;\n    }\n    \n    // We have new deletes or updates\n    assert pendingDeleteCount == 0 || liveDocs.length() == info.info.getDocCount();\n    \n    // Do this so we can delete any created files on\n    // exception; this saves all codecs from having to do\n    // it:\n    TrackingDirectoryWrapper trackingDir = new TrackingDirectoryWrapper(dir);\n    \n    // We can write directly to the actual name (vs to a\n    // .tmp & renaming it) because the file is not live\n    // until segments file is written:\n    boolean success = false;\n    try {\n      Codec codec = info.info.getCodec();\n      if (pendingDeleteCount > 0) {\n        codec.liveDocsFormat().writeLiveDocs((MutableBits)liveDocs, trackingDir, info, pendingDeleteCount, IOContext.DEFAULT);\n      }\n      \n      // apply numeric updates if there are any\n      if (hasFieldUpdates) {\n        // reader could be null e.g. for a just merged segment (from\n        // IndexWriter.commitMergedDeletes).\n//        if (this.reader == null) System.out.println(\"[\" + Thread.currentThread().getName() + \"] RLD.writeLiveDocs: newSR \" + info);\n        final SegmentReader reader = this.reader == null ? new SegmentReader(info, IOContext.READONCE) : this.reader;\n        try {\n          // clone FieldInfos so that we can update their dvGen separately from\n          // the reader's infos and write them to a new fieldInfos_gen file\n          FieldInfos.Builder builder = new FieldInfos.Builder(writer.globalFieldNumberMap);\n          // cannot use builder.add(reader.getFieldInfos()) because it does not\n          // clone FI.attributes as well FI.dvGen\n          for (FieldInfo fi : reader.getFieldInfos()) {\n            FieldInfo clone = builder.add(fi);\n            // copy the stuff FieldInfos.Builder doesn't copy\n            if (fi.attributes() != null) {\n              for (Entry<String,String> e : fi.attributes().entrySet()) {\n                clone.putAttribute(e.getKey(), e.getValue());\n              }\n            }\n            clone.setDocValuesGen(fi.getDocValuesGen());\n          }\n          // create new fields or update existing ones to have NumericDV type\n          for (String f : numericUpdates.keySet()) {\n            builder.addOrUpdate(f, NumericDocValuesField.TYPE);\n          }\n          \n          final FieldInfos fieldInfos = builder.finish();\n          final long nextFieldInfosGen = info.getNextFieldInfosGen();\n          final String segmentSuffix = Long.toString(nextFieldInfosGen, Character.MAX_RADIX);\n          final SegmentWriteState state = new SegmentWriteState(null, trackingDir, info.info, fieldInfos, null, IOContext.DEFAULT, segmentSuffix);\n          final DocValuesFormat docValuesFormat = codec.docValuesFormat();\n          final DocValuesConsumer fieldsConsumer = docValuesFormat.fieldsConsumer(state);\n          boolean fieldsConsumerSuccess = false;\n          try {\n//            System.out.println(\"[\" + Thread.currentThread().getName() + \"] RLD.writeLiveDocs: applying updates; seg=\" + info + \" updates=\" + numericUpdates);\n            for (Entry<String,Map<Integer,Long>> e : numericUpdates.entrySet()) {\n              final String field = e.getKey();\n              final Map<Integer,Long> updates = e.getValue();\n              final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n\n              assert fieldInfo != null;\n\n              fieldInfo.setDocValuesGen(nextFieldInfosGen);\n              \n              // write the numeric updates to a new gen'd docvalues file\n              fieldsConsumer.addNumericField(fieldInfo, new Iterable<Number>() {\n                @SuppressWarnings(\"synthetic-access\")\n                final NumericDocValues currentValues = reader.getNumericDocValues(field);\n                @Override\n                public Iterator<Number> iterator() {\n                  return new Iterator<Number>() {\n\n                    @SuppressWarnings(\"synthetic-access\")\n                    final int maxDoc = reader.maxDoc();\n                    int curDoc = -1;\n                    \n                    @Override\n                    public boolean hasNext() {\n                      return curDoc < maxDoc - 1;\n                    }\n\n                    @Override\n                    public Number next() {\n                      if (++curDoc >= maxDoc) {\n                        throw new NoSuchElementException(\"no more documents to return values for\");\n                      }\n                      Long updatedValue = updates.get(curDoc);\n                      if (updatedValue == null) {\n                        updatedValue = Long.valueOf(currentValues.get(curDoc));\n                      } else if (updatedValue == NumericUpdate.MISSING) {\n                        updatedValue = null;\n                      }\n                      return updatedValue;\n                    }\n\n                    @Override\n                    public void remove() {\n                      throw new UnsupportedOperationException(\"this iterator does not support removing elements\");\n                    }\n                    \n                  };\n                }\n              });\n            }\n            \n            codec.fieldInfosFormat().getFieldInfosWriter().write(trackingDir, info.info.name, segmentSuffix, fieldInfos, IOContext.DEFAULT);\n            fieldsConsumerSuccess = true;\n          } finally {\n            if (fieldsConsumerSuccess) {\n              fieldsConsumer.close();\n            } else {\n              IOUtils.closeWhileHandlingException(fieldsConsumer);\n            }\n          }\n        } finally {\n          if (reader != this.reader) {\n//            System.out.println(\"[\" + Thread.currentThread().getName() + \"] RLD.writeLiveDocs: closeReader \" + reader);\n            reader.close();\n          }\n        }\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        // Advance only the nextWriteDelGen so that a 2nd\n        // attempt to write will write to a new file\n        if (pendingDeleteCount > 0) {\n          info.advanceNextWriteDelGen();\n        }\n        \n        // Advance only the nextWriteDocValuesGen so that a 2nd\n        // attempt to write will write to a new file\n        if (hasFieldUpdates) {\n          info.advanceNextWriteFieldInfosGen();\n        }\n        \n        // Delete any partially created file(s):\n        for (String fileName : trackingDir.getCreatedFiles()) {\n          try {\n            dir.deleteFile(fileName);\n          } catch (Throwable t) {\n            // Ignore so we throw only the first exc\n          }\n        }\n      }\n    }\n    \n    // If we hit an exc in the line above (eg disk full)\n    // then info's delGen remains pointing to the previous\n    // (successfully written) del docs:\n    if (pendingDeleteCount > 0) {\n      info.advanceDelGen();\n      info.setDelCount(info.getDelCount() + pendingDeleteCount);\n      pendingDeleteCount = 0;\n    }\n    \n    if (hasFieldUpdates) {\n      info.advanceFieldInfosGen();\n      // copy all the updates to mergingUpdates, so they can later be applied to the merged segment\n      if (isMerging) {\n        copyUpdatesToMerging();\n      }\n      numericUpdates.clear();\n    }\n\n    info.addUpdatesFiles(trackingDir.getCreatedFiles());\n    \n    return true;\n  }\n\n","sourceOld":"  // Commit live docs (writes new _X_N.del files) and field updates (writes new\n  // _X_N updates files) to the directory; returns true if it wrote any file\n  // and false if there were no new deletes or updates to write:\n  // TODO (DVU_RENAME) to writeDeletesAndUpdates\n  public synchronized boolean writeLiveDocs(Directory dir) throws IOException {\n    assert Thread.holdsLock(writer);\n    //System.out.println(\"rld.writeLiveDocs seg=\" + info + \" pendingDelCount=\" + pendingDeleteCount + \" numericUpdates=\" + numericUpdates);\n    final boolean hasFieldUpdates = hasFieldUpdates();\n    if (pendingDeleteCount == 0 && !hasFieldUpdates) {\n      return false;\n    }\n    \n    // We have new deletes or updates\n    if (pendingDeleteCount > 0) {\n      assert liveDocs.length() == info.info.getDocCount();\n    }\n    \n    // Do this so we can delete any created files on\n    // exception; this saves all codecs from having to do\n    // it:\n    TrackingDirectoryWrapper trackingDir = new TrackingDirectoryWrapper(dir);\n    \n    // We can write directly to the actual name (vs to a\n    // .tmp & renaming it) because the file is not live\n    // until segments file is written:\n    boolean success = false;\n    try {\n      Codec codec = info.info.getCodec();\n      if (pendingDeleteCount > 0) {\n        codec.liveDocsFormat().writeLiveDocs((MutableBits)liveDocs, trackingDir, info, pendingDeleteCount, IOContext.DEFAULT);\n      }\n      \n      // apply numeric updates if there are any\n      if (hasFieldUpdates) {\n        // reader could be null e.g. for a just merged segment (from\n        // IndexWriter.commitMergedDeletes).\n//        if (this.reader == null) System.out.println(\"[\" + Thread.currentThread().getName() + \"] RLD.writeLiveDocs: newSR \" + info);\n        final SegmentReader reader = this.reader == null ? new SegmentReader(info, IOContext.READONCE) : this.reader;\n        try {\n          // clone FieldInfos so that we can update their numericUpdatesGen\n          // separately from the reader's infos and write them to a new\n          // fieldInfos_gen file\n          FieldInfos.Builder builder = new FieldInfos.Builder(writer.globalFieldNumberMap);\n          // cannot use builder.add(reader.getFieldInfos()) because it does not clone FI.attributes\n          for (FieldInfo fi : reader.getFieldInfos()) {\n            FieldInfo clone = builder.add(fi);\n            // copy the stuff FieldInfos.Builder doesn't copy\n            if (fi.attributes() != null) {\n              for (Entry<String,String> e : fi.attributes().entrySet()) {\n                clone.putAttribute(e.getKey(), e.getValue());\n              }\n            }\n          }\n          // create new fields or update existing ones to have NumericDV type\n//          for (String f : numericUpdates.keySet()) {\n//            builder.addOrUpdate(f, NumericDocValuesField.TYPE);\n//          }\n          \n          final FieldInfos fieldInfos = builder.finish();\n          final long nextDocValuesGen = info.getNextDocValuesGen();\n          final String segmentSuffix = Long.toString(nextDocValuesGen, Character.MAX_RADIX);\n          final SegmentWriteState state = new SegmentWriteState(null, trackingDir, info.info, fieldInfos, null, IOContext.DEFAULT, segmentSuffix, true);\n          final DocValuesFormat docValuesFormat = codec.docValuesFormat();\n          final DocValuesConsumer fieldsConsumer = docValuesFormat.fieldsConsumer(state);\n          boolean fieldsConsumerSuccess = false;\n          try {\n//            System.out.println(\"[\" + Thread.currentThread().getName() + \"] RLD.writeLiveDocs: applying updates; seg=\" + info + \" updates=\" + numericUpdates);\n            for (Entry<String,Map<Integer,Long>> e : numericUpdates.entrySet()) {\n              final String field = e.getKey();\n              final Map<Integer,Long> updates = e.getValue();\n              final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n\n              if (fieldInfo == null || fieldInfo.getDocValuesType() != DocValuesType.NUMERIC) {\n                throw new UnsupportedOperationException(\n                    \"cannot update docvalues in a segment with no docvalues field: segment=\" + info + \", field=\" + field);\n              }\n//              assert fieldInfo != null;\n\n              info.setDocValuesGen(fieldInfo.number, nextDocValuesGen);\n              \n              // write the numeric updates to a new gen'd docvalues file\n              fieldsConsumer.addNumericField(fieldInfo, new Iterable<Number>() {\n                @SuppressWarnings(\"synthetic-access\")\n                final NumericDocValues currentValues = reader.getNumericDocValues(field);\n                @Override\n                public Iterator<Number> iterator() {\n                  return new Iterator<Number>() {\n\n                    @SuppressWarnings(\"synthetic-access\")\n                    final int maxDoc = reader.maxDoc();\n                    int curDoc = -1;\n                    \n                    @Override\n                    public boolean hasNext() {\n                      return curDoc < maxDoc - 1;\n                    }\n\n                    @Override\n                    public Number next() {\n                      if (++curDoc >= maxDoc) {\n                        throw new NoSuchElementException(\"no more documents to return values for\");\n                      }\n                      Long updatedValue = updates.get(curDoc);\n                      if (updatedValue == null) {\n                        updatedValue = Long.valueOf(currentValues.get(curDoc));\n                      } else if (updatedValue == NumericUpdate.MISSING) {\n                        updatedValue = null;\n                      }\n                      return updatedValue;\n                    }\n\n                    @Override\n                    public void remove() {\n                      throw new UnsupportedOperationException(\"this iterator does not support removing elements\");\n                    }\n                    \n                  };\n                }\n              });\n            }\n            fieldsConsumerSuccess = true;\n          } finally {\n            if (fieldsConsumerSuccess) {\n              fieldsConsumer.close();\n            } else {\n              IOUtils.closeWhileHandlingException(fieldsConsumer);\n            }\n          }\n        } finally {\n          if (reader != this.reader) {\n//            System.out.println(\"[\" + Thread.currentThread().getName() + \"] RLD.writeLiveDocs: closeReader \" + reader);\n            reader.close();\n          }\n        }\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        // Advance only the nextWriteDelGen so that a 2nd\n        // attempt to write will write to a new file\n        if (pendingDeleteCount > 0) {\n          info.advanceNextWriteDelGen();\n        }\n        \n        // Advance only the nextWriteDocValuesGen so that a 2nd\n        // attempt to write will write to a new file\n        if (hasFieldUpdates) {\n          info.advanceNextWriteDocValuesGen();\n        }\n        \n        // Delete any partially created file(s):\n        for (String fileName : trackingDir.getCreatedFiles()) {\n          try {\n            dir.deleteFile(fileName);\n          } catch (Throwable t) {\n            // Ignore so we throw only the first exc\n          }\n        }\n      }\n    }\n    \n    // If we hit an exc in the line above (eg disk full)\n    // then info's delGen remains pointing to the previous\n    // (successfully written) del docs:\n    if (pendingDeleteCount > 0) {\n      info.advanceDelGen();\n      info.setDelCount(info.getDelCount() + pendingDeleteCount);\n      pendingDeleteCount = 0;\n    }\n    \n    if (hasFieldUpdates) {\n      info.advanceDocValuesGen();\n      // copy all the updates to mergingUpdates, so they can later be applied to the merged segment\n      if (isMerging) {\n        copyUpdatesToMerging();\n      }\n      numericUpdates.clear();\n    }\n\n    info.addUpdatesFiles(trackingDir.getCreatedFiles());\n    \n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2f13fb377f9b5df46af44bf90a2e507a884f2c30","date":1380476222,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/ReadersAndLiveDocs#writeLiveDocs(Directory).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/ReadersAndLiveDocs#writeLiveDocs(Directory).mjava","sourceNew":"  // Commit live docs (writes new _X_N.del files) and field updates (writes new\n  // _X_N updates files) to the directory; returns true if it wrote any file\n  // and false if there were no new deletes or updates to write:\n  // TODO (DVU_RENAME) to writeDeletesAndUpdates\n  public synchronized boolean writeLiveDocs(Directory dir) throws IOException {\n    assert Thread.holdsLock(writer);\n    //System.out.println(\"rld.writeLiveDocs seg=\" + info + \" pendingDelCount=\" + pendingDeleteCount + \" numericUpdates=\" + numericUpdates);\n    final boolean hasFieldUpdates = hasFieldUpdates();\n    if (pendingDeleteCount == 0 && !hasFieldUpdates) {\n      return false;\n    }\n    \n    // We have new deletes or updates\n    assert pendingDeleteCount == 0 || liveDocs.length() == info.info.getDocCount();\n    \n    // Do this so we can delete any created files on\n    // exception; this saves all codecs from having to do\n    // it:\n    TrackingDirectoryWrapper trackingDir = new TrackingDirectoryWrapper(dir);\n    \n    // We can write directly to the actual name (vs to a\n    // .tmp & renaming it) because the file is not live\n    // until segments file is written:\n    FieldInfos fieldInfos = null;\n    boolean success = false;\n    try {\n      Codec codec = info.info.getCodec();\n      if (pendingDeleteCount > 0) {\n        codec.liveDocsFormat().writeLiveDocs((MutableBits)liveDocs, trackingDir, info, pendingDeleteCount, IOContext.DEFAULT);\n      }\n      \n      // apply numeric updates if there are any\n      if (hasFieldUpdates) {\n        // reader could be null e.g. for a just merged segment (from\n        // IndexWriter.commitMergedDeletes).\n//        if (this.reader == null) System.out.println(\"[\" + Thread.currentThread().getName() + \"] RLD.writeLiveDocs: newSR \" + info);\n        final SegmentReader reader = this.reader == null ? new SegmentReader(info, IOContext.READONCE) : this.reader;\n        try {\n          // clone FieldInfos so that we can update their dvGen separately from\n          // the reader's infos and write them to a new fieldInfos_gen file\n          FieldInfos.Builder builder = new FieldInfos.Builder(writer.globalFieldNumberMap);\n          // cannot use builder.add(reader.getFieldInfos()) because it does not\n          // clone FI.attributes as well FI.dvGen\n          for (FieldInfo fi : reader.getFieldInfos()) {\n            FieldInfo clone = builder.add(fi);\n            // copy the stuff FieldInfos.Builder doesn't copy\n            if (fi.attributes() != null) {\n              for (Entry<String,String> e : fi.attributes().entrySet()) {\n                clone.putAttribute(e.getKey(), e.getValue());\n              }\n            }\n            clone.setDocValuesGen(fi.getDocValuesGen());\n          }\n          // create new fields or update existing ones to have NumericDV type\n          for (String f : numericUpdates.keySet()) {\n            builder.addOrUpdate(f, NumericDocValuesField.TYPE);\n          }\n          \n          fieldInfos = builder.finish();\n          final long nextFieldInfosGen = info.getNextFieldInfosGen();\n          final String segmentSuffix = Long.toString(nextFieldInfosGen, Character.MAX_RADIX);\n          final SegmentWriteState state = new SegmentWriteState(null, trackingDir, info.info, fieldInfos, null, IOContext.DEFAULT, segmentSuffix);\n          final DocValuesFormat docValuesFormat = codec.docValuesFormat();\n          final DocValuesConsumer fieldsConsumer = docValuesFormat.fieldsConsumer(state);\n          boolean fieldsConsumerSuccess = false;\n          try {\n//            System.out.println(\"[\" + Thread.currentThread().getName() + \"] RLD.writeLiveDocs: applying updates; seg=\" + info + \" updates=\" + numericUpdates);\n            for (Entry<String,Map<Integer,Long>> e : numericUpdates.entrySet()) {\n              final String field = e.getKey();\n              final Map<Integer,Long> updates = e.getValue();\n              final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n\n              assert fieldInfo != null;\n\n              fieldInfo.setDocValuesGen(nextFieldInfosGen);\n              \n              // write the numeric updates to a new gen'd docvalues file\n              fieldsConsumer.addNumericField(fieldInfo, new Iterable<Number>() {\n                @SuppressWarnings(\"synthetic-access\")\n                final NumericDocValues currentValues = reader.getNumericDocValues(field);\n                @Override\n                public Iterator<Number> iterator() {\n                  return new Iterator<Number>() {\n\n                    @SuppressWarnings(\"synthetic-access\")\n                    final int maxDoc = reader.maxDoc();\n                    int curDoc = -1;\n                    \n                    @Override\n                    public boolean hasNext() {\n                      return curDoc < maxDoc - 1;\n                    }\n\n                    @Override\n                    public Number next() {\n                      if (++curDoc >= maxDoc) {\n                        throw new NoSuchElementException(\"no more documents to return values for\");\n                      }\n                      Long updatedValue = updates.get(curDoc);\n                      if (updatedValue == null) {\n                        updatedValue = Long.valueOf(currentValues.get(curDoc));\n                      } else if (updatedValue == NumericUpdate.MISSING) {\n                        updatedValue = null;\n                      }\n                      return updatedValue;\n                    }\n\n                    @Override\n                    public void remove() {\n                      throw new UnsupportedOperationException(\"this iterator does not support removing elements\");\n                    }\n                    \n                  };\n                }\n              });\n            }\n            \n            codec.fieldInfosFormat().getFieldInfosWriter().write(trackingDir, info.info.name, segmentSuffix, fieldInfos, IOContext.DEFAULT);\n            fieldsConsumerSuccess = true;\n          } finally {\n            if (fieldsConsumerSuccess) {\n              fieldsConsumer.close();\n            } else {\n              IOUtils.closeWhileHandlingException(fieldsConsumer);\n            }\n          }\n        } finally {\n          if (reader != this.reader) {\n//            System.out.println(\"[\" + Thread.currentThread().getName() + \"] RLD.writeLiveDocs: closeReader \" + reader);\n            reader.close();\n          }\n        }\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        // Advance only the nextWriteDelGen so that a 2nd\n        // attempt to write will write to a new file\n        if (pendingDeleteCount > 0) {\n          info.advanceNextWriteDelGen();\n        }\n        \n        // Advance only the nextWriteDocValuesGen so that a 2nd\n        // attempt to write will write to a new file\n        if (hasFieldUpdates) {\n          info.advanceNextWriteFieldInfosGen();\n        }\n        \n        // Delete any partially created file(s):\n        for (String fileName : trackingDir.getCreatedFiles()) {\n          try {\n            dir.deleteFile(fileName);\n          } catch (Throwable t) {\n            // Ignore so we throw only the first exc\n          }\n        }\n      }\n    }\n    \n    // If we hit an exc in the line above (eg disk full)\n    // then info's delGen remains pointing to the previous\n    // (successfully written) del docs:\n    if (pendingDeleteCount > 0) {\n      info.advanceDelGen();\n      info.setDelCount(info.getDelCount() + pendingDeleteCount);\n      pendingDeleteCount = 0;\n    }\n    \n    if (hasFieldUpdates) {\n      info.advanceFieldInfosGen();\n      // copy all the updates to mergingUpdates, so they can later be applied to the merged segment\n      if (isMerging) {\n        copyUpdatesToMerging();\n      }\n      numericUpdates.clear();\n      \n      // create a new map, keeping only the gens that are in use\n      Map<Long,Set<String>> genUpdatesFiles = info.getUpdatesFiles();\n      Map<Long,Set<String>> newGenUpdatesFiles = new HashMap<Long,Set<String>>();\n      final long fieldInfosGen = info.getFieldInfosGen();\n      for (FieldInfo fi : fieldInfos) {\n        long dvGen = fi.getDocValuesGen();\n        if (dvGen != -1 && !newGenUpdatesFiles.containsKey(dvGen)) {\n          if (dvGen == fieldInfosGen) {\n            newGenUpdatesFiles.put(fieldInfosGen, trackingDir.getCreatedFiles());\n          } else {\n            newGenUpdatesFiles.put(dvGen, genUpdatesFiles.get(dvGen));\n          }\n        }\n      }\n      \n      info.setGenUpdatesFiles(newGenUpdatesFiles);\n    }\n\n    return true;\n  }\n\n","sourceOld":"  // Commit live docs (writes new _X_N.del files) and field updates (writes new\n  // _X_N updates files) to the directory; returns true if it wrote any file\n  // and false if there were no new deletes or updates to write:\n  // TODO (DVU_RENAME) to writeDeletesAndUpdates\n  public synchronized boolean writeLiveDocs(Directory dir) throws IOException {\n    assert Thread.holdsLock(writer);\n    //System.out.println(\"rld.writeLiveDocs seg=\" + info + \" pendingDelCount=\" + pendingDeleteCount + \" numericUpdates=\" + numericUpdates);\n    final boolean hasFieldUpdates = hasFieldUpdates();\n    if (pendingDeleteCount == 0 && !hasFieldUpdates) {\n      return false;\n    }\n    \n    // We have new deletes or updates\n    assert pendingDeleteCount == 0 || liveDocs.length() == info.info.getDocCount();\n    \n    // Do this so we can delete any created files on\n    // exception; this saves all codecs from having to do\n    // it:\n    TrackingDirectoryWrapper trackingDir = new TrackingDirectoryWrapper(dir);\n    \n    // We can write directly to the actual name (vs to a\n    // .tmp & renaming it) because the file is not live\n    // until segments file is written:\n    boolean success = false;\n    try {\n      Codec codec = info.info.getCodec();\n      if (pendingDeleteCount > 0) {\n        codec.liveDocsFormat().writeLiveDocs((MutableBits)liveDocs, trackingDir, info, pendingDeleteCount, IOContext.DEFAULT);\n      }\n      \n      // apply numeric updates if there are any\n      if (hasFieldUpdates) {\n        // reader could be null e.g. for a just merged segment (from\n        // IndexWriter.commitMergedDeletes).\n//        if (this.reader == null) System.out.println(\"[\" + Thread.currentThread().getName() + \"] RLD.writeLiveDocs: newSR \" + info);\n        final SegmentReader reader = this.reader == null ? new SegmentReader(info, IOContext.READONCE) : this.reader;\n        try {\n          // clone FieldInfos so that we can update their dvGen separately from\n          // the reader's infos and write them to a new fieldInfos_gen file\n          FieldInfos.Builder builder = new FieldInfos.Builder(writer.globalFieldNumberMap);\n          // cannot use builder.add(reader.getFieldInfos()) because it does not\n          // clone FI.attributes as well FI.dvGen\n          for (FieldInfo fi : reader.getFieldInfos()) {\n            FieldInfo clone = builder.add(fi);\n            // copy the stuff FieldInfos.Builder doesn't copy\n            if (fi.attributes() != null) {\n              for (Entry<String,String> e : fi.attributes().entrySet()) {\n                clone.putAttribute(e.getKey(), e.getValue());\n              }\n            }\n            clone.setDocValuesGen(fi.getDocValuesGen());\n          }\n          // create new fields or update existing ones to have NumericDV type\n          for (String f : numericUpdates.keySet()) {\n            builder.addOrUpdate(f, NumericDocValuesField.TYPE);\n          }\n          \n          final FieldInfos fieldInfos = builder.finish();\n          final long nextFieldInfosGen = info.getNextFieldInfosGen();\n          final String segmentSuffix = Long.toString(nextFieldInfosGen, Character.MAX_RADIX);\n          final SegmentWriteState state = new SegmentWriteState(null, trackingDir, info.info, fieldInfos, null, IOContext.DEFAULT, segmentSuffix);\n          final DocValuesFormat docValuesFormat = codec.docValuesFormat();\n          final DocValuesConsumer fieldsConsumer = docValuesFormat.fieldsConsumer(state);\n          boolean fieldsConsumerSuccess = false;\n          try {\n//            System.out.println(\"[\" + Thread.currentThread().getName() + \"] RLD.writeLiveDocs: applying updates; seg=\" + info + \" updates=\" + numericUpdates);\n            for (Entry<String,Map<Integer,Long>> e : numericUpdates.entrySet()) {\n              final String field = e.getKey();\n              final Map<Integer,Long> updates = e.getValue();\n              final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n\n              assert fieldInfo != null;\n\n              fieldInfo.setDocValuesGen(nextFieldInfosGen);\n              \n              // write the numeric updates to a new gen'd docvalues file\n              fieldsConsumer.addNumericField(fieldInfo, new Iterable<Number>() {\n                @SuppressWarnings(\"synthetic-access\")\n                final NumericDocValues currentValues = reader.getNumericDocValues(field);\n                @Override\n                public Iterator<Number> iterator() {\n                  return new Iterator<Number>() {\n\n                    @SuppressWarnings(\"synthetic-access\")\n                    final int maxDoc = reader.maxDoc();\n                    int curDoc = -1;\n                    \n                    @Override\n                    public boolean hasNext() {\n                      return curDoc < maxDoc - 1;\n                    }\n\n                    @Override\n                    public Number next() {\n                      if (++curDoc >= maxDoc) {\n                        throw new NoSuchElementException(\"no more documents to return values for\");\n                      }\n                      Long updatedValue = updates.get(curDoc);\n                      if (updatedValue == null) {\n                        updatedValue = Long.valueOf(currentValues.get(curDoc));\n                      } else if (updatedValue == NumericUpdate.MISSING) {\n                        updatedValue = null;\n                      }\n                      return updatedValue;\n                    }\n\n                    @Override\n                    public void remove() {\n                      throw new UnsupportedOperationException(\"this iterator does not support removing elements\");\n                    }\n                    \n                  };\n                }\n              });\n            }\n            \n            codec.fieldInfosFormat().getFieldInfosWriter().write(trackingDir, info.info.name, segmentSuffix, fieldInfos, IOContext.DEFAULT);\n            fieldsConsumerSuccess = true;\n          } finally {\n            if (fieldsConsumerSuccess) {\n              fieldsConsumer.close();\n            } else {\n              IOUtils.closeWhileHandlingException(fieldsConsumer);\n            }\n          }\n        } finally {\n          if (reader != this.reader) {\n//            System.out.println(\"[\" + Thread.currentThread().getName() + \"] RLD.writeLiveDocs: closeReader \" + reader);\n            reader.close();\n          }\n        }\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        // Advance only the nextWriteDelGen so that a 2nd\n        // attempt to write will write to a new file\n        if (pendingDeleteCount > 0) {\n          info.advanceNextWriteDelGen();\n        }\n        \n        // Advance only the nextWriteDocValuesGen so that a 2nd\n        // attempt to write will write to a new file\n        if (hasFieldUpdates) {\n          info.advanceNextWriteFieldInfosGen();\n        }\n        \n        // Delete any partially created file(s):\n        for (String fileName : trackingDir.getCreatedFiles()) {\n          try {\n            dir.deleteFile(fileName);\n          } catch (Throwable t) {\n            // Ignore so we throw only the first exc\n          }\n        }\n      }\n    }\n    \n    // If we hit an exc in the line above (eg disk full)\n    // then info's delGen remains pointing to the previous\n    // (successfully written) del docs:\n    if (pendingDeleteCount > 0) {\n      info.advanceDelGen();\n      info.setDelCount(info.getDelCount() + pendingDeleteCount);\n      pendingDeleteCount = 0;\n    }\n    \n    if (hasFieldUpdates) {\n      info.advanceFieldInfosGen();\n      // copy all the updates to mergingUpdates, so they can later be applied to the merged segment\n      if (isMerging) {\n        copyUpdatesToMerging();\n      }\n      numericUpdates.clear();\n    }\n\n    info.addUpdatesFiles(trackingDir.getCreatedFiles());\n    \n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1cff1deb788b9babb942b20707a93e1ab902ce37","date":1380805349,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/ReadersAndLiveDocs#writeLiveDocs(Directory).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/ReadersAndLiveDocs#writeLiveDocs(Directory).mjava","sourceNew":"  // Commit live docs (writes new _X_N.del files) and field updates (writes new\n  // _X_N updates files) to the directory; returns true if it wrote any file\n  // and false if there were no new deletes or updates to write:\n  // TODO (DVU_RENAME) to writeDeletesAndUpdates\n  public synchronized boolean writeLiveDocs(Directory dir) throws IOException {\n    assert Thread.holdsLock(writer);\n    //System.out.println(\"rld.writeLiveDocs seg=\" + info + \" pendingDelCount=\" + pendingDeleteCount + \" numericUpdates=\" + numericUpdates);\n    final boolean hasFieldUpdates = hasFieldUpdates();\n    if (pendingDeleteCount == 0 && !hasFieldUpdates) {\n      return false;\n    }\n    \n    // We have new deletes or updates\n    assert pendingDeleteCount == 0 || liveDocs.length() == info.info.getDocCount();\n    \n    // Do this so we can delete any created files on\n    // exception; this saves all codecs from having to do\n    // it:\n    TrackingDirectoryWrapper trackingDir = new TrackingDirectoryWrapper(dir);\n    \n    // We can write directly to the actual name (vs to a\n    // .tmp & renaming it) because the file is not live\n    // until segments file is written:\n    FieldInfos fieldInfos = null;\n    boolean success = false;\n    try {\n      Codec codec = info.info.getCodec();\n      if (pendingDeleteCount > 0) {\n        codec.liveDocsFormat().writeLiveDocs((MutableBits)liveDocs, trackingDir, info, pendingDeleteCount, IOContext.DEFAULT);\n      }\n      \n      // apply numeric updates if there are any\n      if (hasFieldUpdates) {\n        // reader could be null e.g. for a just merged segment (from\n        // IndexWriter.commitMergedDeletes).\n//        if (this.reader == null) System.out.println(\"[\" + Thread.currentThread().getName() + \"] RLD.writeLiveDocs: newSR \" + info);\n        final SegmentReader reader = this.reader == null ? new SegmentReader(info, IOContext.READONCE) : this.reader;\n        try {\n          // clone FieldInfos so that we can update their dvGen separately from\n          // the reader's infos and write them to a new fieldInfos_gen file\n          FieldInfos.Builder builder = new FieldInfos.Builder(writer.globalFieldNumberMap);\n          // cannot use builder.add(reader.getFieldInfos()) because it does not\n          // clone FI.attributes as well FI.dvGen\n          for (FieldInfo fi : reader.getFieldInfos()) {\n            FieldInfo clone = builder.add(fi);\n            // copy the stuff FieldInfos.Builder doesn't copy\n            if (fi.attributes() != null) {\n              for (Entry<String,String> e : fi.attributes().entrySet()) {\n                clone.putAttribute(e.getKey(), e.getValue());\n              }\n            }\n            clone.setDocValuesGen(fi.getDocValuesGen());\n          }\n          // create new fields or update existing ones to have NumericDV type\n          for (String f : numericUpdates.keySet()) {\n            builder.addOrUpdate(f, NumericDocValuesField.TYPE);\n          }\n          \n          fieldInfos = builder.finish();\n          final long nextFieldInfosGen = info.getNextFieldInfosGen();\n          final String segmentSuffix = Long.toString(nextFieldInfosGen, Character.MAX_RADIX);\n          final SegmentWriteState state = new SegmentWriteState(null, trackingDir, info.info, fieldInfos, null, IOContext.DEFAULT, segmentSuffix);\n          final DocValuesFormat docValuesFormat = codec.docValuesFormat();\n          final DocValuesConsumer fieldsConsumer = docValuesFormat.fieldsConsumer(state);\n          boolean fieldsConsumerSuccess = false;\n          try {\n//            System.out.println(\"[\" + Thread.currentThread().getName() + \"] RLD.writeLiveDocs: applying updates; seg=\" + info + \" updates=\" + numericUpdates);\n            for (Entry<String,Map<Integer,Long>> e : numericUpdates.entrySet()) {\n              final String field = e.getKey();\n              final Map<Integer,Long> updates = e.getValue();\n              final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n\n              assert fieldInfo != null;\n\n              fieldInfo.setDocValuesGen(nextFieldInfosGen);\n              \n              // write the numeric updates to a new gen'd docvalues file\n              fieldsConsumer.addNumericField(fieldInfo, new Iterable<Number>() {\n                @SuppressWarnings(\"synthetic-access\")\n                final NumericDocValues currentValues = reader.getNumericDocValues(field);\n                final Bits docsWithField = reader.getDocsWithField(field);\n                @Override\n                public Iterator<Number> iterator() {\n                  return new Iterator<Number>() {\n\n                    @SuppressWarnings(\"synthetic-access\")\n                    final int maxDoc = reader.maxDoc();\n                    int curDoc = -1;\n                    \n                    @Override\n                    public boolean hasNext() {\n                      return curDoc < maxDoc - 1;\n                    }\n\n                    @Override\n                    public Number next() {\n                      if (++curDoc >= maxDoc) {\n                        throw new NoSuchElementException(\"no more documents to return values for\");\n                      }\n                      Long updatedValue = updates.get(curDoc);\n                      if (updatedValue == null) {\n                        // only read the current value if the document had a value before\n                        if (currentValues != null && docsWithField.get(curDoc)) {\n                          updatedValue = currentValues.get(curDoc);\n                        }\n                      } else if (updatedValue == NumericUpdate.MISSING) {\n                        updatedValue = null;\n                      }\n                      return updatedValue;\n                    }\n\n                    @Override\n                    public void remove() {\n                      throw new UnsupportedOperationException(\"this iterator does not support removing elements\");\n                    }\n                    \n                  };\n                }\n              });\n            }\n            \n            codec.fieldInfosFormat().getFieldInfosWriter().write(trackingDir, info.info.name, segmentSuffix, fieldInfos, IOContext.DEFAULT);\n            fieldsConsumerSuccess = true;\n          } finally {\n            if (fieldsConsumerSuccess) {\n              fieldsConsumer.close();\n            } else {\n              IOUtils.closeWhileHandlingException(fieldsConsumer);\n            }\n          }\n        } finally {\n          if (reader != this.reader) {\n//            System.out.println(\"[\" + Thread.currentThread().getName() + \"] RLD.writeLiveDocs: closeReader \" + reader);\n            reader.close();\n          }\n        }\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        // Advance only the nextWriteDelGen so that a 2nd\n        // attempt to write will write to a new file\n        if (pendingDeleteCount > 0) {\n          info.advanceNextWriteDelGen();\n        }\n        \n        // Advance only the nextWriteDocValuesGen so that a 2nd\n        // attempt to write will write to a new file\n        if (hasFieldUpdates) {\n          info.advanceNextWriteFieldInfosGen();\n        }\n        \n        // Delete any partially created file(s):\n        for (String fileName : trackingDir.getCreatedFiles()) {\n          try {\n            dir.deleteFile(fileName);\n          } catch (Throwable t) {\n            // Ignore so we throw only the first exc\n          }\n        }\n      }\n    }\n    \n    // If we hit an exc in the line above (eg disk full)\n    // then info's delGen remains pointing to the previous\n    // (successfully written) del docs:\n    if (pendingDeleteCount > 0) {\n      info.advanceDelGen();\n      info.setDelCount(info.getDelCount() + pendingDeleteCount);\n      pendingDeleteCount = 0;\n    }\n    \n    if (hasFieldUpdates) {\n      info.advanceFieldInfosGen();\n      // copy all the updates to mergingUpdates, so they can later be applied to the merged segment\n      if (isMerging) {\n        copyUpdatesToMerging();\n      }\n      numericUpdates.clear();\n      \n      // create a new map, keeping only the gens that are in use\n      Map<Long,Set<String>> genUpdatesFiles = info.getUpdatesFiles();\n      Map<Long,Set<String>> newGenUpdatesFiles = new HashMap<Long,Set<String>>();\n      final long fieldInfosGen = info.getFieldInfosGen();\n      for (FieldInfo fi : fieldInfos) {\n        long dvGen = fi.getDocValuesGen();\n        if (dvGen != -1 && !newGenUpdatesFiles.containsKey(dvGen)) {\n          if (dvGen == fieldInfosGen) {\n            newGenUpdatesFiles.put(fieldInfosGen, trackingDir.getCreatedFiles());\n          } else {\n            newGenUpdatesFiles.put(dvGen, genUpdatesFiles.get(dvGen));\n          }\n        }\n      }\n      \n      info.setGenUpdatesFiles(newGenUpdatesFiles);\n    }\n\n    return true;\n  }\n\n","sourceOld":"  // Commit live docs (writes new _X_N.del files) and field updates (writes new\n  // _X_N updates files) to the directory; returns true if it wrote any file\n  // and false if there were no new deletes or updates to write:\n  // TODO (DVU_RENAME) to writeDeletesAndUpdates\n  public synchronized boolean writeLiveDocs(Directory dir) throws IOException {\n    assert Thread.holdsLock(writer);\n    //System.out.println(\"rld.writeLiveDocs seg=\" + info + \" pendingDelCount=\" + pendingDeleteCount + \" numericUpdates=\" + numericUpdates);\n    final boolean hasFieldUpdates = hasFieldUpdates();\n    if (pendingDeleteCount == 0 && !hasFieldUpdates) {\n      return false;\n    }\n    \n    // We have new deletes or updates\n    assert pendingDeleteCount == 0 || liveDocs.length() == info.info.getDocCount();\n    \n    // Do this so we can delete any created files on\n    // exception; this saves all codecs from having to do\n    // it:\n    TrackingDirectoryWrapper trackingDir = new TrackingDirectoryWrapper(dir);\n    \n    // We can write directly to the actual name (vs to a\n    // .tmp & renaming it) because the file is not live\n    // until segments file is written:\n    FieldInfos fieldInfos = null;\n    boolean success = false;\n    try {\n      Codec codec = info.info.getCodec();\n      if (pendingDeleteCount > 0) {\n        codec.liveDocsFormat().writeLiveDocs((MutableBits)liveDocs, trackingDir, info, pendingDeleteCount, IOContext.DEFAULT);\n      }\n      \n      // apply numeric updates if there are any\n      if (hasFieldUpdates) {\n        // reader could be null e.g. for a just merged segment (from\n        // IndexWriter.commitMergedDeletes).\n//        if (this.reader == null) System.out.println(\"[\" + Thread.currentThread().getName() + \"] RLD.writeLiveDocs: newSR \" + info);\n        final SegmentReader reader = this.reader == null ? new SegmentReader(info, IOContext.READONCE) : this.reader;\n        try {\n          // clone FieldInfos so that we can update their dvGen separately from\n          // the reader's infos and write them to a new fieldInfos_gen file\n          FieldInfos.Builder builder = new FieldInfos.Builder(writer.globalFieldNumberMap);\n          // cannot use builder.add(reader.getFieldInfos()) because it does not\n          // clone FI.attributes as well FI.dvGen\n          for (FieldInfo fi : reader.getFieldInfos()) {\n            FieldInfo clone = builder.add(fi);\n            // copy the stuff FieldInfos.Builder doesn't copy\n            if (fi.attributes() != null) {\n              for (Entry<String,String> e : fi.attributes().entrySet()) {\n                clone.putAttribute(e.getKey(), e.getValue());\n              }\n            }\n            clone.setDocValuesGen(fi.getDocValuesGen());\n          }\n          // create new fields or update existing ones to have NumericDV type\n          for (String f : numericUpdates.keySet()) {\n            builder.addOrUpdate(f, NumericDocValuesField.TYPE);\n          }\n          \n          fieldInfos = builder.finish();\n          final long nextFieldInfosGen = info.getNextFieldInfosGen();\n          final String segmentSuffix = Long.toString(nextFieldInfosGen, Character.MAX_RADIX);\n          final SegmentWriteState state = new SegmentWriteState(null, trackingDir, info.info, fieldInfos, null, IOContext.DEFAULT, segmentSuffix);\n          final DocValuesFormat docValuesFormat = codec.docValuesFormat();\n          final DocValuesConsumer fieldsConsumer = docValuesFormat.fieldsConsumer(state);\n          boolean fieldsConsumerSuccess = false;\n          try {\n//            System.out.println(\"[\" + Thread.currentThread().getName() + \"] RLD.writeLiveDocs: applying updates; seg=\" + info + \" updates=\" + numericUpdates);\n            for (Entry<String,Map<Integer,Long>> e : numericUpdates.entrySet()) {\n              final String field = e.getKey();\n              final Map<Integer,Long> updates = e.getValue();\n              final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n\n              assert fieldInfo != null;\n\n              fieldInfo.setDocValuesGen(nextFieldInfosGen);\n              \n              // write the numeric updates to a new gen'd docvalues file\n              fieldsConsumer.addNumericField(fieldInfo, new Iterable<Number>() {\n                @SuppressWarnings(\"synthetic-access\")\n                final NumericDocValues currentValues = reader.getNumericDocValues(field);\n                @Override\n                public Iterator<Number> iterator() {\n                  return new Iterator<Number>() {\n\n                    @SuppressWarnings(\"synthetic-access\")\n                    final int maxDoc = reader.maxDoc();\n                    int curDoc = -1;\n                    \n                    @Override\n                    public boolean hasNext() {\n                      return curDoc < maxDoc - 1;\n                    }\n\n                    @Override\n                    public Number next() {\n                      if (++curDoc >= maxDoc) {\n                        throw new NoSuchElementException(\"no more documents to return values for\");\n                      }\n                      Long updatedValue = updates.get(curDoc);\n                      if (updatedValue == null) {\n                        updatedValue = Long.valueOf(currentValues.get(curDoc));\n                      } else if (updatedValue == NumericUpdate.MISSING) {\n                        updatedValue = null;\n                      }\n                      return updatedValue;\n                    }\n\n                    @Override\n                    public void remove() {\n                      throw new UnsupportedOperationException(\"this iterator does not support removing elements\");\n                    }\n                    \n                  };\n                }\n              });\n            }\n            \n            codec.fieldInfosFormat().getFieldInfosWriter().write(trackingDir, info.info.name, segmentSuffix, fieldInfos, IOContext.DEFAULT);\n            fieldsConsumerSuccess = true;\n          } finally {\n            if (fieldsConsumerSuccess) {\n              fieldsConsumer.close();\n            } else {\n              IOUtils.closeWhileHandlingException(fieldsConsumer);\n            }\n          }\n        } finally {\n          if (reader != this.reader) {\n//            System.out.println(\"[\" + Thread.currentThread().getName() + \"] RLD.writeLiveDocs: closeReader \" + reader);\n            reader.close();\n          }\n        }\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        // Advance only the nextWriteDelGen so that a 2nd\n        // attempt to write will write to a new file\n        if (pendingDeleteCount > 0) {\n          info.advanceNextWriteDelGen();\n        }\n        \n        // Advance only the nextWriteDocValuesGen so that a 2nd\n        // attempt to write will write to a new file\n        if (hasFieldUpdates) {\n          info.advanceNextWriteFieldInfosGen();\n        }\n        \n        // Delete any partially created file(s):\n        for (String fileName : trackingDir.getCreatedFiles()) {\n          try {\n            dir.deleteFile(fileName);\n          } catch (Throwable t) {\n            // Ignore so we throw only the first exc\n          }\n        }\n      }\n    }\n    \n    // If we hit an exc in the line above (eg disk full)\n    // then info's delGen remains pointing to the previous\n    // (successfully written) del docs:\n    if (pendingDeleteCount > 0) {\n      info.advanceDelGen();\n      info.setDelCount(info.getDelCount() + pendingDeleteCount);\n      pendingDeleteCount = 0;\n    }\n    \n    if (hasFieldUpdates) {\n      info.advanceFieldInfosGen();\n      // copy all the updates to mergingUpdates, so they can later be applied to the merged segment\n      if (isMerging) {\n        copyUpdatesToMerging();\n      }\n      numericUpdates.clear();\n      \n      // create a new map, keeping only the gens that are in use\n      Map<Long,Set<String>> genUpdatesFiles = info.getUpdatesFiles();\n      Map<Long,Set<String>> newGenUpdatesFiles = new HashMap<Long,Set<String>>();\n      final long fieldInfosGen = info.getFieldInfosGen();\n      for (FieldInfo fi : fieldInfos) {\n        long dvGen = fi.getDocValuesGen();\n        if (dvGen != -1 && !newGenUpdatesFiles.containsKey(dvGen)) {\n          if (dvGen == fieldInfosGen) {\n            newGenUpdatesFiles.put(fieldInfosGen, trackingDir.getCreatedFiles());\n          } else {\n            newGenUpdatesFiles.put(dvGen, genUpdatesFiles.get(dvGen));\n          }\n        }\n      }\n      \n      info.setGenUpdatesFiles(newGenUpdatesFiles);\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1bae040fd1d5e03e0d8d695a9c25cf4f402e7ffe","date":1381909398,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/ReadersAndLiveDocs#writeLiveDocs(Directory).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/ReadersAndLiveDocs#writeLiveDocs(Directory).mjava","sourceNew":"  // Commit live docs (writes new _X_N.del files) and field updates (writes new\n  // _X_N updates files) to the directory; returns true if it wrote any file\n  // and false if there were no new deletes or updates to write:\n  // TODO (DVU_RENAME) to writeDeletesAndUpdates\n  public synchronized boolean writeLiveDocs(Directory dir) throws IOException {\n    assert Thread.holdsLock(writer);\n    //System.out.println(\"rld.writeLiveDocs seg=\" + info + \" pendingDelCount=\" + pendingDeleteCount + \" numericUpdates=\" + numericUpdates);\n    if (pendingDeleteCount == 0) {\n      return false;\n    }\n    \n    // We have new deletes\n    assert liveDocs.length() == info.info.getDocCount();\n    \n    // Do this so we can delete any created files on\n    // exception; this saves all codecs from having to do\n    // it:\n    TrackingDirectoryWrapper trackingDir = new TrackingDirectoryWrapper(dir);\n    \n    // We can write directly to the actual name (vs to a\n    // .tmp & renaming it) because the file is not live\n    // until segments file is written:\n    boolean success = false;\n    try {\n      Codec codec = info.info.getCodec();\n      codec.liveDocsFormat().writeLiveDocs((MutableBits)liveDocs, trackingDir, info, pendingDeleteCount, IOContext.DEFAULT);\n      success = true;\n    } finally {\n      if (!success) {\n        // Advance only the nextWriteDelGen so that a 2nd\n        // attempt to write will write to a new file\n        info.advanceNextWriteDelGen();\n        \n        // Delete any partially created file(s):\n        for (String fileName : trackingDir.getCreatedFiles()) {\n          try {\n            dir.deleteFile(fileName);\n          } catch (Throwable t) {\n            // Ignore so we throw only the first exc\n          }\n        }\n      }\n    }\n    \n    // If we hit an exc in the line above (eg disk full)\n    // then info's delGen remains pointing to the previous\n    // (successfully written) del docs:\n    info.advanceDelGen();\n    info.setDelCount(info.getDelCount() + pendingDeleteCount);\n    pendingDeleteCount = 0;\n    \n    return true;\n  }\n\n","sourceOld":"  // Commit live docs (writes new _X_N.del files) and field updates (writes new\n  // _X_N updates files) to the directory; returns true if it wrote any file\n  // and false if there were no new deletes or updates to write:\n  // TODO (DVU_RENAME) to writeDeletesAndUpdates\n  public synchronized boolean writeLiveDocs(Directory dir) throws IOException {\n    assert Thread.holdsLock(writer);\n    //System.out.println(\"rld.writeLiveDocs seg=\" + info + \" pendingDelCount=\" + pendingDeleteCount + \" numericUpdates=\" + numericUpdates);\n    final boolean hasFieldUpdates = hasFieldUpdates();\n    if (pendingDeleteCount == 0 && !hasFieldUpdates) {\n      return false;\n    }\n    \n    // We have new deletes or updates\n    assert pendingDeleteCount == 0 || liveDocs.length() == info.info.getDocCount();\n    \n    // Do this so we can delete any created files on\n    // exception; this saves all codecs from having to do\n    // it:\n    TrackingDirectoryWrapper trackingDir = new TrackingDirectoryWrapper(dir);\n    \n    // We can write directly to the actual name (vs to a\n    // .tmp & renaming it) because the file is not live\n    // until segments file is written:\n    FieldInfos fieldInfos = null;\n    boolean success = false;\n    try {\n      Codec codec = info.info.getCodec();\n      if (pendingDeleteCount > 0) {\n        codec.liveDocsFormat().writeLiveDocs((MutableBits)liveDocs, trackingDir, info, pendingDeleteCount, IOContext.DEFAULT);\n      }\n      \n      // apply numeric updates if there are any\n      if (hasFieldUpdates) {\n        // reader could be null e.g. for a just merged segment (from\n        // IndexWriter.commitMergedDeletes).\n//        if (this.reader == null) System.out.println(\"[\" + Thread.currentThread().getName() + \"] RLD.writeLiveDocs: newSR \" + info);\n        final SegmentReader reader = this.reader == null ? new SegmentReader(info, IOContext.READONCE) : this.reader;\n        try {\n          // clone FieldInfos so that we can update their dvGen separately from\n          // the reader's infos and write them to a new fieldInfos_gen file\n          FieldInfos.Builder builder = new FieldInfos.Builder(writer.globalFieldNumberMap);\n          // cannot use builder.add(reader.getFieldInfos()) because it does not\n          // clone FI.attributes as well FI.dvGen\n          for (FieldInfo fi : reader.getFieldInfos()) {\n            FieldInfo clone = builder.add(fi);\n            // copy the stuff FieldInfos.Builder doesn't copy\n            if (fi.attributes() != null) {\n              for (Entry<String,String> e : fi.attributes().entrySet()) {\n                clone.putAttribute(e.getKey(), e.getValue());\n              }\n            }\n            clone.setDocValuesGen(fi.getDocValuesGen());\n          }\n          // create new fields or update existing ones to have NumericDV type\n          for (String f : numericUpdates.keySet()) {\n            builder.addOrUpdate(f, NumericDocValuesField.TYPE);\n          }\n          \n          fieldInfos = builder.finish();\n          final long nextFieldInfosGen = info.getNextFieldInfosGen();\n          final String segmentSuffix = Long.toString(nextFieldInfosGen, Character.MAX_RADIX);\n          final SegmentWriteState state = new SegmentWriteState(null, trackingDir, info.info, fieldInfos, null, IOContext.DEFAULT, segmentSuffix);\n          final DocValuesFormat docValuesFormat = codec.docValuesFormat();\n          final DocValuesConsumer fieldsConsumer = docValuesFormat.fieldsConsumer(state);\n          boolean fieldsConsumerSuccess = false;\n          try {\n//            System.out.println(\"[\" + Thread.currentThread().getName() + \"] RLD.writeLiveDocs: applying updates; seg=\" + info + \" updates=\" + numericUpdates);\n            for (Entry<String,Map<Integer,Long>> e : numericUpdates.entrySet()) {\n              final String field = e.getKey();\n              final Map<Integer,Long> updates = e.getValue();\n              final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n\n              assert fieldInfo != null;\n\n              fieldInfo.setDocValuesGen(nextFieldInfosGen);\n              \n              // write the numeric updates to a new gen'd docvalues file\n              fieldsConsumer.addNumericField(fieldInfo, new Iterable<Number>() {\n                @SuppressWarnings(\"synthetic-access\")\n                final NumericDocValues currentValues = reader.getNumericDocValues(field);\n                final Bits docsWithField = reader.getDocsWithField(field);\n                @Override\n                public Iterator<Number> iterator() {\n                  return new Iterator<Number>() {\n\n                    @SuppressWarnings(\"synthetic-access\")\n                    final int maxDoc = reader.maxDoc();\n                    int curDoc = -1;\n                    \n                    @Override\n                    public boolean hasNext() {\n                      return curDoc < maxDoc - 1;\n                    }\n\n                    @Override\n                    public Number next() {\n                      if (++curDoc >= maxDoc) {\n                        throw new NoSuchElementException(\"no more documents to return values for\");\n                      }\n                      Long updatedValue = updates.get(curDoc);\n                      if (updatedValue == null) {\n                        // only read the current value if the document had a value before\n                        if (currentValues != null && docsWithField.get(curDoc)) {\n                          updatedValue = currentValues.get(curDoc);\n                        }\n                      } else if (updatedValue == NumericUpdate.MISSING) {\n                        updatedValue = null;\n                      }\n                      return updatedValue;\n                    }\n\n                    @Override\n                    public void remove() {\n                      throw new UnsupportedOperationException(\"this iterator does not support removing elements\");\n                    }\n                    \n                  };\n                }\n              });\n            }\n            \n            codec.fieldInfosFormat().getFieldInfosWriter().write(trackingDir, info.info.name, segmentSuffix, fieldInfos, IOContext.DEFAULT);\n            fieldsConsumerSuccess = true;\n          } finally {\n            if (fieldsConsumerSuccess) {\n              fieldsConsumer.close();\n            } else {\n              IOUtils.closeWhileHandlingException(fieldsConsumer);\n            }\n          }\n        } finally {\n          if (reader != this.reader) {\n//            System.out.println(\"[\" + Thread.currentThread().getName() + \"] RLD.writeLiveDocs: closeReader \" + reader);\n            reader.close();\n          }\n        }\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        // Advance only the nextWriteDelGen so that a 2nd\n        // attempt to write will write to a new file\n        if (pendingDeleteCount > 0) {\n          info.advanceNextWriteDelGen();\n        }\n        \n        // Advance only the nextWriteDocValuesGen so that a 2nd\n        // attempt to write will write to a new file\n        if (hasFieldUpdates) {\n          info.advanceNextWriteFieldInfosGen();\n        }\n        \n        // Delete any partially created file(s):\n        for (String fileName : trackingDir.getCreatedFiles()) {\n          try {\n            dir.deleteFile(fileName);\n          } catch (Throwable t) {\n            // Ignore so we throw only the first exc\n          }\n        }\n      }\n    }\n    \n    // If we hit an exc in the line above (eg disk full)\n    // then info's delGen remains pointing to the previous\n    // (successfully written) del docs:\n    if (pendingDeleteCount > 0) {\n      info.advanceDelGen();\n      info.setDelCount(info.getDelCount() + pendingDeleteCount);\n      pendingDeleteCount = 0;\n    }\n    \n    if (hasFieldUpdates) {\n      info.advanceFieldInfosGen();\n      // copy all the updates to mergingUpdates, so they can later be applied to the merged segment\n      if (isMerging) {\n        copyUpdatesToMerging();\n      }\n      numericUpdates.clear();\n      \n      // create a new map, keeping only the gens that are in use\n      Map<Long,Set<String>> genUpdatesFiles = info.getUpdatesFiles();\n      Map<Long,Set<String>> newGenUpdatesFiles = new HashMap<Long,Set<String>>();\n      final long fieldInfosGen = info.getFieldInfosGen();\n      for (FieldInfo fi : fieldInfos) {\n        long dvGen = fi.getDocValuesGen();\n        if (dvGen != -1 && !newGenUpdatesFiles.containsKey(dvGen)) {\n          if (dvGen == fieldInfosGen) {\n            newGenUpdatesFiles.put(fieldInfosGen, trackingDir.getCreatedFiles());\n          } else {\n            newGenUpdatesFiles.put(dvGen, genUpdatesFiles.get(dvGen));\n          }\n        }\n      }\n      \n      info.setGenUpdatesFiles(newGenUpdatesFiles);\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0","date":1383367127,"type":5,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/ReadersAndUpdates#writeLiveDocs(Directory).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/ReadersAndLiveDocs#writeLiveDocs(Directory).mjava","sourceNew":"  // Commit live docs (writes new _X_N.del files) and field updates (writes new\n  // _X_N updates files) to the directory; returns true if it wrote any file\n  // and false if there were no new deletes or updates to write:\n  public synchronized boolean writeLiveDocs(Directory dir) throws IOException {\n    assert Thread.holdsLock(writer);\n    //System.out.println(\"rld.writeLiveDocs seg=\" + info + \" pendingDelCount=\" + pendingDeleteCount + \" numericUpdates=\" + numericUpdates);\n    if (pendingDeleteCount == 0) {\n      return false;\n    }\n    \n    // We have new deletes\n    assert liveDocs.length() == info.info.getDocCount();\n    \n    // Do this so we can delete any created files on\n    // exception; this saves all codecs from having to do\n    // it:\n    TrackingDirectoryWrapper trackingDir = new TrackingDirectoryWrapper(dir);\n    \n    // We can write directly to the actual name (vs to a\n    // .tmp & renaming it) because the file is not live\n    // until segments file is written:\n    boolean success = false;\n    try {\n      Codec codec = info.info.getCodec();\n      codec.liveDocsFormat().writeLiveDocs((MutableBits)liveDocs, trackingDir, info, pendingDeleteCount, IOContext.DEFAULT);\n      success = true;\n    } finally {\n      if (!success) {\n        // Advance only the nextWriteDelGen so that a 2nd\n        // attempt to write will write to a new file\n        info.advanceNextWriteDelGen();\n        \n        // Delete any partially created file(s):\n        for (String fileName : trackingDir.getCreatedFiles()) {\n          try {\n            dir.deleteFile(fileName);\n          } catch (Throwable t) {\n            // Ignore so we throw only the first exc\n          }\n        }\n      }\n    }\n    \n    // If we hit an exc in the line above (eg disk full)\n    // then info's delGen remains pointing to the previous\n    // (successfully written) del docs:\n    info.advanceDelGen();\n    info.setDelCount(info.getDelCount() + pendingDeleteCount);\n    pendingDeleteCount = 0;\n    \n    return true;\n  }\n\n","sourceOld":"  // Commit live docs (writes new _X_N.del files) and field updates (writes new\n  // _X_N updates files) to the directory; returns true if it wrote any file\n  // and false if there were no new deletes or updates to write:\n  // TODO (DVU_RENAME) to writeDeletesAndUpdates\n  public synchronized boolean writeLiveDocs(Directory dir) throws IOException {\n    assert Thread.holdsLock(writer);\n    //System.out.println(\"rld.writeLiveDocs seg=\" + info + \" pendingDelCount=\" + pendingDeleteCount + \" numericUpdates=\" + numericUpdates);\n    if (pendingDeleteCount == 0) {\n      return false;\n    }\n    \n    // We have new deletes\n    assert liveDocs.length() == info.info.getDocCount();\n    \n    // Do this so we can delete any created files on\n    // exception; this saves all codecs from having to do\n    // it:\n    TrackingDirectoryWrapper trackingDir = new TrackingDirectoryWrapper(dir);\n    \n    // We can write directly to the actual name (vs to a\n    // .tmp & renaming it) because the file is not live\n    // until segments file is written:\n    boolean success = false;\n    try {\n      Codec codec = info.info.getCodec();\n      codec.liveDocsFormat().writeLiveDocs((MutableBits)liveDocs, trackingDir, info, pendingDeleteCount, IOContext.DEFAULT);\n      success = true;\n    } finally {\n      if (!success) {\n        // Advance only the nextWriteDelGen so that a 2nd\n        // attempt to write will write to a new file\n        info.advanceNextWriteDelGen();\n        \n        // Delete any partially created file(s):\n        for (String fileName : trackingDir.getCreatedFiles()) {\n          try {\n            dir.deleteFile(fileName);\n          } catch (Throwable t) {\n            // Ignore so we throw only the first exc\n          }\n        }\n      }\n    }\n    \n    // If we hit an exc in the line above (eg disk full)\n    // then info's delGen remains pointing to the previous\n    // (successfully written) del docs:\n    info.advanceDelGen();\n    info.setDelCount(info.getDelCount() + pendingDeleteCount);\n    pendingDeleteCount = 0;\n    \n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"f5b39aaa88608b25873a62fe4b2a5d8edf1a2966":["75e4e08ceec867127dcd9913a5ebbc46cf85a28d"],"e072d0b1fc19e0533d8ce432eed245196bca6fde":["479fba77febd29e498fc4a430359e4cf88341da7"],"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":["615ddbd81799980d0fdd95e0238e1c498b6f47b0","479fba77febd29e498fc4a430359e4cf88341da7"],"38e3b736c7ca086d61b7dbb841c905ee115490da":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","ae695f21c50b03702b5d0fa2543d5af844bb7cd3"],"73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0":["1bae040fd1d5e03e0d8d695a9c25cf4f402e7ffe"],"75e4e08ceec867127dcd9913a5ebbc46cf85a28d":["e072d0b1fc19e0533d8ce432eed245196bca6fde"],"9d153abcf92dc5329d98571a8c3035df9bd80648":["f0b406f1c9ada78b8fe2b12dfa87e9f76d35618c"],"8435160e9702b19398118ddf76b61c846612b6a4":["f5b39aaa88608b25873a62fe4b2a5d8edf1a2966"],"399d5903979ca52514d2bc7e3a362e1c45885c94":["ae695f21c50b03702b5d0fa2543d5af844bb7cd3"],"ae695f21c50b03702b5d0fa2543d5af844bb7cd3":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"479fba77febd29e498fc4a430359e4cf88341da7":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"2f13fb377f9b5df46af44bf90a2e507a884f2c30":["8435160e9702b19398118ddf76b61c846612b6a4"],"1cff1deb788b9babb942b20707a93e1ab902ce37":["2f13fb377f9b5df46af44bf90a2e507a884f2c30"],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["399d5903979ca52514d2bc7e3a362e1c45885c94","203d7d3cb7712e10ef33009a63247ae40c302d7a"],"f0b406f1c9ada78b8fe2b12dfa87e9f76d35618c":["399d5903979ca52514d2bc7e3a362e1c45885c94"],"1bae040fd1d5e03e0d8d695a9c25cf4f402e7ffe":["1cff1deb788b9babb942b20707a93e1ab902ce37"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"203d7d3cb7712e10ef33009a63247ae40c302d7a":["9d153abcf92dc5329d98571a8c3035df9bd80648"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0"]},"commit2Childs":{"f5b39aaa88608b25873a62fe4b2a5d8edf1a2966":["8435160e9702b19398118ddf76b61c846612b6a4"],"e072d0b1fc19e0533d8ce432eed245196bca6fde":["75e4e08ceec867127dcd9913a5ebbc46cf85a28d"],"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":[],"38e3b736c7ca086d61b7dbb841c905ee115490da":[],"73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"75e4e08ceec867127dcd9913a5ebbc46cf85a28d":["f5b39aaa88608b25873a62fe4b2a5d8edf1a2966"],"9d153abcf92dc5329d98571a8c3035df9bd80648":["203d7d3cb7712e10ef33009a63247ae40c302d7a"],"8435160e9702b19398118ddf76b61c846612b6a4":["2f13fb377f9b5df46af44bf90a2e507a884f2c30"],"ae695f21c50b03702b5d0fa2543d5af844bb7cd3":["38e3b736c7ca086d61b7dbb841c905ee115490da","399d5903979ca52514d2bc7e3a362e1c45885c94"],"399d5903979ca52514d2bc7e3a362e1c45885c94":["615ddbd81799980d0fdd95e0238e1c498b6f47b0","f0b406f1c9ada78b8fe2b12dfa87e9f76d35618c"],"479fba77febd29e498fc4a430359e4cf88341da7":["e072d0b1fc19e0533d8ce432eed245196bca6fde","d3fcb70cf561547c7bb1506e0cf32ca7b1287064"],"2f13fb377f9b5df46af44bf90a2e507a884f2c30":["1cff1deb788b9babb942b20707a93e1ab902ce37"],"1cff1deb788b9babb942b20707a93e1ab902ce37":["1bae040fd1d5e03e0d8d695a9c25cf4f402e7ffe"],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","479fba77febd29e498fc4a430359e4cf88341da7"],"f0b406f1c9ada78b8fe2b12dfa87e9f76d35618c":["9d153abcf92dc5329d98571a8c3035df9bd80648"],"1bae040fd1d5e03e0d8d695a9c25cf4f402e7ffe":["73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["38e3b736c7ca086d61b7dbb841c905ee115490da","ae695f21c50b03702b5d0fa2543d5af844bb7cd3"],"203d7d3cb7712e10ef33009a63247ae40c302d7a":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","38e3b736c7ca086d61b7dbb841c905ee115490da","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}