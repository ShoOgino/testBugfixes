{"path":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testImmediateDiskFull().mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testImmediateDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testImmediateDiskFull().mjava","sourceNew":"  // LUCENE-1130: make sure immeidate disk full on creating\n  // an IndexWriter (hit during DW.ThreadState.init()) is\n  // OK:\n  public void testImmediateDiskFull() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n        .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler()));\n    dir.setMaxSizeInBytes(Math.max(1, dir.getRecomputedActualSizeInBytes()));\n    final Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"field\", \"aaa bbb ccc ddd eee fff ggg hhh iii jjj\", customType));\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    // Without fix for LUCENE-1130: this call will hang:\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    try {\n      writer.close(false);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n\n    // Make sure once disk space is avail again, we can\n    // cleanly close:\n    dir.setMaxSizeInBytes(0);\n    writer.close(false);\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1130: make sure immeidate disk full on creating\n  // an IndexWriter (hit during DW.ThreadState.init()) is\n  // OK:\n  public void testImmediateDiskFull() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n        .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler()));\n    dir.setMaxSizeInBytes(Math.max(1, dir.getRecomputedActualSizeInBytes()));\n    final Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"field\", \"aaa bbb ccc ddd eee fff ggg hhh iii jjj\", customType));\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    // Without fix for LUCENE-1130: this call will hang:\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    try {\n      writer.close(false);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n\n    // Make sure once disk space is avail again, we can\n    // cleanly close:\n    dir.setMaxSizeInBytes(0);\n    writer.close(false);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testImmediateDiskFull().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testImmediateDiskFull().mjava","sourceNew":"  // LUCENE-1130: make sure immeidate disk full on creating\n  // an IndexWriter (hit during DW.ThreadState.init()) is\n  // OK:\n  public void testImmediateDiskFull() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler()));\n    dir.setMaxSizeInBytes(Math.max(1, dir.getRecomputedActualSizeInBytes()));\n    final Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"field\", \"aaa bbb ccc ddd eee fff ggg hhh iii jjj\", customType));\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    // Without fix for LUCENE-1130: this call will hang:\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    try {\n      writer.close(false);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n\n    // Make sure once disk space is avail again, we can\n    // cleanly close:\n    dir.setMaxSizeInBytes(0);\n    writer.close(false);\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1130: make sure immeidate disk full on creating\n  // an IndexWriter (hit during DW.ThreadState.init()) is\n  // OK:\n  public void testImmediateDiskFull() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n        .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler()));\n    dir.setMaxSizeInBytes(Math.max(1, dir.getRecomputedActualSizeInBytes()));\n    final Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"field\", \"aaa bbb ccc ddd eee fff ggg hhh iii jjj\", customType));\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    // Without fix for LUCENE-1130: this call will hang:\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    try {\n      writer.close(false);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n\n    // Make sure once disk space is avail again, we can\n    // cleanly close:\n    dir.setMaxSizeInBytes(0);\n    writer.close(false);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d19974432be9aed28ee7dca73bdf01d139e763a9","date":1342822166,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testImmediateDiskFull().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testImmediateDiskFull().mjava","sourceNew":"  // LUCENE-1130: make sure immeidate disk full on creating\n  // an IndexWriter (hit during DW.ThreadState.init()) is\n  // OK:\n  public void testImmediateDiskFull() throws IOException {\n    MockDirectoryWrapper dir = newMockDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler()));\n    dir.setMaxSizeInBytes(Math.max(1, dir.getRecomputedActualSizeInBytes()));\n    final Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"field\", \"aaa bbb ccc ddd eee fff ggg hhh iii jjj\", customType));\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    // Without fix for LUCENE-1130: this call will hang:\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    try {\n      writer.close(false);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n\n    // Make sure once disk space is avail again, we can\n    // cleanly close:\n    dir.setMaxSizeInBytes(0);\n    writer.close(false);\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1130: make sure immeidate disk full on creating\n  // an IndexWriter (hit during DW.ThreadState.init()) is\n  // OK:\n  public void testImmediateDiskFull() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler()));\n    dir.setMaxSizeInBytes(Math.max(1, dir.getRecomputedActualSizeInBytes()));\n    final Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"field\", \"aaa bbb ccc ddd eee fff ggg hhh iii jjj\", customType));\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    // Without fix for LUCENE-1130: this call will hang:\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    try {\n      writer.close(false);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n\n    // Make sure once disk space is avail again, we can\n    // cleanly close:\n    dir.setMaxSizeInBytes(0);\n    writer.close(false);\n    dir.close();\n  }\n\n","bugFix":["1f653cfcf159baeaafe5d01682a911e95bba4012"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4b51f65902cc2d20ddeb7a5b949aaddf990f31a7","date":1343059585,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testImmediateDiskFull().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testImmediateDiskFull().mjava","sourceNew":"  // LUCENE-1130: make sure immeidate disk full on creating\n  // an IndexWriter (hit during DW.ThreadState.init()) is\n  // OK:\n  public void testImmediateDiskFull() throws IOException {\n    MockDirectoryWrapper dir = newMockDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler()));\n    dir.setMaxSizeInBytes(Math.max(1, dir.getRecomputedActualSizeInBytes()));\n    final Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"field\", \"aaa bbb ccc ddd eee fff ggg hhh iii jjj\", customType));\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    // Without fix for LUCENE-1130: this call will hang:\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    try {\n      writer.close(false);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n\n    // Make sure once disk space is avail again, we can\n    // cleanly close:\n    dir.setMaxSizeInBytes(0);\n    writer.close(false);\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1130: make sure immeidate disk full on creating\n  // an IndexWriter (hit during DW.ThreadState.init()) is\n  // OK:\n  public void testImmediateDiskFull() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler()));\n    dir.setMaxSizeInBytes(Math.max(1, dir.getRecomputedActualSizeInBytes()));\n    final Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"field\", \"aaa bbb ccc ddd eee fff ggg hhh iii jjj\", customType));\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    // Without fix for LUCENE-1130: this call will hang:\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    try {\n      writer.close(false);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n\n    // Make sure once disk space is avail again, we can\n    // cleanly close:\n    dir.setMaxSizeInBytes(0);\n    writer.close(false);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"aba371508186796cc6151d8223a5b4e16d02e26e","date":1343474871,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testImmediateDiskFull().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testImmediateDiskFull().mjava","sourceNew":"  // LUCENE-1130: make sure immeidate disk full on creating\n  // an IndexWriter (hit during DW.ThreadState.init()) is\n  // OK:\n  public void testImmediateDiskFull() throws IOException {\n    MockDirectoryWrapper dir = newMockDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler()));\n    dir.setMaxSizeInBytes(Math.max(1, dir.getRecomputedActualSizeInBytes()));\n    final Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"field\", \"aaa bbb ccc ddd eee fff ggg hhh iii jjj\", customType));\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    // Without fix for LUCENE-1130: this call will hang:\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    try {\n      writer.close(false);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n\n    // Make sure once disk space is avail again, we can\n    // cleanly close:\n    dir.setMaxSizeInBytes(0);\n    writer.close(false);\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1130: make sure immeidate disk full on creating\n  // an IndexWriter (hit during DW.ThreadState.init()) is\n  // OK:\n  public void testImmediateDiskFull() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler()));\n    dir.setMaxSizeInBytes(Math.max(1, dir.getRecomputedActualSizeInBytes()));\n    final Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"field\", \"aaa bbb ccc ddd eee fff ggg hhh iii jjj\", customType));\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    // Without fix for LUCENE-1130: this call will hang:\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    try {\n      writer.close(false);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n\n    // Make sure once disk space is avail again, we can\n    // cleanly close:\n    dir.setMaxSizeInBytes(0);\n    writer.close(false);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"39e6d19353f07409c79bdd58d0b496d9240c49b0","date":1344718294,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testImmediateDiskFull().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testImmediateDiskFull().mjava","sourceNew":"  // LUCENE-1130: make sure immeidate disk full on creating\n  // an IndexWriter (hit during DW.ThreadState.init()) is\n  // OK:\n  public void testImmediateDiskFull() throws IOException {\n    MockDirectoryWrapper dir = newMockDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler()));\n    dir.setMaxSizeInBytes(Math.max(1, dir.getRecomputedActualSizeInBytes()));\n    final Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    doc.add(newField(\"field\", \"aaa bbb ccc ddd eee fff ggg hhh iii jjj\", customType));\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    // Without fix for LUCENE-1130: this call will hang:\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    try {\n      writer.close(false);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n\n    // Make sure once disk space is avail again, we can\n    // cleanly close:\n    dir.setMaxSizeInBytes(0);\n    writer.close(false);\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1130: make sure immeidate disk full on creating\n  // an IndexWriter (hit during DW.ThreadState.init()) is\n  // OK:\n  public void testImmediateDiskFull() throws IOException {\n    MockDirectoryWrapper dir = newMockDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler()));\n    dir.setMaxSizeInBytes(Math.max(1, dir.getRecomputedActualSizeInBytes()));\n    final Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"field\", \"aaa bbb ccc ddd eee fff ggg hhh iii jjj\", customType));\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    // Without fix for LUCENE-1130: this call will hang:\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    try {\n      writer.close(false);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n\n    // Make sure once disk space is avail again, we can\n    // cleanly close:\n    dir.setMaxSizeInBytes(0);\n    writer.close(false);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c7869f64c874ebf7f317d22c00baf2b6857797a6","date":1344856617,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testImmediateDiskFull().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testImmediateDiskFull().mjava","sourceNew":"  // LUCENE-1130: make sure immeidate disk full on creating\n  // an IndexWriter (hit during DW.ThreadState.init()) is\n  // OK:\n  public void testImmediateDiskFull() throws IOException {\n    MockDirectoryWrapper dir = newMockDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler()));\n    dir.setMaxSizeInBytes(Math.max(1, dir.getRecomputedActualSizeInBytes()));\n    final Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    doc.add(newField(\"field\", \"aaa bbb ccc ddd eee fff ggg hhh iii jjj\", customType));\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    // Without fix for LUCENE-1130: this call will hang:\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    try {\n      writer.close(false);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n\n    // Make sure once disk space is avail again, we can\n    // cleanly close:\n    dir.setMaxSizeInBytes(0);\n    writer.close(false);\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1130: make sure immeidate disk full on creating\n  // an IndexWriter (hit during DW.ThreadState.init()) is\n  // OK:\n  public void testImmediateDiskFull() throws IOException {\n    MockDirectoryWrapper dir = newMockDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler()));\n    dir.setMaxSizeInBytes(Math.max(1, dir.getRecomputedActualSizeInBytes()));\n    final Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"field\", \"aaa bbb ccc ddd eee fff ggg hhh iii jjj\", customType));\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    // Without fix for LUCENE-1130: this call will hang:\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    try {\n      writer.close(false);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n\n    // Make sure once disk space is avail again, we can\n    // cleanly close:\n    dir.setMaxSizeInBytes(0);\n    writer.close(false);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ba34ddeec9e4ab657150c29a5614a7bfbb53c9","date":1344867506,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testImmediateDiskFull().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testImmediateDiskFull().mjava","sourceNew":"  // LUCENE-1130: make sure immeidate disk full on creating\n  // an IndexWriter (hit during DW.ThreadState.init()) is\n  // OK:\n  public void testImmediateDiskFull() throws IOException {\n    MockDirectoryWrapper dir = newMockDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler()));\n    dir.setMaxSizeInBytes(Math.max(1, dir.getRecomputedActualSizeInBytes()));\n    final Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    doc.add(newField(\"field\", \"aaa bbb ccc ddd eee fff ggg hhh iii jjj\", customType));\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    // Without fix for LUCENE-1130: this call will hang:\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    try {\n      writer.close(false);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n\n    // Make sure once disk space is avail again, we can\n    // cleanly close:\n    dir.setMaxSizeInBytes(0);\n    writer.close(false);\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1130: make sure immeidate disk full on creating\n  // an IndexWriter (hit during DW.ThreadState.init()) is\n  // OK:\n  public void testImmediateDiskFull() throws IOException {\n    MockDirectoryWrapper dir = newMockDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler()));\n    dir.setMaxSizeInBytes(Math.max(1, dir.getRecomputedActualSizeInBytes()));\n    final Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"field\", \"aaa bbb ccc ddd eee fff ggg hhh iii jjj\", customType));\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    // Without fix for LUCENE-1130: this call will hang:\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    try {\n      writer.close(false);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n\n    // Make sure once disk space is avail again, we can\n    // cleanly close:\n    dir.setMaxSizeInBytes(0);\n    writer.close(false);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testImmediateDiskFull().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testImmediateDiskFull().mjava","sourceNew":"  // LUCENE-1130: make sure immeidate disk full on creating\n  // an IndexWriter (hit during DW.ThreadState.init()) is\n  // OK:\n  public void testImmediateDiskFull() throws IOException {\n    MockDirectoryWrapper dir = newMockDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler()));\n    dir.setMaxSizeInBytes(Math.max(1, dir.getRecomputedActualSizeInBytes()));\n    final Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    doc.add(newField(\"field\", \"aaa bbb ccc ddd eee fff ggg hhh iii jjj\", customType));\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    // Without fix for LUCENE-1130: this call will hang:\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    try {\n      writer.shutdown(false);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n\n    // Make sure once disk space is avail again, we can\n    // cleanly close:\n    dir.setMaxSizeInBytes(0);\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1130: make sure immeidate disk full on creating\n  // an IndexWriter (hit during DW.ThreadState.init()) is\n  // OK:\n  public void testImmediateDiskFull() throws IOException {\n    MockDirectoryWrapper dir = newMockDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler()));\n    dir.setMaxSizeInBytes(Math.max(1, dir.getRecomputedActualSizeInBytes()));\n    final Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    doc.add(newField(\"field\", \"aaa bbb ccc ddd eee fff ggg hhh iii jjj\", customType));\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    // Without fix for LUCENE-1130: this call will hang:\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    try {\n      writer.close(false);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n\n    // Make sure once disk space is avail again, we can\n    // cleanly close:\n    dir.setMaxSizeInBytes(0);\n    writer.close(false);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testImmediateDiskFull().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testImmediateDiskFull().mjava","sourceNew":"  // LUCENE-1130: make sure immeidate disk full on creating\n  // an IndexWriter (hit during DW.ThreadState.init()) is\n  // OK:\n  public void testImmediateDiskFull() throws IOException {\n    MockDirectoryWrapper dir = newMockDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                .setMaxBufferedDocs(2)\n                                                .setMergeScheduler(new ConcurrentMergeScheduler()));\n    dir.setMaxSizeInBytes(Math.max(1, dir.getRecomputedActualSizeInBytes()));\n    final Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    doc.add(newField(\"field\", \"aaa bbb ccc ddd eee fff ggg hhh iii jjj\", customType));\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    // Without fix for LUCENE-1130: this call will hang:\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    try {\n      writer.shutdown(false);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n\n    // Make sure once disk space is avail again, we can\n    // cleanly close:\n    dir.setMaxSizeInBytes(0);\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1130: make sure immeidate disk full on creating\n  // an IndexWriter (hit during DW.ThreadState.init()) is\n  // OK:\n  public void testImmediateDiskFull() throws IOException {\n    MockDirectoryWrapper dir = newMockDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler()));\n    dir.setMaxSizeInBytes(Math.max(1, dir.getRecomputedActualSizeInBytes()));\n    final Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    doc.add(newField(\"field\", \"aaa bbb ccc ddd eee fff ggg hhh iii jjj\", customType));\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    // Without fix for LUCENE-1130: this call will hang:\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    try {\n      writer.shutdown(false);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n\n    // Make sure once disk space is avail again, we can\n    // cleanly close:\n    dir.setMaxSizeInBytes(0);\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testImmediateDiskFull().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testImmediateDiskFull().mjava","sourceNew":"  // LUCENE-1130: make sure immeidate disk full on creating\n  // an IndexWriter (hit during DW.ThreadState.init()) is\n  // OK:\n  public void testImmediateDiskFull() throws IOException {\n    MockDirectoryWrapper dir = newMockDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                .setMaxBufferedDocs(2)\n                                                .setMergeScheduler(new ConcurrentMergeScheduler())\n                                                .setCommitOnClose(false));\n    dir.setMaxSizeInBytes(Math.max(1, dir.getRecomputedActualSizeInBytes()));\n    final Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    doc.add(newField(\"field\", \"aaa bbb ccc ddd eee fff ggg hhh iii jjj\", customType));\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    // Without fix for LUCENE-1130: this call will hang:\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    try {\n      writer.commit();\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    } finally {\n      writer.close();\n    }\n\n    // Make sure once disk space is avail again, we can\n    // cleanly close:\n    dir.setMaxSizeInBytes(0);\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1130: make sure immeidate disk full on creating\n  // an IndexWriter (hit during DW.ThreadState.init()) is\n  // OK:\n  public void testImmediateDiskFull() throws IOException {\n    MockDirectoryWrapper dir = newMockDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                .setMaxBufferedDocs(2)\n                                                .setMergeScheduler(new ConcurrentMergeScheduler()));\n    dir.setMaxSizeInBytes(Math.max(1, dir.getRecomputedActualSizeInBytes()));\n    final Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    doc.add(newField(\"field\", \"aaa bbb ccc ddd eee fff ggg hhh iii jjj\", customType));\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    // Without fix for LUCENE-1130: this call will hang:\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    try {\n      writer.shutdown(false);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n\n    // Make sure once disk space is avail again, we can\n    // cleanly close:\n    dir.setMaxSizeInBytes(0);\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"98d2deb8c96c79ebef084a1f8e5a1a6c08608f13","date":1409346855,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testImmediateDiskFull().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testImmediateDiskFull().mjava","sourceNew":"  // LUCENE-1130: make sure immeidate disk full on creating\n  // an IndexWriter (hit during DW.ThreadState.init()) is\n  // OK:\n  public void testImmediateDiskFull() throws IOException {\n    MockDirectoryWrapper dir = newMockDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                .setMaxBufferedDocs(2)\n                                                .setMergeScheduler(new ConcurrentMergeScheduler())\n                                                .setCommitOnClose(false));\n    writer.commit(); // empty commit, to not create confusing situation with first commit\n    dir.setMaxSizeInBytes(Math.max(1, dir.getRecomputedActualSizeInBytes()));\n    final Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    doc.add(newField(\"field\", \"aaa bbb ccc ddd eee fff ggg hhh iii jjj\", customType));\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    // Without fix for LUCENE-1130: this call will hang:\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    try {\n      writer.commit();\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    } finally {\n      writer.close();\n    }\n\n    // Make sure once disk space is avail again, we can\n    // cleanly close:\n    dir.setMaxSizeInBytes(0);\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1130: make sure immeidate disk full on creating\n  // an IndexWriter (hit during DW.ThreadState.init()) is\n  // OK:\n  public void testImmediateDiskFull() throws IOException {\n    MockDirectoryWrapper dir = newMockDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                .setMaxBufferedDocs(2)\n                                                .setMergeScheduler(new ConcurrentMergeScheduler())\n                                                .setCommitOnClose(false));\n    dir.setMaxSizeInBytes(Math.max(1, dir.getRecomputedActualSizeInBytes()));\n    final Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    doc.add(newField(\"field\", \"aaa bbb ccc ddd eee fff ggg hhh iii jjj\", customType));\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    // Without fix for LUCENE-1130: this call will hang:\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    try {\n      writer.commit();\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    } finally {\n      writer.close();\n    }\n\n    // Make sure once disk space is avail again, we can\n    // cleanly close:\n    dir.setMaxSizeInBytes(0);\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9299079153fd7895bf3cf6835cf7019af2ba89b3","date":1417813477,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testImmediateDiskFull().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testImmediateDiskFull().mjava","sourceNew":"  // LUCENE-1130: make sure immeidate disk full on creating\n  // an IndexWriter (hit during DW.ThreadState.init()) is\n  // OK:\n  public void testImmediateDiskFull() throws IOException {\n    MockDirectoryWrapper dir = newMockDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                .setMaxBufferedDocs(2)\n                                                .setMergeScheduler(new ConcurrentMergeScheduler())\n                                                .setCommitOnClose(false));\n    writer.commit(); // empty commit, to not create confusing situation with first commit\n    dir.setMaxSizeInBytes(Math.max(1, dir.getRecomputedActualSizeInBytes()));\n    final Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    doc.add(newField(\"field\", \"aaa bbb ccc ddd eee fff ggg hhh iii jjj\", customType));\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n      assertTrue(writer.deleter.isClosed());\n      assertTrue(writer.isClosed());\n    }\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1130: make sure immeidate disk full on creating\n  // an IndexWriter (hit during DW.ThreadState.init()) is\n  // OK:\n  public void testImmediateDiskFull() throws IOException {\n    MockDirectoryWrapper dir = newMockDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                .setMaxBufferedDocs(2)\n                                                .setMergeScheduler(new ConcurrentMergeScheduler())\n                                                .setCommitOnClose(false));\n    writer.commit(); // empty commit, to not create confusing situation with first commit\n    dir.setMaxSizeInBytes(Math.max(1, dir.getRecomputedActualSizeInBytes()));\n    final Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    doc.add(newField(\"field\", \"aaa bbb ccc ddd eee fff ggg hhh iii jjj\", customType));\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    // Without fix for LUCENE-1130: this call will hang:\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    }\n    try {\n      writer.commit();\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n    } finally {\n      writer.close();\n    }\n\n    // Make sure once disk space is avail again, we can\n    // cleanly close:\n    dir.setMaxSizeInBytes(0);\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":["05fe562aa248790944d43cdd478f512572835ba0"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"05fe562aa248790944d43cdd478f512572835ba0","date":1455901667,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testImmediateDiskFull().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testImmediateDiskFull().mjava","sourceNew":"  // LUCENE-1130: make sure immeidate disk full on creating\n  // an IndexWriter (hit during DW.ThreadState.init()) is\n  // OK:\n  public void testImmediateDiskFull() throws IOException {\n    MockDirectoryWrapper dir = newMockDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                .setMaxBufferedDocs(2)\n                                                .setMergeScheduler(new ConcurrentMergeScheduler())\n                                                .setCommitOnClose(false));\n    writer.commit(); // empty commit, to not create confusing situation with first commit\n    dir.setMaxSizeInBytes(Math.max(1, dir.getRecomputedActualSizeInBytes()));\n    final Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    doc.add(newField(\"field\", \"aaa bbb ccc ddd eee fff ggg hhh iii jjj\", customType));\n    expectThrows(IOException.class, () -> {\n      writer.addDocument(doc);\n    });\n    assertTrue(writer.deleter.isClosed());\n    assertTrue(writer.isClosed());\n\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1130: make sure immeidate disk full on creating\n  // an IndexWriter (hit during DW.ThreadState.init()) is\n  // OK:\n  public void testImmediateDiskFull() throws IOException {\n    MockDirectoryWrapper dir = newMockDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                .setMaxBufferedDocs(2)\n                                                .setMergeScheduler(new ConcurrentMergeScheduler())\n                                                .setCommitOnClose(false));\n    writer.commit(); // empty commit, to not create confusing situation with first commit\n    dir.setMaxSizeInBytes(Math.max(1, dir.getRecomputedActualSizeInBytes()));\n    final Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    doc.add(newField(\"field\", \"aaa bbb ccc ddd eee fff ggg hhh iii jjj\", customType));\n    try {\n      writer.addDocument(doc);\n      fail(\"did not hit disk full\");\n    } catch (IOException ioe) {\n      assertTrue(writer.deleter.isClosed());\n      assertTrue(writer.isClosed());\n    }\n    dir.close();\n  }\n\n","bugFix":["9299079153fd7895bf3cf6835cf7019af2ba89b3","83bbb041887bbef07b8a98d08a0e1713ce137039"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"409da428f28953cf35fddd5c9ff5c7e4f5439863","date":1547556145,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testImmediateDiskFull().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testImmediateDiskFull().mjava","sourceNew":"  // LUCENE-1130: make sure immeidate disk full on creating\n  // an IndexWriter (hit during DW.ThreadState.init()) is\n  // OK:\n  public void testImmediateDiskFull() throws IOException {\n    MockDirectoryWrapper dir = newMockDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                .setMaxBufferedDocs(2)\n                                                .setMergeScheduler(new ConcurrentMergeScheduler())\n                                                .setCommitOnClose(false));\n    writer.commit(); // empty commit, to not create confusing situation with first commit\n    dir.setMaxSizeInBytes(Math.max(1, dir.sizeInBytes()));\n    final Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    doc.add(newField(\"field\", \"aaa bbb ccc ddd eee fff ggg hhh iii jjj\", customType));\n    expectThrows(IOException.class, () -> {\n      writer.addDocument(doc);\n    });\n    assertTrue(writer.deleter.isClosed());\n    assertTrue(writer.isClosed());\n\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1130: make sure immeidate disk full on creating\n  // an IndexWriter (hit during DW.ThreadState.init()) is\n  // OK:\n  public void testImmediateDiskFull() throws IOException {\n    MockDirectoryWrapper dir = newMockDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                .setMaxBufferedDocs(2)\n                                                .setMergeScheduler(new ConcurrentMergeScheduler())\n                                                .setCommitOnClose(false));\n    writer.commit(); // empty commit, to not create confusing situation with first commit\n    dir.setMaxSizeInBytes(Math.max(1, dir.getRecomputedActualSizeInBytes()));\n    final Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    doc.add(newField(\"field\", \"aaa bbb ccc ddd eee fff ggg hhh iii jjj\", customType));\n    expectThrows(IOException.class, () -> {\n      writer.addDocument(doc);\n    });\n    assertTrue(writer.deleter.isClosed());\n    assertTrue(writer.isClosed());\n\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"264935965977b4a9e2f3920420647072c9c49176","date":1586600626,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testImmediateDiskFull().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testImmediateDiskFull().mjava","sourceNew":"  // LUCENE-1130: make sure immediate disk full on creating\n  // an IndexWriter (hit during DWPT#updateDocuments()) is\n  // OK:\n  public void testImmediateDiskFull() throws IOException {\n    MockDirectoryWrapper dir = newMockDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                .setMaxBufferedDocs(2)\n                                                .setMergeScheduler(new ConcurrentMergeScheduler())\n                                                .setCommitOnClose(false));\n    writer.commit(); // empty commit, to not create confusing situation with first commit\n    dir.setMaxSizeInBytes(Math.max(1, dir.sizeInBytes()));\n    final Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    doc.add(newField(\"field\", \"aaa bbb ccc ddd eee fff ggg hhh iii jjj\", customType));\n    expectThrows(IOException.class, () -> {\n      writer.addDocument(doc);\n    });\n    assertTrue(writer.deleter.isClosed());\n    assertTrue(writer.isClosed());\n\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1130: make sure immeidate disk full on creating\n  // an IndexWriter (hit during DW.ThreadState.init()) is\n  // OK:\n  public void testImmediateDiskFull() throws IOException {\n    MockDirectoryWrapper dir = newMockDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                .setMaxBufferedDocs(2)\n                                                .setMergeScheduler(new ConcurrentMergeScheduler())\n                                                .setCommitOnClose(false));\n    writer.commit(); // empty commit, to not create confusing situation with first commit\n    dir.setMaxSizeInBytes(Math.max(1, dir.sizeInBytes()));\n    final Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    doc.add(newField(\"field\", \"aaa bbb ccc ddd eee fff ggg hhh iii jjj\", customType));\n    expectThrows(IOException.class, () -> {\n      writer.addDocument(doc);\n    });\n    assertTrue(writer.deleter.isClosed());\n    assertTrue(writer.isClosed());\n\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8a428f5314daaabf8eab7c50bdc3bc14e6cd1aa2","date":1588002560,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testImmediateDiskFull().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testImmediateDiskFull().mjava","sourceNew":"  // LUCENE-1130: make sure immediate disk full on creating\n  // an IndexWriter (hit during DWPT#updateDocuments()) is\n  // OK:\n  public void testImmediateDiskFull() throws IOException {\n    MockDirectoryWrapper dir = newMockDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                .setMaxBufferedDocs(2)\n                                                .setMergeScheduler(new ConcurrentMergeScheduler())\n                                                .setCommitOnClose(false));\n    writer.commit(); // empty commit, to not create confusing situation with first commit\n    dir.setMaxSizeInBytes(Math.max(1, dir.sizeInBytes()));\n    final Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    doc.add(newField(\"field\", \"aaa bbb ccc ddd eee fff ggg hhh iii jjj\", customType));\n    expectThrows(IOException.class, () -> {\n      writer.addDocument(doc);\n    });\n    assertTrue(writer.isDeleterClosed());\n    assertTrue(writer.isClosed());\n\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1130: make sure immediate disk full on creating\n  // an IndexWriter (hit during DWPT#updateDocuments()) is\n  // OK:\n  public void testImmediateDiskFull() throws IOException {\n    MockDirectoryWrapper dir = newMockDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                .setMaxBufferedDocs(2)\n                                                .setMergeScheduler(new ConcurrentMergeScheduler())\n                                                .setCommitOnClose(false));\n    writer.commit(); // empty commit, to not create confusing situation with first commit\n    dir.setMaxSizeInBytes(Math.max(1, dir.sizeInBytes()));\n    final Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    doc.add(newField(\"field\", \"aaa bbb ccc ddd eee fff ggg hhh iii jjj\", customType));\n    expectThrows(IOException.class, () -> {\n      writer.addDocument(doc);\n    });\n    assertTrue(writer.deleter.isClosed());\n    assertTrue(writer.isClosed());\n\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"264935965977b4a9e2f3920420647072c9c49176":["409da428f28953cf35fddd5c9ff5c7e4f5439863"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"05fe562aa248790944d43cdd478f512572835ba0":["9299079153fd7895bf3cf6835cf7019af2ba89b3"],"98d2deb8c96c79ebef084a1f8e5a1a6c08608f13":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"39e6d19353f07409c79bdd58d0b496d9240c49b0":["d19974432be9aed28ee7dca73bdf01d139e763a9"],"409da428f28953cf35fddd5c9ff5c7e4f5439863":["05fe562aa248790944d43cdd478f512572835ba0"],"aba371508186796cc6151d8223a5b4e16d02e26e":["629c38c4ae4e303d0617e05fbfe508140b32f0a3","d19974432be9aed28ee7dca73bdf01d139e763a9"],"c7869f64c874ebf7f317d22c00baf2b6857797a6":["4b51f65902cc2d20ddeb7a5b949aaddf990f31a7","39e6d19353f07409c79bdd58d0b496d9240c49b0"],"d19974432be9aed28ee7dca73bdf01d139e763a9":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"8a428f5314daaabf8eab7c50bdc3bc14e6cd1aa2":["264935965977b4a9e2f3920420647072c9c49176"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"9299079153fd7895bf3cf6835cf7019af2ba89b3":["98d2deb8c96c79ebef084a1f8e5a1a6c08608f13"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["39e6d19353f07409c79bdd58d0b496d9240c49b0"],"4b51f65902cc2d20ddeb7a5b949aaddf990f31a7":["629c38c4ae4e303d0617e05fbfe508140b32f0a3","d19974432be9aed28ee7dca73bdf01d139e763a9"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"d0ba34ddeec9e4ab657150c29a5614a7bfbb53c9":["aba371508186796cc6151d8223a5b4e16d02e26e","39e6d19353f07409c79bdd58d0b496d9240c49b0"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["8a428f5314daaabf8eab7c50bdc3bc14e6cd1aa2"]},"commit2Childs":{"264935965977b4a9e2f3920420647072c9c49176":["8a428f5314daaabf8eab7c50bdc3bc14e6cd1aa2"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"05fe562aa248790944d43cdd478f512572835ba0":["409da428f28953cf35fddd5c9ff5c7e4f5439863"],"98d2deb8c96c79ebef084a1f8e5a1a6c08608f13":["9299079153fd7895bf3cf6835cf7019af2ba89b3"],"39e6d19353f07409c79bdd58d0b496d9240c49b0":["c7869f64c874ebf7f317d22c00baf2b6857797a6","ae14298f4eec6d5faee6a149f88ba57d14a6f21a","d0ba34ddeec9e4ab657150c29a5614a7bfbb53c9"],"409da428f28953cf35fddd5c9ff5c7e4f5439863":["264935965977b4a9e2f3920420647072c9c49176"],"aba371508186796cc6151d8223a5b4e16d02e26e":["d0ba34ddeec9e4ab657150c29a5614a7bfbb53c9"],"c7869f64c874ebf7f317d22c00baf2b6857797a6":[],"d19974432be9aed28ee7dca73bdf01d139e763a9":["39e6d19353f07409c79bdd58d0b496d9240c49b0","aba371508186796cc6151d8223a5b4e16d02e26e","4b51f65902cc2d20ddeb7a5b949aaddf990f31a7"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["98d2deb8c96c79ebef084a1f8e5a1a6c08608f13"],"8a428f5314daaabf8eab7c50bdc3bc14e6cd1aa2":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"9299079153fd7895bf3cf6835cf7019af2ba89b3":["05fe562aa248790944d43cdd478f512572835ba0"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"4b51f65902cc2d20ddeb7a5b949aaddf990f31a7":["c7869f64c874ebf7f317d22c00baf2b6857797a6"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["aba371508186796cc6151d8223a5b4e16d02e26e","d19974432be9aed28ee7dca73bdf01d139e763a9","4b51f65902cc2d20ddeb7a5b949aaddf990f31a7"],"d0ba34ddeec9e4ab657150c29a5614a7bfbb53c9":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["c7869f64c874ebf7f317d22c00baf2b6857797a6","d0ba34ddeec9e4ab657150c29a5614a7bfbb53c9","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}