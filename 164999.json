{"path":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimExtremeIndexing#testScaleUp().mjava","commits":[{"id":"fc18bc8ea2e2c1e308757ff50671c774438e9f3e","date":1538052583,"type":0,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimExtremeIndexing#testScaleUp().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testScaleUp() throws Exception {\n    String collectionName = \"testScaleUp_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(10);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cluster, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2, false, true));\n\n    //long waitForSeconds = 3 + random().nextInt(5);\n    long waitForSeconds = 1;\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'scaleUpTrigger',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : \" + ABOVE_SIZE + \",\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    long batchSize = BATCH_SIZE;\n    for (long i = 0; i < NUM_BATCHES; i++) {\n      addDocs(collectionName, i * batchSize, batchSize);\n      log.info(String.format(Locale.ROOT, \"#### Total docs so far: %,d\", ((i + 1) * batchSize)));\n      timeSource.sleep(waitForSeconds);\n    }\n    timeSource.sleep(60000);\n    QueryResponse rsp = solrClient.query(collectionName, params(CommonParams.Q, \"*:*\"));\n    SolrDocumentList docs = rsp.getResults();\n    assertNotNull(docs);\n    assertEquals(docs.toString(), batchSize * NUM_BATCHES, docs.getNumFound());\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ae70f2df00762dfce0455c0e39381848762662e5","date":1539113410,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimExtremeIndexing#testScaleUp().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimExtremeIndexing#testScaleUp().mjava","sourceNew":"  @Test\n  public void testScaleUp() throws Exception {\n    String collectionName = \"testScaleUp_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(10);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cluster, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2, false, true));\n\n    //long waitForSeconds = 3 + random().nextInt(5);\n    long waitForSeconds = 1;\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'scaleUpTrigger',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : \" + ABOVE_SIZE + \",\" +\n        \"'maxOps' : \" + MAX_OPS + \",\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    long batchSize = BATCH_SIZE;\n    for (long i = 0; i < NUM_BATCHES; i++) {\n      addDocs(collectionName, i * batchSize, batchSize);\n      log.info(String.format(Locale.ROOT, \"#### Total docs so far: %,d\", ((i + 1) * batchSize)));\n      timeSource.sleep(waitForSeconds);\n    }\n    timeSource.sleep(60000);\n    QueryResponse rsp = solrClient.query(collectionName, params(CommonParams.Q, \"*:*\"));\n    SolrDocumentList docs = rsp.getResults();\n    assertNotNull(docs);\n    assertEquals(docs.toString(), batchSize * NUM_BATCHES, docs.getNumFound());\n  }\n\n","sourceOld":"  @Test\n  public void testScaleUp() throws Exception {\n    String collectionName = \"testScaleUp_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(10);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cluster, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2, false, true));\n\n    //long waitForSeconds = 3 + random().nextInt(5);\n    long waitForSeconds = 1;\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'scaleUpTrigger',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : \" + ABOVE_SIZE + \",\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    long batchSize = BATCH_SIZE;\n    for (long i = 0; i < NUM_BATCHES; i++) {\n      addDocs(collectionName, i * batchSize, batchSize);\n      log.info(String.format(Locale.ROOT, \"#### Total docs so far: %,d\", ((i + 1) * batchSize)));\n      timeSource.sleep(waitForSeconds);\n    }\n    timeSource.sleep(60000);\n    QueryResponse rsp = solrClient.query(collectionName, params(CommonParams.Q, \"*:*\"));\n    SolrDocumentList docs = rsp.getResults();\n    assertNotNull(docs);\n    assertEquals(docs.toString(), batchSize * NUM_BATCHES, docs.getNumFound());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bb222a3f9d9421d5c95afce73013fbd8de07ea1f","date":1543514331,"type":3,"author":"markrmiller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimExtremeIndexing#testScaleUp().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimExtremeIndexing#testScaleUp().mjava","sourceNew":"  @Test\n  public void testScaleUp() throws Exception {\n    String collectionName = \"testScaleUp_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(10);\n    create.process(solrClient);\n    \n    CloudTestUtils.waitForState(cluster, collectionName, 90, TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(2, 2, false, true));\n\n    //long waitForSeconds = 3 + random().nextInt(5);\n    long waitForSeconds = 1;\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'scaleUpTrigger',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : \" + ABOVE_SIZE + \",\" +\n        \"'maxOps' : \" + MAX_OPS + \",\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    long batchSize = BATCH_SIZE;\n    for (long i = 0; i < NUM_BATCHES; i++) {\n      addDocs(collectionName, i * batchSize, batchSize);\n      log.info(String.format(Locale.ROOT, \"#### Total docs so far: %,d\", ((i + 1) * batchSize)));\n      timeSource.sleep(waitForSeconds);\n    }\n    timeSource.sleep(60000);\n    QueryResponse rsp = solrClient.query(collectionName, params(CommonParams.Q, \"*:*\"));\n    SolrDocumentList docs = rsp.getResults();\n    assertNotNull(docs);\n    assertEquals(docs.toString(), batchSize * NUM_BATCHES, docs.getNumFound());\n  }\n\n","sourceOld":"  @Test\n  public void testScaleUp() throws Exception {\n    String collectionName = \"testScaleUp_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(10);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cluster, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2, false, true));\n\n    //long waitForSeconds = 3 + random().nextInt(5);\n    long waitForSeconds = 1;\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'scaleUpTrigger',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : \" + ABOVE_SIZE + \",\" +\n        \"'maxOps' : \" + MAX_OPS + \",\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    long batchSize = BATCH_SIZE;\n    for (long i = 0; i < NUM_BATCHES; i++) {\n      addDocs(collectionName, i * batchSize, batchSize);\n      log.info(String.format(Locale.ROOT, \"#### Total docs so far: %,d\", ((i + 1) * batchSize)));\n      timeSource.sleep(waitForSeconds);\n    }\n    timeSource.sleep(60000);\n    QueryResponse rsp = solrClient.query(collectionName, params(CommonParams.Q, \"*:*\"));\n    SolrDocumentList docs = rsp.getResults();\n    assertNotNull(docs);\n    assertEquals(docs.toString(), batchSize * NUM_BATCHES, docs.getNumFound());\n  }\n\n","bugFix":["fc18bc8ea2e2c1e308757ff50671c774438e9f3e"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"89948af0461fead48f44ba8fb7866f107ce83f22","date":1545157711,"type":3,"author":"Chris Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimExtremeIndexing#testScaleUp().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimExtremeIndexing#testScaleUp().mjava","sourceNew":"  @Test\n  public void testScaleUp() throws Exception {\n    String collectionName = \"testScaleUp_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(10);\n    create.process(solrClient);\n    \n    CloudTestUtils.waitForState(cluster, collectionName, 90, TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(2, 2, false, true));\n\n    //long waitForSeconds = 3 + random().nextInt(5);\n    long waitForSeconds = 1;\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'scaleUpTrigger',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : \" + ABOVE_SIZE + \",\" +\n        \"'maxOps' : \" + MAX_OPS + \",\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    long batchSize = BATCH_SIZE;\n    for (long i = 0; i < NUM_BATCHES; i++) {\n      addDocs(collectionName, i * batchSize, batchSize);\n      log.info(String.format(Locale.ROOT, \"#### Total docs so far: %,d\", ((i + 1) * batchSize)));\n      timeSource.sleep(waitForSeconds);\n    }\n    timeSource.sleep(60000);\n    QueryResponse rsp = solrClient.query(collectionName, params(CommonParams.Q, \"*:*\"));\n    SolrDocumentList docs = rsp.getResults();\n    assertNotNull(docs);\n    assertEquals(docs.toString(), batchSize * NUM_BATCHES, docs.getNumFound());\n  }\n\n","sourceOld":"  @Test\n  public void testScaleUp() throws Exception {\n    String collectionName = \"testScaleUp_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(10);\n    create.process(solrClient);\n    \n    CloudTestUtils.waitForState(cluster, collectionName, 90, TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(2, 2, false, true));\n\n    //long waitForSeconds = 3 + random().nextInt(5);\n    long waitForSeconds = 1;\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'scaleUpTrigger',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : \" + ABOVE_SIZE + \",\" +\n        \"'maxOps' : \" + MAX_OPS + \",\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    long batchSize = BATCH_SIZE;\n    for (long i = 0; i < NUM_BATCHES; i++) {\n      addDocs(collectionName, i * batchSize, batchSize);\n      log.info(String.format(Locale.ROOT, \"#### Total docs so far: %,d\", ((i + 1) * batchSize)));\n      timeSource.sleep(waitForSeconds);\n    }\n    timeSource.sleep(60000);\n    QueryResponse rsp = solrClient.query(collectionName, params(CommonParams.Q, \"*:*\"));\n    SolrDocumentList docs = rsp.getResults();\n    assertNotNull(docs);\n    assertEquals(docs.toString(), batchSize * NUM_BATCHES, docs.getNumFound());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ce85ed088dcf7aa1742105d4a8caa9aab3b491c1","date":1546971158,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimExtremeIndexing#testScaleUp().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimExtremeIndexing#testScaleUp().mjava","sourceNew":"  @Test\n  public void testScaleUp() throws Exception {\n    String collectionName = \"testScaleUp_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(10);\n    create.process(solrClient);\n    \n    CloudTestUtils.waitForState(cluster, collectionName, 90, TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(2, 2, false, true));\n\n    //long waitForSeconds = 3 + random().nextInt(5);\n    long waitForSeconds = 1;\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'scaleUpTrigger',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : \" + ABOVE_SIZE + \",\" +\n        \"'maxOps' : \" + MAX_OPS + \",\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    assertAutoscalingUpdateComplete();\n\n    long batchSize = BATCH_SIZE;\n    for (long i = 0; i < NUM_BATCHES; i++) {\n      addDocs(collectionName, i * batchSize, batchSize);\n      log.info(String.format(Locale.ROOT, \"#### Total docs so far: %,d\", ((i + 1) * batchSize)));\n      timeSource.sleep(waitForSeconds);\n    }\n    timeSource.sleep(60000);\n    QueryResponse rsp = solrClient.query(collectionName, params(CommonParams.Q, \"*:*\"));\n    SolrDocumentList docs = rsp.getResults();\n    assertNotNull(docs);\n    assertEquals(docs.toString(), batchSize * NUM_BATCHES, docs.getNumFound());\n  }\n\n","sourceOld":"  @Test\n  public void testScaleUp() throws Exception {\n    String collectionName = \"testScaleUp_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(10);\n    create.process(solrClient);\n    \n    CloudTestUtils.waitForState(cluster, collectionName, 90, TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(2, 2, false, true));\n\n    //long waitForSeconds = 3 + random().nextInt(5);\n    long waitForSeconds = 1;\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'scaleUpTrigger',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : \" + ABOVE_SIZE + \",\" +\n        \"'maxOps' : \" + MAX_OPS + \",\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    long batchSize = BATCH_SIZE;\n    for (long i = 0; i < NUM_BATCHES; i++) {\n      addDocs(collectionName, i * batchSize, batchSize);\n      log.info(String.format(Locale.ROOT, \"#### Total docs so far: %,d\", ((i + 1) * batchSize)));\n      timeSource.sleep(waitForSeconds);\n    }\n    timeSource.sleep(60000);\n    QueryResponse rsp = solrClient.query(collectionName, params(CommonParams.Q, \"*:*\"));\n    SolrDocumentList docs = rsp.getResults();\n    assertNotNull(docs);\n    assertEquals(docs.toString(), batchSize * NUM_BATCHES, docs.getNumFound());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9ef8d00dbfbeb534eba8a219a5df9d99b2de6ab5","date":1556572478,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimExtremeIndexing#testScaleUp().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimExtremeIndexing#testScaleUp().mjava","sourceNew":"  @Test\n  public void testScaleUp() throws Exception {\n    String collectionName = \"testScaleUp_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(10);\n    create.process(solrClient);\n\n    CloudUtil.waitForState(cluster, collectionName, 90, TimeUnit.SECONDS,\n        CloudUtil.clusterShape(2, 2, false, true));\n\n    //long waitForSeconds = 3 + random().nextInt(5);\n    long waitForSeconds = 1;\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'scaleUpTrigger',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : \" + ABOVE_SIZE + \",\" +\n        \"'maxOps' : \" + MAX_OPS + \",\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    assertAutoscalingUpdateComplete();\n\n    long batchSize = BATCH_SIZE;\n    for (long i = 0; i < NUM_BATCHES; i++) {\n      addDocs(collectionName, i * batchSize, batchSize);\n      log.info(String.format(Locale.ROOT, \"#### Total docs so far: %,d\", ((i + 1) * batchSize)));\n      timeSource.sleep(waitForSeconds);\n    }\n    timeSource.sleep(60000);\n    QueryResponse rsp = solrClient.query(collectionName, params(CommonParams.Q, \"*:*\"));\n    SolrDocumentList docs = rsp.getResults();\n    assertNotNull(docs);\n    assertEquals(docs.toString(), batchSize * NUM_BATCHES, docs.getNumFound());\n  }\n\n","sourceOld":"  @Test\n  public void testScaleUp() throws Exception {\n    String collectionName = \"testScaleUp_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(10);\n    create.process(solrClient);\n    \n    CloudTestUtils.waitForState(cluster, collectionName, 90, TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(2, 2, false, true));\n\n    //long waitForSeconds = 3 + random().nextInt(5);\n    long waitForSeconds = 1;\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'scaleUpTrigger',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : \" + ABOVE_SIZE + \",\" +\n        \"'maxOps' : \" + MAX_OPS + \",\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    assertAutoscalingUpdateComplete();\n\n    long batchSize = BATCH_SIZE;\n    for (long i = 0; i < NUM_BATCHES; i++) {\n      addDocs(collectionName, i * batchSize, batchSize);\n      log.info(String.format(Locale.ROOT, \"#### Total docs so far: %,d\", ((i + 1) * batchSize)));\n      timeSource.sleep(waitForSeconds);\n    }\n    timeSource.sleep(60000);\n    QueryResponse rsp = solrClient.query(collectionName, params(CommonParams.Q, \"*:*\"));\n    SolrDocumentList docs = rsp.getResults();\n    assertNotNull(docs);\n    assertEquals(docs.toString(), batchSize * NUM_BATCHES, docs.getNumFound());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fe9f2c4a0d7ac164e4bdd4eee7f87131aec83fd4","date":1588172214,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimExtremeIndexing#testScaleUp().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimExtremeIndexing#testScaleUp().mjava","sourceNew":"  @Test\n  public void testScaleUp() throws Exception {\n    String collectionName = \"testScaleUp_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(10);\n    create.process(solrClient);\n\n    CloudUtil.waitForState(cluster, collectionName, 90, TimeUnit.SECONDS,\n        CloudUtil.clusterShape(2, 2, false, true));\n\n    //long waitForSeconds = 3 + random().nextInt(5);\n    long waitForSeconds = 1;\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'scaleUpTrigger',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : \" + ABOVE_SIZE + \",\" +\n        \"'maxOps' : \" + MAX_OPS + \",\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    assertAutoscalingUpdateComplete();\n\n    long batchSize = BATCH_SIZE;\n    for (long i = 0; i < NUM_BATCHES; i++) {\n      addDocs(collectionName, i * batchSize, batchSize);\n      if (log.isInfoEnabled()) {\n        log.info(String.format(Locale.ROOT, \"#### Total docs so far: %,d\", ((i + 1) * batchSize))); // logOk\n      }\n      timeSource.sleep(waitForSeconds);\n    }\n    timeSource.sleep(60000);\n    QueryResponse rsp = solrClient.query(collectionName, params(CommonParams.Q, \"*:*\"));\n    SolrDocumentList docs = rsp.getResults();\n    assertNotNull(docs);\n    assertEquals(docs.toString(), batchSize * NUM_BATCHES, docs.getNumFound());\n  }\n\n","sourceOld":"  @Test\n  public void testScaleUp() throws Exception {\n    String collectionName = \"testScaleUp_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(10);\n    create.process(solrClient);\n\n    CloudUtil.waitForState(cluster, collectionName, 90, TimeUnit.SECONDS,\n        CloudUtil.clusterShape(2, 2, false, true));\n\n    //long waitForSeconds = 3 + random().nextInt(5);\n    long waitForSeconds = 1;\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'scaleUpTrigger',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : \" + ABOVE_SIZE + \",\" +\n        \"'maxOps' : \" + MAX_OPS + \",\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    assertAutoscalingUpdateComplete();\n\n    long batchSize = BATCH_SIZE;\n    for (long i = 0; i < NUM_BATCHES; i++) {\n      addDocs(collectionName, i * batchSize, batchSize);\n      log.info(String.format(Locale.ROOT, \"#### Total docs so far: %,d\", ((i + 1) * batchSize)));\n      timeSource.sleep(waitForSeconds);\n    }\n    timeSource.sleep(60000);\n    QueryResponse rsp = solrClient.query(collectionName, params(CommonParams.Q, \"*:*\"));\n    SolrDocumentList docs = rsp.getResults();\n    assertNotNull(docs);\n    assertEquals(docs.toString(), batchSize * NUM_BATCHES, docs.getNumFound());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"aa2585c33d5d66a1c837c312221eb55ddb3c4300","date":1592493170,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimExtremeIndexing#testScaleUp().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimExtremeIndexing#testScaleUp().mjava","sourceNew":"  @Test\n  public void testScaleUp() throws Exception {\n    String collectionName = \"testScaleUp_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(10);\n    create.process(solrClient);\n\n    CloudUtil.waitForState(cluster, collectionName, 90, TimeUnit.SECONDS,\n        CloudUtil.clusterShape(2, 2, false, true));\n\n    //long waitForSeconds = 3 + random().nextInt(5);\n    long waitForSeconds = 1;\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'scaleUpTrigger',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : \" + ABOVE_SIZE + \",\" +\n        \"'maxOps' : \" + MAX_OPS + \",\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    @SuppressWarnings({\"rawtypes\"})\n    SolrRequest req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    assertAutoscalingUpdateComplete();\n\n    long batchSize = BATCH_SIZE;\n    for (long i = 0; i < NUM_BATCHES; i++) {\n      addDocs(collectionName, i * batchSize, batchSize);\n      if (log.isInfoEnabled()) {\n        log.info(String.format(Locale.ROOT, \"#### Total docs so far: %,d\", ((i + 1) * batchSize))); // logOk\n      }\n      timeSource.sleep(waitForSeconds);\n    }\n    timeSource.sleep(60000);\n    QueryResponse rsp = solrClient.query(collectionName, params(CommonParams.Q, \"*:*\"));\n    SolrDocumentList docs = rsp.getResults();\n    assertNotNull(docs);\n    assertEquals(docs.toString(), batchSize * NUM_BATCHES, docs.getNumFound());\n  }\n\n","sourceOld":"  @Test\n  public void testScaleUp() throws Exception {\n    String collectionName = \"testScaleUp_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(10);\n    create.process(solrClient);\n\n    CloudUtil.waitForState(cluster, collectionName, 90, TimeUnit.SECONDS,\n        CloudUtil.clusterShape(2, 2, false, true));\n\n    //long waitForSeconds = 3 + random().nextInt(5);\n    long waitForSeconds = 1;\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'scaleUpTrigger',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : \" + ABOVE_SIZE + \",\" +\n        \"'maxOps' : \" + MAX_OPS + \",\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    assertAutoscalingUpdateComplete();\n\n    long batchSize = BATCH_SIZE;\n    for (long i = 0; i < NUM_BATCHES; i++) {\n      addDocs(collectionName, i * batchSize, batchSize);\n      if (log.isInfoEnabled()) {\n        log.info(String.format(Locale.ROOT, \"#### Total docs so far: %,d\", ((i + 1) * batchSize))); // logOk\n      }\n      timeSource.sleep(waitForSeconds);\n    }\n    timeSource.sleep(60000);\n    QueryResponse rsp = solrClient.query(collectionName, params(CommonParams.Q, \"*:*\"));\n    SolrDocumentList docs = rsp.getResults();\n    assertNotNull(docs);\n    assertEquals(docs.toString(), batchSize * NUM_BATCHES, docs.getNumFound());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e46a76bb135597b8bf35930cfdb3702bdd1cbe6e","date":1594223844,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimExtremeIndexing#testScaleUp().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimExtremeIndexing#testScaleUp().mjava","sourceNew":"  @Test\n  public void testScaleUp() throws Exception {\n    String collectionName = \"testScaleUp_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2);\n    create.process(solrClient);\n\n    CloudUtil.waitForState(cluster, collectionName, 90, TimeUnit.SECONDS,\n        CloudUtil.clusterShape(2, 2, false, true));\n\n    //long waitForSeconds = 3 + random().nextInt(5);\n    long waitForSeconds = 1;\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'scaleUpTrigger',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : \" + ABOVE_SIZE + \",\" +\n        \"'maxOps' : \" + MAX_OPS + \",\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    @SuppressWarnings({\"rawtypes\"})\n    SolrRequest req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    assertAutoscalingUpdateComplete();\n\n    long batchSize = BATCH_SIZE;\n    for (long i = 0; i < NUM_BATCHES; i++) {\n      addDocs(collectionName, i * batchSize, batchSize);\n      if (log.isInfoEnabled()) {\n        log.info(String.format(Locale.ROOT, \"#### Total docs so far: %,d\", ((i + 1) * batchSize))); // logOk\n      }\n      timeSource.sleep(waitForSeconds);\n    }\n    timeSource.sleep(60000);\n    QueryResponse rsp = solrClient.query(collectionName, params(CommonParams.Q, \"*:*\"));\n    SolrDocumentList docs = rsp.getResults();\n    assertNotNull(docs);\n    assertEquals(docs.toString(), batchSize * NUM_BATCHES, docs.getNumFound());\n  }\n\n","sourceOld":"  @Test\n  public void testScaleUp() throws Exception {\n    String collectionName = \"testScaleUp_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(10);\n    create.process(solrClient);\n\n    CloudUtil.waitForState(cluster, collectionName, 90, TimeUnit.SECONDS,\n        CloudUtil.clusterShape(2, 2, false, true));\n\n    //long waitForSeconds = 3 + random().nextInt(5);\n    long waitForSeconds = 1;\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'scaleUpTrigger',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : \" + ABOVE_SIZE + \",\" +\n        \"'maxOps' : \" + MAX_OPS + \",\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    @SuppressWarnings({\"rawtypes\"})\n    SolrRequest req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    assertAutoscalingUpdateComplete();\n\n    long batchSize = BATCH_SIZE;\n    for (long i = 0; i < NUM_BATCHES; i++) {\n      addDocs(collectionName, i * batchSize, batchSize);\n      if (log.isInfoEnabled()) {\n        log.info(String.format(Locale.ROOT, \"#### Total docs so far: %,d\", ((i + 1) * batchSize))); // logOk\n      }\n      timeSource.sleep(waitForSeconds);\n    }\n    timeSource.sleep(60000);\n    QueryResponse rsp = solrClient.query(collectionName, params(CommonParams.Q, \"*:*\"));\n    SolrDocumentList docs = rsp.getResults();\n    assertNotNull(docs);\n    assertEquals(docs.toString(), batchSize * NUM_BATCHES, docs.getNumFound());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3f504512a03d978990cbff30db0522b354e846db","date":1595247421,"type":4,"author":"Ishan Chattopadhyaya","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimExtremeIndexing#testScaleUp().mjava","sourceNew":null,"sourceOld":"  @Test\n  public void testScaleUp() throws Exception {\n    String collectionName = \"testScaleUp_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2);\n    create.process(solrClient);\n\n    CloudUtil.waitForState(cluster, collectionName, 90, TimeUnit.SECONDS,\n        CloudUtil.clusterShape(2, 2, false, true));\n\n    //long waitForSeconds = 3 + random().nextInt(5);\n    long waitForSeconds = 1;\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'scaleUpTrigger',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : \" + ABOVE_SIZE + \",\" +\n        \"'maxOps' : \" + MAX_OPS + \",\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    @SuppressWarnings({\"rawtypes\"})\n    SolrRequest req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    assertAutoscalingUpdateComplete();\n\n    long batchSize = BATCH_SIZE;\n    for (long i = 0; i < NUM_BATCHES; i++) {\n      addDocs(collectionName, i * batchSize, batchSize);\n      if (log.isInfoEnabled()) {\n        log.info(String.format(Locale.ROOT, \"#### Total docs so far: %,d\", ((i + 1) * batchSize))); // logOk\n      }\n      timeSource.sleep(waitForSeconds);\n    }\n    timeSource.sleep(60000);\n    QueryResponse rsp = solrClient.query(collectionName, params(CommonParams.Q, \"*:*\"));\n    SolrDocumentList docs = rsp.getResults();\n    assertNotNull(docs);\n    assertEquals(docs.toString(), batchSize * NUM_BATCHES, docs.getNumFound());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"fc18bc8ea2e2c1e308757ff50671c774438e9f3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"aa2585c33d5d66a1c837c312221eb55ddb3c4300":["fe9f2c4a0d7ac164e4bdd4eee7f87131aec83fd4"],"3f504512a03d978990cbff30db0522b354e846db":["e46a76bb135597b8bf35930cfdb3702bdd1cbe6e"],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["ae70f2df00762dfce0455c0e39381848762662e5"],"fe9f2c4a0d7ac164e4bdd4eee7f87131aec83fd4":["9ef8d00dbfbeb534eba8a219a5df9d99b2de6ab5"],"ce85ed088dcf7aa1742105d4a8caa9aab3b491c1":["89948af0461fead48f44ba8fb7866f107ce83f22"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"9ef8d00dbfbeb534eba8a219a5df9d99b2de6ab5":["ce85ed088dcf7aa1742105d4a8caa9aab3b491c1"],"89948af0461fead48f44ba8fb7866f107ce83f22":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"e46a76bb135597b8bf35930cfdb3702bdd1cbe6e":["aa2585c33d5d66a1c837c312221eb55ddb3c4300"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3f504512a03d978990cbff30db0522b354e846db"],"ae70f2df00762dfce0455c0e39381848762662e5":["fc18bc8ea2e2c1e308757ff50671c774438e9f3e"]},"commit2Childs":{"fc18bc8ea2e2c1e308757ff50671c774438e9f3e":["ae70f2df00762dfce0455c0e39381848762662e5"],"aa2585c33d5d66a1c837c312221eb55ddb3c4300":["e46a76bb135597b8bf35930cfdb3702bdd1cbe6e"],"3f504512a03d978990cbff30db0522b354e846db":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["89948af0461fead48f44ba8fb7866f107ce83f22"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["fc18bc8ea2e2c1e308757ff50671c774438e9f3e"],"fe9f2c4a0d7ac164e4bdd4eee7f87131aec83fd4":["aa2585c33d5d66a1c837c312221eb55ddb3c4300"],"ce85ed088dcf7aa1742105d4a8caa9aab3b491c1":["9ef8d00dbfbeb534eba8a219a5df9d99b2de6ab5"],"9ef8d00dbfbeb534eba8a219a5df9d99b2de6ab5":["fe9f2c4a0d7ac164e4bdd4eee7f87131aec83fd4"],"89948af0461fead48f44ba8fb7866f107ce83f22":["ce85ed088dcf7aa1742105d4a8caa9aab3b491c1"],"e46a76bb135597b8bf35930cfdb3702bdd1cbe6e":["3f504512a03d978990cbff30db0522b354e846db"],"ae70f2df00762dfce0455c0e39381848762662e5":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}