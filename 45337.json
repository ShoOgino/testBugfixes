{"path":"solr/core/src/test/org/apache/solr/uninverting/TestUninvertingReader#testSortedSetIntegerManyValues().mjava","commits":[{"id":"a076c3c721f685b7559308fdc2cd72d91bba67e5","date":1464168992,"type":1,"author":"Mike McCandless","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/uninverting/TestUninvertingReader#testSortedSetIntegerManyValues().mjava","pathOld":"lucene/misc/src/test/org/apache/lucene/uninverting/TestUninvertingReader#testSortedSetIntegerManyValues().mjava","sourceNew":"  /** Tests {@link Type#SORTED_SET_INTEGER} using Integer based fields, with and w/o precision steps */\n  public void testSortedSetIntegerManyValues() throws IOException {\n    final Directory dir = newDirectory();\n    final IndexWriter iw = new IndexWriter(dir, newIndexWriterConfig(null));\n    \n    final FieldType NO_TRIE_TYPE = new FieldType(LegacyIntField.TYPE_NOT_STORED);\n    NO_TRIE_TYPE.setNumericPrecisionStep(Integer.MAX_VALUE);\n\n    final Map<String,Type> UNINVERT_MAP = new LinkedHashMap<String,Type>();\n    UNINVERT_MAP.put(\"notrie_single\", Type.SORTED_SET_INTEGER);\n    UNINVERT_MAP.put(\"notrie_multi\", Type.SORTED_SET_INTEGER);\n    UNINVERT_MAP.put(\"trie_single\", Type.SORTED_SET_INTEGER);\n    UNINVERT_MAP.put(\"trie_multi\", Type.SORTED_SET_INTEGER);\n    final Set<String> MULTI_VALUES = new LinkedHashSet<String>();\n    MULTI_VALUES.add(\"trie_multi\");\n    MULTI_VALUES.add(\"notrie_multi\");\n\n    \n    final int NUM_DOCS = TestUtil.nextInt(random(), 200, 1500);\n    final int MIN = TestUtil.nextInt(random(), 10, 100);\n    final int MAX = MIN + TestUtil.nextInt(random(), 10, 100);\n    final long EXPECTED_VALSET_SIZE = 1 + MAX - MIN;\n\n    { // (at least) one doc should have every value, so that at least one segment has every value\n      final Document doc = new Document();\n      for (int i = MIN; i <= MAX; i++) {\n        doc.add(new LegacyIntField(\"trie_multi\", i, Field.Store.NO));\n        doc.add(new LegacyIntField(\"notrie_multi\", i, NO_TRIE_TYPE));\n      }\n      iw.addDocument(doc);\n    }\n\n    // now add some more random docs (note: starting at i=1 because of previously added doc)\n    for (int i = 1; i < NUM_DOCS; i++) {\n      final Document doc = new Document();\n      if (0 != TestUtil.nextInt(random(), 0, 9)) {\n        int val = TestUtil.nextInt(random(), MIN, MAX);\n        doc.add(new LegacyIntField(\"trie_single\", val, Field.Store.NO));\n        doc.add(new LegacyIntField(\"notrie_single\", val, NO_TRIE_TYPE));\n      }\n      if (0 != TestUtil.nextInt(random(), 0, 9)) {\n        int numMulti = atLeast(1);\n        while (0 < numMulti--) {\n          int val = TestUtil.nextInt(random(), MIN, MAX);\n          doc.add(new LegacyIntField(\"trie_multi\", val, Field.Store.NO));\n          doc.add(new LegacyIntField(\"notrie_multi\", val, NO_TRIE_TYPE));\n        }\n      }\n      iw.addDocument(doc);\n    }\n\n    iw.close();\n    \n    final DirectoryReader ir = UninvertingReader.wrap(DirectoryReader.open(dir), UNINVERT_MAP);\n    TestUtil.checkReader(ir);\n    \n    final int NUM_LEAVES = ir.leaves().size();\n    \n    // check the leaves: no more then total set size\n    for (LeafReaderContext rc : ir.leaves()) {\n      final LeafReader ar = rc.reader();\n      for (String f : UNINVERT_MAP.keySet()) {\n        final SortedSetDocValues v = DocValues.getSortedSet(ar, f);\n        final long valSetSize = v.getValueCount();\n        assertTrue(f + \": Expected no more then \" + EXPECTED_VALSET_SIZE + \" values per segment, got \" +\n                   valSetSize + \" from: \" + ar.toString(),\n                   valSetSize <= EXPECTED_VALSET_SIZE);\n        \n        if (1 == NUM_LEAVES && MULTI_VALUES.contains(f)) {\n          // tighter check on multi fields in single segment index since we know one doc has all of them\n          assertEquals(f + \": Single segment LeafReader's value set should have had exactly expected size\",\n                       EXPECTED_VALSET_SIZE, valSetSize);\n        }\n      }\n    }\n\n    // check the composite of all leaves: exact expectation of set size\n    final LeafReader composite = SlowCompositeReaderWrapper.wrap(ir);\n    TestUtil.checkReader(composite);\n    \n    for (String f : MULTI_VALUES) {\n      final SortedSetDocValues v = composite.getSortedSetDocValues(f);\n      final long valSetSize = v.getValueCount();\n      assertEquals(f + \": Composite reader value set should have had exactly expected size\",\n                   EXPECTED_VALSET_SIZE, valSetSize);\n    }\n    \n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  /** Tests {@link Type#SORTED_SET_INTEGER} using Integer based fields, with and w/o precision steps */\n  public void testSortedSetIntegerManyValues() throws IOException {\n    final Directory dir = newDirectory();\n    final IndexWriter iw = new IndexWriter(dir, newIndexWriterConfig(null));\n    \n    final FieldType NO_TRIE_TYPE = new FieldType(LegacyIntField.TYPE_NOT_STORED);\n    NO_TRIE_TYPE.setNumericPrecisionStep(Integer.MAX_VALUE);\n\n    final Map<String,Type> UNINVERT_MAP = new LinkedHashMap<String,Type>();\n    UNINVERT_MAP.put(\"notrie_single\", Type.SORTED_SET_INTEGER);\n    UNINVERT_MAP.put(\"notrie_multi\", Type.SORTED_SET_INTEGER);\n    UNINVERT_MAP.put(\"trie_single\", Type.SORTED_SET_INTEGER);\n    UNINVERT_MAP.put(\"trie_multi\", Type.SORTED_SET_INTEGER);\n    final Set<String> MULTI_VALUES = new LinkedHashSet<String>();\n    MULTI_VALUES.add(\"trie_multi\");\n    MULTI_VALUES.add(\"notrie_multi\");\n\n    \n    final int NUM_DOCS = TestUtil.nextInt(random(), 200, 1500);\n    final int MIN = TestUtil.nextInt(random(), 10, 100);\n    final int MAX = MIN + TestUtil.nextInt(random(), 10, 100);\n    final long EXPECTED_VALSET_SIZE = 1 + MAX - MIN;\n\n    { // (at least) one doc should have every value, so that at least one segment has every value\n      final Document doc = new Document();\n      for (int i = MIN; i <= MAX; i++) {\n        doc.add(new LegacyIntField(\"trie_multi\", i, Field.Store.NO));\n        doc.add(new LegacyIntField(\"notrie_multi\", i, NO_TRIE_TYPE));\n      }\n      iw.addDocument(doc);\n    }\n\n    // now add some more random docs (note: starting at i=1 because of previously added doc)\n    for (int i = 1; i < NUM_DOCS; i++) {\n      final Document doc = new Document();\n      if (0 != TestUtil.nextInt(random(), 0, 9)) {\n        int val = TestUtil.nextInt(random(), MIN, MAX);\n        doc.add(new LegacyIntField(\"trie_single\", val, Field.Store.NO));\n        doc.add(new LegacyIntField(\"notrie_single\", val, NO_TRIE_TYPE));\n      }\n      if (0 != TestUtil.nextInt(random(), 0, 9)) {\n        int numMulti = atLeast(1);\n        while (0 < numMulti--) {\n          int val = TestUtil.nextInt(random(), MIN, MAX);\n          doc.add(new LegacyIntField(\"trie_multi\", val, Field.Store.NO));\n          doc.add(new LegacyIntField(\"notrie_multi\", val, NO_TRIE_TYPE));\n        }\n      }\n      iw.addDocument(doc);\n    }\n\n    iw.close();\n    \n    final DirectoryReader ir = UninvertingReader.wrap(DirectoryReader.open(dir), UNINVERT_MAP);\n    TestUtil.checkReader(ir);\n    \n    final int NUM_LEAVES = ir.leaves().size();\n    \n    // check the leaves: no more then total set size\n    for (LeafReaderContext rc : ir.leaves()) {\n      final LeafReader ar = rc.reader();\n      for (String f : UNINVERT_MAP.keySet()) {\n        final SortedSetDocValues v = DocValues.getSortedSet(ar, f);\n        final long valSetSize = v.getValueCount();\n        assertTrue(f + \": Expected no more then \" + EXPECTED_VALSET_SIZE + \" values per segment, got \" +\n                   valSetSize + \" from: \" + ar.toString(),\n                   valSetSize <= EXPECTED_VALSET_SIZE);\n        \n        if (1 == NUM_LEAVES && MULTI_VALUES.contains(f)) {\n          // tighter check on multi fields in single segment index since we know one doc has all of them\n          assertEquals(f + \": Single segment LeafReader's value set should have had exactly expected size\",\n                       EXPECTED_VALSET_SIZE, valSetSize);\n        }\n      }\n    }\n\n    // check the composite of all leaves: exact expectation of set size\n    final LeafReader composite = SlowCompositeReaderWrapper.wrap(ir);\n    TestUtil.checkReader(composite);\n    \n    for (String f : MULTI_VALUES) {\n      final SortedSetDocValues v = composite.getSortedSetDocValues(f);\n      final long valSetSize = v.getValueCount();\n      assertEquals(f + \": Composite reader value set should have had exactly expected size\",\n                   EXPECTED_VALSET_SIZE, valSetSize);\n    }\n    \n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0e121d43b5a10f2df530f406f935102656e9c4e8","date":1464198131,"type":1,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/uninverting/TestUninvertingReader#testSortedSetIntegerManyValues().mjava","pathOld":"lucene/misc/src/test/org/apache/lucene/uninverting/TestUninvertingReader#testSortedSetIntegerManyValues().mjava","sourceNew":"  /** Tests {@link Type#SORTED_SET_INTEGER} using Integer based fields, with and w/o precision steps */\n  public void testSortedSetIntegerManyValues() throws IOException {\n    final Directory dir = newDirectory();\n    final IndexWriter iw = new IndexWriter(dir, newIndexWriterConfig(null));\n    \n    final FieldType NO_TRIE_TYPE = new FieldType(LegacyIntField.TYPE_NOT_STORED);\n    NO_TRIE_TYPE.setNumericPrecisionStep(Integer.MAX_VALUE);\n\n    final Map<String,Type> UNINVERT_MAP = new LinkedHashMap<String,Type>();\n    UNINVERT_MAP.put(\"notrie_single\", Type.SORTED_SET_INTEGER);\n    UNINVERT_MAP.put(\"notrie_multi\", Type.SORTED_SET_INTEGER);\n    UNINVERT_MAP.put(\"trie_single\", Type.SORTED_SET_INTEGER);\n    UNINVERT_MAP.put(\"trie_multi\", Type.SORTED_SET_INTEGER);\n    final Set<String> MULTI_VALUES = new LinkedHashSet<String>();\n    MULTI_VALUES.add(\"trie_multi\");\n    MULTI_VALUES.add(\"notrie_multi\");\n\n    \n    final int NUM_DOCS = TestUtil.nextInt(random(), 200, 1500);\n    final int MIN = TestUtil.nextInt(random(), 10, 100);\n    final int MAX = MIN + TestUtil.nextInt(random(), 10, 100);\n    final long EXPECTED_VALSET_SIZE = 1 + MAX - MIN;\n\n    { // (at least) one doc should have every value, so that at least one segment has every value\n      final Document doc = new Document();\n      for (int i = MIN; i <= MAX; i++) {\n        doc.add(new LegacyIntField(\"trie_multi\", i, Field.Store.NO));\n        doc.add(new LegacyIntField(\"notrie_multi\", i, NO_TRIE_TYPE));\n      }\n      iw.addDocument(doc);\n    }\n\n    // now add some more random docs (note: starting at i=1 because of previously added doc)\n    for (int i = 1; i < NUM_DOCS; i++) {\n      final Document doc = new Document();\n      if (0 != TestUtil.nextInt(random(), 0, 9)) {\n        int val = TestUtil.nextInt(random(), MIN, MAX);\n        doc.add(new LegacyIntField(\"trie_single\", val, Field.Store.NO));\n        doc.add(new LegacyIntField(\"notrie_single\", val, NO_TRIE_TYPE));\n      }\n      if (0 != TestUtil.nextInt(random(), 0, 9)) {\n        int numMulti = atLeast(1);\n        while (0 < numMulti--) {\n          int val = TestUtil.nextInt(random(), MIN, MAX);\n          doc.add(new LegacyIntField(\"trie_multi\", val, Field.Store.NO));\n          doc.add(new LegacyIntField(\"notrie_multi\", val, NO_TRIE_TYPE));\n        }\n      }\n      iw.addDocument(doc);\n    }\n\n    iw.close();\n    \n    final DirectoryReader ir = UninvertingReader.wrap(DirectoryReader.open(dir), UNINVERT_MAP);\n    TestUtil.checkReader(ir);\n    \n    final int NUM_LEAVES = ir.leaves().size();\n    \n    // check the leaves: no more then total set size\n    for (LeafReaderContext rc : ir.leaves()) {\n      final LeafReader ar = rc.reader();\n      for (String f : UNINVERT_MAP.keySet()) {\n        final SortedSetDocValues v = DocValues.getSortedSet(ar, f);\n        final long valSetSize = v.getValueCount();\n        assertTrue(f + \": Expected no more then \" + EXPECTED_VALSET_SIZE + \" values per segment, got \" +\n                   valSetSize + \" from: \" + ar.toString(),\n                   valSetSize <= EXPECTED_VALSET_SIZE);\n        \n        if (1 == NUM_LEAVES && MULTI_VALUES.contains(f)) {\n          // tighter check on multi fields in single segment index since we know one doc has all of them\n          assertEquals(f + \": Single segment LeafReader's value set should have had exactly expected size\",\n                       EXPECTED_VALSET_SIZE, valSetSize);\n        }\n      }\n    }\n\n    // check the composite of all leaves: exact expectation of set size\n    final LeafReader composite = SlowCompositeReaderWrapper.wrap(ir);\n    TestUtil.checkReader(composite);\n    \n    for (String f : MULTI_VALUES) {\n      final SortedSetDocValues v = composite.getSortedSetDocValues(f);\n      final long valSetSize = v.getValueCount();\n      assertEquals(f + \": Composite reader value set should have had exactly expected size\",\n                   EXPECTED_VALSET_SIZE, valSetSize);\n    }\n    \n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  /** Tests {@link Type#SORTED_SET_INTEGER} using Integer based fields, with and w/o precision steps */\n  public void testSortedSetIntegerManyValues() throws IOException {\n    final Directory dir = newDirectory();\n    final IndexWriter iw = new IndexWriter(dir, newIndexWriterConfig(null));\n    \n    final FieldType NO_TRIE_TYPE = new FieldType(LegacyIntField.TYPE_NOT_STORED);\n    NO_TRIE_TYPE.setNumericPrecisionStep(Integer.MAX_VALUE);\n\n    final Map<String,Type> UNINVERT_MAP = new LinkedHashMap<String,Type>();\n    UNINVERT_MAP.put(\"notrie_single\", Type.SORTED_SET_INTEGER);\n    UNINVERT_MAP.put(\"notrie_multi\", Type.SORTED_SET_INTEGER);\n    UNINVERT_MAP.put(\"trie_single\", Type.SORTED_SET_INTEGER);\n    UNINVERT_MAP.put(\"trie_multi\", Type.SORTED_SET_INTEGER);\n    final Set<String> MULTI_VALUES = new LinkedHashSet<String>();\n    MULTI_VALUES.add(\"trie_multi\");\n    MULTI_VALUES.add(\"notrie_multi\");\n\n    \n    final int NUM_DOCS = TestUtil.nextInt(random(), 200, 1500);\n    final int MIN = TestUtil.nextInt(random(), 10, 100);\n    final int MAX = MIN + TestUtil.nextInt(random(), 10, 100);\n    final long EXPECTED_VALSET_SIZE = 1 + MAX - MIN;\n\n    { // (at least) one doc should have every value, so that at least one segment has every value\n      final Document doc = new Document();\n      for (int i = MIN; i <= MAX; i++) {\n        doc.add(new LegacyIntField(\"trie_multi\", i, Field.Store.NO));\n        doc.add(new LegacyIntField(\"notrie_multi\", i, NO_TRIE_TYPE));\n      }\n      iw.addDocument(doc);\n    }\n\n    // now add some more random docs (note: starting at i=1 because of previously added doc)\n    for (int i = 1; i < NUM_DOCS; i++) {\n      final Document doc = new Document();\n      if (0 != TestUtil.nextInt(random(), 0, 9)) {\n        int val = TestUtil.nextInt(random(), MIN, MAX);\n        doc.add(new LegacyIntField(\"trie_single\", val, Field.Store.NO));\n        doc.add(new LegacyIntField(\"notrie_single\", val, NO_TRIE_TYPE));\n      }\n      if (0 != TestUtil.nextInt(random(), 0, 9)) {\n        int numMulti = atLeast(1);\n        while (0 < numMulti--) {\n          int val = TestUtil.nextInt(random(), MIN, MAX);\n          doc.add(new LegacyIntField(\"trie_multi\", val, Field.Store.NO));\n          doc.add(new LegacyIntField(\"notrie_multi\", val, NO_TRIE_TYPE));\n        }\n      }\n      iw.addDocument(doc);\n    }\n\n    iw.close();\n    \n    final DirectoryReader ir = UninvertingReader.wrap(DirectoryReader.open(dir), UNINVERT_MAP);\n    TestUtil.checkReader(ir);\n    \n    final int NUM_LEAVES = ir.leaves().size();\n    \n    // check the leaves: no more then total set size\n    for (LeafReaderContext rc : ir.leaves()) {\n      final LeafReader ar = rc.reader();\n      for (String f : UNINVERT_MAP.keySet()) {\n        final SortedSetDocValues v = DocValues.getSortedSet(ar, f);\n        final long valSetSize = v.getValueCount();\n        assertTrue(f + \": Expected no more then \" + EXPECTED_VALSET_SIZE + \" values per segment, got \" +\n                   valSetSize + \" from: \" + ar.toString(),\n                   valSetSize <= EXPECTED_VALSET_SIZE);\n        \n        if (1 == NUM_LEAVES && MULTI_VALUES.contains(f)) {\n          // tighter check on multi fields in single segment index since we know one doc has all of them\n          assertEquals(f + \": Single segment LeafReader's value set should have had exactly expected size\",\n                       EXPECTED_VALSET_SIZE, valSetSize);\n        }\n      }\n    }\n\n    // check the composite of all leaves: exact expectation of set size\n    final LeafReader composite = SlowCompositeReaderWrapper.wrap(ir);\n    TestUtil.checkReader(composite);\n    \n    for (String f : MULTI_VALUES) {\n      final SortedSetDocValues v = composite.getSortedSetDocValues(f);\n      final long valSetSize = v.getValueCount();\n      assertEquals(f + \": Composite reader value set should have had exactly expected size\",\n                   EXPECTED_VALSET_SIZE, valSetSize);\n    }\n    \n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"83870855d82aba6819217abeff5a40779dbb28b4","date":1464291012,"type":1,"author":"Mike McCandless","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/uninverting/TestUninvertingReader#testSortedSetIntegerManyValues().mjava","pathOld":"lucene/misc/src/test/org/apache/lucene/uninverting/TestUninvertingReader#testSortedSetIntegerManyValues().mjava","sourceNew":"  /** Tests {@link Type#SORTED_SET_INTEGER} using Integer based fields, with and w/o precision steps */\n  public void testSortedSetIntegerManyValues() throws IOException {\n    final Directory dir = newDirectory();\n    final IndexWriter iw = new IndexWriter(dir, newIndexWriterConfig(null));\n    \n    final FieldType NO_TRIE_TYPE = new FieldType(LegacyIntField.TYPE_NOT_STORED);\n    NO_TRIE_TYPE.setNumericPrecisionStep(Integer.MAX_VALUE);\n\n    final Map<String,Type> UNINVERT_MAP = new LinkedHashMap<String,Type>();\n    UNINVERT_MAP.put(\"notrie_single\", Type.SORTED_SET_INTEGER);\n    UNINVERT_MAP.put(\"notrie_multi\", Type.SORTED_SET_INTEGER);\n    UNINVERT_MAP.put(\"trie_single\", Type.SORTED_SET_INTEGER);\n    UNINVERT_MAP.put(\"trie_multi\", Type.SORTED_SET_INTEGER);\n    final Set<String> MULTI_VALUES = new LinkedHashSet<String>();\n    MULTI_VALUES.add(\"trie_multi\");\n    MULTI_VALUES.add(\"notrie_multi\");\n\n    \n    final int NUM_DOCS = TestUtil.nextInt(random(), 200, 1500);\n    final int MIN = TestUtil.nextInt(random(), 10, 100);\n    final int MAX = MIN + TestUtil.nextInt(random(), 10, 100);\n    final long EXPECTED_VALSET_SIZE = 1 + MAX - MIN;\n\n    { // (at least) one doc should have every value, so that at least one segment has every value\n      final Document doc = new Document();\n      for (int i = MIN; i <= MAX; i++) {\n        doc.add(new LegacyIntField(\"trie_multi\", i, Field.Store.NO));\n        doc.add(new LegacyIntField(\"notrie_multi\", i, NO_TRIE_TYPE));\n      }\n      iw.addDocument(doc);\n    }\n\n    // now add some more random docs (note: starting at i=1 because of previously added doc)\n    for (int i = 1; i < NUM_DOCS; i++) {\n      final Document doc = new Document();\n      if (0 != TestUtil.nextInt(random(), 0, 9)) {\n        int val = TestUtil.nextInt(random(), MIN, MAX);\n        doc.add(new LegacyIntField(\"trie_single\", val, Field.Store.NO));\n        doc.add(new LegacyIntField(\"notrie_single\", val, NO_TRIE_TYPE));\n      }\n      if (0 != TestUtil.nextInt(random(), 0, 9)) {\n        int numMulti = atLeast(1);\n        while (0 < numMulti--) {\n          int val = TestUtil.nextInt(random(), MIN, MAX);\n          doc.add(new LegacyIntField(\"trie_multi\", val, Field.Store.NO));\n          doc.add(new LegacyIntField(\"notrie_multi\", val, NO_TRIE_TYPE));\n        }\n      }\n      iw.addDocument(doc);\n    }\n\n    iw.close();\n    \n    final DirectoryReader ir = UninvertingReader.wrap(DirectoryReader.open(dir), UNINVERT_MAP);\n    TestUtil.checkReader(ir);\n    \n    final int NUM_LEAVES = ir.leaves().size();\n    \n    // check the leaves: no more then total set size\n    for (LeafReaderContext rc : ir.leaves()) {\n      final LeafReader ar = rc.reader();\n      for (String f : UNINVERT_MAP.keySet()) {\n        final SortedSetDocValues v = DocValues.getSortedSet(ar, f);\n        final long valSetSize = v.getValueCount();\n        assertTrue(f + \": Expected no more then \" + EXPECTED_VALSET_SIZE + \" values per segment, got \" +\n                   valSetSize + \" from: \" + ar.toString(),\n                   valSetSize <= EXPECTED_VALSET_SIZE);\n        \n        if (1 == NUM_LEAVES && MULTI_VALUES.contains(f)) {\n          // tighter check on multi fields in single segment index since we know one doc has all of them\n          assertEquals(f + \": Single segment LeafReader's value set should have had exactly expected size\",\n                       EXPECTED_VALSET_SIZE, valSetSize);\n        }\n      }\n    }\n\n    // check the composite of all leaves: exact expectation of set size\n    final LeafReader composite = SlowCompositeReaderWrapper.wrap(ir);\n    TestUtil.checkReader(composite);\n    \n    for (String f : MULTI_VALUES) {\n      final SortedSetDocValues v = composite.getSortedSetDocValues(f);\n      final long valSetSize = v.getValueCount();\n      assertEquals(f + \": Composite reader value set should have had exactly expected size\",\n                   EXPECTED_VALSET_SIZE, valSetSize);\n    }\n    \n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  /** Tests {@link Type#SORTED_SET_INTEGER} using Integer based fields, with and w/o precision steps */\n  public void testSortedSetIntegerManyValues() throws IOException {\n    final Directory dir = newDirectory();\n    final IndexWriter iw = new IndexWriter(dir, newIndexWriterConfig(null));\n    \n    final FieldType NO_TRIE_TYPE = new FieldType(LegacyIntField.TYPE_NOT_STORED);\n    NO_TRIE_TYPE.setNumericPrecisionStep(Integer.MAX_VALUE);\n\n    final Map<String,Type> UNINVERT_MAP = new LinkedHashMap<String,Type>();\n    UNINVERT_MAP.put(\"notrie_single\", Type.SORTED_SET_INTEGER);\n    UNINVERT_MAP.put(\"notrie_multi\", Type.SORTED_SET_INTEGER);\n    UNINVERT_MAP.put(\"trie_single\", Type.SORTED_SET_INTEGER);\n    UNINVERT_MAP.put(\"trie_multi\", Type.SORTED_SET_INTEGER);\n    final Set<String> MULTI_VALUES = new LinkedHashSet<String>();\n    MULTI_VALUES.add(\"trie_multi\");\n    MULTI_VALUES.add(\"notrie_multi\");\n\n    \n    final int NUM_DOCS = TestUtil.nextInt(random(), 200, 1500);\n    final int MIN = TestUtil.nextInt(random(), 10, 100);\n    final int MAX = MIN + TestUtil.nextInt(random(), 10, 100);\n    final long EXPECTED_VALSET_SIZE = 1 + MAX - MIN;\n\n    { // (at least) one doc should have every value, so that at least one segment has every value\n      final Document doc = new Document();\n      for (int i = MIN; i <= MAX; i++) {\n        doc.add(new LegacyIntField(\"trie_multi\", i, Field.Store.NO));\n        doc.add(new LegacyIntField(\"notrie_multi\", i, NO_TRIE_TYPE));\n      }\n      iw.addDocument(doc);\n    }\n\n    // now add some more random docs (note: starting at i=1 because of previously added doc)\n    for (int i = 1; i < NUM_DOCS; i++) {\n      final Document doc = new Document();\n      if (0 != TestUtil.nextInt(random(), 0, 9)) {\n        int val = TestUtil.nextInt(random(), MIN, MAX);\n        doc.add(new LegacyIntField(\"trie_single\", val, Field.Store.NO));\n        doc.add(new LegacyIntField(\"notrie_single\", val, NO_TRIE_TYPE));\n      }\n      if (0 != TestUtil.nextInt(random(), 0, 9)) {\n        int numMulti = atLeast(1);\n        while (0 < numMulti--) {\n          int val = TestUtil.nextInt(random(), MIN, MAX);\n          doc.add(new LegacyIntField(\"trie_multi\", val, Field.Store.NO));\n          doc.add(new LegacyIntField(\"notrie_multi\", val, NO_TRIE_TYPE));\n        }\n      }\n      iw.addDocument(doc);\n    }\n\n    iw.close();\n    \n    final DirectoryReader ir = UninvertingReader.wrap(DirectoryReader.open(dir), UNINVERT_MAP);\n    TestUtil.checkReader(ir);\n    \n    final int NUM_LEAVES = ir.leaves().size();\n    \n    // check the leaves: no more then total set size\n    for (LeafReaderContext rc : ir.leaves()) {\n      final LeafReader ar = rc.reader();\n      for (String f : UNINVERT_MAP.keySet()) {\n        final SortedSetDocValues v = DocValues.getSortedSet(ar, f);\n        final long valSetSize = v.getValueCount();\n        assertTrue(f + \": Expected no more then \" + EXPECTED_VALSET_SIZE + \" values per segment, got \" +\n                   valSetSize + \" from: \" + ar.toString(),\n                   valSetSize <= EXPECTED_VALSET_SIZE);\n        \n        if (1 == NUM_LEAVES && MULTI_VALUES.contains(f)) {\n          // tighter check on multi fields in single segment index since we know one doc has all of them\n          assertEquals(f + \": Single segment LeafReader's value set should have had exactly expected size\",\n                       EXPECTED_VALSET_SIZE, valSetSize);\n        }\n      }\n    }\n\n    // check the composite of all leaves: exact expectation of set size\n    final LeafReader composite = SlowCompositeReaderWrapper.wrap(ir);\n    TestUtil.checkReader(composite);\n    \n    for (String f : MULTI_VALUES) {\n      final SortedSetDocValues v = composite.getSortedSetDocValues(f);\n      final long valSetSize = v.getValueCount();\n      assertEquals(f + \": Composite reader value set should have had exactly expected size\",\n                   EXPECTED_VALSET_SIZE, valSetSize);\n    }\n    \n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5af5ba0166322092193d4c29880b0f7670fc7ca0","date":1471440525,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/uninverting/TestUninvertingReader#testSortedSetIntegerManyValues().mjava","pathOld":"solr/core/src/test/org/apache/solr/uninverting/TestUninvertingReader#testSortedSetIntegerManyValues().mjava","sourceNew":"  /** Tests {@link Type#SORTED_SET_INTEGER} using Integer based fields, with and w/o precision steps */\n  public void testSortedSetIntegerManyValues() throws IOException {\n    final Directory dir = newDirectory();\n    final IndexWriter iw = new IndexWriter(dir, newIndexWriterConfig(null));\n    \n    final LegacyFieldType NO_TRIE_TYPE = new LegacyFieldType(LegacyIntField.TYPE_NOT_STORED);\n    NO_TRIE_TYPE.setNumericPrecisionStep(Integer.MAX_VALUE);\n\n    final Map<String,Type> UNINVERT_MAP = new LinkedHashMap<String,Type>();\n    UNINVERT_MAP.put(\"notrie_single\", Type.SORTED_SET_INTEGER);\n    UNINVERT_MAP.put(\"notrie_multi\", Type.SORTED_SET_INTEGER);\n    UNINVERT_MAP.put(\"trie_single\", Type.SORTED_SET_INTEGER);\n    UNINVERT_MAP.put(\"trie_multi\", Type.SORTED_SET_INTEGER);\n    final Set<String> MULTI_VALUES = new LinkedHashSet<String>();\n    MULTI_VALUES.add(\"trie_multi\");\n    MULTI_VALUES.add(\"notrie_multi\");\n\n    \n    final int NUM_DOCS = TestUtil.nextInt(random(), 200, 1500);\n    final int MIN = TestUtil.nextInt(random(), 10, 100);\n    final int MAX = MIN + TestUtil.nextInt(random(), 10, 100);\n    final long EXPECTED_VALSET_SIZE = 1 + MAX - MIN;\n\n    { // (at least) one doc should have every value, so that at least one segment has every value\n      final Document doc = new Document();\n      for (int i = MIN; i <= MAX; i++) {\n        doc.add(new LegacyIntField(\"trie_multi\", i, Field.Store.NO));\n        doc.add(new LegacyIntField(\"notrie_multi\", i, NO_TRIE_TYPE));\n      }\n      iw.addDocument(doc);\n    }\n\n    // now add some more random docs (note: starting at i=1 because of previously added doc)\n    for (int i = 1; i < NUM_DOCS; i++) {\n      final Document doc = new Document();\n      if (0 != TestUtil.nextInt(random(), 0, 9)) {\n        int val = TestUtil.nextInt(random(), MIN, MAX);\n        doc.add(new LegacyIntField(\"trie_single\", val, Field.Store.NO));\n        doc.add(new LegacyIntField(\"notrie_single\", val, NO_TRIE_TYPE));\n      }\n      if (0 != TestUtil.nextInt(random(), 0, 9)) {\n        int numMulti = atLeast(1);\n        while (0 < numMulti--) {\n          int val = TestUtil.nextInt(random(), MIN, MAX);\n          doc.add(new LegacyIntField(\"trie_multi\", val, Field.Store.NO));\n          doc.add(new LegacyIntField(\"notrie_multi\", val, NO_TRIE_TYPE));\n        }\n      }\n      iw.addDocument(doc);\n    }\n\n    iw.close();\n    \n    final DirectoryReader ir = UninvertingReader.wrap(DirectoryReader.open(dir), UNINVERT_MAP);\n    TestUtil.checkReader(ir);\n    \n    final int NUM_LEAVES = ir.leaves().size();\n    \n    // check the leaves: no more then total set size\n    for (LeafReaderContext rc : ir.leaves()) {\n      final LeafReader ar = rc.reader();\n      for (String f : UNINVERT_MAP.keySet()) {\n        final SortedSetDocValues v = DocValues.getSortedSet(ar, f);\n        final long valSetSize = v.getValueCount();\n        assertTrue(f + \": Expected no more then \" + EXPECTED_VALSET_SIZE + \" values per segment, got \" +\n                   valSetSize + \" from: \" + ar.toString(),\n                   valSetSize <= EXPECTED_VALSET_SIZE);\n        \n        if (1 == NUM_LEAVES && MULTI_VALUES.contains(f)) {\n          // tighter check on multi fields in single segment index since we know one doc has all of them\n          assertEquals(f + \": Single segment LeafReader's value set should have had exactly expected size\",\n                       EXPECTED_VALSET_SIZE, valSetSize);\n        }\n      }\n    }\n\n    // check the composite of all leaves: exact expectation of set size\n    final LeafReader composite = SlowCompositeReaderWrapper.wrap(ir);\n    TestUtil.checkReader(composite);\n    \n    for (String f : MULTI_VALUES) {\n      final SortedSetDocValues v = composite.getSortedSetDocValues(f);\n      final long valSetSize = v.getValueCount();\n      assertEquals(f + \": Composite reader value set should have had exactly expected size\",\n                   EXPECTED_VALSET_SIZE, valSetSize);\n    }\n    \n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  /** Tests {@link Type#SORTED_SET_INTEGER} using Integer based fields, with and w/o precision steps */\n  public void testSortedSetIntegerManyValues() throws IOException {\n    final Directory dir = newDirectory();\n    final IndexWriter iw = new IndexWriter(dir, newIndexWriterConfig(null));\n    \n    final FieldType NO_TRIE_TYPE = new FieldType(LegacyIntField.TYPE_NOT_STORED);\n    NO_TRIE_TYPE.setNumericPrecisionStep(Integer.MAX_VALUE);\n\n    final Map<String,Type> UNINVERT_MAP = new LinkedHashMap<String,Type>();\n    UNINVERT_MAP.put(\"notrie_single\", Type.SORTED_SET_INTEGER);\n    UNINVERT_MAP.put(\"notrie_multi\", Type.SORTED_SET_INTEGER);\n    UNINVERT_MAP.put(\"trie_single\", Type.SORTED_SET_INTEGER);\n    UNINVERT_MAP.put(\"trie_multi\", Type.SORTED_SET_INTEGER);\n    final Set<String> MULTI_VALUES = new LinkedHashSet<String>();\n    MULTI_VALUES.add(\"trie_multi\");\n    MULTI_VALUES.add(\"notrie_multi\");\n\n    \n    final int NUM_DOCS = TestUtil.nextInt(random(), 200, 1500);\n    final int MIN = TestUtil.nextInt(random(), 10, 100);\n    final int MAX = MIN + TestUtil.nextInt(random(), 10, 100);\n    final long EXPECTED_VALSET_SIZE = 1 + MAX - MIN;\n\n    { // (at least) one doc should have every value, so that at least one segment has every value\n      final Document doc = new Document();\n      for (int i = MIN; i <= MAX; i++) {\n        doc.add(new LegacyIntField(\"trie_multi\", i, Field.Store.NO));\n        doc.add(new LegacyIntField(\"notrie_multi\", i, NO_TRIE_TYPE));\n      }\n      iw.addDocument(doc);\n    }\n\n    // now add some more random docs (note: starting at i=1 because of previously added doc)\n    for (int i = 1; i < NUM_DOCS; i++) {\n      final Document doc = new Document();\n      if (0 != TestUtil.nextInt(random(), 0, 9)) {\n        int val = TestUtil.nextInt(random(), MIN, MAX);\n        doc.add(new LegacyIntField(\"trie_single\", val, Field.Store.NO));\n        doc.add(new LegacyIntField(\"notrie_single\", val, NO_TRIE_TYPE));\n      }\n      if (0 != TestUtil.nextInt(random(), 0, 9)) {\n        int numMulti = atLeast(1);\n        while (0 < numMulti--) {\n          int val = TestUtil.nextInt(random(), MIN, MAX);\n          doc.add(new LegacyIntField(\"trie_multi\", val, Field.Store.NO));\n          doc.add(new LegacyIntField(\"notrie_multi\", val, NO_TRIE_TYPE));\n        }\n      }\n      iw.addDocument(doc);\n    }\n\n    iw.close();\n    \n    final DirectoryReader ir = UninvertingReader.wrap(DirectoryReader.open(dir), UNINVERT_MAP);\n    TestUtil.checkReader(ir);\n    \n    final int NUM_LEAVES = ir.leaves().size();\n    \n    // check the leaves: no more then total set size\n    for (LeafReaderContext rc : ir.leaves()) {\n      final LeafReader ar = rc.reader();\n      for (String f : UNINVERT_MAP.keySet()) {\n        final SortedSetDocValues v = DocValues.getSortedSet(ar, f);\n        final long valSetSize = v.getValueCount();\n        assertTrue(f + \": Expected no more then \" + EXPECTED_VALSET_SIZE + \" values per segment, got \" +\n                   valSetSize + \" from: \" + ar.toString(),\n                   valSetSize <= EXPECTED_VALSET_SIZE);\n        \n        if (1 == NUM_LEAVES && MULTI_VALUES.contains(f)) {\n          // tighter check on multi fields in single segment index since we know one doc has all of them\n          assertEquals(f + \": Single segment LeafReader's value set should have had exactly expected size\",\n                       EXPECTED_VALSET_SIZE, valSetSize);\n        }\n      }\n    }\n\n    // check the composite of all leaves: exact expectation of set size\n    final LeafReader composite = SlowCompositeReaderWrapper.wrap(ir);\n    TestUtil.checkReader(composite);\n    \n    for (String f : MULTI_VALUES) {\n      final SortedSetDocValues v = composite.getSortedSetDocValues(f);\n      final long valSetSize = v.getValueCount();\n      assertEquals(f + \": Composite reader value set should have had exactly expected size\",\n                   EXPECTED_VALSET_SIZE, valSetSize);\n    }\n    \n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2c8bedceb91e64a3f0e831450058fc4a76d2c0a6","date":1471496851,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/uninverting/TestUninvertingReader#testSortedSetIntegerManyValues().mjava","pathOld":"solr/core/src/test/org/apache/solr/uninverting/TestUninvertingReader#testSortedSetIntegerManyValues().mjava","sourceNew":"  /** Tests {@link Type#SORTED_SET_INTEGER} using Integer based fields, with and w/o precision steps */\n  public void testSortedSetIntegerManyValues() throws IOException {\n    final Directory dir = newDirectory();\n    final IndexWriter iw = new IndexWriter(dir, newIndexWriterConfig(null));\n    \n    final LegacyFieldType NO_TRIE_TYPE = new LegacyFieldType(LegacyIntField.TYPE_NOT_STORED);\n    NO_TRIE_TYPE.setNumericPrecisionStep(Integer.MAX_VALUE);\n\n    final Map<String,Type> UNINVERT_MAP = new LinkedHashMap<String,Type>();\n    UNINVERT_MAP.put(\"notrie_single\", Type.SORTED_SET_INTEGER);\n    UNINVERT_MAP.put(\"notrie_multi\", Type.SORTED_SET_INTEGER);\n    UNINVERT_MAP.put(\"trie_single\", Type.SORTED_SET_INTEGER);\n    UNINVERT_MAP.put(\"trie_multi\", Type.SORTED_SET_INTEGER);\n    final Set<String> MULTI_VALUES = new LinkedHashSet<String>();\n    MULTI_VALUES.add(\"trie_multi\");\n    MULTI_VALUES.add(\"notrie_multi\");\n\n    \n    final int NUM_DOCS = TestUtil.nextInt(random(), 200, 1500);\n    final int MIN = TestUtil.nextInt(random(), 10, 100);\n    final int MAX = MIN + TestUtil.nextInt(random(), 10, 100);\n    final long EXPECTED_VALSET_SIZE = 1 + MAX - MIN;\n\n    { // (at least) one doc should have every value, so that at least one segment has every value\n      final Document doc = new Document();\n      for (int i = MIN; i <= MAX; i++) {\n        doc.add(new LegacyIntField(\"trie_multi\", i, Field.Store.NO));\n        doc.add(new LegacyIntField(\"notrie_multi\", i, NO_TRIE_TYPE));\n      }\n      iw.addDocument(doc);\n    }\n\n    // now add some more random docs (note: starting at i=1 because of previously added doc)\n    for (int i = 1; i < NUM_DOCS; i++) {\n      final Document doc = new Document();\n      if (0 != TestUtil.nextInt(random(), 0, 9)) {\n        int val = TestUtil.nextInt(random(), MIN, MAX);\n        doc.add(new LegacyIntField(\"trie_single\", val, Field.Store.NO));\n        doc.add(new LegacyIntField(\"notrie_single\", val, NO_TRIE_TYPE));\n      }\n      if (0 != TestUtil.nextInt(random(), 0, 9)) {\n        int numMulti = atLeast(1);\n        while (0 < numMulti--) {\n          int val = TestUtil.nextInt(random(), MIN, MAX);\n          doc.add(new LegacyIntField(\"trie_multi\", val, Field.Store.NO));\n          doc.add(new LegacyIntField(\"notrie_multi\", val, NO_TRIE_TYPE));\n        }\n      }\n      iw.addDocument(doc);\n    }\n\n    iw.close();\n    \n    final DirectoryReader ir = UninvertingReader.wrap(DirectoryReader.open(dir), UNINVERT_MAP);\n    TestUtil.checkReader(ir);\n    \n    final int NUM_LEAVES = ir.leaves().size();\n    \n    // check the leaves: no more then total set size\n    for (LeafReaderContext rc : ir.leaves()) {\n      final LeafReader ar = rc.reader();\n      for (String f : UNINVERT_MAP.keySet()) {\n        final SortedSetDocValues v = DocValues.getSortedSet(ar, f);\n        final long valSetSize = v.getValueCount();\n        assertTrue(f + \": Expected no more then \" + EXPECTED_VALSET_SIZE + \" values per segment, got \" +\n                   valSetSize + \" from: \" + ar.toString(),\n                   valSetSize <= EXPECTED_VALSET_SIZE);\n        \n        if (1 == NUM_LEAVES && MULTI_VALUES.contains(f)) {\n          // tighter check on multi fields in single segment index since we know one doc has all of them\n          assertEquals(f + \": Single segment LeafReader's value set should have had exactly expected size\",\n                       EXPECTED_VALSET_SIZE, valSetSize);\n        }\n      }\n    }\n\n    // check the composite of all leaves: exact expectation of set size\n    final LeafReader composite = SlowCompositeReaderWrapper.wrap(ir);\n    TestUtil.checkReader(composite);\n    \n    for (String f : MULTI_VALUES) {\n      final SortedSetDocValues v = composite.getSortedSetDocValues(f);\n      final long valSetSize = v.getValueCount();\n      assertEquals(f + \": Composite reader value set should have had exactly expected size\",\n                   EXPECTED_VALSET_SIZE, valSetSize);\n    }\n    \n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  /** Tests {@link Type#SORTED_SET_INTEGER} using Integer based fields, with and w/o precision steps */\n  public void testSortedSetIntegerManyValues() throws IOException {\n    final Directory dir = newDirectory();\n    final IndexWriter iw = new IndexWriter(dir, newIndexWriterConfig(null));\n    \n    final FieldType NO_TRIE_TYPE = new FieldType(LegacyIntField.TYPE_NOT_STORED);\n    NO_TRIE_TYPE.setNumericPrecisionStep(Integer.MAX_VALUE);\n\n    final Map<String,Type> UNINVERT_MAP = new LinkedHashMap<String,Type>();\n    UNINVERT_MAP.put(\"notrie_single\", Type.SORTED_SET_INTEGER);\n    UNINVERT_MAP.put(\"notrie_multi\", Type.SORTED_SET_INTEGER);\n    UNINVERT_MAP.put(\"trie_single\", Type.SORTED_SET_INTEGER);\n    UNINVERT_MAP.put(\"trie_multi\", Type.SORTED_SET_INTEGER);\n    final Set<String> MULTI_VALUES = new LinkedHashSet<String>();\n    MULTI_VALUES.add(\"trie_multi\");\n    MULTI_VALUES.add(\"notrie_multi\");\n\n    \n    final int NUM_DOCS = TestUtil.nextInt(random(), 200, 1500);\n    final int MIN = TestUtil.nextInt(random(), 10, 100);\n    final int MAX = MIN + TestUtil.nextInt(random(), 10, 100);\n    final long EXPECTED_VALSET_SIZE = 1 + MAX - MIN;\n\n    { // (at least) one doc should have every value, so that at least one segment has every value\n      final Document doc = new Document();\n      for (int i = MIN; i <= MAX; i++) {\n        doc.add(new LegacyIntField(\"trie_multi\", i, Field.Store.NO));\n        doc.add(new LegacyIntField(\"notrie_multi\", i, NO_TRIE_TYPE));\n      }\n      iw.addDocument(doc);\n    }\n\n    // now add some more random docs (note: starting at i=1 because of previously added doc)\n    for (int i = 1; i < NUM_DOCS; i++) {\n      final Document doc = new Document();\n      if (0 != TestUtil.nextInt(random(), 0, 9)) {\n        int val = TestUtil.nextInt(random(), MIN, MAX);\n        doc.add(new LegacyIntField(\"trie_single\", val, Field.Store.NO));\n        doc.add(new LegacyIntField(\"notrie_single\", val, NO_TRIE_TYPE));\n      }\n      if (0 != TestUtil.nextInt(random(), 0, 9)) {\n        int numMulti = atLeast(1);\n        while (0 < numMulti--) {\n          int val = TestUtil.nextInt(random(), MIN, MAX);\n          doc.add(new LegacyIntField(\"trie_multi\", val, Field.Store.NO));\n          doc.add(new LegacyIntField(\"notrie_multi\", val, NO_TRIE_TYPE));\n        }\n      }\n      iw.addDocument(doc);\n    }\n\n    iw.close();\n    \n    final DirectoryReader ir = UninvertingReader.wrap(DirectoryReader.open(dir), UNINVERT_MAP);\n    TestUtil.checkReader(ir);\n    \n    final int NUM_LEAVES = ir.leaves().size();\n    \n    // check the leaves: no more then total set size\n    for (LeafReaderContext rc : ir.leaves()) {\n      final LeafReader ar = rc.reader();\n      for (String f : UNINVERT_MAP.keySet()) {\n        final SortedSetDocValues v = DocValues.getSortedSet(ar, f);\n        final long valSetSize = v.getValueCount();\n        assertTrue(f + \": Expected no more then \" + EXPECTED_VALSET_SIZE + \" values per segment, got \" +\n                   valSetSize + \" from: \" + ar.toString(),\n                   valSetSize <= EXPECTED_VALSET_SIZE);\n        \n        if (1 == NUM_LEAVES && MULTI_VALUES.contains(f)) {\n          // tighter check on multi fields in single segment index since we know one doc has all of them\n          assertEquals(f + \": Single segment LeafReader's value set should have had exactly expected size\",\n                       EXPECTED_VALSET_SIZE, valSetSize);\n        }\n      }\n    }\n\n    // check the composite of all leaves: exact expectation of set size\n    final LeafReader composite = SlowCompositeReaderWrapper.wrap(ir);\n    TestUtil.checkReader(composite);\n    \n    for (String f : MULTI_VALUES) {\n      final SortedSetDocValues v = composite.getSortedSetDocValues(f);\n      final long valSetSize = v.getValueCount();\n      assertEquals(f + \": Composite reader value set should have had exactly expected size\",\n                   EXPECTED_VALSET_SIZE, valSetSize);\n    }\n    \n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"403d05f7f8d69b65659157eff1bc1d2717f04c66","date":1471692961,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/uninverting/TestUninvertingReader#testSortedSetIntegerManyValues().mjava","pathOld":"solr/core/src/test/org/apache/solr/uninverting/TestUninvertingReader#testSortedSetIntegerManyValues().mjava","sourceNew":"  /** Tests {@link Type#SORTED_SET_INTEGER} using Integer based fields, with and w/o precision steps */\n  public void testSortedSetIntegerManyValues() throws IOException {\n    final Directory dir = newDirectory();\n    final IndexWriter iw = new IndexWriter(dir, newIndexWriterConfig(null));\n    \n    final LegacyFieldType NO_TRIE_TYPE = new LegacyFieldType(LegacyIntField.TYPE_NOT_STORED);\n    NO_TRIE_TYPE.setNumericPrecisionStep(Integer.MAX_VALUE);\n\n    final Map<String,Type> UNINVERT_MAP = new LinkedHashMap<String,Type>();\n    UNINVERT_MAP.put(\"notrie_single\", Type.SORTED_SET_INTEGER);\n    UNINVERT_MAP.put(\"notrie_multi\", Type.SORTED_SET_INTEGER);\n    UNINVERT_MAP.put(\"trie_single\", Type.SORTED_SET_INTEGER);\n    UNINVERT_MAP.put(\"trie_multi\", Type.SORTED_SET_INTEGER);\n    final Set<String> MULTI_VALUES = new LinkedHashSet<String>();\n    MULTI_VALUES.add(\"trie_multi\");\n    MULTI_VALUES.add(\"notrie_multi\");\n\n    \n    final int NUM_DOCS = TestUtil.nextInt(random(), 200, 1500);\n    final int MIN = TestUtil.nextInt(random(), 10, 100);\n    final int MAX = MIN + TestUtil.nextInt(random(), 10, 100);\n    final long EXPECTED_VALSET_SIZE = 1 + MAX - MIN;\n\n    { // (at least) one doc should have every value, so that at least one segment has every value\n      final Document doc = new Document();\n      for (int i = MIN; i <= MAX; i++) {\n        doc.add(new LegacyIntField(\"trie_multi\", i, Field.Store.NO));\n        doc.add(new LegacyIntField(\"notrie_multi\", i, NO_TRIE_TYPE));\n      }\n      iw.addDocument(doc);\n    }\n\n    // now add some more random docs (note: starting at i=1 because of previously added doc)\n    for (int i = 1; i < NUM_DOCS; i++) {\n      final Document doc = new Document();\n      if (0 != TestUtil.nextInt(random(), 0, 9)) {\n        int val = TestUtil.nextInt(random(), MIN, MAX);\n        doc.add(new LegacyIntField(\"trie_single\", val, Field.Store.NO));\n        doc.add(new LegacyIntField(\"notrie_single\", val, NO_TRIE_TYPE));\n      }\n      if (0 != TestUtil.nextInt(random(), 0, 9)) {\n        int numMulti = atLeast(1);\n        while (0 < numMulti--) {\n          int val = TestUtil.nextInt(random(), MIN, MAX);\n          doc.add(new LegacyIntField(\"trie_multi\", val, Field.Store.NO));\n          doc.add(new LegacyIntField(\"notrie_multi\", val, NO_TRIE_TYPE));\n        }\n      }\n      iw.addDocument(doc);\n    }\n\n    iw.close();\n    \n    final DirectoryReader ir = UninvertingReader.wrap(DirectoryReader.open(dir), UNINVERT_MAP);\n    TestUtil.checkReader(ir);\n    \n    final int NUM_LEAVES = ir.leaves().size();\n    \n    // check the leaves: no more then total set size\n    for (LeafReaderContext rc : ir.leaves()) {\n      final LeafReader ar = rc.reader();\n      for (String f : UNINVERT_MAP.keySet()) {\n        final SortedSetDocValues v = DocValues.getSortedSet(ar, f);\n        final long valSetSize = v.getValueCount();\n        assertTrue(f + \": Expected no more then \" + EXPECTED_VALSET_SIZE + \" values per segment, got \" +\n                   valSetSize + \" from: \" + ar.toString(),\n                   valSetSize <= EXPECTED_VALSET_SIZE);\n        \n        if (1 == NUM_LEAVES && MULTI_VALUES.contains(f)) {\n          // tighter check on multi fields in single segment index since we know one doc has all of them\n          assertEquals(f + \": Single segment LeafReader's value set should have had exactly expected size\",\n                       EXPECTED_VALSET_SIZE, valSetSize);\n        }\n      }\n    }\n\n    // check the composite of all leaves: exact expectation of set size\n    final LeafReader composite = SlowCompositeReaderWrapper.wrap(ir);\n    TestUtil.checkReader(composite);\n    \n    for (String f : MULTI_VALUES) {\n      final SortedSetDocValues v = composite.getSortedSetDocValues(f);\n      final long valSetSize = v.getValueCount();\n      assertEquals(f + \": Composite reader value set should have had exactly expected size\",\n                   EXPECTED_VALSET_SIZE, valSetSize);\n    }\n    \n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  /** Tests {@link Type#SORTED_SET_INTEGER} using Integer based fields, with and w/o precision steps */\n  public void testSortedSetIntegerManyValues() throws IOException {\n    final Directory dir = newDirectory();\n    final IndexWriter iw = new IndexWriter(dir, newIndexWriterConfig(null));\n    \n    final FieldType NO_TRIE_TYPE = new FieldType(LegacyIntField.TYPE_NOT_STORED);\n    NO_TRIE_TYPE.setNumericPrecisionStep(Integer.MAX_VALUE);\n\n    final Map<String,Type> UNINVERT_MAP = new LinkedHashMap<String,Type>();\n    UNINVERT_MAP.put(\"notrie_single\", Type.SORTED_SET_INTEGER);\n    UNINVERT_MAP.put(\"notrie_multi\", Type.SORTED_SET_INTEGER);\n    UNINVERT_MAP.put(\"trie_single\", Type.SORTED_SET_INTEGER);\n    UNINVERT_MAP.put(\"trie_multi\", Type.SORTED_SET_INTEGER);\n    final Set<String> MULTI_VALUES = new LinkedHashSet<String>();\n    MULTI_VALUES.add(\"trie_multi\");\n    MULTI_VALUES.add(\"notrie_multi\");\n\n    \n    final int NUM_DOCS = TestUtil.nextInt(random(), 200, 1500);\n    final int MIN = TestUtil.nextInt(random(), 10, 100);\n    final int MAX = MIN + TestUtil.nextInt(random(), 10, 100);\n    final long EXPECTED_VALSET_SIZE = 1 + MAX - MIN;\n\n    { // (at least) one doc should have every value, so that at least one segment has every value\n      final Document doc = new Document();\n      for (int i = MIN; i <= MAX; i++) {\n        doc.add(new LegacyIntField(\"trie_multi\", i, Field.Store.NO));\n        doc.add(new LegacyIntField(\"notrie_multi\", i, NO_TRIE_TYPE));\n      }\n      iw.addDocument(doc);\n    }\n\n    // now add some more random docs (note: starting at i=1 because of previously added doc)\n    for (int i = 1; i < NUM_DOCS; i++) {\n      final Document doc = new Document();\n      if (0 != TestUtil.nextInt(random(), 0, 9)) {\n        int val = TestUtil.nextInt(random(), MIN, MAX);\n        doc.add(new LegacyIntField(\"trie_single\", val, Field.Store.NO));\n        doc.add(new LegacyIntField(\"notrie_single\", val, NO_TRIE_TYPE));\n      }\n      if (0 != TestUtil.nextInt(random(), 0, 9)) {\n        int numMulti = atLeast(1);\n        while (0 < numMulti--) {\n          int val = TestUtil.nextInt(random(), MIN, MAX);\n          doc.add(new LegacyIntField(\"trie_multi\", val, Field.Store.NO));\n          doc.add(new LegacyIntField(\"notrie_multi\", val, NO_TRIE_TYPE));\n        }\n      }\n      iw.addDocument(doc);\n    }\n\n    iw.close();\n    \n    final DirectoryReader ir = UninvertingReader.wrap(DirectoryReader.open(dir), UNINVERT_MAP);\n    TestUtil.checkReader(ir);\n    \n    final int NUM_LEAVES = ir.leaves().size();\n    \n    // check the leaves: no more then total set size\n    for (LeafReaderContext rc : ir.leaves()) {\n      final LeafReader ar = rc.reader();\n      for (String f : UNINVERT_MAP.keySet()) {\n        final SortedSetDocValues v = DocValues.getSortedSet(ar, f);\n        final long valSetSize = v.getValueCount();\n        assertTrue(f + \": Expected no more then \" + EXPECTED_VALSET_SIZE + \" values per segment, got \" +\n                   valSetSize + \" from: \" + ar.toString(),\n                   valSetSize <= EXPECTED_VALSET_SIZE);\n        \n        if (1 == NUM_LEAVES && MULTI_VALUES.contains(f)) {\n          // tighter check on multi fields in single segment index since we know one doc has all of them\n          assertEquals(f + \": Single segment LeafReader's value set should have had exactly expected size\",\n                       EXPECTED_VALSET_SIZE, valSetSize);\n        }\n      }\n    }\n\n    // check the composite of all leaves: exact expectation of set size\n    final LeafReader composite = SlowCompositeReaderWrapper.wrap(ir);\n    TestUtil.checkReader(composite);\n    \n    for (String f : MULTI_VALUES) {\n      final SortedSetDocValues v = composite.getSortedSetDocValues(f);\n      final long valSetSize = v.getValueCount();\n      assertEquals(f + \": Composite reader value set should have had exactly expected size\",\n                   EXPECTED_VALSET_SIZE, valSetSize);\n    }\n    \n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":0,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/uninverting/TestUninvertingReader#testSortedSetIntegerManyValues().mjava","pathOld":"/dev/null","sourceNew":"  /** Tests {@link Type#SORTED_SET_INTEGER} using Integer based fields, with and w/o precision steps */\n  public void testSortedSetIntegerManyValues() throws IOException {\n    final Directory dir = newDirectory();\n    final IndexWriter iw = new IndexWriter(dir, newIndexWriterConfig(null));\n    \n    final LegacyFieldType NO_TRIE_TYPE = new LegacyFieldType(LegacyIntField.TYPE_NOT_STORED);\n    NO_TRIE_TYPE.setNumericPrecisionStep(Integer.MAX_VALUE);\n\n    final Map<String,Type> UNINVERT_MAP = new LinkedHashMap<String,Type>();\n    UNINVERT_MAP.put(\"notrie_single\", Type.SORTED_SET_INTEGER);\n    UNINVERT_MAP.put(\"notrie_multi\", Type.SORTED_SET_INTEGER);\n    UNINVERT_MAP.put(\"trie_single\", Type.SORTED_SET_INTEGER);\n    UNINVERT_MAP.put(\"trie_multi\", Type.SORTED_SET_INTEGER);\n    final Set<String> MULTI_VALUES = new LinkedHashSet<String>();\n    MULTI_VALUES.add(\"trie_multi\");\n    MULTI_VALUES.add(\"notrie_multi\");\n\n    \n    final int NUM_DOCS = TestUtil.nextInt(random(), 200, 1500);\n    final int MIN = TestUtil.nextInt(random(), 10, 100);\n    final int MAX = MIN + TestUtil.nextInt(random(), 10, 100);\n    final long EXPECTED_VALSET_SIZE = 1 + MAX - MIN;\n\n    { // (at least) one doc should have every value, so that at least one segment has every value\n      final Document doc = new Document();\n      for (int i = MIN; i <= MAX; i++) {\n        doc.add(new LegacyIntField(\"trie_multi\", i, Field.Store.NO));\n        doc.add(new LegacyIntField(\"notrie_multi\", i, NO_TRIE_TYPE));\n      }\n      iw.addDocument(doc);\n    }\n\n    // now add some more random docs (note: starting at i=1 because of previously added doc)\n    for (int i = 1; i < NUM_DOCS; i++) {\n      final Document doc = new Document();\n      if (0 != TestUtil.nextInt(random(), 0, 9)) {\n        int val = TestUtil.nextInt(random(), MIN, MAX);\n        doc.add(new LegacyIntField(\"trie_single\", val, Field.Store.NO));\n        doc.add(new LegacyIntField(\"notrie_single\", val, NO_TRIE_TYPE));\n      }\n      if (0 != TestUtil.nextInt(random(), 0, 9)) {\n        int numMulti = atLeast(1);\n        while (0 < numMulti--) {\n          int val = TestUtil.nextInt(random(), MIN, MAX);\n          doc.add(new LegacyIntField(\"trie_multi\", val, Field.Store.NO));\n          doc.add(new LegacyIntField(\"notrie_multi\", val, NO_TRIE_TYPE));\n        }\n      }\n      iw.addDocument(doc);\n    }\n\n    iw.close();\n    \n    final DirectoryReader ir = UninvertingReader.wrap(DirectoryReader.open(dir), UNINVERT_MAP);\n    TestUtil.checkReader(ir);\n    \n    final int NUM_LEAVES = ir.leaves().size();\n    \n    // check the leaves: no more then total set size\n    for (LeafReaderContext rc : ir.leaves()) {\n      final LeafReader ar = rc.reader();\n      for (String f : UNINVERT_MAP.keySet()) {\n        final SortedSetDocValues v = DocValues.getSortedSet(ar, f);\n        final long valSetSize = v.getValueCount();\n        assertTrue(f + \": Expected no more then \" + EXPECTED_VALSET_SIZE + \" values per segment, got \" +\n                   valSetSize + \" from: \" + ar.toString(),\n                   valSetSize <= EXPECTED_VALSET_SIZE);\n        \n        if (1 == NUM_LEAVES && MULTI_VALUES.contains(f)) {\n          // tighter check on multi fields in single segment index since we know one doc has all of them\n          assertEquals(f + \": Single segment LeafReader's value set should have had exactly expected size\",\n                       EXPECTED_VALSET_SIZE, valSetSize);\n        }\n      }\n    }\n\n    // check the composite of all leaves: exact expectation of set size\n    final LeafReader composite = SlowCompositeReaderWrapper.wrap(ir);\n    TestUtil.checkReader(composite);\n    \n    for (String f : MULTI_VALUES) {\n      final SortedSetDocValues v = composite.getSortedSetDocValues(f);\n      final long valSetSize = v.getValueCount();\n      assertEquals(f + \": Composite reader value set should have had exactly expected size\",\n                   EXPECTED_VALSET_SIZE, valSetSize);\n    }\n    \n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a076c3c721f685b7559308fdc2cd72d91bba67e5":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"403d05f7f8d69b65659157eff1bc1d2717f04c66":["0e121d43b5a10f2df530f406f935102656e9c4e8","2c8bedceb91e64a3f0e831450058fc4a76d2c0a6"],"0e121d43b5a10f2df530f406f935102656e9c4e8":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","a076c3c721f685b7559308fdc2cd72d91bba67e5"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"5af5ba0166322092193d4c29880b0f7670fc7ca0":["0e121d43b5a10f2df530f406f935102656e9c4e8"],"2c8bedceb91e64a3f0e831450058fc4a76d2c0a6":["0e121d43b5a10f2df530f406f935102656e9c4e8","5af5ba0166322092193d4c29880b0f7670fc7ca0"],"83870855d82aba6819217abeff5a40779dbb28b4":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","0e121d43b5a10f2df530f406f935102656e9c4e8"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","403d05f7f8d69b65659157eff1bc1d2717f04c66"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["403d05f7f8d69b65659157eff1bc1d2717f04c66"]},"commit2Childs":{"a076c3c721f685b7559308fdc2cd72d91bba67e5":["0e121d43b5a10f2df530f406f935102656e9c4e8"],"403d05f7f8d69b65659157eff1bc1d2717f04c66":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"0e121d43b5a10f2df530f406f935102656e9c4e8":["403d05f7f8d69b65659157eff1bc1d2717f04c66","5af5ba0166322092193d4c29880b0f7670fc7ca0","2c8bedceb91e64a3f0e831450058fc4a76d2c0a6","83870855d82aba6819217abeff5a40779dbb28b4"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["a076c3c721f685b7559308fdc2cd72d91bba67e5","0e121d43b5a10f2df530f406f935102656e9c4e8","83870855d82aba6819217abeff5a40779dbb28b4","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"5af5ba0166322092193d4c29880b0f7670fc7ca0":["2c8bedceb91e64a3f0e831450058fc4a76d2c0a6"],"2c8bedceb91e64a3f0e831450058fc4a76d2c0a6":["403d05f7f8d69b65659157eff1bc1d2717f04c66"],"83870855d82aba6819217abeff5a40779dbb28b4":[],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["83870855d82aba6819217abeff5a40779dbb28b4","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}