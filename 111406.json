{"path":"lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40FieldInfosReader#read(Directory,String,IOContext).mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40FieldInfosReader#read(Directory,String,IOContext).mjava","pathOld":"lucene/src/java/org/apache/lucene/codecs/lucene40/Lucene40FieldInfosReader#read(Directory,String,IOContext).mjava","sourceNew":"  @Override\n  public FieldInfos read(Directory directory, String segmentName, IOContext iocontext) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentName, \"\", Lucene40FieldInfosWriter.FIELD_INFOS_EXTENSION);\n    IndexInput input = directory.openInput(fileName, iocontext);\n\n    boolean hasVectors = false;\n    boolean hasFreq = false;\n    boolean hasProx = false;\n    \n    try {\n      final int format = input.readVInt();\n\n      if (format > FORMAT_MINIMUM) {\n        throw new IndexFormatTooOldException(input, format, FORMAT_MINIMUM, Lucene40FieldInfosWriter.FORMAT_CURRENT);\n      }\n      if (format < Lucene40FieldInfosWriter.FORMAT_CURRENT) {\n        throw new IndexFormatTooNewException(input, format, FORMAT_MINIMUM, Lucene40FieldInfosWriter.FORMAT_CURRENT);\n      }\n\n      final int size = input.readVInt(); //read in the size\n      FieldInfo infos[] = new FieldInfo[size];\n\n      for (int i = 0; i < size; i++) {\n        String name = input.readString();\n        final int fieldNumber = input.readInt();\n        byte bits = input.readByte();\n        boolean isIndexed = (bits & Lucene40FieldInfosWriter.IS_INDEXED) != 0;\n        boolean storeTermVector = (bits & Lucene40FieldInfosWriter.STORE_TERMVECTOR) != 0;\n        boolean omitNorms = (bits & Lucene40FieldInfosWriter.OMIT_NORMS) != 0;\n        boolean storePayloads = (bits & Lucene40FieldInfosWriter.STORE_PAYLOADS) != 0;\n        final IndexOptions indexOptions;\n        if ((bits & Lucene40FieldInfosWriter.OMIT_TERM_FREQ_AND_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_ONLY;\n        } else if ((bits & Lucene40FieldInfosWriter.OMIT_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS;\n        } else if ((bits & Lucene40FieldInfosWriter.STORE_OFFSETS_IN_POSTINGS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n        } else {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n        }\n\n        // LUCENE-3027: past indices were able to write\n        // storePayloads=true when omitTFAP is also true,\n        // which is invalid.  We correct that, here:\n        if (indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) < 0) {\n          storePayloads = false;\n        }\n        hasVectors |= storeTermVector;\n        hasProx |= isIndexed && indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        hasFreq |= isIndexed && indexOptions != IndexOptions.DOCS_ONLY;\n        // DV Types are packed in one byte\n        byte val = input.readByte();\n        final DocValues.Type docValuesType = getDocValuesType((byte) (val & 0x0F));\n        final DocValues.Type normsType = getDocValuesType((byte) ((val >>> 4) & 0x0F));\n        infos[i] = new FieldInfo(name, isIndexed, fieldNumber, storeTermVector, \n          omitNorms, storePayloads, indexOptions, docValuesType, normsType);\n      }\n\n      if (input.getFilePointer() != input.length()) {\n        throw new CorruptIndexException(\"did not read all bytes from file \\\"\" + fileName + \"\\\": read \" + input.getFilePointer() + \" vs size \" + input.length() + \" (resource: \" + input + \")\");\n      }\n      \n      return new FieldInfos(infos, hasFreq, hasProx, hasVectors);\n    } finally {\n      input.close();\n    }\n  }\n\n","sourceOld":"  @Override\n  public FieldInfos read(Directory directory, String segmentName, IOContext iocontext) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentName, \"\", Lucene40FieldInfosWriter.FIELD_INFOS_EXTENSION);\n    IndexInput input = directory.openInput(fileName, iocontext);\n\n    boolean hasVectors = false;\n    boolean hasFreq = false;\n    boolean hasProx = false;\n    \n    try {\n      final int format = input.readVInt();\n\n      if (format > FORMAT_MINIMUM) {\n        throw new IndexFormatTooOldException(input, format, FORMAT_MINIMUM, Lucene40FieldInfosWriter.FORMAT_CURRENT);\n      }\n      if (format < Lucene40FieldInfosWriter.FORMAT_CURRENT) {\n        throw new IndexFormatTooNewException(input, format, FORMAT_MINIMUM, Lucene40FieldInfosWriter.FORMAT_CURRENT);\n      }\n\n      final int size = input.readVInt(); //read in the size\n      FieldInfo infos[] = new FieldInfo[size];\n\n      for (int i = 0; i < size; i++) {\n        String name = input.readString();\n        final int fieldNumber = input.readInt();\n        byte bits = input.readByte();\n        boolean isIndexed = (bits & Lucene40FieldInfosWriter.IS_INDEXED) != 0;\n        boolean storeTermVector = (bits & Lucene40FieldInfosWriter.STORE_TERMVECTOR) != 0;\n        boolean omitNorms = (bits & Lucene40FieldInfosWriter.OMIT_NORMS) != 0;\n        boolean storePayloads = (bits & Lucene40FieldInfosWriter.STORE_PAYLOADS) != 0;\n        final IndexOptions indexOptions;\n        if ((bits & Lucene40FieldInfosWriter.OMIT_TERM_FREQ_AND_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_ONLY;\n        } else if ((bits & Lucene40FieldInfosWriter.OMIT_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS;\n        } else if ((bits & Lucene40FieldInfosWriter.STORE_OFFSETS_IN_POSTINGS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n        } else {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n        }\n\n        // LUCENE-3027: past indices were able to write\n        // storePayloads=true when omitTFAP is also true,\n        // which is invalid.  We correct that, here:\n        if (indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) < 0) {\n          storePayloads = false;\n        }\n        hasVectors |= storeTermVector;\n        hasProx |= isIndexed && indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        hasFreq |= isIndexed && indexOptions != IndexOptions.DOCS_ONLY;\n        // DV Types are packed in one byte\n        byte val = input.readByte();\n        final DocValues.Type docValuesType = getDocValuesType((byte) (val & 0x0F));\n        final DocValues.Type normsType = getDocValuesType((byte) ((val >>> 4) & 0x0F));\n        infos[i] = new FieldInfo(name, isIndexed, fieldNumber, storeTermVector, \n          omitNorms, storePayloads, indexOptions, docValuesType, normsType);\n      }\n\n      if (input.getFilePointer() != input.length()) {\n        throw new CorruptIndexException(\"did not read all bytes from file \\\"\" + fileName + \"\\\": read \" + input.getFilePointer() + \" vs size \" + input.length() + \" (resource: \" + input + \")\");\n      }\n      \n      return new FieldInfos(infos, hasFreq, hasProx, hasVectors);\n    } finally {\n      input.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f6eee1e5a8555d83dd8f2f2e3c0a4ccec8e7cf9b","date":1337136355,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40FieldInfosReader#read(Directory,String,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40FieldInfosReader#read(Directory,String,IOContext).mjava","sourceNew":"  @Override\n  public FieldInfos read(Directory directory, String segmentName, IOContext iocontext) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentName, \"\", Lucene40FieldInfosWriter.FIELD_INFOS_EXTENSION);\n    IndexInput input = directory.openInput(fileName, iocontext);\n\n    boolean hasVectors = false;\n    boolean hasFreq = false;\n    boolean hasProx = false;\n    \n    try {\n      final int format = input.readVInt();\n\n      if (format > FORMAT_MINIMUM) {\n        throw new IndexFormatTooOldException(input, format, FORMAT_MINIMUM, Lucene40FieldInfosWriter.FORMAT_CURRENT);\n      }\n      if (format < Lucene40FieldInfosWriter.FORMAT_CURRENT) {\n        throw new IndexFormatTooNewException(input, format, FORMAT_MINIMUM, Lucene40FieldInfosWriter.FORMAT_CURRENT);\n      }\n\n      final int size = input.readVInt(); //read in the size\n      FieldInfo infos[] = new FieldInfo[size];\n\n      for (int i = 0; i < size; i++) {\n        String name = input.readString();\n        final int fieldNumber = input.readInt();\n        byte bits = input.readByte();\n        boolean isIndexed = (bits & Lucene40FieldInfosWriter.IS_INDEXED) != 0;\n        boolean storeTermVector = (bits & Lucene40FieldInfosWriter.STORE_TERMVECTOR) != 0;\n        boolean omitNorms = (bits & Lucene40FieldInfosWriter.OMIT_NORMS) != 0;\n        boolean storePayloads = (bits & Lucene40FieldInfosWriter.STORE_PAYLOADS) != 0;\n        final IndexOptions indexOptions;\n        if ((bits & Lucene40FieldInfosWriter.OMIT_TERM_FREQ_AND_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_ONLY;\n        } else if ((bits & Lucene40FieldInfosWriter.OMIT_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS;\n        } else if ((bits & Lucene40FieldInfosWriter.STORE_OFFSETS_IN_POSTINGS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n        } else {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n        }\n\n        // LUCENE-3027: past indices were able to write\n        // storePayloads=true when omitTFAP is also true,\n        // which is invalid.  We correct that, here:\n        if (indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) < 0) {\n          storePayloads = false;\n        }\n        hasVectors |= storeTermVector;\n        hasProx |= isIndexed && indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        hasFreq |= isIndexed && indexOptions != IndexOptions.DOCS_ONLY;\n        // DV Types are packed in one byte\n        byte val = input.readByte();\n        final DocValues.Type docValuesType = getDocValuesType((byte) (val & 0x0F));\n        final DocValues.Type normsType = getDocValuesType((byte) ((val >>> 4) & 0x0F));\n        infos[i] = new FieldInfo(name, isIndexed, fieldNumber, storeTermVector, \n          omitNorms, storePayloads, indexOptions, docValuesType, normsType);\n      }\n\n      if (input.getFilePointer() != input.length()) {\n        throw new CorruptIndexException(\"did not read all bytes from file \\\"\" + fileName + \"\\\": read \" + input.getFilePointer() + \" vs size \" + input.length() + \" (resource: \" + input + \")\");\n      }\n      \n      return new ReadOnlyFieldInfos(infos, hasFreq, hasProx, hasVectors);\n    } finally {\n      input.close();\n    }\n  }\n\n","sourceOld":"  @Override\n  public FieldInfos read(Directory directory, String segmentName, IOContext iocontext) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentName, \"\", Lucene40FieldInfosWriter.FIELD_INFOS_EXTENSION);\n    IndexInput input = directory.openInput(fileName, iocontext);\n\n    boolean hasVectors = false;\n    boolean hasFreq = false;\n    boolean hasProx = false;\n    \n    try {\n      final int format = input.readVInt();\n\n      if (format > FORMAT_MINIMUM) {\n        throw new IndexFormatTooOldException(input, format, FORMAT_MINIMUM, Lucene40FieldInfosWriter.FORMAT_CURRENT);\n      }\n      if (format < Lucene40FieldInfosWriter.FORMAT_CURRENT) {\n        throw new IndexFormatTooNewException(input, format, FORMAT_MINIMUM, Lucene40FieldInfosWriter.FORMAT_CURRENT);\n      }\n\n      final int size = input.readVInt(); //read in the size\n      FieldInfo infos[] = new FieldInfo[size];\n\n      for (int i = 0; i < size; i++) {\n        String name = input.readString();\n        final int fieldNumber = input.readInt();\n        byte bits = input.readByte();\n        boolean isIndexed = (bits & Lucene40FieldInfosWriter.IS_INDEXED) != 0;\n        boolean storeTermVector = (bits & Lucene40FieldInfosWriter.STORE_TERMVECTOR) != 0;\n        boolean omitNorms = (bits & Lucene40FieldInfosWriter.OMIT_NORMS) != 0;\n        boolean storePayloads = (bits & Lucene40FieldInfosWriter.STORE_PAYLOADS) != 0;\n        final IndexOptions indexOptions;\n        if ((bits & Lucene40FieldInfosWriter.OMIT_TERM_FREQ_AND_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_ONLY;\n        } else if ((bits & Lucene40FieldInfosWriter.OMIT_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS;\n        } else if ((bits & Lucene40FieldInfosWriter.STORE_OFFSETS_IN_POSTINGS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n        } else {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n        }\n\n        // LUCENE-3027: past indices were able to write\n        // storePayloads=true when omitTFAP is also true,\n        // which is invalid.  We correct that, here:\n        if (indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) < 0) {\n          storePayloads = false;\n        }\n        hasVectors |= storeTermVector;\n        hasProx |= isIndexed && indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        hasFreq |= isIndexed && indexOptions != IndexOptions.DOCS_ONLY;\n        // DV Types are packed in one byte\n        byte val = input.readByte();\n        final DocValues.Type docValuesType = getDocValuesType((byte) (val & 0x0F));\n        final DocValues.Type normsType = getDocValuesType((byte) ((val >>> 4) & 0x0F));\n        infos[i] = new FieldInfo(name, isIndexed, fieldNumber, storeTermVector, \n          omitNorms, storePayloads, indexOptions, docValuesType, normsType);\n      }\n\n      if (input.getFilePointer() != input.length()) {\n        throw new CorruptIndexException(\"did not read all bytes from file \\\"\" + fileName + \"\\\": read \" + input.getFilePointer() + \" vs size \" + input.length() + \" (resource: \" + input + \")\");\n      }\n      \n      return new FieldInfos(infos, hasFreq, hasProx, hasVectors);\n    } finally {\n      input.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"76923f6a33f2c4bec7f584e3f251261afe7ea276","date":1337149711,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40FieldInfosReader#read(Directory,String,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40FieldInfosReader#read(Directory,String,IOContext).mjava","sourceNew":"  @Override\n  public FieldInfos read(Directory directory, String segmentName, IOContext iocontext) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentName, \"\", Lucene40FieldInfosWriter.FIELD_INFOS_EXTENSION);\n    IndexInput input = directory.openInput(fileName, iocontext);\n    \n    try {\n      final int format = input.readVInt();\n\n      if (format > FORMAT_MINIMUM) {\n        throw new IndexFormatTooOldException(input, format, FORMAT_MINIMUM, Lucene40FieldInfosWriter.FORMAT_CURRENT);\n      }\n      if (format < Lucene40FieldInfosWriter.FORMAT_CURRENT) {\n        throw new IndexFormatTooNewException(input, format, FORMAT_MINIMUM, Lucene40FieldInfosWriter.FORMAT_CURRENT);\n      }\n\n      final int size = input.readVInt(); //read in the size\n      FieldInfo infos[] = new FieldInfo[size];\n\n      for (int i = 0; i < size; i++) {\n        String name = input.readString();\n        final int fieldNumber = input.readInt();\n        byte bits = input.readByte();\n        boolean isIndexed = (bits & Lucene40FieldInfosWriter.IS_INDEXED) != 0;\n        boolean storeTermVector = (bits & Lucene40FieldInfosWriter.STORE_TERMVECTOR) != 0;\n        boolean omitNorms = (bits & Lucene40FieldInfosWriter.OMIT_NORMS) != 0;\n        boolean storePayloads = (bits & Lucene40FieldInfosWriter.STORE_PAYLOADS) != 0;\n        final IndexOptions indexOptions;\n        if ((bits & Lucene40FieldInfosWriter.OMIT_TERM_FREQ_AND_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_ONLY;\n        } else if ((bits & Lucene40FieldInfosWriter.OMIT_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS;\n        } else if ((bits & Lucene40FieldInfosWriter.STORE_OFFSETS_IN_POSTINGS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n        } else {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n        }\n\n        // LUCENE-3027: past indices were able to write\n        // storePayloads=true when omitTFAP is also true,\n        // which is invalid.  We correct that, here:\n        if (indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) < 0) {\n          storePayloads = false;\n        }\n        // DV Types are packed in one byte\n        byte val = input.readByte();\n        final DocValues.Type docValuesType = getDocValuesType((byte) (val & 0x0F));\n        final DocValues.Type normsType = getDocValuesType((byte) ((val >>> 4) & 0x0F));\n        infos[i] = new FieldInfo(name, isIndexed, fieldNumber, storeTermVector, \n          omitNorms, storePayloads, indexOptions, docValuesType, normsType);\n      }\n\n      if (input.getFilePointer() != input.length()) {\n        throw new CorruptIndexException(\"did not read all bytes from file \\\"\" + fileName + \"\\\": read \" + input.getFilePointer() + \" vs size \" + input.length() + \" (resource: \" + input + \")\");\n      }\n      \n      return new ReadOnlyFieldInfos(infos);\n    } finally {\n      input.close();\n    }\n  }\n\n","sourceOld":"  @Override\n  public FieldInfos read(Directory directory, String segmentName, IOContext iocontext) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentName, \"\", Lucene40FieldInfosWriter.FIELD_INFOS_EXTENSION);\n    IndexInput input = directory.openInput(fileName, iocontext);\n\n    boolean hasVectors = false;\n    boolean hasFreq = false;\n    boolean hasProx = false;\n    \n    try {\n      final int format = input.readVInt();\n\n      if (format > FORMAT_MINIMUM) {\n        throw new IndexFormatTooOldException(input, format, FORMAT_MINIMUM, Lucene40FieldInfosWriter.FORMAT_CURRENT);\n      }\n      if (format < Lucene40FieldInfosWriter.FORMAT_CURRENT) {\n        throw new IndexFormatTooNewException(input, format, FORMAT_MINIMUM, Lucene40FieldInfosWriter.FORMAT_CURRENT);\n      }\n\n      final int size = input.readVInt(); //read in the size\n      FieldInfo infos[] = new FieldInfo[size];\n\n      for (int i = 0; i < size; i++) {\n        String name = input.readString();\n        final int fieldNumber = input.readInt();\n        byte bits = input.readByte();\n        boolean isIndexed = (bits & Lucene40FieldInfosWriter.IS_INDEXED) != 0;\n        boolean storeTermVector = (bits & Lucene40FieldInfosWriter.STORE_TERMVECTOR) != 0;\n        boolean omitNorms = (bits & Lucene40FieldInfosWriter.OMIT_NORMS) != 0;\n        boolean storePayloads = (bits & Lucene40FieldInfosWriter.STORE_PAYLOADS) != 0;\n        final IndexOptions indexOptions;\n        if ((bits & Lucene40FieldInfosWriter.OMIT_TERM_FREQ_AND_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_ONLY;\n        } else if ((bits & Lucene40FieldInfosWriter.OMIT_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS;\n        } else if ((bits & Lucene40FieldInfosWriter.STORE_OFFSETS_IN_POSTINGS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n        } else {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n        }\n\n        // LUCENE-3027: past indices were able to write\n        // storePayloads=true when omitTFAP is also true,\n        // which is invalid.  We correct that, here:\n        if (indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) < 0) {\n          storePayloads = false;\n        }\n        hasVectors |= storeTermVector;\n        hasProx |= isIndexed && indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        hasFreq |= isIndexed && indexOptions != IndexOptions.DOCS_ONLY;\n        // DV Types are packed in one byte\n        byte val = input.readByte();\n        final DocValues.Type docValuesType = getDocValuesType((byte) (val & 0x0F));\n        final DocValues.Type normsType = getDocValuesType((byte) ((val >>> 4) & 0x0F));\n        infos[i] = new FieldInfo(name, isIndexed, fieldNumber, storeTermVector, \n          omitNorms, storePayloads, indexOptions, docValuesType, normsType);\n      }\n\n      if (input.getFilePointer() != input.length()) {\n        throw new CorruptIndexException(\"did not read all bytes from file \\\"\" + fileName + \"\\\": read \" + input.getFilePointer() + \" vs size \" + input.length() + \" (resource: \" + input + \")\");\n      }\n      \n      return new ReadOnlyFieldInfos(infos, hasFreq, hasProx, hasVectors);\n    } finally {\n      input.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a851824c09818632c94eba41e60ef5e72e323c8e","date":1337355760,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40FieldInfosReader#read(Directory,String,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40FieldInfosReader#read(Directory,String,IOContext).mjava","sourceNew":"  @Override\n  public FieldInfos read(Directory directory, String segmentName, IOContext iocontext) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentName, \"\", Lucene40FieldInfosWriter.FIELD_INFOS_EXTENSION);\n    IndexInput input = directory.openInput(fileName, iocontext);\n    \n    try {\n      final int format = input.readVInt();\n\n      if (format > FORMAT_MINIMUM) {\n        throw new IndexFormatTooOldException(input, format, FORMAT_MINIMUM, Lucene40FieldInfosWriter.FORMAT_CURRENT);\n      }\n      if (format < Lucene40FieldInfosWriter.FORMAT_CURRENT) {\n        throw new IndexFormatTooNewException(input, format, FORMAT_MINIMUM, Lucene40FieldInfosWriter.FORMAT_CURRENT);\n      }\n\n      final int size = input.readVInt(); //read in the size\n      FieldInfo infos[] = new FieldInfo[size];\n\n      for (int i = 0; i < size; i++) {\n        String name = input.readString();\n        final int fieldNumber = input.readInt();\n        byte bits = input.readByte();\n        boolean isIndexed = (bits & Lucene40FieldInfosWriter.IS_INDEXED) != 0;\n        boolean storeTermVector = (bits & Lucene40FieldInfosWriter.STORE_TERMVECTOR) != 0;\n        boolean omitNorms = (bits & Lucene40FieldInfosWriter.OMIT_NORMS) != 0;\n        boolean storePayloads = (bits & Lucene40FieldInfosWriter.STORE_PAYLOADS) != 0;\n        final IndexOptions indexOptions;\n        if ((bits & Lucene40FieldInfosWriter.OMIT_TERM_FREQ_AND_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_ONLY;\n        } else if ((bits & Lucene40FieldInfosWriter.OMIT_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS;\n        } else if ((bits & Lucene40FieldInfosWriter.STORE_OFFSETS_IN_POSTINGS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n        } else {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n        }\n\n        // LUCENE-3027: past indices were able to write\n        // storePayloads=true when omitTFAP is also true,\n        // which is invalid.  We correct that, here:\n        if (indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) < 0) {\n          storePayloads = false;\n        }\n        // DV Types are packed in one byte\n        byte val = input.readByte();\n        final DocValues.Type docValuesType = getDocValuesType((byte) (val & 0x0F));\n        final DocValues.Type normsType = getDocValuesType((byte) ((val >>> 4) & 0x0F));\n        infos[i] = new FieldInfo(name, isIndexed, fieldNumber, storeTermVector, \n          omitNorms, storePayloads, indexOptions, docValuesType, normsType);\n      }\n\n      if (input.getFilePointer() != input.length()) {\n        throw new CorruptIndexException(\"did not read all bytes from file \\\"\" + fileName + \"\\\": read \" + input.getFilePointer() + \" vs size \" + input.length() + \" (resource: \" + input + \")\");\n      }\n      \n      return new FieldInfos(infos);\n    } finally {\n      input.close();\n    }\n  }\n\n","sourceOld":"  @Override\n  public FieldInfos read(Directory directory, String segmentName, IOContext iocontext) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentName, \"\", Lucene40FieldInfosWriter.FIELD_INFOS_EXTENSION);\n    IndexInput input = directory.openInput(fileName, iocontext);\n    \n    try {\n      final int format = input.readVInt();\n\n      if (format > FORMAT_MINIMUM) {\n        throw new IndexFormatTooOldException(input, format, FORMAT_MINIMUM, Lucene40FieldInfosWriter.FORMAT_CURRENT);\n      }\n      if (format < Lucene40FieldInfosWriter.FORMAT_CURRENT) {\n        throw new IndexFormatTooNewException(input, format, FORMAT_MINIMUM, Lucene40FieldInfosWriter.FORMAT_CURRENT);\n      }\n\n      final int size = input.readVInt(); //read in the size\n      FieldInfo infos[] = new FieldInfo[size];\n\n      for (int i = 0; i < size; i++) {\n        String name = input.readString();\n        final int fieldNumber = input.readInt();\n        byte bits = input.readByte();\n        boolean isIndexed = (bits & Lucene40FieldInfosWriter.IS_INDEXED) != 0;\n        boolean storeTermVector = (bits & Lucene40FieldInfosWriter.STORE_TERMVECTOR) != 0;\n        boolean omitNorms = (bits & Lucene40FieldInfosWriter.OMIT_NORMS) != 0;\n        boolean storePayloads = (bits & Lucene40FieldInfosWriter.STORE_PAYLOADS) != 0;\n        final IndexOptions indexOptions;\n        if ((bits & Lucene40FieldInfosWriter.OMIT_TERM_FREQ_AND_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_ONLY;\n        } else if ((bits & Lucene40FieldInfosWriter.OMIT_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS;\n        } else if ((bits & Lucene40FieldInfosWriter.STORE_OFFSETS_IN_POSTINGS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n        } else {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n        }\n\n        // LUCENE-3027: past indices were able to write\n        // storePayloads=true when omitTFAP is also true,\n        // which is invalid.  We correct that, here:\n        if (indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) < 0) {\n          storePayloads = false;\n        }\n        // DV Types are packed in one byte\n        byte val = input.readByte();\n        final DocValues.Type docValuesType = getDocValuesType((byte) (val & 0x0F));\n        final DocValues.Type normsType = getDocValuesType((byte) ((val >>> 4) & 0x0F));\n        infos[i] = new FieldInfo(name, isIndexed, fieldNumber, storeTermVector, \n          omitNorms, storePayloads, indexOptions, docValuesType, normsType);\n      }\n\n      if (input.getFilePointer() != input.length()) {\n        throw new CorruptIndexException(\"did not read all bytes from file \\\"\" + fileName + \"\\\": read \" + input.getFilePointer() + \" vs size \" + input.length() + \" (resource: \" + input + \")\");\n      }\n      \n      return new ReadOnlyFieldInfos(infos);\n    } finally {\n      input.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a0f42e0639920b2e917c9ece35fb68ad83021e38","date":1337629438,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40FieldInfosReader#read(Directory,String,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40FieldInfosReader#read(Directory,String,IOContext).mjava","sourceNew":"  @Override\n  public FieldInfos read(Directory directory, String segmentName, IOContext iocontext) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentName, \"\", Lucene40FieldInfosWriter.FIELD_INFOS_EXTENSION);\n    IndexInput input = directory.openInput(fileName, iocontext);\n    \n    try {\n      final int format = input.readVInt();\n\n      if (format > FORMAT_MINIMUM) {\n        throw new IndexFormatTooOldException(input, format, FORMAT_MINIMUM, Lucene40FieldInfosWriter.FORMAT_CURRENT);\n      }\n      if (format < Lucene40FieldInfosWriter.FORMAT_CURRENT) {\n        throw new IndexFormatTooNewException(input, format, FORMAT_MINIMUM, Lucene40FieldInfosWriter.FORMAT_CURRENT);\n      }\n\n      final int size = input.readVInt(); //read in the size\n      FieldInfo infos[] = new FieldInfo[size];\n\n      for (int i = 0; i < size; i++) {\n        String name = input.readString();\n        final int fieldNumber = input.readVInt();\n        byte bits = input.readByte();\n        boolean isIndexed = (bits & Lucene40FieldInfosWriter.IS_INDEXED) != 0;\n        boolean storeTermVector = (bits & Lucene40FieldInfosWriter.STORE_TERMVECTOR) != 0;\n        boolean omitNorms = (bits & Lucene40FieldInfosWriter.OMIT_NORMS) != 0;\n        boolean storePayloads = (bits & Lucene40FieldInfosWriter.STORE_PAYLOADS) != 0;\n        final IndexOptions indexOptions;\n        if ((bits & Lucene40FieldInfosWriter.OMIT_TERM_FREQ_AND_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_ONLY;\n        } else if ((bits & Lucene40FieldInfosWriter.OMIT_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS;\n        } else if ((bits & Lucene40FieldInfosWriter.STORE_OFFSETS_IN_POSTINGS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n        } else {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n        }\n\n        // LUCENE-3027: past indices were able to write\n        // storePayloads=true when omitTFAP is also true,\n        // which is invalid.  We correct that, here:\n        if (indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) < 0) {\n          storePayloads = false;\n        }\n        // DV Types are packed in one byte\n        byte val = input.readByte();\n        final DocValues.Type docValuesType = getDocValuesType((byte) (val & 0x0F));\n        final DocValues.Type normsType = getDocValuesType((byte) ((val >>> 4) & 0x0F));\n        final Map<String,String> attributes = input.readStringStringMap();\n        infos[i] = new FieldInfo(name, isIndexed, fieldNumber, storeTermVector, \n          omitNorms, storePayloads, indexOptions, docValuesType, normsType, attributes);\n      }\n\n      if (input.getFilePointer() != input.length()) {\n        throw new CorruptIndexException(\"did not read all bytes from file \\\"\" + fileName + \"\\\": read \" + input.getFilePointer() + \" vs size \" + input.length() + \" (resource: \" + input + \")\");\n      }\n      \n      return new FieldInfos(infos);\n    } finally {\n      input.close();\n    }\n  }\n\n","sourceOld":"  @Override\n  public FieldInfos read(Directory directory, String segmentName, IOContext iocontext) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentName, \"\", Lucene40FieldInfosWriter.FIELD_INFOS_EXTENSION);\n    IndexInput input = directory.openInput(fileName, iocontext);\n    \n    try {\n      final int format = input.readVInt();\n\n      if (format > FORMAT_MINIMUM) {\n        throw new IndexFormatTooOldException(input, format, FORMAT_MINIMUM, Lucene40FieldInfosWriter.FORMAT_CURRENT);\n      }\n      if (format < Lucene40FieldInfosWriter.FORMAT_CURRENT) {\n        throw new IndexFormatTooNewException(input, format, FORMAT_MINIMUM, Lucene40FieldInfosWriter.FORMAT_CURRENT);\n      }\n\n      final int size = input.readVInt(); //read in the size\n      FieldInfo infos[] = new FieldInfo[size];\n\n      for (int i = 0; i < size; i++) {\n        String name = input.readString();\n        final int fieldNumber = input.readInt();\n        byte bits = input.readByte();\n        boolean isIndexed = (bits & Lucene40FieldInfosWriter.IS_INDEXED) != 0;\n        boolean storeTermVector = (bits & Lucene40FieldInfosWriter.STORE_TERMVECTOR) != 0;\n        boolean omitNorms = (bits & Lucene40FieldInfosWriter.OMIT_NORMS) != 0;\n        boolean storePayloads = (bits & Lucene40FieldInfosWriter.STORE_PAYLOADS) != 0;\n        final IndexOptions indexOptions;\n        if ((bits & Lucene40FieldInfosWriter.OMIT_TERM_FREQ_AND_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_ONLY;\n        } else if ((bits & Lucene40FieldInfosWriter.OMIT_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS;\n        } else if ((bits & Lucene40FieldInfosWriter.STORE_OFFSETS_IN_POSTINGS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n        } else {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n        }\n\n        // LUCENE-3027: past indices were able to write\n        // storePayloads=true when omitTFAP is also true,\n        // which is invalid.  We correct that, here:\n        if (indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) < 0) {\n          storePayloads = false;\n        }\n        // DV Types are packed in one byte\n        byte val = input.readByte();\n        final DocValues.Type docValuesType = getDocValuesType((byte) (val & 0x0F));\n        final DocValues.Type normsType = getDocValuesType((byte) ((val >>> 4) & 0x0F));\n        infos[i] = new FieldInfo(name, isIndexed, fieldNumber, storeTermVector, \n          omitNorms, storePayloads, indexOptions, docValuesType, normsType);\n      }\n\n      if (input.getFilePointer() != input.length()) {\n        throw new CorruptIndexException(\"did not read all bytes from file \\\"\" + fileName + \"\\\": read \" + input.getFilePointer() + \" vs size \" + input.length() + \" (resource: \" + input + \")\");\n      }\n      \n      return new FieldInfos(infos);\n    } finally {\n      input.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f00f0f8c602950d28e2cb62039b72f51f5d5c44c","date":1337861286,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40FieldInfosReader#read(Directory,String,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40FieldInfosReader#read(Directory,String,IOContext).mjava","sourceNew":"  @Override\n  public FieldInfos read(Directory directory, String segmentName, IOContext iocontext) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentName, \"\", Lucene40FieldInfosWriter.FIELD_INFOS_EXTENSION);\n    IndexInput input = directory.openInput(fileName, iocontext);\n    \n    try {\n      final int format = input.readVInt();\n\n      if (format > FORMAT_MINIMUM) {\n        throw new IndexFormatTooOldException(input, format, FORMAT_MINIMUM, Lucene40FieldInfosWriter.FORMAT_CURRENT);\n      }\n      if (format < Lucene40FieldInfosWriter.FORMAT_CURRENT) {\n        throw new IndexFormatTooNewException(input, format, FORMAT_MINIMUM, Lucene40FieldInfosWriter.FORMAT_CURRENT);\n      }\n\n      final int size = input.readVInt(); //read in the size\n      FieldInfo infos[] = new FieldInfo[size];\n\n      for (int i = 0; i < size; i++) {\n        String name = input.readString();\n        final int fieldNumber = input.readVInt();\n        byte bits = input.readByte();\n        boolean isIndexed = (bits & Lucene40FieldInfosWriter.IS_INDEXED) != 0;\n        boolean storeTermVector = (bits & Lucene40FieldInfosWriter.STORE_TERMVECTOR) != 0;\n        boolean omitNorms = (bits & Lucene40FieldInfosWriter.OMIT_NORMS) != 0;\n        boolean storePayloads = (bits & Lucene40FieldInfosWriter.STORE_PAYLOADS) != 0;\n        final IndexOptions indexOptions;\n        if ((bits & Lucene40FieldInfosWriter.OMIT_TERM_FREQ_AND_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_ONLY;\n        } else if ((bits & Lucene40FieldInfosWriter.OMIT_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS;\n        } else if ((bits & Lucene40FieldInfosWriter.STORE_OFFSETS_IN_POSTINGS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n        } else {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n        }\n\n        // LUCENE-3027: past indices were able to write\n        // storePayloads=true when omitTFAP is also true,\n        // which is invalid.  We correct that, here:\n        if (indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) < 0) {\n          storePayloads = false;\n        }\n        // DV Types are packed in one byte\n        byte val = input.readByte();\n        final DocValues.Type docValuesType = getDocValuesType((byte) (val & 0x0F));\n        final DocValues.Type normsType = getDocValuesType((byte) ((val >>> 4) & 0x0F));\n        final Map<String,String> attributes = input.readStringStringMap();\n        infos[i] = new FieldInfo(name, isIndexed, fieldNumber, storeTermVector, \n          omitNorms, storePayloads, indexOptions, docValuesType, normsType, Collections.unmodifiableMap(attributes));\n      }\n\n      if (input.getFilePointer() != input.length()) {\n        throw new CorruptIndexException(\"did not read all bytes from file \\\"\" + fileName + \"\\\": read \" + input.getFilePointer() + \" vs size \" + input.length() + \" (resource: \" + input + \")\");\n      }\n      \n      return new FieldInfos(infos);\n    } finally {\n      input.close();\n    }\n  }\n\n","sourceOld":"  @Override\n  public FieldInfos read(Directory directory, String segmentName, IOContext iocontext) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentName, \"\", Lucene40FieldInfosWriter.FIELD_INFOS_EXTENSION);\n    IndexInput input = directory.openInput(fileName, iocontext);\n    \n    try {\n      final int format = input.readVInt();\n\n      if (format > FORMAT_MINIMUM) {\n        throw new IndexFormatTooOldException(input, format, FORMAT_MINIMUM, Lucene40FieldInfosWriter.FORMAT_CURRENT);\n      }\n      if (format < Lucene40FieldInfosWriter.FORMAT_CURRENT) {\n        throw new IndexFormatTooNewException(input, format, FORMAT_MINIMUM, Lucene40FieldInfosWriter.FORMAT_CURRENT);\n      }\n\n      final int size = input.readVInt(); //read in the size\n      FieldInfo infos[] = new FieldInfo[size];\n\n      for (int i = 0; i < size; i++) {\n        String name = input.readString();\n        final int fieldNumber = input.readVInt();\n        byte bits = input.readByte();\n        boolean isIndexed = (bits & Lucene40FieldInfosWriter.IS_INDEXED) != 0;\n        boolean storeTermVector = (bits & Lucene40FieldInfosWriter.STORE_TERMVECTOR) != 0;\n        boolean omitNorms = (bits & Lucene40FieldInfosWriter.OMIT_NORMS) != 0;\n        boolean storePayloads = (bits & Lucene40FieldInfosWriter.STORE_PAYLOADS) != 0;\n        final IndexOptions indexOptions;\n        if ((bits & Lucene40FieldInfosWriter.OMIT_TERM_FREQ_AND_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_ONLY;\n        } else if ((bits & Lucene40FieldInfosWriter.OMIT_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS;\n        } else if ((bits & Lucene40FieldInfosWriter.STORE_OFFSETS_IN_POSTINGS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n        } else {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n        }\n\n        // LUCENE-3027: past indices were able to write\n        // storePayloads=true when omitTFAP is also true,\n        // which is invalid.  We correct that, here:\n        if (indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) < 0) {\n          storePayloads = false;\n        }\n        // DV Types are packed in one byte\n        byte val = input.readByte();\n        final DocValues.Type docValuesType = getDocValuesType((byte) (val & 0x0F));\n        final DocValues.Type normsType = getDocValuesType((byte) ((val >>> 4) & 0x0F));\n        final Map<String,String> attributes = input.readStringStringMap();\n        infos[i] = new FieldInfo(name, isIndexed, fieldNumber, storeTermVector, \n          omitNorms, storePayloads, indexOptions, docValuesType, normsType, attributes);\n      }\n\n      if (input.getFilePointer() != input.length()) {\n        throw new CorruptIndexException(\"did not read all bytes from file \\\"\" + fileName + \"\\\": read \" + input.getFilePointer() + \" vs size \" + input.length() + \" (resource: \" + input + \")\");\n      }\n      \n      return new FieldInfos(infos);\n    } finally {\n      input.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"cc2469a10cffdebd38d207761a32c90c12316b52","date":1337861944,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40FieldInfosReader#read(Directory,String,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40FieldInfosReader#read(Directory,String,IOContext).mjava","sourceNew":"  @Override\n  public FieldInfos read(Directory directory, String segmentName, IOContext iocontext) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentName, \"\", Lucene40FieldInfosWriter.FIELD_INFOS_EXTENSION);\n    IndexInput input = directory.openInput(fileName, iocontext);\n    \n    try {\n      CodecUtil.checkHeader(input, Lucene40FieldInfosWriter.CODEC_NAME, \n                                   Lucene40FieldInfosWriter.FORMAT_START, \n                                   Lucene40FieldInfosWriter.FORMAT_CURRENT);\n\n      final int size = input.readVInt(); //read in the size\n      FieldInfo infos[] = new FieldInfo[size];\n\n      for (int i = 0; i < size; i++) {\n        String name = input.readString();\n        final int fieldNumber = input.readVInt();\n        byte bits = input.readByte();\n        boolean isIndexed = (bits & Lucene40FieldInfosWriter.IS_INDEXED) != 0;\n        boolean storeTermVector = (bits & Lucene40FieldInfosWriter.STORE_TERMVECTOR) != 0;\n        boolean omitNorms = (bits & Lucene40FieldInfosWriter.OMIT_NORMS) != 0;\n        boolean storePayloads = (bits & Lucene40FieldInfosWriter.STORE_PAYLOADS) != 0;\n        final IndexOptions indexOptions;\n        if ((bits & Lucene40FieldInfosWriter.OMIT_TERM_FREQ_AND_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_ONLY;\n        } else if ((bits & Lucene40FieldInfosWriter.OMIT_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS;\n        } else if ((bits & Lucene40FieldInfosWriter.STORE_OFFSETS_IN_POSTINGS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n        } else {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n        }\n\n        // LUCENE-3027: past indices were able to write\n        // storePayloads=true when omitTFAP is also true,\n        // which is invalid.  We correct that, here:\n        if (indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) < 0) {\n          storePayloads = false;\n        }\n        // DV Types are packed in one byte\n        byte val = input.readByte();\n        final DocValues.Type docValuesType = getDocValuesType((byte) (val & 0x0F));\n        final DocValues.Type normsType = getDocValuesType((byte) ((val >>> 4) & 0x0F));\n        final Map<String,String> attributes = input.readStringStringMap();\n        infos[i] = new FieldInfo(name, isIndexed, fieldNumber, storeTermVector, \n          omitNorms, storePayloads, indexOptions, docValuesType, normsType, Collections.unmodifiableMap(attributes));\n      }\n\n      if (input.getFilePointer() != input.length()) {\n        throw new CorruptIndexException(\"did not read all bytes from file \\\"\" + fileName + \"\\\": read \" + input.getFilePointer() + \" vs size \" + input.length() + \" (resource: \" + input + \")\");\n      }\n      \n      return new FieldInfos(infos);\n    } finally {\n      input.close();\n    }\n  }\n\n","sourceOld":"  @Override\n  public FieldInfos read(Directory directory, String segmentName, IOContext iocontext) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentName, \"\", Lucene40FieldInfosWriter.FIELD_INFOS_EXTENSION);\n    IndexInput input = directory.openInput(fileName, iocontext);\n    \n    try {\n      final int format = input.readVInt();\n\n      if (format > FORMAT_MINIMUM) {\n        throw new IndexFormatTooOldException(input, format, FORMAT_MINIMUM, Lucene40FieldInfosWriter.FORMAT_CURRENT);\n      }\n      if (format < Lucene40FieldInfosWriter.FORMAT_CURRENT) {\n        throw new IndexFormatTooNewException(input, format, FORMAT_MINIMUM, Lucene40FieldInfosWriter.FORMAT_CURRENT);\n      }\n\n      final int size = input.readVInt(); //read in the size\n      FieldInfo infos[] = new FieldInfo[size];\n\n      for (int i = 0; i < size; i++) {\n        String name = input.readString();\n        final int fieldNumber = input.readVInt();\n        byte bits = input.readByte();\n        boolean isIndexed = (bits & Lucene40FieldInfosWriter.IS_INDEXED) != 0;\n        boolean storeTermVector = (bits & Lucene40FieldInfosWriter.STORE_TERMVECTOR) != 0;\n        boolean omitNorms = (bits & Lucene40FieldInfosWriter.OMIT_NORMS) != 0;\n        boolean storePayloads = (bits & Lucene40FieldInfosWriter.STORE_PAYLOADS) != 0;\n        final IndexOptions indexOptions;\n        if ((bits & Lucene40FieldInfosWriter.OMIT_TERM_FREQ_AND_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_ONLY;\n        } else if ((bits & Lucene40FieldInfosWriter.OMIT_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS;\n        } else if ((bits & Lucene40FieldInfosWriter.STORE_OFFSETS_IN_POSTINGS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n        } else {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n        }\n\n        // LUCENE-3027: past indices were able to write\n        // storePayloads=true when omitTFAP is also true,\n        // which is invalid.  We correct that, here:\n        if (indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) < 0) {\n          storePayloads = false;\n        }\n        // DV Types are packed in one byte\n        byte val = input.readByte();\n        final DocValues.Type docValuesType = getDocValuesType((byte) (val & 0x0F));\n        final DocValues.Type normsType = getDocValuesType((byte) ((val >>> 4) & 0x0F));\n        final Map<String,String> attributes = input.readStringStringMap();\n        infos[i] = new FieldInfo(name, isIndexed, fieldNumber, storeTermVector, \n          omitNorms, storePayloads, indexOptions, docValuesType, normsType, Collections.unmodifiableMap(attributes));\n      }\n\n      if (input.getFilePointer() != input.length()) {\n        throw new CorruptIndexException(\"did not read all bytes from file \\\"\" + fileName + \"\\\": read \" + input.getFilePointer() + \" vs size \" + input.length() + \" (resource: \" + input + \")\");\n      }\n      \n      return new FieldInfos(infos);\n    } finally {\n      input.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"615ddbd81799980d0fdd95e0238e1c498b6f47b0","date":1338233290,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40FieldInfosReader#read(Directory,String,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40FieldInfosReader#read(Directory,String,IOContext).mjava","sourceNew":"  @Override\n  public FieldInfos read(Directory directory, String segmentName, IOContext iocontext) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentName, \"\", Lucene40FieldInfosWriter.FIELD_INFOS_EXTENSION);\n    IndexInput input = directory.openInput(fileName, iocontext);\n    \n    try {\n      CodecUtil.checkHeader(input, Lucene40FieldInfosWriter.CODEC_NAME, \n                                   Lucene40FieldInfosWriter.FORMAT_START, \n                                   Lucene40FieldInfosWriter.FORMAT_CURRENT);\n\n      final int size = input.readVInt(); //read in the size\n      FieldInfo infos[] = new FieldInfo[size];\n\n      for (int i = 0; i < size; i++) {\n        String name = input.readString();\n        final int fieldNumber = input.readVInt();\n        byte bits = input.readByte();\n        boolean isIndexed = (bits & Lucene40FieldInfosWriter.IS_INDEXED) != 0;\n        boolean storeTermVector = (bits & Lucene40FieldInfosWriter.STORE_TERMVECTOR) != 0;\n        boolean omitNorms = (bits & Lucene40FieldInfosWriter.OMIT_NORMS) != 0;\n        boolean storePayloads = (bits & Lucene40FieldInfosWriter.STORE_PAYLOADS) != 0;\n        final IndexOptions indexOptions;\n        if ((bits & Lucene40FieldInfosWriter.OMIT_TERM_FREQ_AND_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_ONLY;\n        } else if ((bits & Lucene40FieldInfosWriter.OMIT_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS;\n        } else if ((bits & Lucene40FieldInfosWriter.STORE_OFFSETS_IN_POSTINGS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n        } else {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n        }\n\n        // LUCENE-3027: past indices were able to write\n        // storePayloads=true when omitTFAP is also true,\n        // which is invalid.  We correct that, here:\n        if (indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) < 0) {\n          storePayloads = false;\n        }\n        // DV Types are packed in one byte\n        byte val = input.readByte();\n        final DocValues.Type docValuesType = getDocValuesType((byte) (val & 0x0F));\n        final DocValues.Type normsType = getDocValuesType((byte) ((val >>> 4) & 0x0F));\n        final Map<String,String> attributes = input.readStringStringMap();\n        infos[i] = new FieldInfo(name, isIndexed, fieldNumber, storeTermVector, \n          omitNorms, storePayloads, indexOptions, docValuesType, normsType, Collections.unmodifiableMap(attributes));\n      }\n\n      if (input.getFilePointer() != input.length()) {\n        throw new CorruptIndexException(\"did not read all bytes from file \\\"\" + fileName + \"\\\": read \" + input.getFilePointer() + \" vs size \" + input.length() + \" (resource: \" + input + \")\");\n      }\n      \n      return new FieldInfos(infos);\n    } finally {\n      input.close();\n    }\n  }\n\n","sourceOld":"  @Override\n  public FieldInfos read(Directory directory, String segmentName, IOContext iocontext) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentName, \"\", Lucene40FieldInfosWriter.FIELD_INFOS_EXTENSION);\n    IndexInput input = directory.openInput(fileName, iocontext);\n\n    boolean hasVectors = false;\n    boolean hasFreq = false;\n    boolean hasProx = false;\n    \n    try {\n      final int format = input.readVInt();\n\n      if (format > FORMAT_MINIMUM) {\n        throw new IndexFormatTooOldException(input, format, FORMAT_MINIMUM, Lucene40FieldInfosWriter.FORMAT_CURRENT);\n      }\n      if (format < Lucene40FieldInfosWriter.FORMAT_CURRENT) {\n        throw new IndexFormatTooNewException(input, format, FORMAT_MINIMUM, Lucene40FieldInfosWriter.FORMAT_CURRENT);\n      }\n\n      final int size = input.readVInt(); //read in the size\n      FieldInfo infos[] = new FieldInfo[size];\n\n      for (int i = 0; i < size; i++) {\n        String name = input.readString();\n        final int fieldNumber = input.readInt();\n        byte bits = input.readByte();\n        boolean isIndexed = (bits & Lucene40FieldInfosWriter.IS_INDEXED) != 0;\n        boolean storeTermVector = (bits & Lucene40FieldInfosWriter.STORE_TERMVECTOR) != 0;\n        boolean omitNorms = (bits & Lucene40FieldInfosWriter.OMIT_NORMS) != 0;\n        boolean storePayloads = (bits & Lucene40FieldInfosWriter.STORE_PAYLOADS) != 0;\n        final IndexOptions indexOptions;\n        if ((bits & Lucene40FieldInfosWriter.OMIT_TERM_FREQ_AND_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_ONLY;\n        } else if ((bits & Lucene40FieldInfosWriter.OMIT_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS;\n        } else if ((bits & Lucene40FieldInfosWriter.STORE_OFFSETS_IN_POSTINGS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n        } else {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n        }\n\n        // LUCENE-3027: past indices were able to write\n        // storePayloads=true when omitTFAP is also true,\n        // which is invalid.  We correct that, here:\n        if (indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) < 0) {\n          storePayloads = false;\n        }\n        hasVectors |= storeTermVector;\n        hasProx |= isIndexed && indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n        hasFreq |= isIndexed && indexOptions != IndexOptions.DOCS_ONLY;\n        // DV Types are packed in one byte\n        byte val = input.readByte();\n        final DocValues.Type docValuesType = getDocValuesType((byte) (val & 0x0F));\n        final DocValues.Type normsType = getDocValuesType((byte) ((val >>> 4) & 0x0F));\n        infos[i] = new FieldInfo(name, isIndexed, fieldNumber, storeTermVector, \n          omitNorms, storePayloads, indexOptions, docValuesType, normsType);\n      }\n\n      if (input.getFilePointer() != input.length()) {\n        throw new CorruptIndexException(\"did not read all bytes from file \\\"\" + fileName + \"\\\": read \" + input.getFilePointer() + \" vs size \" + input.length() + \" (resource: \" + input + \")\");\n      }\n      \n      return new FieldInfos(infos, hasFreq, hasProx, hasVectors);\n    } finally {\n      input.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"83ede60c0b5bb96ad193414bbd663193b56689b3","date":1338331478,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40FieldInfosReader#read(Directory,String,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40FieldInfosReader#read(Directory,String,IOContext).mjava","sourceNew":"  @Override\n  public FieldInfos read(Directory directory, String segmentName, IOContext iocontext) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentName, \"\", Lucene40FieldInfosWriter.FIELD_INFOS_EXTENSION);\n    IndexInput input = directory.openInput(fileName, iocontext);\n    \n    try {\n      CodecUtil.checkHeader(input, Lucene40FieldInfosWriter.CODEC_NAME, \n                                   Lucene40FieldInfosWriter.FORMAT_START, \n                                   Lucene40FieldInfosWriter.FORMAT_CURRENT);\n\n      final int size = input.readVInt(); //read in the size\n      FieldInfo infos[] = new FieldInfo[size];\n\n      for (int i = 0; i < size; i++) {\n        String name = input.readString();\n        final int fieldNumber = input.readVInt();\n        byte bits = input.readByte();\n        boolean isIndexed = (bits & Lucene40FieldInfosWriter.IS_INDEXED) != 0;\n        boolean storeTermVector = (bits & Lucene40FieldInfosWriter.STORE_TERMVECTOR) != 0;\n        boolean omitNorms = (bits & Lucene40FieldInfosWriter.OMIT_NORMS) != 0;\n        boolean storePayloads = (bits & Lucene40FieldInfosWriter.STORE_PAYLOADS) != 0;\n        final IndexOptions indexOptions;\n        if (!isIndexed) {\n          indexOptions = null;\n        } else if ((bits & Lucene40FieldInfosWriter.OMIT_TERM_FREQ_AND_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_ONLY;\n        } else if ((bits & Lucene40FieldInfosWriter.OMIT_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS;\n        } else if ((bits & Lucene40FieldInfosWriter.STORE_OFFSETS_IN_POSTINGS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n        } else {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n        }\n\n        // LUCENE-3027: past indices were able to write\n        // storePayloads=true when omitTFAP is also true,\n        // which is invalid.  We correct that, here:\n        if (isIndexed && indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) < 0) {\n          storePayloads = false;\n        }\n        // DV Types are packed in one byte\n        byte val = input.readByte();\n        final DocValues.Type docValuesType = getDocValuesType((byte) (val & 0x0F));\n        final DocValues.Type normsType = getDocValuesType((byte) ((val >>> 4) & 0x0F));\n        final Map<String,String> attributes = input.readStringStringMap();\n        infos[i] = new FieldInfo(name, isIndexed, fieldNumber, storeTermVector, \n          omitNorms, storePayloads, indexOptions, docValuesType, normsType, Collections.unmodifiableMap(attributes));\n      }\n\n      if (input.getFilePointer() != input.length()) {\n        throw new CorruptIndexException(\"did not read all bytes from file \\\"\" + fileName + \"\\\": read \" + input.getFilePointer() + \" vs size \" + input.length() + \" (resource: \" + input + \")\");\n      }\n      \n      return new FieldInfos(infos);\n    } finally {\n      input.close();\n    }\n  }\n\n","sourceOld":"  @Override\n  public FieldInfos read(Directory directory, String segmentName, IOContext iocontext) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentName, \"\", Lucene40FieldInfosWriter.FIELD_INFOS_EXTENSION);\n    IndexInput input = directory.openInput(fileName, iocontext);\n    \n    try {\n      CodecUtil.checkHeader(input, Lucene40FieldInfosWriter.CODEC_NAME, \n                                   Lucene40FieldInfosWriter.FORMAT_START, \n                                   Lucene40FieldInfosWriter.FORMAT_CURRENT);\n\n      final int size = input.readVInt(); //read in the size\n      FieldInfo infos[] = new FieldInfo[size];\n\n      for (int i = 0; i < size; i++) {\n        String name = input.readString();\n        final int fieldNumber = input.readVInt();\n        byte bits = input.readByte();\n        boolean isIndexed = (bits & Lucene40FieldInfosWriter.IS_INDEXED) != 0;\n        boolean storeTermVector = (bits & Lucene40FieldInfosWriter.STORE_TERMVECTOR) != 0;\n        boolean omitNorms = (bits & Lucene40FieldInfosWriter.OMIT_NORMS) != 0;\n        boolean storePayloads = (bits & Lucene40FieldInfosWriter.STORE_PAYLOADS) != 0;\n        final IndexOptions indexOptions;\n        if ((bits & Lucene40FieldInfosWriter.OMIT_TERM_FREQ_AND_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_ONLY;\n        } else if ((bits & Lucene40FieldInfosWriter.OMIT_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS;\n        } else if ((bits & Lucene40FieldInfosWriter.STORE_OFFSETS_IN_POSTINGS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n        } else {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n        }\n\n        // LUCENE-3027: past indices were able to write\n        // storePayloads=true when omitTFAP is also true,\n        // which is invalid.  We correct that, here:\n        if (indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) < 0) {\n          storePayloads = false;\n        }\n        // DV Types are packed in one byte\n        byte val = input.readByte();\n        final DocValues.Type docValuesType = getDocValuesType((byte) (val & 0x0F));\n        final DocValues.Type normsType = getDocValuesType((byte) ((val >>> 4) & 0x0F));\n        final Map<String,String> attributes = input.readStringStringMap();\n        infos[i] = new FieldInfo(name, isIndexed, fieldNumber, storeTermVector, \n          omitNorms, storePayloads, indexOptions, docValuesType, normsType, Collections.unmodifiableMap(attributes));\n      }\n\n      if (input.getFilePointer() != input.length()) {\n        throw new CorruptIndexException(\"did not read all bytes from file \\\"\" + fileName + \"\\\": read \" + input.getFilePointer() + \" vs size \" + input.length() + \" (resource: \" + input + \")\");\n      }\n      \n      return new FieldInfos(infos);\n    } finally {\n      input.close();\n    }\n  }\n\n","bugFix":["cfd7f00f3dbc4c50d336540f063493fc0f7d830f","a44b232879361a7ace3520b5b313094a9a35e044"],"bugIntro":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1bf819846fb54a635eb297e36e7c6196d67f8273","date":1349447995,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40FieldInfosReader#read(Directory,String,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40FieldInfosReader#read(Directory,String,IOContext).mjava","sourceNew":"  @Override\n  public FieldInfos read(Directory directory, String segmentName, IOContext iocontext) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentName, \"\", Lucene40FieldInfosWriter.FIELD_INFOS_EXTENSION);\n    IndexInput input = directory.openInput(fileName, iocontext);\n    \n    boolean success = false;\n    try {\n      CodecUtil.checkHeader(input, Lucene40FieldInfosWriter.CODEC_NAME, \n                                   Lucene40FieldInfosWriter.FORMAT_START, \n                                   Lucene40FieldInfosWriter.FORMAT_CURRENT);\n\n      final int size = input.readVInt(); //read in the size\n      FieldInfo infos[] = new FieldInfo[size];\n\n      for (int i = 0; i < size; i++) {\n        String name = input.readString();\n        final int fieldNumber = input.readVInt();\n        byte bits = input.readByte();\n        boolean isIndexed = (bits & Lucene40FieldInfosWriter.IS_INDEXED) != 0;\n        boolean storeTermVector = (bits & Lucene40FieldInfosWriter.STORE_TERMVECTOR) != 0;\n        boolean omitNorms = (bits & Lucene40FieldInfosWriter.OMIT_NORMS) != 0;\n        boolean storePayloads = (bits & Lucene40FieldInfosWriter.STORE_PAYLOADS) != 0;\n        final IndexOptions indexOptions;\n        if (!isIndexed) {\n          indexOptions = null;\n        } else if ((bits & Lucene40FieldInfosWriter.OMIT_TERM_FREQ_AND_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_ONLY;\n        } else if ((bits & Lucene40FieldInfosWriter.OMIT_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS;\n        } else if ((bits & Lucene40FieldInfosWriter.STORE_OFFSETS_IN_POSTINGS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n        } else {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n        }\n\n        // LUCENE-3027: past indices were able to write\n        // storePayloads=true when omitTFAP is also true,\n        // which is invalid.  We correct that, here:\n        if (isIndexed && indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) < 0) {\n          storePayloads = false;\n        }\n        // DV Types are packed in one byte\n        byte val = input.readByte();\n        final DocValues.Type docValuesType = getDocValuesType((byte) (val & 0x0F));\n        final DocValues.Type normsType = getDocValuesType((byte) ((val >>> 4) & 0x0F));\n        final Map<String,String> attributes = input.readStringStringMap();\n        infos[i] = new FieldInfo(name, isIndexed, fieldNumber, storeTermVector, \n          omitNorms, storePayloads, indexOptions, docValuesType, normsType, Collections.unmodifiableMap(attributes));\n      }\n\n      if (input.getFilePointer() != input.length()) {\n        throw new CorruptIndexException(\"did not read all bytes from file \\\"\" + fileName + \"\\\": read \" + input.getFilePointer() + \" vs size \" + input.length() + \" (resource: \" + input + \")\");\n      }\n      FieldInfos fieldInfos = new FieldInfos(infos);\n      success = true;\n      return fieldInfos;\n    } finally {\n      if (success) {\n        input.close();\n      } else {\n        IOUtils.closeWhileHandlingException(input);\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public FieldInfos read(Directory directory, String segmentName, IOContext iocontext) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentName, \"\", Lucene40FieldInfosWriter.FIELD_INFOS_EXTENSION);\n    IndexInput input = directory.openInput(fileName, iocontext);\n    \n    try {\n      CodecUtil.checkHeader(input, Lucene40FieldInfosWriter.CODEC_NAME, \n                                   Lucene40FieldInfosWriter.FORMAT_START, \n                                   Lucene40FieldInfosWriter.FORMAT_CURRENT);\n\n      final int size = input.readVInt(); //read in the size\n      FieldInfo infos[] = new FieldInfo[size];\n\n      for (int i = 0; i < size; i++) {\n        String name = input.readString();\n        final int fieldNumber = input.readVInt();\n        byte bits = input.readByte();\n        boolean isIndexed = (bits & Lucene40FieldInfosWriter.IS_INDEXED) != 0;\n        boolean storeTermVector = (bits & Lucene40FieldInfosWriter.STORE_TERMVECTOR) != 0;\n        boolean omitNorms = (bits & Lucene40FieldInfosWriter.OMIT_NORMS) != 0;\n        boolean storePayloads = (bits & Lucene40FieldInfosWriter.STORE_PAYLOADS) != 0;\n        final IndexOptions indexOptions;\n        if (!isIndexed) {\n          indexOptions = null;\n        } else if ((bits & Lucene40FieldInfosWriter.OMIT_TERM_FREQ_AND_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_ONLY;\n        } else if ((bits & Lucene40FieldInfosWriter.OMIT_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS;\n        } else if ((bits & Lucene40FieldInfosWriter.STORE_OFFSETS_IN_POSTINGS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n        } else {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n        }\n\n        // LUCENE-3027: past indices were able to write\n        // storePayloads=true when omitTFAP is also true,\n        // which is invalid.  We correct that, here:\n        if (isIndexed && indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) < 0) {\n          storePayloads = false;\n        }\n        // DV Types are packed in one byte\n        byte val = input.readByte();\n        final DocValues.Type docValuesType = getDocValuesType((byte) (val & 0x0F));\n        final DocValues.Type normsType = getDocValuesType((byte) ((val >>> 4) & 0x0F));\n        final Map<String,String> attributes = input.readStringStringMap();\n        infos[i] = new FieldInfo(name, isIndexed, fieldNumber, storeTermVector, \n          omitNorms, storePayloads, indexOptions, docValuesType, normsType, Collections.unmodifiableMap(attributes));\n      }\n\n      if (input.getFilePointer() != input.length()) {\n        throw new CorruptIndexException(\"did not read all bytes from file \\\"\" + fileName + \"\\\": read \" + input.getFilePointer() + \" vs size \" + input.length() + \" (resource: \" + input + \")\");\n      }\n      \n      return new FieldInfos(infos);\n    } finally {\n      input.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1af57d1da0dceaad2640da652698505d6a621ce5","date":1358285398,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40FieldInfosReader#read(Directory,String,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40FieldInfosReader#read(Directory,String,IOContext).mjava","sourceNew":"  @Override\n  public FieldInfos read(Directory directory, String segmentName, IOContext iocontext) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentName, \"\", Lucene40FieldInfosWriter.FIELD_INFOS_EXTENSION);\n    IndexInput input = directory.openInput(fileName, iocontext);\n    \n    boolean success = false;\n    try {\n      CodecUtil.checkHeader(input, Lucene40FieldInfosWriter.CODEC_NAME, \n                                   Lucene40FieldInfosWriter.FORMAT_START, \n                                   Lucene40FieldInfosWriter.FORMAT_CURRENT);\n\n      final int size = input.readVInt(); //read in the size\n      FieldInfo infos[] = new FieldInfo[size];\n\n      for (int i = 0; i < size; i++) {\n        String name = input.readString();\n        final int fieldNumber = input.readVInt();\n        byte bits = input.readByte();\n        boolean isIndexed = (bits & Lucene40FieldInfosWriter.IS_INDEXED) != 0;\n        boolean storeTermVector = (bits & Lucene40FieldInfosWriter.STORE_TERMVECTOR) != 0;\n        boolean omitNorms = (bits & Lucene40FieldInfosWriter.OMIT_NORMS) != 0;\n        boolean storePayloads = (bits & Lucene40FieldInfosWriter.STORE_PAYLOADS) != 0;\n        final IndexOptions indexOptions;\n        if (!isIndexed) {\n          indexOptions = null;\n        } else if ((bits & Lucene40FieldInfosWriter.OMIT_TERM_FREQ_AND_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_ONLY;\n        } else if ((bits & Lucene40FieldInfosWriter.OMIT_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS;\n        } else if ((bits & Lucene40FieldInfosWriter.STORE_OFFSETS_IN_POSTINGS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n        } else {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n        }\n\n        // LUCENE-3027: past indices were able to write\n        // storePayloads=true when omitTFAP is also true,\n        // which is invalid.  We correct that, here:\n        if (isIndexed && indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) < 0) {\n          storePayloads = false;\n        }\n        // DV Types are packed in one byte\n        byte val = input.readByte();\n        final DocValuesType docValuesType = getDocValuesTypeFake((byte) (val & 0x0F));\n        final DocValuesType normsType = getDocValuesTypeFake((byte) ((val >>> 4) & 0x0F));\n        final Map<String,String> attributes = input.readStringStringMap();\n        infos[i] = new FieldInfo(name, isIndexed, fieldNumber, storeTermVector, \n          omitNorms, storePayloads, indexOptions, docValuesType, normsType, Collections.unmodifiableMap(attributes));\n      }\n\n      if (input.getFilePointer() != input.length()) {\n        throw new CorruptIndexException(\"did not read all bytes from file \\\"\" + fileName + \"\\\": read \" + input.getFilePointer() + \" vs size \" + input.length() + \" (resource: \" + input + \")\");\n      }\n      FieldInfos fieldInfos = new FieldInfos(infos);\n      success = true;\n      return fieldInfos;\n    } finally {\n      if (success) {\n        input.close();\n      } else {\n        IOUtils.closeWhileHandlingException(input);\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public FieldInfos read(Directory directory, String segmentName, IOContext iocontext) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentName, \"\", Lucene40FieldInfosWriter.FIELD_INFOS_EXTENSION);\n    IndexInput input = directory.openInput(fileName, iocontext);\n    \n    boolean success = false;\n    try {\n      CodecUtil.checkHeader(input, Lucene40FieldInfosWriter.CODEC_NAME, \n                                   Lucene40FieldInfosWriter.FORMAT_START, \n                                   Lucene40FieldInfosWriter.FORMAT_CURRENT);\n\n      final int size = input.readVInt(); //read in the size\n      FieldInfo infos[] = new FieldInfo[size];\n\n      for (int i = 0; i < size; i++) {\n        String name = input.readString();\n        final int fieldNumber = input.readVInt();\n        byte bits = input.readByte();\n        boolean isIndexed = (bits & Lucene40FieldInfosWriter.IS_INDEXED) != 0;\n        boolean storeTermVector = (bits & Lucene40FieldInfosWriter.STORE_TERMVECTOR) != 0;\n        boolean omitNorms = (bits & Lucene40FieldInfosWriter.OMIT_NORMS) != 0;\n        boolean storePayloads = (bits & Lucene40FieldInfosWriter.STORE_PAYLOADS) != 0;\n        final IndexOptions indexOptions;\n        if (!isIndexed) {\n          indexOptions = null;\n        } else if ((bits & Lucene40FieldInfosWriter.OMIT_TERM_FREQ_AND_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_ONLY;\n        } else if ((bits & Lucene40FieldInfosWriter.OMIT_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS;\n        } else if ((bits & Lucene40FieldInfosWriter.STORE_OFFSETS_IN_POSTINGS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n        } else {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n        }\n\n        // LUCENE-3027: past indices were able to write\n        // storePayloads=true when omitTFAP is also true,\n        // which is invalid.  We correct that, here:\n        if (isIndexed && indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) < 0) {\n          storePayloads = false;\n        }\n        // DV Types are packed in one byte\n        byte val = input.readByte();\n        final DocValues.Type docValuesType = getDocValuesType((byte) (val & 0x0F));\n        final DocValues.Type normsType = getDocValuesType((byte) ((val >>> 4) & 0x0F));\n        final Map<String,String> attributes = input.readStringStringMap();\n        infos[i] = new FieldInfo(name, isIndexed, fieldNumber, storeTermVector, \n          omitNorms, storePayloads, indexOptions, docValuesType, normsType, Collections.unmodifiableMap(attributes));\n      }\n\n      if (input.getFilePointer() != input.length()) {\n        throw new CorruptIndexException(\"did not read all bytes from file \\\"\" + fileName + \"\\\": read \" + input.getFilePointer() + \" vs size \" + input.length() + \" (resource: \" + input + \")\");\n      }\n      FieldInfos fieldInfos = new FieldInfos(infos);\n      success = true;\n      return fieldInfos;\n    } finally {\n      if (success) {\n        input.close();\n      } else {\n        IOUtils.closeWhileHandlingException(input);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4e4c8573e7baf60b3f39be994bd2f2c36385d03b","date":1358869567,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40FieldInfosReader#read(Directory,String,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40FieldInfosReader#read(Directory,String,IOContext).mjava","sourceNew":"  @Override\n  public FieldInfos read(Directory directory, String segmentName, IOContext iocontext) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentName, \"\", Lucene40FieldInfosFormat.FIELD_INFOS_EXTENSION);\n    IndexInput input = directory.openInput(fileName, iocontext);\n    \n    boolean success = false;\n    try {\n      CodecUtil.checkHeader(input, Lucene40FieldInfosFormat.CODEC_NAME, \n                                   Lucene40FieldInfosFormat.FORMAT_START, \n                                   Lucene40FieldInfosFormat.FORMAT_CURRENT);\n\n      final int size = input.readVInt(); //read in the size\n      FieldInfo infos[] = new FieldInfo[size];\n\n      for (int i = 0; i < size; i++) {\n        String name = input.readString();\n        final int fieldNumber = input.readVInt();\n        byte bits = input.readByte();\n        boolean isIndexed = (bits & Lucene40FieldInfosFormat.IS_INDEXED) != 0;\n        boolean storeTermVector = (bits & Lucene40FieldInfosFormat.STORE_TERMVECTOR) != 0;\n        boolean omitNorms = (bits & Lucene40FieldInfosFormat.OMIT_NORMS) != 0;\n        boolean storePayloads = (bits & Lucene40FieldInfosFormat.STORE_PAYLOADS) != 0;\n        final IndexOptions indexOptions;\n        if (!isIndexed) {\n          indexOptions = null;\n        } else if ((bits & Lucene40FieldInfosFormat.OMIT_TERM_FREQ_AND_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_ONLY;\n        } else if ((bits & Lucene40FieldInfosFormat.OMIT_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS;\n        } else if ((bits & Lucene40FieldInfosFormat.STORE_OFFSETS_IN_POSTINGS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n        } else {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n        }\n\n        // LUCENE-3027: past indices were able to write\n        // storePayloads=true when omitTFAP is also true,\n        // which is invalid.  We correct that, here:\n        if (isIndexed && indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) < 0) {\n          storePayloads = false;\n        }\n        // DV Types are packed in one byte\n        byte val = input.readByte();\n        final DocValuesType docValuesType = getDocValuesTypeFake((byte) (val & 0x0F));\n        final DocValuesType normsType = getDocValuesTypeFake((byte) ((val >>> 4) & 0x0F));\n        final Map<String,String> attributes = input.readStringStringMap();\n        infos[i] = new FieldInfo(name, isIndexed, fieldNumber, storeTermVector, \n          omitNorms, storePayloads, indexOptions, docValuesType, normsType, Collections.unmodifiableMap(attributes));\n      }\n\n      if (input.getFilePointer() != input.length()) {\n        throw new CorruptIndexException(\"did not read all bytes from file \\\"\" + fileName + \"\\\": read \" + input.getFilePointer() + \" vs size \" + input.length() + \" (resource: \" + input + \")\");\n      }\n      FieldInfos fieldInfos = new FieldInfos(infos);\n      success = true;\n      return fieldInfos;\n    } finally {\n      if (success) {\n        input.close();\n      } else {\n        IOUtils.closeWhileHandlingException(input);\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public FieldInfos read(Directory directory, String segmentName, IOContext iocontext) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentName, \"\", Lucene40FieldInfosWriter.FIELD_INFOS_EXTENSION);\n    IndexInput input = directory.openInput(fileName, iocontext);\n    \n    boolean success = false;\n    try {\n      CodecUtil.checkHeader(input, Lucene40FieldInfosWriter.CODEC_NAME, \n                                   Lucene40FieldInfosWriter.FORMAT_START, \n                                   Lucene40FieldInfosWriter.FORMAT_CURRENT);\n\n      final int size = input.readVInt(); //read in the size\n      FieldInfo infos[] = new FieldInfo[size];\n\n      for (int i = 0; i < size; i++) {\n        String name = input.readString();\n        final int fieldNumber = input.readVInt();\n        byte bits = input.readByte();\n        boolean isIndexed = (bits & Lucene40FieldInfosWriter.IS_INDEXED) != 0;\n        boolean storeTermVector = (bits & Lucene40FieldInfosWriter.STORE_TERMVECTOR) != 0;\n        boolean omitNorms = (bits & Lucene40FieldInfosWriter.OMIT_NORMS) != 0;\n        boolean storePayloads = (bits & Lucene40FieldInfosWriter.STORE_PAYLOADS) != 0;\n        final IndexOptions indexOptions;\n        if (!isIndexed) {\n          indexOptions = null;\n        } else if ((bits & Lucene40FieldInfosWriter.OMIT_TERM_FREQ_AND_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_ONLY;\n        } else if ((bits & Lucene40FieldInfosWriter.OMIT_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS;\n        } else if ((bits & Lucene40FieldInfosWriter.STORE_OFFSETS_IN_POSTINGS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n        } else {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n        }\n\n        // LUCENE-3027: past indices were able to write\n        // storePayloads=true when omitTFAP is also true,\n        // which is invalid.  We correct that, here:\n        if (isIndexed && indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) < 0) {\n          storePayloads = false;\n        }\n        // DV Types are packed in one byte\n        byte val = input.readByte();\n        final DocValuesType docValuesType = getDocValuesTypeFake((byte) (val & 0x0F));\n        final DocValuesType normsType = getDocValuesTypeFake((byte) ((val >>> 4) & 0x0F));\n        final Map<String,String> attributes = input.readStringStringMap();\n        infos[i] = new FieldInfo(name, isIndexed, fieldNumber, storeTermVector, \n          omitNorms, storePayloads, indexOptions, docValuesType, normsType, Collections.unmodifiableMap(attributes));\n      }\n\n      if (input.getFilePointer() != input.length()) {\n        throw new CorruptIndexException(\"did not read all bytes from file \\\"\" + fileName + \"\\\": read \" + input.getFilePointer() + \" vs size \" + input.length() + \" (resource: \" + input + \")\");\n      }\n      FieldInfos fieldInfos = new FieldInfos(infos);\n      success = true;\n      return fieldInfos;\n    } finally {\n      if (success) {\n        input.close();\n      } else {\n        IOUtils.closeWhileHandlingException(input);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3a061a4d303d4aee0918ec2e41c078d900ec23f6","date":1358896586,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40FieldInfosReader#read(Directory,String,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40FieldInfosReader#read(Directory,String,IOContext).mjava","sourceNew":"  @Override\n  public FieldInfos read(Directory directory, String segmentName, IOContext iocontext) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentName, \"\", Lucene40FieldInfosFormat.FIELD_INFOS_EXTENSION);\n    IndexInput input = directory.openInput(fileName, iocontext);\n    \n    boolean success = false;\n    try {\n      CodecUtil.checkHeader(input, Lucene40FieldInfosFormat.CODEC_NAME, \n                                   Lucene40FieldInfosFormat.FORMAT_START, \n                                   Lucene40FieldInfosFormat.FORMAT_CURRENT);\n\n      final int size = input.readVInt(); //read in the size\n      FieldInfo infos[] = new FieldInfo[size];\n\n      for (int i = 0; i < size; i++) {\n        String name = input.readString();\n        final int fieldNumber = input.readVInt();\n        byte bits = input.readByte();\n        boolean isIndexed = (bits & Lucene40FieldInfosFormat.IS_INDEXED) != 0;\n        boolean storeTermVector = (bits & Lucene40FieldInfosFormat.STORE_TERMVECTOR) != 0;\n        boolean omitNorms = (bits & Lucene40FieldInfosFormat.OMIT_NORMS) != 0;\n        boolean storePayloads = (bits & Lucene40FieldInfosFormat.STORE_PAYLOADS) != 0;\n        final IndexOptions indexOptions;\n        if (!isIndexed) {\n          indexOptions = null;\n        } else if ((bits & Lucene40FieldInfosFormat.OMIT_TERM_FREQ_AND_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_ONLY;\n        } else if ((bits & Lucene40FieldInfosFormat.OMIT_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS;\n        } else if ((bits & Lucene40FieldInfosFormat.STORE_OFFSETS_IN_POSTINGS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n        } else {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n        }\n\n        // LUCENE-3027: past indices were able to write\n        // storePayloads=true when omitTFAP is also true,\n        // which is invalid.  We correct that, here:\n        if (isIndexed && indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) < 0) {\n          storePayloads = false;\n        }\n        // DV Types are packed in one byte\n        byte val = input.readByte();\n        final LegacyDocValuesType oldValuesType = getDocValuesType((byte) (val & 0x0F));\n        final LegacyDocValuesType oldNormsType = getDocValuesType((byte) ((val >>> 4) & 0x0F));\n        final Map<String,String> attributes = input.readStringStringMap();;\n        if (oldValuesType.mapping != null) {\n          attributes.put(LEGACY_DV_TYPE_KEY, oldValuesType.name());\n        }\n        if (oldNormsType.mapping != null) {\n          if (oldNormsType.mapping != DocValuesType.NUMERIC) {\n            throw new CorruptIndexException(\"invalid norm type: \" + oldNormsType);\n          }\n          attributes.put(LEGACY_NORM_TYPE_KEY, oldNormsType.name());\n        }\n        infos[i] = new FieldInfo(name, isIndexed, fieldNumber, storeTermVector, \n          omitNorms, storePayloads, indexOptions, oldValuesType.mapping, oldNormsType.mapping, Collections.unmodifiableMap(attributes));\n      }\n\n      if (input.getFilePointer() != input.length()) {\n        throw new CorruptIndexException(\"did not read all bytes from file \\\"\" + fileName + \"\\\": read \" + input.getFilePointer() + \" vs size \" + input.length() + \" (resource: \" + input + \")\");\n      }\n      FieldInfos fieldInfos = new FieldInfos(infos);\n      success = true;\n      return fieldInfos;\n    } finally {\n      if (success) {\n        input.close();\n      } else {\n        IOUtils.closeWhileHandlingException(input);\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public FieldInfos read(Directory directory, String segmentName, IOContext iocontext) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentName, \"\", Lucene40FieldInfosFormat.FIELD_INFOS_EXTENSION);\n    IndexInput input = directory.openInput(fileName, iocontext);\n    \n    boolean success = false;\n    try {\n      CodecUtil.checkHeader(input, Lucene40FieldInfosFormat.CODEC_NAME, \n                                   Lucene40FieldInfosFormat.FORMAT_START, \n                                   Lucene40FieldInfosFormat.FORMAT_CURRENT);\n\n      final int size = input.readVInt(); //read in the size\n      FieldInfo infos[] = new FieldInfo[size];\n\n      for (int i = 0; i < size; i++) {\n        String name = input.readString();\n        final int fieldNumber = input.readVInt();\n        byte bits = input.readByte();\n        boolean isIndexed = (bits & Lucene40FieldInfosFormat.IS_INDEXED) != 0;\n        boolean storeTermVector = (bits & Lucene40FieldInfosFormat.STORE_TERMVECTOR) != 0;\n        boolean omitNorms = (bits & Lucene40FieldInfosFormat.OMIT_NORMS) != 0;\n        boolean storePayloads = (bits & Lucene40FieldInfosFormat.STORE_PAYLOADS) != 0;\n        final IndexOptions indexOptions;\n        if (!isIndexed) {\n          indexOptions = null;\n        } else if ((bits & Lucene40FieldInfosFormat.OMIT_TERM_FREQ_AND_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_ONLY;\n        } else if ((bits & Lucene40FieldInfosFormat.OMIT_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS;\n        } else if ((bits & Lucene40FieldInfosFormat.STORE_OFFSETS_IN_POSTINGS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n        } else {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n        }\n\n        // LUCENE-3027: past indices were able to write\n        // storePayloads=true when omitTFAP is also true,\n        // which is invalid.  We correct that, here:\n        if (isIndexed && indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) < 0) {\n          storePayloads = false;\n        }\n        // DV Types are packed in one byte\n        byte val = input.readByte();\n        final DocValuesType docValuesType = getDocValuesTypeFake((byte) (val & 0x0F));\n        final DocValuesType normsType = getDocValuesTypeFake((byte) ((val >>> 4) & 0x0F));\n        final Map<String,String> attributes = input.readStringStringMap();\n        infos[i] = new FieldInfo(name, isIndexed, fieldNumber, storeTermVector, \n          omitNorms, storePayloads, indexOptions, docValuesType, normsType, Collections.unmodifiableMap(attributes));\n      }\n\n      if (input.getFilePointer() != input.length()) {\n        throw new CorruptIndexException(\"did not read all bytes from file \\\"\" + fileName + \"\\\": read \" + input.getFilePointer() + \" vs size \" + input.length() + \" (resource: \" + input + \")\");\n      }\n      FieldInfos fieldInfos = new FieldInfos(infos);\n      success = true;\n      return fieldInfos;\n    } finally {\n      if (success) {\n        input.close();\n      } else {\n        IOUtils.closeWhileHandlingException(input);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["ca02c6cbb1ba28fd0bd36bd0f8a2ac84be5f0e71"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d4d69c535930b5cce125cff868d40f6373dc27d4","date":1360270101,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40FieldInfosReader#read(Directory,String,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40FieldInfosReader#read(Directory,String,IOContext).mjava","sourceNew":"  @Override\n  public FieldInfos read(Directory directory, String segmentName, IOContext iocontext) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentName, \"\", Lucene40FieldInfosFormat.FIELD_INFOS_EXTENSION);\n    IndexInput input = directory.openInput(fileName, iocontext);\n    \n    boolean success = false;\n    try {\n      CodecUtil.checkHeader(input, Lucene40FieldInfosFormat.CODEC_NAME, \n                                   Lucene40FieldInfosFormat.FORMAT_START, \n                                   Lucene40FieldInfosFormat.FORMAT_CURRENT);\n\n      final int size = input.readVInt(); //read in the size\n      FieldInfo infos[] = new FieldInfo[size];\n\n      for (int i = 0; i < size; i++) {\n        String name = input.readString();\n        final int fieldNumber = input.readVInt();\n        byte bits = input.readByte();\n        boolean isIndexed = (bits & Lucene40FieldInfosFormat.IS_INDEXED) != 0;\n        boolean storeTermVector = (bits & Lucene40FieldInfosFormat.STORE_TERMVECTOR) != 0;\n        boolean omitNorms = (bits & Lucene40FieldInfosFormat.OMIT_NORMS) != 0;\n        boolean storePayloads = (bits & Lucene40FieldInfosFormat.STORE_PAYLOADS) != 0;\n        final IndexOptions indexOptions;\n        if (!isIndexed) {\n          indexOptions = null;\n        } else if ((bits & Lucene40FieldInfosFormat.OMIT_TERM_FREQ_AND_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_ONLY;\n        } else if ((bits & Lucene40FieldInfosFormat.OMIT_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS;\n        } else if ((bits & Lucene40FieldInfosFormat.STORE_OFFSETS_IN_POSTINGS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n        } else {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n        }\n\n        // LUCENE-3027: past indices were able to write\n        // storePayloads=true when omitTFAP is also true,\n        // which is invalid.  We correct that, here:\n        if (isIndexed && indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) < 0) {\n          storePayloads = false;\n        }\n        // DV Types are packed in one byte\n        byte val = input.readByte();\n        final LegacyDocValuesType oldValuesType = getDocValuesType((byte) (val & 0x0F));\n        final LegacyDocValuesType oldNormsType = getDocValuesType((byte) ((val >>> 4) & 0x0F));\n        final Map<String,String> attributes = input.readStringStringMap();;\n        if (oldValuesType.mapping != null) {\n          attributes.put(LEGACY_DV_TYPE_KEY, oldValuesType.name());\n        }\n        if (oldNormsType.mapping != null) {\n          if (oldNormsType.mapping != DocValuesType.NUMERIC) {\n            throw new CorruptIndexException(\"invalid norm type: \" + oldNormsType);\n          }\n          attributes.put(LEGACY_NORM_TYPE_KEY, oldNormsType.name());\n        }\n        infos[i] = new FieldInfo(name, isIndexed, fieldNumber, storeTermVector, \n          omitNorms, storePayloads, indexOptions, oldValuesType.mapping, oldNormsType.mapping, Collections.unmodifiableMap(attributes));\n      }\n\n      if (input.getFilePointer() != input.length()) {\n        throw new CorruptIndexException(\"did not read all bytes from file \\\"\" + fileName + \"\\\": read \" + input.getFilePointer() + \" vs size \" + input.length() + \" (resource: \" + input + \")\");\n      }\n      FieldInfos fieldInfos = new FieldInfos(infos);\n      success = true;\n      return fieldInfos;\n    } finally {\n      if (success) {\n        input.close();\n      } else {\n        IOUtils.closeWhileHandlingException(input);\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public FieldInfos read(Directory directory, String segmentName, IOContext iocontext) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentName, \"\", Lucene40FieldInfosWriter.FIELD_INFOS_EXTENSION);\n    IndexInput input = directory.openInput(fileName, iocontext);\n    \n    boolean success = false;\n    try {\n      CodecUtil.checkHeader(input, Lucene40FieldInfosWriter.CODEC_NAME, \n                                   Lucene40FieldInfosWriter.FORMAT_START, \n                                   Lucene40FieldInfosWriter.FORMAT_CURRENT);\n\n      final int size = input.readVInt(); //read in the size\n      FieldInfo infos[] = new FieldInfo[size];\n\n      for (int i = 0; i < size; i++) {\n        String name = input.readString();\n        final int fieldNumber = input.readVInt();\n        byte bits = input.readByte();\n        boolean isIndexed = (bits & Lucene40FieldInfosWriter.IS_INDEXED) != 0;\n        boolean storeTermVector = (bits & Lucene40FieldInfosWriter.STORE_TERMVECTOR) != 0;\n        boolean omitNorms = (bits & Lucene40FieldInfosWriter.OMIT_NORMS) != 0;\n        boolean storePayloads = (bits & Lucene40FieldInfosWriter.STORE_PAYLOADS) != 0;\n        final IndexOptions indexOptions;\n        if (!isIndexed) {\n          indexOptions = null;\n        } else if ((bits & Lucene40FieldInfosWriter.OMIT_TERM_FREQ_AND_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_ONLY;\n        } else if ((bits & Lucene40FieldInfosWriter.OMIT_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS;\n        } else if ((bits & Lucene40FieldInfosWriter.STORE_OFFSETS_IN_POSTINGS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n        } else {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n        }\n\n        // LUCENE-3027: past indices were able to write\n        // storePayloads=true when omitTFAP is also true,\n        // which is invalid.  We correct that, here:\n        if (isIndexed && indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) < 0) {\n          storePayloads = false;\n        }\n        // DV Types are packed in one byte\n        byte val = input.readByte();\n        final DocValues.Type docValuesType = getDocValuesType((byte) (val & 0x0F));\n        final DocValues.Type normsType = getDocValuesType((byte) ((val >>> 4) & 0x0F));\n        final Map<String,String> attributes = input.readStringStringMap();\n        infos[i] = new FieldInfo(name, isIndexed, fieldNumber, storeTermVector, \n          omitNorms, storePayloads, indexOptions, docValuesType, normsType, Collections.unmodifiableMap(attributes));\n      }\n\n      if (input.getFilePointer() != input.length()) {\n        throw new CorruptIndexException(\"did not read all bytes from file \\\"\" + fileName + \"\\\": read \" + input.getFilePointer() + \" vs size \" + input.length() + \" (resource: \" + input + \")\");\n      }\n      FieldInfos fieldInfos = new FieldInfos(infos);\n      success = true;\n      return fieldInfos;\n    } finally {\n      if (success) {\n        input.close();\n      } else {\n        IOUtils.closeWhileHandlingException(input);\n      }\n    }\n  }\n\n","bugFix":["83ede60c0b5bb96ad193414bbd663193b56689b3","cc2469a10cffdebd38d207761a32c90c12316b52","f00f0f8c602950d28e2cb62039b72f51f5d5c44c","cfd7f00f3dbc4c50d336540f063493fc0f7d830f","a0f42e0639920b2e917c9ece35fb68ad83021e38","9e8d5a6ffbfa3405d234a87c833741eabed98d13"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"90f762b9c981401224de7f0a7c1ffc8fbc67574f","date":1366475889,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40FieldInfosReader#read(Directory,String,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40FieldInfosReader#read(Directory,String,IOContext).mjava","sourceNew":"  @Override\n  public FieldInfos read(Directory directory, String segmentName, IOContext iocontext) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentName, \"\", Lucene40FieldInfosFormat.FIELD_INFOS_EXTENSION);\n    IndexInput input = directory.openInput(fileName, iocontext);\n    \n    boolean success = false;\n    try {\n      CodecUtil.checkHeader(input, Lucene40FieldInfosFormat.CODEC_NAME, \n                                   Lucene40FieldInfosFormat.FORMAT_START, \n                                   Lucene40FieldInfosFormat.FORMAT_CURRENT);\n\n      final int size = input.readVInt(); //read in the size\n      FieldInfo infos[] = new FieldInfo[size];\n\n      for (int i = 0; i < size; i++) {\n        String name = input.readString();\n        final int fieldNumber = input.readVInt();\n        byte bits = input.readByte();\n        boolean isIndexed = (bits & Lucene40FieldInfosFormat.IS_INDEXED) != 0;\n        boolean storeTermVector = (bits & Lucene40FieldInfosFormat.STORE_TERMVECTOR) != 0;\n        boolean omitNorms = (bits & Lucene40FieldInfosFormat.OMIT_NORMS) != 0;\n        boolean storePayloads = (bits & Lucene40FieldInfosFormat.STORE_PAYLOADS) != 0;\n        final IndexOptions indexOptions;\n        if (!isIndexed) {\n          indexOptions = null;\n        } else if ((bits & Lucene40FieldInfosFormat.OMIT_TERM_FREQ_AND_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_ONLY;\n        } else if ((bits & Lucene40FieldInfosFormat.OMIT_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS;\n        } else if ((bits & Lucene40FieldInfosFormat.STORE_OFFSETS_IN_POSTINGS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n        } else {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n        }\n\n        // LUCENE-3027: past indices were able to write\n        // storePayloads=true when omitTFAP is also true,\n        // which is invalid.  We correct that, here:\n        if (isIndexed && indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) < 0) {\n          storePayloads = false;\n        }\n        // DV Types are packed in one byte\n        byte val = input.readByte();\n        final LegacyDocValuesType oldValuesType = getDocValuesType((byte) (val & 0x0F));\n        final LegacyDocValuesType oldNormsType = getDocValuesType((byte) ((val >>> 4) & 0x0F));\n        final Map<String,String> attributes = input.readStringStringMap();;\n        if (oldValuesType.mapping != null) {\n          attributes.put(LEGACY_DV_TYPE_KEY, oldValuesType.name());\n        }\n        if (oldNormsType.mapping != null) {\n          if (oldNormsType.mapping != DocValuesType.NUMERIC) {\n            throw new CorruptIndexException(\"invalid norm type: \" + oldNormsType + \" (resource=\" + input + \")\");\n          }\n          attributes.put(LEGACY_NORM_TYPE_KEY, oldNormsType.name());\n        }\n        infos[i] = new FieldInfo(name, isIndexed, fieldNumber, storeTermVector, \n          omitNorms, storePayloads, indexOptions, oldValuesType.mapping, oldNormsType.mapping, Collections.unmodifiableMap(attributes));\n      }\n\n      if (input.getFilePointer() != input.length()) {\n        throw new CorruptIndexException(\"did not read all bytes from file \\\"\" + fileName + \"\\\": read \" + input.getFilePointer() + \" vs size \" + input.length() + \" (resource: \" + input + \")\");\n      }\n      FieldInfos fieldInfos = new FieldInfos(infos);\n      success = true;\n      return fieldInfos;\n    } finally {\n      if (success) {\n        input.close();\n      } else {\n        IOUtils.closeWhileHandlingException(input);\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public FieldInfos read(Directory directory, String segmentName, IOContext iocontext) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentName, \"\", Lucene40FieldInfosFormat.FIELD_INFOS_EXTENSION);\n    IndexInput input = directory.openInput(fileName, iocontext);\n    \n    boolean success = false;\n    try {\n      CodecUtil.checkHeader(input, Lucene40FieldInfosFormat.CODEC_NAME, \n                                   Lucene40FieldInfosFormat.FORMAT_START, \n                                   Lucene40FieldInfosFormat.FORMAT_CURRENT);\n\n      final int size = input.readVInt(); //read in the size\n      FieldInfo infos[] = new FieldInfo[size];\n\n      for (int i = 0; i < size; i++) {\n        String name = input.readString();\n        final int fieldNumber = input.readVInt();\n        byte bits = input.readByte();\n        boolean isIndexed = (bits & Lucene40FieldInfosFormat.IS_INDEXED) != 0;\n        boolean storeTermVector = (bits & Lucene40FieldInfosFormat.STORE_TERMVECTOR) != 0;\n        boolean omitNorms = (bits & Lucene40FieldInfosFormat.OMIT_NORMS) != 0;\n        boolean storePayloads = (bits & Lucene40FieldInfosFormat.STORE_PAYLOADS) != 0;\n        final IndexOptions indexOptions;\n        if (!isIndexed) {\n          indexOptions = null;\n        } else if ((bits & Lucene40FieldInfosFormat.OMIT_TERM_FREQ_AND_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_ONLY;\n        } else if ((bits & Lucene40FieldInfosFormat.OMIT_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS;\n        } else if ((bits & Lucene40FieldInfosFormat.STORE_OFFSETS_IN_POSTINGS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n        } else {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n        }\n\n        // LUCENE-3027: past indices were able to write\n        // storePayloads=true when omitTFAP is also true,\n        // which is invalid.  We correct that, here:\n        if (isIndexed && indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) < 0) {\n          storePayloads = false;\n        }\n        // DV Types are packed in one byte\n        byte val = input.readByte();\n        final LegacyDocValuesType oldValuesType = getDocValuesType((byte) (val & 0x0F));\n        final LegacyDocValuesType oldNormsType = getDocValuesType((byte) ((val >>> 4) & 0x0F));\n        final Map<String,String> attributes = input.readStringStringMap();;\n        if (oldValuesType.mapping != null) {\n          attributes.put(LEGACY_DV_TYPE_KEY, oldValuesType.name());\n        }\n        if (oldNormsType.mapping != null) {\n          if (oldNormsType.mapping != DocValuesType.NUMERIC) {\n            throw new CorruptIndexException(\"invalid norm type: \" + oldNormsType);\n          }\n          attributes.put(LEGACY_NORM_TYPE_KEY, oldNormsType.name());\n        }\n        infos[i] = new FieldInfo(name, isIndexed, fieldNumber, storeTermVector, \n          omitNorms, storePayloads, indexOptions, oldValuesType.mapping, oldNormsType.mapping, Collections.unmodifiableMap(attributes));\n      }\n\n      if (input.getFilePointer() != input.length()) {\n        throw new CorruptIndexException(\"did not read all bytes from file \\\"\" + fileName + \"\\\": read \" + input.getFilePointer() + \" vs size \" + input.length() + \" (resource: \" + input + \")\");\n      }\n      FieldInfos fieldInfos = new FieldInfos(infos);\n      success = true;\n      return fieldInfos;\n    } finally {\n      if (success) {\n        input.close();\n      } else {\n        IOUtils.closeWhileHandlingException(input);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["9a70ce9bddc6f985feb8e5e182aebe20872328d4","9a70ce9bddc6f985feb8e5e182aebe20872328d4"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8435160e9702b19398118ddf76b61c846612b6a4","date":1380349140,"type":5,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40FieldInfosReader#read(Directory,String,String,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40FieldInfosReader#read(Directory,String,IOContext).mjava","sourceNew":"  @Override\n  public FieldInfos read(Directory directory, String segmentName, String segmentSuffix, IOContext iocontext) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentName, \"\", Lucene40FieldInfosFormat.FIELD_INFOS_EXTENSION);\n    IndexInput input = directory.openInput(fileName, iocontext);\n    \n    boolean success = false;\n    try {\n      CodecUtil.checkHeader(input, Lucene40FieldInfosFormat.CODEC_NAME, \n                                   Lucene40FieldInfosFormat.FORMAT_START, \n                                   Lucene40FieldInfosFormat.FORMAT_CURRENT);\n\n      final int size = input.readVInt(); //read in the size\n      FieldInfo infos[] = new FieldInfo[size];\n\n      for (int i = 0; i < size; i++) {\n        String name = input.readString();\n        final int fieldNumber = input.readVInt();\n        byte bits = input.readByte();\n        boolean isIndexed = (bits & Lucene40FieldInfosFormat.IS_INDEXED) != 0;\n        boolean storeTermVector = (bits & Lucene40FieldInfosFormat.STORE_TERMVECTOR) != 0;\n        boolean omitNorms = (bits & Lucene40FieldInfosFormat.OMIT_NORMS) != 0;\n        boolean storePayloads = (bits & Lucene40FieldInfosFormat.STORE_PAYLOADS) != 0;\n        final IndexOptions indexOptions;\n        if (!isIndexed) {\n          indexOptions = null;\n        } else if ((bits & Lucene40FieldInfosFormat.OMIT_TERM_FREQ_AND_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_ONLY;\n        } else if ((bits & Lucene40FieldInfosFormat.OMIT_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS;\n        } else if ((bits & Lucene40FieldInfosFormat.STORE_OFFSETS_IN_POSTINGS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n        } else {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n        }\n\n        // LUCENE-3027: past indices were able to write\n        // storePayloads=true when omitTFAP is also true,\n        // which is invalid.  We correct that, here:\n        if (isIndexed && indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) < 0) {\n          storePayloads = false;\n        }\n        // DV Types are packed in one byte\n        byte val = input.readByte();\n        final LegacyDocValuesType oldValuesType = getDocValuesType((byte) (val & 0x0F));\n        final LegacyDocValuesType oldNormsType = getDocValuesType((byte) ((val >>> 4) & 0x0F));\n        final Map<String,String> attributes = input.readStringStringMap();;\n        if (oldValuesType.mapping != null) {\n          attributes.put(LEGACY_DV_TYPE_KEY, oldValuesType.name());\n        }\n        if (oldNormsType.mapping != null) {\n          if (oldNormsType.mapping != DocValuesType.NUMERIC) {\n            throw new CorruptIndexException(\"invalid norm type: \" + oldNormsType + \" (resource=\" + input + \")\");\n          }\n          attributes.put(LEGACY_NORM_TYPE_KEY, oldNormsType.name());\n        }\n        infos[i] = new FieldInfo(name, isIndexed, fieldNumber, storeTermVector, \n          omitNorms, storePayloads, indexOptions, oldValuesType.mapping, oldNormsType.mapping, Collections.unmodifiableMap(attributes));\n      }\n\n      if (input.getFilePointer() != input.length()) {\n        throw new CorruptIndexException(\"did not read all bytes from file \\\"\" + fileName + \"\\\": read \" + input.getFilePointer() + \" vs size \" + input.length() + \" (resource: \" + input + \")\");\n      }\n      FieldInfos fieldInfos = new FieldInfos(infos);\n      success = true;\n      return fieldInfos;\n    } finally {\n      if (success) {\n        input.close();\n      } else {\n        IOUtils.closeWhileHandlingException(input);\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public FieldInfos read(Directory directory, String segmentName, IOContext iocontext) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentName, \"\", Lucene40FieldInfosFormat.FIELD_INFOS_EXTENSION);\n    IndexInput input = directory.openInput(fileName, iocontext);\n    \n    boolean success = false;\n    try {\n      CodecUtil.checkHeader(input, Lucene40FieldInfosFormat.CODEC_NAME, \n                                   Lucene40FieldInfosFormat.FORMAT_START, \n                                   Lucene40FieldInfosFormat.FORMAT_CURRENT);\n\n      final int size = input.readVInt(); //read in the size\n      FieldInfo infos[] = new FieldInfo[size];\n\n      for (int i = 0; i < size; i++) {\n        String name = input.readString();\n        final int fieldNumber = input.readVInt();\n        byte bits = input.readByte();\n        boolean isIndexed = (bits & Lucene40FieldInfosFormat.IS_INDEXED) != 0;\n        boolean storeTermVector = (bits & Lucene40FieldInfosFormat.STORE_TERMVECTOR) != 0;\n        boolean omitNorms = (bits & Lucene40FieldInfosFormat.OMIT_NORMS) != 0;\n        boolean storePayloads = (bits & Lucene40FieldInfosFormat.STORE_PAYLOADS) != 0;\n        final IndexOptions indexOptions;\n        if (!isIndexed) {\n          indexOptions = null;\n        } else if ((bits & Lucene40FieldInfosFormat.OMIT_TERM_FREQ_AND_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_ONLY;\n        } else if ((bits & Lucene40FieldInfosFormat.OMIT_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS;\n        } else if ((bits & Lucene40FieldInfosFormat.STORE_OFFSETS_IN_POSTINGS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n        } else {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n        }\n\n        // LUCENE-3027: past indices were able to write\n        // storePayloads=true when omitTFAP is also true,\n        // which is invalid.  We correct that, here:\n        if (isIndexed && indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) < 0) {\n          storePayloads = false;\n        }\n        // DV Types are packed in one byte\n        byte val = input.readByte();\n        final LegacyDocValuesType oldValuesType = getDocValuesType((byte) (val & 0x0F));\n        final LegacyDocValuesType oldNormsType = getDocValuesType((byte) ((val >>> 4) & 0x0F));\n        final Map<String,String> attributes = input.readStringStringMap();;\n        if (oldValuesType.mapping != null) {\n          attributes.put(LEGACY_DV_TYPE_KEY, oldValuesType.name());\n        }\n        if (oldNormsType.mapping != null) {\n          if (oldNormsType.mapping != DocValuesType.NUMERIC) {\n            throw new CorruptIndexException(\"invalid norm type: \" + oldNormsType + \" (resource=\" + input + \")\");\n          }\n          attributes.put(LEGACY_NORM_TYPE_KEY, oldNormsType.name());\n        }\n        infos[i] = new FieldInfo(name, isIndexed, fieldNumber, storeTermVector, \n          omitNorms, storePayloads, indexOptions, oldValuesType.mapping, oldNormsType.mapping, Collections.unmodifiableMap(attributes));\n      }\n\n      if (input.getFilePointer() != input.length()) {\n        throw new CorruptIndexException(\"did not read all bytes from file \\\"\" + fileName + \"\\\": read \" + input.getFilePointer() + \" vs size \" + input.length() + \" (resource: \" + input + \")\");\n      }\n      FieldInfos fieldInfos = new FieldInfos(infos);\n      success = true;\n      return fieldInfos;\n    } finally {\n      if (success) {\n        input.close();\n      } else {\n        IOUtils.closeWhileHandlingException(input);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"90f762b9c981401224de7f0a7c1ffc8fbc67574f":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"1af57d1da0dceaad2640da652698505d6a621ce5":["1bf819846fb54a635eb297e36e7c6196d67f8273"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"8435160e9702b19398118ddf76b61c846612b6a4":["90f762b9c981401224de7f0a7c1ffc8fbc67574f"],"83ede60c0b5bb96ad193414bbd663193b56689b3":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"a0f42e0639920b2e917c9ece35fb68ad83021e38":["a851824c09818632c94eba41e60ef5e72e323c8e"],"a851824c09818632c94eba41e60ef5e72e323c8e":["76923f6a33f2c4bec7f584e3f251261afe7ea276"],"f6eee1e5a8555d83dd8f2f2e3c0a4ccec8e7cf9b":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"76923f6a33f2c4bec7f584e3f251261afe7ea276":["f6eee1e5a8555d83dd8f2f2e3c0a4ccec8e7cf9b"],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["3a119bbc8703c10faa329ec201c654b3a35a1e3e","cc2469a10cffdebd38d207761a32c90c12316b52"],"d4d69c535930b5cce125cff868d40f6373dc27d4":["1bf819846fb54a635eb297e36e7c6196d67f8273","3a061a4d303d4aee0918ec2e41c078d900ec23f6"],"f00f0f8c602950d28e2cb62039b72f51f5d5c44c":["a0f42e0639920b2e917c9ece35fb68ad83021e38"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"4e4c8573e7baf60b3f39be994bd2f2c36385d03b":["1af57d1da0dceaad2640da652698505d6a621ce5"],"3a061a4d303d4aee0918ec2e41c078d900ec23f6":["4e4c8573e7baf60b3f39be994bd2f2c36385d03b"],"1bf819846fb54a635eb297e36e7c6196d67f8273":["83ede60c0b5bb96ad193414bbd663193b56689b3"],"cc2469a10cffdebd38d207761a32c90c12316b52":["f00f0f8c602950d28e2cb62039b72f51f5d5c44c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["8435160e9702b19398118ddf76b61c846612b6a4"]},"commit2Childs":{"90f762b9c981401224de7f0a7c1ffc8fbc67574f":["8435160e9702b19398118ddf76b61c846612b6a4"],"1af57d1da0dceaad2640da652698505d6a621ce5":["4e4c8573e7baf60b3f39be994bd2f2c36385d03b"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["f6eee1e5a8555d83dd8f2f2e3c0a4ccec8e7cf9b","615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"8435160e9702b19398118ddf76b61c846612b6a4":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"83ede60c0b5bb96ad193414bbd663193b56689b3":["1bf819846fb54a635eb297e36e7c6196d67f8273"],"a0f42e0639920b2e917c9ece35fb68ad83021e38":["f00f0f8c602950d28e2cb62039b72f51f5d5c44c"],"a851824c09818632c94eba41e60ef5e72e323c8e":["a0f42e0639920b2e917c9ece35fb68ad83021e38"],"f6eee1e5a8555d83dd8f2f2e3c0a4ccec8e7cf9b":["76923f6a33f2c4bec7f584e3f251261afe7ea276"],"76923f6a33f2c4bec7f584e3f251261afe7ea276":["a851824c09818632c94eba41e60ef5e72e323c8e"],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["83ede60c0b5bb96ad193414bbd663193b56689b3"],"d4d69c535930b5cce125cff868d40f6373dc27d4":["90f762b9c981401224de7f0a7c1ffc8fbc67574f"],"f00f0f8c602950d28e2cb62039b72f51f5d5c44c":["cc2469a10cffdebd38d207761a32c90c12316b52"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"4e4c8573e7baf60b3f39be994bd2f2c36385d03b":["3a061a4d303d4aee0918ec2e41c078d900ec23f6"],"3a061a4d303d4aee0918ec2e41c078d900ec23f6":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"1bf819846fb54a635eb297e36e7c6196d67f8273":["1af57d1da0dceaad2640da652698505d6a621ce5","d4d69c535930b5cce125cff868d40f6373dc27d4"],"cc2469a10cffdebd38d207761a32c90c12316b52":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}