{"path":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareFlushedSegment(FlushedSegment).mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareFlushedSegment(FlushedSegment).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#prepareFlushedSegment(FlushedSegment).mjava","sourceNew":"  /**\n   * Prepares the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}. Use\n   * {@link #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes)} to\n   * publish the returned {@link SegmentInfo} together with its segment private\n   * delete packet.\n   * \n   * @see #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes)\n   */\n  SegmentInfo prepareFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfo newSegment = flushedSegment.segmentInfo;\n\n    setDiagnostics(newSegment, \"flush\");\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.docCount, newSegment.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      if (useCompoundFile(newSegment)) {\n        String compoundFileName = IndexFileNames.segmentFileName(newSegment.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION);\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"creating compound file \" + compoundFileName);\n        }\n        // Now build compound file\n        final Directory cfsDir = new CompoundFileDirectory(directory, compoundFileName, context, true);\n        IOException prior = null;\n        try {\n          for(String fileName : newSegment.files()) {\n            directory.copy(cfsDir, fileName, fileName, context);\n          }\n        } catch(IOException ex) {\n          prior = ex;\n        } finally {\n          IOUtils.closeWhileHandlingException(prior, cfsDir);\n        }\n        // Perform the merge\n        \n        synchronized(this) {\n          deleter.deleteNewFiles(newSegment.files());\n        }\n\n        newSegment.setUseCompoundFile(true);\n      }\n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfo info = flushedSegment.segmentInfo;\n        Codec codec = info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, context);\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"hit exception \" +\n              \"reating compound file for newly flushed segment \" + newSegment.name);\n        }\n\n        synchronized(this) {\n          deleter.refresh(newSegment.name);\n        }\n      }\n    }\n    return newSegment;\n  }\n\n","sourceOld":"  /**\n   * Prepares the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}. Use\n   * {@link #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes)} to\n   * publish the returned {@link SegmentInfo} together with its segment private\n   * delete packet.\n   * \n   * @see #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes)\n   */\n  SegmentInfo prepareFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfo newSegment = flushedSegment.segmentInfo;\n\n    setDiagnostics(newSegment, \"flush\");\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.docCount, newSegment.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      if (useCompoundFile(newSegment)) {\n        String compoundFileName = IndexFileNames.segmentFileName(newSegment.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION);\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"creating compound file \" + compoundFileName);\n        }\n        // Now build compound file\n        final Directory cfsDir = new CompoundFileDirectory(directory, compoundFileName, context, true);\n        IOException prior = null;\n        try {\n          for(String fileName : newSegment.files()) {\n            directory.copy(cfsDir, fileName, fileName, context);\n          }\n        } catch(IOException ex) {\n          prior = ex;\n        } finally {\n          IOUtils.closeWhileHandlingException(prior, cfsDir);\n        }\n        // Perform the merge\n        \n        synchronized(this) {\n          deleter.deleteNewFiles(newSegment.files());\n        }\n\n        newSegment.setUseCompoundFile(true);\n      }\n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfo info = flushedSegment.segmentInfo;\n        Codec codec = info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, context);\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"hit exception \" +\n              \"reating compound file for newly flushed segment \" + newSegment.name);\n        }\n\n        synchronized(this) {\n          deleter.refresh(newSegment.name);\n        }\n      }\n    }\n    return newSegment;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f3a2f7df6ce044e8e7f5fe84cb5b23682fa1b27d","date":1335141740,"type":3,"author":"Christopher John Male","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareFlushedSegment(FlushedSegment).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareFlushedSegment(FlushedSegment).mjava","sourceNew":"  /**\n   * Prepares the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}. Use\n   * {@link #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)} to\n   * publish the returned {@link SegmentInfo} together with its segment private\n   * delete packet.\n   * \n   * @see #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)\n   */\n  SegmentInfo prepareFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfo newSegment = flushedSegment.segmentInfo;\n\n    setDiagnostics(newSegment, \"flush\");\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.docCount, newSegment.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      if (useCompoundFile(newSegment)) {\n        String compoundFileName = IndexFileNames.segmentFileName(newSegment.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION);\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"creating compound file \" + compoundFileName);\n        }\n        // Now build compound file\n        final Directory cfsDir = new CompoundFileDirectory(directory, compoundFileName, context, true);\n        IOException prior = null;\n        try {\n          for(String fileName : newSegment.files()) {\n            directory.copy(cfsDir, fileName, fileName, context);\n          }\n        } catch(IOException ex) {\n          prior = ex;\n        } finally {\n          IOUtils.closeWhileHandlingException(prior, cfsDir);\n        }\n        // Perform the merge\n        \n        synchronized(this) {\n          deleter.deleteNewFiles(newSegment.files());\n        }\n\n        newSegment.setUseCompoundFile(true);\n      }\n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfo info = flushedSegment.segmentInfo;\n        Codec codec = info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, context);\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"hit exception \" +\n              \"reating compound file for newly flushed segment \" + newSegment.name);\n        }\n\n        synchronized(this) {\n          deleter.refresh(newSegment.name);\n        }\n      }\n    }\n    return newSegment;\n  }\n\n","sourceOld":"  /**\n   * Prepares the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}. Use\n   * {@link #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes)} to\n   * publish the returned {@link SegmentInfo} together with its segment private\n   * delete packet.\n   * \n   * @see #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes)\n   */\n  SegmentInfo prepareFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfo newSegment = flushedSegment.segmentInfo;\n\n    setDiagnostics(newSegment, \"flush\");\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.docCount, newSegment.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      if (useCompoundFile(newSegment)) {\n        String compoundFileName = IndexFileNames.segmentFileName(newSegment.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION);\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"creating compound file \" + compoundFileName);\n        }\n        // Now build compound file\n        final Directory cfsDir = new CompoundFileDirectory(directory, compoundFileName, context, true);\n        IOException prior = null;\n        try {\n          for(String fileName : newSegment.files()) {\n            directory.copy(cfsDir, fileName, fileName, context);\n          }\n        } catch(IOException ex) {\n          prior = ex;\n        } finally {\n          IOUtils.closeWhileHandlingException(prior, cfsDir);\n        }\n        // Perform the merge\n        \n        synchronized(this) {\n          deleter.deleteNewFiles(newSegment.files());\n        }\n\n        newSegment.setUseCompoundFile(true);\n      }\n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfo info = flushedSegment.segmentInfo;\n        Codec codec = info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, context);\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"hit exception \" +\n              \"reating compound file for newly flushed segment \" + newSegment.name);\n        }\n\n        synchronized(this) {\n          deleter.refresh(newSegment.name);\n        }\n      }\n    }\n    return newSegment;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f0b406f1c9ada78b8fe2b12dfa87e9f76d35618c","date":1337198060,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareFlushedSegment(FlushedSegment).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareFlushedSegment(FlushedSegment).mjava","sourceNew":"  /**\n   * Prepares the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}. Use\n   * {@link #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)} to\n   * publish the returned {@link SegmentInfo} together with its segment private\n   * delete packet.\n   * \n   * @see #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)\n   */\n  SegmentInfo prepareFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfo newSegment = flushedSegment.segmentInfo;\n\n    setDiagnostics(newSegment, \"flush\");\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.docCount, newSegment.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      if (useCompoundFile(newSegment)) {\n        String compoundFileName = IndexFileNames.segmentFileName(newSegment.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION);\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"creating compound file \" + compoundFileName);\n        }\n        // Now build compound file\n        final Directory cfsDir = new CompoundFileDirectory(directory, compoundFileName, context, true);\n        IOException prior = null;\n        try {\n          for(String fileName : newSegment.files()) {\n            directory.copy(cfsDir, fileName, fileName, context);\n          }\n        } catch(IOException ex) {\n          prior = ex;\n        } finally {\n          IOUtils.closeWhileHandlingException(prior, cfsDir);\n        }\n        // Perform the merge\n        \n        synchronized(this) {\n          deleter.deleteNewFiles(newSegment.files());\n        }\n\n        newSegment.setUseCompoundFile(true);\n      }\n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfo info = flushedSegment.segmentInfo;\n        Codec codec = info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"hit exception \" +\n              \"reating compound file for newly flushed segment \" + newSegment.name);\n        }\n\n        synchronized(this) {\n          deleter.refresh(newSegment.name);\n        }\n      }\n    }\n    return newSegment;\n  }\n\n","sourceOld":"  /**\n   * Prepares the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}. Use\n   * {@link #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)} to\n   * publish the returned {@link SegmentInfo} together with its segment private\n   * delete packet.\n   * \n   * @see #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)\n   */\n  SegmentInfo prepareFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfo newSegment = flushedSegment.segmentInfo;\n\n    setDiagnostics(newSegment, \"flush\");\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.docCount, newSegment.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      if (useCompoundFile(newSegment)) {\n        String compoundFileName = IndexFileNames.segmentFileName(newSegment.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION);\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"creating compound file \" + compoundFileName);\n        }\n        // Now build compound file\n        final Directory cfsDir = new CompoundFileDirectory(directory, compoundFileName, context, true);\n        IOException prior = null;\n        try {\n          for(String fileName : newSegment.files()) {\n            directory.copy(cfsDir, fileName, fileName, context);\n          }\n        } catch(IOException ex) {\n          prior = ex;\n        } finally {\n          IOUtils.closeWhileHandlingException(prior, cfsDir);\n        }\n        // Perform the merge\n        \n        synchronized(this) {\n          deleter.deleteNewFiles(newSegment.files());\n        }\n\n        newSegment.setUseCompoundFile(true);\n      }\n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfo info = flushedSegment.segmentInfo;\n        Codec codec = info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, context);\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"hit exception \" +\n              \"reating compound file for newly flushed segment \" + newSegment.name);\n        }\n\n        synchronized(this) {\n          deleter.refresh(newSegment.name);\n        }\n      }\n    }\n    return newSegment;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4356000e349e38c9fb48034695b7c309abd54557","date":1337460341,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareFlushedSegment(FlushedSegment).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareFlushedSegment(FlushedSegment).mjava","sourceNew":"  /**\n   * Prepares the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}. Use\n   * {@link #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)} to\n   * publish the returned {@link SegmentInfo} together with its segment private\n   * delete packet.\n   * \n   * @see #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)\n   */\n  SegmentInfo prepareFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfo newSegment = flushedSegment.segmentInfo;\n\n    setDiagnostics(newSegment, \"flush\");\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.docCount, newSegment.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      if (useCompoundFile(newSegment)) {\n        String compoundFileName = IndexFileNames.segmentFileName(newSegment.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION);\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"creating compound file \" + compoundFileName);\n        }\n        // Now build compound file\n        // nocommit factor to use craeteCompoundFile method!?\n        final Directory cfsDir = new CompoundFileDirectory(directory, compoundFileName, context, true);\n        IOException prior = null;\n        try {\n          for(String fileName : newSegment.files()) {\n            directory.copy(cfsDir, fileName, fileName, context);\n          }\n        } catch(IOException ex) {\n          prior = ex;\n        } finally {\n          IOUtils.closeWhileHandlingException(prior, cfsDir);\n        }\n        // Perform the merge\n        \n        synchronized(this) {\n          deleter.deleteNewFiles(newSegment.files());\n        }\n\n        newSegment.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfosFormat().getSegmentInfosWriter().write(newSegment, flushedSegment.fieldInfos);\n      newSegment.clearFilesCache();\n\n      // nocommit ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfo info = flushedSegment.segmentInfo;\n        Codec codec = info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"hit exception \" +\n              \"reating compound file for newly flushed segment \" + newSegment.name);\n        }\n\n        synchronized(this) {\n          deleter.refresh(newSegment.name);\n        }\n      }\n    }\n    return newSegment;\n  }\n\n","sourceOld":"  /**\n   * Prepares the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}. Use\n   * {@link #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)} to\n   * publish the returned {@link SegmentInfo} together with its segment private\n   * delete packet.\n   * \n   * @see #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)\n   */\n  SegmentInfo prepareFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfo newSegment = flushedSegment.segmentInfo;\n\n    setDiagnostics(newSegment, \"flush\");\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.docCount, newSegment.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      if (useCompoundFile(newSegment)) {\n        String compoundFileName = IndexFileNames.segmentFileName(newSegment.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION);\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"creating compound file \" + compoundFileName);\n        }\n        // Now build compound file\n        final Directory cfsDir = new CompoundFileDirectory(directory, compoundFileName, context, true);\n        IOException prior = null;\n        try {\n          for(String fileName : newSegment.files()) {\n            directory.copy(cfsDir, fileName, fileName, context);\n          }\n        } catch(IOException ex) {\n          prior = ex;\n        } finally {\n          IOUtils.closeWhileHandlingException(prior, cfsDir);\n        }\n        // Perform the merge\n        \n        synchronized(this) {\n          deleter.deleteNewFiles(newSegment.files());\n        }\n\n        newSegment.setUseCompoundFile(true);\n      }\n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfo info = flushedSegment.segmentInfo;\n        Codec codec = info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"hit exception \" +\n              \"reating compound file for newly flushed segment \" + newSegment.name);\n        }\n\n        synchronized(this) {\n          deleter.refresh(newSegment.name);\n        }\n      }\n    }\n    return newSegment;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"352763be0465236f8e2ac188aa1b761cb3e1c9ee","date":1337516554,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareFlushedSegment(FlushedSegment).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareFlushedSegment(FlushedSegment).mjava","sourceNew":"  /**\n   * Prepares the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}. Use\n   * {@link #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)} to\n   * publish the returned {@link SegmentInfo} together with its segment private\n   * delete packet.\n   * \n   * @see #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)\n   */\n  SegmentInfo prepareFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfo newSegment = flushedSegment.segmentInfo;\n\n    setDiagnostics(newSegment, \"flush\");\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.docCount, newSegment.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      if (useCompoundFile(newSegment)) {\n        String compoundFileName = IndexFileNames.segmentFileName(newSegment.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION);\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"creating compound file \" + compoundFileName);\n        }\n        // Now build compound file\n        // nocommit factor to use craeteCompoundFile method!?\n        final Directory cfsDir = new CompoundFileDirectory(directory, compoundFileName, context, true);\n        IOException prior = null;\n        try {\n          for(String fileName : newSegment.files()) {\n            directory.copy(cfsDir, fileName, fileName, context);\n          }\n        } catch(IOException ex) {\n          prior = ex;\n        } finally {\n          IOUtils.closeWhileHandlingException(prior, cfsDir);\n        }\n        // Perform the merge\n        \n        synchronized(this) {\n          deleter.deleteNewFiles(newSegment.files());\n        }\n\n        newSegment.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfosFormat().getSegmentInfosWriter().write(directory, newSegment, flushedSegment.fieldInfos, context);\n      newSegment.clearFilesCache();\n\n      // nocommit ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfo info = flushedSegment.segmentInfo;\n        Codec codec = info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"hit exception \" +\n              \"reating compound file for newly flushed segment \" + newSegment.name);\n        }\n\n        synchronized(this) {\n          deleter.refresh(newSegment.name);\n        }\n      }\n    }\n    return newSegment;\n  }\n\n","sourceOld":"  /**\n   * Prepares the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}. Use\n   * {@link #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)} to\n   * publish the returned {@link SegmentInfo} together with its segment private\n   * delete packet.\n   * \n   * @see #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)\n   */\n  SegmentInfo prepareFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfo newSegment = flushedSegment.segmentInfo;\n\n    setDiagnostics(newSegment, \"flush\");\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.docCount, newSegment.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      if (useCompoundFile(newSegment)) {\n        String compoundFileName = IndexFileNames.segmentFileName(newSegment.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION);\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"creating compound file \" + compoundFileName);\n        }\n        // Now build compound file\n        // nocommit factor to use craeteCompoundFile method!?\n        final Directory cfsDir = new CompoundFileDirectory(directory, compoundFileName, context, true);\n        IOException prior = null;\n        try {\n          for(String fileName : newSegment.files()) {\n            directory.copy(cfsDir, fileName, fileName, context);\n          }\n        } catch(IOException ex) {\n          prior = ex;\n        } finally {\n          IOUtils.closeWhileHandlingException(prior, cfsDir);\n        }\n        // Perform the merge\n        \n        synchronized(this) {\n          deleter.deleteNewFiles(newSegment.files());\n        }\n\n        newSegment.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfosFormat().getSegmentInfosWriter().write(newSegment, flushedSegment.fieldInfos);\n      newSegment.clearFilesCache();\n\n      // nocommit ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfo info = flushedSegment.segmentInfo;\n        Codec codec = info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"hit exception \" +\n              \"reating compound file for newly flushed segment \" + newSegment.name);\n        }\n\n        synchronized(this) {\n          deleter.refresh(newSegment.name);\n        }\n      }\n    }\n    return newSegment;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9b2af6b2c05418fb9df466c739ed5b3a153eadde","date":1337520269,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareFlushedSegment(FlushedSegment).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareFlushedSegment(FlushedSegment).mjava","sourceNew":"  /**\n   * Prepares the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}. Use\n   * {@link #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)} to\n   * publish the returned {@link SegmentInfo} together with its segment private\n   * delete packet.\n   * \n   * @see #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)\n   */\n  SegmentInfo prepareFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfo newSegment = flushedSegment.segmentInfo;\n\n    setDiagnostics(newSegment, \"flush\");\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.docCount, newSegment.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      if (useCompoundFile(newSegment)) {\n        String compoundFileName = IndexFileNames.segmentFileName(newSegment.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION);\n\n        // Now build compound file\n        Collection<String> files = createCompoundFile(infoStream, directory, compoundFileName, MergeState.CheckAbort.NONE, newSegment, context);\n        newSegment.setUseCompoundFile(true);\n        \n        synchronized(this) {\n          deleter.deleteNewFiles(files);\n        }\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfosFormat().getSegmentInfosWriter().write(directory, newSegment, flushedSegment.fieldInfos, context);\n      newSegment.clearFilesCache();\n\n      // nocommit ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfo info = flushedSegment.segmentInfo;\n        Codec codec = info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"hit exception \" +\n              \"reating compound file for newly flushed segment \" + newSegment.name);\n        }\n\n        synchronized(this) {\n          deleter.refresh(newSegment.name);\n        }\n      }\n    }\n    return newSegment;\n  }\n\n","sourceOld":"  /**\n   * Prepares the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}. Use\n   * {@link #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)} to\n   * publish the returned {@link SegmentInfo} together with its segment private\n   * delete packet.\n   * \n   * @see #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)\n   */\n  SegmentInfo prepareFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfo newSegment = flushedSegment.segmentInfo;\n\n    setDiagnostics(newSegment, \"flush\");\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.docCount, newSegment.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      if (useCompoundFile(newSegment)) {\n        String compoundFileName = IndexFileNames.segmentFileName(newSegment.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION);\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"creating compound file \" + compoundFileName);\n        }\n        // Now build compound file\n        // nocommit factor to use craeteCompoundFile method!?\n        final Directory cfsDir = new CompoundFileDirectory(directory, compoundFileName, context, true);\n        IOException prior = null;\n        try {\n          for(String fileName : newSegment.files()) {\n            directory.copy(cfsDir, fileName, fileName, context);\n          }\n        } catch(IOException ex) {\n          prior = ex;\n        } finally {\n          IOUtils.closeWhileHandlingException(prior, cfsDir);\n        }\n        // Perform the merge\n        \n        synchronized(this) {\n          deleter.deleteNewFiles(newSegment.files());\n        }\n\n        newSegment.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfosFormat().getSegmentInfosWriter().write(directory, newSegment, flushedSegment.fieldInfos, context);\n      newSegment.clearFilesCache();\n\n      // nocommit ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfo info = flushedSegment.segmentInfo;\n        Codec codec = info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"hit exception \" +\n              \"reating compound file for newly flushed segment \" + newSegment.name);\n        }\n\n        synchronized(this) {\n          deleter.refresh(newSegment.name);\n        }\n      }\n    }\n    return newSegment;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1494abe5dc85557ec2e2772f87660d48f831c3a5","date":1337614370,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareFlushedSegment(FlushedSegment).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareFlushedSegment(FlushedSegment).mjava","sourceNew":"  /**\n   * Prepares the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}. Use\n   * {@link #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)} to\n   * publish the returned {@link SegmentInfo} together with its segment private\n   * delete packet.\n   * \n   * @see #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)\n   */\n  SegmentInfo prepareFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfo newSegment = flushedSegment.segmentInfo;\n\n    setDiagnostics(newSegment, \"flush\");\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.docCount, newSegment.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      if (useCompoundFile(newSegment)) {\n\n        // Now build compound file\n        Collection<String> oldFiles = createCompoundFile(infoStream, directory, MergeState.CheckAbort.NONE, newSegment, context);\n        newSegment.setUseCompoundFile(true);\n        \n        synchronized(this) {\n          deleter.deleteNewFiles(oldFiles);\n        }\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfosFormat().getSegmentInfosWriter().write(directory, newSegment, flushedSegment.fieldInfos, context);\n      newSegment.clearFilesCache();\n\n      // nocommit ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfo info = flushedSegment.segmentInfo;\n        Codec codec = info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"hit exception \" +\n              \"reating compound file for newly flushed segment \" + newSegment.name);\n        }\n\n        synchronized(this) {\n          deleter.refresh(newSegment.name);\n        }\n      }\n    }\n    return newSegment;\n  }\n\n","sourceOld":"  /**\n   * Prepares the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}. Use\n   * {@link #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)} to\n   * publish the returned {@link SegmentInfo} together with its segment private\n   * delete packet.\n   * \n   * @see #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)\n   */\n  SegmentInfo prepareFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfo newSegment = flushedSegment.segmentInfo;\n\n    setDiagnostics(newSegment, \"flush\");\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.docCount, newSegment.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      if (useCompoundFile(newSegment)) {\n        String compoundFileName = IndexFileNames.segmentFileName(newSegment.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION);\n\n        // Now build compound file\n        Collection<String> files = createCompoundFile(infoStream, directory, compoundFileName, MergeState.CheckAbort.NONE, newSegment, context);\n        newSegment.setUseCompoundFile(true);\n        \n        synchronized(this) {\n          deleter.deleteNewFiles(files);\n        }\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfosFormat().getSegmentInfosWriter().write(directory, newSegment, flushedSegment.fieldInfos, context);\n      newSegment.clearFilesCache();\n\n      // nocommit ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfo info = flushedSegment.segmentInfo;\n        Codec codec = info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"hit exception \" +\n              \"reating compound file for newly flushed segment \" + newSegment.name);\n        }\n\n        synchronized(this) {\n          deleter.refresh(newSegment.name);\n        }\n      }\n    }\n    return newSegment;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9a46feaa8775cb79964b568371b8eedaef5f576b","date":1337620767,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareFlushedSegment(FlushedSegment).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareFlushedSegment(FlushedSegment).mjava","sourceNew":"  /**\n   * Prepares the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}. Use\n   * {@link #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)} to\n   * publish the returned {@link SegmentInfo} together with its segment private\n   * delete packet.\n   * \n   * @see #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)\n   */\n  SegmentInfo prepareFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfo newSegment = flushedSegment.segmentInfo;\n\n    setDiagnostics(newSegment, \"flush\");\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.docCount, newSegment.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      if (useCompoundFile(newSegment)) {\n\n        // Now build compound file\n        Collection<String> oldFiles = createCompoundFile(infoStream, directory, MergeState.CheckAbort.NONE, newSegment, context);\n        newSegment.setUseCompoundFile(true);\n        \n        synchronized(this) {\n          deleter.deleteNewFiles(oldFiles);\n        }\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfosFormat().getSegmentInfosWriter().write(directory, newSegment, flushedSegment.fieldInfos, context);\n\n      // nocommit ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfo info = flushedSegment.segmentInfo;\n        Codec codec = info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"hit exception \" +\n              \"reating compound file for newly flushed segment \" + newSegment.name);\n        }\n\n        synchronized(this) {\n          deleter.refresh(newSegment.name);\n        }\n      }\n    }\n    return newSegment;\n  }\n\n","sourceOld":"  /**\n   * Prepares the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}. Use\n   * {@link #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)} to\n   * publish the returned {@link SegmentInfo} together with its segment private\n   * delete packet.\n   * \n   * @see #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)\n   */\n  SegmentInfo prepareFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfo newSegment = flushedSegment.segmentInfo;\n\n    setDiagnostics(newSegment, \"flush\");\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.docCount, newSegment.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      if (useCompoundFile(newSegment)) {\n\n        // Now build compound file\n        Collection<String> oldFiles = createCompoundFile(infoStream, directory, MergeState.CheckAbort.NONE, newSegment, context);\n        newSegment.setUseCompoundFile(true);\n        \n        synchronized(this) {\n          deleter.deleteNewFiles(oldFiles);\n        }\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfosFormat().getSegmentInfosWriter().write(directory, newSegment, flushedSegment.fieldInfos, context);\n      newSegment.clearFilesCache();\n\n      // nocommit ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfo info = flushedSegment.segmentInfo;\n        Codec codec = info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"hit exception \" +\n              \"reating compound file for newly flushed segment \" + newSegment.name);\n        }\n\n        synchronized(this) {\n          deleter.refresh(newSegment.name);\n        }\n      }\n    }\n    return newSegment;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"22b3128eea8c61f8f1f387dac6b3e9504bc8036e","date":1337625491,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareFlushedSegment(FlushedSegment).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareFlushedSegment(FlushedSegment).mjava","sourceNew":"  /**\n   * Prepares the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}. Use\n   * {@link #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)} to\n   * publish the returned {@link SegmentInfo} together with its segment private\n   * delete packet.\n   * \n   * @see #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)\n   */\n  SegmentInfo prepareFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfo newSegment = flushedSegment.segmentInfo;\n\n    setDiagnostics(newSegment, \"flush\");\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.docCount, newSegment.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      if (useCompoundFile(newSegment)) {\n\n        // Now build compound file\n        Collection<String> oldFiles = createCompoundFile(infoStream, directory, MergeState.CheckAbort.NONE, newSegment, context);\n        newSegment.setUseCompoundFile(true);\n        \n        synchronized(this) {\n          deleter.deleteNewFiles(oldFiles);\n        }\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfosFormat().getSegmentInfosWriter().write(directory, newSegment, flushedSegment.fieldInfos, context);\n\n      // nocommit ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfo info = flushedSegment.segmentInfo;\n        Codec codec = info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"hit exception \" +\n              \"reating compound file for newly flushed segment \" + newSegment.name);\n        }\n\n        synchronized(this) {\n          deleter.refresh(newSegment.name);\n        }\n      }\n    }\n    return newSegment;\n  }\n\n","sourceOld":"  /**\n   * Prepares the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}. Use\n   * {@link #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)} to\n   * publish the returned {@link SegmentInfo} together with its segment private\n   * delete packet.\n   * \n   * @see #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)\n   */\n  SegmentInfo prepareFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfo newSegment = flushedSegment.segmentInfo;\n\n    setDiagnostics(newSegment, \"flush\");\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.docCount, newSegment.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      if (useCompoundFile(newSegment)) {\n\n        // Now build compound file\n        Collection<String> oldFiles = createCompoundFile(infoStream, directory, MergeState.CheckAbort.NONE, newSegment, context);\n        newSegment.setUseCompoundFile(true);\n        \n        synchronized(this) {\n          deleter.deleteNewFiles(oldFiles);\n        }\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfosFormat().getSegmentInfosWriter().write(directory, newSegment, flushedSegment.fieldInfos, context);\n\n      // nocommit ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfo info = flushedSegment.segmentInfo;\n        Codec codec = info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"hit exception \" +\n              \"reating compound file for newly flushed segment \" + newSegment.name);\n        }\n\n        synchronized(this) {\n          deleter.refresh(newSegment.name);\n        }\n      }\n    }\n    return newSegment;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9d153abcf92dc5329d98571a8c3035df9bd80648","date":1337702630,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareFlushedSegment(FlushedSegment).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareFlushedSegment(FlushedSegment).mjava","sourceNew":"  /**\n   * Prepares the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}. Use\n   * {@link #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)} to\n   * publish the returned {@link SegmentInfo} together with its segment private\n   * delete packet.\n   * \n   * @see #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)\n   */\n  SegmentInfoPerCommit prepareFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfoPerCommit newSegment = flushedSegment.segmentInfo;\n\n    setDiagnostics(newSegment.info, \"flush\");\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.docCount, newSegment.info.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      if (useCompoundFile(newSegment)) {\n\n        // Now build compound file\n        Collection<String> oldFiles = createCompoundFile(infoStream, directory, MergeState.CheckAbort.NONE, newSegment.info, context);\n        newSegment.info.setUseCompoundFile(true);\n        \n        synchronized(this) {\n          deleter.deleteNewFiles(oldFiles);\n        }\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfosFormat().getSegmentInfosWriter().write(directory, newSegment.info, flushedSegment.fieldInfos, context);\n\n      // nocommit ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfoPerCommit info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"hit exception \" +\n              \"reating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n\n        synchronized(this) {\n          deleter.refresh(newSegment.info.name);\n        }\n      }\n    }\n    return newSegment;\n  }\n\n","sourceOld":"  /**\n   * Prepares the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}. Use\n   * {@link #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)} to\n   * publish the returned {@link SegmentInfo} together with its segment private\n   * delete packet.\n   * \n   * @see #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)\n   */\n  SegmentInfo prepareFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfo newSegment = flushedSegment.segmentInfo;\n\n    setDiagnostics(newSegment, \"flush\");\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.docCount, newSegment.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      if (useCompoundFile(newSegment)) {\n\n        // Now build compound file\n        Collection<String> oldFiles = createCompoundFile(infoStream, directory, MergeState.CheckAbort.NONE, newSegment, context);\n        newSegment.setUseCompoundFile(true);\n        \n        synchronized(this) {\n          deleter.deleteNewFiles(oldFiles);\n        }\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfosFormat().getSegmentInfosWriter().write(directory, newSegment, flushedSegment.fieldInfos, context);\n\n      // nocommit ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfo info = flushedSegment.segmentInfo;\n        Codec codec = info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"hit exception \" +\n              \"reating compound file for newly flushed segment \" + newSegment.name);\n        }\n\n        synchronized(this) {\n          deleter.refresh(newSegment.name);\n        }\n      }\n    }\n    return newSegment;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9ee159418514037b0fa456cf8b5d6c91e2bf5557","date":1337721836,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareFlushedSegment(FlushedSegment).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareFlushedSegment(FlushedSegment).mjava","sourceNew":"  /**\n   * Prepares the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}. Use\n   * {@link #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)} to\n   * publish the returned {@link SegmentInfo} together with its segment private\n   * delete packet.\n   * \n   * @see #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)\n   */\n  SegmentInfoPerCommit prepareFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfoPerCommit newSegment = flushedSegment.segmentInfo;\n\n    setDiagnostics(newSegment.info, \"flush\");\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.docCount, newSegment.info.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      if (useCompoundFile(newSegment)) {\n\n        // Now build compound file\n        Collection<String> oldFiles = createCompoundFile(infoStream, directory, MergeState.CheckAbort.NONE, newSegment.info, context);\n        newSegment.info.setUseCompoundFile(true);\n        \n        synchronized(this) {\n          deleter.deleteNewFiles(oldFiles);\n        }\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().getSegmentInfosWriter().write(directory, newSegment.info, flushedSegment.fieldInfos, context);\n\n      // nocommit ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfoPerCommit info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"hit exception \" +\n              \"reating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n\n        synchronized(this) {\n          deleter.refresh(newSegment.info.name);\n        }\n      }\n    }\n    return newSegment;\n  }\n\n","sourceOld":"  /**\n   * Prepares the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}. Use\n   * {@link #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)} to\n   * publish the returned {@link SegmentInfo} together with its segment private\n   * delete packet.\n   * \n   * @see #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)\n   */\n  SegmentInfoPerCommit prepareFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfoPerCommit newSegment = flushedSegment.segmentInfo;\n\n    setDiagnostics(newSegment.info, \"flush\");\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.docCount, newSegment.info.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      if (useCompoundFile(newSegment)) {\n\n        // Now build compound file\n        Collection<String> oldFiles = createCompoundFile(infoStream, directory, MergeState.CheckAbort.NONE, newSegment.info, context);\n        newSegment.info.setUseCompoundFile(true);\n        \n        synchronized(this) {\n          deleter.deleteNewFiles(oldFiles);\n        }\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfosFormat().getSegmentInfosWriter().write(directory, newSegment.info, flushedSegment.fieldInfos, context);\n\n      // nocommit ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfoPerCommit info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"hit exception \" +\n              \"reating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n\n        synchronized(this) {\n          deleter.refresh(newSegment.info.name);\n        }\n      }\n    }\n    return newSegment;\n  }\n\n","bugFix":null,"bugIntro":["2edef7afebca00bf81a8bef95d44ea971ba309fa"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fb5728b83dbb3e002cdd22adfe6caf103a96ef15","date":1337791289,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareFlushedSegment(FlushedSegment).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareFlushedSegment(FlushedSegment).mjava","sourceNew":"  /**\n   * Prepares the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}. Use\n   * {@link #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)} to\n   * publish the returned {@link SegmentInfo} together with its segment private\n   * delete packet.\n   * \n   * @see #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)\n   */\n  SegmentInfoPerCommit prepareFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfoPerCommit newSegment = flushedSegment.segmentInfo;\n\n    setDiagnostics(newSegment.info, \"flush\");\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.docCount, newSegment.info.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      if (useCompoundFile(newSegment)) {\n\n        // Now build compound file\n        Collection<String> oldFiles = createCompoundFile(infoStream, directory, MergeState.CheckAbort.NONE, newSegment.info, context);\n        newSegment.info.setUseCompoundFile(true);\n        \n        synchronized(this) {\n          deleter.deleteNewFiles(oldFiles);\n        }\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().getSegmentInfosWriter().write(directory, newSegment.info, flushedSegment.fieldInfos, context);\n\n      // TODO: ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfoPerCommit info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"hit exception \" +\n              \"reating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n\n        synchronized(this) {\n          deleter.refresh(newSegment.info.name);\n        }\n      }\n    }\n    return newSegment;\n  }\n\n","sourceOld":"  /**\n   * Prepares the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}. Use\n   * {@link #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)} to\n   * publish the returned {@link SegmentInfo} together with its segment private\n   * delete packet.\n   * \n   * @see #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)\n   */\n  SegmentInfoPerCommit prepareFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfoPerCommit newSegment = flushedSegment.segmentInfo;\n\n    setDiagnostics(newSegment.info, \"flush\");\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.docCount, newSegment.info.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      if (useCompoundFile(newSegment)) {\n\n        // Now build compound file\n        Collection<String> oldFiles = createCompoundFile(infoStream, directory, MergeState.CheckAbort.NONE, newSegment.info, context);\n        newSegment.info.setUseCompoundFile(true);\n        \n        synchronized(this) {\n          deleter.deleteNewFiles(oldFiles);\n        }\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().getSegmentInfosWriter().write(directory, newSegment.info, flushedSegment.fieldInfos, context);\n\n      // nocommit ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfoPerCommit info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"hit exception \" +\n              \"reating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n\n        synchronized(this) {\n          deleter.refresh(newSegment.info.name);\n        }\n      }\n    }\n    return newSegment;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"203d7d3cb7712e10ef33009a63247ae40c302d7a","date":1337798111,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareFlushedSegment(FlushedSegment).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareFlushedSegment(FlushedSegment).mjava","sourceNew":"  /**\n   * Prepares the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}. Use\n   * {@link #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)} to\n   * publish the returned {@link SegmentInfo} together with its segment private\n   * delete packet.\n   * \n   * @see #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)\n   */\n  SegmentInfoPerCommit prepareFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfoPerCommit newSegment = flushedSegment.segmentInfo;\n\n    setDiagnostics(newSegment.info, \"flush\");\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.getDocCount(), newSegment.info.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      if (useCompoundFile(newSegment)) {\n\n        // Now build compound file\n        Collection<String> oldFiles = createCompoundFile(infoStream, directory, MergeState.CheckAbort.NONE, newSegment.info, context);\n        newSegment.info.setUseCompoundFile(true);\n        \n        synchronized(this) {\n          deleter.deleteNewFiles(oldFiles);\n        }\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().getSegmentInfosWriter().write(directory, newSegment.info, flushedSegment.fieldInfos, context);\n\n      // TODO: ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfoPerCommit info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"hit exception \" +\n              \"reating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n\n        synchronized(this) {\n          deleter.refresh(newSegment.info.name);\n        }\n      }\n    }\n    return newSegment;\n  }\n\n","sourceOld":"  /**\n   * Prepares the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}. Use\n   * {@link #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)} to\n   * publish the returned {@link SegmentInfo} together with its segment private\n   * delete packet.\n   * \n   * @see #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)\n   */\n  SegmentInfoPerCommit prepareFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfoPerCommit newSegment = flushedSegment.segmentInfo;\n\n    setDiagnostics(newSegment.info, \"flush\");\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.docCount, newSegment.info.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      if (useCompoundFile(newSegment)) {\n\n        // Now build compound file\n        Collection<String> oldFiles = createCompoundFile(infoStream, directory, MergeState.CheckAbort.NONE, newSegment.info, context);\n        newSegment.info.setUseCompoundFile(true);\n        \n        synchronized(this) {\n          deleter.deleteNewFiles(oldFiles);\n        }\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().getSegmentInfosWriter().write(directory, newSegment.info, flushedSegment.fieldInfos, context);\n\n      // TODO: ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfoPerCommit info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"hit exception \" +\n              \"reating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n\n        synchronized(this) {\n          deleter.refresh(newSegment.info.name);\n        }\n      }\n    }\n    return newSegment;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"615ddbd81799980d0fdd95e0238e1c498b6f47b0","date":1338233290,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareFlushedSegment(FlushedSegment).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareFlushedSegment(FlushedSegment).mjava","sourceNew":"  /**\n   * Prepares the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}. Use\n   * {@link #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)} to\n   * publish the returned {@link SegmentInfo} together with its segment private\n   * delete packet.\n   * \n   * @see #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)\n   */\n  SegmentInfoPerCommit prepareFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfoPerCommit newSegment = flushedSegment.segmentInfo;\n\n    setDiagnostics(newSegment.info, \"flush\");\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.getDocCount(), newSegment.info.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      if (useCompoundFile(newSegment)) {\n\n        // Now build compound file\n        Collection<String> oldFiles = createCompoundFile(infoStream, directory, MergeState.CheckAbort.NONE, newSegment.info, context);\n        newSegment.info.setUseCompoundFile(true);\n        \n        synchronized(this) {\n          deleter.deleteNewFiles(oldFiles);\n        }\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().getSegmentInfosWriter().write(directory, newSegment.info, flushedSegment.fieldInfos, context);\n\n      // TODO: ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfoPerCommit info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"hit exception \" +\n              \"reating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n\n        synchronized(this) {\n          deleter.refresh(newSegment.info.name);\n        }\n      }\n    }\n    return newSegment;\n  }\n\n","sourceOld":"  /**\n   * Prepares the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}. Use\n   * {@link #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)} to\n   * publish the returned {@link SegmentInfo} together with its segment private\n   * delete packet.\n   * \n   * @see #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)\n   */\n  SegmentInfo prepareFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfo newSegment = flushedSegment.segmentInfo;\n\n    setDiagnostics(newSegment, \"flush\");\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.docCount, newSegment.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      if (useCompoundFile(newSegment)) {\n        String compoundFileName = IndexFileNames.segmentFileName(newSegment.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION);\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"creating compound file \" + compoundFileName);\n        }\n        // Now build compound file\n        final Directory cfsDir = new CompoundFileDirectory(directory, compoundFileName, context, true);\n        IOException prior = null;\n        try {\n          for(String fileName : newSegment.files()) {\n            directory.copy(cfsDir, fileName, fileName, context);\n          }\n        } catch(IOException ex) {\n          prior = ex;\n        } finally {\n          IOUtils.closeWhileHandlingException(prior, cfsDir);\n        }\n        // Perform the merge\n        \n        synchronized(this) {\n          deleter.deleteNewFiles(newSegment.files());\n        }\n\n        newSegment.setUseCompoundFile(true);\n      }\n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfo info = flushedSegment.segmentInfo;\n        Codec codec = info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, context);\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"hit exception \" +\n              \"reating compound file for newly flushed segment \" + newSegment.name);\n        }\n\n        synchronized(this) {\n          deleter.refresh(newSegment.name);\n        }\n      }\n    }\n    return newSegment;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2edef7afebca00bf81a8bef95d44ea971ba309fa","date":1339101284,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareFlushedSegment(FlushedSegment).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareFlushedSegment(FlushedSegment).mjava","sourceNew":"  /**\n   * Prepares the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}. Use\n   * {@link #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)} to\n   * publish the returned {@link SegmentInfo} together with its segment private\n   * delete packet.\n   * \n   * @see #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)\n   */\n  SegmentInfoPerCommit prepareFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfoPerCommit newSegment = flushedSegment.segmentInfo;\n\n    setDiagnostics(newSegment.info, \"flush\");\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.getDocCount(), newSegment.info.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      if (useCompoundFile(newSegment)) {\n\n        // Now build compound file\n        Collection<String> oldFiles = createCompoundFile(infoStream, directory, MergeState.CheckAbort.NONE, newSegment.info, context);\n        newSegment.info.setUseCompoundFile(true);\n        \n        synchronized(this) {\n          deleter.deleteNewFiles(oldFiles);\n        }\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, newSegment.info, flushedSegment.fieldInfos, context);\n\n      // TODO: ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfoPerCommit info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"hit exception \" +\n              \"reating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n\n        synchronized(this) {\n          deleter.refresh(newSegment.info.name);\n        }\n      }\n    }\n    return newSegment;\n  }\n\n","sourceOld":"  /**\n   * Prepares the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}. Use\n   * {@link #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)} to\n   * publish the returned {@link SegmentInfo} together with its segment private\n   * delete packet.\n   * \n   * @see #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)\n   */\n  SegmentInfoPerCommit prepareFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfoPerCommit newSegment = flushedSegment.segmentInfo;\n\n    setDiagnostics(newSegment.info, \"flush\");\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.getDocCount(), newSegment.info.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      if (useCompoundFile(newSegment)) {\n\n        // Now build compound file\n        Collection<String> oldFiles = createCompoundFile(infoStream, directory, MergeState.CheckAbort.NONE, newSegment.info, context);\n        newSegment.info.setUseCompoundFile(true);\n        \n        synchronized(this) {\n          deleter.deleteNewFiles(oldFiles);\n        }\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().getSegmentInfosWriter().write(directory, newSegment.info, flushedSegment.fieldInfos, context);\n\n      // TODO: ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfoPerCommit info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"hit exception \" +\n              \"reating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n\n        synchronized(this) {\n          deleter.refresh(newSegment.info.name);\n        }\n      }\n    }\n    return newSegment;\n  }\n\n","bugFix":["9ee159418514037b0fa456cf8b5d6c91e2bf5557"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bd9ddb59e9d33950773d186a8b726b5610ae3aad","date":1341258232,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareFlushedSegment(FlushedSegment).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareFlushedSegment(FlushedSegment).mjava","sourceNew":"  /**\n   * Prepares the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}. Use\n   * {@link #publishFlushedSegment(SegmentInfoPerCommit, FrozenBufferedDeletes, FrozenBufferedDeletes)} to\n   * publish the returned {@link SegmentInfo} together with its segment private\n   * delete packet.\n   * \n   * @see #publishFlushedSegment(SegmentInfoPerCommit, FrozenBufferedDeletes, FrozenBufferedDeletes)\n   */\n  SegmentInfoPerCommit prepareFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfoPerCommit newSegment = flushedSegment.segmentInfo;\n\n    setDiagnostics(newSegment.info, \"flush\");\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.getDocCount(), newSegment.info.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      if (useCompoundFile(newSegment)) {\n\n        // Now build compound file\n        Collection<String> oldFiles = createCompoundFile(infoStream, directory, MergeState.CheckAbort.NONE, newSegment.info, context);\n        newSegment.info.setUseCompoundFile(true);\n        \n        synchronized(this) {\n          deleter.deleteNewFiles(oldFiles);\n        }\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, newSegment.info, flushedSegment.fieldInfos, context);\n\n      // TODO: ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfoPerCommit info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"hit exception \" +\n              \"reating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n\n        synchronized(this) {\n          deleter.refresh(newSegment.info.name);\n        }\n      }\n    }\n    return newSegment;\n  }\n\n","sourceOld":"  /**\n   * Prepares the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}. Use\n   * {@link #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)} to\n   * publish the returned {@link SegmentInfo} together with its segment private\n   * delete packet.\n   * \n   * @see #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)\n   */\n  SegmentInfoPerCommit prepareFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfoPerCommit newSegment = flushedSegment.segmentInfo;\n\n    setDiagnostics(newSegment.info, \"flush\");\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.getDocCount(), newSegment.info.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      if (useCompoundFile(newSegment)) {\n\n        // Now build compound file\n        Collection<String> oldFiles = createCompoundFile(infoStream, directory, MergeState.CheckAbort.NONE, newSegment.info, context);\n        newSegment.info.setUseCompoundFile(true);\n        \n        synchronized(this) {\n          deleter.deleteNewFiles(oldFiles);\n        }\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, newSegment.info, flushedSegment.fieldInfos, context);\n\n      // TODO: ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfoPerCommit info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"hit exception \" +\n              \"reating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n\n        synchronized(this) {\n          deleter.refresh(newSegment.info.name);\n        }\n      }\n    }\n    return newSegment;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fe33227f6805edab2036cbb80645cc4e2d1fa424","date":1342713534,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareFlushedSegment(FlushedSegment).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareFlushedSegment(FlushedSegment).mjava","sourceNew":"  /**\n   * Prepares the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}. Use\n   * {@link #publishFlushedSegment(SegmentInfoPerCommit, FrozenBufferedDeletes, FrozenBufferedDeletes)} to\n   * publish the returned {@link SegmentInfo} together with its segment private\n   * delete packet.\n   * \n   * @see #publishFlushedSegment(SegmentInfoPerCommit, FrozenBufferedDeletes, FrozenBufferedDeletes)\n   */\n  SegmentInfoPerCommit prepareFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfoPerCommit newSegment = flushedSegment.segmentInfo;\n\n    setDiagnostics(newSegment.info, \"flush\");\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.getDocCount(), newSegment.info.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      if (useCompoundFile(newSegment)) {\n\n        // Now build compound file\n        Collection<String> oldFiles = createCompoundFile(infoStream, directory, MergeState.CheckAbort.NONE, newSegment.info, context);\n        newSegment.info.setUseCompoundFile(true);\n        \n        synchronized(this) {\n          deleter.deleteNewFiles(oldFiles);\n        }\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, newSegment.info, flushedSegment.fieldInfos, context);\n\n      // TODO: ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfoPerCommit info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"hit exception \" +\n              \"reating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n\n        synchronized(this) {\n          deleter.refresh(newSegment.info.name);\n        }\n      }\n    }\n    return newSegment;\n  }\n\n","sourceOld":"  /**\n   * Prepares the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}. Use\n   * {@link #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)} to\n   * publish the returned {@link SegmentInfo} together with its segment private\n   * delete packet.\n   * \n   * @see #publishFlushedSegment(SegmentInfo, FrozenBufferedDeletes, FrozenBufferedDeletes)\n   */\n  SegmentInfoPerCommit prepareFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfoPerCommit newSegment = flushedSegment.segmentInfo;\n\n    setDiagnostics(newSegment.info, \"flush\");\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.getDocCount(), newSegment.info.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      if (useCompoundFile(newSegment)) {\n\n        // Now build compound file\n        Collection<String> oldFiles = createCompoundFile(infoStream, directory, MergeState.CheckAbort.NONE, newSegment.info, context);\n        newSegment.info.setUseCompoundFile(true);\n        \n        synchronized(this) {\n          deleter.deleteNewFiles(oldFiles);\n        }\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, newSegment.info, flushedSegment.fieldInfos, context);\n\n      // TODO: ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfoPerCommit info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"hit exception \" +\n              \"reating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n\n        synchronized(this) {\n          deleter.refresh(newSegment.info.name);\n        }\n      }\n    }\n    return newSegment;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9eae2a56dc810a17cf807d831f720dec931a03de","date":1349262073,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareFlushedSegment(FlushedSegment).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareFlushedSegment(FlushedSegment).mjava","sourceNew":"  /**\n   * Prepares the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}. Use\n   * {@link #publishFlushedSegment(SegmentInfoPerCommit, FrozenBufferedDeletes, FrozenBufferedDeletes)} to\n   * publish the returned {@link SegmentInfo} together with its segment private\n   * delete packet.\n   * \n   * @see #publishFlushedSegment(SegmentInfoPerCommit, FrozenBufferedDeletes, FrozenBufferedDeletes)\n   */\n  SegmentInfoPerCommit prepareFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfoPerCommit newSegment = flushedSegment.segmentInfo;\n\n    setDiagnostics(newSegment.info, \"flush\");\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.getDocCount(), newSegment.info.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      if (useCompoundFile(newSegment)) {\n\n        // Now build compound file\n        Collection<String> oldFiles = createCompoundFile(infoStream, directory, MergeState.CheckAbort.NONE, newSegment.info, context);\n        newSegment.info.setUseCompoundFile(true);\n\n        synchronized(this) {\n          deleter.deleteNewFiles(oldFiles);\n        }\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, newSegment.info, flushedSegment.fieldInfos, context);\n\n      // TODO: ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfoPerCommit info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"hit exception \" +\n              \"reating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n\n        synchronized(this) {\n          deleter.refresh(newSegment.info.name);\n        }\n      }\n    }\n    return newSegment;\n  }\n\n","sourceOld":"  /**\n   * Prepares the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}. Use\n   * {@link #publishFlushedSegment(SegmentInfoPerCommit, FrozenBufferedDeletes, FrozenBufferedDeletes)} to\n   * publish the returned {@link SegmentInfo} together with its segment private\n   * delete packet.\n   * \n   * @see #publishFlushedSegment(SegmentInfoPerCommit, FrozenBufferedDeletes, FrozenBufferedDeletes)\n   */\n  SegmentInfoPerCommit prepareFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfoPerCommit newSegment = flushedSegment.segmentInfo;\n\n    setDiagnostics(newSegment.info, \"flush\");\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.getDocCount(), newSegment.info.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      if (useCompoundFile(newSegment)) {\n\n        // Now build compound file\n        Collection<String> oldFiles = createCompoundFile(infoStream, directory, MergeState.CheckAbort.NONE, newSegment.info, context);\n        newSegment.info.setUseCompoundFile(true);\n        \n        synchronized(this) {\n          deleter.deleteNewFiles(oldFiles);\n        }\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, newSegment.info, flushedSegment.fieldInfos, context);\n\n      // TODO: ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfoPerCommit info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"hit exception \" +\n              \"reating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n\n        synchronized(this) {\n          deleter.refresh(newSegment.info.name);\n        }\n      }\n    }\n    return newSegment;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c6bb01d819ee2a06924d25bb5683fe4dcf8cf1a7","date":1349855720,"type":5,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#sealFlushedSegment(FlushedSegment).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareFlushedSegment(FlushedSegment).mjava","sourceNew":"  /**\n   * Seals the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}.\n   */\n  void sealFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfoPerCommit newSegment = flushedSegment.segmentInfo;\n\n    IndexWriter.setDiagnostics(newSegment.info, \"flush\");\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.getDocCount(), newSegment.info.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      if (writer.useCompoundFile(newSegment)) {\n\n        // Now build compound file\n        Collection<String> oldFiles = IndexWriter.createCompoundFile(infoStream, directory, MergeState.CheckAbort.NONE, newSegment.info, context);\n        newSegment.info.setUseCompoundFile(true);\n        writer.deleteNewFiles(oldFiles);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, newSegment.info, flushedSegment.fieldInfos, context);\n\n      // TODO: ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfoPerCommit info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"hit exception \" +\n              \"reating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n        writer.flushFailed(newSegment.info);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Prepares the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}. Use\n   * {@link #publishFlushedSegment(SegmentInfoPerCommit, FrozenBufferedDeletes, FrozenBufferedDeletes)} to\n   * publish the returned {@link SegmentInfo} together with its segment private\n   * delete packet.\n   * \n   * @see #publishFlushedSegment(SegmentInfoPerCommit, FrozenBufferedDeletes, FrozenBufferedDeletes)\n   */\n  SegmentInfoPerCommit prepareFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfoPerCommit newSegment = flushedSegment.segmentInfo;\n\n    setDiagnostics(newSegment.info, \"flush\");\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.getDocCount(), newSegment.info.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      if (useCompoundFile(newSegment)) {\n\n        // Now build compound file\n        Collection<String> oldFiles = createCompoundFile(infoStream, directory, MergeState.CheckAbort.NONE, newSegment.info, context);\n        newSegment.info.setUseCompoundFile(true);\n\n        synchronized(this) {\n          deleter.deleteNewFiles(oldFiles);\n        }\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, newSegment.info, flushedSegment.fieldInfos, context);\n\n      // TODO: ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfoPerCommit info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"hit exception \" +\n              \"reating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n\n        synchronized(this) {\n          deleter.refresh(newSegment.info.name);\n        }\n      }\n    }\n    return newSegment;\n  }\n\n","bugFix":null,"bugIntro":["fdc3f2b9a4e1c1aacfa53b304c4e42c13a1677ef"],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"fb5728b83dbb3e002cdd22adfe6caf103a96ef15":["9ee159418514037b0fa456cf8b5d6c91e2bf5557"],"9eae2a56dc810a17cf807d831f720dec931a03de":["bd9ddb59e9d33950773d186a8b726b5610ae3aad"],"9a46feaa8775cb79964b568371b8eedaef5f576b":["1494abe5dc85557ec2e2772f87660d48f831c3a5"],"352763be0465236f8e2ac188aa1b761cb3e1c9ee":["4356000e349e38c9fb48034695b7c309abd54557"],"2edef7afebca00bf81a8bef95d44ea971ba309fa":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"9d153abcf92dc5329d98571a8c3035df9bd80648":["22b3128eea8c61f8f1f387dac6b3e9504bc8036e"],"9b2af6b2c05418fb9df466c739ed5b3a153eadde":["352763be0465236f8e2ac188aa1b761cb3e1c9ee"],"f3a2f7df6ce044e8e7f5fe84cb5b23682fa1b27d":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"c6bb01d819ee2a06924d25bb5683fe4dcf8cf1a7":["9eae2a56dc810a17cf807d831f720dec931a03de"],"1494abe5dc85557ec2e2772f87660d48f831c3a5":["9b2af6b2c05418fb9df466c739ed5b3a153eadde"],"bd9ddb59e9d33950773d186a8b726b5610ae3aad":["2edef7afebca00bf81a8bef95d44ea971ba309fa"],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["f3a2f7df6ce044e8e7f5fe84cb5b23682fa1b27d","203d7d3cb7712e10ef33009a63247ae40c302d7a"],"4356000e349e38c9fb48034695b7c309abd54557":["f0b406f1c9ada78b8fe2b12dfa87e9f76d35618c"],"f0b406f1c9ada78b8fe2b12dfa87e9f76d35618c":["f3a2f7df6ce044e8e7f5fe84cb5b23682fa1b27d"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":["2edef7afebca00bf81a8bef95d44ea971ba309fa","bd9ddb59e9d33950773d186a8b726b5610ae3aad"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"9ee159418514037b0fa456cf8b5d6c91e2bf5557":["9d153abcf92dc5329d98571a8c3035df9bd80648"],"22b3128eea8c61f8f1f387dac6b3e9504bc8036e":["9a46feaa8775cb79964b568371b8eedaef5f576b"],"203d7d3cb7712e10ef33009a63247ae40c302d7a":["fb5728b83dbb3e002cdd22adfe6caf103a96ef15"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["c6bb01d819ee2a06924d25bb5683fe4dcf8cf1a7"]},"commit2Childs":{"fb5728b83dbb3e002cdd22adfe6caf103a96ef15":["203d7d3cb7712e10ef33009a63247ae40c302d7a"],"9eae2a56dc810a17cf807d831f720dec931a03de":["c6bb01d819ee2a06924d25bb5683fe4dcf8cf1a7"],"9a46feaa8775cb79964b568371b8eedaef5f576b":["22b3128eea8c61f8f1f387dac6b3e9504bc8036e"],"352763be0465236f8e2ac188aa1b761cb3e1c9ee":["9b2af6b2c05418fb9df466c739ed5b3a153eadde"],"2edef7afebca00bf81a8bef95d44ea971ba309fa":["bd9ddb59e9d33950773d186a8b726b5610ae3aad","fe33227f6805edab2036cbb80645cc4e2d1fa424"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["f3a2f7df6ce044e8e7f5fe84cb5b23682fa1b27d"],"9d153abcf92dc5329d98571a8c3035df9bd80648":["9ee159418514037b0fa456cf8b5d6c91e2bf5557"],"9b2af6b2c05418fb9df466c739ed5b3a153eadde":["1494abe5dc85557ec2e2772f87660d48f831c3a5"],"f3a2f7df6ce044e8e7f5fe84cb5b23682fa1b27d":["615ddbd81799980d0fdd95e0238e1c498b6f47b0","f0b406f1c9ada78b8fe2b12dfa87e9f76d35618c"],"c6bb01d819ee2a06924d25bb5683fe4dcf8cf1a7":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"1494abe5dc85557ec2e2772f87660d48f831c3a5":["9a46feaa8775cb79964b568371b8eedaef5f576b"],"bd9ddb59e9d33950773d186a8b726b5610ae3aad":["9eae2a56dc810a17cf807d831f720dec931a03de","fe33227f6805edab2036cbb80645cc4e2d1fa424"],"4356000e349e38c9fb48034695b7c309abd54557":["352763be0465236f8e2ac188aa1b761cb3e1c9ee"],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["2edef7afebca00bf81a8bef95d44ea971ba309fa"],"f0b406f1c9ada78b8fe2b12dfa87e9f76d35618c":["4356000e349e38c9fb48034695b7c309abd54557"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"9ee159418514037b0fa456cf8b5d6c91e2bf5557":["fb5728b83dbb3e002cdd22adfe6caf103a96ef15"],"22b3128eea8c61f8f1f387dac6b3e9504bc8036e":["9d153abcf92dc5329d98571a8c3035df9bd80648"],"203d7d3cb7712e10ef33009a63247ae40c302d7a":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["fe33227f6805edab2036cbb80645cc4e2d1fa424","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}