{"path":"lucene/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/SentenceTokenizer#incrementToken().mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/SentenceTokenizer#incrementToken().mjava","pathOld":"contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/SentenceTokenizer#incrementToken().mjava","sourceNew":"  @Override\n  public boolean incrementToken() throws IOException {\n    clearAttributes();\n    buffer.setLength(0);\n    int ci;\n    char ch, pch;\n    boolean atBegin = true;\n    tokenStart = tokenEnd;\n    ci = input.read();\n    ch = (char) ci;\n\n    while (true) {\n      if (ci == -1) {\n        break;\n      } else if (PUNCTION.indexOf(ch) != -1) {\n        // End of a sentence\n        buffer.append(ch);\n        tokenEnd++;\n        break;\n      } else if (atBegin && Utility.SPACES.indexOf(ch) != -1) {\n        tokenStart++;\n        tokenEnd++;\n        ci = input.read();\n        ch = (char) ci;\n      } else {\n        buffer.append(ch);\n        atBegin = false;\n        tokenEnd++;\n        pch = ch;\n        ci = input.read();\n        ch = (char) ci;\n        // Two spaces, such as CR, LF\n        if (Utility.SPACES.indexOf(ch) != -1\n            && Utility.SPACES.indexOf(pch) != -1) {\n          // buffer.append(ch);\n          tokenEnd++;\n          break;\n        }\n      }\n    }\n    if (buffer.length() == 0)\n      return false;\n    else {\n      termAtt.setTermBuffer(buffer.toString());\n      offsetAtt.setOffset(correctOffset(tokenStart), correctOffset(tokenEnd));\n      typeAtt.setType(\"sentence\");\n      return true;\n    }\n  }\n\n","sourceOld":"  @Override\n  public boolean incrementToken() throws IOException {\n    clearAttributes();\n    buffer.setLength(0);\n    int ci;\n    char ch, pch;\n    boolean atBegin = true;\n    tokenStart = tokenEnd;\n    ci = input.read();\n    ch = (char) ci;\n\n    while (true) {\n      if (ci == -1) {\n        break;\n      } else if (PUNCTION.indexOf(ch) != -1) {\n        // End of a sentence\n        buffer.append(ch);\n        tokenEnd++;\n        break;\n      } else if (atBegin && Utility.SPACES.indexOf(ch) != -1) {\n        tokenStart++;\n        tokenEnd++;\n        ci = input.read();\n        ch = (char) ci;\n      } else {\n        buffer.append(ch);\n        atBegin = false;\n        tokenEnd++;\n        pch = ch;\n        ci = input.read();\n        ch = (char) ci;\n        // Two spaces, such as CR, LF\n        if (Utility.SPACES.indexOf(ch) != -1\n            && Utility.SPACES.indexOf(pch) != -1) {\n          // buffer.append(ch);\n          tokenEnd++;\n          break;\n        }\n      }\n    }\n    if (buffer.length() == 0)\n      return false;\n    else {\n      termAtt.setTermBuffer(buffer.toString());\n      offsetAtt.setOffset(correctOffset(tokenStart), correctOffset(tokenEnd));\n      typeAtt.setType(\"sentence\");\n      return true;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0f080986da691a3bba7b757f43ab72cdc82b57ce","date":1273069619,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"modules/analysis/smartcn/src/java/org/apache/lucene/analysis/cn/smart/SentenceTokenizer#incrementToken().mjava","pathOld":"lucene/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/SentenceTokenizer#incrementToken().mjava","sourceNew":"  @Override\n  public boolean incrementToken() throws IOException {\n    clearAttributes();\n    buffer.setLength(0);\n    int ci;\n    char ch, pch;\n    boolean atBegin = true;\n    tokenStart = tokenEnd;\n    ci = input.read();\n    ch = (char) ci;\n\n    while (true) {\n      if (ci == -1) {\n        break;\n      } else if (PUNCTION.indexOf(ch) != -1) {\n        // End of a sentence\n        buffer.append(ch);\n        tokenEnd++;\n        break;\n      } else if (atBegin && Utility.SPACES.indexOf(ch) != -1) {\n        tokenStart++;\n        tokenEnd++;\n        ci = input.read();\n        ch = (char) ci;\n      } else {\n        buffer.append(ch);\n        atBegin = false;\n        tokenEnd++;\n        pch = ch;\n        ci = input.read();\n        ch = (char) ci;\n        // Two spaces, such as CR, LF\n        if (Utility.SPACES.indexOf(ch) != -1\n            && Utility.SPACES.indexOf(pch) != -1) {\n          // buffer.append(ch);\n          tokenEnd++;\n          break;\n        }\n      }\n    }\n    if (buffer.length() == 0)\n      return false;\n    else {\n      termAtt.setTermBuffer(buffer.toString());\n      offsetAtt.setOffset(correctOffset(tokenStart), correctOffset(tokenEnd));\n      typeAtt.setType(\"sentence\");\n      return true;\n    }\n  }\n\n","sourceOld":"  @Override\n  public boolean incrementToken() throws IOException {\n    clearAttributes();\n    buffer.setLength(0);\n    int ci;\n    char ch, pch;\n    boolean atBegin = true;\n    tokenStart = tokenEnd;\n    ci = input.read();\n    ch = (char) ci;\n\n    while (true) {\n      if (ci == -1) {\n        break;\n      } else if (PUNCTION.indexOf(ch) != -1) {\n        // End of a sentence\n        buffer.append(ch);\n        tokenEnd++;\n        break;\n      } else if (atBegin && Utility.SPACES.indexOf(ch) != -1) {\n        tokenStart++;\n        tokenEnd++;\n        ci = input.read();\n        ch = (char) ci;\n      } else {\n        buffer.append(ch);\n        atBegin = false;\n        tokenEnd++;\n        pch = ch;\n        ci = input.read();\n        ch = (char) ci;\n        // Two spaces, such as CR, LF\n        if (Utility.SPACES.indexOf(ch) != -1\n            && Utility.SPACES.indexOf(pch) != -1) {\n          // buffer.append(ch);\n          tokenEnd++;\n          break;\n        }\n      }\n    }\n    if (buffer.length() == 0)\n      return false;\n    else {\n      termAtt.setTermBuffer(buffer.toString());\n      offsetAtt.setOffset(correctOffset(tokenStart), correctOffset(tokenEnd));\n      typeAtt.setType(\"sentence\");\n      return true;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"0f080986da691a3bba7b757f43ab72cdc82b57ce":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["0f080986da691a3bba7b757f43ab72cdc82b57ce"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"0f080986da691a3bba7b757f43ab72cdc82b57ce":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["0f080986da691a3bba7b757f43ab72cdc82b57ce"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}