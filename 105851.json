{"path":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentPhrase().mjava","commits":[{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentPhrase().mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentPhrase().mjava","sourceNew":"  public void testConcurrentPhrase() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final PhraseQuery phraseQuery = new PhraseQuery();\n      phraseQuery.add(new Term(FIELD, \"fox\"));\n      phraseQuery.add(new Term(FIELD, \"jumped\"));\n      phraseQuery.setSlop(0);\n      TopDocs hits = indexSearcher.search(phraseQuery, 1);\n      assertEquals(1, hits.totalHits);\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n\n      final TokenStream tokenStream = TokenSources\n          .getTokenStream(indexReader.getTermVector(\n              0, FIELD), false);\n      assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n          TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","sourceOld":"  public void testConcurrentPhrase() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final PhraseQuery phraseQuery = new PhraseQuery();\n      phraseQuery.add(new Term(FIELD, \"fox\"));\n      phraseQuery.add(new Term(FIELD, \"jumped\"));\n      phraseQuery.setSlop(0);\n      TopDocs hits = indexSearcher.search(phraseQuery, 1);\n      assertEquals(1, hits.totalHits);\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n\n      final TokenStream tokenStream = TokenSources\n          .getTokenStream(indexReader.getTermVector(\n              0, FIELD), false);\n      assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n          TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f","date":1338430031,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentPhrase().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentPhrase().mjava","sourceNew":"  public void testConcurrentPhrase() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = DirectoryReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final PhraseQuery phraseQuery = new PhraseQuery();\n      phraseQuery.add(new Term(FIELD, \"fox\"));\n      phraseQuery.add(new Term(FIELD, \"jumped\"));\n      phraseQuery.setSlop(0);\n      TopDocs hits = indexSearcher.search(phraseQuery, 1);\n      assertEquals(1, hits.totalHits);\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n\n      final TokenStream tokenStream = TokenSources\n          .getTokenStream(indexReader.getTermVector(\n              0, FIELD), false);\n      assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n          TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","sourceOld":"  public void testConcurrentPhrase() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final PhraseQuery phraseQuery = new PhraseQuery();\n      phraseQuery.add(new Term(FIELD, \"fox\"));\n      phraseQuery.add(new Term(FIELD, \"jumped\"));\n      phraseQuery.setSlop(0);\n      TopDocs hits = indexSearcher.search(phraseQuery, 1);\n      assertEquals(1, hits.totalHits);\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n\n      final TokenStream tokenStream = TokenSources\n          .getTokenStream(indexReader.getTermVector(\n              0, FIELD), false);\n      assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n          TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"04f07771a2a7dd3a395700665ed839c3dae2def2","date":1339350139,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentPhrase().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentPhrase().mjava","sourceNew":"  public void testConcurrentPhrase() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = DirectoryReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final PhraseQuery phraseQuery = new PhraseQuery();\n      phraseQuery.add(new Term(FIELD, \"fox\"));\n      phraseQuery.add(new Term(FIELD, \"jumped\"));\n      phraseQuery.setSlop(0);\n      TopDocs hits = indexSearcher.search(phraseQuery, 1);\n      assertEquals(1, hits.totalHits);\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n\n      final TokenStream tokenStream = TokenSources\n          .getTokenStream(indexReader.getTermVector(\n              0, FIELD), false);\n      assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n          TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","sourceOld":"  public void testConcurrentPhrase() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = DirectoryReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final PhraseQuery phraseQuery = new PhraseQuery();\n      phraseQuery.add(new Term(FIELD, \"fox\"));\n      phraseQuery.add(new Term(FIELD, \"jumped\"));\n      phraseQuery.setSlop(0);\n      TopDocs hits = indexSearcher.search(phraseQuery, 1);\n      assertEquals(1, hits.totalHits);\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n\n      final TokenStream tokenStream = TokenSources\n          .getTokenStream(indexReader.getTermVector(\n              0, FIELD), false);\n      assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n          TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","bugFix":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4d3e8520fd031bab31fd0e4d480e55958bc45efe","date":1340901565,"type":3,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentPhrase().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentPhrase().mjava","sourceNew":"  public void testConcurrentPhrase() throws IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = DirectoryReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final PhraseQuery phraseQuery = new PhraseQuery();\n      phraseQuery.add(new Term(FIELD, \"fox\"));\n      phraseQuery.add(new Term(FIELD, \"jumped\"));\n      phraseQuery.setSlop(0);\n      TopDocs hits = indexSearcher.search(phraseQuery, 1);\n      assertEquals(1, hits.totalHits);\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n\n      final TokenStream tokenStream = TokenSources\n          .getTokenStream(indexReader.getTermVector(\n              0, FIELD), false);\n      assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n          TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","sourceOld":"  public void testConcurrentPhrase() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = DirectoryReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final PhraseQuery phraseQuery = new PhraseQuery();\n      phraseQuery.add(new Term(FIELD, \"fox\"));\n      phraseQuery.add(new Term(FIELD, \"jumped\"));\n      phraseQuery.setSlop(0);\n      TopDocs hits = indexSearcher.search(phraseQuery, 1);\n      assertEquals(1, hits.totalHits);\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n\n      final TokenStream tokenStream = TokenSources\n          .getTokenStream(indexReader.getTermVector(\n              0, FIELD), false);\n      assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n          TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","bugFix":["fafd002a407d38098f1f0edf4365f971102ae0ef"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fe33227f6805edab2036cbb80645cc4e2d1fa424","date":1342713534,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentPhrase().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentPhrase().mjava","sourceNew":"  public void testConcurrentPhrase() throws IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = DirectoryReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final PhraseQuery phraseQuery = new PhraseQuery();\n      phraseQuery.add(new Term(FIELD, \"fox\"));\n      phraseQuery.add(new Term(FIELD, \"jumped\"));\n      phraseQuery.setSlop(0);\n      TopDocs hits = indexSearcher.search(phraseQuery, 1);\n      assertEquals(1, hits.totalHits);\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n\n      final TokenStream tokenStream = TokenSources\n          .getTokenStream(indexReader.getTermVector(\n              0, FIELD), false);\n      assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n          TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","sourceOld":"  public void testConcurrentPhrase() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = DirectoryReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final PhraseQuery phraseQuery = new PhraseQuery();\n      phraseQuery.add(new Term(FIELD, \"fox\"));\n      phraseQuery.add(new Term(FIELD, \"jumped\"));\n      phraseQuery.setSlop(0);\n      TopDocs hits = indexSearcher.search(phraseQuery, 1);\n      assertEquals(1, hits.totalHits);\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n\n      final TokenStream tokenStream = TokenSources\n          .getTokenStream(indexReader.getTermVector(\n              0, FIELD), false);\n      assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n          TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentPhrase().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentPhrase().mjava","sourceNew":"  public void testConcurrentPhrase() throws IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.shutdown();\n    }\n    final IndexReader indexReader = DirectoryReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final PhraseQuery phraseQuery = new PhraseQuery();\n      phraseQuery.add(new Term(FIELD, \"fox\"));\n      phraseQuery.add(new Term(FIELD, \"jumped\"));\n      phraseQuery.setSlop(0);\n      TopDocs hits = indexSearcher.search(phraseQuery, 1);\n      assertEquals(1, hits.totalHits);\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n\n      final TokenStream tokenStream = TokenSources\n          .getTokenStream(indexReader.getTermVector(\n              0, FIELD), false);\n      assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n          TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","sourceOld":"  public void testConcurrentPhrase() throws IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = DirectoryReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final PhraseQuery phraseQuery = new PhraseQuery();\n      phraseQuery.add(new Term(FIELD, \"fox\"));\n      phraseQuery.add(new Term(FIELD, \"jumped\"));\n      phraseQuery.setSlop(0);\n      TopDocs hits = indexSearcher.search(phraseQuery, 1);\n      assertEquals(1, hits.totalHits);\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n\n      final TokenStream tokenStream = TokenSources\n          .getTokenStream(indexReader.getTermVector(\n              0, FIELD), false);\n      assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n          TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentPhrase().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentPhrase().mjava","sourceNew":"  public void testConcurrentPhrase() throws IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.shutdown();\n    }\n    final IndexReader indexReader = DirectoryReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final PhraseQuery phraseQuery = new PhraseQuery();\n      phraseQuery.add(new Term(FIELD, \"fox\"));\n      phraseQuery.add(new Term(FIELD, \"jumped\"));\n      phraseQuery.setSlop(0);\n      TopDocs hits = indexSearcher.search(phraseQuery, 1);\n      assertEquals(1, hits.totalHits);\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n\n      final TokenStream tokenStream = TokenSources\n          .getTokenStream(indexReader.getTermVector(\n              0, FIELD), false);\n      assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n          TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","sourceOld":"  public void testConcurrentPhrase() throws IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.shutdown();\n    }\n    final IndexReader indexReader = DirectoryReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final PhraseQuery phraseQuery = new PhraseQuery();\n      phraseQuery.add(new Term(FIELD, \"fox\"));\n      phraseQuery.add(new Term(FIELD, \"jumped\"));\n      phraseQuery.setSlop(0);\n      TopDocs hits = indexSearcher.search(phraseQuery, 1);\n      assertEquals(1, hits.totalHits);\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n\n      final TokenStream tokenStream = TokenSources\n          .getTokenStream(indexReader.getTermVector(\n              0, FIELD), false);\n      assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n          TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentPhrase().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentPhrase().mjava","sourceNew":"  public void testConcurrentPhrase() throws IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = DirectoryReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final PhraseQuery phraseQuery = new PhraseQuery();\n      phraseQuery.add(new Term(FIELD, \"fox\"));\n      phraseQuery.add(new Term(FIELD, \"jumped\"));\n      phraseQuery.setSlop(0);\n      TopDocs hits = indexSearcher.search(phraseQuery, 1);\n      assertEquals(1, hits.totalHits);\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n\n      final TokenStream tokenStream = TokenSources\n          .getTokenStream(indexReader.getTermVector(\n              0, FIELD), false);\n      assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n          TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","sourceOld":"  public void testConcurrentPhrase() throws IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.shutdown();\n    }\n    final IndexReader indexReader = DirectoryReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final PhraseQuery phraseQuery = new PhraseQuery();\n      phraseQuery.add(new Term(FIELD, \"fox\"));\n      phraseQuery.add(new Term(FIELD, \"jumped\"));\n      phraseQuery.setSlop(0);\n      TopDocs hits = indexSearcher.search(phraseQuery, 1);\n      assertEquals(1, hits.totalHits);\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n\n      final TokenStream tokenStream = TokenSources\n          .getTokenStream(indexReader.getTermVector(\n              0, FIELD), false);\n      assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n          TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"08a32c8b6fbb299bd14b2e45490c9554c794a85e","date":1417322051,"type":3,"author":"David Wayne Smiley","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentPhrase().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentPhrase().mjava","sourceNew":"  public void testConcurrentPhrase() throws IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = DirectoryReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final PhraseQuery phraseQuery = new PhraseQuery();\n      phraseQuery.add(new Term(FIELD, \"fox\"));\n      phraseQuery.add(new Term(FIELD, \"jumped\"));\n      phraseQuery.setSlop(0);\n      TopDocs hits = indexSearcher.search(phraseQuery, 1);\n      assertEquals(1, hits.totalHits);\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n\n      final TokenStream tokenStream = TokenSources\n          .getTokenStream(indexReader.getTermVector(\n              0, FIELD));\n      assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n          TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","sourceOld":"  public void testConcurrentPhrase() throws IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = DirectoryReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final PhraseQuery phraseQuery = new PhraseQuery();\n      phraseQuery.add(new Term(FIELD, \"fox\"));\n      phraseQuery.add(new Term(FIELD, \"jumped\"));\n      phraseQuery.setSlop(0);\n      TopDocs hits = indexSearcher.search(phraseQuery, 1);\n      assertEquals(1, hits.totalHits);\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n\n      final TokenStream tokenStream = TokenSources\n          .getTokenStream(indexReader.getTermVector(\n              0, FIELD), false);\n      assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n          TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5d62e4938659e263e96ae8188e11aea8a940aea5","date":1430230314,"type":3,"author":"David Wayne Smiley","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentPhrase().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentPhrase().mjava","sourceNew":"  public void testConcurrentPhrase() throws IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = DirectoryReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final PhraseQuery phraseQuery = new PhraseQuery();\n      phraseQuery.add(new Term(FIELD, \"fox\"));\n      phraseQuery.add(new Term(FIELD, \"jumped\"));\n      phraseQuery.setSlop(0);\n      TopDocs hits = indexSearcher.search(phraseQuery, 1);\n      assertEquals(1, hits.totalHits);\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n\n      final TokenStream tokenStream =\n          TokenSources.getTermVectorTokenStreamOrNull(FIELD, indexReader.getTermVectors(0), -1);\n      assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n          TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","sourceOld":"  public void testConcurrentPhrase() throws IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = DirectoryReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final PhraseQuery phraseQuery = new PhraseQuery();\n      phraseQuery.add(new Term(FIELD, \"fox\"));\n      phraseQuery.add(new Term(FIELD, \"jumped\"));\n      phraseQuery.setSlop(0);\n      TopDocs hits = indexSearcher.search(phraseQuery, 1);\n      assertEquals(1, hits.totalHits);\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n\n      final TokenStream tokenStream = TokenSources\n          .getTokenStream(indexReader.getTermVector(\n              0, FIELD));\n      assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n          TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e9e1499c5d26c936238506df90a3c02c76707722","date":1434449920,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentPhrase().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentPhrase().mjava","sourceNew":"  public void testConcurrentPhrase() throws IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = DirectoryReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final PhraseQuery phraseQuery = new PhraseQuery(FIELD, \"fox\", \"jumped\");\n      TopDocs hits = indexSearcher.search(phraseQuery, 1);\n      assertEquals(1, hits.totalHits);\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n\n      final TokenStream tokenStream =\n          TokenSources.getTermVectorTokenStreamOrNull(FIELD, indexReader.getTermVectors(0), -1);\n      assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n          TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","sourceOld":"  public void testConcurrentPhrase() throws IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = DirectoryReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final PhraseQuery phraseQuery = new PhraseQuery();\n      phraseQuery.add(new Term(FIELD, \"fox\"));\n      phraseQuery.add(new Term(FIELD, \"jumped\"));\n      phraseQuery.setSlop(0);\n      TopDocs hits = indexSearcher.search(phraseQuery, 1);\n      assertEquals(1, hits.totalHits);\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n\n      final TokenStream tokenStream =\n          TokenSources.getTermVectorTokenStreamOrNull(FIELD, indexReader.getTermVectors(0), -1);\n      assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n          TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"83788ad129a5154d5c6562c4e8ce3db48793aada","date":1532961485,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentPhrase().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentPhrase().mjava","sourceNew":"  public void testConcurrentPhrase() throws IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = DirectoryReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final PhraseQuery phraseQuery = new PhraseQuery(FIELD, \"fox\", \"jumped\");\n      TopDocs hits = indexSearcher.search(phraseQuery, 1);\n      assertEquals(1, hits.totalHits.value);\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n\n      final TokenStream tokenStream =\n          TokenSources.getTermVectorTokenStreamOrNull(FIELD, indexReader.getTermVectors(0), -1);\n      assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n          TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","sourceOld":"  public void testConcurrentPhrase() throws IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = DirectoryReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final PhraseQuery phraseQuery = new PhraseQuery(FIELD, \"fox\", \"jumped\");\n      TopDocs hits = indexSearcher.search(phraseQuery, 1);\n      assertEquals(1, hits.totalHits);\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n\n      final TokenStream tokenStream =\n          TokenSources.getTermVectorTokenStreamOrNull(FIELD, indexReader.getTermVectors(0), -1);\n      assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n          TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"08a32c8b6fbb299bd14b2e45490c9554c794a85e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"5d62e4938659e263e96ae8188e11aea8a940aea5":["08a32c8b6fbb299bd14b2e45490c9554c794a85e"],"04f07771a2a7dd3a395700665ed839c3dae2def2":["e7e8d6f15900ee22ac3cb0a503f15dc952a3580f"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"e9e1499c5d26c936238506df90a3c02c76707722":["5d62e4938659e263e96ae8188e11aea8a940aea5"],"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":["04f07771a2a7dd3a395700665ed839c3dae2def2","4d3e8520fd031bab31fd0e4d480e55958bc45efe"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["4d3e8520fd031bab31fd0e4d480e55958bc45efe"],"83788ad129a5154d5c6562c4e8ce3db48793aada":["e9e1499c5d26c936238506df90a3c02c76707722"],"4d3e8520fd031bab31fd0e4d480e55958bc45efe":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["83788ad129a5154d5c6562c4e8ce3db48793aada"]},"commit2Childs":{"08a32c8b6fbb299bd14b2e45490c9554c794a85e":["5d62e4938659e263e96ae8188e11aea8a940aea5"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"5d62e4938659e263e96ae8188e11aea8a940aea5":["e9e1499c5d26c936238506df90a3c02c76707722"],"04f07771a2a7dd3a395700665ed839c3dae2def2":["fe33227f6805edab2036cbb80645cc4e2d1fa424","4d3e8520fd031bab31fd0e4d480e55958bc45efe"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["e7e8d6f15900ee22ac3cb0a503f15dc952a3580f"],"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"e9e1499c5d26c936238506df90a3c02c76707722":["83788ad129a5154d5c6562c4e8ce3db48793aada"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["08a32c8b6fbb299bd14b2e45490c9554c794a85e"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"4d3e8520fd031bab31fd0e4d480e55958bc45efe":["fe33227f6805edab2036cbb80645cc4e2d1fa424","ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"83788ad129a5154d5c6562c4e8ce3db48793aada":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["fe33227f6805edab2036cbb80645cc4e2d1fa424","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}