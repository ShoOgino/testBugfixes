{"path":"lucene/misc/src/test/org/apache/lucene/search/TestEarlyTerminatingSortingCollector#createRandomIndex(Integer).mjava","commits":[{"id":"ff0a9c7bbae145588b269529bb55009dec1bb733","date":1438605556,"type":1,"author":"Christine Poerschke","isMerge":false,"pathNew":"lucene/misc/src/test/org/apache/lucene/search/TestEarlyTerminatingSortingCollector#createRandomIndex(Integer).mjava","pathOld":"lucene/misc/src/test/org/apache/lucene/search/TestEarlyTerminatingSortingCollector#createRandomIndex().mjava","sourceNew":"  private void createRandomIndex(Integer maxSegmentCount) throws IOException {\n    dir = newDirectory();\n    numDocs = atLeast(150);\n    final int numTerms = TestUtil.nextInt(random(), 1, numDocs / 5);\n    Set<String> randomTerms = new HashSet<>();\n    while (randomTerms.size() < numTerms) {\n      randomTerms.add(TestUtil.randomSimpleString(random()));\n    }\n    terms = new ArrayList<>(randomTerms);\n    final long seed = random().nextLong();\n    final IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(new Random(seed)));\n    iwc.setMergeScheduler(new SerialMergeScheduler()); // for reproducible tests\n    mergePolicy = TestSortingMergePolicy.newSortingMergePolicy(sort);\n    iwc.setMergePolicy(mergePolicy);\n    iw = new RandomIndexWriter(new Random(seed), dir, iwc);\n    iw.setDoRandomForceMerge(false); // don't do this, it may happen anyway with MockRandomMP\n    for (int i = 0; i < numDocs; ++i) {\n      final Document doc = randomDocument();\n      iw.addDocument(doc);\n      if (i == numDocs / 2 || (i != numDocs - 1 && random().nextInt(8) == 0)) {\n        iw.commit();\n      }\n      if (random().nextInt(15) == 0) {\n        final String term = RandomPicks.randomFrom(random(), terms);\n        iw.deleteDocuments(new Term(\"s\", term));\n      }\n    }\n    if (maxSegmentCount != null) {\n      iw.forceMerge(maxSegmentCount.intValue());\n    }\n    else if (random().nextBoolean()) {\n      iw.forceMerge(forceMergeMaxSegmentCount);\n    }\n    reader = iw.getReader();\n  }\n\n","sourceOld":"  private void createRandomIndex() throws IOException {\n    dir = newDirectory();\n    numDocs = atLeast(150);\n    final int numTerms = TestUtil.nextInt(random(), 1, numDocs / 5);\n    Set<String> randomTerms = new HashSet<>();\n    while (randomTerms.size() < numTerms) {\n      randomTerms.add(TestUtil.randomSimpleString(random()));\n    }\n    terms = new ArrayList<>(randomTerms);\n    final long seed = random().nextLong();\n    final IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(new Random(seed)));\n    iwc.setMergeScheduler(new SerialMergeScheduler()); // for reproducible tests\n    mergePolicy = TestSortingMergePolicy.newSortingMergePolicy(sort);\n    iwc.setMergePolicy(mergePolicy);\n    iw = new RandomIndexWriter(new Random(seed), dir, iwc);\n    iw.setDoRandomForceMerge(false); // don't do this, it may happen anyway with MockRandomMP\n    for (int i = 0; i < numDocs; ++i) {\n      final Document doc = randomDocument();\n      iw.addDocument(doc);\n      if (i == numDocs / 2 || (i != numDocs - 1 && random().nextInt(8) == 0)) {\n        iw.commit();\n      }\n      if (random().nextInt(15) == 0) {\n        final String term = RandomPicks.randomFrom(random(), terms);\n        iw.deleteDocuments(new Term(\"s\", term));\n      }\n    }\n    if (random().nextBoolean()) {\n      iw.forceMerge(5);\n    }\n    reader = iw.getReader();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"75f521a62662f1ec69a2107e8ca6d1e37d54c033","date":1438786323,"type":5,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/misc/src/test/org/apache/lucene/search/TestEarlyTerminatingSortingCollector#createRandomIndex(boolean).mjava","pathOld":"lucene/misc/src/test/org/apache/lucene/search/TestEarlyTerminatingSortingCollector#createRandomIndex(Integer).mjava","sourceNew":"  private void createRandomIndex(boolean singleSortedSegment) throws IOException {\n    dir = newDirectory();\n    numDocs = atLeast(150);\n    final int numTerms = TestUtil.nextInt(random(), 1, numDocs / 5);\n    Set<String> randomTerms = new HashSet<>();\n    while (randomTerms.size() < numTerms) {\n      randomTerms.add(TestUtil.randomSimpleString(random()));\n    }\n    terms = new ArrayList<>(randomTerms);\n    final long seed = random().nextLong();\n    final IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(new Random(seed)));\n    iwc.setMergeScheduler(new SerialMergeScheduler()); // for reproducible tests\n    mergePolicy = TestSortingMergePolicy.newSortingMergePolicy(sort);\n    iwc.setMergePolicy(mergePolicy);\n    iw = new RandomIndexWriter(new Random(seed), dir, iwc);\n    iw.setDoRandomForceMerge(false); // don't do this, it may happen anyway with MockRandomMP\n    for (int i = 0; i < numDocs; ++i) {\n      final Document doc = randomDocument();\n      iw.addDocument(doc);\n      if (i == numDocs / 2 || (i != numDocs - 1 && random().nextInt(8) == 0)) {\n        iw.commit();\n      }\n      if (random().nextInt(15) == 0) {\n        final String term = RandomPicks.randomFrom(random(), terms);\n        iw.deleteDocuments(new Term(\"s\", term));\n      }\n    }\n    if (singleSortedSegment) {\n      // because of deletions, there might still be a single flush segment in\n      // the index, although want want a sorted segment so it needs to be merged\n      iw.getReader().close(); // refresh\n      iw.addDocument(new Document());\n      iw.forceMerge(1);\n    }\n    else if (random().nextBoolean()) {\n      iw.forceMerge(forceMergeMaxSegmentCount);\n    }\n    reader = iw.getReader();\n  }\n\n","sourceOld":"  private void createRandomIndex(Integer maxSegmentCount) throws IOException {\n    dir = newDirectory();\n    numDocs = atLeast(150);\n    final int numTerms = TestUtil.nextInt(random(), 1, numDocs / 5);\n    Set<String> randomTerms = new HashSet<>();\n    while (randomTerms.size() < numTerms) {\n      randomTerms.add(TestUtil.randomSimpleString(random()));\n    }\n    terms = new ArrayList<>(randomTerms);\n    final long seed = random().nextLong();\n    final IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(new Random(seed)));\n    iwc.setMergeScheduler(new SerialMergeScheduler()); // for reproducible tests\n    mergePolicy = TestSortingMergePolicy.newSortingMergePolicy(sort);\n    iwc.setMergePolicy(mergePolicy);\n    iw = new RandomIndexWriter(new Random(seed), dir, iwc);\n    iw.setDoRandomForceMerge(false); // don't do this, it may happen anyway with MockRandomMP\n    for (int i = 0; i < numDocs; ++i) {\n      final Document doc = randomDocument();\n      iw.addDocument(doc);\n      if (i == numDocs / 2 || (i != numDocs - 1 && random().nextInt(8) == 0)) {\n        iw.commit();\n      }\n      if (random().nextInt(15) == 0) {\n        final String term = RandomPicks.randomFrom(random(), terms);\n        iw.deleteDocuments(new Term(\"s\", term));\n      }\n    }\n    if (maxSegmentCount != null) {\n      iw.forceMerge(maxSegmentCount.intValue());\n    }\n    else if (random().nextBoolean()) {\n      iw.forceMerge(forceMergeMaxSegmentCount);\n    }\n    reader = iw.getReader();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"ff0a9c7bbae145588b269529bb55009dec1bb733":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"75f521a62662f1ec69a2107e8ca6d1e37d54c033":["ff0a9c7bbae145588b269529bb55009dec1bb733"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["75f521a62662f1ec69a2107e8ca6d1e37d54c033"]},"commit2Childs":{"ff0a9c7bbae145588b269529bb55009dec1bb733":["75f521a62662f1ec69a2107e8ca6d1e37d54c033"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["ff0a9c7bbae145588b269529bb55009dec1bb733"],"75f521a62662f1ec69a2107e8ca6d1e37d54c033":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}