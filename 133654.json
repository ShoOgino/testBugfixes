{"path":"lucene/analysis/common/src/java/org/apache/lucene/analysis/cjk/CJKBigramFilter#incrementToken().mjava","commits":[{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/cjk/CJKBigramFilter#incrementToken().mjava","pathOld":"modules/analysis/common/src/java/org/apache/lucene/analysis/cjk/CJKBigramFilter#incrementToken().mjava","sourceNew":"  /*\n   * much of this complexity revolves around handling the special case of a \n   * \"lone cjk character\" where cjktokenizer would output a unigram. this \n   * is also the only time we ever have to captureState.\n   */\n  @Override\n  public boolean incrementToken() throws IOException {\n    while (true) {\n      if (hasBufferedBigram()) {\n        \n        // case 1: we have multiple remaining codepoints buffered,\n        // so we can emit a bigram here.\n        \n        flushBigram();\n        return true;\n      } else if (doNext()) {\n        \n        // case 2: look at the token type. should we form any n-grams?\n        \n        String type = typeAtt.type();\n        if (type == doHan || type == doHiragana || type == doKatakana || type == doHangul) {\n          \n          // acceptable CJK type: we form n-grams from these.\n          // as long as the offsets are aligned, we just add these to our current buffer.\n          // otherwise, we clear the buffer and start over.\n          \n          if (offsetAtt.startOffset() != lastEndOffset) { // unaligned, clear queue\n            if (hasBufferedUnigram()) {\n              \n              // we have a buffered unigram, and we peeked ahead to see if we could form\n              // a bigram, but we can't, because the offsets are unaligned. capture the state \n              // of this peeked data to be revisited next time thru the loop, and dump our unigram.\n              \n              loneState = captureState();\n              flushUnigram();\n              return true;\n            }\n            index = 0;\n            bufferLen = 0;\n          }\n          refill();\n        } else {\n          \n          // not a CJK type: we just return these as-is.\n          \n          if (hasBufferedUnigram()) {\n            \n            // we have a buffered unigram, and we peeked ahead to see if we could form\n            // a bigram, but we can't, because its not a CJK type. capture the state \n            // of this peeked data to be revisited next time thru the loop, and dump our unigram.\n            \n            loneState = captureState();\n            flushUnigram();\n            return true;\n          }\n          return true;\n        }\n      } else {\n        \n        // case 3: we have only zero or 1 codepoints buffered, \n        // so not enough to form a bigram. But, we also have no\n        // more input. So if we have a buffered codepoint, emit\n        // a unigram, otherwise, its end of stream.\n        \n        if (hasBufferedUnigram()) {\n          flushUnigram(); // flush our remaining unigram\n          return true;\n        }\n        return false;\n      }\n    }\n  }\n\n","sourceOld":"  /*\n   * much of this complexity revolves around handling the special case of a \n   * \"lone cjk character\" where cjktokenizer would output a unigram. this \n   * is also the only time we ever have to captureState.\n   */\n  @Override\n  public boolean incrementToken() throws IOException {\n    while (true) {\n      if (hasBufferedBigram()) {\n        \n        // case 1: we have multiple remaining codepoints buffered,\n        // so we can emit a bigram here.\n        \n        flushBigram();\n        return true;\n      } else if (doNext()) {\n        \n        // case 2: look at the token type. should we form any n-grams?\n        \n        String type = typeAtt.type();\n        if (type == doHan || type == doHiragana || type == doKatakana || type == doHangul) {\n          \n          // acceptable CJK type: we form n-grams from these.\n          // as long as the offsets are aligned, we just add these to our current buffer.\n          // otherwise, we clear the buffer and start over.\n          \n          if (offsetAtt.startOffset() != lastEndOffset) { // unaligned, clear queue\n            if (hasBufferedUnigram()) {\n              \n              // we have a buffered unigram, and we peeked ahead to see if we could form\n              // a bigram, but we can't, because the offsets are unaligned. capture the state \n              // of this peeked data to be revisited next time thru the loop, and dump our unigram.\n              \n              loneState = captureState();\n              flushUnigram();\n              return true;\n            }\n            index = 0;\n            bufferLen = 0;\n          }\n          refill();\n        } else {\n          \n          // not a CJK type: we just return these as-is.\n          \n          if (hasBufferedUnigram()) {\n            \n            // we have a buffered unigram, and we peeked ahead to see if we could form\n            // a bigram, but we can't, because its not a CJK type. capture the state \n            // of this peeked data to be revisited next time thru the loop, and dump our unigram.\n            \n            loneState = captureState();\n            flushUnigram();\n            return true;\n          }\n          return true;\n        }\n      } else {\n        \n        // case 3: we have only zero or 1 codepoints buffered, \n        // so not enough to form a bigram. But, we also have no\n        // more input. So if we have a buffered codepoint, emit\n        // a unigram, otherwise, its end of stream.\n        \n        if (hasBufferedUnigram()) {\n          flushUnigram(); // flush our remaining unigram\n          return true;\n        }\n        return false;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1548959d8ee1230b6fe5bc9da6115d9fc4019bc9","date":1344119834,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/cjk/CJKBigramFilter#incrementToken().mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/cjk/CJKBigramFilter#incrementToken().mjava","sourceNew":"  /*\n   * much of this complexity revolves around handling the special case of a \n   * \"lone cjk character\" where cjktokenizer would output a unigram. this \n   * is also the only time we ever have to captureState.\n   */\n  @Override\n  public boolean incrementToken() throws IOException {\n    while (true) {\n      if (hasBufferedBigram()) {\n        \n        // case 1: we have multiple remaining codepoints buffered,\n        // so we can emit a bigram here.\n        \n        if (outputUnigrams) {\n\n          // when also outputting unigrams, we output the unigram first,\n          // then rewind back to revisit the bigram.\n          // so an input of ABC is A + (rewind)AB + B + (rewind)BC + C\n          // the logic in hasBufferedUnigram ensures we output the C, \n          // even though it did actually have adjacent CJK characters.\n\n          if (ngramState) {\n            flushBigram();\n          } else {\n            flushUnigram();\n            index--;\n          }\n          ngramState = !ngramState;\n        } else {\n          flushBigram();\n        }\n        return true;\n      } else if (doNext()) {\n        \n        // case 2: look at the token type. should we form any n-grams?\n        \n        String type = typeAtt.type();\n        if (type == doHan || type == doHiragana || type == doKatakana || type == doHangul) {\n          \n          // acceptable CJK type: we form n-grams from these.\n          // as long as the offsets are aligned, we just add these to our current buffer.\n          // otherwise, we clear the buffer and start over.\n          \n          if (offsetAtt.startOffset() != lastEndOffset) { // unaligned, clear queue\n            if (hasBufferedUnigram()) {\n              \n              // we have a buffered unigram, and we peeked ahead to see if we could form\n              // a bigram, but we can't, because the offsets are unaligned. capture the state \n              // of this peeked data to be revisited next time thru the loop, and dump our unigram.\n              \n              loneState = captureState();\n              flushUnigram();\n              return true;\n            }\n            index = 0;\n            bufferLen = 0;\n          }\n          refill();\n        } else {\n          \n          // not a CJK type: we just return these as-is.\n          \n          if (hasBufferedUnigram()) {\n            \n            // we have a buffered unigram, and we peeked ahead to see if we could form\n            // a bigram, but we can't, because its not a CJK type. capture the state \n            // of this peeked data to be revisited next time thru the loop, and dump our unigram.\n            \n            loneState = captureState();\n            flushUnigram();\n            return true;\n          }\n          return true;\n        }\n      } else {\n        \n        // case 3: we have only zero or 1 codepoints buffered, \n        // so not enough to form a bigram. But, we also have no\n        // more input. So if we have a buffered codepoint, emit\n        // a unigram, otherwise, its end of stream.\n        \n        if (hasBufferedUnigram()) {\n          flushUnigram(); // flush our remaining unigram\n          return true;\n        }\n        return false;\n      }\n    }\n  }\n\n","sourceOld":"  /*\n   * much of this complexity revolves around handling the special case of a \n   * \"lone cjk character\" where cjktokenizer would output a unigram. this \n   * is also the only time we ever have to captureState.\n   */\n  @Override\n  public boolean incrementToken() throws IOException {\n    while (true) {\n      if (hasBufferedBigram()) {\n        \n        // case 1: we have multiple remaining codepoints buffered,\n        // so we can emit a bigram here.\n        \n        flushBigram();\n        return true;\n      } else if (doNext()) {\n        \n        // case 2: look at the token type. should we form any n-grams?\n        \n        String type = typeAtt.type();\n        if (type == doHan || type == doHiragana || type == doKatakana || type == doHangul) {\n          \n          // acceptable CJK type: we form n-grams from these.\n          // as long as the offsets are aligned, we just add these to our current buffer.\n          // otherwise, we clear the buffer and start over.\n          \n          if (offsetAtt.startOffset() != lastEndOffset) { // unaligned, clear queue\n            if (hasBufferedUnigram()) {\n              \n              // we have a buffered unigram, and we peeked ahead to see if we could form\n              // a bigram, but we can't, because the offsets are unaligned. capture the state \n              // of this peeked data to be revisited next time thru the loop, and dump our unigram.\n              \n              loneState = captureState();\n              flushUnigram();\n              return true;\n            }\n            index = 0;\n            bufferLen = 0;\n          }\n          refill();\n        } else {\n          \n          // not a CJK type: we just return these as-is.\n          \n          if (hasBufferedUnigram()) {\n            \n            // we have a buffered unigram, and we peeked ahead to see if we could form\n            // a bigram, but we can't, because its not a CJK type. capture the state \n            // of this peeked data to be revisited next time thru the loop, and dump our unigram.\n            \n            loneState = captureState();\n            flushUnigram();\n            return true;\n          }\n          return true;\n        }\n      } else {\n        \n        // case 3: we have only zero or 1 codepoints buffered, \n        // so not enough to form a bigram. But, we also have no\n        // more input. So if we have a buffered codepoint, emit\n        // a unigram, otherwise, its end of stream.\n        \n        if (hasBufferedUnigram()) {\n          flushUnigram(); // flush our remaining unigram\n          return true;\n        }\n        return false;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d6f074e73200c07d54f242d3880a8da5a35ff97b","date":1344507653,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/cjk/CJKBigramFilter#incrementToken().mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/cjk/CJKBigramFilter#incrementToken().mjava","sourceNew":"  /*\n   * much of this complexity revolves around handling the special case of a \n   * \"lone cjk character\" where cjktokenizer would output a unigram. this \n   * is also the only time we ever have to captureState.\n   */\n  @Override\n  public boolean incrementToken() throws IOException {\n    while (true) {\n      if (hasBufferedBigram()) {\n        \n        // case 1: we have multiple remaining codepoints buffered,\n        // so we can emit a bigram here.\n        \n        if (outputUnigrams) {\n\n          // when also outputting unigrams, we output the unigram first,\n          // then rewind back to revisit the bigram.\n          // so an input of ABC is A + (rewind)AB + B + (rewind)BC + C\n          // the logic in hasBufferedUnigram ensures we output the C, \n          // even though it did actually have adjacent CJK characters.\n\n          if (ngramState) {\n            flushBigram();\n          } else {\n            flushUnigram();\n            index--;\n          }\n          ngramState = !ngramState;\n        } else {\n          flushBigram();\n        }\n        return true;\n      } else if (doNext()) {\n        \n        // case 2: look at the token type. should we form any n-grams?\n        \n        String type = typeAtt.type();\n        if (type == doHan || type == doHiragana || type == doKatakana || type == doHangul) {\n          \n          // acceptable CJK type: we form n-grams from these.\n          // as long as the offsets are aligned, we just add these to our current buffer.\n          // otherwise, we clear the buffer and start over.\n          \n          if (offsetAtt.startOffset() != lastEndOffset) { // unaligned, clear queue\n            if (hasBufferedUnigram()) {\n              \n              // we have a buffered unigram, and we peeked ahead to see if we could form\n              // a bigram, but we can't, because the offsets are unaligned. capture the state \n              // of this peeked data to be revisited next time thru the loop, and dump our unigram.\n              \n              loneState = captureState();\n              flushUnigram();\n              return true;\n            }\n            index = 0;\n            bufferLen = 0;\n          }\n          refill();\n        } else {\n          \n          // not a CJK type: we just return these as-is.\n          \n          if (hasBufferedUnigram()) {\n            \n            // we have a buffered unigram, and we peeked ahead to see if we could form\n            // a bigram, but we can't, because its not a CJK type. capture the state \n            // of this peeked data to be revisited next time thru the loop, and dump our unigram.\n            \n            loneState = captureState();\n            flushUnigram();\n            return true;\n          }\n          return true;\n        }\n      } else {\n        \n        // case 3: we have only zero or 1 codepoints buffered, \n        // so not enough to form a bigram. But, we also have no\n        // more input. So if we have a buffered codepoint, emit\n        // a unigram, otherwise, its end of stream.\n        \n        if (hasBufferedUnigram()) {\n          flushUnigram(); // flush our remaining unigram\n          return true;\n        }\n        return false;\n      }\n    }\n  }\n\n","sourceOld":"  /*\n   * much of this complexity revolves around handling the special case of a \n   * \"lone cjk character\" where cjktokenizer would output a unigram. this \n   * is also the only time we ever have to captureState.\n   */\n  @Override\n  public boolean incrementToken() throws IOException {\n    while (true) {\n      if (hasBufferedBigram()) {\n        \n        // case 1: we have multiple remaining codepoints buffered,\n        // so we can emit a bigram here.\n        \n        flushBigram();\n        return true;\n      } else if (doNext()) {\n        \n        // case 2: look at the token type. should we form any n-grams?\n        \n        String type = typeAtt.type();\n        if (type == doHan || type == doHiragana || type == doKatakana || type == doHangul) {\n          \n          // acceptable CJK type: we form n-grams from these.\n          // as long as the offsets are aligned, we just add these to our current buffer.\n          // otherwise, we clear the buffer and start over.\n          \n          if (offsetAtt.startOffset() != lastEndOffset) { // unaligned, clear queue\n            if (hasBufferedUnigram()) {\n              \n              // we have a buffered unigram, and we peeked ahead to see if we could form\n              // a bigram, but we can't, because the offsets are unaligned. capture the state \n              // of this peeked data to be revisited next time thru the loop, and dump our unigram.\n              \n              loneState = captureState();\n              flushUnigram();\n              return true;\n            }\n            index = 0;\n            bufferLen = 0;\n          }\n          refill();\n        } else {\n          \n          // not a CJK type: we just return these as-is.\n          \n          if (hasBufferedUnigram()) {\n            \n            // we have a buffered unigram, and we peeked ahead to see if we could form\n            // a bigram, but we can't, because its not a CJK type. capture the state \n            // of this peeked data to be revisited next time thru the loop, and dump our unigram.\n            \n            loneState = captureState();\n            flushUnigram();\n            return true;\n          }\n          return true;\n        }\n      } else {\n        \n        // case 3: we have only zero or 1 codepoints buffered, \n        // so not enough to form a bigram. But, we also have no\n        // more input. So if we have a buffered codepoint, emit\n        // a unigram, otherwise, its end of stream.\n        \n        if (hasBufferedUnigram()) {\n          flushUnigram(); // flush our remaining unigram\n          return true;\n        }\n        return false;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c7869f64c874ebf7f317d22c00baf2b6857797a6","date":1344856617,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/cjk/CJKBigramFilter#incrementToken().mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/cjk/CJKBigramFilter#incrementToken().mjava","sourceNew":"  /*\n   * much of this complexity revolves around handling the special case of a \n   * \"lone cjk character\" where cjktokenizer would output a unigram. this \n   * is also the only time we ever have to captureState.\n   */\n  @Override\n  public boolean incrementToken() throws IOException {\n    while (true) {\n      if (hasBufferedBigram()) {\n        \n        // case 1: we have multiple remaining codepoints buffered,\n        // so we can emit a bigram here.\n        \n        if (outputUnigrams) {\n\n          // when also outputting unigrams, we output the unigram first,\n          // then rewind back to revisit the bigram.\n          // so an input of ABC is A + (rewind)AB + B + (rewind)BC + C\n          // the logic in hasBufferedUnigram ensures we output the C, \n          // even though it did actually have adjacent CJK characters.\n\n          if (ngramState) {\n            flushBigram();\n          } else {\n            flushUnigram();\n            index--;\n          }\n          ngramState = !ngramState;\n        } else {\n          flushBigram();\n        }\n        return true;\n      } else if (doNext()) {\n        \n        // case 2: look at the token type. should we form any n-grams?\n        \n        String type = typeAtt.type();\n        if (type == doHan || type == doHiragana || type == doKatakana || type == doHangul) {\n          \n          // acceptable CJK type: we form n-grams from these.\n          // as long as the offsets are aligned, we just add these to our current buffer.\n          // otherwise, we clear the buffer and start over.\n          \n          if (offsetAtt.startOffset() != lastEndOffset) { // unaligned, clear queue\n            if (hasBufferedUnigram()) {\n              \n              // we have a buffered unigram, and we peeked ahead to see if we could form\n              // a bigram, but we can't, because the offsets are unaligned. capture the state \n              // of this peeked data to be revisited next time thru the loop, and dump our unigram.\n              \n              loneState = captureState();\n              flushUnigram();\n              return true;\n            }\n            index = 0;\n            bufferLen = 0;\n          }\n          refill();\n        } else {\n          \n          // not a CJK type: we just return these as-is.\n          \n          if (hasBufferedUnigram()) {\n            \n            // we have a buffered unigram, and we peeked ahead to see if we could form\n            // a bigram, but we can't, because its not a CJK type. capture the state \n            // of this peeked data to be revisited next time thru the loop, and dump our unigram.\n            \n            loneState = captureState();\n            flushUnigram();\n            return true;\n          }\n          return true;\n        }\n      } else {\n        \n        // case 3: we have only zero or 1 codepoints buffered, \n        // so not enough to form a bigram. But, we also have no\n        // more input. So if we have a buffered codepoint, emit\n        // a unigram, otherwise, its end of stream.\n        \n        if (hasBufferedUnigram()) {\n          flushUnigram(); // flush our remaining unigram\n          return true;\n        }\n        return false;\n      }\n    }\n  }\n\n","sourceOld":"  /*\n   * much of this complexity revolves around handling the special case of a \n   * \"lone cjk character\" where cjktokenizer would output a unigram. this \n   * is also the only time we ever have to captureState.\n   */\n  @Override\n  public boolean incrementToken() throws IOException {\n    while (true) {\n      if (hasBufferedBigram()) {\n        \n        // case 1: we have multiple remaining codepoints buffered,\n        // so we can emit a bigram here.\n        \n        flushBigram();\n        return true;\n      } else if (doNext()) {\n        \n        // case 2: look at the token type. should we form any n-grams?\n        \n        String type = typeAtt.type();\n        if (type == doHan || type == doHiragana || type == doKatakana || type == doHangul) {\n          \n          // acceptable CJK type: we form n-grams from these.\n          // as long as the offsets are aligned, we just add these to our current buffer.\n          // otherwise, we clear the buffer and start over.\n          \n          if (offsetAtt.startOffset() != lastEndOffset) { // unaligned, clear queue\n            if (hasBufferedUnigram()) {\n              \n              // we have a buffered unigram, and we peeked ahead to see if we could form\n              // a bigram, but we can't, because the offsets are unaligned. capture the state \n              // of this peeked data to be revisited next time thru the loop, and dump our unigram.\n              \n              loneState = captureState();\n              flushUnigram();\n              return true;\n            }\n            index = 0;\n            bufferLen = 0;\n          }\n          refill();\n        } else {\n          \n          // not a CJK type: we just return these as-is.\n          \n          if (hasBufferedUnigram()) {\n            \n            // we have a buffered unigram, and we peeked ahead to see if we could form\n            // a bigram, but we can't, because its not a CJK type. capture the state \n            // of this peeked data to be revisited next time thru the loop, and dump our unigram.\n            \n            loneState = captureState();\n            flushUnigram();\n            return true;\n          }\n          return true;\n        }\n      } else {\n        \n        // case 3: we have only zero or 1 codepoints buffered, \n        // so not enough to form a bigram. But, we also have no\n        // more input. So if we have a buffered codepoint, emit\n        // a unigram, otherwise, its end of stream.\n        \n        if (hasBufferedUnigram()) {\n          flushUnigram(); // flush our remaining unigram\n          return true;\n        }\n        return false;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8aa2bb13f56a3ad540fd2dc5e882e1ed4bf799d1","date":1419400138,"type":3,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/cjk/CJKBigramFilter#incrementToken().mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/cjk/CJKBigramFilter#incrementToken().mjava","sourceNew":"  /*\n   * much of this complexity revolves around handling the special case of a \n   * \"lone cjk character\" where cjktokenizer would output a unigram. this \n   * is also the only time we ever have to captureState.\n   */\n  @Override\n  public boolean incrementToken() throws IOException {\n    while (true) {\n      if (hasBufferedBigram()) {\n        \n        // case 1: we have multiple remaining codepoints buffered,\n        // so we can emit a bigram here.\n        \n        if (outputUnigrams) {\n\n          // when also outputting unigrams, we output the unigram first,\n          // then rewind back to revisit the bigram.\n          // so an input of ABC is A + (rewind)AB + B + (rewind)BC + C\n          // the logic in hasBufferedUnigram ensures we output the C, \n          // even though it did actually have adjacent CJK characters.\n\n          if (ngramState) {\n            flushBigram();\n          } else {\n            flushUnigram();\n            index--;\n          }\n          ngramState = !ngramState;\n        } else {\n          flushBigram();\n        }\n        return true;\n      } else if (doNext()) {\n        \n        // case 2: look at the token type. should we form any n-grams?\n        \n        String type = typeAtt.type();\n        if (type == doHan || type == doHiragana || type == doKatakana || type == doHangul) {\n          \n          // acceptable CJK type: we form n-grams from these.\n          // as long as the offsets are aligned, we just add these to our current buffer.\n          // otherwise, we clear the buffer and start over.\n          \n          if (offsetAtt.startOffset() != lastEndOffset) { // unaligned, clear queue\n            if (hasBufferedUnigram()) {\n              \n              // we have a buffered unigram, and we peeked ahead to see if we could form\n              // a bigram, but we can't, because the offsets are unaligned. capture the state \n              // of this peeked data to be revisited next time thru the loop, and dump our unigram.\n              \n              loneState = captureState();\n              flushUnigram();\n              return true;\n            }\n            index = 0;\n            bufferLen = 0;\n          }\n          refill();\n        } else {\n          \n          // not a CJK type: we just return these as-is.\n          \n          if (hasBufferedUnigram()) {\n            \n            // we have a buffered unigram, and we peeked ahead to see if we could form\n            // a bigram, but we can't, because it's not a CJK type. capture the state \n            // of this peeked data to be revisited next time thru the loop, and dump our unigram.\n            \n            loneState = captureState();\n            flushUnigram();\n            return true;\n          }\n          return true;\n        }\n      } else {\n        \n        // case 3: we have only zero or 1 codepoints buffered, \n        // so not enough to form a bigram. But, we also have no\n        // more input. So if we have a buffered codepoint, emit\n        // a unigram, otherwise, it's end of stream.\n        \n        if (hasBufferedUnigram()) {\n          flushUnigram(); // flush our remaining unigram\n          return true;\n        }\n        return false;\n      }\n    }\n  }\n\n","sourceOld":"  /*\n   * much of this complexity revolves around handling the special case of a \n   * \"lone cjk character\" where cjktokenizer would output a unigram. this \n   * is also the only time we ever have to captureState.\n   */\n  @Override\n  public boolean incrementToken() throws IOException {\n    while (true) {\n      if (hasBufferedBigram()) {\n        \n        // case 1: we have multiple remaining codepoints buffered,\n        // so we can emit a bigram here.\n        \n        if (outputUnigrams) {\n\n          // when also outputting unigrams, we output the unigram first,\n          // then rewind back to revisit the bigram.\n          // so an input of ABC is A + (rewind)AB + B + (rewind)BC + C\n          // the logic in hasBufferedUnigram ensures we output the C, \n          // even though it did actually have adjacent CJK characters.\n\n          if (ngramState) {\n            flushBigram();\n          } else {\n            flushUnigram();\n            index--;\n          }\n          ngramState = !ngramState;\n        } else {\n          flushBigram();\n        }\n        return true;\n      } else if (doNext()) {\n        \n        // case 2: look at the token type. should we form any n-grams?\n        \n        String type = typeAtt.type();\n        if (type == doHan || type == doHiragana || type == doKatakana || type == doHangul) {\n          \n          // acceptable CJK type: we form n-grams from these.\n          // as long as the offsets are aligned, we just add these to our current buffer.\n          // otherwise, we clear the buffer and start over.\n          \n          if (offsetAtt.startOffset() != lastEndOffset) { // unaligned, clear queue\n            if (hasBufferedUnigram()) {\n              \n              // we have a buffered unigram, and we peeked ahead to see if we could form\n              // a bigram, but we can't, because the offsets are unaligned. capture the state \n              // of this peeked data to be revisited next time thru the loop, and dump our unigram.\n              \n              loneState = captureState();\n              flushUnigram();\n              return true;\n            }\n            index = 0;\n            bufferLen = 0;\n          }\n          refill();\n        } else {\n          \n          // not a CJK type: we just return these as-is.\n          \n          if (hasBufferedUnigram()) {\n            \n            // we have a buffered unigram, and we peeked ahead to see if we could form\n            // a bigram, but we can't, because its not a CJK type. capture the state \n            // of this peeked data to be revisited next time thru the loop, and dump our unigram.\n            \n            loneState = captureState();\n            flushUnigram();\n            return true;\n          }\n          return true;\n        }\n      } else {\n        \n        // case 3: we have only zero or 1 codepoints buffered, \n        // so not enough to form a bigram. But, we also have no\n        // more input. So if we have a buffered codepoint, emit\n        // a unigram, otherwise, its end of stream.\n        \n        if (hasBufferedUnigram()) {\n          flushUnigram(); // flush our remaining unigram\n          return true;\n        }\n        return false;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"8aa2bb13f56a3ad540fd2dc5e882e1ed4bf799d1":["1548959d8ee1230b6fe5bc9da6115d9fc4019bc9"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"c7869f64c874ebf7f317d22c00baf2b6857797a6":["b89678825b68eccaf09e6ab71675fc0b0af1e099","1548959d8ee1230b6fe5bc9da6115d9fc4019bc9"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d6f074e73200c07d54f242d3880a8da5a35ff97b":["b89678825b68eccaf09e6ab71675fc0b0af1e099","1548959d8ee1230b6fe5bc9da6115d9fc4019bc9"],"1548959d8ee1230b6fe5bc9da6115d9fc4019bc9":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["8aa2bb13f56a3ad540fd2dc5e882e1ed4bf799d1"]},"commit2Childs":{"8aa2bb13f56a3ad540fd2dc5e882e1ed4bf799d1":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["c7869f64c874ebf7f317d22c00baf2b6857797a6","d6f074e73200c07d54f242d3880a8da5a35ff97b","1548959d8ee1230b6fe5bc9da6115d9fc4019bc9"],"c7869f64c874ebf7f317d22c00baf2b6857797a6":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":[],"1548959d8ee1230b6fe5bc9da6115d9fc4019bc9":["8aa2bb13f56a3ad540fd2dc5e882e1ed4bf799d1","c7869f64c874ebf7f317d22c00baf2b6857797a6","d6f074e73200c07d54f242d3880a8da5a35ff97b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["c7869f64c874ebf7f317d22c00baf2b6857797a6","d6f074e73200c07d54f242d3880a8da5a35ff97b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}