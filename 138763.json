{"path":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#switchToOffline().mjava","commits":[{"id":"e3ce1ef883d26aa73919aa2d53991726e96caa13","date":1445421402,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#switchToOffline().mjava","pathOld":"/dev/null","sourceNew":"  /** If the current segment has too many points then we switchover to temp files / offline sort. */\n  private void switchToOffline() throws IOException {\n\n    // For each .add we just append to this input file, then in .finish we sort this input and resursively build the tree:\n    offlinePointWriter = new OfflinePointWriter(tempDir, tempFileNamePrefix, packedBytesLength);\n    PointReader reader = heapPointWriter.getReader(0);\n    for(int i=0;i<pointCount;i++) {\n      boolean hasNext = reader.next();\n      assert hasNext;\n      offlinePointWriter.append(reader.packedValue(), i, heapPointWriter.docIDs[i]);\n    }\n\n    heapPointWriter = null;\n    tempInput = offlinePointWriter.out;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5e0ee6f2f1bca6579b1a6d15b7157bfae948d8d7","date":1445465522,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#switchToOffline().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#switchToOffline().mjava","sourceNew":"  /** If the current segment has too many points then we switchover to temp files / offline sort. */\n  private void switchToOffline() throws IOException {\n\n    // For each .add we just append to this input file, then in .finish we sort this input and resursively build the tree:\n    offlinePointWriter = new OfflinePointWriter(tempDir, tempFileNamePrefix, packedBytesLength);\n    tempInput = offlinePointWriter.out;\n    PointReader reader = heapPointWriter.getReader(0);\n    for(int i=0;i<pointCount;i++) {\n      boolean hasNext = reader.next();\n      assert hasNext;\n      offlinePointWriter.append(reader.packedValue(), i, heapPointWriter.docIDs[i]);\n    }\n\n    heapPointWriter = null;\n  }\n\n","sourceOld":"  /** If the current segment has too many points then we switchover to temp files / offline sort. */\n  private void switchToOffline() throws IOException {\n\n    // For each .add we just append to this input file, then in .finish we sort this input and resursively build the tree:\n    offlinePointWriter = new OfflinePointWriter(tempDir, tempFileNamePrefix, packedBytesLength);\n    PointReader reader = heapPointWriter.getReader(0);\n    for(int i=0;i<pointCount;i++) {\n      boolean hasNext = reader.next();\n      assert hasNext;\n      offlinePointWriter.append(reader.packedValue(), i, heapPointWriter.docIDs[i]);\n    }\n\n    heapPointWriter = null;\n    tempInput = offlinePointWriter.out;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9a5a0f27d9486cd33de88627ed3d2ff8dc5074ca","date":1457777566,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#switchToOffline().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#switchToOffline().mjava","sourceNew":"  /** If the current segment has too many points then we switchover to temp files / offline sort. */\n  private void switchToOffline() throws IOException {\n\n    // For each .add we just append to this input file, then in .finish we sort this input and resursively build the tree:\n    offlinePointWriter = new OfflinePointWriter(tempDir, tempFileNamePrefix, packedBytesLength, longOrds);\n    tempInput = offlinePointWriter.out;\n    PointReader reader = heapPointWriter.getReader(0);\n    for(int i=0;i<pointCount;i++) {\n      boolean hasNext = reader.next();\n      assert hasNext;\n      offlinePointWriter.append(reader.packedValue(), i, heapPointWriter.docIDs[i]);\n    }\n\n    heapPointWriter = null;\n  }\n\n","sourceOld":"  /** If the current segment has too many points then we switchover to temp files / offline sort. */\n  private void switchToOffline() throws IOException {\n\n    // For each .add we just append to this input file, then in .finish we sort this input and resursively build the tree:\n    offlinePointWriter = new OfflinePointWriter(tempDir, tempFileNamePrefix, packedBytesLength);\n    tempInput = offlinePointWriter.out;\n    PointReader reader = heapPointWriter.getReader(0);\n    for(int i=0;i<pointCount;i++) {\n      boolean hasNext = reader.next();\n      assert hasNext;\n      offlinePointWriter.append(reader.packedValue(), i, heapPointWriter.docIDs[i]);\n    }\n\n    heapPointWriter = null;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"739dbfe581cd9ed58cc78180a0a8bf51f6a63b46","date":1457864929,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#switchToOffline().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#switchToOffline().mjava","sourceNew":"  /** If the current segment has too many points then we switchover to temp files / offline sort. */\n  private void switchToOffline() throws IOException {\n\n    // For each .add we just append to this input file, then in .finish we sort this input and resursively build the tree:\n    offlinePointWriter = new OfflinePointWriter(tempDir, tempFileNamePrefix, packedBytesLength, longOrds, \"switch\");\n    tempInput = offlinePointWriter.out;\n    PointReader reader = heapPointWriter.getReader(0);\n    for(int i=0;i<pointCount;i++) {\n      boolean hasNext = reader.next();\n      assert hasNext;\n      offlinePointWriter.append(reader.packedValue(), i, heapPointWriter.docIDs[i]);\n    }\n\n    heapPointWriter = null;\n  }\n\n","sourceOld":"  /** If the current segment has too many points then we switchover to temp files / offline sort. */\n  private void switchToOffline() throws IOException {\n\n    // For each .add we just append to this input file, then in .finish we sort this input and resursively build the tree:\n    offlinePointWriter = new OfflinePointWriter(tempDir, tempFileNamePrefix, packedBytesLength, longOrds);\n    tempInput = offlinePointWriter.out;\n    PointReader reader = heapPointWriter.getReader(0);\n    for(int i=0;i<pointCount;i++) {\n      boolean hasNext = reader.next();\n      assert hasNext;\n      offlinePointWriter.append(reader.packedValue(), i, heapPointWriter.docIDs[i]);\n    }\n\n    heapPointWriter = null;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2b84d416bbd661ae4b2a28d103bdfccb851e00de","date":1458041762,"type":5,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#spillToOffline().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#switchToOffline().mjava","sourceNew":"  /** If the current segment has too many points then we spill over to temp files / offline sort. */\n  private void spillToOffline() throws IOException {\n\n    // For each .add we just append to this input file, then in .finish we sort this input and resursively build the tree:\n    offlinePointWriter = new OfflinePointWriter(tempDir, tempFileNamePrefix, packedBytesLength, longOrds, \"spill\");\n    tempInput = offlinePointWriter.out;\n    PointReader reader = heapPointWriter.getReader(0);\n    for(int i=0;i<pointCount;i++) {\n      boolean hasNext = reader.next();\n      assert hasNext;\n      offlinePointWriter.append(reader.packedValue(), i, heapPointWriter.docIDs[i]);\n    }\n\n    heapPointWriter = null;\n  }\n\n","sourceOld":"  /** If the current segment has too many points then we switchover to temp files / offline sort. */\n  private void switchToOffline() throws IOException {\n\n    // For each .add we just append to this input file, then in .finish we sort this input and resursively build the tree:\n    offlinePointWriter = new OfflinePointWriter(tempDir, tempFileNamePrefix, packedBytesLength, longOrds, \"switch\");\n    tempInput = offlinePointWriter.out;\n    PointReader reader = heapPointWriter.getReader(0);\n    for(int i=0;i<pointCount;i++) {\n      boolean hasNext = reader.next();\n      assert hasNext;\n      offlinePointWriter.append(reader.packedValue(), i, heapPointWriter.docIDs[i]);\n    }\n\n    heapPointWriter = null;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"9a5a0f27d9486cd33de88627ed3d2ff8dc5074ca":["5e0ee6f2f1bca6579b1a6d15b7157bfae948d8d7"],"5e0ee6f2f1bca6579b1a6d15b7157bfae948d8d7":["e3ce1ef883d26aa73919aa2d53991726e96caa13"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"e3ce1ef883d26aa73919aa2d53991726e96caa13":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"2b84d416bbd661ae4b2a28d103bdfccb851e00de":["739dbfe581cd9ed58cc78180a0a8bf51f6a63b46"],"739dbfe581cd9ed58cc78180a0a8bf51f6a63b46":["9a5a0f27d9486cd33de88627ed3d2ff8dc5074ca"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["2b84d416bbd661ae4b2a28d103bdfccb851e00de"]},"commit2Childs":{"9a5a0f27d9486cd33de88627ed3d2ff8dc5074ca":["739dbfe581cd9ed58cc78180a0a8bf51f6a63b46"],"5e0ee6f2f1bca6579b1a6d15b7157bfae948d8d7":["9a5a0f27d9486cd33de88627ed3d2ff8dc5074ca"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["e3ce1ef883d26aa73919aa2d53991726e96caa13"],"e3ce1ef883d26aa73919aa2d53991726e96caa13":["5e0ee6f2f1bca6579b1a6d15b7157bfae948d8d7"],"2b84d416bbd661ae4b2a28d103bdfccb851e00de":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"739dbfe581cd9ed58cc78180a0a8bf51f6a63b46":["2b84d416bbd661ae4b2a28d103bdfccb851e00de"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}