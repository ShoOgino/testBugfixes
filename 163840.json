{"path":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumNoReuse().mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumNoReuse().mjava","pathOld":"lucene/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumNoReuse().mjava","sourceNew":"  public void testReuseDocsEnumNoReuse() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random);\n    writer.commit();\n\n    DirectoryReader open = DirectoryReader.open(dir);\n    new ReaderUtil.Gather(open) {\n      @Override\n      protected void add(int base, AtomicReader r) throws IOException {\n        Terms terms = r.terms(\"body\");\n        TermsEnum iterator = terms.iterator(null);\n        IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n        MatchNoBits bits = new Bits.MatchNoBits(r.maxDoc());\n        while ((iterator.next()) != null) {\n          DocsEnum docs = iterator.docs(random.nextBoolean() ? bits : new Bits.MatchNoBits(r.maxDoc()), null, random.nextBoolean());\n          enums.put(docs, true);\n        }\n        \n        assertEquals(terms.getUniqueTermCount(), enums.size());  \n      }\n    }.run();\n    IOUtils.close(writer, open, dir);\n  }\n\n","sourceOld":"  public void testReuseDocsEnumNoReuse() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random);\n    writer.commit();\n\n    DirectoryReader open = DirectoryReader.open(dir);\n    new ReaderUtil.Gather(open) {\n      @Override\n      protected void add(int base, AtomicReader r) throws IOException {\n        Terms terms = r.terms(\"body\");\n        TermsEnum iterator = terms.iterator(null);\n        IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n        MatchNoBits bits = new Bits.MatchNoBits(r.maxDoc());\n        while ((iterator.next()) != null) {\n          DocsEnum docs = iterator.docs(random.nextBoolean() ? bits : new Bits.MatchNoBits(r.maxDoc()), null, random.nextBoolean());\n          enums.put(docs, true);\n        }\n        \n        assertEquals(terms.getUniqueTermCount(), enums.size());  \n      }\n    }.run();\n    IOUtils.close(writer, open, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bdb5e42b0cecd8dfb27767a02ada71899bf17917","date":1334100099,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumNoReuse().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumNoReuse().mjava","sourceNew":"  public void testReuseDocsEnumNoReuse() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random);\n    writer.commit();\n\n    DirectoryReader open = DirectoryReader.open(dir);\n    new ReaderUtil.Gather(open) {\n      @Override\n      protected void add(int base, AtomicReader r) throws IOException {\n        Terms terms = r.terms(\"body\");\n        TermsEnum iterator = terms.iterator(null);\n        IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n        MatchNoBits bits = new Bits.MatchNoBits(r.maxDoc());\n        while ((iterator.next()) != null) {\n          DocsEnum docs = iterator.docs(random.nextBoolean() ? bits : new Bits.MatchNoBits(r.maxDoc()), null, random.nextBoolean());\n          enums.put(docs, true);\n        }\n        \n        assertEquals(terms.size(), enums.size());\n      }\n    }.run();\n    IOUtils.close(writer, open, dir);\n  }\n\n","sourceOld":"  public void testReuseDocsEnumNoReuse() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random);\n    writer.commit();\n\n    DirectoryReader open = DirectoryReader.open(dir);\n    new ReaderUtil.Gather(open) {\n      @Override\n      protected void add(int base, AtomicReader r) throws IOException {\n        Terms terms = r.terms(\"body\");\n        TermsEnum iterator = terms.iterator(null);\n        IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n        MatchNoBits bits = new Bits.MatchNoBits(r.maxDoc());\n        while ((iterator.next()) != null) {\n          DocsEnum docs = iterator.docs(random.nextBoolean() ? bits : new Bits.MatchNoBits(r.maxDoc()), null, random.nextBoolean());\n          enums.put(docs, true);\n        }\n        \n        assertEquals(terms.getUniqueTermCount(), enums.size());  \n      }\n    }.run();\n    IOUtils.close(writer, open, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5a238fc456663f685a9db1ed8d680e348bb45171","date":1334173266,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumNoReuse().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumNoReuse().mjava","sourceNew":"  public void testReuseDocsEnumNoReuse() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random);\n    writer.commit();\n\n    DirectoryReader open = DirectoryReader.open(dir);\n    new ReaderUtil.Gather(open) {\n      @Override\n      protected void add(int base, AtomicReader r) throws IOException {\n        Terms terms = r.terms(\"body\");\n        TermsEnum iterator = terms.iterator(null);\n        IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n        MatchNoBits bits = new Bits.MatchNoBits(r.maxDoc());\n        while ((iterator.next()) != null) {\n          DocsEnum docs = iterator.docs(random.nextBoolean() ? bits : new Bits.MatchNoBits(r.maxDoc()), null, random.nextBoolean());\n          enums.put(docs, true);\n        }\n        \n        assertEquals(terms.size(), enums.size());\n      }\n    }.run();\n    IOUtils.close(writer, open, dir);\n  }\n\n","sourceOld":"  public void testReuseDocsEnumNoReuse() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random);\n    writer.commit();\n\n    DirectoryReader open = DirectoryReader.open(dir);\n    new ReaderUtil.Gather(open) {\n      @Override\n      protected void add(int base, AtomicReader r) throws IOException {\n        Terms terms = r.terms(\"body\");\n        TermsEnum iterator = terms.iterator(null);\n        IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n        MatchNoBits bits = new Bits.MatchNoBits(r.maxDoc());\n        while ((iterator.next()) != null) {\n          DocsEnum docs = iterator.docs(random.nextBoolean() ? bits : new Bits.MatchNoBits(r.maxDoc()), null, random.nextBoolean());\n          enums.put(docs, true);\n        }\n        \n        assertEquals(terms.getUniqueTermCount(), enums.size());  \n      }\n    }.run();\n    IOUtils.close(writer, open, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumNoReuse().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumNoReuse().mjava","sourceNew":"  public void testReuseDocsEnumNoReuse() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader open = DirectoryReader.open(dir);\n    new ReaderUtil.Gather(open) {\n      @Override\n      protected void add(int base, AtomicReader r) throws IOException {\n        Terms terms = r.terms(\"body\");\n        TermsEnum iterator = terms.iterator(null);\n        IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n        MatchNoBits bits = new Bits.MatchNoBits(r.maxDoc());\n        while ((iterator.next()) != null) {\n          DocsEnum docs = iterator.docs(random().nextBoolean() ? bits : new Bits.MatchNoBits(r.maxDoc()), null, random().nextBoolean());\n          enums.put(docs, true);\n        }\n        \n        assertEquals(terms.size(), enums.size());\n      }\n    }.run();\n    IOUtils.close(writer, open, dir);\n  }\n\n","sourceOld":"  public void testReuseDocsEnumNoReuse() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random);\n    writer.commit();\n\n    DirectoryReader open = DirectoryReader.open(dir);\n    new ReaderUtil.Gather(open) {\n      @Override\n      protected void add(int base, AtomicReader r) throws IOException {\n        Terms terms = r.terms(\"body\");\n        TermsEnum iterator = terms.iterator(null);\n        IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n        MatchNoBits bits = new Bits.MatchNoBits(r.maxDoc());\n        while ((iterator.next()) != null) {\n          DocsEnum docs = iterator.docs(random.nextBoolean() ? bits : new Bits.MatchNoBits(r.maxDoc()), null, random.nextBoolean());\n          enums.put(docs, true);\n        }\n        \n        assertEquals(terms.size(), enums.size());\n      }\n    }.run();\n    IOUtils.close(writer, open, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c","date":1340090669,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumNoReuse().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumNoReuse().mjava","sourceNew":"  public void testReuseDocsEnumNoReuse() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader open = DirectoryReader.open(dir);\n    for (AtomicReader indexReader : open.getSequentialSubReaders()) {\n      Terms terms = indexReader.terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(indexReader.maxDoc());\n      while ((iterator.next()) != null) {\n        DocsEnum docs = iterator.docs(random().nextBoolean() ? bits : new Bits.MatchNoBits(indexReader.maxDoc()), null, random().nextBoolean());\n        enums.put(docs, true);\n      }\n      \n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, open, dir);\n  }\n\n","sourceOld":"  public void testReuseDocsEnumNoReuse() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader open = DirectoryReader.open(dir);\n    new ReaderUtil.Gather(open) {\n      @Override\n      protected void add(int base, AtomicReader r) throws IOException {\n        Terms terms = r.terms(\"body\");\n        TermsEnum iterator = terms.iterator(null);\n        IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n        MatchNoBits bits = new Bits.MatchNoBits(r.maxDoc());\n        while ((iterator.next()) != null) {\n          DocsEnum docs = iterator.docs(random().nextBoolean() ? bits : new Bits.MatchNoBits(r.maxDoc()), null, random().nextBoolean());\n          enums.put(docs, true);\n        }\n        \n        assertEquals(terms.size(), enums.size());\n      }\n    }.run();\n    IOUtils.close(writer, open, dir);\n  }\n\n","bugFix":null,"bugIntro":["ced66195b26fdb1f77ee00e2a77ec6918dedd766","02331260bb246364779cb6f04919ca47900d01bb"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"02331260bb246364779cb6f04919ca47900d01bb","date":1343749884,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumNoReuse().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumNoReuse().mjava","sourceNew":"  public void testReuseDocsEnumNoReuse() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader open = DirectoryReader.open(dir);\n    for (AtomicReader indexReader : open.getSequentialSubReaders()) {\n      Terms terms = indexReader.terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(indexReader.maxDoc());\n      while ((iterator.next()) != null) {\n        DocsEnum docs = iterator.docs(random().nextBoolean() ? bits : new Bits.MatchNoBits(indexReader.maxDoc()), null, random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      \n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, open, dir);\n  }\n\n","sourceOld":"  public void testReuseDocsEnumNoReuse() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader open = DirectoryReader.open(dir);\n    for (AtomicReader indexReader : open.getSequentialSubReaders()) {\n      Terms terms = indexReader.terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(indexReader.maxDoc());\n      while ((iterator.next()) != null) {\n        DocsEnum docs = iterator.docs(random().nextBoolean() ? bits : new Bits.MatchNoBits(indexReader.maxDoc()), null, random().nextBoolean());\n        enums.put(docs, true);\n      }\n      \n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, open, dir);\n  }\n\n","bugFix":["4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","date":1343768312,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumNoReuse().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumNoReuse().mjava","sourceNew":"  public void testReuseDocsEnumNoReuse() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader open = DirectoryReader.open(dir);\n    for (AtomicReader indexReader : open.getSequentialSubReaders()) {\n      Terms terms = indexReader.terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(indexReader.maxDoc());\n      while ((iterator.next()) != null) {\n        DocsEnum docs = iterator.docs(random().nextBoolean() ? bits : new Bits.MatchNoBits(indexReader.maxDoc()), null, random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      \n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, open, dir);\n  }\n\n","sourceOld":"  public void testReuseDocsEnumNoReuse() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader open = DirectoryReader.open(dir);\n    for (AtomicReader indexReader : open.getSequentialSubReaders()) {\n      Terms terms = indexReader.terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(indexReader.maxDoc());\n      while ((iterator.next()) != null) {\n        DocsEnum docs = iterator.docs(random().nextBoolean() ? bits : new Bits.MatchNoBits(indexReader.maxDoc()), null, random().nextBoolean());\n        enums.put(docs, true);\n      }\n      \n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, open, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d6f074e73200c07d54f242d3880a8da5a35ff97b","date":1344507653,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumNoReuse().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumNoReuse().mjava","sourceNew":"  public void testReuseDocsEnumNoReuse() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader open = DirectoryReader.open(dir);\n    for (AtomicReader indexReader : open.getSequentialSubReaders()) {\n      Terms terms = indexReader.terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(indexReader.maxDoc());\n      while ((iterator.next()) != null) {\n        DocsEnum docs = iterator.docs(random().nextBoolean() ? bits : new Bits.MatchNoBits(indexReader.maxDoc()), null, random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      \n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, open, dir);\n  }\n\n","sourceOld":"  public void testReuseDocsEnumNoReuse() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader open = DirectoryReader.open(dir);\n    for (AtomicReader indexReader : open.getSequentialSubReaders()) {\n      Terms terms = indexReader.terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(indexReader.maxDoc());\n      while ((iterator.next()) != null) {\n        DocsEnum docs = iterator.docs(random().nextBoolean() ? bits : new Bits.MatchNoBits(indexReader.maxDoc()), null, random().nextBoolean());\n        enums.put(docs, true);\n      }\n      \n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, open, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ced66195b26fdb1f77ee00e2a77ec6918dedd766","date":1344948886,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumNoReuse().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumNoReuse().mjava","sourceNew":"  public void testReuseDocsEnumNoReuse() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader open = DirectoryReader.open(dir);\n    for (AtomicReaderContext ctx : open.leaves()) {\n      AtomicReader indexReader = ctx.reader();\n      Terms terms = indexReader.terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(indexReader.maxDoc());\n      while ((iterator.next()) != null) {\n        DocsEnum docs = iterator.docs(random().nextBoolean() ? bits : new Bits.MatchNoBits(indexReader.maxDoc()), null, random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      \n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, open, dir);\n  }\n\n","sourceOld":"  public void testReuseDocsEnumNoReuse() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader open = DirectoryReader.open(dir);\n    for (AtomicReader indexReader : open.getSequentialSubReaders()) {\n      Terms terms = indexReader.terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(indexReader.maxDoc());\n      while ((iterator.next()) != null) {\n        DocsEnum docs = iterator.docs(random().nextBoolean() ? bits : new Bits.MatchNoBits(indexReader.maxDoc()), null, random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      \n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, open, dir);\n  }\n\n","bugFix":["4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198","date":1345029782,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumNoReuse().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumNoReuse().mjava","sourceNew":"  public void testReuseDocsEnumNoReuse() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader open = DirectoryReader.open(dir);\n    for (AtomicReaderContext ctx : open.leaves()) {\n      AtomicReader indexReader = ctx.reader();\n      Terms terms = indexReader.terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(indexReader.maxDoc());\n      while ((iterator.next()) != null) {\n        DocsEnum docs = iterator.docs(random().nextBoolean() ? bits : new Bits.MatchNoBits(indexReader.maxDoc()), null, random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      \n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, open, dir);\n  }\n\n","sourceOld":"  public void testReuseDocsEnumNoReuse() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader open = DirectoryReader.open(dir);\n    for (AtomicReader indexReader : open.getSequentialSubReaders()) {\n      Terms terms = indexReader.terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(indexReader.maxDoc());\n      while ((iterator.next()) != null) {\n        DocsEnum docs = iterator.docs(random().nextBoolean() ? bits : new Bits.MatchNoBits(indexReader.maxDoc()), null, random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      \n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, open, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3c188105a9aae04f56c24996f98f8333fc825d2e","date":1345031914,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumNoReuse().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumNoReuse().mjava","sourceNew":"  public void testReuseDocsEnumNoReuse() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader open = DirectoryReader.open(dir);\n    for (AtomicReaderContext ctx : open.leaves()) {\n      AtomicReader indexReader = ctx.reader();\n      Terms terms = indexReader.terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(indexReader.maxDoc());\n      while ((iterator.next()) != null) {\n        DocsEnum docs = iterator.docs(random().nextBoolean() ? bits : new Bits.MatchNoBits(indexReader.maxDoc()), null, random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      \n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, open, dir);\n  }\n\n","sourceOld":"  public void testReuseDocsEnumNoReuse() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader open = DirectoryReader.open(dir);\n    for (AtomicReader indexReader : open.getSequentialSubReaders()) {\n      Terms terms = indexReader.terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(indexReader.maxDoc());\n      while ((iterator.next()) != null) {\n        DocsEnum docs = iterator.docs(random().nextBoolean() ? bits : new Bits.MatchNoBits(indexReader.maxDoc()), null, random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      \n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, open, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1c93396a1df03720cb20e2c2f513a6fa59b21e4c","date":1345032673,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumNoReuse().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumNoReuse().mjava","sourceNew":"  public void testReuseDocsEnumNoReuse() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader open = DirectoryReader.open(dir);\n    for (AtomicReader indexReader : open.getSequentialSubReaders()) {\n      Terms terms = indexReader.terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(indexReader.maxDoc());\n      while ((iterator.next()) != null) {\n        DocsEnum docs = iterator.docs(random().nextBoolean() ? bits : new Bits.MatchNoBits(indexReader.maxDoc()), null, random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      \n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, open, dir);\n  }\n\n","sourceOld":"  public void testReuseDocsEnumNoReuse() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader open = DirectoryReader.open(dir);\n    for (AtomicReaderContext ctx : open.leaves()) {\n      AtomicReader indexReader = ctx.reader();\n      Terms terms = indexReader.terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(indexReader.maxDoc());\n      while ((iterator.next()) != null) {\n        DocsEnum docs = iterator.docs(random().nextBoolean() ? bits : new Bits.MatchNoBits(indexReader.maxDoc()), null, random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      \n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, open, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b05c56a41b733e02a189c48895922b5bd8c7f3d1","date":1345033322,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumNoReuse().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumNoReuse().mjava","sourceNew":"  public void testReuseDocsEnumNoReuse() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader open = DirectoryReader.open(dir);\n    for (AtomicReaderContext ctx : open.leaves()) {\n      AtomicReader indexReader = ctx.reader();\n      Terms terms = indexReader.terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(indexReader.maxDoc());\n      while ((iterator.next()) != null) {\n        DocsEnum docs = iterator.docs(random().nextBoolean() ? bits : new Bits.MatchNoBits(indexReader.maxDoc()), null, random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      \n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, open, dir);\n  }\n\n","sourceOld":"  public void testReuseDocsEnumNoReuse() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader open = DirectoryReader.open(dir);\n    for (AtomicReader indexReader : open.getSequentialSubReaders()) {\n      Terms terms = indexReader.terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(indexReader.maxDoc());\n      while ((iterator.next()) != null) {\n        DocsEnum docs = iterator.docs(random().nextBoolean() ? bits : new Bits.MatchNoBits(indexReader.maxDoc()), null, random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      \n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, open, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6616b1fd222bb5a60f7f7856ace312252bc97890","date":1350142044,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumNoReuse().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumNoReuse().mjava","sourceNew":"  public void testReuseDocsEnumNoReuse() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40RWPostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader open = DirectoryReader.open(dir);\n    for (AtomicReaderContext ctx : open.leaves()) {\n      AtomicReader indexReader = ctx.reader();\n      Terms terms = indexReader.terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(indexReader.maxDoc());\n      while ((iterator.next()) != null) {\n        DocsEnum docs = iterator.docs(random().nextBoolean() ? bits : new Bits.MatchNoBits(indexReader.maxDoc()), null, random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      \n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, open, dir);\n  }\n\n","sourceOld":"  public void testReuseDocsEnumNoReuse() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader open = DirectoryReader.open(dir);\n    for (AtomicReaderContext ctx : open.leaves()) {\n      AtomicReader indexReader = ctx.reader();\n      Terms terms = indexReader.terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(indexReader.maxDoc());\n      while ((iterator.next()) != null) {\n        DocsEnum docs = iterator.docs(random().nextBoolean() ? bits : new Bits.MatchNoBits(indexReader.maxDoc()), null, random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      \n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, open, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c7492bcb52be51e55d596134b95b2e53cc4ffb91","date":1350223278,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumNoReuse().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumNoReuse().mjava","sourceNew":"  public void testReuseDocsEnumNoReuse() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40RWPostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader open = DirectoryReader.open(dir);\n    for (AtomicReaderContext ctx : open.leaves()) {\n      AtomicReader indexReader = ctx.reader();\n      Terms terms = indexReader.terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(indexReader.maxDoc());\n      while ((iterator.next()) != null) {\n        DocsEnum docs = iterator.docs(random().nextBoolean() ? bits : new Bits.MatchNoBits(indexReader.maxDoc()), null, random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      \n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, open, dir);\n  }\n\n","sourceOld":"  public void testReuseDocsEnumNoReuse() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader open = DirectoryReader.open(dir);\n    for (AtomicReaderContext ctx : open.leaves()) {\n      AtomicReader indexReader = ctx.reader();\n      Terms terms = indexReader.terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(indexReader.maxDoc());\n      while ((iterator.next()) != null) {\n        DocsEnum docs = iterator.docs(random().nextBoolean() ? bits : new Bits.MatchNoBits(indexReader.maxDoc()), null, random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      \n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, open, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"db4fdbf3d262768eabc027cd8321edca0cd11fa8","date":1350574784,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumNoReuse().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumNoReuse().mjava","sourceNew":"  public void testReuseDocsEnumNoReuse() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40RWPostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader open = DirectoryReader.open(dir);\n    for (AtomicReaderContext ctx : open.leaves()) {\n      AtomicReader indexReader = ctx.reader();\n      Terms terms = indexReader.terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(indexReader.maxDoc());\n      while ((iterator.next()) != null) {\n        DocsEnum docs = iterator.docs(random().nextBoolean() ? bits : new Bits.MatchNoBits(indexReader.maxDoc()), null, random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      \n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, open, dir);\n  }\n\n","sourceOld":"  public void testReuseDocsEnumNoReuse() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader open = DirectoryReader.open(dir);\n    for (AtomicReaderContext ctx : open.leaves()) {\n      AtomicReader indexReader = ctx.reader();\n      Terms terms = indexReader.terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(indexReader.maxDoc());\n      while ((iterator.next()) != null) {\n        DocsEnum docs = iterator.docs(random().nextBoolean() ? bits : new Bits.MatchNoBits(indexReader.maxDoc()), null, random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      \n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, open, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"15250ca94ba8ab3bcdd476daf6bf3f3febb92640","date":1355200097,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumNoReuse().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumNoReuse().mjava","sourceNew":"  public void testReuseDocsEnumNoReuse() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40RWPostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader open = DirectoryReader.open(dir);\n    for (AtomicReaderContext ctx : open.leaves()) {\n      AtomicReader indexReader = ctx.reader();\n      Terms terms = indexReader.terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(indexReader.maxDoc());\n      while ((iterator.next()) != null) {\n        DocsEnum docs = iterator.docs(random().nextBoolean() ? bits : new Bits.MatchNoBits(indexReader.maxDoc()), null, random().nextBoolean() ? DocsEnum.FLAG_FREQS : DocsEnum.FLAG_NONE);\n        enums.put(docs, true);\n      }\n      \n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, open, dir);\n  }\n\n","sourceOld":"  public void testReuseDocsEnumNoReuse() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40RWPostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader open = DirectoryReader.open(dir);\n    for (AtomicReaderContext ctx : open.leaves()) {\n      AtomicReader indexReader = ctx.reader();\n      Terms terms = indexReader.terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(indexReader.maxDoc());\n      while ((iterator.next()) != null) {\n        DocsEnum docs = iterator.docs(random().nextBoolean() ? bits : new Bits.MatchNoBits(indexReader.maxDoc()), null, random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      \n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, open, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d3fcb70cf561547c7bb1506e0cf32ca7b1287064","date":1357616416,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumNoReuse().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumNoReuse().mjava","sourceNew":"  public void testReuseDocsEnumNoReuse() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40RWPostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader open = DirectoryReader.open(dir);\n    for (AtomicReaderContext ctx : open.leaves()) {\n      AtomicReader indexReader = ctx.reader();\n      Terms terms = indexReader.terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(indexReader.maxDoc());\n      while ((iterator.next()) != null) {\n        DocsEnum docs = iterator.docs(random().nextBoolean() ? bits : new Bits.MatchNoBits(indexReader.maxDoc()), null, random().nextBoolean() ? DocsEnum.FLAG_FREQS : DocsEnum.FLAG_NONE);\n        enums.put(docs, true);\n      }\n      \n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, open, dir);\n  }\n\n","sourceOld":"  public void testReuseDocsEnumNoReuse() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40RWPostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader open = DirectoryReader.open(dir);\n    for (AtomicReaderContext ctx : open.leaves()) {\n      AtomicReader indexReader = ctx.reader();\n      Terms terms = indexReader.terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(indexReader.maxDoc());\n      while ((iterator.next()) != null) {\n        DocsEnum docs = iterator.docs(random().nextBoolean() ? bits : new Bits.MatchNoBits(indexReader.maxDoc()), null, random().nextBoolean() ? DocsEnum.FLAG_FREQS : 0);\n        enums.put(docs, true);\n      }\n      \n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, open, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6613659748fe4411a7dcf85266e55db1f95f7315","date":1392773913,"type":3,"author":"Benson Margulies","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumNoReuse().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumNoReuse().mjava","sourceNew":"  public void testReuseDocsEnumNoReuse() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = TestUtil.alwaysPostingsFormat(new Lucene40RWPostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader open = DirectoryReader.open(dir);\n    for (AtomicReaderContext ctx : open.leaves()) {\n      AtomicReader indexReader = ctx.reader();\n      Terms terms = indexReader.terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(indexReader.maxDoc());\n      while ((iterator.next()) != null) {\n        DocsEnum docs = iterator.docs(random().nextBoolean() ? bits : new Bits.MatchNoBits(indexReader.maxDoc()), null, random().nextBoolean() ? DocsEnum.FLAG_FREQS : DocsEnum.FLAG_NONE);\n        enums.put(docs, true);\n      }\n      \n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, open, dir);\n  }\n\n","sourceOld":"  public void testReuseDocsEnumNoReuse() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40RWPostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader open = DirectoryReader.open(dir);\n    for (AtomicReaderContext ctx : open.leaves()) {\n      AtomicReader indexReader = ctx.reader();\n      Terms terms = indexReader.terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(indexReader.maxDoc());\n      while ((iterator.next()) != null) {\n        DocsEnum docs = iterator.docs(random().nextBoolean() ? bits : new Bits.MatchNoBits(indexReader.maxDoc()), null, random().nextBoolean() ? DocsEnum.FLAG_FREQS : DocsEnum.FLAG_NONE);\n        enums.put(docs, true);\n      }\n      \n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, open, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumNoReuse().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumNoReuse().mjava","sourceNew":"  public void testReuseDocsEnumNoReuse() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = TestUtil.alwaysPostingsFormat(new Lucene40RWPostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader open = DirectoryReader.open(dir);\n    for (AtomicReaderContext ctx : open.leaves()) {\n      AtomicReader indexReader = ctx.reader();\n      Terms terms = indexReader.terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<>();\n      MatchNoBits bits = new Bits.MatchNoBits(indexReader.maxDoc());\n      while ((iterator.next()) != null) {\n        DocsEnum docs = iterator.docs(random().nextBoolean() ? bits : new Bits.MatchNoBits(indexReader.maxDoc()), null, random().nextBoolean() ? DocsEnum.FLAG_FREQS : DocsEnum.FLAG_NONE);\n        enums.put(docs, true);\n      }\n      \n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, open, dir);\n  }\n\n","sourceOld":"  public void testReuseDocsEnumNoReuse() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = TestUtil.alwaysPostingsFormat(new Lucene40RWPostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader open = DirectoryReader.open(dir);\n    for (AtomicReaderContext ctx : open.leaves()) {\n      AtomicReader indexReader = ctx.reader();\n      Terms terms = indexReader.terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(indexReader.maxDoc());\n      while ((iterator.next()) != null) {\n        DocsEnum docs = iterator.docs(random().nextBoolean() ? bits : new Bits.MatchNoBits(indexReader.maxDoc()), null, random().nextBoolean() ? DocsEnum.FLAG_FREQS : DocsEnum.FLAG_NONE);\n        enums.put(docs, true);\n      }\n      \n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, open, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumNoReuse().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumNoReuse().mjava","sourceNew":"  public void testReuseDocsEnumNoReuse() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = TestUtil.alwaysPostingsFormat(new Lucene40RWPostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader open = DirectoryReader.open(dir);\n    for (AtomicReaderContext ctx : open.leaves()) {\n      AtomicReader indexReader = ctx.reader();\n      Terms terms = indexReader.terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<>();\n      MatchNoBits bits = new Bits.MatchNoBits(indexReader.maxDoc());\n      while ((iterator.next()) != null) {\n        DocsEnum docs = iterator.docs(random().nextBoolean() ? bits : new Bits.MatchNoBits(indexReader.maxDoc()), null, random().nextBoolean() ? DocsEnum.FLAG_FREQS : DocsEnum.FLAG_NONE);\n        enums.put(docs, true);\n      }\n      \n      assertEquals(terms.size(), enums.size());\n    }\n    writer.commit();\n    IOUtils.close(writer, open, dir);\n  }\n\n","sourceOld":"  public void testReuseDocsEnumNoReuse() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = TestUtil.alwaysPostingsFormat(new Lucene40RWPostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader open = DirectoryReader.open(dir);\n    for (AtomicReaderContext ctx : open.leaves()) {\n      AtomicReader indexReader = ctx.reader();\n      Terms terms = indexReader.terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<>();\n      MatchNoBits bits = new Bits.MatchNoBits(indexReader.maxDoc());\n      while ((iterator.next()) != null) {\n        DocsEnum docs = iterator.docs(random().nextBoolean() ? bits : new Bits.MatchNoBits(indexReader.maxDoc()), null, random().nextBoolean() ? DocsEnum.FLAG_FREQS : DocsEnum.FLAG_NONE);\n        enums.put(docs, true);\n      }\n      \n      assertEquals(terms.size(), enums.size());\n    }\n    IOUtils.close(writer, open, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumNoReuse().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumNoReuse().mjava","sourceNew":"  public void testReuseDocsEnumNoReuse() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = TestUtil.alwaysPostingsFormat(new Lucene40RWPostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader open = DirectoryReader.open(dir);\n    for (AtomicReaderContext ctx : open.leaves()) {\n      AtomicReader indexReader = ctx.reader();\n      Terms terms = indexReader.terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<>();\n      MatchNoBits bits = new Bits.MatchNoBits(indexReader.maxDoc());\n      while ((iterator.next()) != null) {\n        DocsEnum docs = iterator.docs(random().nextBoolean() ? bits : new Bits.MatchNoBits(indexReader.maxDoc()), null, random().nextBoolean() ? DocsEnum.FLAG_FREQS : DocsEnum.FLAG_NONE);\n        enums.put(docs, true);\n      }\n      \n      assertEquals(terms.size(), enums.size());\n    }\n    writer.commit();\n    IOUtils.close(writer, open, dir);\n  }\n\n","sourceOld":"  public void testReuseDocsEnumNoReuse() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = TestUtil.alwaysPostingsFormat(new Lucene40RWPostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader open = DirectoryReader.open(dir);\n    for (AtomicReaderContext ctx : open.leaves()) {\n      AtomicReader indexReader = ctx.reader();\n      Terms terms = indexReader.terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<>();\n      MatchNoBits bits = new Bits.MatchNoBits(indexReader.maxDoc());\n      while ((iterator.next()) != null) {\n        DocsEnum docs = iterator.docs(random().nextBoolean() ? bits : new Bits.MatchNoBits(indexReader.maxDoc()), null, random().nextBoolean() ? DocsEnum.FLAG_FREQS : DocsEnum.FLAG_NONE);\n        enums.put(docs, true);\n      }\n      \n      assertEquals(terms.size(), enums.size());\n    }\n    writer.commit();\n    IOUtils.close(writer, open, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cc45c615dbb82bf79d5f9550286098367874fbf","date":1409571423,"type":5,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/backward-codecs/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumNoReuse().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumNoReuse().mjava","sourceNew":"  public void testReuseDocsEnumNoReuse() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = TestUtil.alwaysPostingsFormat(new Lucene40RWPostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader open = DirectoryReader.open(dir);\n    for (AtomicReaderContext ctx : open.leaves()) {\n      AtomicReader indexReader = ctx.reader();\n      Terms terms = indexReader.terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<>();\n      MatchNoBits bits = new Bits.MatchNoBits(indexReader.maxDoc());\n      while ((iterator.next()) != null) {\n        DocsEnum docs = iterator.docs(random().nextBoolean() ? bits : new Bits.MatchNoBits(indexReader.maxDoc()), null, random().nextBoolean() ? DocsEnum.FLAG_FREQS : DocsEnum.FLAG_NONE);\n        enums.put(docs, true);\n      }\n      \n      assertEquals(terms.size(), enums.size());\n    }\n    writer.commit();\n    IOUtils.close(writer, open, dir);\n  }\n\n","sourceOld":"  public void testReuseDocsEnumNoReuse() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = TestUtil.alwaysPostingsFormat(new Lucene40RWPostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader open = DirectoryReader.open(dir);\n    for (AtomicReaderContext ctx : open.leaves()) {\n      AtomicReader indexReader = ctx.reader();\n      Terms terms = indexReader.terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<>();\n      MatchNoBits bits = new Bits.MatchNoBits(indexReader.maxDoc());\n      while ((iterator.next()) != null) {\n        DocsEnum docs = iterator.docs(random().nextBoolean() ? bits : new Bits.MatchNoBits(indexReader.maxDoc()), null, random().nextBoolean() ? DocsEnum.FLAG_FREQS : DocsEnum.FLAG_NONE);\n        enums.put(docs, true);\n      }\n      \n      assertEquals(terms.size(), enums.size());\n    }\n    writer.commit();\n    IOUtils.close(writer, open, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"402ad3ddc9da7b70da1b167667a60ece6a1381fb","date":1409656478,"type":5,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/backward-codecs/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumNoReuse().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumNoReuse().mjava","sourceNew":"  public void testReuseDocsEnumNoReuse() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = TestUtil.alwaysPostingsFormat(new Lucene40RWPostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader open = DirectoryReader.open(dir);\n    for (AtomicReaderContext ctx : open.leaves()) {\n      AtomicReader indexReader = ctx.reader();\n      Terms terms = indexReader.terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<>();\n      MatchNoBits bits = new Bits.MatchNoBits(indexReader.maxDoc());\n      while ((iterator.next()) != null) {\n        DocsEnum docs = iterator.docs(random().nextBoolean() ? bits : new Bits.MatchNoBits(indexReader.maxDoc()), null, random().nextBoolean() ? DocsEnum.FLAG_FREQS : DocsEnum.FLAG_NONE);\n        enums.put(docs, true);\n      }\n      \n      assertEquals(terms.size(), enums.size());\n    }\n    writer.commit();\n    IOUtils.close(writer, open, dir);\n  }\n\n","sourceOld":"  public void testReuseDocsEnumNoReuse() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = TestUtil.alwaysPostingsFormat(new Lucene40RWPostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(new MockAnalyzer(random())).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random());\n    writer.commit();\n\n    DirectoryReader open = DirectoryReader.open(dir);\n    for (AtomicReaderContext ctx : open.leaves()) {\n      AtomicReader indexReader = ctx.reader();\n      Terms terms = indexReader.terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<>();\n      MatchNoBits bits = new Bits.MatchNoBits(indexReader.maxDoc());\n      while ((iterator.next()) != null) {\n        DocsEnum docs = iterator.docs(random().nextBoolean() ? bits : new Bits.MatchNoBits(indexReader.maxDoc()), null, random().nextBoolean() ? DocsEnum.FLAG_FREQS : DocsEnum.FLAG_NONE);\n        enums.put(docs, true);\n      }\n      \n      assertEquals(terms.size(), enums.size());\n    }\n    writer.commit();\n    IOUtils.close(writer, open, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":["c7492bcb52be51e55d596134b95b2e53cc4ffb91","15250ca94ba8ab3bcdd476daf6bf3f3febb92640"],"bdb5e42b0cecd8dfb27767a02ada71899bf17917":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"3c188105a9aae04f56c24996f98f8333fc825d2e":["b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f"],"b05c56a41b733e02a189c48895922b5bd8c7f3d1":["1c93396a1df03720cb20e2c2f513a6fa59b21e4c","ced66195b26fdb1f77ee00e2a77ec6918dedd766"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198":["d6f074e73200c07d54f242d3880a8da5a35ff97b","ced66195b26fdb1f77ee00e2a77ec6918dedd766"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"4cc45c615dbb82bf79d5f9550286098367874fbf":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"ced66195b26fdb1f77ee00e2a77ec6918dedd766":["02331260bb246364779cb6f04919ca47900d01bb"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["6613659748fe4411a7dcf85266e55db1f95f7315"],"6616b1fd222bb5a60f7f7856ace312252bc97890":["ced66195b26fdb1f77ee00e2a77ec6918dedd766"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"5a238fc456663f685a9db1ed8d680e348bb45171":["3a119bbc8703c10faa329ec201c654b3a35a1e3e","bdb5e42b0cecd8dfb27767a02ada71899bf17917"],"4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"6613659748fe4411a7dcf85266e55db1f95f7315":["15250ca94ba8ab3bcdd476daf6bf3f3febb92640"],"db4fdbf3d262768eabc027cd8321edca0cd11fa8":["ced66195b26fdb1f77ee00e2a77ec6918dedd766","c7492bcb52be51e55d596134b95b2e53cc4ffb91"],"1c93396a1df03720cb20e2c2f513a6fa59b21e4c":["3c188105a9aae04f56c24996f98f8333fc825d2e"],"402ad3ddc9da7b70da1b167667a60ece6a1381fb":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","4cc45c615dbb82bf79d5f9550286098367874fbf"],"c7492bcb52be51e55d596134b95b2e53cc4ffb91":["ced66195b26fdb1f77ee00e2a77ec6918dedd766","6616b1fd222bb5a60f7f7856ace312252bc97890"],"15250ca94ba8ab3bcdd476daf6bf3f3febb92640":["c7492bcb52be51e55d596134b95b2e53cc4ffb91"],"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f":["4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c","02331260bb246364779cb6f04919ca47900d01bb"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":["4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c","02331260bb246364779cb6f04919ca47900d01bb"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["bdb5e42b0cecd8dfb27767a02ada71899bf17917"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["402ad3ddc9da7b70da1b167667a60ece6a1381fb"],"02331260bb246364779cb6f04919ca47900d01bb":["4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c"]},"commit2Childs":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":[],"bdb5e42b0cecd8dfb27767a02ada71899bf17917":["5a238fc456663f685a9db1ed8d680e348bb45171","629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"3c188105a9aae04f56c24996f98f8333fc825d2e":["1c93396a1df03720cb20e2c2f513a6fa59b21e4c"],"b05c56a41b733e02a189c48895922b5bd8c7f3d1":[],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["bdb5e42b0cecd8dfb27767a02ada71899bf17917","5a238fc456663f685a9db1ed8d680e348bb45171"],"c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"4cc45c615dbb82bf79d5f9550286098367874fbf":["402ad3ddc9da7b70da1b167667a60ece6a1381fb"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"ced66195b26fdb1f77ee00e2a77ec6918dedd766":["b05c56a41b733e02a189c48895922b5bd8c7f3d1","c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198","6616b1fd222bb5a60f7f7856ace312252bc97890","db4fdbf3d262768eabc027cd8321edca0cd11fa8","c7492bcb52be51e55d596134b95b2e53cc4ffb91"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"6616b1fd222bb5a60f7f7856ace312252bc97890":["c7492bcb52be51e55d596134b95b2e53cc4ffb91"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["4cc45c615dbb82bf79d5f9550286098367874fbf","402ad3ddc9da7b70da1b167667a60ece6a1381fb"],"5a238fc456663f685a9db1ed8d680e348bb45171":[],"4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c":["b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","d6f074e73200c07d54f242d3880a8da5a35ff97b","02331260bb246364779cb6f04919ca47900d01bb"],"6613659748fe4411a7dcf85266e55db1f95f7315":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"1c93396a1df03720cb20e2c2f513a6fa59b21e4c":["b05c56a41b733e02a189c48895922b5bd8c7f3d1"],"db4fdbf3d262768eabc027cd8321edca0cd11fa8":[],"402ad3ddc9da7b70da1b167667a60ece6a1381fb":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"c7492bcb52be51e55d596134b95b2e53cc4ffb91":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","db4fdbf3d262768eabc027cd8321edca0cd11fa8","15250ca94ba8ab3bcdd476daf6bf3f3febb92640"],"15250ca94ba8ab3bcdd476daf6bf3f3febb92640":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","6613659748fe4411a7dcf85266e55db1f95f7315"],"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f":["3c188105a9aae04f56c24996f98f8333fc825d2e"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":["c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c"],"02331260bb246364779cb6f04919ca47900d01bb":["ced66195b26fdb1f77ee00e2a77ec6918dedd766","b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","d6f074e73200c07d54f242d3880a8da5a35ff97b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","b05c56a41b733e02a189c48895922b5bd8c7f3d1","c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198","5a238fc456663f685a9db1ed8d680e348bb45171","db4fdbf3d262768eabc027cd8321edca0cd11fa8","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}