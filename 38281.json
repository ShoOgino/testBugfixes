{"path":"lucene/suggest/src/java/org/apache/lucene/search/suggest/fst/FSTCompletionLookup#build(TermFreqPayloadIterator).mjava","commits":[{"id":"ada2f7352a7f964fe49bccd13227c4ec38563d39","date":1381659982,"type":1,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/fst/FSTCompletionLookup#build(TermFreqPayloadIterator).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/fst/FSTCompletionLookup#build(TermFreqIterator).mjava","sourceNew":"  @Override\n  public void build(TermFreqPayloadIterator tfit) throws IOException {\n    if (tfit.hasPayloads()) {\n      throw new IllegalArgumentException(\"this suggester doesn't support payloads\");\n    }\n    File tempInput = File.createTempFile(\n        FSTCompletionLookup.class.getSimpleName(), \".input\", Sort.defaultTempDir());\n    File tempSorted = File.createTempFile(\n        FSTCompletionLookup.class.getSimpleName(), \".sorted\", Sort.defaultTempDir());\n\n    Sort.ByteSequencesWriter writer = new Sort.ByteSequencesWriter(tempInput);\n    Sort.ByteSequencesReader reader = null;\n    ExternalRefSorter sorter = null;\n\n    // Push floats up front before sequences to sort them. For now, assume they are non-negative.\n    // If negative floats are allowed some trickery needs to be done to find their byte order.\n    boolean success = false;\n    try {\n      byte [] buffer = new byte [0];\n      ByteArrayDataOutput output = new ByteArrayDataOutput(buffer);\n      BytesRef spare;\n      while ((spare = tfit.next()) != null) {\n        if (spare.length + 4 >= buffer.length) {\n          buffer = ArrayUtil.grow(buffer, spare.length + 4);\n        }\n\n        output.reset(buffer);\n        output.writeInt(encodeWeight(tfit.weight()));\n        output.writeBytes(spare.bytes, spare.offset, spare.length);\n        writer.write(buffer, 0, output.getPosition());\n      }\n      writer.close();\n\n      // We don't know the distribution of scores and we need to bucket them, so we'll sort\n      // and divide into equal buckets.\n      SortInfo info = new Sort().sort(tempInput, tempSorted);\n      tempInput.delete();\n      FSTCompletionBuilder builder = new FSTCompletionBuilder(\n          buckets, sorter = new ExternalRefSorter(new Sort()), sharedTailLength);\n\n      final int inputLines = info.lines;\n      reader = new Sort.ByteSequencesReader(tempSorted);\n      long line = 0;\n      int previousBucket = 0;\n      int previousScore = 0;\n      ByteArrayDataInput input = new ByteArrayDataInput();\n      BytesRef tmp1 = new BytesRef();\n      BytesRef tmp2 = new BytesRef();\n      while (reader.read(tmp1)) {\n        input.reset(tmp1.bytes);\n        int currentScore = input.readInt();\n\n        int bucket;\n        if (line > 0 && currentScore == previousScore) {\n          bucket = previousBucket;\n        } else {\n          bucket = (int) (line * buckets / inputLines);\n        }\n        previousScore = currentScore;\n        previousBucket = bucket;\n\n        // Only append the input, discard the weight.\n        tmp2.bytes = tmp1.bytes;\n        tmp2.offset = input.getPosition();\n        tmp2.length = tmp1.length - input.getPosition();\n        builder.add(tmp2, bucket);\n\n        line++;\n      }\n\n      // The two FSTCompletions share the same automaton.\n      this.higherWeightsCompletion = builder.build();\n      this.normalCompletion = new FSTCompletion(\n          higherWeightsCompletion.getFST(), false, exactMatchFirst);\n      \n      success = true;\n    } finally {\n      if (success) \n        IOUtils.close(reader, writer, sorter);\n      else \n        IOUtils.closeWhileHandlingException(reader, writer, sorter);\n\n      tempInput.delete();\n      tempSorted.delete();\n    }\n  }\n\n","sourceOld":"  @Override\n  public void build(TermFreqIterator tfit) throws IOException {\n    if (tfit instanceof TermFreqPayloadIterator) {\n      throw new IllegalArgumentException(\"this suggester doesn't support payloads\");\n    }\n    File tempInput = File.createTempFile(\n        FSTCompletionLookup.class.getSimpleName(), \".input\", Sort.defaultTempDir());\n    File tempSorted = File.createTempFile(\n        FSTCompletionLookup.class.getSimpleName(), \".sorted\", Sort.defaultTempDir());\n\n    Sort.ByteSequencesWriter writer = new Sort.ByteSequencesWriter(tempInput);\n    Sort.ByteSequencesReader reader = null;\n    ExternalRefSorter sorter = null;\n\n    // Push floats up front before sequences to sort them. For now, assume they are non-negative.\n    // If negative floats are allowed some trickery needs to be done to find their byte order.\n    boolean success = false;\n    try {\n      byte [] buffer = new byte [0];\n      ByteArrayDataOutput output = new ByteArrayDataOutput(buffer);\n      BytesRef spare;\n      while ((spare = tfit.next()) != null) {\n        if (spare.length + 4 >= buffer.length) {\n          buffer = ArrayUtil.grow(buffer, spare.length + 4);\n        }\n\n        output.reset(buffer);\n        output.writeInt(encodeWeight(tfit.weight()));\n        output.writeBytes(spare.bytes, spare.offset, spare.length);\n        writer.write(buffer, 0, output.getPosition());\n      }\n      writer.close();\n\n      // We don't know the distribution of scores and we need to bucket them, so we'll sort\n      // and divide into equal buckets.\n      SortInfo info = new Sort().sort(tempInput, tempSorted);\n      tempInput.delete();\n      FSTCompletionBuilder builder = new FSTCompletionBuilder(\n          buckets, sorter = new ExternalRefSorter(new Sort()), sharedTailLength);\n\n      final int inputLines = info.lines;\n      reader = new Sort.ByteSequencesReader(tempSorted);\n      long line = 0;\n      int previousBucket = 0;\n      int previousScore = 0;\n      ByteArrayDataInput input = new ByteArrayDataInput();\n      BytesRef tmp1 = new BytesRef();\n      BytesRef tmp2 = new BytesRef();\n      while (reader.read(tmp1)) {\n        input.reset(tmp1.bytes);\n        int currentScore = input.readInt();\n\n        int bucket;\n        if (line > 0 && currentScore == previousScore) {\n          bucket = previousBucket;\n        } else {\n          bucket = (int) (line * buckets / inputLines);\n        }\n        previousScore = currentScore;\n        previousBucket = bucket;\n\n        // Only append the input, discard the weight.\n        tmp2.bytes = tmp1.bytes;\n        tmp2.offset = input.getPosition();\n        tmp2.length = tmp1.length - input.getPosition();\n        builder.add(tmp2, bucket);\n\n        line++;\n      }\n\n      // The two FSTCompletions share the same automaton.\n      this.higherWeightsCompletion = builder.build();\n      this.normalCompletion = new FSTCompletion(\n          higherWeightsCompletion.getFST(), false, exactMatchFirst);\n      \n      success = true;\n    } finally {\n      if (success) \n        IOUtils.close(reader, writer, sorter);\n      else \n        IOUtils.closeWhileHandlingException(reader, writer, sorter);\n\n      tempInput.delete();\n      tempSorted.delete();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"41aee74b5f91a096e3fd950f4a336bc763f0e7a7","date":1381772070,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/fst/FSTCompletionLookup#build(InputIterator).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/fst/FSTCompletionLookup#build(TermFreqPayloadIterator).mjava","sourceNew":"  @Override\n  public void build(InputIterator tfit) throws IOException {\n    if (tfit.hasPayloads()) {\n      throw new IllegalArgumentException(\"this suggester doesn't support payloads\");\n    }\n    File tempInput = File.createTempFile(\n        FSTCompletionLookup.class.getSimpleName(), \".input\", Sort.defaultTempDir());\n    File tempSorted = File.createTempFile(\n        FSTCompletionLookup.class.getSimpleName(), \".sorted\", Sort.defaultTempDir());\n\n    Sort.ByteSequencesWriter writer = new Sort.ByteSequencesWriter(tempInput);\n    Sort.ByteSequencesReader reader = null;\n    ExternalRefSorter sorter = null;\n\n    // Push floats up front before sequences to sort them. For now, assume they are non-negative.\n    // If negative floats are allowed some trickery needs to be done to find their byte order.\n    boolean success = false;\n    try {\n      byte [] buffer = new byte [0];\n      ByteArrayDataOutput output = new ByteArrayDataOutput(buffer);\n      BytesRef spare;\n      while ((spare = tfit.next()) != null) {\n        if (spare.length + 4 >= buffer.length) {\n          buffer = ArrayUtil.grow(buffer, spare.length + 4);\n        }\n\n        output.reset(buffer);\n        output.writeInt(encodeWeight(tfit.weight()));\n        output.writeBytes(spare.bytes, spare.offset, spare.length);\n        writer.write(buffer, 0, output.getPosition());\n      }\n      writer.close();\n\n      // We don't know the distribution of scores and we need to bucket them, so we'll sort\n      // and divide into equal buckets.\n      SortInfo info = new Sort().sort(tempInput, tempSorted);\n      tempInput.delete();\n      FSTCompletionBuilder builder = new FSTCompletionBuilder(\n          buckets, sorter = new ExternalRefSorter(new Sort()), sharedTailLength);\n\n      final int inputLines = info.lines;\n      reader = new Sort.ByteSequencesReader(tempSorted);\n      long line = 0;\n      int previousBucket = 0;\n      int previousScore = 0;\n      ByteArrayDataInput input = new ByteArrayDataInput();\n      BytesRef tmp1 = new BytesRef();\n      BytesRef tmp2 = new BytesRef();\n      while (reader.read(tmp1)) {\n        input.reset(tmp1.bytes);\n        int currentScore = input.readInt();\n\n        int bucket;\n        if (line > 0 && currentScore == previousScore) {\n          bucket = previousBucket;\n        } else {\n          bucket = (int) (line * buckets / inputLines);\n        }\n        previousScore = currentScore;\n        previousBucket = bucket;\n\n        // Only append the input, discard the weight.\n        tmp2.bytes = tmp1.bytes;\n        tmp2.offset = input.getPosition();\n        tmp2.length = tmp1.length - input.getPosition();\n        builder.add(tmp2, bucket);\n\n        line++;\n      }\n\n      // The two FSTCompletions share the same automaton.\n      this.higherWeightsCompletion = builder.build();\n      this.normalCompletion = new FSTCompletion(\n          higherWeightsCompletion.getFST(), false, exactMatchFirst);\n      \n      success = true;\n    } finally {\n      if (success) \n        IOUtils.close(reader, writer, sorter);\n      else \n        IOUtils.closeWhileHandlingException(reader, writer, sorter);\n\n      tempInput.delete();\n      tempSorted.delete();\n    }\n  }\n\n","sourceOld":"  @Override\n  public void build(TermFreqPayloadIterator tfit) throws IOException {\n    if (tfit.hasPayloads()) {\n      throw new IllegalArgumentException(\"this suggester doesn't support payloads\");\n    }\n    File tempInput = File.createTempFile(\n        FSTCompletionLookup.class.getSimpleName(), \".input\", Sort.defaultTempDir());\n    File tempSorted = File.createTempFile(\n        FSTCompletionLookup.class.getSimpleName(), \".sorted\", Sort.defaultTempDir());\n\n    Sort.ByteSequencesWriter writer = new Sort.ByteSequencesWriter(tempInput);\n    Sort.ByteSequencesReader reader = null;\n    ExternalRefSorter sorter = null;\n\n    // Push floats up front before sequences to sort them. For now, assume they are non-negative.\n    // If negative floats are allowed some trickery needs to be done to find their byte order.\n    boolean success = false;\n    try {\n      byte [] buffer = new byte [0];\n      ByteArrayDataOutput output = new ByteArrayDataOutput(buffer);\n      BytesRef spare;\n      while ((spare = tfit.next()) != null) {\n        if (spare.length + 4 >= buffer.length) {\n          buffer = ArrayUtil.grow(buffer, spare.length + 4);\n        }\n\n        output.reset(buffer);\n        output.writeInt(encodeWeight(tfit.weight()));\n        output.writeBytes(spare.bytes, spare.offset, spare.length);\n        writer.write(buffer, 0, output.getPosition());\n      }\n      writer.close();\n\n      // We don't know the distribution of scores and we need to bucket them, so we'll sort\n      // and divide into equal buckets.\n      SortInfo info = new Sort().sort(tempInput, tempSorted);\n      tempInput.delete();\n      FSTCompletionBuilder builder = new FSTCompletionBuilder(\n          buckets, sorter = new ExternalRefSorter(new Sort()), sharedTailLength);\n\n      final int inputLines = info.lines;\n      reader = new Sort.ByteSequencesReader(tempSorted);\n      long line = 0;\n      int previousBucket = 0;\n      int previousScore = 0;\n      ByteArrayDataInput input = new ByteArrayDataInput();\n      BytesRef tmp1 = new BytesRef();\n      BytesRef tmp2 = new BytesRef();\n      while (reader.read(tmp1)) {\n        input.reset(tmp1.bytes);\n        int currentScore = input.readInt();\n\n        int bucket;\n        if (line > 0 && currentScore == previousScore) {\n          bucket = previousBucket;\n        } else {\n          bucket = (int) (line * buckets / inputLines);\n        }\n        previousScore = currentScore;\n        previousBucket = bucket;\n\n        // Only append the input, discard the weight.\n        tmp2.bytes = tmp1.bytes;\n        tmp2.offset = input.getPosition();\n        tmp2.length = tmp1.length - input.getPosition();\n        builder.add(tmp2, bucket);\n\n        line++;\n      }\n\n      // The two FSTCompletions share the same automaton.\n      this.higherWeightsCompletion = builder.build();\n      this.normalCompletion = new FSTCompletion(\n          higherWeightsCompletion.getFST(), false, exactMatchFirst);\n      \n      success = true;\n    } finally {\n      if (success) \n        IOUtils.close(reader, writer, sorter);\n      else \n        IOUtils.closeWhileHandlingException(reader, writer, sorter);\n\n      tempInput.delete();\n      tempSorted.delete();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"41aee74b5f91a096e3fd950f4a336bc763f0e7a7":["ada2f7352a7f964fe49bccd13227c4ec38563d39"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["41aee74b5f91a096e3fd950f4a336bc763f0e7a7"],"ada2f7352a7f964fe49bccd13227c4ec38563d39":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"41aee74b5f91a096e3fd950f4a336bc763f0e7a7":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["ada2f7352a7f964fe49bccd13227c4ec38563d39"],"ada2f7352a7f964fe49bccd13227c4ec38563d39":["41aee74b5f91a096e3fd950f4a336bc763f0e7a7"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}