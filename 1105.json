{"path":"lucene/src/java/org/apache/lucene/codecs/lucene40/values/VarStraightBytesImpl.Writer#finish(int).mjava","commits":[{"id":"a0ae5e3ed1232483b7b8a014f175a5fe43595982","date":1324062192,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/codecs/lucene40/values/VarStraightBytesImpl.Writer#finish(int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/lucene40/values/VarStraightBytesImpl.Writer#finish(int).mjava","sourceNew":"    @Override\n    public void finish(int docCount) throws IOException {\n      boolean success = false;\n      assert (!merge && datOut == null) || (merge && datOut != null); \n      final IndexOutput datOut = getOrCreateDataOut();\n      try {\n        if (!merge) {\n          // header is already written in getDataOut()\n          pool.writePool(datOut);\n        }\n        success = true;\n      } finally {\n        if (success) {\n          IOUtils.close(datOut);\n        } else {\n          IOUtils.closeWhileHandlingException(datOut);\n        }\n        pool.dropBuffersAndReset();\n      }\n\n      success = false;\n      final IndexOutput idxOut = getOrCreateIndexOut();\n      try {\n        if (lastDocID == -1) {\n          idxOut.writeVLong(0);\n          final PackedInts.Writer w = PackedInts.getWriter(idxOut, docCount+1,\n              PackedInts.bitsRequired(0));\n          // docCount+1 so we write sentinel\n          for (int i = 0; i < docCount+1; i++) {\n            w.add(0);\n          }\n          w.finish();\n        } else {\n          fill(docCount, address);\n          idxOut.writeVLong(address);\n          final PackedInts.Writer w = PackedInts.getWriter(idxOut, docCount+1,\n              PackedInts.bitsRequired(address));\n          for (int i = 0; i < docCount; i++) {\n            w.add(docToAddress[i]);\n          }\n          // write sentinel\n          w.add(address);\n          w.finish();\n        }\n        success = true;\n      } finally {\n        bytesUsed.addAndGet(-(docToAddress.length)\n            * RamUsageEstimator.NUM_BYTES_INT);\n        docToAddress = null;\n        if (success) {\n          IOUtils.close(idxOut);\n        } else {\n          IOUtils.closeWhileHandlingException(idxOut);\n        }\n      }\n    }\n\n","sourceOld":"    @Override\n    public void finish(int docCount) throws IOException {\n      boolean success = false;\n      assert (!merge && datOut == null) || (merge && datOut != null); \n      final IndexOutput datOut = getOrCreateDataOut();\n      try {\n        if (!merge) {\n          // header is already written in getDataOut()\n          pool.writePool(datOut);\n        }\n        success = true;\n      } finally {\n        if (success) {\n          IOUtils.close(datOut);\n        } else {\n          IOUtils.closeWhileHandlingException(datOut);\n        }\n        pool.dropBuffersAndReset();\n      }\n\n      success = false;\n      final IndexOutput idxOut = getOrCreateIndexOut();\n      try {\n        if (lastDocID == -1) {\n          idxOut.writeVLong(0);\n          final PackedInts.Writer w = PackedInts.getWriter(idxOut, docCount+1,\n              PackedInts.bitsRequired(0));\n          // docCount+1 so we write sentinel\n          for (int i = 0; i < docCount+1; i++) {\n            w.add(0);\n          }\n          w.finish();\n        } else {\n          fill(docCount, address);\n          idxOut.writeVLong(address);\n          final PackedInts.Writer w = PackedInts.getWriter(idxOut, docCount+1,\n              PackedInts.bitsRequired(address));\n          for (int i = 0; i < docCount; i++) {\n            w.add(docToAddress[i]);\n          }\n          // write sentinel\n          w.add(address);\n          w.finish();\n        }\n        success = true;\n      } finally {\n        bytesUsed.addAndGet(-(docToAddress.length)\n            * RamUsageEstimator.NUM_BYTES_INT);\n        docToAddress = null;\n        if (success) {\n          IOUtils.close(idxOut);\n        } else {\n          IOUtils.closeWhileHandlingException(idxOut);\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/VarStraightBytesImpl.Writer#finish(int).mjava","pathOld":"lucene/src/java/org/apache/lucene/codecs/lucene40/values/VarStraightBytesImpl.Writer#finish(int).mjava","sourceNew":"    @Override\n    public void finish(int docCount) throws IOException {\n      boolean success = false;\n      assert (!merge && datOut == null) || (merge && datOut != null); \n      final IndexOutput datOut = getOrCreateDataOut();\n      try {\n        if (!merge) {\n          // header is already written in getDataOut()\n          pool.writePool(datOut);\n        }\n        success = true;\n      } finally {\n        if (success) {\n          IOUtils.close(datOut);\n        } else {\n          IOUtils.closeWhileHandlingException(datOut);\n        }\n        pool.dropBuffersAndReset();\n      }\n\n      success = false;\n      final IndexOutput idxOut = getOrCreateIndexOut();\n      try {\n        if (lastDocID == -1) {\n          idxOut.writeVLong(0);\n          final PackedInts.Writer w = PackedInts.getWriter(idxOut, docCount+1,\n              PackedInts.bitsRequired(0));\n          // docCount+1 so we write sentinel\n          for (int i = 0; i < docCount+1; i++) {\n            w.add(0);\n          }\n          w.finish();\n        } else {\n          fill(docCount, address);\n          idxOut.writeVLong(address);\n          final PackedInts.Writer w = PackedInts.getWriter(idxOut, docCount+1,\n              PackedInts.bitsRequired(address));\n          for (int i = 0; i < docCount; i++) {\n            w.add(docToAddress[i]);\n          }\n          // write sentinel\n          w.add(address);\n          w.finish();\n        }\n        success = true;\n      } finally {\n        bytesUsed.addAndGet(-(docToAddress.length)\n            * RamUsageEstimator.NUM_BYTES_INT);\n        docToAddress = null;\n        if (success) {\n          IOUtils.close(idxOut);\n        } else {\n          IOUtils.closeWhileHandlingException(idxOut);\n        }\n      }\n    }\n\n","sourceOld":"    @Override\n    public void finish(int docCount) throws IOException {\n      boolean success = false;\n      assert (!merge && datOut == null) || (merge && datOut != null); \n      final IndexOutput datOut = getOrCreateDataOut();\n      try {\n        if (!merge) {\n          // header is already written in getDataOut()\n          pool.writePool(datOut);\n        }\n        success = true;\n      } finally {\n        if (success) {\n          IOUtils.close(datOut);\n        } else {\n          IOUtils.closeWhileHandlingException(datOut);\n        }\n        pool.dropBuffersAndReset();\n      }\n\n      success = false;\n      final IndexOutput idxOut = getOrCreateIndexOut();\n      try {\n        if (lastDocID == -1) {\n          idxOut.writeVLong(0);\n          final PackedInts.Writer w = PackedInts.getWriter(idxOut, docCount+1,\n              PackedInts.bitsRequired(0));\n          // docCount+1 so we write sentinel\n          for (int i = 0; i < docCount+1; i++) {\n            w.add(0);\n          }\n          w.finish();\n        } else {\n          fill(docCount, address);\n          idxOut.writeVLong(address);\n          final PackedInts.Writer w = PackedInts.getWriter(idxOut, docCount+1,\n              PackedInts.bitsRequired(address));\n          for (int i = 0; i < docCount; i++) {\n            w.add(docToAddress[i]);\n          }\n          // write sentinel\n          w.add(address);\n          w.finish();\n        }\n        success = true;\n      } finally {\n        bytesUsed.addAndGet(-(docToAddress.length)\n            * RamUsageEstimator.NUM_BYTES_INT);\n        docToAddress = null;\n        if (success) {\n          IOUtils.close(idxOut);\n        } else {\n          IOUtils.closeWhileHandlingException(idxOut);\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0ae5e3ed1232483b7b8a014f175a5fe43595982"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a0ae5e3ed1232483b7b8a014f175a5fe43595982":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"]},"commit2Childs":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["a0ae5e3ed1232483b7b8a014f175a5fe43595982"],"a0ae5e3ed1232483b7b8a014f175a5fe43595982":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}