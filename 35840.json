{"path":"solr/core/src/java/org/apache/solr/cloud/ZkController#giveupLeadership(CoreDescriptor,Throwable).mjava","commits":[{"id":"1257989f08e6750eeab73e5e9f7847fc48b04a1a","date":1531102463,"type":0,"author":"Cao Manh Dat","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#giveupLeadership(CoreDescriptor,Throwable).mjava","pathOld":"/dev/null","sourceNew":"  public void giveupLeadership(CoreDescriptor cd, Throwable tragicException) {\n    DocCollection dc = getClusterState().getCollectionOrNull(cd.getCollectionName());\n    if (dc == null) return;\n\n    Slice shard = dc.getSlice(cd.getCloudDescriptor().getShardId());\n    if (shard == null) return;\n\n    // if this replica is not a leader, it will be put in recovery state by the leader\n    if (shard.getReplica(cd.getCloudDescriptor().getCoreNodeName()) != shard.getLeader()) return;\n\n    int numActiveReplicas = shard.getReplicas(\n        rep -> rep.getState() == Replica.State.ACTIVE\n            && rep.getType() != Type.PULL\n            && getClusterState().getLiveNodes().contains(rep.getNodeName())\n    ).size();\n\n    // at least the leader still be able to search, we should give up leadership if other replicas can take over\n    if (numActiveReplicas >= 2) {\n      String key = cd.getCollectionName() + \":\" + cd.getCloudDescriptor().getCoreNodeName();\n      //TODO better handling the case when delete replica was failed\n      if (replicasMetTragicEvent.putIfAbsent(key, tragicException) == null) {\n        log.warn(\"Leader {} met tragic exception, give up its leadership\", key, tragicException);\n        try {\n          // by using Overseer to remove and add replica back, we can do the task in an async/robust manner\n          Map<String,Object> props = new HashMap<>();\n          props.put(Overseer.QUEUE_OPERATION, \"deletereplica\");\n          props.put(COLLECTION_PROP, cd.getCollectionName());\n          props.put(SHARD_ID_PROP, shard.getName());\n          props.put(REPLICA_PROP, cd.getCloudDescriptor().getCoreNodeName());\n          getOverseerCollectionQueue().offer(Utils.toJSON(new ZkNodeProps(props)));\n\n          props.clear();\n          props.put(Overseer.QUEUE_OPERATION, \"addreplica\");\n          props.put(COLLECTION_PROP, cd.getCollectionName());\n          props.put(SHARD_ID_PROP, shard.getName());\n          props.put(ZkStateReader.REPLICA_TYPE, cd.getCloudDescriptor().getReplicaType().name().toUpperCase(Locale.ROOT));\n          props.put(CoreAdminParams.NODE, getNodeName());\n          getOverseerCollectionQueue().offer(Utils.toJSON(new ZkNodeProps(props)));\n        } catch (KeeperException e) {\n          log.info(\"Met exception on give up leadership for {}\", key, e);\n          replicasMetTragicEvent.remove(key);\n        } catch (InterruptedException e) {\n          Thread.currentThread().interrupt();\n          log.info(\"Met exception on give up leadership for {}\", key, e);\n          replicasMetTragicEvent.remove(key);\n        }\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["621e93cf8b1c2790854610edc69525443538210b"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26","date":1531589977,"type":0,"author":"Michael Braun","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#giveupLeadership(CoreDescriptor,Throwable).mjava","pathOld":"/dev/null","sourceNew":"  public void giveupLeadership(CoreDescriptor cd, Throwable tragicException) {\n    DocCollection dc = getClusterState().getCollectionOrNull(cd.getCollectionName());\n    if (dc == null) return;\n\n    Slice shard = dc.getSlice(cd.getCloudDescriptor().getShardId());\n    if (shard == null) return;\n\n    // if this replica is not a leader, it will be put in recovery state by the leader\n    if (shard.getReplica(cd.getCloudDescriptor().getCoreNodeName()) != shard.getLeader()) return;\n\n    int numActiveReplicas = shard.getReplicas(\n        rep -> rep.getState() == Replica.State.ACTIVE\n            && rep.getType() != Type.PULL\n            && getClusterState().getLiveNodes().contains(rep.getNodeName())\n    ).size();\n\n    // at least the leader still be able to search, we should give up leadership if other replicas can take over\n    if (numActiveReplicas >= 2) {\n      String key = cd.getCollectionName() + \":\" + cd.getCloudDescriptor().getCoreNodeName();\n      //TODO better handling the case when delete replica was failed\n      if (replicasMetTragicEvent.putIfAbsent(key, tragicException) == null) {\n        log.warn(\"Leader {} met tragic exception, give up its leadership\", key, tragicException);\n        try {\n          // by using Overseer to remove and add replica back, we can do the task in an async/robust manner\n          Map<String,Object> props = new HashMap<>();\n          props.put(Overseer.QUEUE_OPERATION, \"deletereplica\");\n          props.put(COLLECTION_PROP, cd.getCollectionName());\n          props.put(SHARD_ID_PROP, shard.getName());\n          props.put(REPLICA_PROP, cd.getCloudDescriptor().getCoreNodeName());\n          getOverseerCollectionQueue().offer(Utils.toJSON(new ZkNodeProps(props)));\n\n          props.clear();\n          props.put(Overseer.QUEUE_OPERATION, \"addreplica\");\n          props.put(COLLECTION_PROP, cd.getCollectionName());\n          props.put(SHARD_ID_PROP, shard.getName());\n          props.put(ZkStateReader.REPLICA_TYPE, cd.getCloudDescriptor().getReplicaType().name().toUpperCase(Locale.ROOT));\n          props.put(CoreAdminParams.NODE, getNodeName());\n          getOverseerCollectionQueue().offer(Utils.toJSON(new ZkNodeProps(props)));\n        } catch (KeeperException e) {\n          log.info(\"Met exception on give up leadership for {}\", key, e);\n          replicasMetTragicEvent.remove(key);\n        } catch (InterruptedException e) {\n          Thread.currentThread().interrupt();\n          log.info(\"Met exception on give up leadership for {}\", key, e);\n          replicasMetTragicEvent.remove(key);\n        }\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","date":1531905561,"type":0,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#giveupLeadership(CoreDescriptor,Throwable).mjava","pathOld":"/dev/null","sourceNew":"  public void giveupLeadership(CoreDescriptor cd, Throwable tragicException) {\n    DocCollection dc = getClusterState().getCollectionOrNull(cd.getCollectionName());\n    if (dc == null) return;\n\n    Slice shard = dc.getSlice(cd.getCloudDescriptor().getShardId());\n    if (shard == null) return;\n\n    // if this replica is not a leader, it will be put in recovery state by the leader\n    if (shard.getReplica(cd.getCloudDescriptor().getCoreNodeName()) != shard.getLeader()) return;\n\n    int numActiveReplicas = shard.getReplicas(\n        rep -> rep.getState() == Replica.State.ACTIVE\n            && rep.getType() != Type.PULL\n            && getClusterState().getLiveNodes().contains(rep.getNodeName())\n    ).size();\n\n    // at least the leader still be able to search, we should give up leadership if other replicas can take over\n    if (numActiveReplicas >= 2) {\n      String key = cd.getCollectionName() + \":\" + cd.getCloudDescriptor().getCoreNodeName();\n      //TODO better handling the case when delete replica was failed\n      if (replicasMetTragicEvent.putIfAbsent(key, tragicException) == null) {\n        log.warn(\"Leader {} met tragic exception, give up its leadership\", key, tragicException);\n        try {\n          // by using Overseer to remove and add replica back, we can do the task in an async/robust manner\n          Map<String,Object> props = new HashMap<>();\n          props.put(Overseer.QUEUE_OPERATION, \"deletereplica\");\n          props.put(COLLECTION_PROP, cd.getCollectionName());\n          props.put(SHARD_ID_PROP, shard.getName());\n          props.put(REPLICA_PROP, cd.getCloudDescriptor().getCoreNodeName());\n          getOverseerCollectionQueue().offer(Utils.toJSON(new ZkNodeProps(props)));\n\n          props.clear();\n          props.put(Overseer.QUEUE_OPERATION, \"addreplica\");\n          props.put(COLLECTION_PROP, cd.getCollectionName());\n          props.put(SHARD_ID_PROP, shard.getName());\n          props.put(ZkStateReader.REPLICA_TYPE, cd.getCloudDescriptor().getReplicaType().name().toUpperCase(Locale.ROOT));\n          props.put(CoreAdminParams.NODE, getNodeName());\n          getOverseerCollectionQueue().offer(Utils.toJSON(new ZkNodeProps(props)));\n        } catch (KeeperException e) {\n          log.info(\"Met exception on give up leadership for {}\", key, e);\n          replicasMetTragicEvent.remove(key);\n        } catch (InterruptedException e) {\n          Thread.currentThread().interrupt();\n          log.info(\"Met exception on give up leadership for {}\", key, e);\n          replicasMetTragicEvent.remove(key);\n        }\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"621e93cf8b1c2790854610edc69525443538210b","date":1550271095,"type":3,"author":"Tomas Fernandez Lobbe","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#giveupLeadership(CoreDescriptor,Throwable).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#giveupLeadership(CoreDescriptor,Throwable).mjava","sourceNew":"  /**\n   * Best effort to give up the leadership of a shard in a core after hitting a tragic exception\n   * @param cd The current core descriptor\n   * @param tragicException The tragic exception from the {@code IndexWriter}\n   */\n  public void giveupLeadership(CoreDescriptor cd, Throwable tragicException) {\n    assert tragicException != null;\n    assert cd != null;\n    DocCollection dc = getClusterState().getCollectionOrNull(cd.getCollectionName());\n    if (dc == null) return;\n\n    Slice shard = dc.getSlice(cd.getCloudDescriptor().getShardId());\n    if (shard == null) return;\n\n    // if this replica is not a leader, it will be put in recovery state by the leader\n    if (shard.getReplica(cd.getCloudDescriptor().getCoreNodeName()) != shard.getLeader()) return;\n\n    int numActiveReplicas = shard.getReplicas(\n        rep -> rep.getState() == Replica.State.ACTIVE\n            && rep.getType() != Type.PULL\n            && getClusterState().getLiveNodes().contains(rep.getNodeName())\n    ).size();\n\n    // at least the leader still be able to search, we should give up leadership if other replicas can take over\n    if (numActiveReplicas >= 2) {\n      String key = cd.getCollectionName() + \":\" + cd.getCloudDescriptor().getCoreNodeName();\n      //TODO better handling the case when delete replica was failed\n      if (replicasMetTragicEvent.putIfAbsent(key, tragicException) == null) {\n        log.warn(\"Leader {} met tragic exception, give up its leadership\", key, tragicException);\n        try {\n          // by using Overseer to remove and add replica back, we can do the task in an async/robust manner\n          Map<String,Object> props = new HashMap<>();\n          props.put(Overseer.QUEUE_OPERATION, \"deletereplica\");\n          props.put(COLLECTION_PROP, cd.getCollectionName());\n          props.put(SHARD_ID_PROP, shard.getName());\n          props.put(REPLICA_PROP, cd.getCloudDescriptor().getCoreNodeName());\n          getOverseerCollectionQueue().offer(Utils.toJSON(new ZkNodeProps(props)));\n\n          props.clear();\n          props.put(Overseer.QUEUE_OPERATION, \"addreplica\");\n          props.put(COLLECTION_PROP, cd.getCollectionName());\n          props.put(SHARD_ID_PROP, shard.getName());\n          props.put(ZkStateReader.REPLICA_TYPE, cd.getCloudDescriptor().getReplicaType().name().toUpperCase(Locale.ROOT));\n          props.put(CoreAdminParams.NODE, getNodeName());\n          getOverseerCollectionQueue().offer(Utils.toJSON(new ZkNodeProps(props)));\n        } catch (Exception e) {\n          // Exceptions are not bubbled up. giveupLeadership is best effort, and is only called in case of some other\n          // unrecoverable error happened\n          log.error(\"Met exception on give up leadership for {}\", key, e);\n          replicasMetTragicEvent.remove(key);\n          SolrZkClient.checkInterrupted(e);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  public void giveupLeadership(CoreDescriptor cd, Throwable tragicException) {\n    DocCollection dc = getClusterState().getCollectionOrNull(cd.getCollectionName());\n    if (dc == null) return;\n\n    Slice shard = dc.getSlice(cd.getCloudDescriptor().getShardId());\n    if (shard == null) return;\n\n    // if this replica is not a leader, it will be put in recovery state by the leader\n    if (shard.getReplica(cd.getCloudDescriptor().getCoreNodeName()) != shard.getLeader()) return;\n\n    int numActiveReplicas = shard.getReplicas(\n        rep -> rep.getState() == Replica.State.ACTIVE\n            && rep.getType() != Type.PULL\n            && getClusterState().getLiveNodes().contains(rep.getNodeName())\n    ).size();\n\n    // at least the leader still be able to search, we should give up leadership if other replicas can take over\n    if (numActiveReplicas >= 2) {\n      String key = cd.getCollectionName() + \":\" + cd.getCloudDescriptor().getCoreNodeName();\n      //TODO better handling the case when delete replica was failed\n      if (replicasMetTragicEvent.putIfAbsent(key, tragicException) == null) {\n        log.warn(\"Leader {} met tragic exception, give up its leadership\", key, tragicException);\n        try {\n          // by using Overseer to remove and add replica back, we can do the task in an async/robust manner\n          Map<String,Object> props = new HashMap<>();\n          props.put(Overseer.QUEUE_OPERATION, \"deletereplica\");\n          props.put(COLLECTION_PROP, cd.getCollectionName());\n          props.put(SHARD_ID_PROP, shard.getName());\n          props.put(REPLICA_PROP, cd.getCloudDescriptor().getCoreNodeName());\n          getOverseerCollectionQueue().offer(Utils.toJSON(new ZkNodeProps(props)));\n\n          props.clear();\n          props.put(Overseer.QUEUE_OPERATION, \"addreplica\");\n          props.put(COLLECTION_PROP, cd.getCollectionName());\n          props.put(SHARD_ID_PROP, shard.getName());\n          props.put(ZkStateReader.REPLICA_TYPE, cd.getCloudDescriptor().getReplicaType().name().toUpperCase(Locale.ROOT));\n          props.put(CoreAdminParams.NODE, getNodeName());\n          getOverseerCollectionQueue().offer(Utils.toJSON(new ZkNodeProps(props)));\n        } catch (KeeperException e) {\n          log.info(\"Met exception on give up leadership for {}\", key, e);\n          replicasMetTragicEvent.remove(key);\n        } catch (InterruptedException e) {\n          Thread.currentThread().interrupt();\n          log.info(\"Met exception on give up leadership for {}\", key, e);\n          replicasMetTragicEvent.remove(key);\n        }\n      }\n    }\n  }\n\n","bugFix":["1257989f08e6750eeab73e5e9f7847fc48b04a1a"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"621e93cf8b1c2790854610edc69525443538210b":["1257989f08e6750eeab73e5e9f7847fc48b04a1a"],"1257989f08e6750eeab73e5e9f7847fc48b04a1a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","1257989f08e6750eeab73e5e9f7847fc48b04a1a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["621e93cf8b1c2790854610edc69525443538210b"],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","1257989f08e6750eeab73e5e9f7847fc48b04a1a"]},"commit2Childs":{"621e93cf8b1c2790854610edc69525443538210b":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"1257989f08e6750eeab73e5e9f7847fc48b04a1a":["621e93cf8b1c2790854610edc69525443538210b","0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["1257989f08e6750eeab73e5e9f7847fc48b04a1a","0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":[]},"heads":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","cd5edd1f2b162a5cfa08efd17851a07373a96817","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}