{"path":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","pathOld":"src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","sourceNew":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n      \n      // First build up a starting index:\n      RAMDirectory startDir = new MockRAMDirectory();\n      IndexWriter writer = new IndexWriter(startDir, new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)));\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      long diskUsage = startDir.sizeInBytes();\n      long diskFree = diskUsage+100;      \n\n      IOException err = null;\n\n      boolean done = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockRAMDirectory dir = new MockRAMDirectory(startDir);\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate, diskFree);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"contents\", (float) 2.0);\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Whether we succeeded or failed, check that all\n          // un-referenced files were in fact deleted (ie,\n          // we did not create garbage).  Just create a\n          // new IndexFileDeleter, have it delete\n          // unreferenced files, then verify that in fact\n          // no files were deleted:\n          String[] startFiles = dir.listAll();\n          SegmentInfos infos = new SegmentInfos();\n          infos.read(dir);\n          new IndexFileDeleter(dir, new KeepOnlyLastCommitDeletionPolicy(), infos, null, null);\n          String[] endFiles = dir.listAll();\n\n          Arrays.sort(startFiles);\n          Arrays.sort(endFiles);\n\n          //for(int i=0;i<startFiles.length;i++) {\n          //  System.out.println(\"  startFiles: \" + i + \": \" + startFiles[i]);\n          //}\n\n          if (!Arrays.equals(startFiles, endFiles)) {\n            String successStr;\n            if (success) {\n              successStr = \"success\";\n            } else {\n              successStr = \"IOException\";\n              err.printStackTrace();\n            }\n            fail(\"reader.close() failed to delete unreferenced files after \" + successStr + \" (\" + diskFree + \" bytes): before delete:\\n    \" + arrayToString(startFiles) + \"\\n  after delete:\\n    \" + arrayToString(endFiles));\n          }\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","sourceOld":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n      \n      // First build up a starting index:\n      RAMDirectory startDir = new MockRAMDirectory();\n      IndexWriter writer = new IndexWriter(startDir, new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)));\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      long diskUsage = startDir.sizeInBytes();\n      long diskFree = diskUsage+100;      \n\n      IOException err = null;\n\n      boolean done = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockRAMDirectory dir = new MockRAMDirectory(startDir);\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate, diskFree);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"contents\", (float) 2.0);\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Whether we succeeded or failed, check that all\n          // un-referenced files were in fact deleted (ie,\n          // we did not create garbage).  Just create a\n          // new IndexFileDeleter, have it delete\n          // unreferenced files, then verify that in fact\n          // no files were deleted:\n          String[] startFiles = dir.listAll();\n          SegmentInfos infos = new SegmentInfos();\n          infos.read(dir);\n          new IndexFileDeleter(dir, new KeepOnlyLastCommitDeletionPolicy(), infos, null, null);\n          String[] endFiles = dir.listAll();\n\n          Arrays.sort(startFiles);\n          Arrays.sort(endFiles);\n\n          //for(int i=0;i<startFiles.length;i++) {\n          //  System.out.println(\"  startFiles: \" + i + \": \" + startFiles[i]);\n          //}\n\n          if (!Arrays.equals(startFiles, endFiles)) {\n            String successStr;\n            if (success) {\n              successStr = \"success\";\n            } else {\n              successStr = \"IOException\";\n              err.printStackTrace();\n            }\n            fail(\"reader.close() failed to delete unreferenced files after \" + successStr + \" (\" + diskFree + \" bytes): before delete:\\n    \" + arrayToString(startFiles) + \"\\n  after delete:\\n    \" + arrayToString(endFiles));\n          }\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"955c32f886db6f6356c9fcdea6b1f1cb4effda24","date":1270581567,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","sourceNew":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n      \n      // First build up a starting index:\n      RAMDirectory startDir = new MockRAMDirectory();\n      IndexWriter writer = new IndexWriter(startDir, new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)));\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      long diskUsage = ((MockRAMDirectory) startDir).getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockRAMDirectory dir = new MockRAMDirectory(startDir);\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate, diskFree);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", (float) 2.0);\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Whether we succeeded or failed, check that all\n          // un-referenced files were in fact deleted (ie,\n          // we did not create garbage).  Just create a\n          // new IndexFileDeleter, have it delete\n          // unreferenced files, then verify that in fact\n          // no files were deleted:\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"reader.close() failed to delete unreferenced files\");\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","sourceOld":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n      \n      // First build up a starting index:\n      RAMDirectory startDir = new MockRAMDirectory();\n      IndexWriter writer = new IndexWriter(startDir, new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)));\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      long diskUsage = startDir.sizeInBytes();\n      long diskFree = diskUsage+100;      \n\n      IOException err = null;\n\n      boolean done = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockRAMDirectory dir = new MockRAMDirectory(startDir);\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate, diskFree);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"contents\", (float) 2.0);\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Whether we succeeded or failed, check that all\n          // un-referenced files were in fact deleted (ie,\n          // we did not create garbage).  Just create a\n          // new IndexFileDeleter, have it delete\n          // unreferenced files, then verify that in fact\n          // no files were deleted:\n          String[] startFiles = dir.listAll();\n          SegmentInfos infos = new SegmentInfos();\n          infos.read(dir);\n          new IndexFileDeleter(dir, new KeepOnlyLastCommitDeletionPolicy(), infos, null, null);\n          String[] endFiles = dir.listAll();\n\n          Arrays.sort(startFiles);\n          Arrays.sort(endFiles);\n\n          //for(int i=0;i<startFiles.length;i++) {\n          //  System.out.println(\"  startFiles: \" + i + \": \" + startFiles[i]);\n          //}\n\n          if (!Arrays.equals(startFiles, endFiles)) {\n            String successStr;\n            if (success) {\n              successStr = \"success\";\n            } else {\n              successStr = \"IOException\";\n              err.printStackTrace();\n            }\n            fail(\"reader.close() failed to delete unreferenced files after \" + successStr + \" (\" + diskFree + \" bytes): before delete:\\n    \" + arrayToString(startFiles) + \"\\n  after delete:\\n    \" + arrayToString(endFiles));\n          }\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d572389229127c297dd1fa5ce4758e1cec41e799","date":1273610938,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","sourceNew":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n      \n      // First build up a starting index:\n      RAMDirectory startDir = new MockRAMDirectory();\n      IndexWriter writer = new IndexWriter(startDir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      long diskUsage = ((MockRAMDirectory) startDir).getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockRAMDirectory dir = new MockRAMDirectory(startDir);\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate, diskFree);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", (float) 2.0);\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Whether we succeeded or failed, check that all\n          // un-referenced files were in fact deleted (ie,\n          // we did not create garbage).  Just create a\n          // new IndexFileDeleter, have it delete\n          // unreferenced files, then verify that in fact\n          // no files were deleted:\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"reader.close() failed to delete unreferenced files\");\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","sourceOld":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n      \n      // First build up a starting index:\n      RAMDirectory startDir = new MockRAMDirectory();\n      IndexWriter writer = new IndexWriter(startDir, new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)));\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      long diskUsage = ((MockRAMDirectory) startDir).getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockRAMDirectory dir = new MockRAMDirectory(startDir);\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate, diskFree);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", (float) 2.0);\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Whether we succeeded or failed, check that all\n          // un-referenced files were in fact deleted (ie,\n          // we did not create garbage).  Just create a\n          // new IndexFileDeleter, have it delete\n          // unreferenced files, then verify that in fact\n          // no files were deleted:\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"reader.close() failed to delete unreferenced files\");\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b21422ff1d1d56499dec481f193b402e5e8def5b","date":1281472367,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","sourceNew":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n      \n      // First build up a starting index:\n      RAMDirectory startDir = new MockRAMDirectory();\n      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      long diskUsage = ((MockRAMDirectory) startDir).getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockRAMDirectory dir = new MockRAMDirectory(startDir);\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate, diskFree);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", (float) 2.0);\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Whether we succeeded or failed, check that all\n          // un-referenced files were in fact deleted (ie,\n          // we did not create garbage).  Just create a\n          // new IndexFileDeleter, have it delete\n          // unreferenced files, then verify that in fact\n          // no files were deleted:\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"reader.close() failed to delete unreferenced files\");\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","sourceOld":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n      \n      // First build up a starting index:\n      RAMDirectory startDir = new MockRAMDirectory();\n      IndexWriter writer = new IndexWriter(startDir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      long diskUsage = ((MockRAMDirectory) startDir).getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockRAMDirectory dir = new MockRAMDirectory(startDir);\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate, diskFree);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", (float) 2.0);\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Whether we succeeded or failed, check that all\n          // un-referenced files were in fact deleted (ie,\n          // we did not create garbage).  Just create a\n          // new IndexFileDeleter, have it delete\n          // unreferenced files, then verify that in fact\n          // no files were deleted:\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"reader.close() failed to delete unreferenced files\");\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1a2e46fd1b7cbc52d7d6461a6ef99e7107ae2a9c","date":1281477834,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","sourceNew":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n      \n      // First build up a starting index:\n      MockRAMDirectory startDir = new MockRAMDirectory();\n      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      long diskUsage = ((MockRAMDirectory) startDir).getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockRAMDirectory dir = new MockRAMDirectory(startDir);\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate, diskFree);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", (float) 2.0);\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Whether we succeeded or failed, check that all\n          // un-referenced files were in fact deleted (ie,\n          // we did not create garbage).  Just create a\n          // new IndexFileDeleter, have it delete\n          // unreferenced files, then verify that in fact\n          // no files were deleted:\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"reader.close() failed to delete unreferenced files\");\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","sourceOld":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n      \n      // First build up a starting index:\n      RAMDirectory startDir = new MockRAMDirectory();\n      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      long diskUsage = ((MockRAMDirectory) startDir).getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockRAMDirectory dir = new MockRAMDirectory(startDir);\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate, diskFree);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", (float) 2.0);\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Whether we succeeded or failed, check that all\n          // un-referenced files were in fact deleted (ie,\n          // we did not create garbage).  Just create a\n          // new IndexFileDeleter, have it delete\n          // unreferenced files, then verify that in fact\n          // no files were deleted:\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"reader.close() failed to delete unreferenced files\");\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c","date":1281646583,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","sourceNew":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n      \n      // First build up a starting index:\n      MockRAMDirectory startDir = newDirectory(random);\n      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      long diskUsage = ((MockRAMDirectory) startDir).getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockRAMDirectory dir = new MockRAMDirectory(startDir);\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate, diskFree);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", (float) 2.0);\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Whether we succeeded or failed, check that all\n          // un-referenced files were in fact deleted (ie,\n          // we did not create garbage).  Just create a\n          // new IndexFileDeleter, have it delete\n          // unreferenced files, then verify that in fact\n          // no files were deleted:\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"reader.close() failed to delete unreferenced files\");\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","sourceOld":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n      \n      // First build up a starting index:\n      MockRAMDirectory startDir = new MockRAMDirectory();\n      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      long diskUsage = ((MockRAMDirectory) startDir).getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockRAMDirectory dir = new MockRAMDirectory(startDir);\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate, diskFree);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", (float) 2.0);\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Whether we succeeded or failed, check that all\n          // un-referenced files were in fact deleted (ie,\n          // we did not create garbage).  Just create a\n          // new IndexFileDeleter, have it delete\n          // unreferenced files, then verify that in fact\n          // no files were deleted:\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"reader.close() failed to delete unreferenced files\");\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a05409176bd65129d67a785ee70e881e238a9aef","date":1282582843,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","sourceNew":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n      \n      // First build up a starting index:\n      MockDirectoryWrapper startDir = newDirectory(random);\n      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      long diskUsage = startDir.getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(new RAMDirectory(startDir));\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate, diskFree);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", (float) 2.0);\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Whether we succeeded or failed, check that all\n          // un-referenced files were in fact deleted (ie,\n          // we did not create garbage).  Just create a\n          // new IndexFileDeleter, have it delete\n          // unreferenced files, then verify that in fact\n          // no files were deleted:\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"reader.close() failed to delete unreferenced files\");\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","sourceOld":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n      \n      // First build up a starting index:\n      MockRAMDirectory startDir = newDirectory(random);\n      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      long diskUsage = ((MockRAMDirectory) startDir).getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockRAMDirectory dir = new MockRAMDirectory(startDir);\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate, diskFree);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", (float) 2.0);\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Whether we succeeded or failed, check that all\n          // un-referenced files were in fact deleted (ie,\n          // we did not create garbage).  Just create a\n          // new IndexFileDeleter, have it delete\n          // unreferenced files, then verify that in fact\n          // no files were deleted:\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"reader.close() failed to delete unreferenced files\");\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1f653cfcf159baeaafe5d01682a911e95bba4012","date":1284122058,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","sourceNew":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n      \n      // First build up a starting index:\n      MockDirectoryWrapper startDir = newDirectory();\n      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      long diskUsage = startDir.getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(new RAMDirectory(startDir));\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate, diskFree);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", (float) 2.0);\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Whether we succeeded or failed, check that all\n          // un-referenced files were in fact deleted (ie,\n          // we did not create garbage).  Just create a\n          // new IndexFileDeleter, have it delete\n          // unreferenced files, then verify that in fact\n          // no files were deleted:\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"reader.close() failed to delete unreferenced files\");\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","sourceOld":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n      \n      // First build up a starting index:\n      MockDirectoryWrapper startDir = newDirectory(random);\n      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      long diskUsage = startDir.getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(new RAMDirectory(startDir));\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate, diskFree);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", (float) 2.0);\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Whether we succeeded or failed, check that all\n          // un-referenced files were in fact deleted (ie,\n          // we did not create garbage).  Just create a\n          // new IndexFileDeleter, have it delete\n          // unreferenced files, then verify that in fact\n          // no files were deleted:\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"reader.close() failed to delete unreferenced files\");\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"132903c28af3aa6f67284b78de91c0f0a99488c2","date":1284282129,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","sourceNew":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n      \n      // First build up a starting index:\n      MockDirectoryWrapper startDir = newDirectory();\n      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      long diskUsage = startDir.getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(new RAMDirectory(startDir));\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate, diskFree);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", (float) 2.0);\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Whether we succeeded or failed, check that all\n          // un-referenced files were in fact deleted (ie,\n          // we did not create garbage).  Just create a\n          // new IndexFileDeleter, have it delete\n          // unreferenced files, then verify that in fact\n          // no files were deleted:\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"reader.close() failed to delete unreferenced files\");\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","sourceOld":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n      \n      // First build up a starting index:\n      MockDirectoryWrapper startDir = newDirectory();\n      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      long diskUsage = startDir.getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(new RAMDirectory(startDir));\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate, diskFree);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", (float) 2.0);\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Whether we succeeded or failed, check that all\n          // un-referenced files were in fact deleted (ie,\n          // we did not create garbage).  Just create a\n          // new IndexFileDeleter, have it delete\n          // unreferenced files, then verify that in fact\n          // no files were deleted:\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"reader.close() failed to delete unreferenced files\");\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"53a31399f2471493d67b19a95c028a74e0113b6a","date":1289817072,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","sourceNew":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n      \n      // First build up a starting index:\n      MockDirectoryWrapper startDir = newDirectory();\n      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      long diskUsage = startDir.getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", (float) 2.0);\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Whether we succeeded or failed, check that all\n          // un-referenced files were in fact deleted (ie,\n          // we did not create garbage).  Just create a\n          // new IndexFileDeleter, have it delete\n          // unreferenced files, then verify that in fact\n          // no files were deleted:\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"reader.close() failed to delete unreferenced files\");\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","sourceOld":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n      \n      // First build up a starting index:\n      MockDirectoryWrapper startDir = newDirectory();\n      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      long diskUsage = startDir.getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(new RAMDirectory(startDir));\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate, diskFree);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", (float) 2.0);\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Whether we succeeded or failed, check that all\n          // un-referenced files were in fact deleted (ie,\n          // we did not create garbage).  Just create a\n          // new IndexFileDeleter, have it delete\n          // unreferenced files, then verify that in fact\n          // no files were deleted:\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"reader.close() failed to delete unreferenced files\");\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9ab1f5591dc05f1f2b5407d809c9699f75554a32","date":1290008586,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","sourceNew":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n      \n      // First build up a starting index:\n      MockDirectoryWrapper startDir = newDirectory();\n      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      long diskUsage = startDir.getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", (float) 2.0);\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Whether we succeeded or failed, check that all\n          // un-referenced files were in fact deleted (ie,\n          // we did not create garbage).  Just create a\n          // new IndexFileDeleter, have it delete\n          // unreferenced files, then verify that in fact\n          // no files were deleted:\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"reader.close() failed to delete unreferenced files\");\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","sourceOld":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n      \n      // First build up a starting index:\n      MockDirectoryWrapper startDir = newDirectory();\n      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      long diskUsage = startDir.getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(new RAMDirectory(startDir));\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate, diskFree);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", (float) 2.0);\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Whether we succeeded or failed, check that all\n          // un-referenced files were in fact deleted (ie,\n          // we did not create garbage).  Just create a\n          // new IndexFileDeleter, have it delete\n          // unreferenced files, then verify that in fact\n          // no files were deleted:\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"reader.close() failed to delete unreferenced files\");\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","sourceNew":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n\n      // First build up a starting index:\n      MockDirectoryWrapper startDir = newDirectory();\n      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      long diskUsage = startDir.getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", (float) 2.0);\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Whether we succeeded or failed, check that all\n          // un-referenced files were in fact deleted (ie,\n          // we did not create garbage).  Just create a\n          // new IndexFileDeleter, have it delete\n          // unreferenced files, then verify that in fact\n          // no files were deleted:\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"reader.close() failed to delete unreferenced files\");\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","sourceOld":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n      \n      // First build up a starting index:\n      RAMDirectory startDir = new MockRAMDirectory();\n      IndexWriter writer = new IndexWriter(startDir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      long diskUsage = ((MockRAMDirectory) startDir).getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockRAMDirectory dir = new MockRAMDirectory(startDir);\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate, diskFree);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", (float) 2.0);\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Whether we succeeded or failed, check that all\n          // un-referenced files were in fact deleted (ie,\n          // we did not create garbage).  Just create a\n          // new IndexFileDeleter, have it delete\n          // unreferenced files, then verify that in fact\n          // no files were deleted:\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"reader.close() failed to delete unreferenced files\");\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"347c6da08ee2df2551ec05ebb1754e685937c1f3","date":1294422164,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","sourceNew":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n      \n      // First build up a starting index:\n      MockDirectoryWrapper startDir = newDirectory();\n      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      long diskUsage = startDir.getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", (float) 2.0);\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Whether we succeeded or failed, check that all\n          // un-referenced files were in fact deleted (ie,\n          // we did not create garbage).  Just create a\n          // new IndexFileDeleter, have it delete\n          // unreferenced files, then verify that in fact\n          // no files were deleted:\n          IndexWriter.unlock(dir);\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"reader.close() failed to delete unreferenced files\");\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","sourceOld":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n      \n      // First build up a starting index:\n      MockDirectoryWrapper startDir = newDirectory();\n      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      long diskUsage = startDir.getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", (float) 2.0);\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Whether we succeeded or failed, check that all\n          // un-referenced files were in fact deleted (ie,\n          // we did not create garbage).  Just create a\n          // new IndexFileDeleter, have it delete\n          // unreferenced files, then verify that in fact\n          // no files were deleted:\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"reader.close() failed to delete unreferenced files\");\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7a54e23e03b47f3d568ab3020bdd386e4b2f0a05","date":1294877328,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","sourceNew":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n      \n      // First build up a starting index:\n      MockDirectoryWrapper startDir = newDirectory();\n      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      long diskUsage = startDir.getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", Similarity.getDefault().encodeNormValue(2.0f));\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Whether we succeeded or failed, check that all\n          // un-referenced files were in fact deleted (ie,\n          // we did not create garbage).  Just create a\n          // new IndexFileDeleter, have it delete\n          // unreferenced files, then verify that in fact\n          // no files were deleted:\n          IndexWriter.unlock(dir);\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"reader.close() failed to delete unreferenced files\");\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","sourceOld":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n      \n      // First build up a starting index:\n      MockDirectoryWrapper startDir = newDirectory();\n      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      long diskUsage = startDir.getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", (float) 2.0);\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Whether we succeeded or failed, check that all\n          // un-referenced files were in fact deleted (ie,\n          // we did not create garbage).  Just create a\n          // new IndexFileDeleter, have it delete\n          // unreferenced files, then verify that in fact\n          // no files were deleted:\n          IndexWriter.unlock(dir);\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"reader.close() failed to delete unreferenced files\");\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"868da859b43505d9d2a023bfeae6dd0c795f5295","date":1294948401,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","sourceNew":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n\n      // First build up a starting index:\n      MockDirectoryWrapper startDir = newDirectory();\n      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      long diskUsage = startDir.getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", Similarity.getDefault().encodeNormValue(2.0f));\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Whether we succeeded or failed, check that all\n          // un-referenced files were in fact deleted (ie,\n          // we did not create garbage).  Just create a\n          // new IndexFileDeleter, have it delete\n          // unreferenced files, then verify that in fact\n          // no files were deleted:\n          IndexWriter.unlock(dir);\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"reader.close() failed to delete unreferenced files\");\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","sourceOld":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n\n      // First build up a starting index:\n      MockDirectoryWrapper startDir = newDirectory();\n      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      long diskUsage = startDir.getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", (float) 2.0);\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Whether we succeeded or failed, check that all\n          // un-referenced files were in fact deleted (ie,\n          // we did not create garbage).  Just create a\n          // new IndexFileDeleter, have it delete\n          // unreferenced files, then verify that in fact\n          // no files were deleted:\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"reader.close() failed to delete unreferenced files\");\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b1add9ddc0005b07550d4350720aac22dc9886b3","date":1295549635,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","sourceNew":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n      \n      // First build up a starting index:\n      MockDirectoryWrapper startDir = newDirectory();\n      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n      if (VERBOSE) {\n        System.out.println(\"TEST: create initial index\");\n        writer.setInfoStream(System.out);\n      }\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      {\n        IndexReader r = IndexReader.open(startDir);\n        IndexSearcher searcher = new IndexSearcher(r);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(\"exception when init searching: \" + e);\n        }\n        r.close();\n      }\n\n      long diskUsage = startDir.getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", Similarity.getDefault().encodeNormValue(2.0f));\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Whether we succeeded or failed, check that all\n          // un-referenced files were in fact deleted (ie,\n          // we did not create garbage).  Just create a\n          // new IndexFileDeleter, have it delete\n          // unreferenced files, then verify that in fact\n          // no files were deleted:\n          IndexWriter.unlock(dir);\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"reader.close() failed to delete unreferenced files\");\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","sourceOld":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n      \n      // First build up a starting index:\n      MockDirectoryWrapper startDir = newDirectory();\n      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      long diskUsage = startDir.getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", Similarity.getDefault().encodeNormValue(2.0f));\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Whether we succeeded or failed, check that all\n          // un-referenced files were in fact deleted (ie,\n          // we did not create garbage).  Just create a\n          // new IndexFileDeleter, have it delete\n          // unreferenced files, then verify that in fact\n          // no files were deleted:\n          IndexWriter.unlock(dir);\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"reader.close() failed to delete unreferenced files\");\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e79a6d080bdd5b2a8f56342cf571b5476de04180","date":1295638686,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","sourceNew":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n\n      // First build up a starting index:\n      MockDirectoryWrapper startDir = newDirectory();\n      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n      if (VERBOSE) {\n        System.out.println(\"TEST: create initial index\");\n        writer.setInfoStream(System.out);\n      }\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      {\n        IndexReader r = IndexReader.open(startDir);\n        IndexSearcher searcher = new IndexSearcher(r);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(\"exception when init searching: \" + e);\n        }\n        r.close();\n      }\n\n      long diskUsage = startDir.getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", Similarity.getDefault().encodeNormValue(2.0f));\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Whether we succeeded or failed, check that all\n          // un-referenced files were in fact deleted (ie,\n          // we did not create garbage).  Just create a\n          // new IndexFileDeleter, have it delete\n          // unreferenced files, then verify that in fact\n          // no files were deleted:\n          IndexWriter.unlock(dir);\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"reader.close() failed to delete unreferenced files\");\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","sourceOld":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n\n      // First build up a starting index:\n      MockDirectoryWrapper startDir = newDirectory();\n      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      long diskUsage = startDir.getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", Similarity.getDefault().encodeNormValue(2.0f));\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Whether we succeeded or failed, check that all\n          // un-referenced files were in fact deleted (ie,\n          // we did not create garbage).  Just create a\n          // new IndexFileDeleter, have it delete\n          // unreferenced files, then verify that in fact\n          // no files were deleted:\n          IndexWriter.unlock(dir);\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"reader.close() failed to delete unreferenced files\");\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fd9325c7ff9928fabe81c28553b41fc7aa57dfab","date":1295896411,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","sourceNew":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n      \n      // First build up a starting index:\n      MockDirectoryWrapper startDir = newDirectory();\n      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n      if (VERBOSE) {\n        System.out.println(\"TEST: create initial index\");\n        writer.setInfoStream(System.out);\n      }\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      {\n        IndexReader r = IndexReader.open(startDir);\n        IndexSearcher searcher = new IndexSearcher(r);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(\"exception when init searching: \" + e);\n        }\n        r.close();\n      }\n\n      long diskUsage = startDir.getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate);\n          Similarity sim = new DefaultSimilarity().get(\"content\");\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", sim.encodeNormValue(2.0f));\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Whether we succeeded or failed, check that all\n          // un-referenced files were in fact deleted (ie,\n          // we did not create garbage).  Just create a\n          // new IndexFileDeleter, have it delete\n          // unreferenced files, then verify that in fact\n          // no files were deleted:\n          IndexWriter.unlock(dir);\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"reader.close() failed to delete unreferenced files\");\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","sourceOld":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n      \n      // First build up a starting index:\n      MockDirectoryWrapper startDir = newDirectory();\n      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n      if (VERBOSE) {\n        System.out.println(\"TEST: create initial index\");\n        writer.setInfoStream(System.out);\n      }\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      {\n        IndexReader r = IndexReader.open(startDir);\n        IndexSearcher searcher = new IndexSearcher(r);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(\"exception when init searching: \" + e);\n        }\n        r.close();\n      }\n\n      long diskUsage = startDir.getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", Similarity.getDefault().encodeNormValue(2.0f));\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Whether we succeeded or failed, check that all\n          // un-referenced files were in fact deleted (ie,\n          // we did not create garbage).  Just create a\n          // new IndexFileDeleter, have it delete\n          // unreferenced files, then verify that in fact\n          // no files were deleted:\n          IndexWriter.unlock(dir);\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"reader.close() failed to delete unreferenced files\");\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bb9b72f7c3d7827c64dd4ec580ded81778da361d","date":1295897920,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","sourceNew":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n\n      // First build up a starting index:\n      MockDirectoryWrapper startDir = newDirectory();\n      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n      if (VERBOSE) {\n        System.out.println(\"TEST: create initial index\");\n        writer.setInfoStream(System.out);\n      }\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      {\n        IndexReader r = IndexReader.open(startDir);\n        IndexSearcher searcher = new IndexSearcher(r);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(\"exception when init searching: \" + e);\n        }\n        r.close();\n      }\n\n      long diskUsage = startDir.getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate);\n          Similarity sim = new DefaultSimilarity().get(\"content\");\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", sim.encodeNormValue(2.0f));\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Whether we succeeded or failed, check that all\n          // un-referenced files were in fact deleted (ie,\n          // we did not create garbage).  Just create a\n          // new IndexFileDeleter, have it delete\n          // unreferenced files, then verify that in fact\n          // no files were deleted:\n          IndexWriter.unlock(dir);\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"reader.close() failed to delete unreferenced files\");\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","sourceOld":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n\n      // First build up a starting index:\n      MockDirectoryWrapper startDir = newDirectory();\n      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n      if (VERBOSE) {\n        System.out.println(\"TEST: create initial index\");\n        writer.setInfoStream(System.out);\n      }\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      {\n        IndexReader r = IndexReader.open(startDir);\n        IndexSearcher searcher = new IndexSearcher(r);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(\"exception when init searching: \" + e);\n        }\n        r.close();\n      }\n\n      long diskUsage = startDir.getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", Similarity.getDefault().encodeNormValue(2.0f));\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Whether we succeeded or failed, check that all\n          // un-referenced files were in fact deleted (ie,\n          // we did not create garbage).  Just create a\n          // new IndexFileDeleter, have it delete\n          // unreferenced files, then verify that in fact\n          // no files were deleted:\n          IndexWriter.unlock(dir);\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"reader.close() failed to delete unreferenced files\");\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2eeb4770be14d50eecf65d37dd5ab961fbaded2b","date":1296078937,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","sourceNew":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n      \n      // First build up a starting index:\n      MockDirectoryWrapper startDir = newDirectory();\n      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n      if (VERBOSE) {\n        System.out.println(\"TEST: create initial index\");\n        writer.setInfoStream(System.out);\n      }\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      {\n        IndexReader r = IndexReader.open(startDir);\n        IndexSearcher searcher = new IndexSearcher(r);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(\"exception when init searching: \" + e);\n        }\n        r.close();\n      }\n\n      long diskUsage = startDir.getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate);\n          Similarity sim = new DefaultSimilarity().get(\"content\");\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", sim.encodeNormValue(2.0f));\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","sourceOld":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n      \n      // First build up a starting index:\n      MockDirectoryWrapper startDir = newDirectory();\n      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n      if (VERBOSE) {\n        System.out.println(\"TEST: create initial index\");\n        writer.setInfoStream(System.out);\n      }\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      {\n        IndexReader r = IndexReader.open(startDir);\n        IndexSearcher searcher = new IndexSearcher(r);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(\"exception when init searching: \" + e);\n        }\n        r.close();\n      }\n\n      long diskUsage = startDir.getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate);\n          Similarity sim = new DefaultSimilarity().get(\"content\");\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", sim.encodeNormValue(2.0f));\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Whether we succeeded or failed, check that all\n          // un-referenced files were in fact deleted (ie,\n          // we did not create garbage).  Just create a\n          // new IndexFileDeleter, have it delete\n          // unreferenced files, then verify that in fact\n          // no files were deleted:\n          IndexWriter.unlock(dir);\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"reader.close() failed to delete unreferenced files\");\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"790e1fde4caa765b3faaad3fbcd25c6973450336","date":1296689245,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","sourceNew":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n      \n      // First build up a starting index:\n      MockDirectoryWrapper startDir = newDirectory();\n      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n      if (VERBOSE) {\n        System.out.println(\"TEST: create initial index\");\n        writer.setInfoStream(System.out);\n      }\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      {\n        IndexReader r = IndexReader.open(startDir);\n        IndexSearcher searcher = newSearcher(r);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(\"exception when init searching: \" + e);\n        }\n        searcher.close();\n        r.close();\n      }\n\n      long diskUsage = startDir.getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate);\n          Similarity sim = new DefaultSimilarity().get(\"content\");\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", sim.encodeNormValue(2.0f));\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = newSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","sourceOld":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n      \n      // First build up a starting index:\n      MockDirectoryWrapper startDir = newDirectory();\n      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n      if (VERBOSE) {\n        System.out.println(\"TEST: create initial index\");\n        writer.setInfoStream(System.out);\n      }\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      {\n        IndexReader r = IndexReader.open(startDir);\n        IndexSearcher searcher = new IndexSearcher(r);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(\"exception when init searching: \" + e);\n        }\n        r.close();\n      }\n\n      long diskUsage = startDir.getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate);\n          Similarity sim = new DefaultSimilarity().get(\"content\");\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", sim.encodeNormValue(2.0f));\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"29ef99d61cda9641b6250bf9567329a6e65f901d","date":1297244127,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","sourceNew":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n      \n      // First build up a starting index:\n      MockDirectoryWrapper startDir = newDirectory();\n      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n      if (VERBOSE) {\n        System.out.println(\"TEST: create initial index\");\n        writer.setInfoStream(System.out);\n      }\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      {\n        IndexReader r = IndexReader.open(startDir);\n        IndexSearcher searcher = newSearcher(r);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(\"exception when init searching: \" + e);\n        }\n        searcher.close();\n        r.close();\n      }\n\n      long diskUsage = startDir.getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate);\n          Similarity sim = new DefaultSimilarity().get(\"content\");\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", sim.encodeNormValue(2.0f));\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = newSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","sourceOld":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n      \n      // First build up a starting index:\n      MockDirectoryWrapper startDir = newDirectory();\n      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      long diskUsage = startDir.getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", (float) 2.0);\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Whether we succeeded or failed, check that all\n          // un-referenced files were in fact deleted (ie,\n          // we did not create garbage).  Just create a\n          // new IndexFileDeleter, have it delete\n          // unreferenced files, then verify that in fact\n          // no files were deleted:\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"reader.close() failed to delete unreferenced files\");\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bde51b089eb7f86171eb3406e38a274743f9b7ac","date":1298336439,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","sourceNew":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n\n      // First build up a starting index:\n      MockDirectoryWrapper startDir = newDirectory();\n      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n      if (VERBOSE) {\n        System.out.println(\"TEST: create initial index\");\n        writer.setInfoStream(System.out);\n      }\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      {\n        IndexReader r = IndexReader.open(startDir);\n        IndexSearcher searcher = newSearcher(r);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(\"exception when init searching: \" + e);\n        }\n        searcher.close();\n        r.close();\n      }\n\n      long diskUsage = startDir.getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate);\n          Similarity sim = new DefaultSimilarity().get(\"content\");\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", sim.encodeNormValue(2.0f));\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = newSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","sourceOld":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n\n      // First build up a starting index:\n      MockDirectoryWrapper startDir = newDirectory();\n      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n      if (VERBOSE) {\n        System.out.println(\"TEST: create initial index\");\n        writer.setInfoStream(System.out);\n      }\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      {\n        IndexReader r = IndexReader.open(startDir);\n        IndexSearcher searcher = new IndexSearcher(r);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(\"exception when init searching: \" + e);\n        }\n        r.close();\n      }\n\n      long diskUsage = startDir.getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate);\n          Similarity sim = new DefaultSimilarity().get(\"content\");\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", sim.encodeNormValue(2.0f));\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Whether we succeeded or failed, check that all\n          // un-referenced files were in fact deleted (ie,\n          // we did not create garbage).  Just create a\n          // new IndexFileDeleter, have it delete\n          // unreferenced files, then verify that in fact\n          // no files were deleted:\n          IndexWriter.unlock(dir);\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"reader.close() failed to delete unreferenced files\");\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a31c91eda919456f5f9237b086174385292f9935","date":1299074041,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","sourceNew":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n      \n      // First build up a starting index:\n      MockDirectoryWrapper startDir = newDirectory();\n      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n      if (VERBOSE) {\n        System.out.println(\"TEST: create initial index\");\n        writer.setInfoStream(System.out);\n      }\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      {\n        IndexReader r = IndexReader.open(startDir);\n        IndexSearcher searcher = newSearcher(r);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(\"exception when init searching: \" + e);\n        }\n        searcher.close();\n        r.close();\n      }\n\n      long diskUsage = startDir.getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate);\n          Similarity sim = new DefaultSimilarity();\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", sim.encodeNormValue(2.0f));\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = newSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","sourceOld":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n      \n      // First build up a starting index:\n      MockDirectoryWrapper startDir = newDirectory();\n      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n      if (VERBOSE) {\n        System.out.println(\"TEST: create initial index\");\n        writer.setInfoStream(System.out);\n      }\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      {\n        IndexReader r = IndexReader.open(startDir);\n        IndexSearcher searcher = newSearcher(r);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(\"exception when init searching: \" + e);\n        }\n        searcher.close();\n        r.close();\n      }\n\n      long diskUsage = startDir.getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate);\n          Similarity sim = new DefaultSimilarity().get(\"content\");\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", sim.encodeNormValue(2.0f));\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = newSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d619839baa8ce5503e496b94a9e42ad6f079293f","date":1301309428,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","sourceNew":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n      \n      // First build up a starting index:\n      MockDirectoryWrapper startDir = newDirectory();\n      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n      if (VERBOSE) {\n        System.out.println(\"TEST: create initial index\");\n        writer.setInfoStream(System.out);\n      }\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      {\n        IndexReader r = IndexReader.open(startDir);\n        IndexSearcher searcher = newSearcher(r);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(\"exception when init searching: \" + e);\n        }\n        searcher.close();\n        r.close();\n      }\n\n      long diskUsage = startDir.getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate);\n          Similarity sim = new DefaultSimilarity();\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", sim.encodeNormValue(2.0f));\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = newSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","sourceOld":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n      \n      // First build up a starting index:\n      MockDirectoryWrapper startDir = newDirectory();\n      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n      if (VERBOSE) {\n        System.out.println(\"TEST: create initial index\");\n        writer.setInfoStream(System.out);\n      }\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      {\n        IndexReader r = IndexReader.open(startDir);\n        IndexSearcher searcher = newSearcher(r);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(\"exception when init searching: \" + e);\n        }\n        searcher.close();\n        r.close();\n      }\n\n      long diskUsage = startDir.getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate);\n          Similarity sim = new DefaultSimilarity().get(\"content\");\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", sim.encodeNormValue(2.0f));\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = newSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c0ef0193974807e4bddf5432a6b0287fe4d6c9df","date":1301476645,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","sourceNew":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n\n      // First build up a starting index:\n      MockDirectoryWrapper startDir = newDirectory();\n      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n      if (VERBOSE) {\n        System.out.println(\"TEST: create initial index\");\n        writer.setInfoStream(System.out);\n      }\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      {\n        IndexReader r = IndexReader.open(startDir);\n        IndexSearcher searcher = newSearcher(r);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(\"exception when init searching: \" + e);\n        }\n        searcher.close();\n        r.close();\n      }\n\n      long diskUsage = startDir.getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate);\n          Similarity sim = new DefaultSimilarity();\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", sim.encodeNormValue(2.0f));\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = newSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","sourceOld":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n\n      // First build up a starting index:\n      MockDirectoryWrapper startDir = newDirectory();\n      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n      if (VERBOSE) {\n        System.out.println(\"TEST: create initial index\");\n        writer.setInfoStream(System.out);\n      }\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      {\n        IndexReader r = IndexReader.open(startDir);\n        IndexSearcher searcher = newSearcher(r);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(\"exception when init searching: \" + e);\n        }\n        searcher.close();\n        r.close();\n      }\n\n      long diskUsage = startDir.getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate);\n          Similarity sim = new DefaultSimilarity().get(\"content\");\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", sim.encodeNormValue(2.0f));\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = newSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f2c5f0cb44df114db4228c8f77861714b5cabaea","date":1302542431,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","sourceNew":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n      \n      // First build up a starting index:\n      MockDirectoryWrapper startDir = newDirectory();\n      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n      if (VERBOSE) {\n        System.out.println(\"TEST: create initial index\");\n        writer.setInfoStream(System.out);\n      }\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      {\n        IndexReader r = IndexReader.open(startDir);\n        IndexSearcher searcher = newSearcher(r);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(\"exception when init searching: \" + e);\n        }\n        searcher.close();\n        r.close();\n      }\n\n      long diskUsage = startDir.getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate);\n          Similarity sim = new DefaultSimilarity();\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", sim.encodeNormValue(2.0f));\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = newSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","sourceOld":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n      \n      // First build up a starting index:\n      MockDirectoryWrapper startDir = newDirectory();\n      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n      if (VERBOSE) {\n        System.out.println(\"TEST: create initial index\");\n        writer.setInfoStream(System.out);\n      }\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      {\n        IndexReader r = IndexReader.open(startDir);\n        IndexSearcher searcher = newSearcher(r);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(\"exception when init searching: \" + e);\n        }\n        searcher.close();\n        r.close();\n      }\n\n      long diskUsage = startDir.getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate);\n          Similarity sim = new DefaultSimilarity();\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", sim.encodeNormValue(2.0f));\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = newSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"962d04139994fce5193143ef35615499a9a96d78","date":1302693744,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","sourceNew":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n\n      // First build up a starting index:\n      MockDirectoryWrapper startDir = newDirectory();\n      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n      if (VERBOSE) {\n        System.out.println(\"TEST: create initial index\");\n        writer.setInfoStream(System.out);\n      }\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      {\n        IndexReader r = IndexReader.open(startDir);\n        IndexSearcher searcher = newSearcher(r);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(\"exception when init searching: \" + e);\n        }\n        searcher.close();\n        r.close();\n      }\n\n      long diskUsage = startDir.getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate);\n          Similarity sim = new DefaultSimilarity();\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", sim.encodeNormValue(2.0f));\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = newSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","sourceOld":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n\n      // First build up a starting index:\n      MockDirectoryWrapper startDir = newDirectory();\n      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n      if (VERBOSE) {\n        System.out.println(\"TEST: create initial index\");\n        writer.setInfoStream(System.out);\n      }\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      {\n        IndexReader r = IndexReader.open(startDir);\n        IndexSearcher searcher = newSearcher(r);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(\"exception when init searching: \" + e);\n        }\n        searcher.close();\n        r.close();\n      }\n\n      long diskUsage = startDir.getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate);\n          Similarity sim = new DefaultSimilarity();\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", sim.encodeNormValue(2.0f));\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = newSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"135621f3a0670a9394eb563224a3b76cc4dddc0f","date":1304344257,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","sourceNew":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n      \n      // First build up a starting index:\n      MockDirectoryWrapper startDir = newDirectory();\n      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n      if (VERBOSE) {\n        System.out.println(\"TEST: create initial index\");\n        writer.setInfoStream(System.out);\n      }\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      {\n        IndexReader r = IndexReader.open(startDir);\n        IndexSearcher searcher = newSearcher(r);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(\"exception when init searching: \" + e);\n        }\n        searcher.close();\n        r.close();\n      }\n\n      long diskUsage = startDir.getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate);\n          Similarity sim = new DefaultSimilarity();\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", sim.encodeNormValue(2.0f));\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = newSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","sourceOld":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n      \n      // First build up a starting index:\n      MockDirectoryWrapper startDir = newDirectory();\n      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n      if (VERBOSE) {\n        System.out.println(\"TEST: create initial index\");\n        writer.setInfoStream(System.out);\n      }\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      {\n        IndexReader r = IndexReader.open(startDir);\n        IndexSearcher searcher = newSearcher(r);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(\"exception when init searching: \" + e);\n        }\n        searcher.close();\n        r.close();\n      }\n\n      long diskUsage = startDir.getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate);\n          Similarity sim = new DefaultSimilarity();\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", sim.encodeNormValue(2.0f));\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = newSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","sourceNew":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n      \n      // First build up a starting index:\n      MockDirectoryWrapper startDir = newDirectory();\n      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n      if (VERBOSE) {\n        System.out.println(\"TEST: create initial index\");\n        writer.setInfoStream(System.out);\n      }\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      {\n        IndexReader r = IndexReader.open(startDir);\n        IndexSearcher searcher = newSearcher(r);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(\"exception when init searching: \" + e);\n        }\n        searcher.close();\n        r.close();\n      }\n\n      long diskUsage = startDir.getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate);\n          Similarity sim = new DefaultSimilarity();\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", sim.encodeNormValue(2.0f));\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = newSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","sourceOld":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n      \n      // First build up a starting index:\n      MockDirectoryWrapper startDir = newDirectory();\n      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n      if (VERBOSE) {\n        System.out.println(\"TEST: create initial index\");\n        writer.setInfoStream(System.out);\n      }\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      {\n        IndexReader r = IndexReader.open(startDir);\n        IndexSearcher searcher = newSearcher(r);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(\"exception when init searching: \" + e);\n        }\n        searcher.close();\n        r.close();\n      }\n\n      long diskUsage = startDir.getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate);\n          Similarity sim = new DefaultSimilarity();\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", sim.encodeNormValue(2.0f));\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = newSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ff6fd241dc6610f7f81b62e3ba4cedf105939623","date":1307331653,"type":4,"author":"Robert Muir","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","sourceNew":null,"sourceOld":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n      \n      // First build up a starting index:\n      MockDirectoryWrapper startDir = newDirectory();\n      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n      if (VERBOSE) {\n        System.out.println(\"TEST: create initial index\");\n        writer.setInfoStream(System.out);\n      }\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      {\n        IndexReader r = IndexReader.open(startDir);\n        IndexSearcher searcher = newSearcher(r);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(\"exception when init searching: \" + e);\n        }\n        searcher.close();\n        r.close();\n      }\n\n      long diskUsage = startDir.getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate);\n          Similarity sim = new DefaultSimilarity();\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", sim.encodeNormValue(2.0f));\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = newSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"79c2cb24929f2649a8875fb629086171f914d5ce","date":1307332717,"type":4,"author":"Steven Rowe","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","sourceNew":null,"sourceOld":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n      \n      // First build up a starting index:\n      MockDirectoryWrapper startDir = newDirectory();\n      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n      if (VERBOSE) {\n        System.out.println(\"TEST: create initial index\");\n        writer.setInfoStream(System.out);\n      }\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      {\n        IndexReader r = IndexReader.open(startDir);\n        IndexSearcher searcher = newSearcher(r);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(\"exception when init searching: \" + e);\n        }\n        searcher.close();\n        r.close();\n      }\n\n      long diskUsage = startDir.getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate);\n          Similarity sim = new DefaultSimilarity();\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", sim.encodeNormValue(2.0f));\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = newSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"77cf4379b2824f6ea34b091c495d6e95c38ff9e2","date":1307610475,"type":4,"author":"Simon Willnauer","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testDiskFull().mjava","sourceNew":null,"sourceOld":"    /**\n     * Make sure if reader tries to commit but hits disk\n     * full that reader remains consistent and usable.\n     */\n    public void testDiskFull() throws IOException {\n\n      Term searchTerm = new Term(\"content\", \"aaa\");\n      int START_COUNT = 157;\n      int END_COUNT = 144;\n      \n      // First build up a starting index:\n      MockDirectoryWrapper startDir = newDirectory();\n      IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n      if (VERBOSE) {\n        System.out.println(\"TEST: create initial index\");\n        writer.setInfoStream(System.out);\n      }\n      for(int i=0;i<157;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n        d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n        writer.addDocument(d);\n        if (0==i%10)\n          writer.commit();\n      }\n      writer.close();\n\n      {\n        IndexReader r = IndexReader.open(startDir);\n        IndexSearcher searcher = newSearcher(r);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(\"exception when init searching: \" + e);\n        }\n        searcher.close();\n        r.close();\n      }\n\n      long diskUsage = startDir.getRecomputedActualSizeInBytes();\n      long diskFree = diskUsage+100;\n\n      IOException err = null;\n\n      boolean done = false;\n      boolean gotExc = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while(!done) {\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));\n\n        // If IndexReader hits disk full, it can write to\n        // the same files again.\n        dir.setPreventDoubleWrite(false);\n\n        IndexReader reader = IndexReader.open(dir, false);\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for(int x=0;x<2;x++) {\n\n          double rate = 0.05;\n          double diskRatio = ((double) diskFree)/diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (VERBOSE) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate);\n          Similarity sim = new DefaultSimilarity();\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for(int i=0;i<13;i++) {\n                reader.deleteDocument(docId);\n                reader.setNorm(docId, \"content\", sim.encodeNormValue(2.0f));\n                docId += 12;\n              }\n            }\n            reader.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          } catch (IOException e) {\n            if (VERBOSE) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            gotExc = true;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, false);\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n          }\n          /*\n          int result = newReader.docFreq(searchTerm);\n          if (success) {\n            if (result != END_COUNT) {\n              fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result != START_COUNT && result != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n          */\n\n          IndexSearcher searcher = newSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          } catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            if (!gotExc)\n              fail(\"never hit disk full\");\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n\n      startDir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"955c32f886db6f6356c9fcdea6b1f1cb4effda24":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"132903c28af3aa6f67284b78de91c0f0a99488c2":["1f653cfcf159baeaafe5d01682a911e95bba4012"],"b1add9ddc0005b07550d4350720aac22dc9886b3":["7a54e23e03b47f3d568ab3020bdd386e4b2f0a05"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["d572389229127c297dd1fa5ce4758e1cec41e799","53a31399f2471493d67b19a95c028a74e0113b6a"],"bb9b72f7c3d7827c64dd4ec580ded81778da361d":["e79a6d080bdd5b2a8f56342cf571b5476de04180","fd9325c7ff9928fabe81c28553b41fc7aa57dfab"],"fd9325c7ff9928fabe81c28553b41fc7aa57dfab":["b1add9ddc0005b07550d4350720aac22dc9886b3"],"c0ef0193974807e4bddf5432a6b0287fe4d6c9df":["bde51b089eb7f86171eb3406e38a274743f9b7ac","a31c91eda919456f5f9237b086174385292f9935"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["a31c91eda919456f5f9237b086174385292f9935"],"53a31399f2471493d67b19a95c028a74e0113b6a":["132903c28af3aa6f67284b78de91c0f0a99488c2"],"79c2cb24929f2649a8875fb629086171f914d5ce":["a3776dccca01c11e7046323cfad46a3b4a471233","ff6fd241dc6610f7f81b62e3ba4cedf105939623"],"1f653cfcf159baeaafe5d01682a911e95bba4012":["a05409176bd65129d67a785ee70e881e238a9aef"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["9ab1f5591dc05f1f2b5407d809c9699f75554a32","790e1fde4caa765b3faaad3fbcd25c6973450336"],"1a2e46fd1b7cbc52d7d6461a6ef99e7107ae2a9c":["b21422ff1d1d56499dec481f193b402e5e8def5b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a05409176bd65129d67a785ee70e881e238a9aef":["ab9633cb67e3c0aec3c066147a23a957d6e7ad8c"],"b21422ff1d1d56499dec481f193b402e5e8def5b":["d572389229127c297dd1fa5ce4758e1cec41e799"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["bb9b72f7c3d7827c64dd4ec580ded81778da361d","790e1fde4caa765b3faaad3fbcd25c6973450336"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"7a54e23e03b47f3d568ab3020bdd386e4b2f0a05":["347c6da08ee2df2551ec05ebb1754e685937c1f3"],"ff6fd241dc6610f7f81b62e3ba4cedf105939623":["f2c5f0cb44df114db4228c8f77861714b5cabaea"],"a31c91eda919456f5f9237b086174385292f9935":["790e1fde4caa765b3faaad3fbcd25c6973450336"],"9ab1f5591dc05f1f2b5407d809c9699f75554a32":["132903c28af3aa6f67284b78de91c0f0a99488c2","53a31399f2471493d67b19a95c028a74e0113b6a"],"2eeb4770be14d50eecf65d37dd5ab961fbaded2b":["fd9325c7ff9928fabe81c28553b41fc7aa57dfab"],"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c":["1a2e46fd1b7cbc52d7d6461a6ef99e7107ae2a9c"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["d619839baa8ce5503e496b94a9e42ad6f079293f","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"347c6da08ee2df2551ec05ebb1754e685937c1f3":["53a31399f2471493d67b19a95c028a74e0113b6a"],"d572389229127c297dd1fa5ce4758e1cec41e799":["955c32f886db6f6356c9fcdea6b1f1cb4effda24"],"962d04139994fce5193143ef35615499a9a96d78":["c0ef0193974807e4bddf5432a6b0287fe4d6c9df","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"e79a6d080bdd5b2a8f56342cf571b5476de04180":["868da859b43505d9d2a023bfeae6dd0c795f5295","b1add9ddc0005b07550d4350720aac22dc9886b3"],"790e1fde4caa765b3faaad3fbcd25c6973450336":["2eeb4770be14d50eecf65d37dd5ab961fbaded2b"],"d619839baa8ce5503e496b94a9e42ad6f079293f":["29ef99d61cda9641b6250bf9567329a6e65f901d","a31c91eda919456f5f9237b086174385292f9935"],"a3776dccca01c11e7046323cfad46a3b4a471233":["a31c91eda919456f5f9237b086174385292f9935","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"77cf4379b2824f6ea34b091c495d6e95c38ff9e2":["135621f3a0670a9394eb563224a3b76cc4dddc0f","ff6fd241dc6610f7f81b62e3ba4cedf105939623"],"868da859b43505d9d2a023bfeae6dd0c795f5295":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","7a54e23e03b47f3d568ab3020bdd386e4b2f0a05"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["ff6fd241dc6610f7f81b62e3ba4cedf105939623"]},"commit2Childs":{"955c32f886db6f6356c9fcdea6b1f1cb4effda24":["d572389229127c297dd1fa5ce4758e1cec41e799"],"132903c28af3aa6f67284b78de91c0f0a99488c2":["53a31399f2471493d67b19a95c028a74e0113b6a","9ab1f5591dc05f1f2b5407d809c9699f75554a32"],"b1add9ddc0005b07550d4350720aac22dc9886b3":["fd9325c7ff9928fabe81c28553b41fc7aa57dfab","e79a6d080bdd5b2a8f56342cf571b5476de04180"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["868da859b43505d9d2a023bfeae6dd0c795f5295"],"bb9b72f7c3d7827c64dd4ec580ded81778da361d":["bde51b089eb7f86171eb3406e38a274743f9b7ac"],"fd9325c7ff9928fabe81c28553b41fc7aa57dfab":["bb9b72f7c3d7827c64dd4ec580ded81778da361d","2eeb4770be14d50eecf65d37dd5ab961fbaded2b"],"c0ef0193974807e4bddf5432a6b0287fe4d6c9df":["962d04139994fce5193143ef35615499a9a96d78"],"53a31399f2471493d67b19a95c028a74e0113b6a":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","9ab1f5591dc05f1f2b5407d809c9699f75554a32","347c6da08ee2df2551ec05ebb1754e685937c1f3"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["ff6fd241dc6610f7f81b62e3ba4cedf105939623","135621f3a0670a9394eb563224a3b76cc4dddc0f","962d04139994fce5193143ef35615499a9a96d78","a3776dccca01c11e7046323cfad46a3b4a471233"],"79c2cb24929f2649a8875fb629086171f914d5ce":[],"1f653cfcf159baeaafe5d01682a911e95bba4012":["132903c28af3aa6f67284b78de91c0f0a99488c2"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["d619839baa8ce5503e496b94a9e42ad6f079293f"],"1a2e46fd1b7cbc52d7d6461a6ef99e7107ae2a9c":["ab9633cb67e3c0aec3c066147a23a957d6e7ad8c"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"a05409176bd65129d67a785ee70e881e238a9aef":["1f653cfcf159baeaafe5d01682a911e95bba4012"],"b21422ff1d1d56499dec481f193b402e5e8def5b":["1a2e46fd1b7cbc52d7d6461a6ef99e7107ae2a9c"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["c0ef0193974807e4bddf5432a6b0287fe4d6c9df"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["955c32f886db6f6356c9fcdea6b1f1cb4effda24"],"7a54e23e03b47f3d568ab3020bdd386e4b2f0a05":["b1add9ddc0005b07550d4350720aac22dc9886b3","868da859b43505d9d2a023bfeae6dd0c795f5295"],"ff6fd241dc6610f7f81b62e3ba4cedf105939623":["79c2cb24929f2649a8875fb629086171f914d5ce","77cf4379b2824f6ea34b091c495d6e95c38ff9e2","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a31c91eda919456f5f9237b086174385292f9935":["c0ef0193974807e4bddf5432a6b0287fe4d6c9df","f2c5f0cb44df114db4228c8f77861714b5cabaea","d619839baa8ce5503e496b94a9e42ad6f079293f","a3776dccca01c11e7046323cfad46a3b4a471233"],"9ab1f5591dc05f1f2b5407d809c9699f75554a32":["29ef99d61cda9641b6250bf9567329a6e65f901d"],"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c":["a05409176bd65129d67a785ee70e881e238a9aef"],"2eeb4770be14d50eecf65d37dd5ab961fbaded2b":["790e1fde4caa765b3faaad3fbcd25c6973450336"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["77cf4379b2824f6ea34b091c495d6e95c38ff9e2"],"347c6da08ee2df2551ec05ebb1754e685937c1f3":["7a54e23e03b47f3d568ab3020bdd386e4b2f0a05"],"d572389229127c297dd1fa5ce4758e1cec41e799":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","b21422ff1d1d56499dec481f193b402e5e8def5b"],"962d04139994fce5193143ef35615499a9a96d78":[],"e79a6d080bdd5b2a8f56342cf571b5476de04180":["bb9b72f7c3d7827c64dd4ec580ded81778da361d"],"790e1fde4caa765b3faaad3fbcd25c6973450336":["29ef99d61cda9641b6250bf9567329a6e65f901d","bde51b089eb7f86171eb3406e38a274743f9b7ac","a31c91eda919456f5f9237b086174385292f9935"],"d619839baa8ce5503e496b94a9e42ad6f079293f":["135621f3a0670a9394eb563224a3b76cc4dddc0f"],"a3776dccca01c11e7046323cfad46a3b4a471233":["79c2cb24929f2649a8875fb629086171f914d5ce"],"77cf4379b2824f6ea34b091c495d6e95c38ff9e2":[],"868da859b43505d9d2a023bfeae6dd0c795f5295":["e79a6d080bdd5b2a8f56342cf571b5476de04180"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["79c2cb24929f2649a8875fb629086171f914d5ce","962d04139994fce5193143ef35615499a9a96d78","77cf4379b2824f6ea34b091c495d6e95c38ff9e2","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}