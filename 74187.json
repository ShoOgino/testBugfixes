{"path":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testPropagateBulkScorer().mjava","commits":[{"id":"631e24c389c59f74b6d125a2a4cb909d6fbfa356","date":1445957240,"type":0,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testPropagateBulkScorer().mjava","pathOld":"/dev/null","sourceNew":"  public void testPropagateBulkScorer() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    w.addDocument(new Document());\n    IndexReader reader = w.getReader();\n    w.close();\n    IndexSearcher searcher = newSearcher(reader);\n    LeafReaderContext leaf = searcher.getIndexReader().leaves().get(0);\n    AtomicBoolean scorerCalled = new AtomicBoolean();\n    AtomicBoolean bulkScorerCalled = new AtomicBoolean();\n    LRUQueryCache cache = new LRUQueryCache(1, Long.MAX_VALUE);\n\n    // test that the bulk scorer is propagated when a scorer should not be cached\n    Weight weight = searcher.createNormalizedWeight(new MatchAllDocsQuery(), false);\n    weight = new WeightWrapper(weight, scorerCalled, bulkScorerCalled);\n    weight = cache.doCache(weight, NEVER_CACHE);\n    weight.bulkScorer(leaf);\n    assertEquals(true, bulkScorerCalled.get());\n    assertEquals(false, scorerCalled.get());\n    assertEquals(0, cache.getCacheCount());\n\n    // test that the doc id set is computed using the bulk scorer\n    bulkScorerCalled.set(false);\n    weight = searcher.createNormalizedWeight(new MatchAllDocsQuery(), false);\n    weight = new WeightWrapper(weight, scorerCalled, bulkScorerCalled);\n    weight = cache.doCache(weight, QueryCachingPolicy.ALWAYS_CACHE);\n    weight.scorer(leaf);\n    assertEquals(true, bulkScorerCalled.get());\n    assertEquals(false, scorerCalled.get());\n    assertEquals(1, cache.getCacheCount());\n\n    searcher.getIndexReader().close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"aac61ee5b4492f174e60bd54939aba9539906edf","date":1461245473,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testPropagateBulkScorer().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testPropagateBulkScorer().mjava","sourceNew":"  public void testPropagateBulkScorer() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    w.addDocument(new Document());\n    IndexReader reader = w.getReader();\n    w.close();\n    IndexSearcher searcher = newSearcher(reader);\n    LeafReaderContext leaf = searcher.getIndexReader().leaves().get(0);\n    AtomicBoolean scorerCalled = new AtomicBoolean();\n    AtomicBoolean bulkScorerCalled = new AtomicBoolean();\n    LRUQueryCache cache = new LRUQueryCache(1, Long.MAX_VALUE, context -> true);\n\n    // test that the bulk scorer is propagated when a scorer should not be cached\n    Weight weight = searcher.createNormalizedWeight(new MatchAllDocsQuery(), false);\n    weight = new WeightWrapper(weight, scorerCalled, bulkScorerCalled);\n    weight = cache.doCache(weight, NEVER_CACHE);\n    weight.bulkScorer(leaf);\n    assertEquals(true, bulkScorerCalled.get());\n    assertEquals(false, scorerCalled.get());\n    assertEquals(0, cache.getCacheCount());\n\n    // test that the doc id set is computed using the bulk scorer\n    bulkScorerCalled.set(false);\n    weight = searcher.createNormalizedWeight(new MatchAllDocsQuery(), false);\n    weight = new WeightWrapper(weight, scorerCalled, bulkScorerCalled);\n    weight = cache.doCache(weight, QueryCachingPolicy.ALWAYS_CACHE);\n    weight.scorer(leaf);\n    assertEquals(true, bulkScorerCalled.get());\n    assertEquals(false, scorerCalled.get());\n    assertEquals(1, cache.getCacheCount());\n\n    searcher.getIndexReader().close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testPropagateBulkScorer() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    w.addDocument(new Document());\n    IndexReader reader = w.getReader();\n    w.close();\n    IndexSearcher searcher = newSearcher(reader);\n    LeafReaderContext leaf = searcher.getIndexReader().leaves().get(0);\n    AtomicBoolean scorerCalled = new AtomicBoolean();\n    AtomicBoolean bulkScorerCalled = new AtomicBoolean();\n    LRUQueryCache cache = new LRUQueryCache(1, Long.MAX_VALUE);\n\n    // test that the bulk scorer is propagated when a scorer should not be cached\n    Weight weight = searcher.createNormalizedWeight(new MatchAllDocsQuery(), false);\n    weight = new WeightWrapper(weight, scorerCalled, bulkScorerCalled);\n    weight = cache.doCache(weight, NEVER_CACHE);\n    weight.bulkScorer(leaf);\n    assertEquals(true, bulkScorerCalled.get());\n    assertEquals(false, scorerCalled.get());\n    assertEquals(0, cache.getCacheCount());\n\n    // test that the doc id set is computed using the bulk scorer\n    bulkScorerCalled.set(false);\n    weight = searcher.createNormalizedWeight(new MatchAllDocsQuery(), false);\n    weight = new WeightWrapper(weight, scorerCalled, bulkScorerCalled);\n    weight = cache.doCache(weight, QueryCachingPolicy.ALWAYS_CACHE);\n    weight.scorer(leaf);\n    assertEquals(true, bulkScorerCalled.get());\n    assertEquals(false, scorerCalled.get());\n    assertEquals(1, cache.getCacheCount());\n\n    searcher.getIndexReader().close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c7732a106554be0db3e03ac5211e46f6e0c285b8","date":1511975378,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testPropagateBulkScorer().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testPropagateBulkScorer().mjava","sourceNew":"  public void testPropagateBulkScorer() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    w.addDocument(new Document());\n    IndexReader reader = w.getReader();\n    w.close();\n    IndexSearcher searcher = newSearcher(reader);\n    LeafReaderContext leaf = searcher.getIndexReader().leaves().get(0);\n    AtomicBoolean scorerCalled = new AtomicBoolean();\n    AtomicBoolean bulkScorerCalled = new AtomicBoolean();\n    LRUQueryCache cache = new LRUQueryCache(1, Long.MAX_VALUE, context -> true, Float.POSITIVE_INFINITY);\n\n    // test that the bulk scorer is propagated when a scorer should not be cached\n    Weight weight = searcher.createNormalizedWeight(new MatchAllDocsQuery(), false);\n    weight = new WeightWrapper(weight, scorerCalled, bulkScorerCalled);\n    weight = cache.doCache(weight, NEVER_CACHE);\n    weight.bulkScorer(leaf);\n    assertEquals(true, bulkScorerCalled.get());\n    assertEquals(false, scorerCalled.get());\n    assertEquals(0, cache.getCacheCount());\n\n    searcher.getIndexReader().close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testPropagateBulkScorer() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    w.addDocument(new Document());\n    IndexReader reader = w.getReader();\n    w.close();\n    IndexSearcher searcher = newSearcher(reader);\n    LeafReaderContext leaf = searcher.getIndexReader().leaves().get(0);\n    AtomicBoolean scorerCalled = new AtomicBoolean();\n    AtomicBoolean bulkScorerCalled = new AtomicBoolean();\n    LRUQueryCache cache = new LRUQueryCache(1, Long.MAX_VALUE, context -> true);\n\n    // test that the bulk scorer is propagated when a scorer should not be cached\n    Weight weight = searcher.createNormalizedWeight(new MatchAllDocsQuery(), false);\n    weight = new WeightWrapper(weight, scorerCalled, bulkScorerCalled);\n    weight = cache.doCache(weight, NEVER_CACHE);\n    weight.bulkScorer(leaf);\n    assertEquals(true, bulkScorerCalled.get());\n    assertEquals(false, scorerCalled.get());\n    assertEquals(0, cache.getCacheCount());\n\n    // test that the doc id set is computed using the bulk scorer\n    bulkScorerCalled.set(false);\n    weight = searcher.createNormalizedWeight(new MatchAllDocsQuery(), false);\n    weight = new WeightWrapper(weight, scorerCalled, bulkScorerCalled);\n    weight = cache.doCache(weight, QueryCachingPolicy.ALWAYS_CACHE);\n    weight.scorer(leaf);\n    assertEquals(true, bulkScorerCalled.get());\n    assertEquals(false, scorerCalled.get());\n    assertEquals(1, cache.getCacheCount());\n\n    searcher.getIndexReader().close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1aad05eeff7818b0833c02ac6b743aa72054963b","date":1512093122,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testPropagateBulkScorer().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testPropagateBulkScorer().mjava","sourceNew":"  public void testPropagateBulkScorer() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    w.addDocument(new Document());\n    IndexReader reader = w.getReader();\n    w.close();\n    IndexSearcher searcher = newSearcher(reader);\n    LeafReaderContext leaf = searcher.getIndexReader().leaves().get(0);\n    AtomicBoolean scorerCalled = new AtomicBoolean();\n    AtomicBoolean bulkScorerCalled = new AtomicBoolean();\n    LRUQueryCache cache = new LRUQueryCache(1, Long.MAX_VALUE, context -> true, Float.POSITIVE_INFINITY);\n\n    // test that the bulk scorer is propagated when a scorer should not be cached\n    Weight weight = searcher.createNormalizedWeight(new MatchAllDocsQuery(), false);\n    weight = new WeightWrapper(weight, scorerCalled, bulkScorerCalled);\n    weight = cache.doCache(weight, NEVER_CACHE);\n    weight.bulkScorer(leaf);\n    assertEquals(true, bulkScorerCalled.get());\n    assertEquals(false, scorerCalled.get());\n    assertEquals(0, cache.getCacheCount());\n\n    searcher.getIndexReader().close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testPropagateBulkScorer() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    w.addDocument(new Document());\n    IndexReader reader = w.getReader();\n    w.close();\n    IndexSearcher searcher = newSearcher(reader);\n    LeafReaderContext leaf = searcher.getIndexReader().leaves().get(0);\n    AtomicBoolean scorerCalled = new AtomicBoolean();\n    AtomicBoolean bulkScorerCalled = new AtomicBoolean();\n    LRUQueryCache cache = new LRUQueryCache(1, Long.MAX_VALUE, context -> true);\n\n    // test that the bulk scorer is propagated when a scorer should not be cached\n    Weight weight = searcher.createNormalizedWeight(new MatchAllDocsQuery(), false);\n    weight = new WeightWrapper(weight, scorerCalled, bulkScorerCalled);\n    weight = cache.doCache(weight, NEVER_CACHE);\n    weight.bulkScorer(leaf);\n    assertEquals(true, bulkScorerCalled.get());\n    assertEquals(false, scorerCalled.get());\n    assertEquals(0, cache.getCacheCount());\n\n    // test that the doc id set is computed using the bulk scorer\n    bulkScorerCalled.set(false);\n    weight = searcher.createNormalizedWeight(new MatchAllDocsQuery(), false);\n    weight = new WeightWrapper(weight, scorerCalled, bulkScorerCalled);\n    weight = cache.doCache(weight, QueryCachingPolicy.ALWAYS_CACHE);\n    weight.scorer(leaf);\n    assertEquals(true, bulkScorerCalled.get());\n    assertEquals(false, scorerCalled.get());\n    assertEquals(1, cache.getCacheCount());\n\n    searcher.getIndexReader().close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9fc47cb7b4346802411bb432f501ed0673d7119e","date":1512640179,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testPropagateBulkScorer().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testPropagateBulkScorer().mjava","sourceNew":"  public void testPropagateBulkScorer() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    w.addDocument(new Document());\n    IndexReader reader = w.getReader();\n    w.close();\n    IndexSearcher searcher = newSearcher(reader);\n    LeafReaderContext leaf = searcher.getIndexReader().leaves().get(0);\n    AtomicBoolean scorerCalled = new AtomicBoolean();\n    AtomicBoolean bulkScorerCalled = new AtomicBoolean();\n    LRUQueryCache cache = new LRUQueryCache(1, Long.MAX_VALUE, context -> true, Float.POSITIVE_INFINITY);\n\n    // test that the bulk scorer is propagated when a scorer should not be cached\n    Weight weight = searcher.createNormalizedWeight(new MatchAllDocsQuery(), ScoreMode.COMPLETE_NO_SCORES);\n    weight = new WeightWrapper(weight, scorerCalled, bulkScorerCalled);\n    weight = cache.doCache(weight, NEVER_CACHE);\n    weight.bulkScorer(leaf);\n    assertEquals(true, bulkScorerCalled.get());\n    assertEquals(false, scorerCalled.get());\n    assertEquals(0, cache.getCacheCount());\n\n    searcher.getIndexReader().close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testPropagateBulkScorer() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    w.addDocument(new Document());\n    IndexReader reader = w.getReader();\n    w.close();\n    IndexSearcher searcher = newSearcher(reader);\n    LeafReaderContext leaf = searcher.getIndexReader().leaves().get(0);\n    AtomicBoolean scorerCalled = new AtomicBoolean();\n    AtomicBoolean bulkScorerCalled = new AtomicBoolean();\n    LRUQueryCache cache = new LRUQueryCache(1, Long.MAX_VALUE, context -> true, Float.POSITIVE_INFINITY);\n\n    // test that the bulk scorer is propagated when a scorer should not be cached\n    Weight weight = searcher.createNormalizedWeight(new MatchAllDocsQuery(), false);\n    weight = new WeightWrapper(weight, scorerCalled, bulkScorerCalled);\n    weight = cache.doCache(weight, NEVER_CACHE);\n    weight.bulkScorer(leaf);\n    assertEquals(true, bulkScorerCalled.get());\n    assertEquals(false, scorerCalled.get());\n    assertEquals(0, cache.getCacheCount());\n\n    searcher.getIndexReader().close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"417142ff08fda9cf0b72d5133e63097a166c6458","date":1512729693,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testPropagateBulkScorer().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testPropagateBulkScorer().mjava","sourceNew":"  public void testPropagateBulkScorer() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    w.addDocument(new Document());\n    IndexReader reader = w.getReader();\n    w.close();\n    IndexSearcher searcher = newSearcher(reader);\n    LeafReaderContext leaf = searcher.getIndexReader().leaves().get(0);\n    AtomicBoolean scorerCalled = new AtomicBoolean();\n    AtomicBoolean bulkScorerCalled = new AtomicBoolean();\n    LRUQueryCache cache = new LRUQueryCache(1, Long.MAX_VALUE, context -> true, Float.POSITIVE_INFINITY);\n\n    // test that the bulk scorer is propagated when a scorer should not be cached\n    Weight weight = searcher.createNormalizedWeight(new MatchAllDocsQuery(), ScoreMode.COMPLETE_NO_SCORES);\n    weight = new WeightWrapper(weight, scorerCalled, bulkScorerCalled);\n    weight = cache.doCache(weight, NEVER_CACHE);\n    weight.bulkScorer(leaf);\n    assertEquals(true, bulkScorerCalled.get());\n    assertEquals(false, scorerCalled.get());\n    assertEquals(0, cache.getCacheCount());\n\n    searcher.getIndexReader().close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testPropagateBulkScorer() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    w.addDocument(new Document());\n    IndexReader reader = w.getReader();\n    w.close();\n    IndexSearcher searcher = newSearcher(reader);\n    LeafReaderContext leaf = searcher.getIndexReader().leaves().get(0);\n    AtomicBoolean scorerCalled = new AtomicBoolean();\n    AtomicBoolean bulkScorerCalled = new AtomicBoolean();\n    LRUQueryCache cache = new LRUQueryCache(1, Long.MAX_VALUE, context -> true, Float.POSITIVE_INFINITY);\n\n    // test that the bulk scorer is propagated when a scorer should not be cached\n    Weight weight = searcher.createNormalizedWeight(new MatchAllDocsQuery(), false);\n    weight = new WeightWrapper(weight, scorerCalled, bulkScorerCalled);\n    weight = cache.doCache(weight, NEVER_CACHE);\n    weight.bulkScorer(leaf);\n    assertEquals(true, bulkScorerCalled.get());\n    assertEquals(false, scorerCalled.get());\n    assertEquals(0, cache.getCacheCount());\n\n    searcher.getIndexReader().close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"789fb338d3c53b4478938723d60f6623e764ca38","date":1521535944,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testPropagateBulkScorer().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testPropagateBulkScorer().mjava","sourceNew":"  public void testPropagateBulkScorer() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    w.addDocument(new Document());\n    IndexReader reader = w.getReader();\n    w.close();\n    IndexSearcher searcher = newSearcher(reader);\n    LeafReaderContext leaf = searcher.getIndexReader().leaves().get(0);\n    AtomicBoolean scorerCalled = new AtomicBoolean();\n    AtomicBoolean bulkScorerCalled = new AtomicBoolean();\n    LRUQueryCache cache = new LRUQueryCache(1, Long.MAX_VALUE, context -> true);\n\n    // test that the bulk scorer is propagated when a scorer should not be cached\n    Weight weight = searcher.createNormalizedWeight(new MatchAllDocsQuery(), ScoreMode.COMPLETE_NO_SCORES);\n    weight = new WeightWrapper(weight, scorerCalled, bulkScorerCalled);\n    weight = cache.doCache(weight, NEVER_CACHE);\n    weight.bulkScorer(leaf);\n    assertEquals(true, bulkScorerCalled.get());\n    assertEquals(false, scorerCalled.get());\n    assertEquals(0, cache.getCacheCount());\n\n    // test that the doc id set is computed using the bulk scorer\n    bulkScorerCalled.set(false);\n    weight = searcher.createNormalizedWeight(new MatchAllDocsQuery(), ScoreMode.COMPLETE_NO_SCORES);\n    weight = new WeightWrapper(weight, scorerCalled, bulkScorerCalled);\n    weight = cache.doCache(weight, QueryCachingPolicy.ALWAYS_CACHE);\n    weight.scorer(leaf);\n    assertEquals(true, bulkScorerCalled.get());\n    assertEquals(false, scorerCalled.get());\n    assertEquals(1, cache.getCacheCount());\n\n    searcher.getIndexReader().close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testPropagateBulkScorer() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    w.addDocument(new Document());\n    IndexReader reader = w.getReader();\n    w.close();\n    IndexSearcher searcher = newSearcher(reader);\n    LeafReaderContext leaf = searcher.getIndexReader().leaves().get(0);\n    AtomicBoolean scorerCalled = new AtomicBoolean();\n    AtomicBoolean bulkScorerCalled = new AtomicBoolean();\n    LRUQueryCache cache = new LRUQueryCache(1, Long.MAX_VALUE, context -> true, Float.POSITIVE_INFINITY);\n\n    // test that the bulk scorer is propagated when a scorer should not be cached\n    Weight weight = searcher.createNormalizedWeight(new MatchAllDocsQuery(), ScoreMode.COMPLETE_NO_SCORES);\n    weight = new WeightWrapper(weight, scorerCalled, bulkScorerCalled);\n    weight = cache.doCache(weight, NEVER_CACHE);\n    weight.bulkScorer(leaf);\n    assertEquals(true, bulkScorerCalled.get());\n    assertEquals(false, scorerCalled.get());\n    assertEquals(0, cache.getCacheCount());\n\n    searcher.getIndexReader().close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6815b5b5d6334b2245dd7be2f8b6cca949bf7f43","date":1521731438,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testPropagateBulkScorer().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testPropagateBulkScorer().mjava","sourceNew":"  public void testPropagateBulkScorer() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    w.addDocument(new Document());\n    IndexReader reader = w.getReader();\n    w.close();\n    IndexSearcher searcher = newSearcher(reader);\n    LeafReaderContext leaf = searcher.getIndexReader().leaves().get(0);\n    AtomicBoolean scorerCalled = new AtomicBoolean();\n    AtomicBoolean bulkScorerCalled = new AtomicBoolean();\n    LRUQueryCache cache = new LRUQueryCache(1, Long.MAX_VALUE, context -> true);\n\n    // test that the bulk scorer is propagated when a scorer should not be cached\n    Weight weight = searcher.createNormalizedWeight(new MatchAllDocsQuery(), ScoreMode.COMPLETE_NO_SCORES);\n    weight = new WeightWrapper(weight, scorerCalled, bulkScorerCalled);\n    weight = cache.doCache(weight, NEVER_CACHE);\n    weight.bulkScorer(leaf);\n    assertEquals(true, bulkScorerCalled.get());\n    assertEquals(false, scorerCalled.get());\n    assertEquals(0, cache.getCacheCount());\n\n    // test that the doc id set is computed using the bulk scorer\n    bulkScorerCalled.set(false);\n    weight = searcher.createNormalizedWeight(new MatchAllDocsQuery(), ScoreMode.COMPLETE_NO_SCORES);\n    weight = new WeightWrapper(weight, scorerCalled, bulkScorerCalled);\n    weight = cache.doCache(weight, QueryCachingPolicy.ALWAYS_CACHE);\n    weight.scorer(leaf);\n    assertEquals(true, bulkScorerCalled.get());\n    assertEquals(false, scorerCalled.get());\n    assertEquals(1, cache.getCacheCount());\n\n    searcher.getIndexReader().close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testPropagateBulkScorer() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    w.addDocument(new Document());\n    IndexReader reader = w.getReader();\n    w.close();\n    IndexSearcher searcher = newSearcher(reader);\n    LeafReaderContext leaf = searcher.getIndexReader().leaves().get(0);\n    AtomicBoolean scorerCalled = new AtomicBoolean();\n    AtomicBoolean bulkScorerCalled = new AtomicBoolean();\n    LRUQueryCache cache = new LRUQueryCache(1, Long.MAX_VALUE, context -> true, Float.POSITIVE_INFINITY);\n\n    // test that the bulk scorer is propagated when a scorer should not be cached\n    Weight weight = searcher.createNormalizedWeight(new MatchAllDocsQuery(), ScoreMode.COMPLETE_NO_SCORES);\n    weight = new WeightWrapper(weight, scorerCalled, bulkScorerCalled);\n    weight = cache.doCache(weight, NEVER_CACHE);\n    weight.bulkScorer(leaf);\n    assertEquals(true, bulkScorerCalled.get());\n    assertEquals(false, scorerCalled.get());\n    assertEquals(0, cache.getCacheCount());\n\n    searcher.getIndexReader().close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"475584d5e08a22ad3fc7babefe006d77bc744567","date":1523282824,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testPropagateBulkScorer().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testPropagateBulkScorer().mjava","sourceNew":"  public void testPropagateBulkScorer() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    w.addDocument(new Document());\n    IndexReader reader = w.getReader();\n    w.close();\n    IndexSearcher searcher = newSearcher(reader);\n    LeafReaderContext leaf = searcher.getIndexReader().leaves().get(0);\n    AtomicBoolean scorerCalled = new AtomicBoolean();\n    AtomicBoolean bulkScorerCalled = new AtomicBoolean();\n    LRUQueryCache cache = new LRUQueryCache(1, Long.MAX_VALUE, context -> true);\n\n    // test that the bulk scorer is propagated when a scorer should not be cached\n    Weight weight = searcher.createWeight(new MatchAllDocsQuery(), ScoreMode.COMPLETE_NO_SCORES, 1);\n    weight = new WeightWrapper(weight, scorerCalled, bulkScorerCalled);\n    weight = cache.doCache(weight, NEVER_CACHE);\n    weight.bulkScorer(leaf);\n    assertEquals(true, bulkScorerCalled.get());\n    assertEquals(false, scorerCalled.get());\n    assertEquals(0, cache.getCacheCount());\n\n    // test that the doc id set is computed using the bulk scorer\n    bulkScorerCalled.set(false);\n    weight = searcher.createWeight(new MatchAllDocsQuery(), ScoreMode.COMPLETE_NO_SCORES, 1);\n    weight = new WeightWrapper(weight, scorerCalled, bulkScorerCalled);\n    weight = cache.doCache(weight, QueryCachingPolicy.ALWAYS_CACHE);\n    weight.scorer(leaf);\n    assertEquals(true, bulkScorerCalled.get());\n    assertEquals(false, scorerCalled.get());\n    assertEquals(1, cache.getCacheCount());\n\n    searcher.getIndexReader().close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testPropagateBulkScorer() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    w.addDocument(new Document());\n    IndexReader reader = w.getReader();\n    w.close();\n    IndexSearcher searcher = newSearcher(reader);\n    LeafReaderContext leaf = searcher.getIndexReader().leaves().get(0);\n    AtomicBoolean scorerCalled = new AtomicBoolean();\n    AtomicBoolean bulkScorerCalled = new AtomicBoolean();\n    LRUQueryCache cache = new LRUQueryCache(1, Long.MAX_VALUE, context -> true);\n\n    // test that the bulk scorer is propagated when a scorer should not be cached\n    Weight weight = searcher.createNormalizedWeight(new MatchAllDocsQuery(), ScoreMode.COMPLETE_NO_SCORES);\n    weight = new WeightWrapper(weight, scorerCalled, bulkScorerCalled);\n    weight = cache.doCache(weight, NEVER_CACHE);\n    weight.bulkScorer(leaf);\n    assertEquals(true, bulkScorerCalled.get());\n    assertEquals(false, scorerCalled.get());\n    assertEquals(0, cache.getCacheCount());\n\n    // test that the doc id set is computed using the bulk scorer\n    bulkScorerCalled.set(false);\n    weight = searcher.createNormalizedWeight(new MatchAllDocsQuery(), ScoreMode.COMPLETE_NO_SCORES);\n    weight = new WeightWrapper(weight, scorerCalled, bulkScorerCalled);\n    weight = cache.doCache(weight, QueryCachingPolicy.ALWAYS_CACHE);\n    weight.scorer(leaf);\n    assertEquals(true, bulkScorerCalled.get());\n    assertEquals(false, scorerCalled.get());\n    assertEquals(1, cache.getCacheCount());\n\n    searcher.getIndexReader().close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d58e44159788900f4a2113b84463dc3fbbf80f20","date":1523319203,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testPropagateBulkScorer().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testPropagateBulkScorer().mjava","sourceNew":"  public void testPropagateBulkScorer() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    w.addDocument(new Document());\n    IndexReader reader = w.getReader();\n    w.close();\n    IndexSearcher searcher = newSearcher(reader);\n    LeafReaderContext leaf = searcher.getIndexReader().leaves().get(0);\n    AtomicBoolean scorerCalled = new AtomicBoolean();\n    AtomicBoolean bulkScorerCalled = new AtomicBoolean();\n    LRUQueryCache cache = new LRUQueryCache(1, Long.MAX_VALUE, context -> true);\n\n    // test that the bulk scorer is propagated when a scorer should not be cached\n    Weight weight = searcher.createWeight(new MatchAllDocsQuery(), ScoreMode.COMPLETE_NO_SCORES, 1);\n    weight = new WeightWrapper(weight, scorerCalled, bulkScorerCalled);\n    weight = cache.doCache(weight, NEVER_CACHE);\n    weight.bulkScorer(leaf);\n    assertEquals(true, bulkScorerCalled.get());\n    assertEquals(false, scorerCalled.get());\n    assertEquals(0, cache.getCacheCount());\n\n    // test that the doc id set is computed using the bulk scorer\n    bulkScorerCalled.set(false);\n    weight = searcher.createWeight(new MatchAllDocsQuery(), ScoreMode.COMPLETE_NO_SCORES, 1);\n    weight = new WeightWrapper(weight, scorerCalled, bulkScorerCalled);\n    weight = cache.doCache(weight, QueryCachingPolicy.ALWAYS_CACHE);\n    weight.scorer(leaf);\n    assertEquals(true, bulkScorerCalled.get());\n    assertEquals(false, scorerCalled.get());\n    assertEquals(1, cache.getCacheCount());\n\n    searcher.getIndexReader().close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testPropagateBulkScorer() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    w.addDocument(new Document());\n    IndexReader reader = w.getReader();\n    w.close();\n    IndexSearcher searcher = newSearcher(reader);\n    LeafReaderContext leaf = searcher.getIndexReader().leaves().get(0);\n    AtomicBoolean scorerCalled = new AtomicBoolean();\n    AtomicBoolean bulkScorerCalled = new AtomicBoolean();\n    LRUQueryCache cache = new LRUQueryCache(1, Long.MAX_VALUE, context -> true);\n\n    // test that the bulk scorer is propagated when a scorer should not be cached\n    Weight weight = searcher.createNormalizedWeight(new MatchAllDocsQuery(), ScoreMode.COMPLETE_NO_SCORES);\n    weight = new WeightWrapper(weight, scorerCalled, bulkScorerCalled);\n    weight = cache.doCache(weight, NEVER_CACHE);\n    weight.bulkScorer(leaf);\n    assertEquals(true, bulkScorerCalled.get());\n    assertEquals(false, scorerCalled.get());\n    assertEquals(0, cache.getCacheCount());\n\n    // test that the doc id set is computed using the bulk scorer\n    bulkScorerCalled.set(false);\n    weight = searcher.createNormalizedWeight(new MatchAllDocsQuery(), ScoreMode.COMPLETE_NO_SCORES);\n    weight = new WeightWrapper(weight, scorerCalled, bulkScorerCalled);\n    weight = cache.doCache(weight, QueryCachingPolicy.ALWAYS_CACHE);\n    weight.scorer(leaf);\n    assertEquals(true, bulkScorerCalled.get());\n    assertEquals(false, scorerCalled.get());\n    assertEquals(1, cache.getCacheCount());\n\n    searcher.getIndexReader().close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6c9d00c591703058371b3dc36f4957a6f24ca302","date":1527233410,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testPropagateBulkScorer().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testPropagateBulkScorer().mjava","sourceNew":"  public void testPropagateBulkScorer() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    w.addDocument(new Document());\n    IndexReader reader = w.getReader();\n    w.close();\n    IndexSearcher searcher = newSearcher(reader);\n    LeafReaderContext leaf = searcher.getIndexReader().leaves().get(0);\n    AtomicBoolean scorerCalled = new AtomicBoolean();\n    AtomicBoolean bulkScorerCalled = new AtomicBoolean();\n    LRUQueryCache cache = new LRUQueryCache(1, Long.MAX_VALUE, context -> true);\n\n    // test that the bulk scorer is propagated when a scorer should not be cached\n    Weight weight = searcher.createWeight(new MatchAllDocsQuery(), ScoreMode.COMPLETE_NO_SCORES, 1);\n    weight = new WeightWrapper(weight, scorerCalled, bulkScorerCalled);\n    weight = cache.doCache(weight, NEVER_CACHE);\n    weight.bulkScorer(leaf);\n    assertEquals(true, bulkScorerCalled.get());\n    assertEquals(false, scorerCalled.get());\n    assertEquals(0, cache.getCacheCount());\n\n    // test that the doc id set is computed using the bulk scorer\n    bulkScorerCalled.set(false);\n    weight = searcher.createWeight(new MatchAllDocsQuery(), ScoreMode.COMPLETE_NO_SCORES, 1);\n    weight = new WeightWrapper(weight, scorerCalled, bulkScorerCalled);\n    weight = cache.doCache(weight, ALWAYS_CACHE);\n    weight.scorer(leaf);\n    assertEquals(true, bulkScorerCalled.get());\n    assertEquals(false, scorerCalled.get());\n    assertEquals(1, cache.getCacheCount());\n\n    searcher.getIndexReader().close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testPropagateBulkScorer() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    w.addDocument(new Document());\n    IndexReader reader = w.getReader();\n    w.close();\n    IndexSearcher searcher = newSearcher(reader);\n    LeafReaderContext leaf = searcher.getIndexReader().leaves().get(0);\n    AtomicBoolean scorerCalled = new AtomicBoolean();\n    AtomicBoolean bulkScorerCalled = new AtomicBoolean();\n    LRUQueryCache cache = new LRUQueryCache(1, Long.MAX_VALUE, context -> true);\n\n    // test that the bulk scorer is propagated when a scorer should not be cached\n    Weight weight = searcher.createWeight(new MatchAllDocsQuery(), ScoreMode.COMPLETE_NO_SCORES, 1);\n    weight = new WeightWrapper(weight, scorerCalled, bulkScorerCalled);\n    weight = cache.doCache(weight, NEVER_CACHE);\n    weight.bulkScorer(leaf);\n    assertEquals(true, bulkScorerCalled.get());\n    assertEquals(false, scorerCalled.get());\n    assertEquals(0, cache.getCacheCount());\n\n    // test that the doc id set is computed using the bulk scorer\n    bulkScorerCalled.set(false);\n    weight = searcher.createWeight(new MatchAllDocsQuery(), ScoreMode.COMPLETE_NO_SCORES, 1);\n    weight = new WeightWrapper(weight, scorerCalled, bulkScorerCalled);\n    weight = cache.doCache(weight, QueryCachingPolicy.ALWAYS_CACHE);\n    weight.scorer(leaf);\n    assertEquals(true, bulkScorerCalled.get());\n    assertEquals(false, scorerCalled.get());\n    assertEquals(1, cache.getCacheCount());\n\n    searcher.getIndexReader().close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b5754bd6f04f13b67e9575f8b226a0303c31c7d5","date":1573506453,"type":3,"author":"ginger","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testPropagateBulkScorer().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testPropagateBulkScorer().mjava","sourceNew":"  public void testPropagateBulkScorer() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    w.addDocument(new Document());\n    IndexReader reader = w.getReader();\n    w.close();\n    IndexSearcher searcher = newSearcher(reader);\n    LeafReaderContext leaf = searcher.getIndexReader().leaves().get(0);\n    AtomicBoolean scorerCalled = new AtomicBoolean();\n    AtomicBoolean bulkScorerCalled = new AtomicBoolean();\n    LRUQueryCache cache = new LRUQueryCache(1, Long.MAX_VALUE, context -> true, Float.POSITIVE_INFINITY);\n\n    // test that the bulk scorer is propagated when a scorer should not be cached\n    Weight weight = searcher.createWeight(new MatchAllDocsQuery(), ScoreMode.COMPLETE_NO_SCORES, 1);\n    weight = new WeightWrapper(weight, scorerCalled, bulkScorerCalled);\n    weight = cache.doCache(weight, NEVER_CACHE);\n    weight.bulkScorer(leaf);\n    assertEquals(true, bulkScorerCalled.get());\n    assertEquals(false, scorerCalled.get());\n    assertEquals(0, cache.getCacheCount());\n\n    searcher.getIndexReader().close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testPropagateBulkScorer() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    w.addDocument(new Document());\n    IndexReader reader = w.getReader();\n    w.close();\n    IndexSearcher searcher = newSearcher(reader);\n    LeafReaderContext leaf = searcher.getIndexReader().leaves().get(0);\n    AtomicBoolean scorerCalled = new AtomicBoolean();\n    AtomicBoolean bulkScorerCalled = new AtomicBoolean();\n    LRUQueryCache cache = new LRUQueryCache(1, Long.MAX_VALUE, context -> true);\n\n    // test that the bulk scorer is propagated when a scorer should not be cached\n    Weight weight = searcher.createWeight(new MatchAllDocsQuery(), ScoreMode.COMPLETE_NO_SCORES, 1);\n    weight = new WeightWrapper(weight, scorerCalled, bulkScorerCalled);\n    weight = cache.doCache(weight, NEVER_CACHE);\n    weight.bulkScorer(leaf);\n    assertEquals(true, bulkScorerCalled.get());\n    assertEquals(false, scorerCalled.get());\n    assertEquals(0, cache.getCacheCount());\n\n    // test that the doc id set is computed using the bulk scorer\n    bulkScorerCalled.set(false);\n    weight = searcher.createWeight(new MatchAllDocsQuery(), ScoreMode.COMPLETE_NO_SCORES, 1);\n    weight = new WeightWrapper(weight, scorerCalled, bulkScorerCalled);\n    weight = cache.doCache(weight, ALWAYS_CACHE);\n    weight.scorer(leaf);\n    assertEquals(true, bulkScorerCalled.get());\n    assertEquals(false, scorerCalled.get());\n    assertEquals(1, cache.getCacheCount());\n\n    searcher.getIndexReader().close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1fbdd90cd58912788fecb1044df8f566a4420e59","date":1574749923,"type":3,"author":"Atri Sharma","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testPropagateBulkScorer().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testPropagateBulkScorer().mjava","sourceNew":"  public void testPropagateBulkScorer() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    w.addDocument(new Document());\n    IndexReader reader = w.getReader();\n    w.close();\n    IndexSearcher searcher = newSearcher(reader);\n    LeafReaderContext leaf = searcher.getIndexReader().leaves().get(0);\n    AtomicBoolean scorerCalled = new AtomicBoolean();\n    AtomicBoolean bulkScorerCalled = new AtomicBoolean();\n    LRUQueryCache cache = new LRUQueryCache(1, Long.MAX_VALUE, context -> true, Float.POSITIVE_INFINITY);\n\n    // test that the bulk scorer is propagated when a scorer should not be cached\n    Weight weight = searcher.createWeight(new MatchAllDocsQuery(), ScoreMode.COMPLETE_NO_SCORES, 1);\n    weight = new WeightWrapper(weight, scorerCalled, bulkScorerCalled);\n    weight = cache.doCache(weight, NEVER_CACHE, null /* executor */);\n    weight.bulkScorer(leaf);\n    assertEquals(true, bulkScorerCalled.get());\n    assertEquals(false, scorerCalled.get());\n    assertEquals(0, cache.getCacheCount());\n\n    searcher.getIndexReader().close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testPropagateBulkScorer() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    w.addDocument(new Document());\n    IndexReader reader = w.getReader();\n    w.close();\n    IndexSearcher searcher = newSearcher(reader);\n    LeafReaderContext leaf = searcher.getIndexReader().leaves().get(0);\n    AtomicBoolean scorerCalled = new AtomicBoolean();\n    AtomicBoolean bulkScorerCalled = new AtomicBoolean();\n    LRUQueryCache cache = new LRUQueryCache(1, Long.MAX_VALUE, context -> true, Float.POSITIVE_INFINITY);\n\n    // test that the bulk scorer is propagated when a scorer should not be cached\n    Weight weight = searcher.createWeight(new MatchAllDocsQuery(), ScoreMode.COMPLETE_NO_SCORES, 1);\n    weight = new WeightWrapper(weight, scorerCalled, bulkScorerCalled);\n    weight = cache.doCache(weight, NEVER_CACHE);\n    weight.bulkScorer(leaf);\n    assertEquals(true, bulkScorerCalled.get());\n    assertEquals(false, scorerCalled.get());\n    assertEquals(0, cache.getCacheCount());\n\n    searcher.getIndexReader().close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9bbc355b3e849ee4a34763155bb78e638d625419","date":1574952532,"type":3,"author":"Atri Sharma","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testPropagateBulkScorer().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testPropagateBulkScorer().mjava","sourceNew":"  public void testPropagateBulkScorer() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    w.addDocument(new Document());\n    IndexReader reader = w.getReader();\n    w.close();\n    IndexSearcher searcher = newSearcher(reader);\n    LeafReaderContext leaf = searcher.getIndexReader().leaves().get(0);\n    AtomicBoolean scorerCalled = new AtomicBoolean();\n    AtomicBoolean bulkScorerCalled = new AtomicBoolean();\n    LRUQueryCache cache = new LRUQueryCache(1, Long.MAX_VALUE, context -> true, Float.POSITIVE_INFINITY);\n\n    // test that the bulk scorer is propagated when a scorer should not be cached\n    Weight weight = searcher.createWeight(new MatchAllDocsQuery(), ScoreMode.COMPLETE_NO_SCORES, 1);\n    weight = new WeightWrapper(weight, scorerCalled, bulkScorerCalled);\n    weight = cache.doCache(weight, NEVER_CACHE);\n    weight.bulkScorer(leaf);\n    assertEquals(true, bulkScorerCalled.get());\n    assertEquals(false, scorerCalled.get());\n    assertEquals(0, cache.getCacheCount());\n\n    searcher.getIndexReader().close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testPropagateBulkScorer() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    w.addDocument(new Document());\n    IndexReader reader = w.getReader();\n    w.close();\n    IndexSearcher searcher = newSearcher(reader);\n    LeafReaderContext leaf = searcher.getIndexReader().leaves().get(0);\n    AtomicBoolean scorerCalled = new AtomicBoolean();\n    AtomicBoolean bulkScorerCalled = new AtomicBoolean();\n    LRUQueryCache cache = new LRUQueryCache(1, Long.MAX_VALUE, context -> true, Float.POSITIVE_INFINITY);\n\n    // test that the bulk scorer is propagated when a scorer should not be cached\n    Weight weight = searcher.createWeight(new MatchAllDocsQuery(), ScoreMode.COMPLETE_NO_SCORES, 1);\n    weight = new WeightWrapper(weight, scorerCalled, bulkScorerCalled);\n    weight = cache.doCache(weight, NEVER_CACHE, null /* executor */);\n    weight.bulkScorer(leaf);\n    assertEquals(true, bulkScorerCalled.get());\n    assertEquals(false, scorerCalled.get());\n    assertEquals(0, cache.getCacheCount());\n\n    searcher.getIndexReader().close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"6815b5b5d6334b2245dd7be2f8b6cca949bf7f43":["417142ff08fda9cf0b72d5133e63097a166c6458","789fb338d3c53b4478938723d60f6623e764ca38"],"475584d5e08a22ad3fc7babefe006d77bc744567":["6815b5b5d6334b2245dd7be2f8b6cca949bf7f43"],"aac61ee5b4492f174e60bd54939aba9539906edf":["631e24c389c59f74b6d125a2a4cb909d6fbfa356"],"6c9d00c591703058371b3dc36f4957a6f24ca302":["d58e44159788900f4a2113b84463dc3fbbf80f20"],"b5754bd6f04f13b67e9575f8b226a0303c31c7d5":["6c9d00c591703058371b3dc36f4957a6f24ca302"],"417142ff08fda9cf0b72d5133e63097a166c6458":["1aad05eeff7818b0833c02ac6b743aa72054963b","9fc47cb7b4346802411bb432f501ed0673d7119e"],"1fbdd90cd58912788fecb1044df8f566a4420e59":["b5754bd6f04f13b67e9575f8b226a0303c31c7d5"],"c7732a106554be0db3e03ac5211e46f6e0c285b8":["aac61ee5b4492f174e60bd54939aba9539906edf"],"1aad05eeff7818b0833c02ac6b743aa72054963b":["aac61ee5b4492f174e60bd54939aba9539906edf","c7732a106554be0db3e03ac5211e46f6e0c285b8"],"d58e44159788900f4a2113b84463dc3fbbf80f20":["6815b5b5d6334b2245dd7be2f8b6cca949bf7f43","475584d5e08a22ad3fc7babefe006d77bc744567"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"789fb338d3c53b4478938723d60f6623e764ca38":["417142ff08fda9cf0b72d5133e63097a166c6458"],"9bbc355b3e849ee4a34763155bb78e638d625419":["1fbdd90cd58912788fecb1044df8f566a4420e59"],"631e24c389c59f74b6d125a2a4cb909d6fbfa356":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"9fc47cb7b4346802411bb432f501ed0673d7119e":["1aad05eeff7818b0833c02ac6b743aa72054963b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9bbc355b3e849ee4a34763155bb78e638d625419"]},"commit2Childs":{"6815b5b5d6334b2245dd7be2f8b6cca949bf7f43":["475584d5e08a22ad3fc7babefe006d77bc744567","d58e44159788900f4a2113b84463dc3fbbf80f20"],"475584d5e08a22ad3fc7babefe006d77bc744567":["d58e44159788900f4a2113b84463dc3fbbf80f20"],"aac61ee5b4492f174e60bd54939aba9539906edf":["c7732a106554be0db3e03ac5211e46f6e0c285b8","1aad05eeff7818b0833c02ac6b743aa72054963b"],"6c9d00c591703058371b3dc36f4957a6f24ca302":["b5754bd6f04f13b67e9575f8b226a0303c31c7d5"],"b5754bd6f04f13b67e9575f8b226a0303c31c7d5":["1fbdd90cd58912788fecb1044df8f566a4420e59"],"417142ff08fda9cf0b72d5133e63097a166c6458":["6815b5b5d6334b2245dd7be2f8b6cca949bf7f43","789fb338d3c53b4478938723d60f6623e764ca38"],"1fbdd90cd58912788fecb1044df8f566a4420e59":["9bbc355b3e849ee4a34763155bb78e638d625419"],"c7732a106554be0db3e03ac5211e46f6e0c285b8":["1aad05eeff7818b0833c02ac6b743aa72054963b"],"d58e44159788900f4a2113b84463dc3fbbf80f20":["6c9d00c591703058371b3dc36f4957a6f24ca302"],"1aad05eeff7818b0833c02ac6b743aa72054963b":["417142ff08fda9cf0b72d5133e63097a166c6458","9fc47cb7b4346802411bb432f501ed0673d7119e"],"789fb338d3c53b4478938723d60f6623e764ca38":["6815b5b5d6334b2245dd7be2f8b6cca949bf7f43"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["631e24c389c59f74b6d125a2a4cb909d6fbfa356"],"631e24c389c59f74b6d125a2a4cb909d6fbfa356":["aac61ee5b4492f174e60bd54939aba9539906edf"],"9bbc355b3e849ee4a34763155bb78e638d625419":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"9fc47cb7b4346802411bb432f501ed0673d7119e":["417142ff08fda9cf0b72d5133e63097a166c6458"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}