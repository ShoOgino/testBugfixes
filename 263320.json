{"path":"lucene/core/src/java/org/apache/lucene/codecs/lucene70/Lucene70DocValuesConsumer#addTermsDict(SortedSetDocValues).mjava","commits":[{"id":"23e44daeaa8b89694d10df5999956c8e14a7dd09","date":1476689300,"type":0,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene70/Lucene70DocValuesConsumer#addTermsDict(SortedSetDocValues).mjava","pathOld":"/dev/null","sourceNew":"  private void addTermsDict(SortedSetDocValues values) throws IOException {\n    final long size = values.getValueCount();\n    meta.writeVLong(size);\n    meta.writeInt(Lucene70DocValuesFormat.TERMS_DICT_BLOCK_SHIFT);\n\n    RAMOutputStream addressBuffer = new RAMOutputStream();\n    meta.writeInt(DIRECT_MONOTONIC_BLOCK_SHIFT);\n    long numBlocks = (size + Lucene70DocValuesFormat.TERMS_DICT_BLOCK_MASK) >>> Lucene70DocValuesFormat.TERMS_DICT_BLOCK_SHIFT;\n    DirectMonotonicWriter writer = DirectMonotonicWriter.getInstance(meta, addressBuffer, numBlocks, DIRECT_MONOTONIC_BLOCK_SHIFT);\n\n    BytesRefBuilder previous = new BytesRefBuilder();\n    long ord = 0;\n    long start = data.getFilePointer();\n    int maxLength = 0;\n    TermsEnum iterator = values.termsEnum();\n    for (BytesRef term = iterator.next(); term != null; term = iterator.next()) {\n      if ((ord & Lucene70DocValuesFormat.TERMS_DICT_BLOCK_MASK) == 0) {\n        writer.add(data.getFilePointer() - start);\n        data.writeVInt(term.length);\n        data.writeBytes(term.bytes, term.offset, term.length);\n      } else {\n        final int prefixLength = StringHelper.bytesDifference(previous.get(), term);\n        final int suffixLength = term.length - prefixLength;\n        assert suffixLength > 0; // terms are unique\n\n        data.writeByte((byte) (Math.min(prefixLength, 15) | (Math.min(15, suffixLength - 1) << 4)));\n        if (prefixLength >= 15) {\n          data.writeVInt(prefixLength - 15);\n        }\n        if (suffixLength >= 16) {\n          data.writeVInt(suffixLength - 16);\n        }\n        data.writeBytes(term.bytes, term.offset + prefixLength, term.length - prefixLength);\n      }\n      maxLength = Math.max(maxLength, term.length);\n      previous.copyBytes(term);\n      ++ord;\n    }\n    writer.finish();\n    meta.writeInt(maxLength);\n    meta.writeLong(start);\n    meta.writeLong(data.getFilePointer() - start);\n    start = data.getFilePointer();\n    addressBuffer.writeTo(data);\n    meta.writeLong(start);\n    meta.writeLong(data.getFilePointer() - start);\n\n    // Now write the reverse terms index\n    writeTermsIndex(values);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":0,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene70/Lucene70DocValuesConsumer#addTermsDict(SortedSetDocValues).mjava","pathOld":"/dev/null","sourceNew":"  private void addTermsDict(SortedSetDocValues values) throws IOException {\n    final long size = values.getValueCount();\n    meta.writeVLong(size);\n    meta.writeInt(Lucene70DocValuesFormat.TERMS_DICT_BLOCK_SHIFT);\n\n    RAMOutputStream addressBuffer = new RAMOutputStream();\n    meta.writeInt(DIRECT_MONOTONIC_BLOCK_SHIFT);\n    long numBlocks = (size + Lucene70DocValuesFormat.TERMS_DICT_BLOCK_MASK) >>> Lucene70DocValuesFormat.TERMS_DICT_BLOCK_SHIFT;\n    DirectMonotonicWriter writer = DirectMonotonicWriter.getInstance(meta, addressBuffer, numBlocks, DIRECT_MONOTONIC_BLOCK_SHIFT);\n\n    BytesRefBuilder previous = new BytesRefBuilder();\n    long ord = 0;\n    long start = data.getFilePointer();\n    int maxLength = 0;\n    TermsEnum iterator = values.termsEnum();\n    for (BytesRef term = iterator.next(); term != null; term = iterator.next()) {\n      if ((ord & Lucene70DocValuesFormat.TERMS_DICT_BLOCK_MASK) == 0) {\n        writer.add(data.getFilePointer() - start);\n        data.writeVInt(term.length);\n        data.writeBytes(term.bytes, term.offset, term.length);\n      } else {\n        final int prefixLength = StringHelper.bytesDifference(previous.get(), term);\n        final int suffixLength = term.length - prefixLength;\n        assert suffixLength > 0; // terms are unique\n\n        data.writeByte((byte) (Math.min(prefixLength, 15) | (Math.min(15, suffixLength - 1) << 4)));\n        if (prefixLength >= 15) {\n          data.writeVInt(prefixLength - 15);\n        }\n        if (suffixLength >= 16) {\n          data.writeVInt(suffixLength - 16);\n        }\n        data.writeBytes(term.bytes, term.offset + prefixLength, term.length - prefixLength);\n      }\n      maxLength = Math.max(maxLength, term.length);\n      previous.copyBytes(term);\n      ++ord;\n    }\n    writer.finish();\n    meta.writeInt(maxLength);\n    meta.writeLong(start);\n    meta.writeLong(data.getFilePointer() - start);\n    start = data.getFilePointer();\n    addressBuffer.writeTo(data);\n    meta.writeLong(start);\n    meta.writeLong(data.getFilePointer() - start);\n\n    // Now write the reverse terms index\n    writeTermsIndex(values);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"409da428f28953cf35fddd5c9ff5c7e4f5439863","date":1547556145,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene70/Lucene70DocValuesConsumer#addTermsDict(SortedSetDocValues).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene70/Lucene70DocValuesConsumer#addTermsDict(SortedSetDocValues).mjava","sourceNew":"  private void addTermsDict(SortedSetDocValues values) throws IOException {\n    final long size = values.getValueCount();\n    meta.writeVLong(size);\n    meta.writeInt(Lucene70DocValuesFormat.TERMS_DICT_BLOCK_SHIFT);\n\n    ByteBuffersDataOutput addressBuffer = new ByteBuffersDataOutput();\n    ByteBuffersIndexOutput addressOutput = new ByteBuffersIndexOutput(addressBuffer, \"temp\", \"temp\");\n    meta.writeInt(DIRECT_MONOTONIC_BLOCK_SHIFT);\n    long numBlocks = (size + Lucene70DocValuesFormat.TERMS_DICT_BLOCK_MASK) >>> Lucene70DocValuesFormat.TERMS_DICT_BLOCK_SHIFT;\n    DirectMonotonicWriter writer = DirectMonotonicWriter.getInstance(meta, addressOutput, numBlocks, DIRECT_MONOTONIC_BLOCK_SHIFT);\n\n    BytesRefBuilder previous = new BytesRefBuilder();\n    long ord = 0;\n    long start = data.getFilePointer();\n    int maxLength = 0;\n    TermsEnum iterator = values.termsEnum();\n    for (BytesRef term = iterator.next(); term != null; term = iterator.next()) {\n      if ((ord & Lucene70DocValuesFormat.TERMS_DICT_BLOCK_MASK) == 0) {\n        writer.add(data.getFilePointer() - start);\n        data.writeVInt(term.length);\n        data.writeBytes(term.bytes, term.offset, term.length);\n      } else {\n        final int prefixLength = StringHelper.bytesDifference(previous.get(), term);\n        final int suffixLength = term.length - prefixLength;\n        assert suffixLength > 0; // terms are unique\n\n        data.writeByte((byte) (Math.min(prefixLength, 15) | (Math.min(15, suffixLength - 1) << 4)));\n        if (prefixLength >= 15) {\n          data.writeVInt(prefixLength - 15);\n        }\n        if (suffixLength >= 16) {\n          data.writeVInt(suffixLength - 16);\n        }\n        data.writeBytes(term.bytes, term.offset + prefixLength, term.length - prefixLength);\n      }\n      maxLength = Math.max(maxLength, term.length);\n      previous.copyBytes(term);\n      ++ord;\n    }\n    writer.finish();\n    meta.writeInt(maxLength);\n    meta.writeLong(start);\n    meta.writeLong(data.getFilePointer() - start);\n    start = data.getFilePointer();\n    addressBuffer.copyTo(data);\n    meta.writeLong(start);\n    meta.writeLong(data.getFilePointer() - start);\n\n    // Now write the reverse terms index\n    writeTermsIndex(values);\n  }\n\n","sourceOld":"  private void addTermsDict(SortedSetDocValues values) throws IOException {\n    final long size = values.getValueCount();\n    meta.writeVLong(size);\n    meta.writeInt(Lucene70DocValuesFormat.TERMS_DICT_BLOCK_SHIFT);\n\n    RAMOutputStream addressBuffer = new RAMOutputStream();\n    meta.writeInt(DIRECT_MONOTONIC_BLOCK_SHIFT);\n    long numBlocks = (size + Lucene70DocValuesFormat.TERMS_DICT_BLOCK_MASK) >>> Lucene70DocValuesFormat.TERMS_DICT_BLOCK_SHIFT;\n    DirectMonotonicWriter writer = DirectMonotonicWriter.getInstance(meta, addressBuffer, numBlocks, DIRECT_MONOTONIC_BLOCK_SHIFT);\n\n    BytesRefBuilder previous = new BytesRefBuilder();\n    long ord = 0;\n    long start = data.getFilePointer();\n    int maxLength = 0;\n    TermsEnum iterator = values.termsEnum();\n    for (BytesRef term = iterator.next(); term != null; term = iterator.next()) {\n      if ((ord & Lucene70DocValuesFormat.TERMS_DICT_BLOCK_MASK) == 0) {\n        writer.add(data.getFilePointer() - start);\n        data.writeVInt(term.length);\n        data.writeBytes(term.bytes, term.offset, term.length);\n      } else {\n        final int prefixLength = StringHelper.bytesDifference(previous.get(), term);\n        final int suffixLength = term.length - prefixLength;\n        assert suffixLength > 0; // terms are unique\n\n        data.writeByte((byte) (Math.min(prefixLength, 15) | (Math.min(15, suffixLength - 1) << 4)));\n        if (prefixLength >= 15) {\n          data.writeVInt(prefixLength - 15);\n        }\n        if (suffixLength >= 16) {\n          data.writeVInt(suffixLength - 16);\n        }\n        data.writeBytes(term.bytes, term.offset + prefixLength, term.length - prefixLength);\n      }\n      maxLength = Math.max(maxLength, term.length);\n      previous.copyBytes(term);\n      ++ord;\n    }\n    writer.finish();\n    meta.writeInt(maxLength);\n    meta.writeLong(start);\n    meta.writeLong(data.getFilePointer() - start);\n    start = data.getFilePointer();\n    addressBuffer.writeTo(data);\n    meta.writeLong(start);\n    meta.writeLong(data.getFilePointer() - start);\n\n    // Now write the reverse terms index\n    writeTermsIndex(values);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"03e17b020972a0d6e8d6823f545571a66646a167","date":1547847724,"type":5,"author":"Toke Eskildsen","isMerge":false,"pathNew":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene70/Lucene70DocValuesConsumer#addTermsDict(SortedSetDocValues).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene70/Lucene70DocValuesConsumer#addTermsDict(SortedSetDocValues).mjava","sourceNew":"  private void addTermsDict(SortedSetDocValues values) throws IOException {\n    final long size = values.getValueCount();\n    meta.writeVLong(size);\n    meta.writeInt(Lucene70DocValuesFormat.TERMS_DICT_BLOCK_SHIFT);\n\n    ByteBuffersDataOutput addressBuffer = new ByteBuffersDataOutput();\n    ByteBuffersIndexOutput addressOutput = new ByteBuffersIndexOutput(addressBuffer, \"temp\", \"temp\");\n    meta.writeInt(DIRECT_MONOTONIC_BLOCK_SHIFT);\n    long numBlocks = (size + Lucene70DocValuesFormat.TERMS_DICT_BLOCK_MASK) >>> Lucene70DocValuesFormat.TERMS_DICT_BLOCK_SHIFT;\n    DirectMonotonicWriter writer = DirectMonotonicWriter.getInstance(meta, addressOutput, numBlocks, DIRECT_MONOTONIC_BLOCK_SHIFT);\n\n    BytesRefBuilder previous = new BytesRefBuilder();\n    long ord = 0;\n    long start = data.getFilePointer();\n    int maxLength = 0;\n    TermsEnum iterator = values.termsEnum();\n    for (BytesRef term = iterator.next(); term != null; term = iterator.next()) {\n      if ((ord & Lucene70DocValuesFormat.TERMS_DICT_BLOCK_MASK) == 0) {\n        writer.add(data.getFilePointer() - start);\n        data.writeVInt(term.length);\n        data.writeBytes(term.bytes, term.offset, term.length);\n      } else {\n        final int prefixLength = StringHelper.bytesDifference(previous.get(), term);\n        final int suffixLength = term.length - prefixLength;\n        assert suffixLength > 0; // terms are unique\n\n        data.writeByte((byte) (Math.min(prefixLength, 15) | (Math.min(15, suffixLength - 1) << 4)));\n        if (prefixLength >= 15) {\n          data.writeVInt(prefixLength - 15);\n        }\n        if (suffixLength >= 16) {\n          data.writeVInt(suffixLength - 16);\n        }\n        data.writeBytes(term.bytes, term.offset + prefixLength, term.length - prefixLength);\n      }\n      maxLength = Math.max(maxLength, term.length);\n      previous.copyBytes(term);\n      ++ord;\n    }\n    writer.finish();\n    meta.writeInt(maxLength);\n    meta.writeLong(start);\n    meta.writeLong(data.getFilePointer() - start);\n    start = data.getFilePointer();\n    addressBuffer.copyTo(data);\n    meta.writeLong(start);\n    meta.writeLong(data.getFilePointer() - start);\n\n    // Now write the reverse terms index\n    writeTermsIndex(values);\n  }\n\n","sourceOld":"  private void addTermsDict(SortedSetDocValues values) throws IOException {\n    final long size = values.getValueCount();\n    meta.writeVLong(size);\n    meta.writeInt(Lucene70DocValuesFormat.TERMS_DICT_BLOCK_SHIFT);\n\n    ByteBuffersDataOutput addressBuffer = new ByteBuffersDataOutput();\n    ByteBuffersIndexOutput addressOutput = new ByteBuffersIndexOutput(addressBuffer, \"temp\", \"temp\");\n    meta.writeInt(DIRECT_MONOTONIC_BLOCK_SHIFT);\n    long numBlocks = (size + Lucene70DocValuesFormat.TERMS_DICT_BLOCK_MASK) >>> Lucene70DocValuesFormat.TERMS_DICT_BLOCK_SHIFT;\n    DirectMonotonicWriter writer = DirectMonotonicWriter.getInstance(meta, addressOutput, numBlocks, DIRECT_MONOTONIC_BLOCK_SHIFT);\n\n    BytesRefBuilder previous = new BytesRefBuilder();\n    long ord = 0;\n    long start = data.getFilePointer();\n    int maxLength = 0;\n    TermsEnum iterator = values.termsEnum();\n    for (BytesRef term = iterator.next(); term != null; term = iterator.next()) {\n      if ((ord & Lucene70DocValuesFormat.TERMS_DICT_BLOCK_MASK) == 0) {\n        writer.add(data.getFilePointer() - start);\n        data.writeVInt(term.length);\n        data.writeBytes(term.bytes, term.offset, term.length);\n      } else {\n        final int prefixLength = StringHelper.bytesDifference(previous.get(), term);\n        final int suffixLength = term.length - prefixLength;\n        assert suffixLength > 0; // terms are unique\n\n        data.writeByte((byte) (Math.min(prefixLength, 15) | (Math.min(15, suffixLength - 1) << 4)));\n        if (prefixLength >= 15) {\n          data.writeVInt(prefixLength - 15);\n        }\n        if (suffixLength >= 16) {\n          data.writeVInt(suffixLength - 16);\n        }\n        data.writeBytes(term.bytes, term.offset + prefixLength, term.length - prefixLength);\n      }\n      maxLength = Math.max(maxLength, term.length);\n      previous.copyBytes(term);\n      ++ord;\n    }\n    writer.finish();\n    meta.writeInt(maxLength);\n    meta.writeLong(start);\n    meta.writeLong(data.getFilePointer() - start);\n    start = data.getFilePointer();\n    addressBuffer.copyTo(data);\n    meta.writeLong(start);\n    meta.writeLong(data.getFilePointer() - start);\n\n    // Now write the reverse terms index\n    writeTermsIndex(values);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c89f1ef80a9432f4eabaeda9a1e135cd72e60836","date":1547972642,"type":5,"author":"Tommaso Teofili","isMerge":true,"pathNew":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene70/Lucene70DocValuesConsumer#addTermsDict(SortedSetDocValues).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene70/Lucene70DocValuesConsumer#addTermsDict(SortedSetDocValues).mjava","sourceNew":"  private void addTermsDict(SortedSetDocValues values) throws IOException {\n    final long size = values.getValueCount();\n    meta.writeVLong(size);\n    meta.writeInt(Lucene70DocValuesFormat.TERMS_DICT_BLOCK_SHIFT);\n\n    ByteBuffersDataOutput addressBuffer = new ByteBuffersDataOutput();\n    ByteBuffersIndexOutput addressOutput = new ByteBuffersIndexOutput(addressBuffer, \"temp\", \"temp\");\n    meta.writeInt(DIRECT_MONOTONIC_BLOCK_SHIFT);\n    long numBlocks = (size + Lucene70DocValuesFormat.TERMS_DICT_BLOCK_MASK) >>> Lucene70DocValuesFormat.TERMS_DICT_BLOCK_SHIFT;\n    DirectMonotonicWriter writer = DirectMonotonicWriter.getInstance(meta, addressOutput, numBlocks, DIRECT_MONOTONIC_BLOCK_SHIFT);\n\n    BytesRefBuilder previous = new BytesRefBuilder();\n    long ord = 0;\n    long start = data.getFilePointer();\n    int maxLength = 0;\n    TermsEnum iterator = values.termsEnum();\n    for (BytesRef term = iterator.next(); term != null; term = iterator.next()) {\n      if ((ord & Lucene70DocValuesFormat.TERMS_DICT_BLOCK_MASK) == 0) {\n        writer.add(data.getFilePointer() - start);\n        data.writeVInt(term.length);\n        data.writeBytes(term.bytes, term.offset, term.length);\n      } else {\n        final int prefixLength = StringHelper.bytesDifference(previous.get(), term);\n        final int suffixLength = term.length - prefixLength;\n        assert suffixLength > 0; // terms are unique\n\n        data.writeByte((byte) (Math.min(prefixLength, 15) | (Math.min(15, suffixLength - 1) << 4)));\n        if (prefixLength >= 15) {\n          data.writeVInt(prefixLength - 15);\n        }\n        if (suffixLength >= 16) {\n          data.writeVInt(suffixLength - 16);\n        }\n        data.writeBytes(term.bytes, term.offset + prefixLength, term.length - prefixLength);\n      }\n      maxLength = Math.max(maxLength, term.length);\n      previous.copyBytes(term);\n      ++ord;\n    }\n    writer.finish();\n    meta.writeInt(maxLength);\n    meta.writeLong(start);\n    meta.writeLong(data.getFilePointer() - start);\n    start = data.getFilePointer();\n    addressBuffer.copyTo(data);\n    meta.writeLong(start);\n    meta.writeLong(data.getFilePointer() - start);\n\n    // Now write the reverse terms index\n    writeTermsIndex(values);\n  }\n\n","sourceOld":"  private void addTermsDict(SortedSetDocValues values) throws IOException {\n    final long size = values.getValueCount();\n    meta.writeVLong(size);\n    meta.writeInt(Lucene70DocValuesFormat.TERMS_DICT_BLOCK_SHIFT);\n\n    ByteBuffersDataOutput addressBuffer = new ByteBuffersDataOutput();\n    ByteBuffersIndexOutput addressOutput = new ByteBuffersIndexOutput(addressBuffer, \"temp\", \"temp\");\n    meta.writeInt(DIRECT_MONOTONIC_BLOCK_SHIFT);\n    long numBlocks = (size + Lucene70DocValuesFormat.TERMS_DICT_BLOCK_MASK) >>> Lucene70DocValuesFormat.TERMS_DICT_BLOCK_SHIFT;\n    DirectMonotonicWriter writer = DirectMonotonicWriter.getInstance(meta, addressOutput, numBlocks, DIRECT_MONOTONIC_BLOCK_SHIFT);\n\n    BytesRefBuilder previous = new BytesRefBuilder();\n    long ord = 0;\n    long start = data.getFilePointer();\n    int maxLength = 0;\n    TermsEnum iterator = values.termsEnum();\n    for (BytesRef term = iterator.next(); term != null; term = iterator.next()) {\n      if ((ord & Lucene70DocValuesFormat.TERMS_DICT_BLOCK_MASK) == 0) {\n        writer.add(data.getFilePointer() - start);\n        data.writeVInt(term.length);\n        data.writeBytes(term.bytes, term.offset, term.length);\n      } else {\n        final int prefixLength = StringHelper.bytesDifference(previous.get(), term);\n        final int suffixLength = term.length - prefixLength;\n        assert suffixLength > 0; // terms are unique\n\n        data.writeByte((byte) (Math.min(prefixLength, 15) | (Math.min(15, suffixLength - 1) << 4)));\n        if (prefixLength >= 15) {\n          data.writeVInt(prefixLength - 15);\n        }\n        if (suffixLength >= 16) {\n          data.writeVInt(suffixLength - 16);\n        }\n        data.writeBytes(term.bytes, term.offset + prefixLength, term.length - prefixLength);\n      }\n      maxLength = Math.max(maxLength, term.length);\n      previous.copyBytes(term);\n      ++ord;\n    }\n    writer.finish();\n    meta.writeInt(maxLength);\n    meta.writeLong(start);\n    meta.writeLong(data.getFilePointer() - start);\n    start = data.getFilePointer();\n    addressBuffer.copyTo(data);\n    meta.writeLong(start);\n    meta.writeLong(data.getFilePointer() - start);\n\n    // Now write the reverse terms index\n    writeTermsIndex(values);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"03e17b020972a0d6e8d6823f545571a66646a167":["409da428f28953cf35fddd5c9ff5c7e4f5439863"],"409da428f28953cf35fddd5c9ff5c7e4f5439863":["23e44daeaa8b89694d10df5999956c8e14a7dd09"],"23e44daeaa8b89694d10df5999956c8e14a7dd09":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"c89f1ef80a9432f4eabaeda9a1e135cd72e60836":["409da428f28953cf35fddd5c9ff5c7e4f5439863","03e17b020972a0d6e8d6823f545571a66646a167"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","23e44daeaa8b89694d10df5999956c8e14a7dd09"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["03e17b020972a0d6e8d6823f545571a66646a167"]},"commit2Childs":{"03e17b020972a0d6e8d6823f545571a66646a167":["c89f1ef80a9432f4eabaeda9a1e135cd72e60836","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"409da428f28953cf35fddd5c9ff5c7e4f5439863":["03e17b020972a0d6e8d6823f545571a66646a167","c89f1ef80a9432f4eabaeda9a1e135cd72e60836"],"23e44daeaa8b89694d10df5999956c8e14a7dd09":["409da428f28953cf35fddd5c9ff5c7e4f5439863","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"c89f1ef80a9432f4eabaeda9a1e135cd72e60836":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["23e44daeaa8b89694d10df5999956c8e14a7dd09","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["c89f1ef80a9432f4eabaeda9a1e135cd72e60836","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}