{"path":"lucene/core/src/java/org/apache/lucene/codecs/lucene60/Lucene60FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","commits":[{"id":"1eee4175312c41f89aa23427f9e4edfc00deeaac","date":1446373190,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene60/Lucene60FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        CodecUtil.checkIndexHeader(input,\n                                   Lucene60FieldInfosFormat.CODEC_NAME, \n                                   Lucene60FieldInfosFormat.FORMAT_START, \n                                   Lucene60FieldInfosFormat.FORMAT_CURRENT,\n                                   segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        // previous field's attribute map, we share when possible:\n        Map<String,String> lastAttributes = Collections.emptyMap();\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & STORE_PAYLOADS) != 0;\n\n          final IndexOptions indexOptions = getIndexOptions(input, input.readByte());\n          \n          // DV Types are packed in one byte\n          final DocValuesType docValuesType = getDocValuesType(input, input.readByte());\n          final long dvGen = input.readLong();\n          Map<String,String> attributes = input.readMapOfStrings();\n          // just use the last field's map if its the same\n          if (attributes.equals(lastAttributes)) {\n            attributes = lastAttributes;\n          }\n          lastAttributes = attributes;\n          int dimensionCount = input.readVInt();\n          int dimensionNumBytes;\n          if (dimensionCount != 0) {\n            dimensionNumBytes = input.readVInt();\n          } else {\n            dimensionNumBytes = 0;\n          }\n\n          try {\n            infos[i] = new FieldInfo(name, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, attributes,\n                                     dimensionCount, dimensionNumBytes);\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cab7a79353f33d1a94cd307bf33aa5148601ebe6","date":1453391888,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene60/Lucene60FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene60/Lucene60FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","sourceNew":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        CodecUtil.checkIndexHeader(input,\n                                   Lucene60FieldInfosFormat.CODEC_NAME, \n                                   Lucene60FieldInfosFormat.FORMAT_START, \n                                   Lucene60FieldInfosFormat.FORMAT_CURRENT,\n                                   segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        // previous field's attribute map, we share when possible:\n        Map<String,String> lastAttributes = Collections.emptyMap();\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & STORE_PAYLOADS) != 0;\n\n          final IndexOptions indexOptions = getIndexOptions(input, input.readByte());\n          \n          // DV Types are packed in one byte\n          final DocValuesType docValuesType = getDocValuesType(input, input.readByte());\n          final long dvGen = input.readLong();\n          Map<String,String> attributes = input.readMapOfStrings();\n          // just use the last field's map if its the same\n          if (attributes.equals(lastAttributes)) {\n            attributes = lastAttributes;\n          }\n          lastAttributes = attributes;\n          int pointDimensionCount = input.readVInt();\n          int pointNumBytes;\n          if (pointDimensionCount != 0) {\n            pointNumBytes = input.readVInt();\n          } else {\n            pointNumBytes = 0;\n          }\n\n          try {\n            infos[i] = new FieldInfo(name, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, attributes,\n                                     pointDimensionCount, pointNumBytes);\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","sourceOld":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        CodecUtil.checkIndexHeader(input,\n                                   Lucene60FieldInfosFormat.CODEC_NAME, \n                                   Lucene60FieldInfosFormat.FORMAT_START, \n                                   Lucene60FieldInfosFormat.FORMAT_CURRENT,\n                                   segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        // previous field's attribute map, we share when possible:\n        Map<String,String> lastAttributes = Collections.emptyMap();\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & STORE_PAYLOADS) != 0;\n\n          final IndexOptions indexOptions = getIndexOptions(input, input.readByte());\n          \n          // DV Types are packed in one byte\n          final DocValuesType docValuesType = getDocValuesType(input, input.readByte());\n          final long dvGen = input.readLong();\n          Map<String,String> attributes = input.readMapOfStrings();\n          // just use the last field's map if its the same\n          if (attributes.equals(lastAttributes)) {\n            attributes = lastAttributes;\n          }\n          lastAttributes = attributes;\n          int dimensionCount = input.readVInt();\n          int dimensionNumBytes;\n          if (dimensionCount != 0) {\n            dimensionNumBytes = input.readVInt();\n          } else {\n            dimensionNumBytes = 0;\n          }\n\n          try {\n            infos[i] = new FieldInfo(name, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, attributes,\n                                     dimensionCount, dimensionNumBytes);\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"eeba0a4d0845889a402dd225793d62f009d029c9","date":1527938093,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene60/Lucene60FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene60/Lucene60FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","sourceNew":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        CodecUtil.checkIndexHeader(input,\n                                   Lucene60FieldInfosFormat.CODEC_NAME, \n                                   Lucene60FieldInfosFormat.FORMAT_START, \n                                   Lucene60FieldInfosFormat.FORMAT_CURRENT,\n                                   segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        // previous field's attribute map, we share when possible:\n        Map<String,String> lastAttributes = Collections.emptyMap();\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & STORE_PAYLOADS) != 0;\n          boolean isSoftDeletesField = (bits & SOFT_DELETES_FIELD) != 0;\n\n          final IndexOptions indexOptions = getIndexOptions(input, input.readByte());\n          \n          // DV Types are packed in one byte\n          final DocValuesType docValuesType = getDocValuesType(input, input.readByte());\n          final long dvGen = input.readLong();\n          Map<String,String> attributes = input.readMapOfStrings();\n          // just use the last field's map if its the same\n          if (attributes.equals(lastAttributes)) {\n            attributes = lastAttributes;\n          }\n          lastAttributes = attributes;\n          int pointDimensionCount = input.readVInt();\n          int pointNumBytes;\n          if (pointDimensionCount != 0) {\n            pointNumBytes = input.readVInt();\n          } else {\n            pointNumBytes = 0;\n          }\n\n          try {\n            infos[i] = new FieldInfo(name, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, attributes,\n                                     pointDimensionCount, pointNumBytes, isSoftDeletesField);\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","sourceOld":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        CodecUtil.checkIndexHeader(input,\n                                   Lucene60FieldInfosFormat.CODEC_NAME, \n                                   Lucene60FieldInfosFormat.FORMAT_START, \n                                   Lucene60FieldInfosFormat.FORMAT_CURRENT,\n                                   segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        // previous field's attribute map, we share when possible:\n        Map<String,String> lastAttributes = Collections.emptyMap();\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & STORE_PAYLOADS) != 0;\n\n          final IndexOptions indexOptions = getIndexOptions(input, input.readByte());\n          \n          // DV Types are packed in one byte\n          final DocValuesType docValuesType = getDocValuesType(input, input.readByte());\n          final long dvGen = input.readLong();\n          Map<String,String> attributes = input.readMapOfStrings();\n          // just use the last field's map if its the same\n          if (attributes.equals(lastAttributes)) {\n            attributes = lastAttributes;\n          }\n          lastAttributes = attributes;\n          int pointDimensionCount = input.readVInt();\n          int pointNumBytes;\n          if (pointDimensionCount != 0) {\n            pointNumBytes = input.readVInt();\n          } else {\n            pointNumBytes = 0;\n          }\n\n          try {\n            infos[i] = new FieldInfo(name, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, attributes,\n                                     pointDimensionCount, pointNumBytes);\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ab548c8f96022b4780f7500a30b19b4f4a5feeb6","date":1527940044,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene60/Lucene60FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene60/Lucene60FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","sourceNew":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        CodecUtil.checkIndexHeader(input,\n                                   Lucene60FieldInfosFormat.CODEC_NAME, \n                                   Lucene60FieldInfosFormat.FORMAT_START, \n                                   Lucene60FieldInfosFormat.FORMAT_CURRENT,\n                                   segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        // previous field's attribute map, we share when possible:\n        Map<String,String> lastAttributes = Collections.emptyMap();\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & STORE_PAYLOADS) != 0;\n\n          final IndexOptions indexOptions = getIndexOptions(input, input.readByte());\n          \n          // DV Types are packed in one byte\n          final DocValuesType docValuesType = getDocValuesType(input, input.readByte());\n          final long dvGen = input.readLong();\n          Map<String,String> attributes = input.readMapOfStrings();\n          // just use the last field's map if its the same\n          if (attributes.equals(lastAttributes)) {\n            attributes = lastAttributes;\n          }\n          lastAttributes = attributes;\n          int pointDimensionCount = input.readVInt();\n          int pointNumBytes;\n          if (pointDimensionCount != 0) {\n            pointNumBytes = input.readVInt();\n          } else {\n            pointNumBytes = 0;\n          }\n\n          try {\n            infos[i] = new FieldInfo(name, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, attributes,\n                                     pointDimensionCount, pointNumBytes);\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","sourceOld":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        CodecUtil.checkIndexHeader(input,\n                                   Lucene60FieldInfosFormat.CODEC_NAME, \n                                   Lucene60FieldInfosFormat.FORMAT_START, \n                                   Lucene60FieldInfosFormat.FORMAT_CURRENT,\n                                   segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        // previous field's attribute map, we share when possible:\n        Map<String,String> lastAttributes = Collections.emptyMap();\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & STORE_PAYLOADS) != 0;\n          boolean isSoftDeletesField = (bits & SOFT_DELETES_FIELD) != 0;\n\n          final IndexOptions indexOptions = getIndexOptions(input, input.readByte());\n          \n          // DV Types are packed in one byte\n          final DocValuesType docValuesType = getDocValuesType(input, input.readByte());\n          final long dvGen = input.readLong();\n          Map<String,String> attributes = input.readMapOfStrings();\n          // just use the last field's map if its the same\n          if (attributes.equals(lastAttributes)) {\n            attributes = lastAttributes;\n          }\n          lastAttributes = attributes;\n          int pointDimensionCount = input.readVInt();\n          int pointNumBytes;\n          if (pointDimensionCount != 0) {\n            pointNumBytes = input.readVInt();\n          } else {\n            pointNumBytes = 0;\n          }\n\n          try {\n            infos[i] = new FieldInfo(name, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, attributes,\n                                     pointDimensionCount, pointNumBytes, isSoftDeletesField);\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b7e4ca6dc9612ff741d8713743e2bccfae5eadac","date":1528093718,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene60/Lucene60FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene60/Lucene60FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","sourceNew":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        CodecUtil.checkIndexHeader(input,\n                                   Lucene60FieldInfosFormat.CODEC_NAME, \n                                   Lucene60FieldInfosFormat.FORMAT_START, \n                                   Lucene60FieldInfosFormat.FORMAT_CURRENT,\n                                   segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        // previous field's attribute map, we share when possible:\n        Map<String,String> lastAttributes = Collections.emptyMap();\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & STORE_PAYLOADS) != 0;\n          boolean isSoftDeletesField = (bits & SOFT_DELETES_FIELD) != 0;\n\n          final IndexOptions indexOptions = getIndexOptions(input, input.readByte());\n          \n          // DV Types are packed in one byte\n          final DocValuesType docValuesType = getDocValuesType(input, input.readByte());\n          final long dvGen = input.readLong();\n          Map<String,String> attributes = input.readMapOfStrings();\n          // just use the last field's map if its the same\n          if (attributes.equals(lastAttributes)) {\n            attributes = lastAttributes;\n          }\n          lastAttributes = attributes;\n          int pointDimensionCount = input.readVInt();\n          int pointNumBytes;\n          if (pointDimensionCount != 0) {\n            pointNumBytes = input.readVInt();\n          } else {\n            pointNumBytes = 0;\n          }\n\n          try {\n            infos[i] = new FieldInfo(name, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, attributes,\n                                     pointDimensionCount, pointNumBytes, isSoftDeletesField);\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","sourceOld":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        CodecUtil.checkIndexHeader(input,\n                                   Lucene60FieldInfosFormat.CODEC_NAME, \n                                   Lucene60FieldInfosFormat.FORMAT_START, \n                                   Lucene60FieldInfosFormat.FORMAT_CURRENT,\n                                   segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        // previous field's attribute map, we share when possible:\n        Map<String,String> lastAttributes = Collections.emptyMap();\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & STORE_PAYLOADS) != 0;\n\n          final IndexOptions indexOptions = getIndexOptions(input, input.readByte());\n          \n          // DV Types are packed in one byte\n          final DocValuesType docValuesType = getDocValuesType(input, input.readByte());\n          final long dvGen = input.readLong();\n          Map<String,String> attributes = input.readMapOfStrings();\n          // just use the last field's map if its the same\n          if (attributes.equals(lastAttributes)) {\n            attributes = lastAttributes;\n          }\n          lastAttributes = attributes;\n          int pointDimensionCount = input.readVInt();\n          int pointNumBytes;\n          if (pointDimensionCount != 0) {\n            pointNumBytes = input.readVInt();\n          } else {\n            pointNumBytes = 0;\n          }\n\n          try {\n            infos[i] = new FieldInfo(name, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, attributes,\n                                     pointDimensionCount, pointNumBytes);\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f592209545c71895260367152601e9200399776d","date":1528238935,"type":3,"author":"Michael Braun","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene60/Lucene60FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene60/Lucene60FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","sourceNew":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        CodecUtil.checkIndexHeader(input,\n                                   Lucene60FieldInfosFormat.CODEC_NAME, \n                                   Lucene60FieldInfosFormat.FORMAT_START, \n                                   Lucene60FieldInfosFormat.FORMAT_CURRENT,\n                                   segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        // previous field's attribute map, we share when possible:\n        Map<String,String> lastAttributes = Collections.emptyMap();\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & STORE_PAYLOADS) != 0;\n          boolean isSoftDeletesField = (bits & SOFT_DELETES_FIELD) != 0;\n\n          final IndexOptions indexOptions = getIndexOptions(input, input.readByte());\n          \n          // DV Types are packed in one byte\n          final DocValuesType docValuesType = getDocValuesType(input, input.readByte());\n          final long dvGen = input.readLong();\n          Map<String,String> attributes = input.readMapOfStrings();\n          // just use the last field's map if its the same\n          if (attributes.equals(lastAttributes)) {\n            attributes = lastAttributes;\n          }\n          lastAttributes = attributes;\n          int pointDimensionCount = input.readVInt();\n          int pointNumBytes;\n          if (pointDimensionCount != 0) {\n            pointNumBytes = input.readVInt();\n          } else {\n            pointNumBytes = 0;\n          }\n\n          try {\n            infos[i] = new FieldInfo(name, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, attributes,\n                                     pointDimensionCount, pointNumBytes, isSoftDeletesField);\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","sourceOld":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        CodecUtil.checkIndexHeader(input,\n                                   Lucene60FieldInfosFormat.CODEC_NAME, \n                                   Lucene60FieldInfosFormat.FORMAT_START, \n                                   Lucene60FieldInfosFormat.FORMAT_CURRENT,\n                                   segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        // previous field's attribute map, we share when possible:\n        Map<String,String> lastAttributes = Collections.emptyMap();\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & STORE_PAYLOADS) != 0;\n\n          final IndexOptions indexOptions = getIndexOptions(input, input.readByte());\n          \n          // DV Types are packed in one byte\n          final DocValuesType docValuesType = getDocValuesType(input, input.readByte());\n          final long dvGen = input.readLong();\n          Map<String,String> attributes = input.readMapOfStrings();\n          // just use the last field's map if its the same\n          if (attributes.equals(lastAttributes)) {\n            attributes = lastAttributes;\n          }\n          lastAttributes = attributes;\n          int pointDimensionCount = input.readVInt();\n          int pointNumBytes;\n          if (pointDimensionCount != 0) {\n            pointNumBytes = input.readVInt();\n          } else {\n            pointNumBytes = 0;\n          }\n\n          try {\n            infos[i] = new FieldInfo(name, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, attributes,\n                                     pointDimensionCount, pointNumBytes);\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b70042a8a492f7054d480ccdd2be9796510d4327","date":1528386658,"type":3,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene60/Lucene60FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene60/Lucene60FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","sourceNew":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        CodecUtil.checkIndexHeader(input,\n                                   Lucene60FieldInfosFormat.CODEC_NAME, \n                                   Lucene60FieldInfosFormat.FORMAT_START, \n                                   Lucene60FieldInfosFormat.FORMAT_CURRENT,\n                                   segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        // previous field's attribute map, we share when possible:\n        Map<String,String> lastAttributes = Collections.emptyMap();\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & STORE_PAYLOADS) != 0;\n          boolean isSoftDeletesField = (bits & SOFT_DELETES_FIELD) != 0;\n\n          final IndexOptions indexOptions = getIndexOptions(input, input.readByte());\n          \n          // DV Types are packed in one byte\n          final DocValuesType docValuesType = getDocValuesType(input, input.readByte());\n          final long dvGen = input.readLong();\n          Map<String,String> attributes = input.readMapOfStrings();\n          // just use the last field's map if its the same\n          if (attributes.equals(lastAttributes)) {\n            attributes = lastAttributes;\n          }\n          lastAttributes = attributes;\n          int pointDimensionCount = input.readVInt();\n          int pointNumBytes;\n          if (pointDimensionCount != 0) {\n            pointNumBytes = input.readVInt();\n          } else {\n            pointNumBytes = 0;\n          }\n\n          try {\n            infos[i] = new FieldInfo(name, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, attributes,\n                                     pointDimensionCount, pointNumBytes, isSoftDeletesField);\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","sourceOld":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        CodecUtil.checkIndexHeader(input,\n                                   Lucene60FieldInfosFormat.CODEC_NAME, \n                                   Lucene60FieldInfosFormat.FORMAT_START, \n                                   Lucene60FieldInfosFormat.FORMAT_CURRENT,\n                                   segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        // previous field's attribute map, we share when possible:\n        Map<String,String> lastAttributes = Collections.emptyMap();\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & STORE_PAYLOADS) != 0;\n\n          final IndexOptions indexOptions = getIndexOptions(input, input.readByte());\n          \n          // DV Types are packed in one byte\n          final DocValuesType docValuesType = getDocValuesType(input, input.readByte());\n          final long dvGen = input.readLong();\n          Map<String,String> attributes = input.readMapOfStrings();\n          // just use the last field's map if its the same\n          if (attributes.equals(lastAttributes)) {\n            attributes = lastAttributes;\n          }\n          lastAttributes = attributes;\n          int pointDimensionCount = input.readVInt();\n          int pointNumBytes;\n          if (pointDimensionCount != 0) {\n            pointNumBytes = input.readVInt();\n          } else {\n            pointNumBytes = 0;\n          }\n\n          try {\n            infos[i] = new FieldInfo(name, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, attributes,\n                                     pointDimensionCount, pointNumBytes);\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f6652c943595e92c187ee904c382863013eae28f","date":1539042663,"type":3,"author":"Nicholas Knize","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene60/Lucene60FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene60/Lucene60FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","sourceNew":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        int version = CodecUtil.checkIndexHeader(input,\n                                   Lucene60FieldInfosFormat.CODEC_NAME, \n                                   Lucene60FieldInfosFormat.FORMAT_START, \n                                   Lucene60FieldInfosFormat.FORMAT_CURRENT,\n                                   segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        // previous field's attribute map, we share when possible:\n        Map<String,String> lastAttributes = Collections.emptyMap();\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & STORE_PAYLOADS) != 0;\n          boolean isSoftDeletesField = (bits & SOFT_DELETES_FIELD) != 0;\n\n          final IndexOptions indexOptions = getIndexOptions(input, input.readByte());\n          \n          // DV Types are packed in one byte\n          final DocValuesType docValuesType = getDocValuesType(input, input.readByte());\n          final long dvGen = input.readLong();\n          Map<String,String> attributes = input.readMapOfStrings();\n          // just use the last field's map if its the same\n          if (attributes.equals(lastAttributes)) {\n            attributes = lastAttributes;\n          }\n          lastAttributes = attributes;\n          int pointDataDimensionCount = input.readVInt();\n          int pointNumBytes;\n          int pointIndexDimensionCount = pointDataDimensionCount;\n          if (pointDataDimensionCount != 0) {\n            if (version >= Lucene60FieldInfosFormat.FORMAT_SELECTIVE_INDEXING) {\n              pointIndexDimensionCount = input.readVInt();\n            }\n            pointNumBytes = input.readVInt();\n          } else {\n            pointNumBytes = 0;\n          }\n\n          try {\n            infos[i] = new FieldInfo(name, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, attributes,\n                                     pointDataDimensionCount, pointIndexDimensionCount, pointNumBytes, isSoftDeletesField);\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","sourceOld":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        CodecUtil.checkIndexHeader(input,\n                                   Lucene60FieldInfosFormat.CODEC_NAME, \n                                   Lucene60FieldInfosFormat.FORMAT_START, \n                                   Lucene60FieldInfosFormat.FORMAT_CURRENT,\n                                   segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        // previous field's attribute map, we share when possible:\n        Map<String,String> lastAttributes = Collections.emptyMap();\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & STORE_PAYLOADS) != 0;\n          boolean isSoftDeletesField = (bits & SOFT_DELETES_FIELD) != 0;\n\n          final IndexOptions indexOptions = getIndexOptions(input, input.readByte());\n          \n          // DV Types are packed in one byte\n          final DocValuesType docValuesType = getDocValuesType(input, input.readByte());\n          final long dvGen = input.readLong();\n          Map<String,String> attributes = input.readMapOfStrings();\n          // just use the last field's map if its the same\n          if (attributes.equals(lastAttributes)) {\n            attributes = lastAttributes;\n          }\n          lastAttributes = attributes;\n          int pointDimensionCount = input.readVInt();\n          int pointNumBytes;\n          if (pointDimensionCount != 0) {\n            pointNumBytes = input.readVInt();\n          } else {\n            pointNumBytes = 0;\n          }\n\n          try {\n            infos[i] = new FieldInfo(name, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, attributes,\n                                     pointDimensionCount, pointNumBytes, isSoftDeletesField);\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"683b2041fcb490acd2bfec6034c593b3cfb2098c","date":1596135595,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene60/Lucene60FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene60/Lucene60FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","sourceNew":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        int version = CodecUtil.checkIndexHeader(input,\n                                   Lucene60FieldInfosFormat.CODEC_NAME, \n                                   Lucene60FieldInfosFormat.FORMAT_START, \n                                   Lucene60FieldInfosFormat.FORMAT_CURRENT,\n                                   segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        // previous field's attribute map, we share when possible:\n        Map<String,String> lastAttributes = Collections.emptyMap();\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & STORE_PAYLOADS) != 0;\n          boolean isSoftDeletesField = (bits & SOFT_DELETES_FIELD) != 0;\n\n          final IndexOptions indexOptions = getIndexOptions(input, input.readByte());\n          \n          // DV Types are packed in one byte\n          final DocValuesType docValuesType = getDocValuesType(input, input.readByte());\n          final long dvGen = input.readLong();\n          Map<String,String> attributes = input.readMapOfStrings();\n          // just use the last field's map if its the same\n          if (attributes.equals(lastAttributes)) {\n            attributes = lastAttributes;\n          }\n          lastAttributes = attributes;\n          int pointDataDimensionCount = input.readVInt();\n          int pointNumBytes;\n          int pointIndexDimensionCount = pointDataDimensionCount;\n          if (pointDataDimensionCount != 0) {\n            if (version >= Lucene60FieldInfosFormat.FORMAT_SELECTIVE_INDEXING) {\n              pointIndexDimensionCount = input.readVInt();\n            }\n            pointNumBytes = input.readVInt();\n          } else {\n            pointNumBytes = 0;\n          }\n\n          try {\n            infos[i] = new FieldInfo(name, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, attributes,\n                                     pointDataDimensionCount, pointIndexDimensionCount, pointNumBytes, isSoftDeletesField);\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","sourceOld":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        int version = CodecUtil.checkIndexHeader(input,\n                                   Lucene60FieldInfosFormat.CODEC_NAME, \n                                   Lucene60FieldInfosFormat.FORMAT_START, \n                                   Lucene60FieldInfosFormat.FORMAT_CURRENT,\n                                   segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        // previous field's attribute map, we share when possible:\n        Map<String,String> lastAttributes = Collections.emptyMap();\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & STORE_PAYLOADS) != 0;\n          boolean isSoftDeletesField = (bits & SOFT_DELETES_FIELD) != 0;\n\n          final IndexOptions indexOptions = getIndexOptions(input, input.readByte());\n          \n          // DV Types are packed in one byte\n          final DocValuesType docValuesType = getDocValuesType(input, input.readByte());\n          final long dvGen = input.readLong();\n          Map<String,String> attributes = input.readMapOfStrings();\n          // just use the last field's map if its the same\n          if (attributes.equals(lastAttributes)) {\n            attributes = lastAttributes;\n          }\n          lastAttributes = attributes;\n          int pointDataDimensionCount = input.readVInt();\n          int pointNumBytes;\n          int pointIndexDimensionCount = pointDataDimensionCount;\n          if (pointDataDimensionCount != 0) {\n            if (version >= Lucene60FieldInfosFormat.FORMAT_SELECTIVE_INDEXING) {\n              pointIndexDimensionCount = input.readVInt();\n            }\n            pointNumBytes = input.readVInt();\n          } else {\n            pointNumBytes = 0;\n          }\n\n          try {\n            infos[i] = new FieldInfo(name, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, attributes,\n                                     pointDataDimensionCount, pointIndexDimensionCount, pointNumBytes, isSoftDeletesField);\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"cab7a79353f33d1a94cd307bf33aa5148601ebe6":["1eee4175312c41f89aa23427f9e4edfc00deeaac"],"f6652c943595e92c187ee904c382863013eae28f":["b7e4ca6dc9612ff741d8713743e2bccfae5eadac"],"ab548c8f96022b4780f7500a30b19b4f4a5feeb6":["eeba0a4d0845889a402dd225793d62f009d029c9"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b70042a8a492f7054d480ccdd2be9796510d4327":["cab7a79353f33d1a94cd307bf33aa5148601ebe6","b7e4ca6dc9612ff741d8713743e2bccfae5eadac"],"b7e4ca6dc9612ff741d8713743e2bccfae5eadac":["ab548c8f96022b4780f7500a30b19b4f4a5feeb6"],"eeba0a4d0845889a402dd225793d62f009d029c9":["cab7a79353f33d1a94cd307bf33aa5148601ebe6"],"1eee4175312c41f89aa23427f9e4edfc00deeaac":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"683b2041fcb490acd2bfec6034c593b3cfb2098c":["f6652c943595e92c187ee904c382863013eae28f"],"f592209545c71895260367152601e9200399776d":["ab548c8f96022b4780f7500a30b19b4f4a5feeb6","b7e4ca6dc9612ff741d8713743e2bccfae5eadac"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["683b2041fcb490acd2bfec6034c593b3cfb2098c"]},"commit2Childs":{"cab7a79353f33d1a94cd307bf33aa5148601ebe6":["b70042a8a492f7054d480ccdd2be9796510d4327","eeba0a4d0845889a402dd225793d62f009d029c9"],"f6652c943595e92c187ee904c382863013eae28f":["683b2041fcb490acd2bfec6034c593b3cfb2098c"],"ab548c8f96022b4780f7500a30b19b4f4a5feeb6":["b7e4ca6dc9612ff741d8713743e2bccfae5eadac","f592209545c71895260367152601e9200399776d"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["1eee4175312c41f89aa23427f9e4edfc00deeaac"],"b70042a8a492f7054d480ccdd2be9796510d4327":[],"1eee4175312c41f89aa23427f9e4edfc00deeaac":["cab7a79353f33d1a94cd307bf33aa5148601ebe6"],"b7e4ca6dc9612ff741d8713743e2bccfae5eadac":["f6652c943595e92c187ee904c382863013eae28f","b70042a8a492f7054d480ccdd2be9796510d4327","f592209545c71895260367152601e9200399776d"],"eeba0a4d0845889a402dd225793d62f009d029c9":["ab548c8f96022b4780f7500a30b19b4f4a5feeb6"],"683b2041fcb490acd2bfec6034c593b3cfb2098c":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"f592209545c71895260367152601e9200399776d":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["b70042a8a492f7054d480ccdd2be9796510d4327","f592209545c71895260367152601e9200399776d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}