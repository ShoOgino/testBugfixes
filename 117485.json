{"path":"sandbox/contributions/webcrawler-LARM/src/de/lanlab/larm/fetcher/FetcherMain#FetcherMain(int).mjava","commits":[{"id":"05d36e0b328ec96237035fbcca240e73631396e5","date":1020520725,"type":0,"author":"Otis Gospodnetic","isMerge":false,"pathNew":"sandbox/contributions/webcrawler-LARM/src/de/lanlab/larm/fetcher/FetcherMain#FetcherMain(int).mjava","pathOld":"/dev/null","sourceNew":"    /**\n     * initializes all classes and registers anonymous adapter classes as\n     * listeners for fetcher events.\n     *\n     * @param nrThreads  number of fetcher threads to be created\n     */\n    public FetcherMain(int nrThreads)\n    {\n        // to make things clear, this method is commented a bit better than\n        // the rest of the program...\n\n        // this is the main message queue. handlers are registered with\n        // the queue, and whenever a message is put in it, they are passed to the\n        // filters in a \"chain of responibility\" manner. Every listener can decide\n        // to throw the message away\n        messageHandler = new MessageHandler();\n\n        // the storage is the class which saves a WebDocument somewhere, no\n        // matter how it does it, whether it's in a file, in a database or\n        // whatever\n\n\n        // example for the (very slow) SQL Server storage:\n        // this.storage = new SQLServerStorage(\"sun.jdbc.odbc.JdbcOdbcDriver\",\"jdbc:odbc:search\",\"sa\",\"...\",nrThreads);\n\n        // the LogStorage used here does extensive logging. It logs all links and\n        // document information.\n        // it also saves all documents to page files. Probably this single storage\n        // could also be replaced by a pipeline; or even incorporated into the\n        // existing message pipeline\n        SimpleLogger log = new SimpleLogger(\"store\", false);\n        this.storage = new LogStorage(log, true, \"logs/pagefile\");\n\n        // a third example would be the NullStorage, which converts the documents into\n        // heat, which evaporates above the processor\n        // NullStorage();\n\n        // create the filters and add them to the message queue\n        urlScopeFilter = new URLScopeFilter();\n\n        urlVisitedFilter = new URLVisitedFilter(100000, log);\n\n        // dnsResolver = new DNSResolver();\n        hostManager = new HostManager(1000);\n\n        reFilter = new RobotExclusionFilter(hostManager);\n\n        fetcher = new Fetcher(nrThreads, storage, hostManager);\n\n        knownPathsFilter = new KnownPathsFilter();\n\n        urlLengthFilter = new URLLengthFilter(255);\n\n        // prevent message box popups\n        HTTPConnection.setDefaultAllowUserInteraction(false);\n\n        // prevent GZipped files from being decoded\n        HTTPConnection.removeDefaultModule(HTTPClient.ContentEncodingModule.class);\n\n        // initialize the threads\n        fetcher.init();\n\n        // the thread monitor watches the thread pool.\n\n        monitor = new ThreadMonitor(urlLengthFilter,\n                urlVisitedFilter,\n                urlScopeFilter,\n                /*dnsResolver,*/\n                reFilter,\n                messageHandler,\n                fetcher.getThreadPool(),\n                hostManager,\n                5000        // wake up every 5 seconds\n                );\n\n\n        // add all filters to the handler.\n        messageHandler.addListener(urlLengthFilter);\n        messageHandler.addListener(urlScopeFilter);\n        messageHandler.addListener(reFilter);\n        messageHandler.addListener(urlVisitedFilter);\n        messageHandler.addListener(knownPathsFilter);\n        messageHandler.addListener(fetcher);\n\n        /* uncomment this to enable HTTPClient logging\n        try\n        {\n            HTTPClient.Log.setLogWriter(new java.io.FileWriter(\"logs/HttpClient.log\"),false);\n            HTTPClient.Log.setLogging(HTTPClient.Log.ALL, true);\n        }\n        catch (Exception e)\n        {\n            e.printStackTrace();\n        }\n        */\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"21b526e3e9974b2651365fbae52a976e6fc77aa4","date":1022108962,"type":3,"author":"cmarschner","isMerge":false,"pathNew":"sandbox/contributions/webcrawler-LARM/src/de/lanlab/larm/fetcher/FetcherMain#FetcherMain(int).mjava","pathOld":"sandbox/contributions/webcrawler-LARM/src/de/lanlab/larm/fetcher/FetcherMain#FetcherMain(int).mjava","sourceNew":"    /**\n     * initializes all classes and registers anonymous adapter classes as\n     * listeners for fetcher events.\n     *\n     * @param nrThreads  number of fetcher threads to be created\n     */\n    public FetcherMain(int nrThreads)\n    {\n        // to make things clear, this method is commented a bit better than\n        // the rest of the program...\n\n        // this is the main message queue. handlers are registered with\n        // the queue, and whenever a message is put in it, they are passed to the\n        // filters in a \"chain of responibility\" manner. Every listener can decide\n        // to throw the message away\n        messageHandler = new MessageHandler();\n\n        // the storage is the class which saves a WebDocument somewhere, no\n        // matter how it does it, whether it's in a file, in a database or\n        // whatever\n\n\n        // example for the (very slow) SQL Server storage:\n        // this.storage = new SQLServerStorage(\"sun.jdbc.odbc.JdbcOdbcDriver\",\"jdbc:odbc:search\",\"sa\",\"...\",nrThreads);\n\n        // the LogStorage used here does extensive logging. It logs all links and\n        // document information.\n        // it also saves all documents to page files. Probably this single storage\n        // could also be replaced by a pipeline; or even incorporated into the\n        // existing message pipeline\n        SimpleLogger storeLog = new SimpleLogger(\"store\", false);\n        SimpleLogger linksLog = new SimpleLogger(\"links\", false);\n        this.storage = new LogStorage(storeLog, true, \"logs/pagefile\");\n\n        // a third example would be the NullStorage, which converts the documents into\n        // heat, which evaporates above the processor\n        // NullStorage();\n\n        // create the filters and add them to the message queue\n        urlScopeFilter = new URLScopeFilter();\n\n        urlVisitedFilter = new URLVisitedFilter(100000, linksLog);\n\n        // dnsResolver = new DNSResolver();\n        hostManager = new HostManager(1000);\n\n        reFilter = new RobotExclusionFilter(hostManager);\n\n        fetcher = new Fetcher(nrThreads, storage, hostManager);\n\n        knownPathsFilter = new KnownPathsFilter();\n\n        urlLengthFilter = new URLLengthFilter(255);\n\n        // prevent message box popups\n        HTTPConnection.setDefaultAllowUserInteraction(false);\n\n        // prevent GZipped files from being decoded\n        HTTPConnection.removeDefaultModule(HTTPClient.ContentEncodingModule.class);\n\n        // initialize the threads\n        fetcher.init();\n\n        // the thread monitor watches the thread pool.\n\n        monitor = new ThreadMonitor(urlLengthFilter,\n                urlVisitedFilter,\n                urlScopeFilter,\n                /*dnsResolver,*/\n                reFilter,\n                messageHandler,\n                fetcher.getThreadPool(),\n                hostManager,\n                5000        // wake up every 5 seconds\n                );\n\n\n        // add all filters to the handler.\n        messageHandler.addListener(urlLengthFilter);\n        messageHandler.addListener(urlScopeFilter);\n        messageHandler.addListener(reFilter);\n        messageHandler.addListener(urlVisitedFilter);\n        messageHandler.addListener(knownPathsFilter);\n        messageHandler.addListener(fetcher);\n\n        /* uncomment this to enable HTTPClient logging\n        try\n        {\n            HTTPClient.Log.setLogWriter(new java.io.FileWriter(\"logs/HttpClient.log\"),false);\n            HTTPClient.Log.setLogging(HTTPClient.Log.ALL, true);\n        }\n        catch (Exception e)\n        {\n            e.printStackTrace();\n        }\n        */\n    }\n\n","sourceOld":"    /**\n     * initializes all classes and registers anonymous adapter classes as\n     * listeners for fetcher events.\n     *\n     * @param nrThreads  number of fetcher threads to be created\n     */\n    public FetcherMain(int nrThreads)\n    {\n        // to make things clear, this method is commented a bit better than\n        // the rest of the program...\n\n        // this is the main message queue. handlers are registered with\n        // the queue, and whenever a message is put in it, they are passed to the\n        // filters in a \"chain of responibility\" manner. Every listener can decide\n        // to throw the message away\n        messageHandler = new MessageHandler();\n\n        // the storage is the class which saves a WebDocument somewhere, no\n        // matter how it does it, whether it's in a file, in a database or\n        // whatever\n\n\n        // example for the (very slow) SQL Server storage:\n        // this.storage = new SQLServerStorage(\"sun.jdbc.odbc.JdbcOdbcDriver\",\"jdbc:odbc:search\",\"sa\",\"...\",nrThreads);\n\n        // the LogStorage used here does extensive logging. It logs all links and\n        // document information.\n        // it also saves all documents to page files. Probably this single storage\n        // could also be replaced by a pipeline; or even incorporated into the\n        // existing message pipeline\n        SimpleLogger log = new SimpleLogger(\"store\", false);\n        this.storage = new LogStorage(log, true, \"logs/pagefile\");\n\n        // a third example would be the NullStorage, which converts the documents into\n        // heat, which evaporates above the processor\n        // NullStorage();\n\n        // create the filters and add them to the message queue\n        urlScopeFilter = new URLScopeFilter();\n\n        urlVisitedFilter = new URLVisitedFilter(100000, log);\n\n        // dnsResolver = new DNSResolver();\n        hostManager = new HostManager(1000);\n\n        reFilter = new RobotExclusionFilter(hostManager);\n\n        fetcher = new Fetcher(nrThreads, storage, hostManager);\n\n        knownPathsFilter = new KnownPathsFilter();\n\n        urlLengthFilter = new URLLengthFilter(255);\n\n        // prevent message box popups\n        HTTPConnection.setDefaultAllowUserInteraction(false);\n\n        // prevent GZipped files from being decoded\n        HTTPConnection.removeDefaultModule(HTTPClient.ContentEncodingModule.class);\n\n        // initialize the threads\n        fetcher.init();\n\n        // the thread monitor watches the thread pool.\n\n        monitor = new ThreadMonitor(urlLengthFilter,\n                urlVisitedFilter,\n                urlScopeFilter,\n                /*dnsResolver,*/\n                reFilter,\n                messageHandler,\n                fetcher.getThreadPool(),\n                hostManager,\n                5000        // wake up every 5 seconds\n                );\n\n\n        // add all filters to the handler.\n        messageHandler.addListener(urlLengthFilter);\n        messageHandler.addListener(urlScopeFilter);\n        messageHandler.addListener(reFilter);\n        messageHandler.addListener(urlVisitedFilter);\n        messageHandler.addListener(knownPathsFilter);\n        messageHandler.addListener(fetcher);\n\n        /* uncomment this to enable HTTPClient logging\n        try\n        {\n            HTTPClient.Log.setLogWriter(new java.io.FileWriter(\"logs/HttpClient.log\"),false);\n            HTTPClient.Log.setLogging(HTTPClient.Log.ALL, true);\n        }\n        catch (Exception e)\n        {\n            e.printStackTrace();\n        }\n        */\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"12c7634bf3bb6da687c9b32ca310e7fb8fac8e1e","date":1022957716,"type":3,"author":"cmarschner","isMerge":false,"pathNew":"sandbox/contributions/webcrawler-LARM/src/de/lanlab/larm/fetcher/FetcherMain#FetcherMain(int).mjava","pathOld":"sandbox/contributions/webcrawler-LARM/src/de/lanlab/larm/fetcher/FetcherMain#FetcherMain(int).mjava","sourceNew":"    /**\n     * initializes all classes and registers anonymous adapter classes as\n     * listeners for fetcher events.\n     *\n     * @param nrThreads  number of fetcher threads to be created\n     */\n    public FetcherMain(int nrThreads)\n    {\n        // to make things clear, this method is commented a bit better than\n        // the rest of the program...\n\n        // this is the main message queue. handlers are registered with\n        // the queue, and whenever a message is put in it, they are passed to the\n        // filters in a \"chain of responibility\" manner. Every listener can decide\n        // to throw the message away\n        messageHandler = new MessageHandler();\n\n        // the storage is the class which saves a WebDocument somewhere, no\n        // matter how it does it, whether it's in a file, in a database or\n        // whatever\n\n\n        // example for the (very slow) SQL Server storage:\n        // this.storage = new SQLServerStorage(\"sun.jdbc.odbc.JdbcOdbcDriver\",\"jdbc:odbc:search\",\"sa\",\"...\",nrThreads);\n\n        // the LogStorage used here does extensive logging. It logs all links and\n        // document information.\n        // it also saves all documents to page files. Probably this single storage\n        // could also be replaced by a pipeline; or even incorporated into the\n        // existing message pipeline\n        SimpleLogger storeLog = new SimpleLogger(\"store\", false);\n        SimpleLogger linksLog = new SimpleLogger(\"links\", false);\n\n\n        StoragePipeline storage = new StoragePipeline();\n        storage.addDocStorage(new LogStorage(storeLog, /* save in page files? */ false, /* logfile prefix */ \"logs/pagefile\"));\n        storage.addLinkStorage(new LinkLogStorage(linksLog));\n        storage.addLinkStorage(messageHandler);\n        //storage.addStorage(new LuceneStorage(...));\n        //storage.addStorage(new JMSStorage(...));\n\n        // a third example would be the NullStorage, which converts the documents into\n        // heat, which evaporates above the processor\n        // NullStorage();\n\n        // create the filters and add them to the message queue\n        urlScopeFilter = new URLScopeFilter();\n\n        urlVisitedFilter = new URLVisitedFilter(100000);\n\n        // dnsResolver = new DNSResolver();\n        hostManager = new HostManager(1000);\n\n        reFilter = new RobotExclusionFilter(hostManager);\n\n        fetcher = new Fetcher(nrThreads, storage, storage, hostManager);\n\n        knownPathsFilter = new KnownPathsFilter();\n\n        urlLengthFilter = new URLLengthFilter(255);\n\n        // prevent message box popups\n        HTTPConnection.setDefaultAllowUserInteraction(false);\n\n        // prevent GZipped files from being decoded\n        HTTPConnection.removeDefaultModule(HTTPClient.ContentEncodingModule.class);\n\n\n\n        // initialize the threads\n        fetcher.init();\n\n        // the thread monitor watches the thread pool.\n\n        monitor = new ThreadMonitor(urlLengthFilter,\n                urlVisitedFilter,\n                urlScopeFilter,\n                /*dnsResolver,*/\n                reFilter,\n                messageHandler,\n                fetcher.getThreadPool(),\n                hostManager,\n                5000        // wake up every 5 seconds\n                );\n\n\n        // add all filters to the handler.\n        messageHandler.addListener(urlLengthFilter);\n        messageHandler.addListener(urlScopeFilter);\n        messageHandler.addListener(reFilter);\n        messageHandler.addListener(urlVisitedFilter);\n        messageHandler.addListener(knownPathsFilter);\n        messageHandler.addListener(fetcher);\n\n        /* uncomment this to enable HTTPClient logging\n        try\n        {\n            HTTPClient.Log.setLogWriter(new java.io.FileWriter(\"logs/HttpClient.log\"),false);\n            HTTPClient.Log.setLogging(HTTPClient.Log.ALL, true);\n        }\n        catch (Exception e)\n        {\n            e.printStackTrace();\n        }\n        */\n    }\n\n","sourceOld":"    /**\n     * initializes all classes and registers anonymous adapter classes as\n     * listeners for fetcher events.\n     *\n     * @param nrThreads  number of fetcher threads to be created\n     */\n    public FetcherMain(int nrThreads)\n    {\n        // to make things clear, this method is commented a bit better than\n        // the rest of the program...\n\n        // this is the main message queue. handlers are registered with\n        // the queue, and whenever a message is put in it, they are passed to the\n        // filters in a \"chain of responibility\" manner. Every listener can decide\n        // to throw the message away\n        messageHandler = new MessageHandler();\n\n        // the storage is the class which saves a WebDocument somewhere, no\n        // matter how it does it, whether it's in a file, in a database or\n        // whatever\n\n\n        // example for the (very slow) SQL Server storage:\n        // this.storage = new SQLServerStorage(\"sun.jdbc.odbc.JdbcOdbcDriver\",\"jdbc:odbc:search\",\"sa\",\"...\",nrThreads);\n\n        // the LogStorage used here does extensive logging. It logs all links and\n        // document information.\n        // it also saves all documents to page files. Probably this single storage\n        // could also be replaced by a pipeline; or even incorporated into the\n        // existing message pipeline\n        SimpleLogger storeLog = new SimpleLogger(\"store\", false);\n        SimpleLogger linksLog = new SimpleLogger(\"links\", false);\n        this.storage = new LogStorage(storeLog, true, \"logs/pagefile\");\n\n        // a third example would be the NullStorage, which converts the documents into\n        // heat, which evaporates above the processor\n        // NullStorage();\n\n        // create the filters and add them to the message queue\n        urlScopeFilter = new URLScopeFilter();\n\n        urlVisitedFilter = new URLVisitedFilter(100000, linksLog);\n\n        // dnsResolver = new DNSResolver();\n        hostManager = new HostManager(1000);\n\n        reFilter = new RobotExclusionFilter(hostManager);\n\n        fetcher = new Fetcher(nrThreads, storage, hostManager);\n\n        knownPathsFilter = new KnownPathsFilter();\n\n        urlLengthFilter = new URLLengthFilter(255);\n\n        // prevent message box popups\n        HTTPConnection.setDefaultAllowUserInteraction(false);\n\n        // prevent GZipped files from being decoded\n        HTTPConnection.removeDefaultModule(HTTPClient.ContentEncodingModule.class);\n\n        // initialize the threads\n        fetcher.init();\n\n        // the thread monitor watches the thread pool.\n\n        monitor = new ThreadMonitor(urlLengthFilter,\n                urlVisitedFilter,\n                urlScopeFilter,\n                /*dnsResolver,*/\n                reFilter,\n                messageHandler,\n                fetcher.getThreadPool(),\n                hostManager,\n                5000        // wake up every 5 seconds\n                );\n\n\n        // add all filters to the handler.\n        messageHandler.addListener(urlLengthFilter);\n        messageHandler.addListener(urlScopeFilter);\n        messageHandler.addListener(reFilter);\n        messageHandler.addListener(urlVisitedFilter);\n        messageHandler.addListener(knownPathsFilter);\n        messageHandler.addListener(fetcher);\n\n        /* uncomment this to enable HTTPClient logging\n        try\n        {\n            HTTPClient.Log.setLogWriter(new java.io.FileWriter(\"logs/HttpClient.log\"),false);\n            HTTPClient.Log.setLogging(HTTPClient.Log.ALL, true);\n        }\n        catch (Exception e)\n        {\n            e.printStackTrace();\n        }\n        */\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e56132d241479de027bc013a7094c731e7bb581e","date":1024361110,"type":3,"author":"cmarschner","isMerge":false,"pathNew":"sandbox/contributions/webcrawler-LARM/src/de/lanlab/larm/fetcher/FetcherMain#FetcherMain(int).mjava","pathOld":"sandbox/contributions/webcrawler-LARM/src/de/lanlab/larm/fetcher/FetcherMain#FetcherMain(int).mjava","sourceNew":"    /**\n     * initializes all classes and registers anonymous adapter classes as\n     * listeners for fetcher events.\n     *\n     * @param nrThreads  number of fetcher threads to be created\n     */\n    public FetcherMain(int nrThreads)\n    {\n        // to make things clear, this method is commented a bit better than\n        // the rest of the program...\n\n        // this is the main message queue. handlers are registered with\n        // the queue, and whenever a message is put in it, they are passed to the\n        // filters in a \"chain of responibility\" manner. Every listener can decide\n        // to throw the message away\n        messageHandler = new MessageHandler();\n\n        // the storage is the class which saves a WebDocument somewhere, no\n        // matter how it does it, whether it's in a file, in a database or\n        // whatever\n\n\n        // example for the (very slow) SQL Server storage:\n        // this.storage = new SQLServerStorage(\"sun.jdbc.odbc.JdbcOdbcDriver\",\"jdbc:odbc:search\",\"sa\",\"...\",nrThreads);\n\n        // the LogStorage used here does extensive logging. It logs all links and\n        // document information.\n        // it also saves all documents to page files. Probably this single storage\n        // could also be replaced by a pipeline; or even incorporated into the\n        // existing message pipeline\n        SimpleLogger storeLog = new SimpleLogger(\"store\", false);\n        SimpleLogger linksLog = new SimpleLogger(\"links\", false);\n\n\n        StoragePipeline storage = new StoragePipeline();\n        //storage.addDocStorage(new LogStorage(storeLog, /* save in page files? */ false, /* logfile prefix */ \"logs/pagefile\"));\n        storage.addLinkStorage(new LinkLogStorage(linksLog));\n        storage.addLinkStorage(messageHandler);\n\n        LuceneStorage luceneStorage = new LuceneStorage();\n        luceneStorage.setAnalyzer(new org.apache.lucene.analysis.de.GermanAnalyzer());\n        luceneStorage.setCreate(true);\n        luceneStorage.setIndexName(\"luceneIndex\");\n        luceneStorage.setFieldInfo(\"url\", LuceneStorage.INDEX | LuceneStorage.STORE);\n        luceneStorage.setFieldInfo(\"content\", LuceneStorage.INDEX | LuceneStorage.STORE | LuceneStorage.TOKEN);\n        storage.addDocStorage(luceneStorage);\n        storage.open();\n\n        //storage.addStorage(new JMSStorage(...));\n\n        // a third example would be the NullStorage, which converts the documents into\n        // heat, which evaporates above the processor\n        // NullStorage();\n\n        // create the filters and add them to the message queue\n        urlScopeFilter = new URLScopeFilter();\n\n        urlVisitedFilter = new URLVisitedFilter(100000);\n\n        // dnsResolver = new DNSResolver();\n        hostManager = new HostManager(1000);\n\n        reFilter = new RobotExclusionFilter(hostManager);\n\n        fetcher = new Fetcher(nrThreads, storage, storage, hostManager);\n\n        knownPathsFilter = new KnownPathsFilter();\n\n        urlLengthFilter = new URLLengthFilter(255);\n\n        // prevent message box popups\n        HTTPConnection.setDefaultAllowUserInteraction(false);\n\n        // prevent GZipped files from being decoded\n        HTTPConnection.removeDefaultModule(HTTPClient.ContentEncodingModule.class);\n\n\n\n        // initialize the threads\n        fetcher.init();\n\n        // the thread monitor watches the thread pool.\n\n        monitor = new ThreadMonitor(urlLengthFilter,\n                urlVisitedFilter,\n                urlScopeFilter,\n                /*dnsResolver,*/\n                reFilter,\n                messageHandler,\n                fetcher.getThreadPool(),\n                hostManager,\n                5000        // wake up every 5 seconds\n                );\n\n\n        // add all filters to the handler.\n        messageHandler.addListener(urlLengthFilter);\n        messageHandler.addListener(urlScopeFilter);\n        messageHandler.addListener(reFilter);\n        messageHandler.addListener(urlVisitedFilter);\n        messageHandler.addListener(knownPathsFilter);\n        messageHandler.addListener(fetcher);\n\n        /* uncomment this to enable HTTPClient logging\n        try\n        {\n            HTTPClient.Log.setLogWriter(new java.io.FileWriter(\"logs/HttpClient.log\"),false);\n            HTTPClient.Log.setLogging(HTTPClient.Log.ALL, true);\n        }\n        catch (Exception e)\n        {\n            e.printStackTrace();\n        }\n        */\n    }\n\n","sourceOld":"    /**\n     * initializes all classes and registers anonymous adapter classes as\n     * listeners for fetcher events.\n     *\n     * @param nrThreads  number of fetcher threads to be created\n     */\n    public FetcherMain(int nrThreads)\n    {\n        // to make things clear, this method is commented a bit better than\n        // the rest of the program...\n\n        // this is the main message queue. handlers are registered with\n        // the queue, and whenever a message is put in it, they are passed to the\n        // filters in a \"chain of responibility\" manner. Every listener can decide\n        // to throw the message away\n        messageHandler = new MessageHandler();\n\n        // the storage is the class which saves a WebDocument somewhere, no\n        // matter how it does it, whether it's in a file, in a database or\n        // whatever\n\n\n        // example for the (very slow) SQL Server storage:\n        // this.storage = new SQLServerStorage(\"sun.jdbc.odbc.JdbcOdbcDriver\",\"jdbc:odbc:search\",\"sa\",\"...\",nrThreads);\n\n        // the LogStorage used here does extensive logging. It logs all links and\n        // document information.\n        // it also saves all documents to page files. Probably this single storage\n        // could also be replaced by a pipeline; or even incorporated into the\n        // existing message pipeline\n        SimpleLogger storeLog = new SimpleLogger(\"store\", false);\n        SimpleLogger linksLog = new SimpleLogger(\"links\", false);\n\n\n        StoragePipeline storage = new StoragePipeline();\n        storage.addDocStorage(new LogStorage(storeLog, /* save in page files? */ false, /* logfile prefix */ \"logs/pagefile\"));\n        storage.addLinkStorage(new LinkLogStorage(linksLog));\n        storage.addLinkStorage(messageHandler);\n        //storage.addStorage(new LuceneStorage(...));\n        //storage.addStorage(new JMSStorage(...));\n\n        // a third example would be the NullStorage, which converts the documents into\n        // heat, which evaporates above the processor\n        // NullStorage();\n\n        // create the filters and add them to the message queue\n        urlScopeFilter = new URLScopeFilter();\n\n        urlVisitedFilter = new URLVisitedFilter(100000);\n\n        // dnsResolver = new DNSResolver();\n        hostManager = new HostManager(1000);\n\n        reFilter = new RobotExclusionFilter(hostManager);\n\n        fetcher = new Fetcher(nrThreads, storage, storage, hostManager);\n\n        knownPathsFilter = new KnownPathsFilter();\n\n        urlLengthFilter = new URLLengthFilter(255);\n\n        // prevent message box popups\n        HTTPConnection.setDefaultAllowUserInteraction(false);\n\n        // prevent GZipped files from being decoded\n        HTTPConnection.removeDefaultModule(HTTPClient.ContentEncodingModule.class);\n\n\n\n        // initialize the threads\n        fetcher.init();\n\n        // the thread monitor watches the thread pool.\n\n        monitor = new ThreadMonitor(urlLengthFilter,\n                urlVisitedFilter,\n                urlScopeFilter,\n                /*dnsResolver,*/\n                reFilter,\n                messageHandler,\n                fetcher.getThreadPool(),\n                hostManager,\n                5000        // wake up every 5 seconds\n                );\n\n\n        // add all filters to the handler.\n        messageHandler.addListener(urlLengthFilter);\n        messageHandler.addListener(urlScopeFilter);\n        messageHandler.addListener(reFilter);\n        messageHandler.addListener(urlVisitedFilter);\n        messageHandler.addListener(knownPathsFilter);\n        messageHandler.addListener(fetcher);\n\n        /* uncomment this to enable HTTPClient logging\n        try\n        {\n            HTTPClient.Log.setLogWriter(new java.io.FileWriter(\"logs/HttpClient.log\"),false);\n            HTTPClient.Log.setLogging(HTTPClient.Log.ALL, true);\n        }\n        catch (Exception e)\n        {\n            e.printStackTrace();\n        }\n        */\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2a383cc27dffe14c5d655eb57a87a1c7ae80b23a","date":1032050294,"type":3,"author":"Otis Gospodnetic","isMerge":false,"pathNew":"sandbox/contributions/webcrawler-LARM/src/de/lanlab/larm/fetcher/FetcherMain#FetcherMain(int).mjava","pathOld":"sandbox/contributions/webcrawler-LARM/src/de/lanlab/larm/fetcher/FetcherMain#FetcherMain(int).mjava","sourceNew":"    /**\n     * initializes all classes and registers anonymous adapter classes as\n     * listeners for fetcher events.\n     *\n     * @param nrThreads  number of fetcher threads to be created\n     */\n    private FetcherMain(int nrThreads)\n    {\n        // to make things clear, this method is commented a bit better than\n        // the rest of the program...\n\n        // this is the main message queue. handlers are registered with\n        // the queue, and whenever a message is put in it, the message is passed to the\n        // filters in a \"chain of responibility\" manner. Every listener can decide\n        // to throw the message away\n        messageHandler = new MessageHandler();\n\n        // the storage is the class which saves a WebDocument somewhere, no\n        // matter how it does it, whether it's in a file, in a database or\n        // whatever\n\n        // example for the (very slow) SQL Server storage:\n        // this.storage = new SQLServerStorage(\"sun.jdbc.odbc.JdbcOdbcDriver\",\"jdbc:odbc:search\",\"sa\",\"...\",nrThreads);\n\n        // the LogStorage used here does extensive logging. It logs all links and\n        // document information.\n        // it also saves all documents to page files. Probably this single storage\n        // could also be replaced by a pipeline; or even incorporated into the\n        // existing message pipeline\n        SimpleLogger storeLog = new SimpleLogger(\"store\", false);\n        SimpleLogger linksLog = new SimpleLogger(\"links\", false);\n\n\n        StoragePipeline storage = new StoragePipeline();\n        //storage.addDocStorage(new LogStorage(storeLog, /* save in page files? */ false, /* logfile prefix */ \"logs/pagefile\"));\n        storage.addLinkStorage(new LinkLogStorage(linksLog));\n        storage.addLinkStorage(messageHandler);\n\n        LuceneStorage luceneStorage = new LuceneStorage();\n        luceneStorage.setAnalyzer(new org.apache.lucene.analysis.de.GermanAnalyzer());\n        luceneStorage.setCreate(true);\n\t// FIXME: index name and path need to be configurable\n        luceneStorage.setIndexName(\"luceneIndex\");\n        luceneStorage.setFieldInfo(\"url\", LuceneStorage.INDEX | LuceneStorage.STORE);\n        luceneStorage.setFieldInfo(\"content\", LuceneStorage.INDEX | LuceneStorage.STORE | LuceneStorage.TOKEN);\n        storage.addDocStorage(luceneStorage);\n        storage.open();\n\n        //storage.addStorage(new JMSStorage(...));\n\n        // a third example would be the NullStorage, which converts the documents into\n        // heat, which evaporates above the processor\n        // NullStorage();\n\n        hostManager = new HostManager(1000);\n\n        // create the filters and add them to the message queue\n        reFilter = new RobotExclusionFilter(hostManager);\n        urlScopeFilter = new URLScopeFilter();\n        urlVisitedFilter = new URLVisitedFilter(100000);\n        knownPathsFilter = new KnownPathsFilter();\n        urlLengthFilter = new URLLengthFilter(255);\n\n        // dnsResolver = new DNSResolver();\n        fetcher = new Fetcher(nrThreads, storage, storage, hostManager);\n\n        // prevent message box popups\n        HTTPConnection.setDefaultAllowUserInteraction(false);\n\n        // prevent GZipped files from being decoded\n        HTTPConnection.removeDefaultModule(HTTPClient.ContentEncodingModule.class);\n\n        // initialize the threads\n        fetcher.init();\n\n        // the thread monitor watches the thread pool.\n\n        monitor = new ThreadMonitor(urlLengthFilter,\n                urlVisitedFilter,\n                urlScopeFilter,\n                /*dnsResolver,*/\n                reFilter,\n                messageHandler,\n                fetcher.getThreadPool(),\n                hostManager,\n                5000        // wake up every 5 seconds\n                );\n\n\n        // add all filters to the handler.\n        messageHandler.addListener(urlLengthFilter);\n        messageHandler.addListener(urlScopeFilter);\n        messageHandler.addListener(reFilter);\n        messageHandler.addListener(urlVisitedFilter);\n        messageHandler.addListener(knownPathsFilter);\n        messageHandler.addListener(fetcher);\n\n        /* uncomment this to enable HTTPClient logging\n        try\n        {\n            HTTPClient.Log.setLogWriter(new java.io.FileWriter(\"logs/HttpClient.log\"),false);\n            HTTPClient.Log.setLogging(HTTPClient.Log.ALL, true);\n        }\n        catch (Exception e)\n        {\n            e.printStackTrace();\n        }\n        */\n    }\n\n","sourceOld":"    /**\n     * initializes all classes and registers anonymous adapter classes as\n     * listeners for fetcher events.\n     *\n     * @param nrThreads  number of fetcher threads to be created\n     */\n    public FetcherMain(int nrThreads)\n    {\n        // to make things clear, this method is commented a bit better than\n        // the rest of the program...\n\n        // this is the main message queue. handlers are registered with\n        // the queue, and whenever a message is put in it, they are passed to the\n        // filters in a \"chain of responibility\" manner. Every listener can decide\n        // to throw the message away\n        messageHandler = new MessageHandler();\n\n        // the storage is the class which saves a WebDocument somewhere, no\n        // matter how it does it, whether it's in a file, in a database or\n        // whatever\n\n\n        // example for the (very slow) SQL Server storage:\n        // this.storage = new SQLServerStorage(\"sun.jdbc.odbc.JdbcOdbcDriver\",\"jdbc:odbc:search\",\"sa\",\"...\",nrThreads);\n\n        // the LogStorage used here does extensive logging. It logs all links and\n        // document information.\n        // it also saves all documents to page files. Probably this single storage\n        // could also be replaced by a pipeline; or even incorporated into the\n        // existing message pipeline\n        SimpleLogger storeLog = new SimpleLogger(\"store\", false);\n        SimpleLogger linksLog = new SimpleLogger(\"links\", false);\n\n\n        StoragePipeline storage = new StoragePipeline();\n        //storage.addDocStorage(new LogStorage(storeLog, /* save in page files? */ false, /* logfile prefix */ \"logs/pagefile\"));\n        storage.addLinkStorage(new LinkLogStorage(linksLog));\n        storage.addLinkStorage(messageHandler);\n\n        LuceneStorage luceneStorage = new LuceneStorage();\n        luceneStorage.setAnalyzer(new org.apache.lucene.analysis.de.GermanAnalyzer());\n        luceneStorage.setCreate(true);\n        luceneStorage.setIndexName(\"luceneIndex\");\n        luceneStorage.setFieldInfo(\"url\", LuceneStorage.INDEX | LuceneStorage.STORE);\n        luceneStorage.setFieldInfo(\"content\", LuceneStorage.INDEX | LuceneStorage.STORE | LuceneStorage.TOKEN);\n        storage.addDocStorage(luceneStorage);\n        storage.open();\n\n        //storage.addStorage(new JMSStorage(...));\n\n        // a third example would be the NullStorage, which converts the documents into\n        // heat, which evaporates above the processor\n        // NullStorage();\n\n        // create the filters and add them to the message queue\n        urlScopeFilter = new URLScopeFilter();\n\n        urlVisitedFilter = new URLVisitedFilter(100000);\n\n        // dnsResolver = new DNSResolver();\n        hostManager = new HostManager(1000);\n\n        reFilter = new RobotExclusionFilter(hostManager);\n\n        fetcher = new Fetcher(nrThreads, storage, storage, hostManager);\n\n        knownPathsFilter = new KnownPathsFilter();\n\n        urlLengthFilter = new URLLengthFilter(255);\n\n        // prevent message box popups\n        HTTPConnection.setDefaultAllowUserInteraction(false);\n\n        // prevent GZipped files from being decoded\n        HTTPConnection.removeDefaultModule(HTTPClient.ContentEncodingModule.class);\n\n\n\n        // initialize the threads\n        fetcher.init();\n\n        // the thread monitor watches the thread pool.\n\n        monitor = new ThreadMonitor(urlLengthFilter,\n                urlVisitedFilter,\n                urlScopeFilter,\n                /*dnsResolver,*/\n                reFilter,\n                messageHandler,\n                fetcher.getThreadPool(),\n                hostManager,\n                5000        // wake up every 5 seconds\n                );\n\n\n        // add all filters to the handler.\n        messageHandler.addListener(urlLengthFilter);\n        messageHandler.addListener(urlScopeFilter);\n        messageHandler.addListener(reFilter);\n        messageHandler.addListener(urlVisitedFilter);\n        messageHandler.addListener(knownPathsFilter);\n        messageHandler.addListener(fetcher);\n\n        /* uncomment this to enable HTTPClient logging\n        try\n        {\n            HTTPClient.Log.setLogWriter(new java.io.FileWriter(\"logs/HttpClient.log\"),false);\n            HTTPClient.Log.setLogging(HTTPClient.Log.ALL, true);\n        }\n        catch (Exception e)\n        {\n            e.printStackTrace();\n        }\n        */\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2b24dfe829236e25670a0fb6bd671abc4e2a91f9","date":1035299107,"type":5,"author":"cmarschner","isMerge":false,"pathNew":"sandbox/contributions/webcrawler-LARM/src/de/lanlab/larm/fetcher/FetcherMain#FetcherMain(int,String).mjava","pathOld":"sandbox/contributions/webcrawler-LARM/src/de/lanlab/larm/fetcher/FetcherMain#FetcherMain(int).mjava","sourceNew":"    /**\n     * initializes all classes and registers anonymous adapter classes as\n     * listeners for fetcher events.\n     *\n     * @param nrThreads  number of fetcher threads to be created\n     */\n    public FetcherMain(int nrThreads, String hostResolverFile) throws Exception\n    {\n        // to make things clear, this method is commented a bit better than\n        // the rest of the program...\n\n        // this is the main message queue. handlers are registered with\n        // the queue, and whenever a message is put in it, the message is passed to the\n        // filters in a \"chain of responibility\" manner. Every listener can decide\n        // to throw the message away\n        messageHandler = new MessageHandler();\n\n        // the storage is the class which saves a WebDocument somewhere, no\n        // matter how it does it, whether it's in a file, in a database or\n        // whatever\n\n        // example for the (very slow) SQL Server storage:\n        // this.storage = new SQLServerStorage(\"sun.jdbc.odbc.JdbcOdbcDriver\",\"jdbc:odbc:search\",\"sa\",\"...\",nrThreads);\n\n        // the LogStorage used here does extensive logging. It logs all links and\n        // document information.\n        // it also saves all documents to page files.\n        File logsDir = new File(\"logs\");\n        logsDir.mkdir();    // ensure log directory exists\n\n        // in this experimental implementation, the crawler is pretty verbose\n        // the SimpleLogger, however, is a FlyWeight logger which is buffered and\n        // not thread safe by default\n        SimpleLogger storeLog = new SimpleLogger(\"store\", /* add date/time? */ false);\n        SimpleLogger visitedLog = new SimpleLogger(\"URLVisitedFilter\", /* add date/time? */ false);\n        SimpleLogger scopeLog = new SimpleLogger(\"URLScopeFilter\", /* add date/time? */ false);\n        SimpleLogger pathsLog = new SimpleLogger(\"KnownPathsFilter\", /* add date/time? */ false);\n        SimpleLogger linksLog = new SimpleLogger(\"links\", /* add date/time? */ false);\n        SimpleLogger lengthLog = new SimpleLogger(\"length\", /* add date/time? */ false);\n\n        StoragePipeline storage = new StoragePipeline();\n\n\n        // in the default configuration, the crawler will only save the document\n        // information to store.log and the link information to links.log\n        // The contents of the files are _not_ saved. If you set\n        // \"save in page files\" to \"true\", they will be saved in \"page files\",\n        // binary files each containing a set of documents. Here, the\n        // maximum file size is ~50 MB (crawled files won't be split up into different\n        // files). The logs/store.log file contains pointers to these files: a page\n        // file number, the offset within that file, and the document's length\n\n        // FIXME: default constructor for all storages + bean access methods\n        storage.addDocStorage(new LogStorage(storeLog, /* save in page files? */ false,\n                                             /* page file prefix */ \"logs/pagefile\"));\n        storage.addLinkStorage(new LinkLogStorage(linksLog));\n        storage.addLinkStorage(messageHandler);\n        /*\n        // experimental Lucene storage. will slow the crawler down *a lot*\n        LuceneStorage luceneStorage = new LuceneStorage();\n        luceneStorage.setAnalyzer(new org.apache.lucene.analysis.de.GermanAnalyzer());\n        luceneStorage.setCreate(true);\n\t// FIXME: index name and path need to be configurable\n        luceneStorage.setIndexName(\"luceneIndex\");\n        // the field names come from URLMessage.java and WebDocument.java. See\n        // LuceneStorage source for details\n        luceneStorage.setFieldInfo(\"url\", LuceneStorage.INDEX | LuceneStorage.STORE);\n        luceneStorage.setFieldInfo(\"content\", LuceneStorage.INDEX | LuceneStorage.STORE | LuceneStorage.TOKEN);\n        storage.addDocStorage(luceneStorage);\n        */\n\n        storage.open();\n\n        //storage.addStorage(new JMSStorage(...));\n\n        // create the filters and add them to the message queue\n        urlScopeFilter = new URLScopeFilter(scopeLog);\n\n        // dnsResolver = new DNSResolver();\n        hostManager = new HostManager(1000);\n        hostResolver = new HostResolver();\n        hostResolver.initFromFile(hostResolverFile);\n        hostManager.setHostResolver(hostResolver);\n\n//        hostManager.addSynonym(\"www.fachsprachen.uni-muenchen.de\", \"www.fremdsprachen.uni-muenchen.de\");\n//        hostManager.addSynonym(\"www.uni-muenchen.de\", \"www.lmu.de\");\n//        hostManager.addSynonym(\"www.uni-muenchen.de\", \"uni-muenchen.de\");\n//        hostManager.addSynonym(\"webinfo.uni-muenchen.de\", \"www.webinfo.uni-muenchen.de\");\n//        hostManager.addSynonym(\"webinfo.uni-muenchen.de\", \"webinfo.campus.lmu.de\");\n//        hostManager.addSynonym(\"www.s-a.uni-muenchen.de\", \"s-a.uni-muenchen.de\");\n\n        reFilter = new RobotExclusionFilter(hostManager);\n\n        fetcher = new Fetcher(nrThreads, storage, storage, hostManager);\n\n        // prevent message box popups\n        HTTPConnection.setDefaultAllowUserInteraction(false);\n\n        // prevent GZipped files from being decoded\n        HTTPConnection.removeDefaultModule(HTTPClient.ContentEncodingModule.class);\n\n        urlVisitedFilter = new URLVisitedFilter(visitedLog, 100000);\n\n        // initialize the threads\n        fetcher.init();\n\n        // the thread monitor watches the thread pool.\n\n        monitor = new ThreadMonitor(urlLengthFilter,\n                urlVisitedFilter,\n                urlScopeFilter,\n                /*dnsResolver,*/\n                reFilter,\n                messageHandler,\n                fetcher.getThreadPool(),\n                hostManager,\n                5000        // wake up every 5 seconds\n                );\n\n\n        // add all filters to the handler.\n        messageHandler.addListener(urlLengthFilter);\n        messageHandler.addListener(urlScopeFilter);\n        messageHandler.addListener(reFilter);\n        messageHandler.addListener(urlVisitedFilter);\n        messageHandler.addListener(knownPathsFilter);\n\n        messageHandler.addListener(fetcher);\n\n         //uncomment this to enable HTTPClient logging\n        /*\n        try\n        {\n            HTTPClient.Log.setLogWriter(new java.io.OutputStreamWriter(System.out) //new java.io.FileWriter(\"logs/HttpClient.log\")\n            ,false);\n            HTTPClient.Log.setLogging(HTTPClient.Log.ALL, true);\n        }\n        catch (Exception e)\n        {\n            e.printStackTrace();\n        }\n        */\n\n    }\n\n","sourceOld":"    /**\n     * initializes all classes and registers anonymous adapter classes as\n     * listeners for fetcher events.\n     *\n     * @param nrThreads  number of fetcher threads to be created\n     */\n    private FetcherMain(int nrThreads)\n    {\n        // to make things clear, this method is commented a bit better than\n        // the rest of the program...\n\n        // this is the main message queue. handlers are registered with\n        // the queue, and whenever a message is put in it, the message is passed to the\n        // filters in a \"chain of responibility\" manner. Every listener can decide\n        // to throw the message away\n        messageHandler = new MessageHandler();\n\n        // the storage is the class which saves a WebDocument somewhere, no\n        // matter how it does it, whether it's in a file, in a database or\n        // whatever\n\n        // example for the (very slow) SQL Server storage:\n        // this.storage = new SQLServerStorage(\"sun.jdbc.odbc.JdbcOdbcDriver\",\"jdbc:odbc:search\",\"sa\",\"...\",nrThreads);\n\n        // the LogStorage used here does extensive logging. It logs all links and\n        // document information.\n        // it also saves all documents to page files. Probably this single storage\n        // could also be replaced by a pipeline; or even incorporated into the\n        // existing message pipeline\n        SimpleLogger storeLog = new SimpleLogger(\"store\", false);\n        SimpleLogger linksLog = new SimpleLogger(\"links\", false);\n\n\n        StoragePipeline storage = new StoragePipeline();\n        //storage.addDocStorage(new LogStorage(storeLog, /* save in page files? */ false, /* logfile prefix */ \"logs/pagefile\"));\n        storage.addLinkStorage(new LinkLogStorage(linksLog));\n        storage.addLinkStorage(messageHandler);\n\n        LuceneStorage luceneStorage = new LuceneStorage();\n        luceneStorage.setAnalyzer(new org.apache.lucene.analysis.de.GermanAnalyzer());\n        luceneStorage.setCreate(true);\n\t// FIXME: index name and path need to be configurable\n        luceneStorage.setIndexName(\"luceneIndex\");\n        luceneStorage.setFieldInfo(\"url\", LuceneStorage.INDEX | LuceneStorage.STORE);\n        luceneStorage.setFieldInfo(\"content\", LuceneStorage.INDEX | LuceneStorage.STORE | LuceneStorage.TOKEN);\n        storage.addDocStorage(luceneStorage);\n        storage.open();\n\n        //storage.addStorage(new JMSStorage(...));\n\n        // a third example would be the NullStorage, which converts the documents into\n        // heat, which evaporates above the processor\n        // NullStorage();\n\n        hostManager = new HostManager(1000);\n\n        // create the filters and add them to the message queue\n        reFilter = new RobotExclusionFilter(hostManager);\n        urlScopeFilter = new URLScopeFilter();\n        urlVisitedFilter = new URLVisitedFilter(100000);\n        knownPathsFilter = new KnownPathsFilter();\n        urlLengthFilter = new URLLengthFilter(255);\n\n        // dnsResolver = new DNSResolver();\n        fetcher = new Fetcher(nrThreads, storage, storage, hostManager);\n\n        // prevent message box popups\n        HTTPConnection.setDefaultAllowUserInteraction(false);\n\n        // prevent GZipped files from being decoded\n        HTTPConnection.removeDefaultModule(HTTPClient.ContentEncodingModule.class);\n\n        // initialize the threads\n        fetcher.init();\n\n        // the thread monitor watches the thread pool.\n\n        monitor = new ThreadMonitor(urlLengthFilter,\n                urlVisitedFilter,\n                urlScopeFilter,\n                /*dnsResolver,*/\n                reFilter,\n                messageHandler,\n                fetcher.getThreadPool(),\n                hostManager,\n                5000        // wake up every 5 seconds\n                );\n\n\n        // add all filters to the handler.\n        messageHandler.addListener(urlLengthFilter);\n        messageHandler.addListener(urlScopeFilter);\n        messageHandler.addListener(reFilter);\n        messageHandler.addListener(urlVisitedFilter);\n        messageHandler.addListener(knownPathsFilter);\n        messageHandler.addListener(fetcher);\n\n        /* uncomment this to enable HTTPClient logging\n        try\n        {\n            HTTPClient.Log.setLogWriter(new java.io.FileWriter(\"logs/HttpClient.log\"),false);\n            HTTPClient.Log.setLogging(HTTPClient.Log.ALL, true);\n        }\n        catch (Exception e)\n        {\n            e.printStackTrace();\n        }\n        */\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"e56132d241479de027bc013a7094c731e7bb581e":["12c7634bf3bb6da687c9b32ca310e7fb8fac8e1e"],"12c7634bf3bb6da687c9b32ca310e7fb8fac8e1e":["21b526e3e9974b2651365fbae52a976e6fc77aa4"],"2b24dfe829236e25670a0fb6bd671abc4e2a91f9":["2a383cc27dffe14c5d655eb57a87a1c7ae80b23a"],"2a383cc27dffe14c5d655eb57a87a1c7ae80b23a":["e56132d241479de027bc013a7094c731e7bb581e"],"21b526e3e9974b2651365fbae52a976e6fc77aa4":["05d36e0b328ec96237035fbcca240e73631396e5"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"05d36e0b328ec96237035fbcca240e73631396e5":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["2b24dfe829236e25670a0fb6bd671abc4e2a91f9"]},"commit2Childs":{"e56132d241479de027bc013a7094c731e7bb581e":["2a383cc27dffe14c5d655eb57a87a1c7ae80b23a"],"12c7634bf3bb6da687c9b32ca310e7fb8fac8e1e":["e56132d241479de027bc013a7094c731e7bb581e"],"2b24dfe829236e25670a0fb6bd671abc4e2a91f9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"2a383cc27dffe14c5d655eb57a87a1c7ae80b23a":["2b24dfe829236e25670a0fb6bd671abc4e2a91f9"],"21b526e3e9974b2651365fbae52a976e6fc77aa4":["12c7634bf3bb6da687c9b32ca310e7fb8fac8e1e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["05d36e0b328ec96237035fbcca240e73631396e5"],"05d36e0b328ec96237035fbcca240e73631396e5":["21b526e3e9974b2651365fbae52a976e6fc77aa4"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}