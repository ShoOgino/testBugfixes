{"path":"lucene/core/src/java/org/apache/lucene/search/PhraseQuery.PhraseWeight#scorer(LeafReaderContext).mjava","commits":[{"id":"0f4464508ee83288c8c4585b533f9faaa93aa314","date":1435240759,"type":1,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/PhraseQuery.PhraseWeight#scorer(LeafReaderContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/PhraseQuery.PhraseWeight#scorer(LeafReaderContext,Bits).mjava","sourceNew":"    @Override\n    public Scorer scorer(LeafReaderContext context) throws IOException {\n      assert terms.length > 0;\n      final LeafReader reader = context.reader();\n      PostingsAndFreq[] postingsFreqs = new PostingsAndFreq[terms.length];\n\n      final Terms fieldTerms = reader.terms(field);\n      if (fieldTerms == null) {\n        return null;\n      }\n\n      if (fieldTerms.hasPositions() == false) {\n        throw new IllegalStateException(\"field \\\"\" + field + \"\\\" was indexed without position data; cannot run PhraseQuery (phrase=\" + getQuery() + \")\");\n      }\n\n      // Reuse single TermsEnum below:\n      final TermsEnum te = fieldTerms.iterator();\n      \n      for (int i = 0; i < terms.length; i++) {\n        final Term t = terms[i];\n        final TermState state = states[i].get(context.ord);\n        if (state == null) { /* term doesnt exist in this segment */\n          assert termNotInReader(reader, t): \"no termstate found but term exists in reader\";\n          return null;\n        }\n        te.seekExact(t.bytes(), state);\n        PostingsEnum postingsEnum = te.postings(null, PostingsEnum.POSITIONS);\n        postingsFreqs[i] = new PostingsAndFreq(postingsEnum, positions[i], t);\n      }\n\n      // sort by increasing docFreq order\n      if (slop == 0) {\n        ArrayUtil.timSort(postingsFreqs);\n      }\n\n      if (slop == 0) {  // optimize exact case\n        return new ExactPhraseScorer(this, postingsFreqs, similarity.simScorer(stats, context), needsScores);\n      } else {\n        return new SloppyPhraseScorer(this, postingsFreqs, slop, similarity.simScorer(stats, context), needsScores);\n      }\n    }\n\n","sourceOld":"    @Override\n    public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {\n      assert terms.length > 0;\n      final LeafReader reader = context.reader();\n      final Bits liveDocs = acceptDocs;\n      PostingsAndFreq[] postingsFreqs = new PostingsAndFreq[terms.length];\n\n      final Terms fieldTerms = reader.terms(field);\n      if (fieldTerms == null) {\n        return null;\n      }\n\n      if (fieldTerms.hasPositions() == false) {\n        throw new IllegalStateException(\"field \\\"\" + field + \"\\\" was indexed without position data; cannot run PhraseQuery (phrase=\" + getQuery() + \")\");\n      }\n\n      // Reuse single TermsEnum below:\n      final TermsEnum te = fieldTerms.iterator();\n      \n      for (int i = 0; i < terms.length; i++) {\n        final Term t = terms[i];\n        final TermState state = states[i].get(context.ord);\n        if (state == null) { /* term doesnt exist in this segment */\n          assert termNotInReader(reader, t): \"no termstate found but term exists in reader\";\n          return null;\n        }\n        te.seekExact(t.bytes(), state);\n        PostingsEnum postingsEnum = te.postings(liveDocs, null, PostingsEnum.POSITIONS);\n        postingsFreqs[i] = new PostingsAndFreq(postingsEnum, positions[i], t);\n      }\n\n      // sort by increasing docFreq order\n      if (slop == 0) {\n        ArrayUtil.timSort(postingsFreqs);\n      }\n\n      if (slop == 0) {  // optimize exact case\n        return new ExactPhraseScorer(this, postingsFreqs, similarity.simScorer(stats, context), needsScores);\n      } else {\n        return new SloppyPhraseScorer(this, postingsFreqs, slop, similarity.simScorer(stats, context), needsScores);\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d277693481ea6007c1d83cd503d0859bb3b64d20","date":1447445281,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/PhraseQuery.PhraseWeight#scorer(LeafReaderContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/PhraseQuery.PhraseWeight#scorer(LeafReaderContext).mjava","sourceNew":"    @Override\n    public Scorer scorer(LeafReaderContext context) throws IOException {\n      assert terms.length > 0;\n      final LeafReader reader = context.reader();\n      PostingsAndFreq[] postingsFreqs = new PostingsAndFreq[terms.length];\n\n      final Terms fieldTerms = reader.terms(field);\n      if (fieldTerms == null) {\n        return null;\n      }\n\n      if (fieldTerms.hasPositions() == false) {\n        throw new IllegalStateException(\"field \\\"\" + field + \"\\\" was indexed without position data; cannot run PhraseQuery (phrase=\" + getQuery() + \")\");\n      }\n\n      // Reuse single TermsEnum below:\n      final TermsEnum te = fieldTerms.iterator();\n      float totalMatchCost = 0;\n      \n      for (int i = 0; i < terms.length; i++) {\n        final Term t = terms[i];\n        final TermState state = states[i].get(context.ord);\n        if (state == null) { /* term doesnt exist in this segment */\n          assert termNotInReader(reader, t): \"no termstate found but term exists in reader\";\n          return null;\n        }\n        te.seekExact(t.bytes(), state);\n        PostingsEnum postingsEnum = te.postings(null, PostingsEnum.POSITIONS);\n        postingsFreqs[i] = new PostingsAndFreq(postingsEnum, positions[i], t);\n        totalMatchCost += termPositionsCost(te);\n      }\n\n      // sort by increasing docFreq order\n      if (slop == 0) {\n        ArrayUtil.timSort(postingsFreqs);\n      }\n\n      if (slop == 0) {  // optimize exact case\n        return new ExactPhraseScorer(this, postingsFreqs,\n                                      similarity.simScorer(stats, context),\n                                      needsScores, totalMatchCost);\n      } else {\n        return new SloppyPhraseScorer(this, postingsFreqs, slop,\n                                        similarity.simScorer(stats, context),\n                                        needsScores, totalMatchCost);\n      }\n    }\n\n","sourceOld":"    @Override\n    public Scorer scorer(LeafReaderContext context) throws IOException {\n      assert terms.length > 0;\n      final LeafReader reader = context.reader();\n      PostingsAndFreq[] postingsFreqs = new PostingsAndFreq[terms.length];\n\n      final Terms fieldTerms = reader.terms(field);\n      if (fieldTerms == null) {\n        return null;\n      }\n\n      if (fieldTerms.hasPositions() == false) {\n        throw new IllegalStateException(\"field \\\"\" + field + \"\\\" was indexed without position data; cannot run PhraseQuery (phrase=\" + getQuery() + \")\");\n      }\n\n      // Reuse single TermsEnum below:\n      final TermsEnum te = fieldTerms.iterator();\n      \n      for (int i = 0; i < terms.length; i++) {\n        final Term t = terms[i];\n        final TermState state = states[i].get(context.ord);\n        if (state == null) { /* term doesnt exist in this segment */\n          assert termNotInReader(reader, t): \"no termstate found but term exists in reader\";\n          return null;\n        }\n        te.seekExact(t.bytes(), state);\n        PostingsEnum postingsEnum = te.postings(null, PostingsEnum.POSITIONS);\n        postingsFreqs[i] = new PostingsAndFreq(postingsEnum, positions[i], t);\n      }\n\n      // sort by increasing docFreq order\n      if (slop == 0) {\n        ArrayUtil.timSort(postingsFreqs);\n      }\n\n      if (slop == 0) {  // optimize exact case\n        return new ExactPhraseScorer(this, postingsFreqs, similarity.simScorer(stats, context), needsScores);\n      } else {\n        return new SloppyPhraseScorer(this, postingsFreqs, slop, similarity.simScorer(stats, context), needsScores);\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"33eef98c565ee21b199f04b92acd6e00b842bd1e","date":1514538360,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/PhraseQuery.PhraseWeight#scorer(LeafReaderContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/PhraseQuery.PhraseWeight#scorer(LeafReaderContext).mjava","sourceNew":"    @Override\n    public Scorer scorer(LeafReaderContext context) throws IOException {\n      assert terms.length > 0;\n      final LeafReader reader = context.reader();\n      PostingsAndFreq[] postingsFreqs = new PostingsAndFreq[terms.length];\n\n      final Terms fieldTerms = reader.terms(field);\n      if (fieldTerms == null) {\n        return null;\n      }\n\n      if (fieldTerms.hasPositions() == false) {\n        throw new IllegalStateException(\"field \\\"\" + field + \"\\\" was indexed without position data; cannot run PhraseQuery (phrase=\" + getQuery() + \")\");\n      }\n\n      // Reuse single TermsEnum below:\n      final TermsEnum te = fieldTerms.iterator();\n      float totalMatchCost = 0;\n      \n      for (int i = 0; i < terms.length; i++) {\n        final Term t = terms[i];\n        final TermState state = states[i].get(context.ord);\n        if (state == null) { /* term doesnt exist in this segment */\n          assert termNotInReader(reader, t): \"no termstate found but term exists in reader\";\n          return null;\n        }\n        te.seekExact(t.bytes(), state);\n        PostingsEnum postingsEnum = te.postings(null, PostingsEnum.POSITIONS);\n        postingsFreqs[i] = new PostingsAndFreq(postingsEnum, positions[i], t);\n        totalMatchCost += termPositionsCost(te);\n      }\n\n      // sort by increasing docFreq order\n      if (slop == 0) {\n        ArrayUtil.timSort(postingsFreqs);\n      }\n\n      if (slop == 0) {  // optimize exact case\n        return new ExactPhraseScorer(this, postingsFreqs,\n                                      similarity.simScorer(stats, context),\n                                      scoreMode, totalMatchCost);\n      } else {\n        return new SloppyPhraseScorer(this, postingsFreqs, slop,\n                                        similarity.simScorer(stats, context),\n                                        scoreMode.needsScores(), totalMatchCost);\n      }\n    }\n\n","sourceOld":"    @Override\n    public Scorer scorer(LeafReaderContext context) throws IOException {\n      assert terms.length > 0;\n      final LeafReader reader = context.reader();\n      PostingsAndFreq[] postingsFreqs = new PostingsAndFreq[terms.length];\n\n      final Terms fieldTerms = reader.terms(field);\n      if (fieldTerms == null) {\n        return null;\n      }\n\n      if (fieldTerms.hasPositions() == false) {\n        throw new IllegalStateException(\"field \\\"\" + field + \"\\\" was indexed without position data; cannot run PhraseQuery (phrase=\" + getQuery() + \")\");\n      }\n\n      // Reuse single TermsEnum below:\n      final TermsEnum te = fieldTerms.iterator();\n      float totalMatchCost = 0;\n      \n      for (int i = 0; i < terms.length; i++) {\n        final Term t = terms[i];\n        final TermState state = states[i].get(context.ord);\n        if (state == null) { /* term doesnt exist in this segment */\n          assert termNotInReader(reader, t): \"no termstate found but term exists in reader\";\n          return null;\n        }\n        te.seekExact(t.bytes(), state);\n        PostingsEnum postingsEnum = te.postings(null, PostingsEnum.POSITIONS);\n        postingsFreqs[i] = new PostingsAndFreq(postingsEnum, positions[i], t);\n        totalMatchCost += termPositionsCost(te);\n      }\n\n      // sort by increasing docFreq order\n      if (slop == 0) {\n        ArrayUtil.timSort(postingsFreqs);\n      }\n\n      if (slop == 0) {  // optimize exact case\n        return new ExactPhraseScorer(this, postingsFreqs,\n                                      similarity.simScorer(stats, context),\n                                      needsScores, totalMatchCost);\n      } else {\n        return new SloppyPhraseScorer(this, postingsFreqs, slop,\n                                        similarity.simScorer(stats, context),\n                                        needsScores, totalMatchCost);\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"68d6cb7f0f019661a784bd0e5a21e85b5f812af6","date":1515075216,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/PhraseQuery.PhraseWeight#scorer(LeafReaderContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/PhraseQuery.PhraseWeight#scorer(LeafReaderContext).mjava","sourceNew":"    @Override\n    public Scorer scorer(LeafReaderContext context) throws IOException {\n      assert terms.length > 0;\n      final LeafReader reader = context.reader();\n      PostingsAndFreq[] postingsFreqs = new PostingsAndFreq[terms.length];\n\n      final Terms fieldTerms = reader.terms(field);\n      if (fieldTerms == null) {\n        return null;\n      }\n\n      if (fieldTerms.hasPositions() == false) {\n        throw new IllegalStateException(\"field \\\"\" + field + \"\\\" was indexed without position data; cannot run PhraseQuery (phrase=\" + getQuery() + \")\");\n      }\n\n      // Reuse single TermsEnum below:\n      final TermsEnum te = fieldTerms.iterator();\n      float totalMatchCost = 0;\n      \n      for (int i = 0; i < terms.length; i++) {\n        final Term t = terms[i];\n        final TermState state = states[i].get(context.ord);\n        if (state == null) { /* term doesnt exist in this segment */\n          assert termNotInReader(reader, t): \"no termstate found but term exists in reader\";\n          return null;\n        }\n        te.seekExact(t.bytes(), state);\n        PostingsEnum postingsEnum = te.postings(null, PostingsEnum.POSITIONS);\n        postingsFreqs[i] = new PostingsAndFreq(postingsEnum, positions[i], t);\n        totalMatchCost += termPositionsCost(te);\n      }\n\n      // sort by increasing docFreq order\n      if (slop == 0) {\n        ArrayUtil.timSort(postingsFreqs);\n      }\n\n      if (slop == 0) {  // optimize exact case\n        return new ExactPhraseScorer(this, postingsFreqs,\n                                      new LeafSimScorer(stats, context.reader(), scoreMode.needsScores(), Integer.MAX_VALUE),\n                                      scoreMode, totalMatchCost);\n      } else {\n        return new SloppyPhraseScorer(this, postingsFreqs, slop,\n                                        new LeafSimScorer(stats, context.reader(), scoreMode.needsScores(), Float.POSITIVE_INFINITY),\n                                        scoreMode.needsScores(), totalMatchCost);\n      }\n    }\n\n","sourceOld":"    @Override\n    public Scorer scorer(LeafReaderContext context) throws IOException {\n      assert terms.length > 0;\n      final LeafReader reader = context.reader();\n      PostingsAndFreq[] postingsFreqs = new PostingsAndFreq[terms.length];\n\n      final Terms fieldTerms = reader.terms(field);\n      if (fieldTerms == null) {\n        return null;\n      }\n\n      if (fieldTerms.hasPositions() == false) {\n        throw new IllegalStateException(\"field \\\"\" + field + \"\\\" was indexed without position data; cannot run PhraseQuery (phrase=\" + getQuery() + \")\");\n      }\n\n      // Reuse single TermsEnum below:\n      final TermsEnum te = fieldTerms.iterator();\n      float totalMatchCost = 0;\n      \n      for (int i = 0; i < terms.length; i++) {\n        final Term t = terms[i];\n        final TermState state = states[i].get(context.ord);\n        if (state == null) { /* term doesnt exist in this segment */\n          assert termNotInReader(reader, t): \"no termstate found but term exists in reader\";\n          return null;\n        }\n        te.seekExact(t.bytes(), state);\n        PostingsEnum postingsEnum = te.postings(null, PostingsEnum.POSITIONS);\n        postingsFreqs[i] = new PostingsAndFreq(postingsEnum, positions[i], t);\n        totalMatchCost += termPositionsCost(te);\n      }\n\n      // sort by increasing docFreq order\n      if (slop == 0) {\n        ArrayUtil.timSort(postingsFreqs);\n      }\n\n      if (slop == 0) {  // optimize exact case\n        return new ExactPhraseScorer(this, postingsFreqs,\n                                      similarity.simScorer(stats, context),\n                                      scoreMode, totalMatchCost);\n      } else {\n        return new SloppyPhraseScorer(this, postingsFreqs, slop,\n                                        similarity.simScorer(stats, context),\n                                        scoreMode.needsScores(), totalMatchCost);\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a6e9f769521480a623f897c0d59089b919fa4239","date":1515161835,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/PhraseQuery.PhraseWeight#scorer(LeafReaderContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/PhraseQuery.PhraseWeight#scorer(LeafReaderContext).mjava","sourceNew":"    @Override\n    public Scorer scorer(LeafReaderContext context) throws IOException {\n      assert terms.length > 0;\n      final LeafReader reader = context.reader();\n      PostingsAndFreq[] postingsFreqs = new PostingsAndFreq[terms.length];\n\n      final Terms fieldTerms = reader.terms(field);\n      if (fieldTerms == null) {\n        return null;\n      }\n\n      if (fieldTerms.hasPositions() == false) {\n        throw new IllegalStateException(\"field \\\"\" + field + \"\\\" was indexed without position data; cannot run PhraseQuery (phrase=\" + getQuery() + \")\");\n      }\n\n      // Reuse single TermsEnum below:\n      final TermsEnum te = fieldTerms.iterator();\n      float totalMatchCost = 0;\n      \n      for (int i = 0; i < terms.length; i++) {\n        final Term t = terms[i];\n        final TermState state = states[i].get(context);\n        if (state == null) { /* term doesnt exist in this segment */\n          assert termNotInReader(reader, t): \"no termstate found but term exists in reader\";\n          return null;\n        }\n        te.seekExact(t.bytes(), state);\n        PostingsEnum postingsEnum = te.postings(null, PostingsEnum.POSITIONS);\n        postingsFreqs[i] = new PostingsAndFreq(postingsEnum, positions[i], t);\n        totalMatchCost += termPositionsCost(te);\n      }\n\n      // sort by increasing docFreq order\n      if (slop == 0) {\n        ArrayUtil.timSort(postingsFreqs);\n      }\n\n      if (slop == 0) {  // optimize exact case\n        return new ExactPhraseScorer(this, postingsFreqs,\n                                      new LeafSimScorer(stats, context.reader(), scoreMode.needsScores(), Integer.MAX_VALUE),\n                                      scoreMode, totalMatchCost);\n      } else {\n        return new SloppyPhraseScorer(this, postingsFreqs, slop,\n                                        new LeafSimScorer(stats, context.reader(), scoreMode.needsScores(), Float.POSITIVE_INFINITY),\n                                        scoreMode.needsScores(), totalMatchCost);\n      }\n    }\n\n","sourceOld":"    @Override\n    public Scorer scorer(LeafReaderContext context) throws IOException {\n      assert terms.length > 0;\n      final LeafReader reader = context.reader();\n      PostingsAndFreq[] postingsFreqs = new PostingsAndFreq[terms.length];\n\n      final Terms fieldTerms = reader.terms(field);\n      if (fieldTerms == null) {\n        return null;\n      }\n\n      if (fieldTerms.hasPositions() == false) {\n        throw new IllegalStateException(\"field \\\"\" + field + \"\\\" was indexed without position data; cannot run PhraseQuery (phrase=\" + getQuery() + \")\");\n      }\n\n      // Reuse single TermsEnum below:\n      final TermsEnum te = fieldTerms.iterator();\n      float totalMatchCost = 0;\n      \n      for (int i = 0; i < terms.length; i++) {\n        final Term t = terms[i];\n        final TermState state = states[i].get(context.ord);\n        if (state == null) { /* term doesnt exist in this segment */\n          assert termNotInReader(reader, t): \"no termstate found but term exists in reader\";\n          return null;\n        }\n        te.seekExact(t.bytes(), state);\n        PostingsEnum postingsEnum = te.postings(null, PostingsEnum.POSITIONS);\n        postingsFreqs[i] = new PostingsAndFreq(postingsEnum, positions[i], t);\n        totalMatchCost += termPositionsCost(te);\n      }\n\n      // sort by increasing docFreq order\n      if (slop == 0) {\n        ArrayUtil.timSort(postingsFreqs);\n      }\n\n      if (slop == 0) {  // optimize exact case\n        return new ExactPhraseScorer(this, postingsFreqs,\n                                      new LeafSimScorer(stats, context.reader(), scoreMode.needsScores(), Integer.MAX_VALUE),\n                                      scoreMode, totalMatchCost);\n      } else {\n        return new SloppyPhraseScorer(this, postingsFreqs, slop,\n                                        new LeafSimScorer(stats, context.reader(), scoreMode.needsScores(), Float.POSITIVE_INFINITY),\n                                        scoreMode.needsScores(), totalMatchCost);\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0c68bfb3354451a11c895b36484af94f27530b79","date":1515505336,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/PhraseQuery.PhraseWeight#scorer(LeafReaderContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/PhraseQuery.PhraseWeight#scorer(LeafReaderContext).mjava","sourceNew":"    @Override\n    public Scorer scorer(LeafReaderContext context) throws IOException {\n      assert terms.length > 0;\n      final LeafReader reader = context.reader();\n      PostingsAndFreq[] postingsFreqs = new PostingsAndFreq[terms.length];\n\n      final Terms fieldTerms = reader.terms(field);\n      if (fieldTerms == null) {\n        return null;\n      }\n\n      if (fieldTerms.hasPositions() == false) {\n        throw new IllegalStateException(\"field \\\"\" + field + \"\\\" was indexed without position data; cannot run PhraseQuery (phrase=\" + getQuery() + \")\");\n      }\n\n      // Reuse single TermsEnum below:\n      final TermsEnum te = fieldTerms.iterator();\n      float totalMatchCost = 0;\n      \n      for (int i = 0; i < terms.length; i++) {\n        final Term t = terms[i];\n        final TermState state = states[i].get(context);\n        if (state == null) { /* term doesnt exist in this segment */\n          assert termNotInReader(reader, t): \"no termstate found but term exists in reader\";\n          return null;\n        }\n        te.seekExact(t.bytes(), state);\n        PostingsEnum postingsEnum = te.postings(null, PostingsEnum.POSITIONS);\n        postingsFreqs[i] = new PostingsAndFreq(postingsEnum, positions[i], t);\n        totalMatchCost += termPositionsCost(te);\n      }\n\n      // sort by increasing docFreq order\n      if (slop == 0) {\n        ArrayUtil.timSort(postingsFreqs);\n      }\n\n      if (slop == 0) {  // optimize exact case\n        return new ExactPhraseScorer(this, postingsFreqs,\n                                      new LeafSimScorer(stats, context.reader(), scoreMode.needsScores(), Integer.MAX_VALUE),\n                                      scoreMode, totalMatchCost);\n      } else {\n        return new SloppyPhraseScorer(this, postingsFreqs, slop,\n                                        new LeafSimScorer(stats, context.reader(), scoreMode.needsScores(), Float.MAX_VALUE),\n                                        scoreMode.needsScores(), totalMatchCost);\n      }\n    }\n\n","sourceOld":"    @Override\n    public Scorer scorer(LeafReaderContext context) throws IOException {\n      assert terms.length > 0;\n      final LeafReader reader = context.reader();\n      PostingsAndFreq[] postingsFreqs = new PostingsAndFreq[terms.length];\n\n      final Terms fieldTerms = reader.terms(field);\n      if (fieldTerms == null) {\n        return null;\n      }\n\n      if (fieldTerms.hasPositions() == false) {\n        throw new IllegalStateException(\"field \\\"\" + field + \"\\\" was indexed without position data; cannot run PhraseQuery (phrase=\" + getQuery() + \")\");\n      }\n\n      // Reuse single TermsEnum below:\n      final TermsEnum te = fieldTerms.iterator();\n      float totalMatchCost = 0;\n      \n      for (int i = 0; i < terms.length; i++) {\n        final Term t = terms[i];\n        final TermState state = states[i].get(context);\n        if (state == null) { /* term doesnt exist in this segment */\n          assert termNotInReader(reader, t): \"no termstate found but term exists in reader\";\n          return null;\n        }\n        te.seekExact(t.bytes(), state);\n        PostingsEnum postingsEnum = te.postings(null, PostingsEnum.POSITIONS);\n        postingsFreqs[i] = new PostingsAndFreq(postingsEnum, positions[i], t);\n        totalMatchCost += termPositionsCost(te);\n      }\n\n      // sort by increasing docFreq order\n      if (slop == 0) {\n        ArrayUtil.timSort(postingsFreqs);\n      }\n\n      if (slop == 0) {  // optimize exact case\n        return new ExactPhraseScorer(this, postingsFreqs,\n                                      new LeafSimScorer(stats, context.reader(), scoreMode.needsScores(), Integer.MAX_VALUE),\n                                      scoreMode, totalMatchCost);\n      } else {\n        return new SloppyPhraseScorer(this, postingsFreqs, slop,\n                                        new LeafSimScorer(stats, context.reader(), scoreMode.needsScores(), Float.POSITIVE_INFINITY),\n                                        scoreMode.needsScores(), totalMatchCost);\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b94236357aaa22b76c10629851fe4e376e0cea82","date":1516710914,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/search/PhraseQuery.PhraseWeight#scorer(LeafReaderContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/PhraseQuery.PhraseWeight#scorer(LeafReaderContext).mjava","sourceNew":"    @Override\n    public Scorer scorer(LeafReaderContext context) throws IOException {\n      assert terms.length > 0;\n      final LeafReader reader = context.reader();\n      PostingsAndFreq[] postingsFreqs = new PostingsAndFreq[terms.length];\n\n      final Terms fieldTerms = reader.terms(field);\n      if (fieldTerms == null) {\n        return null;\n      }\n\n      if (fieldTerms.hasPositions() == false) {\n        throw new IllegalStateException(\"field \\\"\" + field + \"\\\" was indexed without position data; cannot run PhraseQuery (phrase=\" + getQuery() + \")\");\n      }\n\n      // Reuse single TermsEnum below:\n      final TermsEnum te = fieldTerms.iterator();\n      float totalMatchCost = 0;\n      \n      for (int i = 0; i < terms.length; i++) {\n        final Term t = terms[i];\n        final TermState state = states[i].get(context);\n        if (state == null) { /* term doesnt exist in this segment */\n          assert termNotInReader(reader, t): \"no termstate found but term exists in reader\";\n          return null;\n        }\n        te.seekExact(t.bytes(), state);\n        PostingsEnum postingsEnum = te.postings(null, PostingsEnum.POSITIONS);\n        postingsFreqs[i] = new PostingsAndFreq(postingsEnum, positions[i], t);\n        totalMatchCost += termPositionsCost(te);\n      }\n\n      // sort by increasing docFreq order\n      if (slop == 0) {\n        ArrayUtil.timSort(postingsFreqs);\n      }\n\n      if (slop == 0) {  // optimize exact case\n        return new ExactPhraseScorer(this, postingsFreqs,\n                                      new LeafSimScorer(stats, context.reader(), scoreMode.needsScores(), Integer.MAX_VALUE),\n                                      scoreMode, totalMatchCost);\n      } else {\n        return new SloppyPhraseScorer(this, postingsFreqs, slop,\n                                        new LeafSimScorer(stats, context.reader(), scoreMode.needsScores(), Float.MAX_VALUE),\n                                        scoreMode.needsScores(), totalMatchCost);\n      }\n    }\n\n","sourceOld":"    @Override\n    public Scorer scorer(LeafReaderContext context) throws IOException {\n      assert terms.length > 0;\n      final LeafReader reader = context.reader();\n      PostingsAndFreq[] postingsFreqs = new PostingsAndFreq[terms.length];\n\n      final Terms fieldTerms = reader.terms(field);\n      if (fieldTerms == null) {\n        return null;\n      }\n\n      if (fieldTerms.hasPositions() == false) {\n        throw new IllegalStateException(\"field \\\"\" + field + \"\\\" was indexed without position data; cannot run PhraseQuery (phrase=\" + getQuery() + \")\");\n      }\n\n      // Reuse single TermsEnum below:\n      final TermsEnum te = fieldTerms.iterator();\n      float totalMatchCost = 0;\n      \n      for (int i = 0; i < terms.length; i++) {\n        final Term t = terms[i];\n        final TermState state = states[i].get(context.ord);\n        if (state == null) { /* term doesnt exist in this segment */\n          assert termNotInReader(reader, t): \"no termstate found but term exists in reader\";\n          return null;\n        }\n        te.seekExact(t.bytes(), state);\n        PostingsEnum postingsEnum = te.postings(null, PostingsEnum.POSITIONS);\n        postingsFreqs[i] = new PostingsAndFreq(postingsEnum, positions[i], t);\n        totalMatchCost += termPositionsCost(te);\n      }\n\n      // sort by increasing docFreq order\n      if (slop == 0) {\n        ArrayUtil.timSort(postingsFreqs);\n      }\n\n      if (slop == 0) {  // optimize exact case\n        return new ExactPhraseScorer(this, postingsFreqs,\n                                      similarity.simScorer(stats, context),\n                                      scoreMode, totalMatchCost);\n      } else {\n        return new SloppyPhraseScorer(this, postingsFreqs, slop,\n                                        similarity.simScorer(stats, context),\n                                        scoreMode.needsScores(), totalMatchCost);\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3b11b9d5eaf9707760ca5151530830a825197023","date":1525941319,"type":4,"author":"Alan Woodward","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/core/src/java/org/apache/lucene/search/PhraseQuery.PhraseWeight#scorer(LeafReaderContext).mjava","sourceNew":null,"sourceOld":"    @Override\n    public Scorer scorer(LeafReaderContext context) throws IOException {\n      assert terms.length > 0;\n      final LeafReader reader = context.reader();\n      PostingsAndFreq[] postingsFreqs = new PostingsAndFreq[terms.length];\n\n      final Terms fieldTerms = reader.terms(field);\n      if (fieldTerms == null) {\n        return null;\n      }\n\n      if (fieldTerms.hasPositions() == false) {\n        throw new IllegalStateException(\"field \\\"\" + field + \"\\\" was indexed without position data; cannot run PhraseQuery (phrase=\" + getQuery() + \")\");\n      }\n\n      // Reuse single TermsEnum below:\n      final TermsEnum te = fieldTerms.iterator();\n      float totalMatchCost = 0;\n      \n      for (int i = 0; i < terms.length; i++) {\n        final Term t = terms[i];\n        final TermState state = states[i].get(context);\n        if (state == null) { /* term doesnt exist in this segment */\n          assert termNotInReader(reader, t): \"no termstate found but term exists in reader\";\n          return null;\n        }\n        te.seekExact(t.bytes(), state);\n        PostingsEnum postingsEnum = te.postings(null, PostingsEnum.POSITIONS);\n        postingsFreqs[i] = new PostingsAndFreq(postingsEnum, positions[i], t);\n        totalMatchCost += termPositionsCost(te);\n      }\n\n      // sort by increasing docFreq order\n      if (slop == 0) {\n        ArrayUtil.timSort(postingsFreqs);\n      }\n\n      if (slop == 0) {  // optimize exact case\n        return new ExactPhraseScorer(this, postingsFreqs,\n                                      new LeafSimScorer(stats, context.reader(), scoreMode.needsScores(), Integer.MAX_VALUE),\n                                      scoreMode, totalMatchCost);\n      } else {\n        return new SloppyPhraseScorer(this, postingsFreqs, slop,\n                                        new LeafSimScorer(stats, context.reader(), scoreMode.needsScores(), Float.MAX_VALUE),\n                                        scoreMode.needsScores(), totalMatchCost);\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"d277693481ea6007c1d83cd503d0859bb3b64d20":["0f4464508ee83288c8c4585b533f9faaa93aa314"],"0c68bfb3354451a11c895b36484af94f27530b79":["a6e9f769521480a623f897c0d59089b919fa4239"],"b94236357aaa22b76c10629851fe4e376e0cea82":["33eef98c565ee21b199f04b92acd6e00b842bd1e","0c68bfb3354451a11c895b36484af94f27530b79"],"68d6cb7f0f019661a784bd0e5a21e85b5f812af6":["33eef98c565ee21b199f04b92acd6e00b842bd1e"],"0f4464508ee83288c8c4585b533f9faaa93aa314":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a6e9f769521480a623f897c0d59089b919fa4239":["68d6cb7f0f019661a784bd0e5a21e85b5f812af6"],"33eef98c565ee21b199f04b92acd6e00b842bd1e":["d277693481ea6007c1d83cd503d0859bb3b64d20"],"3b11b9d5eaf9707760ca5151530830a825197023":["b94236357aaa22b76c10629851fe4e376e0cea82"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3b11b9d5eaf9707760ca5151530830a825197023"]},"commit2Childs":{"d277693481ea6007c1d83cd503d0859bb3b64d20":["33eef98c565ee21b199f04b92acd6e00b842bd1e"],"0c68bfb3354451a11c895b36484af94f27530b79":["b94236357aaa22b76c10629851fe4e376e0cea82"],"b94236357aaa22b76c10629851fe4e376e0cea82":["3b11b9d5eaf9707760ca5151530830a825197023"],"68d6cb7f0f019661a784bd0e5a21e85b5f812af6":["a6e9f769521480a623f897c0d59089b919fa4239"],"0f4464508ee83288c8c4585b533f9faaa93aa314":["d277693481ea6007c1d83cd503d0859bb3b64d20"],"a6e9f769521480a623f897c0d59089b919fa4239":["0c68bfb3354451a11c895b36484af94f27530b79"],"33eef98c565ee21b199f04b92acd6e00b842bd1e":["b94236357aaa22b76c10629851fe4e376e0cea82","68d6cb7f0f019661a784bd0e5a21e85b5f812af6"],"3b11b9d5eaf9707760ca5151530830a825197023":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["0f4464508ee83288c8c4585b533f9faaa93aa314"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}