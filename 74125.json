{"path":"modules/queryparser/src/java/org/apache/lucene/queryparser/xml/builders/LikeThisQueryBuilder#getQuery(Element).mjava","commits":[{"id":"251550f5d19b526a76f8c5126ae7bb2d22cf8935","date":1315202008,"type":1,"author":"Christopher John Male","isMerge":false,"pathNew":"modules/queryparser/src/java/org/apache/lucene/queryparser/xml/builders/LikeThisQueryBuilder#getQuery(Element).mjava","pathOld":"lucene/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/LikeThisQueryBuilder#getQuery(Element).mjava","sourceNew":"  /* (non-Javadoc)\n    * @see org.apache.lucene.xmlparser.QueryObjectBuilder#process(org.w3c.dom.Element)\n    */\n  public Query getQuery(Element e) throws ParserException {\n    String fieldsList = e.getAttribute(\"fieldNames\"); //a comma-delimited list of fields\n    String fields[] = defaultFieldNames;\n    if ((fieldsList != null) && (fieldsList.trim().length() > 0)) {\n      fields = fieldsList.trim().split(\",\");\n      //trim the fieldnames\n      for (int i = 0; i < fields.length; i++) {\n        fields[i] = fields[i].trim();\n      }\n    }\n\n    //Parse any \"stopWords\" attribute\n    //TODO MoreLikeThis needs to ideally have per-field stopWords lists - until then\n    //I use all analyzers/fields to generate multi-field compatible stop list\n    String stopWords = e.getAttribute(\"stopWords\");\n    Set<String> stopWordsSet = null;\n    if ((stopWords != null) && (fields != null)) {\n      stopWordsSet = new HashSet<String>();\n      for (String field : fields) {\n        try {\n          TokenStream ts = analyzer.reusableTokenStream(field, new StringReader(stopWords));\n          CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n          ts.reset();\n          while (ts.incrementToken()) {\n            stopWordsSet.add(termAtt.toString());\n          }\n          ts.end();\n          ts.close();\n        } catch (IOException ioe) {\n          throw new ParserException(\"IoException parsing stop words list in \"\n              + getClass().getName() + \":\" + ioe.getLocalizedMessage());\n        }\n      }\n    }\n\n\n    MoreLikeThisQuery mlt = new MoreLikeThisQuery(DOMUtils.getText(e), fields, analyzer, fields[0]);\n    mlt.setMaxQueryTerms(DOMUtils.getAttribute(e, \"maxQueryTerms\", DEFAULT_MAX_QUERY_TERMS));\n    mlt.setMinTermFrequency(DOMUtils.getAttribute(e, \"minTermFrequency\", DEFAULT_MIN_TERM_FREQUENCY));\n    mlt.setPercentTermsToMatch(DOMUtils.getAttribute(e, \"percentTermsToMatch\", DEFAULT_PERCENT_TERMS_TO_MATCH) / 100);\n    mlt.setStopWords(stopWordsSet);\n    int minDocFreq = DOMUtils.getAttribute(e, \"minDocFreq\", -1);\n    if (minDocFreq >= 0) {\n      mlt.setMinDocFreq(minDocFreq);\n    }\n\n    mlt.setBoost(DOMUtils.getAttribute(e, \"boost\", 1.0f));\n\n    return mlt;\n  }\n\n","sourceOld":"  /* (non-Javadoc)\n    * @see org.apache.lucene.xmlparser.QueryObjectBuilder#process(org.w3c.dom.Element)\n    */\n  public Query getQuery(Element e) throws ParserException {\n    String fieldsList = e.getAttribute(\"fieldNames\"); //a comma-delimited list of fields\n    String fields[] = defaultFieldNames;\n    if ((fieldsList != null) && (fieldsList.trim().length() > 0)) {\n      fields = fieldsList.trim().split(\",\");\n      //trim the fieldnames\n      for (int i = 0; i < fields.length; i++) {\n        fields[i] = fields[i].trim();\n      }\n    }\n\n    //Parse any \"stopWords\" attribute\n    //TODO MoreLikeThis needs to ideally have per-field stopWords lists - until then\n    //I use all analyzers/fields to generate multi-field compatible stop list\n    String stopWords = e.getAttribute(\"stopWords\");\n    Set<String> stopWordsSet = null;\n    if ((stopWords != null) && (fields != null)) {\n      stopWordsSet = new HashSet<String>();\n      for (String field : fields) {\n        try {\n          TokenStream ts = analyzer.reusableTokenStream(field, new StringReader(stopWords));\n          CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n          ts.reset();\n          while (ts.incrementToken()) {\n            stopWordsSet.add(termAtt.toString());\n          }\n          ts.end();\n          ts.close();\n        } catch (IOException ioe) {\n          throw new ParserException(\"IoException parsing stop words list in \"\n              + getClass().getName() + \":\" + ioe.getLocalizedMessage());\n        }\n      }\n    }\n\n\n    MoreLikeThisQuery mlt = new MoreLikeThisQuery(DOMUtils.getText(e), fields, analyzer, fields[0]);\n    mlt.setMaxQueryTerms(DOMUtils.getAttribute(e, \"maxQueryTerms\", DEFAULT_MAX_QUERY_TERMS));\n    mlt.setMinTermFrequency(DOMUtils.getAttribute(e, \"minTermFrequency\", DEFAULT_MIN_TERM_FREQUENCY));\n    mlt.setPercentTermsToMatch(DOMUtils.getAttribute(e, \"percentTermsToMatch\", DEFAULT_PERCENT_TERMS_TO_MATCH) / 100);\n    mlt.setStopWords(stopWordsSet);\n    int minDocFreq = DOMUtils.getAttribute(e, \"minDocFreq\", -1);\n    if (minDocFreq >= 0) {\n      mlt.setMinDocFreq(minDocFreq);\n    }\n\n    mlt.setBoost(DOMUtils.getAttribute(e, \"boost\", 1.0f));\n\n    return mlt;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"69e043c521d4e8db770cc140c63f5ef51f03426a","date":1317187614,"type":3,"author":"Christopher John Male","isMerge":false,"pathNew":"modules/queryparser/src/java/org/apache/lucene/queryparser/xml/builders/LikeThisQueryBuilder#getQuery(Element).mjava","pathOld":"modules/queryparser/src/java/org/apache/lucene/queryparser/xml/builders/LikeThisQueryBuilder#getQuery(Element).mjava","sourceNew":"  /* (non-Javadoc)\n    * @see org.apache.lucene.xmlparser.QueryObjectBuilder#process(org.w3c.dom.Element)\n    */\n  public Query getQuery(Element e) throws ParserException {\n    String fieldsList = e.getAttribute(\"fieldNames\"); //a comma-delimited list of fields\n    String fields[] = defaultFieldNames;\n    if ((fieldsList != null) && (fieldsList.trim().length() > 0)) {\n      fields = fieldsList.trim().split(\",\");\n      //trim the fieldnames\n      for (int i = 0; i < fields.length; i++) {\n        fields[i] = fields[i].trim();\n      }\n    }\n\n    //Parse any \"stopWords\" attribute\n    //TODO MoreLikeThis needs to ideally have per-field stopWords lists - until then\n    //I use all analyzers/fields to generate multi-field compatible stop list\n    String stopWords = e.getAttribute(\"stopWords\");\n    Set<String> stopWordsSet = null;\n    if ((stopWords != null) && (fields != null)) {\n      stopWordsSet = new HashSet<String>();\n      for (String field : fields) {\n        try {\n          TokenStream ts = analyzer.tokenStream(field, new StringReader(stopWords));\n          CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n          ts.reset();\n          while (ts.incrementToken()) {\n            stopWordsSet.add(termAtt.toString());\n          }\n          ts.end();\n          ts.close();\n        } catch (IOException ioe) {\n          throw new ParserException(\"IoException parsing stop words list in \"\n              + getClass().getName() + \":\" + ioe.getLocalizedMessage());\n        }\n      }\n    }\n\n\n    MoreLikeThisQuery mlt = new MoreLikeThisQuery(DOMUtils.getText(e), fields, analyzer, fields[0]);\n    mlt.setMaxQueryTerms(DOMUtils.getAttribute(e, \"maxQueryTerms\", DEFAULT_MAX_QUERY_TERMS));\n    mlt.setMinTermFrequency(DOMUtils.getAttribute(e, \"minTermFrequency\", DEFAULT_MIN_TERM_FREQUENCY));\n    mlt.setPercentTermsToMatch(DOMUtils.getAttribute(e, \"percentTermsToMatch\", DEFAULT_PERCENT_TERMS_TO_MATCH) / 100);\n    mlt.setStopWords(stopWordsSet);\n    int minDocFreq = DOMUtils.getAttribute(e, \"minDocFreq\", -1);\n    if (minDocFreq >= 0) {\n      mlt.setMinDocFreq(minDocFreq);\n    }\n\n    mlt.setBoost(DOMUtils.getAttribute(e, \"boost\", 1.0f));\n\n    return mlt;\n  }\n\n","sourceOld":"  /* (non-Javadoc)\n    * @see org.apache.lucene.xmlparser.QueryObjectBuilder#process(org.w3c.dom.Element)\n    */\n  public Query getQuery(Element e) throws ParserException {\n    String fieldsList = e.getAttribute(\"fieldNames\"); //a comma-delimited list of fields\n    String fields[] = defaultFieldNames;\n    if ((fieldsList != null) && (fieldsList.trim().length() > 0)) {\n      fields = fieldsList.trim().split(\",\");\n      //trim the fieldnames\n      for (int i = 0; i < fields.length; i++) {\n        fields[i] = fields[i].trim();\n      }\n    }\n\n    //Parse any \"stopWords\" attribute\n    //TODO MoreLikeThis needs to ideally have per-field stopWords lists - until then\n    //I use all analyzers/fields to generate multi-field compatible stop list\n    String stopWords = e.getAttribute(\"stopWords\");\n    Set<String> stopWordsSet = null;\n    if ((stopWords != null) && (fields != null)) {\n      stopWordsSet = new HashSet<String>();\n      for (String field : fields) {\n        try {\n          TokenStream ts = analyzer.reusableTokenStream(field, new StringReader(stopWords));\n          CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n          ts.reset();\n          while (ts.incrementToken()) {\n            stopWordsSet.add(termAtt.toString());\n          }\n          ts.end();\n          ts.close();\n        } catch (IOException ioe) {\n          throw new ParserException(\"IoException parsing stop words list in \"\n              + getClass().getName() + \":\" + ioe.getLocalizedMessage());\n        }\n      }\n    }\n\n\n    MoreLikeThisQuery mlt = new MoreLikeThisQuery(DOMUtils.getText(e), fields, analyzer, fields[0]);\n    mlt.setMaxQueryTerms(DOMUtils.getAttribute(e, \"maxQueryTerms\", DEFAULT_MAX_QUERY_TERMS));\n    mlt.setMinTermFrequency(DOMUtils.getAttribute(e, \"minTermFrequency\", DEFAULT_MIN_TERM_FREQUENCY));\n    mlt.setPercentTermsToMatch(DOMUtils.getAttribute(e, \"percentTermsToMatch\", DEFAULT_PERCENT_TERMS_TO_MATCH) / 100);\n    mlt.setStopWords(stopWordsSet);\n    int minDocFreq = DOMUtils.getAttribute(e, \"minDocFreq\", -1);\n    if (minDocFreq >= 0) {\n      mlt.setMinDocFreq(minDocFreq);\n    }\n\n    mlt.setBoost(DOMUtils.getAttribute(e, \"boost\", 1.0f));\n\n    return mlt;\n  }\n\n","bugFix":null,"bugIntro":["c83d6c4335f31cae14f625a222bc842f20073dcd"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/queryparser/src/java/org/apache/lucene/queryparser/xml/builders/LikeThisQueryBuilder#getQuery(Element).mjava","pathOld":"modules/queryparser/src/java/org/apache/lucene/queryparser/xml/builders/LikeThisQueryBuilder#getQuery(Element).mjava","sourceNew":"  /* (non-Javadoc)\n    * @see org.apache.lucene.xmlparser.QueryObjectBuilder#process(org.w3c.dom.Element)\n    */\n  public Query getQuery(Element e) throws ParserException {\n    String fieldsList = e.getAttribute(\"fieldNames\"); //a comma-delimited list of fields\n    String fields[] = defaultFieldNames;\n    if ((fieldsList != null) && (fieldsList.trim().length() > 0)) {\n      fields = fieldsList.trim().split(\",\");\n      //trim the fieldnames\n      for (int i = 0; i < fields.length; i++) {\n        fields[i] = fields[i].trim();\n      }\n    }\n\n    //Parse any \"stopWords\" attribute\n    //TODO MoreLikeThis needs to ideally have per-field stopWords lists - until then\n    //I use all analyzers/fields to generate multi-field compatible stop list\n    String stopWords = e.getAttribute(\"stopWords\");\n    Set<String> stopWordsSet = null;\n    if ((stopWords != null) && (fields != null)) {\n      stopWordsSet = new HashSet<String>();\n      for (String field : fields) {\n        try {\n          TokenStream ts = analyzer.tokenStream(field, new StringReader(stopWords));\n          CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n          ts.reset();\n          while (ts.incrementToken()) {\n            stopWordsSet.add(termAtt.toString());\n          }\n          ts.end();\n          ts.close();\n        } catch (IOException ioe) {\n          throw new ParserException(\"IoException parsing stop words list in \"\n              + getClass().getName() + \":\" + ioe.getLocalizedMessage());\n        }\n      }\n    }\n\n\n    MoreLikeThisQuery mlt = new MoreLikeThisQuery(DOMUtils.getText(e), fields, analyzer, fields[0]);\n    mlt.setMaxQueryTerms(DOMUtils.getAttribute(e, \"maxQueryTerms\", DEFAULT_MAX_QUERY_TERMS));\n    mlt.setMinTermFrequency(DOMUtils.getAttribute(e, \"minTermFrequency\", DEFAULT_MIN_TERM_FREQUENCY));\n    mlt.setPercentTermsToMatch(DOMUtils.getAttribute(e, \"percentTermsToMatch\", DEFAULT_PERCENT_TERMS_TO_MATCH) / 100);\n    mlt.setStopWords(stopWordsSet);\n    int minDocFreq = DOMUtils.getAttribute(e, \"minDocFreq\", -1);\n    if (minDocFreq >= 0) {\n      mlt.setMinDocFreq(minDocFreq);\n    }\n\n    mlt.setBoost(DOMUtils.getAttribute(e, \"boost\", 1.0f));\n\n    return mlt;\n  }\n\n","sourceOld":"  /* (non-Javadoc)\n    * @see org.apache.lucene.xmlparser.QueryObjectBuilder#process(org.w3c.dom.Element)\n    */\n  public Query getQuery(Element e) throws ParserException {\n    String fieldsList = e.getAttribute(\"fieldNames\"); //a comma-delimited list of fields\n    String fields[] = defaultFieldNames;\n    if ((fieldsList != null) && (fieldsList.trim().length() > 0)) {\n      fields = fieldsList.trim().split(\",\");\n      //trim the fieldnames\n      for (int i = 0; i < fields.length; i++) {\n        fields[i] = fields[i].trim();\n      }\n    }\n\n    //Parse any \"stopWords\" attribute\n    //TODO MoreLikeThis needs to ideally have per-field stopWords lists - until then\n    //I use all analyzers/fields to generate multi-field compatible stop list\n    String stopWords = e.getAttribute(\"stopWords\");\n    Set<String> stopWordsSet = null;\n    if ((stopWords != null) && (fields != null)) {\n      stopWordsSet = new HashSet<String>();\n      for (String field : fields) {\n        try {\n          TokenStream ts = analyzer.tokenStream(field, new StringReader(stopWords));\n          CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n          ts.reset();\n          while (ts.incrementToken()) {\n            stopWordsSet.add(termAtt.toString());\n          }\n          ts.end();\n          ts.close();\n        } catch (IOException ioe) {\n          throw new ParserException(\"IoException parsing stop words list in \"\n              + getClass().getName() + \":\" + ioe.getLocalizedMessage());\n        }\n      }\n    }\n\n\n    MoreLikeThisQuery mlt = new MoreLikeThisQuery(DOMUtils.getText(e), fields, analyzer, fields[0]);\n    mlt.setMaxQueryTerms(DOMUtils.getAttribute(e, \"maxQueryTerms\", DEFAULT_MAX_QUERY_TERMS));\n    mlt.setMinTermFrequency(DOMUtils.getAttribute(e, \"minTermFrequency\", DEFAULT_MIN_TERM_FREQUENCY));\n    mlt.setPercentTermsToMatch(DOMUtils.getAttribute(e, \"percentTermsToMatch\", DEFAULT_PERCENT_TERMS_TO_MATCH) / 100);\n    mlt.setStopWords(stopWordsSet);\n    int minDocFreq = DOMUtils.getAttribute(e, \"minDocFreq\", -1);\n    if (minDocFreq >= 0) {\n      mlt.setMinDocFreq(minDocFreq);\n    }\n\n    mlt.setBoost(DOMUtils.getAttribute(e, \"boost\", 1.0f));\n\n    return mlt;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["69e043c521d4e8db770cc140c63f5ef51f03426a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"251550f5d19b526a76f8c5126ae7bb2d22cf8935":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"69e043c521d4e8db770cc140c63f5ef51f03426a":["251550f5d19b526a76f8c5126ae7bb2d22cf8935"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b89678825b68eccaf09e6ab71675fc0b0af1e099"]},"commit2Childs":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["251550f5d19b526a76f8c5126ae7bb2d22cf8935"],"251550f5d19b526a76f8c5126ae7bb2d22cf8935":["69e043c521d4e8db770cc140c63f5ef51f03426a"],"69e043c521d4e8db770cc140c63f5ef51f03426a":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}