{"path":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommit(Map[String,String]).mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommit(Map[String,String]).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#prepareCommit(Map[String,String]).mjava","sourceNew":"  /** <p>Expert: prepare for commit, specifying\n   *  commitUserData Map (String -> String).  This does the\n   *  first phase of 2-phase commit. This method does all\n   *  steps necessary to commit changes since this writer\n   *  was opened: flushes pending added and deleted docs,\n   *  syncs the index files, writes most of next segments_N\n   *  file.  After calling this you must call either {@link\n   *  #commit()} to finish the commit, or {@link\n   *  #rollback()} to revert the commit and undo all changes\n   *  done since the writer was opened.</p>\n   *\n   *  You can also just call {@link #commit(Map)} directly\n   *  without prepareCommit first in which case that method\n   *  will internally call prepareCommit.\n   *\n   *  <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   *  you should immediately close the writer.  See <a\n   *  href=\"#OOME\">above</a> for details.</p>\n   *\n   *  @param commitUserData Opaque Map (String->String)\n   *  that's recorded into the segments file in the index,\n   *  and retrievable by {@link\n   *  DirectoryReader#getCommitUserData}.  Note that when\n   *  IndexWriter commits itself during {@link #close}, the\n   *  commitUserData is unchanged (just carried over from\n   *  the prior commit).  If this is null then the previous\n   *  commitUserData is kept.  Also, the commitUserData will\n   *  only \"stick\" if there are actually changes in the\n   *  index to commit.\n   */\n  public final void prepareCommit(Map<String,String> commitUserData) throws CorruptIndexException, IOException {\n    ensureOpen(false);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"prepareCommit: flush\");\n      infoStream.message(\"IW\", \"  index before flush \" + segString());\n    }\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot commit\");\n    }\n\n    if (pendingCommit != null) {\n      throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n    }\n\n    doBeforeFlush();\n    assert testPoint(\"startDoFlush\");\n    SegmentInfos toCommit = null;\n    boolean anySegmentsFlushed = false;\n\n    // This is copied from doFlush, except it's modified to\n    // clone & incRef the flushed SegmentInfos inside the\n    // sync block:\n\n    try {\n\n      synchronized (fullFlushLock) {\n        boolean flushSuccess = false;\n        boolean success = false;\n        try {\n          anySegmentsFlushed = docWriter.flushAllThreads();\n          if (!anySegmentsFlushed) {\n            // prevent double increment since docWriter#doFlush increments the flushcount\n            // if we flushed anything.\n            flushCount.incrementAndGet();\n          }\n          flushSuccess = true;\n\n          synchronized(this) {\n            maybeApplyDeletes(true);\n\n            readerPool.commit(segmentInfos);\n\n            // Must clone the segmentInfos while we still\n            // hold fullFlushLock and while sync'd so that\n            // no partial changes (eg a delete w/o\n            // corresponding add from an updateDocument) can\n            // sneak into the commit point:\n            toCommit = (SegmentInfos) segmentInfos.clone();\n\n            pendingCommitChangeCount = changeCount;\n\n            // This protects the segmentInfos we are now going\n            // to commit.  This is important in case, eg, while\n            // we are trying to sync all referenced files, a\n            // merge completes which would otherwise have\n            // removed the files we are now syncing.    \n            filesToCommit = toCommit.files(directory, false);\n            deleter.incRef(filesToCommit);\n          }\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n            }\n          }\n          // Done: finish the full flush!\n          docWriter.finishFullFlush(flushSuccess);\n          doAfterFlush();\n        }\n      }\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"prepareCommit\");\n    }\n \n    boolean success = false;\n    try {\n      if (anySegmentsFlushed) {\n        maybeMerge();\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        synchronized (this) {\n          deleter.decRef(filesToCommit);\n          filesToCommit = null;\n        }\n      }\n    }\n\n    startCommit(toCommit, commitUserData);\n  }\n\n","sourceOld":"  /** <p>Expert: prepare for commit, specifying\n   *  commitUserData Map (String -> String).  This does the\n   *  first phase of 2-phase commit. This method does all\n   *  steps necessary to commit changes since this writer\n   *  was opened: flushes pending added and deleted docs,\n   *  syncs the index files, writes most of next segments_N\n   *  file.  After calling this you must call either {@link\n   *  #commit()} to finish the commit, or {@link\n   *  #rollback()} to revert the commit and undo all changes\n   *  done since the writer was opened.</p>\n   *\n   *  You can also just call {@link #commit(Map)} directly\n   *  without prepareCommit first in which case that method\n   *  will internally call prepareCommit.\n   *\n   *  <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   *  you should immediately close the writer.  See <a\n   *  href=\"#OOME\">above</a> for details.</p>\n   *\n   *  @param commitUserData Opaque Map (String->String)\n   *  that's recorded into the segments file in the index,\n   *  and retrievable by {@link\n   *  DirectoryReader#getCommitUserData}.  Note that when\n   *  IndexWriter commits itself during {@link #close}, the\n   *  commitUserData is unchanged (just carried over from\n   *  the prior commit).  If this is null then the previous\n   *  commitUserData is kept.  Also, the commitUserData will\n   *  only \"stick\" if there are actually changes in the\n   *  index to commit.\n   */\n  public final void prepareCommit(Map<String,String> commitUserData) throws CorruptIndexException, IOException {\n    ensureOpen(false);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"prepareCommit: flush\");\n      infoStream.message(\"IW\", \"  index before flush \" + segString());\n    }\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot commit\");\n    }\n\n    if (pendingCommit != null) {\n      throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n    }\n\n    doBeforeFlush();\n    assert testPoint(\"startDoFlush\");\n    SegmentInfos toCommit = null;\n    boolean anySegmentsFlushed = false;\n\n    // This is copied from doFlush, except it's modified to\n    // clone & incRef the flushed SegmentInfos inside the\n    // sync block:\n\n    try {\n\n      synchronized (fullFlushLock) {\n        boolean flushSuccess = false;\n        boolean success = false;\n        try {\n          anySegmentsFlushed = docWriter.flushAllThreads();\n          if (!anySegmentsFlushed) {\n            // prevent double increment since docWriter#doFlush increments the flushcount\n            // if we flushed anything.\n            flushCount.incrementAndGet();\n          }\n          flushSuccess = true;\n\n          synchronized(this) {\n            maybeApplyDeletes(true);\n\n            readerPool.commit(segmentInfos);\n\n            // Must clone the segmentInfos while we still\n            // hold fullFlushLock and while sync'd so that\n            // no partial changes (eg a delete w/o\n            // corresponding add from an updateDocument) can\n            // sneak into the commit point:\n            toCommit = (SegmentInfos) segmentInfos.clone();\n\n            pendingCommitChangeCount = changeCount;\n\n            // This protects the segmentInfos we are now going\n            // to commit.  This is important in case, eg, while\n            // we are trying to sync all referenced files, a\n            // merge completes which would otherwise have\n            // removed the files we are now syncing.    \n            filesToCommit = toCommit.files(directory, false);\n            deleter.incRef(filesToCommit);\n          }\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n            }\n          }\n          // Done: finish the full flush!\n          docWriter.finishFullFlush(flushSuccess);\n          doAfterFlush();\n        }\n      }\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"prepareCommit\");\n    }\n \n    boolean success = false;\n    try {\n      if (anySegmentsFlushed) {\n        maybeMerge();\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        synchronized (this) {\n          deleter.decRef(filesToCommit);\n          filesToCommit = null;\n        }\n      }\n    }\n\n    startCommit(toCommit, commitUserData);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"438e995b4e32916f631722aab36254146830fefb","date":1328903827,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommit(Map[String,String]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommit(Map[String,String]).mjava","sourceNew":"  /** <p>Expert: prepare for commit, specifying\n   *  commitUserData Map (String -> String).  This does the\n   *  first phase of 2-phase commit. This method does all\n   *  steps necessary to commit changes since this writer\n   *  was opened: flushes pending added and deleted docs,\n   *  syncs the index files, writes most of next segments_N\n   *  file.  After calling this you must call either {@link\n   *  #commit()} to finish the commit, or {@link\n   *  #rollback()} to revert the commit and undo all changes\n   *  done since the writer was opened.</p>\n   *\n   *  You can also just call {@link #commit(Map)} directly\n   *  without prepareCommit first in which case that method\n   *  will internally call prepareCommit.\n   *\n   *  <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   *  you should immediately close the writer.  See <a\n   *  href=\"#OOME\">above</a> for details.</p>\n   *\n   *  @param commitUserData Opaque Map (String->String)\n   *  that's recorded into the segments file in the index,\n   *  and retrievable by {@link\n   *  IndexCommit#getUserData}.  Note that when\n   *  IndexWriter commits itself during {@link #close}, the\n   *  commitUserData is unchanged (just carried over from\n   *  the prior commit).  If this is null then the previous\n   *  commitUserData is kept.  Also, the commitUserData will\n   *  only \"stick\" if there are actually changes in the\n   *  index to commit.\n   */\n  public final void prepareCommit(Map<String,String> commitUserData) throws CorruptIndexException, IOException {\n    ensureOpen(false);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"prepareCommit: flush\");\n      infoStream.message(\"IW\", \"  index before flush \" + segString());\n    }\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot commit\");\n    }\n\n    if (pendingCommit != null) {\n      throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n    }\n\n    doBeforeFlush();\n    assert testPoint(\"startDoFlush\");\n    SegmentInfos toCommit = null;\n    boolean anySegmentsFlushed = false;\n\n    // This is copied from doFlush, except it's modified to\n    // clone & incRef the flushed SegmentInfos inside the\n    // sync block:\n\n    try {\n\n      synchronized (fullFlushLock) {\n        boolean flushSuccess = false;\n        boolean success = false;\n        try {\n          anySegmentsFlushed = docWriter.flushAllThreads();\n          if (!anySegmentsFlushed) {\n            // prevent double increment since docWriter#doFlush increments the flushcount\n            // if we flushed anything.\n            flushCount.incrementAndGet();\n          }\n          flushSuccess = true;\n\n          synchronized(this) {\n            maybeApplyDeletes(true);\n\n            readerPool.commit(segmentInfos);\n\n            // Must clone the segmentInfos while we still\n            // hold fullFlushLock and while sync'd so that\n            // no partial changes (eg a delete w/o\n            // corresponding add from an updateDocument) can\n            // sneak into the commit point:\n            toCommit = (SegmentInfos) segmentInfos.clone();\n\n            pendingCommitChangeCount = changeCount;\n\n            // This protects the segmentInfos we are now going\n            // to commit.  This is important in case, eg, while\n            // we are trying to sync all referenced files, a\n            // merge completes which would otherwise have\n            // removed the files we are now syncing.    \n            filesToCommit = toCommit.files(directory, false);\n            deleter.incRef(filesToCommit);\n          }\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n            }\n          }\n          // Done: finish the full flush!\n          docWriter.finishFullFlush(flushSuccess);\n          doAfterFlush();\n        }\n      }\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"prepareCommit\");\n    }\n \n    boolean success = false;\n    try {\n      if (anySegmentsFlushed) {\n        maybeMerge();\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        synchronized (this) {\n          deleter.decRef(filesToCommit);\n          filesToCommit = null;\n        }\n      }\n    }\n\n    startCommit(toCommit, commitUserData);\n  }\n\n","sourceOld":"  /** <p>Expert: prepare for commit, specifying\n   *  commitUserData Map (String -> String).  This does the\n   *  first phase of 2-phase commit. This method does all\n   *  steps necessary to commit changes since this writer\n   *  was opened: flushes pending added and deleted docs,\n   *  syncs the index files, writes most of next segments_N\n   *  file.  After calling this you must call either {@link\n   *  #commit()} to finish the commit, or {@link\n   *  #rollback()} to revert the commit and undo all changes\n   *  done since the writer was opened.</p>\n   *\n   *  You can also just call {@link #commit(Map)} directly\n   *  without prepareCommit first in which case that method\n   *  will internally call prepareCommit.\n   *\n   *  <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   *  you should immediately close the writer.  See <a\n   *  href=\"#OOME\">above</a> for details.</p>\n   *\n   *  @param commitUserData Opaque Map (String->String)\n   *  that's recorded into the segments file in the index,\n   *  and retrievable by {@link\n   *  DirectoryReader#getCommitUserData}.  Note that when\n   *  IndexWriter commits itself during {@link #close}, the\n   *  commitUserData is unchanged (just carried over from\n   *  the prior commit).  If this is null then the previous\n   *  commitUserData is kept.  Also, the commitUserData will\n   *  only \"stick\" if there are actually changes in the\n   *  index to commit.\n   */\n  public final void prepareCommit(Map<String,String> commitUserData) throws CorruptIndexException, IOException {\n    ensureOpen(false);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"prepareCommit: flush\");\n      infoStream.message(\"IW\", \"  index before flush \" + segString());\n    }\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot commit\");\n    }\n\n    if (pendingCommit != null) {\n      throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n    }\n\n    doBeforeFlush();\n    assert testPoint(\"startDoFlush\");\n    SegmentInfos toCommit = null;\n    boolean anySegmentsFlushed = false;\n\n    // This is copied from doFlush, except it's modified to\n    // clone & incRef the flushed SegmentInfos inside the\n    // sync block:\n\n    try {\n\n      synchronized (fullFlushLock) {\n        boolean flushSuccess = false;\n        boolean success = false;\n        try {\n          anySegmentsFlushed = docWriter.flushAllThreads();\n          if (!anySegmentsFlushed) {\n            // prevent double increment since docWriter#doFlush increments the flushcount\n            // if we flushed anything.\n            flushCount.incrementAndGet();\n          }\n          flushSuccess = true;\n\n          synchronized(this) {\n            maybeApplyDeletes(true);\n\n            readerPool.commit(segmentInfos);\n\n            // Must clone the segmentInfos while we still\n            // hold fullFlushLock and while sync'd so that\n            // no partial changes (eg a delete w/o\n            // corresponding add from an updateDocument) can\n            // sneak into the commit point:\n            toCommit = (SegmentInfos) segmentInfos.clone();\n\n            pendingCommitChangeCount = changeCount;\n\n            // This protects the segmentInfos we are now going\n            // to commit.  This is important in case, eg, while\n            // we are trying to sync all referenced files, a\n            // merge completes which would otherwise have\n            // removed the files we are now syncing.    \n            filesToCommit = toCommit.files(directory, false);\n            deleter.incRef(filesToCommit);\n          }\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n            }\n          }\n          // Done: finish the full flush!\n          docWriter.finishFullFlush(flushSuccess);\n          doAfterFlush();\n        }\n      }\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"prepareCommit\");\n    }\n \n    boolean success = false;\n    try {\n      if (anySegmentsFlushed) {\n        maybeMerge();\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        synchronized (this) {\n          deleter.decRef(filesToCommit);\n          filesToCommit = null;\n        }\n      }\n    }\n\n    startCommit(toCommit, commitUserData);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"77f2d7c2378a8a9c822e657ca7c4902aaa79f3ac","date":1331837771,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommit(Map[String,String]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommit(Map[String,String]).mjava","sourceNew":"  /** <p>Expert: prepare for commit, specifying\n   *  commitUserData Map (String -> String).  This does the\n   *  first phase of 2-phase commit. This method does all\n   *  steps necessary to commit changes since this writer\n   *  was opened: flushes pending added and deleted docs,\n   *  syncs the index files, writes most of next segments_N\n   *  file.  After calling this you must call either {@link\n   *  #commit()} to finish the commit, or {@link\n   *  #rollback()} to revert the commit and undo all changes\n   *  done since the writer was opened.</p>\n   *\n   *  <p>You can also just call {@link #commit(Map)} directly\n   *  without prepareCommit first in which case that method\n   *  will internally call prepareCommit.\n   *\n   *  <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   *  you should immediately close the writer.  See <a\n   *  href=\"#OOME\">above</a> for details.</p>\n   *\n   *  @param commitUserData Opaque Map (String->String)\n   *  that's recorded into the segments file in the index,\n   *  and retrievable by {@link\n   *  IndexCommit#getUserData}.  Note that when\n   *  IndexWriter commits itself during {@link #close}, the\n   *  commitUserData is unchanged (just carried over from\n   *  the prior commit).  If this is null then the previous\n   *  commitUserData is kept.  Also, the commitUserData will\n   *  only \"stick\" if there are actually changes in the\n   *  index to commit.\n   */\n  public final void prepareCommit(Map<String,String> commitUserData) throws CorruptIndexException, IOException {\n    ensureOpen(false);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"prepareCommit: flush\");\n      infoStream.message(\"IW\", \"  index before flush \" + segString());\n    }\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot commit\");\n    }\n\n    if (pendingCommit != null) {\n      throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n    }\n\n    doBeforeFlush();\n    assert testPoint(\"startDoFlush\");\n    SegmentInfos toCommit = null;\n    boolean anySegmentsFlushed = false;\n\n    // This is copied from doFlush, except it's modified to\n    // clone & incRef the flushed SegmentInfos inside the\n    // sync block:\n\n    try {\n\n      synchronized (fullFlushLock) {\n        boolean flushSuccess = false;\n        boolean success = false;\n        try {\n          anySegmentsFlushed = docWriter.flushAllThreads();\n          if (!anySegmentsFlushed) {\n            // prevent double increment since docWriter#doFlush increments the flushcount\n            // if we flushed anything.\n            flushCount.incrementAndGet();\n          }\n          flushSuccess = true;\n\n          synchronized(this) {\n            maybeApplyDeletes(true);\n\n            readerPool.commit(segmentInfos);\n\n            // Must clone the segmentInfos while we still\n            // hold fullFlushLock and while sync'd so that\n            // no partial changes (eg a delete w/o\n            // corresponding add from an updateDocument) can\n            // sneak into the commit point:\n            toCommit = (SegmentInfos) segmentInfos.clone();\n\n            pendingCommitChangeCount = changeCount;\n\n            // This protects the segmentInfos we are now going\n            // to commit.  This is important in case, eg, while\n            // we are trying to sync all referenced files, a\n            // merge completes which would otherwise have\n            // removed the files we are now syncing.    \n            filesToCommit = toCommit.files(directory, false);\n            deleter.incRef(filesToCommit);\n          }\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n            }\n          }\n          // Done: finish the full flush!\n          docWriter.finishFullFlush(flushSuccess);\n          doAfterFlush();\n        }\n      }\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"prepareCommit\");\n    }\n \n    boolean success = false;\n    try {\n      if (anySegmentsFlushed) {\n        maybeMerge();\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        synchronized (this) {\n          deleter.decRef(filesToCommit);\n          filesToCommit = null;\n        }\n      }\n    }\n\n    startCommit(toCommit, commitUserData);\n  }\n\n","sourceOld":"  /** <p>Expert: prepare for commit, specifying\n   *  commitUserData Map (String -> String).  This does the\n   *  first phase of 2-phase commit. This method does all\n   *  steps necessary to commit changes since this writer\n   *  was opened: flushes pending added and deleted docs,\n   *  syncs the index files, writes most of next segments_N\n   *  file.  After calling this you must call either {@link\n   *  #commit()} to finish the commit, or {@link\n   *  #rollback()} to revert the commit and undo all changes\n   *  done since the writer was opened.</p>\n   *\n   *  You can also just call {@link #commit(Map)} directly\n   *  without prepareCommit first in which case that method\n   *  will internally call prepareCommit.\n   *\n   *  <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   *  you should immediately close the writer.  See <a\n   *  href=\"#OOME\">above</a> for details.</p>\n   *\n   *  @param commitUserData Opaque Map (String->String)\n   *  that's recorded into the segments file in the index,\n   *  and retrievable by {@link\n   *  IndexCommit#getUserData}.  Note that when\n   *  IndexWriter commits itself during {@link #close}, the\n   *  commitUserData is unchanged (just carried over from\n   *  the prior commit).  If this is null then the previous\n   *  commitUserData is kept.  Also, the commitUserData will\n   *  only \"stick\" if there are actually changes in the\n   *  index to commit.\n   */\n  public final void prepareCommit(Map<String,String> commitUserData) throws CorruptIndexException, IOException {\n    ensureOpen(false);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"prepareCommit: flush\");\n      infoStream.message(\"IW\", \"  index before flush \" + segString());\n    }\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot commit\");\n    }\n\n    if (pendingCommit != null) {\n      throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n    }\n\n    doBeforeFlush();\n    assert testPoint(\"startDoFlush\");\n    SegmentInfos toCommit = null;\n    boolean anySegmentsFlushed = false;\n\n    // This is copied from doFlush, except it's modified to\n    // clone & incRef the flushed SegmentInfos inside the\n    // sync block:\n\n    try {\n\n      synchronized (fullFlushLock) {\n        boolean flushSuccess = false;\n        boolean success = false;\n        try {\n          anySegmentsFlushed = docWriter.flushAllThreads();\n          if (!anySegmentsFlushed) {\n            // prevent double increment since docWriter#doFlush increments the flushcount\n            // if we flushed anything.\n            flushCount.incrementAndGet();\n          }\n          flushSuccess = true;\n\n          synchronized(this) {\n            maybeApplyDeletes(true);\n\n            readerPool.commit(segmentInfos);\n\n            // Must clone the segmentInfos while we still\n            // hold fullFlushLock and while sync'd so that\n            // no partial changes (eg a delete w/o\n            // corresponding add from an updateDocument) can\n            // sneak into the commit point:\n            toCommit = (SegmentInfos) segmentInfos.clone();\n\n            pendingCommitChangeCount = changeCount;\n\n            // This protects the segmentInfos we are now going\n            // to commit.  This is important in case, eg, while\n            // we are trying to sync all referenced files, a\n            // merge completes which would otherwise have\n            // removed the files we are now syncing.    \n            filesToCommit = toCommit.files(directory, false);\n            deleter.incRef(filesToCommit);\n          }\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n            }\n          }\n          // Done: finish the full flush!\n          docWriter.finishFullFlush(flushSuccess);\n          doAfterFlush();\n        }\n      }\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"prepareCommit\");\n    }\n \n    boolean success = false;\n    try {\n      if (anySegmentsFlushed) {\n        maybeMerge();\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        synchronized (this) {\n          deleter.decRef(filesToCommit);\n          filesToCommit = null;\n        }\n      }\n    }\n\n    startCommit(toCommit, commitUserData);\n  }\n\n","bugFix":["d3ab91f3bb602daf6393fa7f78b11afd3400d669"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"399d5903979ca52514d2bc7e3a362e1c45885c94","date":1333042474,"type":3,"author":"Ryan McKinley","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommit(Map[String,String]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommit(Map[String,String]).mjava","sourceNew":"  /** <p>Expert: prepare for commit, specifying\n   *  commitUserData Map (String -> String).  This does the\n   *  first phase of 2-phase commit. This method does all\n   *  steps necessary to commit changes since this writer\n   *  was opened: flushes pending added and deleted docs,\n   *  syncs the index files, writes most of next segments_N\n   *  file.  After calling this you must call either {@link\n   *  #commit()} to finish the commit, or {@link\n   *  #rollback()} to revert the commit and undo all changes\n   *  done since the writer was opened.</p>\n   *\n   *  <p>You can also just call {@link #commit(Map)} directly\n   *  without prepareCommit first in which case that method\n   *  will internally call prepareCommit.\n   *\n   *  <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   *  you should immediately close the writer.  See <a\n   *  href=\"#OOME\">above</a> for details.</p>\n   *\n   *  @param commitUserData Opaque Map (String->String)\n   *  that's recorded into the segments file in the index,\n   *  and retrievable by {@link\n   *  IndexCommit#getUserData}.  Note that when\n   *  IndexWriter commits itself during {@link #close}, the\n   *  commitUserData is unchanged (just carried over from\n   *  the prior commit).  If this is null then the previous\n   *  commitUserData is kept.  Also, the commitUserData will\n   *  only \"stick\" if there are actually changes in the\n   *  index to commit.\n   */\n  public final void prepareCommit(Map<String,String> commitUserData) throws CorruptIndexException, IOException {\n    ensureOpen(false);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"prepareCommit: flush\");\n      infoStream.message(\"IW\", \"  index before flush \" + segString());\n    }\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot commit\");\n    }\n\n    if (pendingCommit != null) {\n      throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n    }\n\n    doBeforeFlush();\n    assert testPoint(\"startDoFlush\");\n    SegmentInfos toCommit = null;\n    boolean anySegmentsFlushed = false;\n\n    // This is copied from doFlush, except it's modified to\n    // clone & incRef the flushed SegmentInfos inside the\n    // sync block:\n\n    try {\n\n      synchronized (fullFlushLock) {\n        boolean flushSuccess = false;\n        boolean success = false;\n        try {\n          anySegmentsFlushed = docWriter.flushAllThreads();\n          if (!anySegmentsFlushed) {\n            // prevent double increment since docWriter#doFlush increments the flushcount\n            // if we flushed anything.\n            flushCount.incrementAndGet();\n          }\n          flushSuccess = true;\n\n          synchronized(this) {\n            maybeApplyDeletes(true);\n\n            readerPool.commit(segmentInfos);\n\n            // Must clone the segmentInfos while we still\n            // hold fullFlushLock and while sync'd so that\n            // no partial changes (eg a delete w/o\n            // corresponding add from an updateDocument) can\n            // sneak into the commit point:\n            toCommit = segmentInfos.clone();\n\n            pendingCommitChangeCount = changeCount;\n\n            // This protects the segmentInfos we are now going\n            // to commit.  This is important in case, eg, while\n            // we are trying to sync all referenced files, a\n            // merge completes which would otherwise have\n            // removed the files we are now syncing.    \n            filesToCommit = toCommit.files(directory, false);\n            deleter.incRef(filesToCommit);\n          }\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n            }\n          }\n          // Done: finish the full flush!\n          docWriter.finishFullFlush(flushSuccess);\n          doAfterFlush();\n        }\n      }\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"prepareCommit\");\n    }\n \n    boolean success = false;\n    try {\n      if (anySegmentsFlushed) {\n        maybeMerge();\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        synchronized (this) {\n          deleter.decRef(filesToCommit);\n          filesToCommit = null;\n        }\n      }\n    }\n\n    startCommit(toCommit, commitUserData);\n  }\n\n","sourceOld":"  /** <p>Expert: prepare for commit, specifying\n   *  commitUserData Map (String -> String).  This does the\n   *  first phase of 2-phase commit. This method does all\n   *  steps necessary to commit changes since this writer\n   *  was opened: flushes pending added and deleted docs,\n   *  syncs the index files, writes most of next segments_N\n   *  file.  After calling this you must call either {@link\n   *  #commit()} to finish the commit, or {@link\n   *  #rollback()} to revert the commit and undo all changes\n   *  done since the writer was opened.</p>\n   *\n   *  <p>You can also just call {@link #commit(Map)} directly\n   *  without prepareCommit first in which case that method\n   *  will internally call prepareCommit.\n   *\n   *  <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   *  you should immediately close the writer.  See <a\n   *  href=\"#OOME\">above</a> for details.</p>\n   *\n   *  @param commitUserData Opaque Map (String->String)\n   *  that's recorded into the segments file in the index,\n   *  and retrievable by {@link\n   *  IndexCommit#getUserData}.  Note that when\n   *  IndexWriter commits itself during {@link #close}, the\n   *  commitUserData is unchanged (just carried over from\n   *  the prior commit).  If this is null then the previous\n   *  commitUserData is kept.  Also, the commitUserData will\n   *  only \"stick\" if there are actually changes in the\n   *  index to commit.\n   */\n  public final void prepareCommit(Map<String,String> commitUserData) throws CorruptIndexException, IOException {\n    ensureOpen(false);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"prepareCommit: flush\");\n      infoStream.message(\"IW\", \"  index before flush \" + segString());\n    }\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot commit\");\n    }\n\n    if (pendingCommit != null) {\n      throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n    }\n\n    doBeforeFlush();\n    assert testPoint(\"startDoFlush\");\n    SegmentInfos toCommit = null;\n    boolean anySegmentsFlushed = false;\n\n    // This is copied from doFlush, except it's modified to\n    // clone & incRef the flushed SegmentInfos inside the\n    // sync block:\n\n    try {\n\n      synchronized (fullFlushLock) {\n        boolean flushSuccess = false;\n        boolean success = false;\n        try {\n          anySegmentsFlushed = docWriter.flushAllThreads();\n          if (!anySegmentsFlushed) {\n            // prevent double increment since docWriter#doFlush increments the flushcount\n            // if we flushed anything.\n            flushCount.incrementAndGet();\n          }\n          flushSuccess = true;\n\n          synchronized(this) {\n            maybeApplyDeletes(true);\n\n            readerPool.commit(segmentInfos);\n\n            // Must clone the segmentInfos while we still\n            // hold fullFlushLock and while sync'd so that\n            // no partial changes (eg a delete w/o\n            // corresponding add from an updateDocument) can\n            // sneak into the commit point:\n            toCommit = (SegmentInfos) segmentInfos.clone();\n\n            pendingCommitChangeCount = changeCount;\n\n            // This protects the segmentInfos we are now going\n            // to commit.  This is important in case, eg, while\n            // we are trying to sync all referenced files, a\n            // merge completes which would otherwise have\n            // removed the files we are now syncing.    \n            filesToCommit = toCommit.files(directory, false);\n            deleter.incRef(filesToCommit);\n          }\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n            }\n          }\n          // Done: finish the full flush!\n          docWriter.finishFullFlush(flushSuccess);\n          doAfterFlush();\n        }\n      }\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"prepareCommit\");\n    }\n \n    boolean success = false;\n    try {\n      if (anySegmentsFlushed) {\n        maybeMerge();\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        synchronized (this) {\n          deleter.decRef(filesToCommit);\n          filesToCommit = null;\n        }\n      }\n    }\n\n    startCommit(toCommit, commitUserData);\n  }\n\n","bugFix":null,"bugIntro":["f241b963c5bcd6c2293a928059dd2d64988a6042"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f241b963c5bcd6c2293a928059dd2d64988a6042","date":1340296137,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommit(Map[String,String]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommit(Map[String,String]).mjava","sourceNew":"  /** <p>Expert: prepare for commit, specifying\n   *  commitUserData Map (String -> String).  This does the\n   *  first phase of 2-phase commit. This method does all\n   *  steps necessary to commit changes since this writer\n   *  was opened: flushes pending added and deleted docs,\n   *  syncs the index files, writes most of next segments_N\n   *  file.  After calling this you must call either {@link\n   *  #commit()} to finish the commit, or {@link\n   *  #rollback()} to revert the commit and undo all changes\n   *  done since the writer was opened.</p>\n   *\n   *  <p>You can also just call {@link #commit(Map)} directly\n   *  without prepareCommit first in which case that method\n   *  will internally call prepareCommit.\n   *\n   *  <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   *  you should immediately close the writer.  See <a\n   *  href=\"#OOME\">above</a> for details.</p>\n   *\n   *  @param commitUserData Opaque Map (String->String)\n   *  that's recorded into the segments file in the index,\n   *  and retrievable by {@link\n   *  IndexCommit#getUserData}.  Note that when\n   *  IndexWriter commits itself during {@link #close}, the\n   *  commitUserData is unchanged (just carried over from\n   *  the prior commit).  If this is null then the previous\n   *  commitUserData is kept.  Also, the commitUserData will\n   *  only \"stick\" if there are actually changes in the\n   *  index to commit.\n   */\n  public final void prepareCommit(Map<String,String> commitUserData) throws CorruptIndexException, IOException {\n    ensureOpen(false);\n\n    synchronized(commitLock) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (hitOOM) {\n        throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot commit\");\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      assert testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            anySegmentsFlushed = docWriter.flushAllThreads();\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount;\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(directory, false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"prepareCommit\");\n      }\n \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge();\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            deleter.decRef(filesToCommit);\n            filesToCommit = null;\n          }\n        }\n      }\n\n      startCommit(toCommit, commitUserData);\n    }\n  }\n\n","sourceOld":"  /** <p>Expert: prepare for commit, specifying\n   *  commitUserData Map (String -> String).  This does the\n   *  first phase of 2-phase commit. This method does all\n   *  steps necessary to commit changes since this writer\n   *  was opened: flushes pending added and deleted docs,\n   *  syncs the index files, writes most of next segments_N\n   *  file.  After calling this you must call either {@link\n   *  #commit()} to finish the commit, or {@link\n   *  #rollback()} to revert the commit and undo all changes\n   *  done since the writer was opened.</p>\n   *\n   *  <p>You can also just call {@link #commit(Map)} directly\n   *  without prepareCommit first in which case that method\n   *  will internally call prepareCommit.\n   *\n   *  <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   *  you should immediately close the writer.  See <a\n   *  href=\"#OOME\">above</a> for details.</p>\n   *\n   *  @param commitUserData Opaque Map (String->String)\n   *  that's recorded into the segments file in the index,\n   *  and retrievable by {@link\n   *  IndexCommit#getUserData}.  Note that when\n   *  IndexWriter commits itself during {@link #close}, the\n   *  commitUserData is unchanged (just carried over from\n   *  the prior commit).  If this is null then the previous\n   *  commitUserData is kept.  Also, the commitUserData will\n   *  only \"stick\" if there are actually changes in the\n   *  index to commit.\n   */\n  public final void prepareCommit(Map<String,String> commitUserData) throws CorruptIndexException, IOException {\n    ensureOpen(false);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"prepareCommit: flush\");\n      infoStream.message(\"IW\", \"  index before flush \" + segString());\n    }\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot commit\");\n    }\n\n    if (pendingCommit != null) {\n      throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n    }\n\n    doBeforeFlush();\n    assert testPoint(\"startDoFlush\");\n    SegmentInfos toCommit = null;\n    boolean anySegmentsFlushed = false;\n\n    // This is copied from doFlush, except it's modified to\n    // clone & incRef the flushed SegmentInfos inside the\n    // sync block:\n\n    try {\n\n      synchronized (fullFlushLock) {\n        boolean flushSuccess = false;\n        boolean success = false;\n        try {\n          anySegmentsFlushed = docWriter.flushAllThreads();\n          if (!anySegmentsFlushed) {\n            // prevent double increment since docWriter#doFlush increments the flushcount\n            // if we flushed anything.\n            flushCount.incrementAndGet();\n          }\n          flushSuccess = true;\n\n          synchronized(this) {\n            maybeApplyDeletes(true);\n\n            readerPool.commit(segmentInfos);\n\n            // Must clone the segmentInfos while we still\n            // hold fullFlushLock and while sync'd so that\n            // no partial changes (eg a delete w/o\n            // corresponding add from an updateDocument) can\n            // sneak into the commit point:\n            toCommit = segmentInfos.clone();\n\n            pendingCommitChangeCount = changeCount;\n\n            // This protects the segmentInfos we are now going\n            // to commit.  This is important in case, eg, while\n            // we are trying to sync all referenced files, a\n            // merge completes which would otherwise have\n            // removed the files we are now syncing.    \n            filesToCommit = toCommit.files(directory, false);\n            deleter.incRef(filesToCommit);\n          }\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n            }\n          }\n          // Done: finish the full flush!\n          docWriter.finishFullFlush(flushSuccess);\n          doAfterFlush();\n        }\n      }\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"prepareCommit\");\n    }\n \n    boolean success = false;\n    try {\n      if (anySegmentsFlushed) {\n        maybeMerge();\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        synchronized (this) {\n          deleter.decRef(filesToCommit);\n          filesToCommit = null;\n        }\n      }\n    }\n\n    startCommit(toCommit, commitUserData);\n  }\n\n","bugFix":["06584e6e98d592b34e1329b384182f368d2025e8","58c6bbc222f074c844e736e6fb23647e3db9cfe3","ce99e2b80b5a9cb2b9b59c01219e5397b081dcd8","c5df35ab57c223ea11aec64b53bf611904f3dced","399d5903979ca52514d2bc7e3a362e1c45885c94","c00afe74a80796ed1f30a9509b150ff104746a1f","47d5b6b2c183bf4deaffb52b7cb8dec16c8dcf0f","ed64610da1b28a1c2c9d0a27212adef27ae1baad","f7719bda090a2ae5bab940a27ba7bb9054b29818"],"bugIntro":["901d103ab7c2eeae92b111fc91bb1b00580a3fd7","f372764a5bd3ebacde5b99ee3303153eb5ec0d2f","f372764a5bd3ebacde5b99ee3303153eb5ec0d2f","f372764a5bd3ebacde5b99ee3303153eb5ec0d2f","f372764a5bd3ebacde5b99ee3303153eb5ec0d2f","f372764a5bd3ebacde5b99ee3303153eb5ec0d2f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4d3e8520fd031bab31fd0e4d480e55958bc45efe","date":1340901565,"type":3,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommit(Map[String,String]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommit(Map[String,String]).mjava","sourceNew":"  /** <p>Expert: prepare for commit, specifying\n   *  commitUserData Map (String -> String).  This does the\n   *  first phase of 2-phase commit. This method does all\n   *  steps necessary to commit changes since this writer\n   *  was opened: flushes pending added and deleted docs,\n   *  syncs the index files, writes most of next segments_N\n   *  file.  After calling this you must call either {@link\n   *  #commit()} to finish the commit, or {@link\n   *  #rollback()} to revert the commit and undo all changes\n   *  done since the writer was opened.</p>\n   *\n   *  <p>You can also just call {@link #commit(Map)} directly\n   *  without prepareCommit first in which case that method\n   *  will internally call prepareCommit.\n   *\n   *  <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   *  you should immediately close the writer.  See <a\n   *  href=\"#OOME\">above</a> for details.</p>\n   *\n   *  @param commitUserData Opaque Map (String->String)\n   *  that's recorded into the segments file in the index,\n   *  and retrievable by {@link\n   *  IndexCommit#getUserData}.  Note that when\n   *  IndexWriter commits itself during {@link #close}, the\n   *  commitUserData is unchanged (just carried over from\n   *  the prior commit).  If this is null then the previous\n   *  commitUserData is kept.  Also, the commitUserData will\n   *  only \"stick\" if there are actually changes in the\n   *  index to commit.\n   */\n  public final void prepareCommit(Map<String,String> commitUserData) throws IOException {\n    ensureOpen(false);\n\n    synchronized(commitLock) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (hitOOM) {\n        throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot commit\");\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      assert testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            anySegmentsFlushed = docWriter.flushAllThreads();\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount;\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(directory, false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"prepareCommit\");\n      }\n \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge();\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            deleter.decRef(filesToCommit);\n            filesToCommit = null;\n          }\n        }\n      }\n\n      startCommit(toCommit, commitUserData);\n    }\n  }\n\n","sourceOld":"  /** <p>Expert: prepare for commit, specifying\n   *  commitUserData Map (String -> String).  This does the\n   *  first phase of 2-phase commit. This method does all\n   *  steps necessary to commit changes since this writer\n   *  was opened: flushes pending added and deleted docs,\n   *  syncs the index files, writes most of next segments_N\n   *  file.  After calling this you must call either {@link\n   *  #commit()} to finish the commit, or {@link\n   *  #rollback()} to revert the commit and undo all changes\n   *  done since the writer was opened.</p>\n   *\n   *  <p>You can also just call {@link #commit(Map)} directly\n   *  without prepareCommit first in which case that method\n   *  will internally call prepareCommit.\n   *\n   *  <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   *  you should immediately close the writer.  See <a\n   *  href=\"#OOME\">above</a> for details.</p>\n   *\n   *  @param commitUserData Opaque Map (String->String)\n   *  that's recorded into the segments file in the index,\n   *  and retrievable by {@link\n   *  IndexCommit#getUserData}.  Note that when\n   *  IndexWriter commits itself during {@link #close}, the\n   *  commitUserData is unchanged (just carried over from\n   *  the prior commit).  If this is null then the previous\n   *  commitUserData is kept.  Also, the commitUserData will\n   *  only \"stick\" if there are actually changes in the\n   *  index to commit.\n   */\n  public final void prepareCommit(Map<String,String> commitUserData) throws CorruptIndexException, IOException {\n    ensureOpen(false);\n\n    synchronized(commitLock) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (hitOOM) {\n        throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot commit\");\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      assert testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            anySegmentsFlushed = docWriter.flushAllThreads();\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount;\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(directory, false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"prepareCommit\");\n      }\n \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge();\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            deleter.decRef(filesToCommit);\n            filesToCommit = null;\n          }\n        }\n      }\n\n      startCommit(toCommit, commitUserData);\n    }\n  }\n\n","bugFix":["ef82ff03e4016c705811b2658e81471a645c0e49"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fe33227f6805edab2036cbb80645cc4e2d1fa424","date":1342713534,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommit(Map[String,String]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommit(Map[String,String]).mjava","sourceNew":"  /** <p>Expert: prepare for commit, specifying\n   *  commitUserData Map (String -> String).  This does the\n   *  first phase of 2-phase commit. This method does all\n   *  steps necessary to commit changes since this writer\n   *  was opened: flushes pending added and deleted docs,\n   *  syncs the index files, writes most of next segments_N\n   *  file.  After calling this you must call either {@link\n   *  #commit()} to finish the commit, or {@link\n   *  #rollback()} to revert the commit and undo all changes\n   *  done since the writer was opened.</p>\n   *\n   *  <p>You can also just call {@link #commit(Map)} directly\n   *  without prepareCommit first in which case that method\n   *  will internally call prepareCommit.\n   *\n   *  <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   *  you should immediately close the writer.  See <a\n   *  href=\"#OOME\">above</a> for details.</p>\n   *\n   *  @param commitUserData Opaque Map (String->String)\n   *  that's recorded into the segments file in the index,\n   *  and retrievable by {@link\n   *  IndexCommit#getUserData}.  Note that when\n   *  IndexWriter commits itself during {@link #close}, the\n   *  commitUserData is unchanged (just carried over from\n   *  the prior commit).  If this is null then the previous\n   *  commitUserData is kept.  Also, the commitUserData will\n   *  only \"stick\" if there are actually changes in the\n   *  index to commit.\n   */\n  public final void prepareCommit(Map<String,String> commitUserData) throws IOException {\n    ensureOpen(false);\n\n    synchronized(commitLock) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (hitOOM) {\n        throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot commit\");\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      assert testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            anySegmentsFlushed = docWriter.flushAllThreads();\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount;\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(directory, false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"prepareCommit\");\n      }\n \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge();\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            deleter.decRef(filesToCommit);\n            filesToCommit = null;\n          }\n        }\n      }\n\n      startCommit(toCommit, commitUserData);\n    }\n  }\n\n","sourceOld":"  /** <p>Expert: prepare for commit, specifying\n   *  commitUserData Map (String -> String).  This does the\n   *  first phase of 2-phase commit. This method does all\n   *  steps necessary to commit changes since this writer\n   *  was opened: flushes pending added and deleted docs,\n   *  syncs the index files, writes most of next segments_N\n   *  file.  After calling this you must call either {@link\n   *  #commit()} to finish the commit, or {@link\n   *  #rollback()} to revert the commit and undo all changes\n   *  done since the writer was opened.</p>\n   *\n   *  <p>You can also just call {@link #commit(Map)} directly\n   *  without prepareCommit first in which case that method\n   *  will internally call prepareCommit.\n   *\n   *  <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   *  you should immediately close the writer.  See <a\n   *  href=\"#OOME\">above</a> for details.</p>\n   *\n   *  @param commitUserData Opaque Map (String->String)\n   *  that's recorded into the segments file in the index,\n   *  and retrievable by {@link\n   *  IndexCommit#getUserData}.  Note that when\n   *  IndexWriter commits itself during {@link #close}, the\n   *  commitUserData is unchanged (just carried over from\n   *  the prior commit).  If this is null then the previous\n   *  commitUserData is kept.  Also, the commitUserData will\n   *  only \"stick\" if there are actually changes in the\n   *  index to commit.\n   */\n  public final void prepareCommit(Map<String,String> commitUserData) throws CorruptIndexException, IOException {\n    ensureOpen(false);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"prepareCommit: flush\");\n      infoStream.message(\"IW\", \"  index before flush \" + segString());\n    }\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot commit\");\n    }\n\n    if (pendingCommit != null) {\n      throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n    }\n\n    doBeforeFlush();\n    assert testPoint(\"startDoFlush\");\n    SegmentInfos toCommit = null;\n    boolean anySegmentsFlushed = false;\n\n    // This is copied from doFlush, except it's modified to\n    // clone & incRef the flushed SegmentInfos inside the\n    // sync block:\n\n    try {\n\n      synchronized (fullFlushLock) {\n        boolean flushSuccess = false;\n        boolean success = false;\n        try {\n          anySegmentsFlushed = docWriter.flushAllThreads();\n          if (!anySegmentsFlushed) {\n            // prevent double increment since docWriter#doFlush increments the flushcount\n            // if we flushed anything.\n            flushCount.incrementAndGet();\n          }\n          flushSuccess = true;\n\n          synchronized(this) {\n            maybeApplyDeletes(true);\n\n            readerPool.commit(segmentInfos);\n\n            // Must clone the segmentInfos while we still\n            // hold fullFlushLock and while sync'd so that\n            // no partial changes (eg a delete w/o\n            // corresponding add from an updateDocument) can\n            // sneak into the commit point:\n            toCommit = segmentInfos.clone();\n\n            pendingCommitChangeCount = changeCount;\n\n            // This protects the segmentInfos we are now going\n            // to commit.  This is important in case, eg, while\n            // we are trying to sync all referenced files, a\n            // merge completes which would otherwise have\n            // removed the files we are now syncing.    \n            filesToCommit = toCommit.files(directory, false);\n            deleter.incRef(filesToCommit);\n          }\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n            }\n          }\n          // Done: finish the full flush!\n          docWriter.finishFullFlush(flushSuccess);\n          doAfterFlush();\n        }\n      }\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"prepareCommit\");\n    }\n \n    boolean success = false;\n    try {\n      if (anySegmentsFlushed) {\n        maybeMerge();\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        synchronized (this) {\n          deleter.decRef(filesToCommit);\n          filesToCommit = null;\n        }\n      }\n    }\n\n    startCommit(toCommit, commitUserData);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"181b1aa5a99534972fbfd5595cdbb38bba5f39ee","date":1350576187,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommit(Map[String,String]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommit(Map[String,String]).mjava","sourceNew":"  /** <p>Expert: prepare for commit, specifying\n   *  commitUserData Map (String -> String).  This does the\n   *  first phase of 2-phase commit. This method does all\n   *  steps necessary to commit changes since this writer\n   *  was opened: flushes pending added and deleted docs,\n   *  syncs the index files, writes most of next segments_N\n   *  file.  After calling this you must call either {@link\n   *  #commit()} to finish the commit, or {@link\n   *  #rollback()} to revert the commit and undo all changes\n   *  done since the writer was opened.</p>\n   *\n   *  <p>You can also just call {@link #commit(Map)} directly\n   *  without prepareCommit first in which case that method\n   *  will internally call prepareCommit.\n   *\n   *  <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   *  you should immediately close the writer.  See <a\n   *  href=\"#OOME\">above</a> for details.</p>\n   *\n   *  @param commitUserData Opaque Map (String->String)\n   *  that's recorded into the segments file in the index,\n   *  and retrievable by {@link\n   *  IndexCommit#getUserData}.  Note that when\n   *  IndexWriter commits itself during {@link #close}, the\n   *  commitUserData is unchanged (just carried over from\n   *  the prior commit).  If this is null then the previous\n   *  commitUserData is kept.  Also, the commitUserData will\n   *  only \"stick\" if there are actually changes in the\n   *  index to commit.\n   */\n  public final void prepareCommit(Map<String,String> commitUserData) throws IOException {\n    ensureOpen(false);\n\n    synchronized(commitLock) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (hitOOM) {\n        throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot commit\");\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      assert testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            anySegmentsFlushed = docWriter.flushAllThreads();\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount;\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(directory, false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"prepareCommit\");\n      }\n \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            deleter.decRef(filesToCommit);\n            filesToCommit = null;\n          }\n        }\n      }\n\n      startCommit(toCommit, commitUserData);\n    }\n  }\n\n","sourceOld":"  /** <p>Expert: prepare for commit, specifying\n   *  commitUserData Map (String -> String).  This does the\n   *  first phase of 2-phase commit. This method does all\n   *  steps necessary to commit changes since this writer\n   *  was opened: flushes pending added and deleted docs,\n   *  syncs the index files, writes most of next segments_N\n   *  file.  After calling this you must call either {@link\n   *  #commit()} to finish the commit, or {@link\n   *  #rollback()} to revert the commit and undo all changes\n   *  done since the writer was opened.</p>\n   *\n   *  <p>You can also just call {@link #commit(Map)} directly\n   *  without prepareCommit first in which case that method\n   *  will internally call prepareCommit.\n   *\n   *  <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   *  you should immediately close the writer.  See <a\n   *  href=\"#OOME\">above</a> for details.</p>\n   *\n   *  @param commitUserData Opaque Map (String->String)\n   *  that's recorded into the segments file in the index,\n   *  and retrievable by {@link\n   *  IndexCommit#getUserData}.  Note that when\n   *  IndexWriter commits itself during {@link #close}, the\n   *  commitUserData is unchanged (just carried over from\n   *  the prior commit).  If this is null then the previous\n   *  commitUserData is kept.  Also, the commitUserData will\n   *  only \"stick\" if there are actually changes in the\n   *  index to commit.\n   */\n  public final void prepareCommit(Map<String,String> commitUserData) throws IOException {\n    ensureOpen(false);\n\n    synchronized(commitLock) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (hitOOM) {\n        throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot commit\");\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      assert testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            anySegmentsFlushed = docWriter.flushAllThreads();\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount;\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(directory, false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"prepareCommit\");\n      }\n \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge();\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            deleter.decRef(filesToCommit);\n            filesToCommit = null;\n          }\n        }\n      }\n\n      startCommit(toCommit, commitUserData);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"62e52115b56781006682fd92c6938efaf174304d","date":1351014780,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommit(Map[String,String]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommit(Map[String,String]).mjava","sourceNew":"  /** <p>Expert: prepare for commit, specifying\n   *  commitUserData Map (String -> String).  This does the\n   *  first phase of 2-phase commit. This method does all\n   *  steps necessary to commit changes since this writer\n   *  was opened: flushes pending added and deleted docs,\n   *  syncs the index files, writes most of next segments_N\n   *  file.  After calling this you must call either {@link\n   *  #commit()} to finish the commit, or {@link\n   *  #rollback()} to revert the commit and undo all changes\n   *  done since the writer was opened.</p>\n   *\n   *  <p>You can also just call {@link #commit(Map)} directly\n   *  without prepareCommit first in which case that method\n   *  will internally call prepareCommit.\n   *\n   *  <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   *  you should immediately close the writer.  See <a\n   *  href=\"#OOME\">above</a> for details.</p>\n   *\n   *  @param commitUserData Opaque Map (String->String)\n   *  that's recorded into the segments file in the index,\n   *  and retrievable by {@link\n   *  IndexCommit#getUserData}.  Note that when\n   *  IndexWriter commits itself during {@link #close}, the\n   *  commitUserData is unchanged (just carried over from\n   *  the prior commit).  If this is null then the previous\n   *  commitUserData is kept.  Also, the commitUserData will\n   *  only \"stick\" if there are actually changes in the\n   *  index to commit.\n   */\n  public final void prepareCommit(Map<String,String> commitUserData) throws IOException {\n    ensureOpen(false);\n\n    synchronized(commitLock) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (hitOOM) {\n        throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot commit\");\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      assert testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            anySegmentsFlushed = docWriter.flushAllThreads();\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount;\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(directory, false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"prepareCommit\");\n      }\n \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            deleter.decRef(filesToCommit);\n            filesToCommit = null;\n          }\n        }\n      }\n\n      startCommit(toCommit, commitUserData);\n    }\n  }\n\n","sourceOld":"  /** <p>Expert: prepare for commit, specifying\n   *  commitUserData Map (String -> String).  This does the\n   *  first phase of 2-phase commit. This method does all\n   *  steps necessary to commit changes since this writer\n   *  was opened: flushes pending added and deleted docs,\n   *  syncs the index files, writes most of next segments_N\n   *  file.  After calling this you must call either {@link\n   *  #commit()} to finish the commit, or {@link\n   *  #rollback()} to revert the commit and undo all changes\n   *  done since the writer was opened.</p>\n   *\n   *  <p>You can also just call {@link #commit(Map)} directly\n   *  without prepareCommit first in which case that method\n   *  will internally call prepareCommit.\n   *\n   *  <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   *  you should immediately close the writer.  See <a\n   *  href=\"#OOME\">above</a> for details.</p>\n   *\n   *  @param commitUserData Opaque Map (String->String)\n   *  that's recorded into the segments file in the index,\n   *  and retrievable by {@link\n   *  IndexCommit#getUserData}.  Note that when\n   *  IndexWriter commits itself during {@link #close}, the\n   *  commitUserData is unchanged (just carried over from\n   *  the prior commit).  If this is null then the previous\n   *  commitUserData is kept.  Also, the commitUserData will\n   *  only \"stick\" if there are actually changes in the\n   *  index to commit.\n   */\n  public final void prepareCommit(Map<String,String> commitUserData) throws IOException {\n    ensureOpen(false);\n\n    synchronized(commitLock) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (hitOOM) {\n        throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot commit\");\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      assert testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            anySegmentsFlushed = docWriter.flushAllThreads();\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount;\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(directory, false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"prepareCommit\");\n      }\n \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge();\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            deleter.decRef(filesToCommit);\n            filesToCommit = null;\n          }\n        }\n      }\n\n      startCommit(toCommit, commitUserData);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b47e1512544568a22b82c96169d466fae8a4b79e","date":1354519309,"type":5,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommit(Map[String,String]).mjava","sourceNew":"  private void prepareCommitInternal() throws IOException {\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (hitOOM) {\n        throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot commit\");\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      assert testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            anySegmentsFlushed = docWriter.flushAllThreads();\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount;\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(directory, false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"prepareCommit\");\n      }\n \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            deleter.decRef(filesToCommit);\n            filesToCommit = null;\n          }\n        }\n      }\n\n      startCommit(toCommit);\n    }\n  }\n\n","sourceOld":"  /** <p>Expert: prepare for commit, specifying\n   *  commitUserData Map (String -> String).  This does the\n   *  first phase of 2-phase commit. This method does all\n   *  steps necessary to commit changes since this writer\n   *  was opened: flushes pending added and deleted docs,\n   *  syncs the index files, writes most of next segments_N\n   *  file.  After calling this you must call either {@link\n   *  #commit()} to finish the commit, or {@link\n   *  #rollback()} to revert the commit and undo all changes\n   *  done since the writer was opened.</p>\n   *\n   *  <p>You can also just call {@link #commit(Map)} directly\n   *  without prepareCommit first in which case that method\n   *  will internally call prepareCommit.\n   *\n   *  <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   *  you should immediately close the writer.  See <a\n   *  href=\"#OOME\">above</a> for details.</p>\n   *\n   *  @param commitUserData Opaque Map (String->String)\n   *  that's recorded into the segments file in the index,\n   *  and retrievable by {@link\n   *  IndexCommit#getUserData}.  Note that when\n   *  IndexWriter commits itself during {@link #close}, the\n   *  commitUserData is unchanged (just carried over from\n   *  the prior commit).  If this is null then the previous\n   *  commitUserData is kept.  Also, the commitUserData will\n   *  only \"stick\" if there are actually changes in the\n   *  index to commit.\n   */\n  public final void prepareCommit(Map<String,String> commitUserData) throws IOException {\n    ensureOpen(false);\n\n    synchronized(commitLock) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (hitOOM) {\n        throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot commit\");\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      assert testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            anySegmentsFlushed = docWriter.flushAllThreads();\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount;\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(directory, false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"prepareCommit\");\n      }\n \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            deleter.decRef(filesToCommit);\n            filesToCommit = null;\n          }\n        }\n      }\n\n      startCommit(toCommit, commitUserData);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"407687e67faf6e1f02a211ca078d8e3eed631027","date":1355157407,"type":4,"author":"Robert Muir","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommit(Map[String,String]).mjava","sourceNew":null,"sourceOld":"  /** <p>Expert: prepare for commit, specifying\n   *  commitUserData Map (String -> String).  This does the\n   *  first phase of 2-phase commit. This method does all\n   *  steps necessary to commit changes since this writer\n   *  was opened: flushes pending added and deleted docs,\n   *  syncs the index files, writes most of next segments_N\n   *  file.  After calling this you must call either {@link\n   *  #commit()} to finish the commit, or {@link\n   *  #rollback()} to revert the commit and undo all changes\n   *  done since the writer was opened.</p>\n   *\n   *  <p>You can also just call {@link #commit(Map)} directly\n   *  without prepareCommit first in which case that method\n   *  will internally call prepareCommit.\n   *\n   *  <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   *  you should immediately close the writer.  See <a\n   *  href=\"#OOME\">above</a> for details.</p>\n   *\n   *  @param commitUserData Opaque Map (String->String)\n   *  that's recorded into the segments file in the index,\n   *  and retrievable by {@link\n   *  IndexCommit#getUserData}.  Note that when\n   *  IndexWriter commits itself during {@link #close}, the\n   *  commitUserData is unchanged (just carried over from\n   *  the prior commit).  If this is null then the previous\n   *  commitUserData is kept.  Also, the commitUserData will\n   *  only \"stick\" if there are actually changes in the\n   *  index to commit.\n   */\n  public final void prepareCommit(Map<String,String> commitUserData) throws IOException {\n    ensureOpen(false);\n\n    synchronized(commitLock) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (hitOOM) {\n        throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot commit\");\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      assert testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            anySegmentsFlushed = docWriter.flushAllThreads();\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount;\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(directory, false);\n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"prepareCommit\");\n      }\n \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            deleter.decRef(filesToCommit);\n            filesToCommit = null;\n          }\n        }\n      }\n\n      startCommit(toCommit, commitUserData);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"f241b963c5bcd6c2293a928059dd2d64988a6042":["399d5903979ca52514d2bc7e3a362e1c45885c94"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"407687e67faf6e1f02a211ca078d8e3eed631027":["181b1aa5a99534972fbfd5595cdbb38bba5f39ee","b47e1512544568a22b82c96169d466fae8a4b79e"],"399d5903979ca52514d2bc7e3a362e1c45885c94":["77f2d7c2378a8a9c822e657ca7c4902aaa79f3ac"],"62e52115b56781006682fd92c6938efaf174304d":["4d3e8520fd031bab31fd0e4d480e55958bc45efe","181b1aa5a99534972fbfd5595cdbb38bba5f39ee"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":["399d5903979ca52514d2bc7e3a362e1c45885c94","4d3e8520fd031bab31fd0e4d480e55958bc45efe"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"181b1aa5a99534972fbfd5595cdbb38bba5f39ee":["4d3e8520fd031bab31fd0e4d480e55958bc45efe"],"77f2d7c2378a8a9c822e657ca7c4902aaa79f3ac":["438e995b4e32916f631722aab36254146830fefb"],"b47e1512544568a22b82c96169d466fae8a4b79e":["181b1aa5a99534972fbfd5595cdbb38bba5f39ee"],"4d3e8520fd031bab31fd0e4d480e55958bc45efe":["f241b963c5bcd6c2293a928059dd2d64988a6042"],"438e995b4e32916f631722aab36254146830fefb":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b47e1512544568a22b82c96169d466fae8a4b79e"]},"commit2Childs":{"f241b963c5bcd6c2293a928059dd2d64988a6042":["4d3e8520fd031bab31fd0e4d480e55958bc45efe"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["438e995b4e32916f631722aab36254146830fefb"],"407687e67faf6e1f02a211ca078d8e3eed631027":[],"399d5903979ca52514d2bc7e3a362e1c45885c94":["f241b963c5bcd6c2293a928059dd2d64988a6042","fe33227f6805edab2036cbb80645cc4e2d1fa424"],"62e52115b56781006682fd92c6938efaf174304d":[],"fe33227f6805edab2036cbb80645cc4e2d1fa424":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"181b1aa5a99534972fbfd5595cdbb38bba5f39ee":["407687e67faf6e1f02a211ca078d8e3eed631027","62e52115b56781006682fd92c6938efaf174304d","b47e1512544568a22b82c96169d466fae8a4b79e"],"77f2d7c2378a8a9c822e657ca7c4902aaa79f3ac":["399d5903979ca52514d2bc7e3a362e1c45885c94"],"b47e1512544568a22b82c96169d466fae8a4b79e":["407687e67faf6e1f02a211ca078d8e3eed631027","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"4d3e8520fd031bab31fd0e4d480e55958bc45efe":["62e52115b56781006682fd92c6938efaf174304d","fe33227f6805edab2036cbb80645cc4e2d1fa424","181b1aa5a99534972fbfd5595cdbb38bba5f39ee"],"438e995b4e32916f631722aab36254146830fefb":["77f2d7c2378a8a9c822e657ca7c4902aaa79f3ac"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["407687e67faf6e1f02a211ca078d8e3eed631027","62e52115b56781006682fd92c6938efaf174304d","fe33227f6805edab2036cbb80645cc4e2d1fa424","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}