{"path":"lucene/test-framework/src/java/org/apache/lucene/index/BaseTermVectorsFormatTestCase.RandomTokenStream#RandomTokenStream(int,String[],BytesRef[],boolean).mjava","commits":[{"id":"f21ce13f410ee015e1ba14687ab4b8518ac52a11","date":1359713213,"type":1,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseTermVectorsFormatTestCase.RandomTokenStream#RandomTokenStream(int,String[],BytesRef[],boolean).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPayloadsOnVectors.RandomTokenStream#RandomTokenStream(int,String[],boolean).mjava","sourceNew":"    protected RandomTokenStream(int len, String[] sampleTerms, BytesRef[] sampleTermBytes, boolean offsetsGoBackwards) {\n      terms = new String[len];\n      termBytes = new BytesRef[len];\n      positionsIncrements = new int[len];\n      positions = new int[len];\n      startOffsets = new int[len];\n      endOffsets = new int[len];\n      payloads = new BytesRef[len];\n      for (int i = 0; i < len; ++i) {\n        final int o = random().nextInt(sampleTerms.length);\n        terms[i] = sampleTerms[o];\n        termBytes[i] = sampleTermBytes[o];\n        positionsIncrements[i] = _TestUtil.nextInt(random(), i == 0 ? 1 : 0, 10);\n        if (offsetsGoBackwards) {\n          startOffsets[i] = random().nextInt();\n          endOffsets[i] = random().nextInt();\n        } else {\n          if (i == 0) {\n            startOffsets[i] = _TestUtil.nextInt(random(), 0, 1 << 16);\n          } else {\n            startOffsets[i] = startOffsets[i-1] + _TestUtil.nextInt(random(), 0, rarely() ? 1 << 16 : 20);\n          }\n          endOffsets[i] = startOffsets[i] + _TestUtil.nextInt(random(), 0, rarely() ? 1 << 10 : 20);\n        }\n      }\n\n      for (int i = 0; i < len; ++i) {\n        if (i == 0) {\n          positions[i] = positionsIncrements[i] - 1;\n        } else {\n          positions[i] = positions[i - 1] + positionsIncrements[i];\n        }\n      }\n      if (rarely()) {\n        Arrays.fill(payloads, randomPayload());\n      } else {\n        for (int i = 0; i < len; ++i) {\n          payloads[i] = randomPayload();\n        }\n      }\n\n      positionToTerms = new HashMap<Integer, Set<Integer>>(len);\n      startOffsetToTerms = new HashMap<Integer, Set<Integer>>(len);\n      for (int i = 0; i < len; ++i) {\n        if (!positionToTerms.containsKey(positions[i])) {\n          positionToTerms.put(positions[i], new HashSet<Integer>(1));\n        }\n        positionToTerms.get(positions[i]).add(i);\n        if (!startOffsetToTerms.containsKey(startOffsets[i])) {\n          startOffsetToTerms.put(startOffsets[i], new HashSet<Integer>(1));\n        }\n        startOffsetToTerms.get(startOffsets[i]).add(i);\n      }\n\n      freqs = new HashMap<String, Integer>();\n      for (String term : terms) {\n        if (freqs.containsKey(term)) {\n          freqs.put(term, freqs.get(term) + 1);\n        } else {\n          freqs.put(term, 1);\n        }\n      }\n\n      addAttributeImpl(new PermissiveOffsetAttributeImpl());\n\n      termAtt = addAttribute(CharTermAttribute.class);\n      piAtt = addAttribute(PositionIncrementAttribute.class);\n      oAtt = addAttribute(OffsetAttribute.class);\n      pAtt = addAttribute(PayloadAttribute.class);\n    }\n\n","sourceOld":"    RandomTokenStream(int len, String[] sampleTerms, boolean weird) {\n      terms = new String[len];\n      positionsIncrements = new int[len];\n      positions = new int[len];\n      startOffsets = new int[len];\n      endOffsets = new int[len];\n      payloads = new BytesRef[len];\n      for (int i = 0; i < len; ++i) {\n        terms[i] = RandomPicks.randomFrom(random(), sampleTerms);\n        if (weird) {\n          positionsIncrements[i] = _TestUtil.nextInt(random(), 1, 1 << 18);\n          startOffsets[i] = random().nextInt();\n          endOffsets[i] = random().nextInt();\n        } else if (i == 0) {\n          positionsIncrements[i] = _TestUtil.nextInt(random(), 1, 1 << 5);\n          startOffsets[i] = _TestUtil.nextInt(random(), 0, 1 << 16);\n          endOffsets[i] = startOffsets[i] + _TestUtil.nextInt(random(), 0, rarely() ? 1 << 10 : 20);\n        } else {\n          positionsIncrements[i] = _TestUtil.nextInt(random(), 0, 1 << 5);\n          startOffsets[i] = startOffsets[i-1] + _TestUtil.nextInt(random(), 0, 1 << 16);\n          endOffsets[i] = startOffsets[i] + _TestUtil.nextInt(random(), 0, rarely() ? 1 << 10 : 20);\n        }\n      }\n      for (int i = 0; i < len; ++i) {\n        if (i == 0) {\n          positions[i] = positionsIncrements[i] - 1;\n        } else {\n          positions[i] = positions[i - 1] + positionsIncrements[i];\n        }\n      }\n      if (rarely()) {\n        Arrays.fill(payloads, randomPayload());\n      } else {\n        for (int i = 0; i < len; ++i) {\n          payloads[i] = randomPayload();\n        }\n      }\n\n      positionToTerms = new HashMap<Integer, Set<Integer>>();\n      startOffsetToTerms = new HashMap<Integer, Set<Integer>>();\n      for (int i = 0; i < len; ++i) {\n        if (!positionToTerms.containsKey(positions[i])) {\n          positionToTerms.put(positions[i], new HashSet<Integer>(1));\n        }\n        positionToTerms.get(positions[i]).add(i);\n        if (!startOffsetToTerms.containsKey(startOffsets[i])) {\n          startOffsetToTerms.put(startOffsets[i], new HashSet<Integer>(1));\n        }\n        startOffsetToTerms.get(startOffsets[i]).add(i);\n      }\n\n      addAttributeImpl(new PermissiveOffsetAttributeImpl());\n\n      termAtt = addAttribute(CharTermAttribute.class);\n      piAtt = addAttribute(PositionIncrementAttribute.class);\n      oAtt = addAttribute(OffsetAttribute.class);\n      pAtt = addAttribute(PayloadAttribute.class);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0fa6955ed1b1007ded1349ab72cea4555640432f","date":1359721908,"type":1,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseTermVectorsFormatTestCase.RandomTokenStream#RandomTokenStream(int,String[],BytesRef[],boolean).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPayloadsOnVectors.RandomTokenStream#RandomTokenStream(int,String[],boolean).mjava","sourceNew":"    protected RandomTokenStream(int len, String[] sampleTerms, BytesRef[] sampleTermBytes, boolean offsetsGoBackwards) {\n      terms = new String[len];\n      termBytes = new BytesRef[len];\n      positionsIncrements = new int[len];\n      positions = new int[len];\n      startOffsets = new int[len];\n      endOffsets = new int[len];\n      payloads = new BytesRef[len];\n      for (int i = 0; i < len; ++i) {\n        final int o = random().nextInt(sampleTerms.length);\n        terms[i] = sampleTerms[o];\n        termBytes[i] = sampleTermBytes[o];\n        positionsIncrements[i] = _TestUtil.nextInt(random(), i == 0 ? 1 : 0, 10);\n        if (offsetsGoBackwards) {\n          startOffsets[i] = random().nextInt();\n          endOffsets[i] = random().nextInt();\n        } else {\n          if (i == 0) {\n            startOffsets[i] = _TestUtil.nextInt(random(), 0, 1 << 16);\n          } else {\n            startOffsets[i] = startOffsets[i-1] + _TestUtil.nextInt(random(), 0, rarely() ? 1 << 16 : 20);\n          }\n          endOffsets[i] = startOffsets[i] + _TestUtil.nextInt(random(), 0, rarely() ? 1 << 10 : 20);\n        }\n      }\n\n      for (int i = 0; i < len; ++i) {\n        if (i == 0) {\n          positions[i] = positionsIncrements[i] - 1;\n        } else {\n          positions[i] = positions[i - 1] + positionsIncrements[i];\n        }\n      }\n      if (rarely()) {\n        Arrays.fill(payloads, randomPayload());\n      } else {\n        for (int i = 0; i < len; ++i) {\n          payloads[i] = randomPayload();\n        }\n      }\n\n      positionToTerms = new HashMap<Integer, Set<Integer>>(len);\n      startOffsetToTerms = new HashMap<Integer, Set<Integer>>(len);\n      for (int i = 0; i < len; ++i) {\n        if (!positionToTerms.containsKey(positions[i])) {\n          positionToTerms.put(positions[i], new HashSet<Integer>(1));\n        }\n        positionToTerms.get(positions[i]).add(i);\n        if (!startOffsetToTerms.containsKey(startOffsets[i])) {\n          startOffsetToTerms.put(startOffsets[i], new HashSet<Integer>(1));\n        }\n        startOffsetToTerms.get(startOffsets[i]).add(i);\n      }\n\n      freqs = new HashMap<String, Integer>();\n      for (String term : terms) {\n        if (freqs.containsKey(term)) {\n          freqs.put(term, freqs.get(term) + 1);\n        } else {\n          freqs.put(term, 1);\n        }\n      }\n\n      addAttributeImpl(new PermissiveOffsetAttributeImpl());\n\n      termAtt = addAttribute(CharTermAttribute.class);\n      piAtt = addAttribute(PositionIncrementAttribute.class);\n      oAtt = addAttribute(OffsetAttribute.class);\n      pAtt = addAttribute(PayloadAttribute.class);\n    }\n\n","sourceOld":"    RandomTokenStream(int len, String[] sampleTerms, boolean weird) {\n      terms = new String[len];\n      positionsIncrements = new int[len];\n      positions = new int[len];\n      startOffsets = new int[len];\n      endOffsets = new int[len];\n      payloads = new BytesRef[len];\n      for (int i = 0; i < len; ++i) {\n        terms[i] = RandomPicks.randomFrom(random(), sampleTerms);\n        if (weird) {\n          positionsIncrements[i] = _TestUtil.nextInt(random(), 1, 1 << 18);\n          startOffsets[i] = random().nextInt();\n          endOffsets[i] = random().nextInt();\n        } else if (i == 0) {\n          positionsIncrements[i] = _TestUtil.nextInt(random(), 1, 1 << 5);\n          startOffsets[i] = _TestUtil.nextInt(random(), 0, 1 << 16);\n          endOffsets[i] = startOffsets[i] + _TestUtil.nextInt(random(), 0, rarely() ? 1 << 10 : 20);\n        } else {\n          positionsIncrements[i] = _TestUtil.nextInt(random(), 0, 1 << 5);\n          startOffsets[i] = startOffsets[i-1] + _TestUtil.nextInt(random(), 0, 1 << 16);\n          endOffsets[i] = startOffsets[i] + _TestUtil.nextInt(random(), 0, rarely() ? 1 << 10 : 20);\n        }\n      }\n      for (int i = 0; i < len; ++i) {\n        if (i == 0) {\n          positions[i] = positionsIncrements[i] - 1;\n        } else {\n          positions[i] = positions[i - 1] + positionsIncrements[i];\n        }\n      }\n      if (rarely()) {\n        Arrays.fill(payloads, randomPayload());\n      } else {\n        for (int i = 0; i < len; ++i) {\n          payloads[i] = randomPayload();\n        }\n      }\n\n      positionToTerms = new HashMap<Integer, Set<Integer>>();\n      startOffsetToTerms = new HashMap<Integer, Set<Integer>>();\n      for (int i = 0; i < len; ++i) {\n        if (!positionToTerms.containsKey(positions[i])) {\n          positionToTerms.put(positions[i], new HashSet<Integer>(1));\n        }\n        positionToTerms.get(positions[i]).add(i);\n        if (!startOffsetToTerms.containsKey(startOffsets[i])) {\n          startOffsetToTerms.put(startOffsets[i], new HashSet<Integer>(1));\n        }\n        startOffsetToTerms.get(startOffsets[i]).add(i);\n      }\n\n      addAttributeImpl(new PermissiveOffsetAttributeImpl());\n\n      termAtt = addAttribute(CharTermAttribute.class);\n      piAtt = addAttribute(PositionIncrementAttribute.class);\n      oAtt = addAttribute(OffsetAttribute.class);\n      pAtt = addAttribute(PayloadAttribute.class);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6613659748fe4411a7dcf85266e55db1f95f7315","date":1392773913,"type":3,"author":"Benson Margulies","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseTermVectorsFormatTestCase.RandomTokenStream#RandomTokenStream(int,String[],BytesRef[],boolean).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/BaseTermVectorsFormatTestCase.RandomTokenStream#RandomTokenStream(int,String[],BytesRef[],boolean).mjava","sourceNew":"    protected RandomTokenStream(int len, String[] sampleTerms, BytesRef[] sampleTermBytes, boolean offsetsGoBackwards) {\n      terms = new String[len];\n      termBytes = new BytesRef[len];\n      positionsIncrements = new int[len];\n      positions = new int[len];\n      startOffsets = new int[len];\n      endOffsets = new int[len];\n      payloads = new BytesRef[len];\n      for (int i = 0; i < len; ++i) {\n        final int o = random().nextInt(sampleTerms.length);\n        terms[i] = sampleTerms[o];\n        termBytes[i] = sampleTermBytes[o];\n        positionsIncrements[i] = TestUtil.nextInt(random(), i == 0 ? 1 : 0, 10);\n        if (offsetsGoBackwards) {\n          startOffsets[i] = random().nextInt();\n          endOffsets[i] = random().nextInt();\n        } else {\n          if (i == 0) {\n            startOffsets[i] = TestUtil.nextInt(random(), 0, 1 << 16);\n          } else {\n            startOffsets[i] = startOffsets[i-1] + TestUtil.nextInt(random(), 0, rarely() ? 1 << 16 : 20);\n          }\n          endOffsets[i] = startOffsets[i] + TestUtil.nextInt(random(), 0, rarely() ? 1 << 10 : 20);\n        }\n      }\n\n      for (int i = 0; i < len; ++i) {\n        if (i == 0) {\n          positions[i] = positionsIncrements[i] - 1;\n        } else {\n          positions[i] = positions[i - 1] + positionsIncrements[i];\n        }\n      }\n      if (rarely()) {\n        Arrays.fill(payloads, randomPayload());\n      } else {\n        for (int i = 0; i < len; ++i) {\n          payloads[i] = randomPayload();\n        }\n      }\n\n      positionToTerms = new HashMap<Integer, Set<Integer>>(len);\n      startOffsetToTerms = new HashMap<Integer, Set<Integer>>(len);\n      for (int i = 0; i < len; ++i) {\n        if (!positionToTerms.containsKey(positions[i])) {\n          positionToTerms.put(positions[i], new HashSet<Integer>(1));\n        }\n        positionToTerms.get(positions[i]).add(i);\n        if (!startOffsetToTerms.containsKey(startOffsets[i])) {\n          startOffsetToTerms.put(startOffsets[i], new HashSet<Integer>(1));\n        }\n        startOffsetToTerms.get(startOffsets[i]).add(i);\n      }\n\n      freqs = new HashMap<String, Integer>();\n      for (String term : terms) {\n        if (freqs.containsKey(term)) {\n          freqs.put(term, freqs.get(term) + 1);\n        } else {\n          freqs.put(term, 1);\n        }\n      }\n\n      addAttributeImpl(new PermissiveOffsetAttributeImpl());\n\n      termAtt = addAttribute(CharTermAttribute.class);\n      piAtt = addAttribute(PositionIncrementAttribute.class);\n      oAtt = addAttribute(OffsetAttribute.class);\n      pAtt = addAttribute(PayloadAttribute.class);\n    }\n\n","sourceOld":"    protected RandomTokenStream(int len, String[] sampleTerms, BytesRef[] sampleTermBytes, boolean offsetsGoBackwards) {\n      terms = new String[len];\n      termBytes = new BytesRef[len];\n      positionsIncrements = new int[len];\n      positions = new int[len];\n      startOffsets = new int[len];\n      endOffsets = new int[len];\n      payloads = new BytesRef[len];\n      for (int i = 0; i < len; ++i) {\n        final int o = random().nextInt(sampleTerms.length);\n        terms[i] = sampleTerms[o];\n        termBytes[i] = sampleTermBytes[o];\n        positionsIncrements[i] = _TestUtil.nextInt(random(), i == 0 ? 1 : 0, 10);\n        if (offsetsGoBackwards) {\n          startOffsets[i] = random().nextInt();\n          endOffsets[i] = random().nextInt();\n        } else {\n          if (i == 0) {\n            startOffsets[i] = _TestUtil.nextInt(random(), 0, 1 << 16);\n          } else {\n            startOffsets[i] = startOffsets[i-1] + _TestUtil.nextInt(random(), 0, rarely() ? 1 << 16 : 20);\n          }\n          endOffsets[i] = startOffsets[i] + _TestUtil.nextInt(random(), 0, rarely() ? 1 << 10 : 20);\n        }\n      }\n\n      for (int i = 0; i < len; ++i) {\n        if (i == 0) {\n          positions[i] = positionsIncrements[i] - 1;\n        } else {\n          positions[i] = positions[i - 1] + positionsIncrements[i];\n        }\n      }\n      if (rarely()) {\n        Arrays.fill(payloads, randomPayload());\n      } else {\n        for (int i = 0; i < len; ++i) {\n          payloads[i] = randomPayload();\n        }\n      }\n\n      positionToTerms = new HashMap<Integer, Set<Integer>>(len);\n      startOffsetToTerms = new HashMap<Integer, Set<Integer>>(len);\n      for (int i = 0; i < len; ++i) {\n        if (!positionToTerms.containsKey(positions[i])) {\n          positionToTerms.put(positions[i], new HashSet<Integer>(1));\n        }\n        positionToTerms.get(positions[i]).add(i);\n        if (!startOffsetToTerms.containsKey(startOffsets[i])) {\n          startOffsetToTerms.put(startOffsets[i], new HashSet<Integer>(1));\n        }\n        startOffsetToTerms.get(startOffsets[i]).add(i);\n      }\n\n      freqs = new HashMap<String, Integer>();\n      for (String term : terms) {\n        if (freqs.containsKey(term)) {\n          freqs.put(term, freqs.get(term) + 1);\n        } else {\n          freqs.put(term, 1);\n        }\n      }\n\n      addAttributeImpl(new PermissiveOffsetAttributeImpl());\n\n      termAtt = addAttribute(CharTermAttribute.class);\n      piAtt = addAttribute(PositionIncrementAttribute.class);\n      oAtt = addAttribute(OffsetAttribute.class);\n      pAtt = addAttribute(PayloadAttribute.class);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseTermVectorsFormatTestCase.RandomTokenStream#RandomTokenStream(int,String[],BytesRef[],boolean).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/BaseTermVectorsFormatTestCase.RandomTokenStream#RandomTokenStream(int,String[],BytesRef[],boolean).mjava","sourceNew":"    protected RandomTokenStream(int len, String[] sampleTerms, BytesRef[] sampleTermBytes, boolean offsetsGoBackwards) {\n      terms = new String[len];\n      termBytes = new BytesRef[len];\n      positionsIncrements = new int[len];\n      positions = new int[len];\n      startOffsets = new int[len];\n      endOffsets = new int[len];\n      payloads = new BytesRef[len];\n      for (int i = 0; i < len; ++i) {\n        final int o = random().nextInt(sampleTerms.length);\n        terms[i] = sampleTerms[o];\n        termBytes[i] = sampleTermBytes[o];\n        positionsIncrements[i] = TestUtil.nextInt(random(), i == 0 ? 1 : 0, 10);\n        if (offsetsGoBackwards) {\n          startOffsets[i] = random().nextInt();\n          endOffsets[i] = random().nextInt();\n        } else {\n          if (i == 0) {\n            startOffsets[i] = TestUtil.nextInt(random(), 0, 1 << 16);\n          } else {\n            startOffsets[i] = startOffsets[i-1] + TestUtil.nextInt(random(), 0, rarely() ? 1 << 16 : 20);\n          }\n          endOffsets[i] = startOffsets[i] + TestUtil.nextInt(random(), 0, rarely() ? 1 << 10 : 20);\n        }\n      }\n\n      for (int i = 0; i < len; ++i) {\n        if (i == 0) {\n          positions[i] = positionsIncrements[i] - 1;\n        } else {\n          positions[i] = positions[i - 1] + positionsIncrements[i];\n        }\n      }\n      if (rarely()) {\n        Arrays.fill(payloads, randomPayload());\n      } else {\n        for (int i = 0; i < len; ++i) {\n          payloads[i] = randomPayload();\n        }\n      }\n\n      positionToTerms = new HashMap<>(len);\n      startOffsetToTerms = new HashMap<>(len);\n      for (int i = 0; i < len; ++i) {\n        if (!positionToTerms.containsKey(positions[i])) {\n          positionToTerms.put(positions[i], new HashSet<Integer>(1));\n        }\n        positionToTerms.get(positions[i]).add(i);\n        if (!startOffsetToTerms.containsKey(startOffsets[i])) {\n          startOffsetToTerms.put(startOffsets[i], new HashSet<Integer>(1));\n        }\n        startOffsetToTerms.get(startOffsets[i]).add(i);\n      }\n\n      freqs = new HashMap<>();\n      for (String term : terms) {\n        if (freqs.containsKey(term)) {\n          freqs.put(term, freqs.get(term) + 1);\n        } else {\n          freqs.put(term, 1);\n        }\n      }\n\n      addAttributeImpl(new PermissiveOffsetAttributeImpl());\n\n      termAtt = addAttribute(CharTermAttribute.class);\n      piAtt = addAttribute(PositionIncrementAttribute.class);\n      oAtt = addAttribute(OffsetAttribute.class);\n      pAtt = addAttribute(PayloadAttribute.class);\n    }\n\n","sourceOld":"    protected RandomTokenStream(int len, String[] sampleTerms, BytesRef[] sampleTermBytes, boolean offsetsGoBackwards) {\n      terms = new String[len];\n      termBytes = new BytesRef[len];\n      positionsIncrements = new int[len];\n      positions = new int[len];\n      startOffsets = new int[len];\n      endOffsets = new int[len];\n      payloads = new BytesRef[len];\n      for (int i = 0; i < len; ++i) {\n        final int o = random().nextInt(sampleTerms.length);\n        terms[i] = sampleTerms[o];\n        termBytes[i] = sampleTermBytes[o];\n        positionsIncrements[i] = TestUtil.nextInt(random(), i == 0 ? 1 : 0, 10);\n        if (offsetsGoBackwards) {\n          startOffsets[i] = random().nextInt();\n          endOffsets[i] = random().nextInt();\n        } else {\n          if (i == 0) {\n            startOffsets[i] = TestUtil.nextInt(random(), 0, 1 << 16);\n          } else {\n            startOffsets[i] = startOffsets[i-1] + TestUtil.nextInt(random(), 0, rarely() ? 1 << 16 : 20);\n          }\n          endOffsets[i] = startOffsets[i] + TestUtil.nextInt(random(), 0, rarely() ? 1 << 10 : 20);\n        }\n      }\n\n      for (int i = 0; i < len; ++i) {\n        if (i == 0) {\n          positions[i] = positionsIncrements[i] - 1;\n        } else {\n          positions[i] = positions[i - 1] + positionsIncrements[i];\n        }\n      }\n      if (rarely()) {\n        Arrays.fill(payloads, randomPayload());\n      } else {\n        for (int i = 0; i < len; ++i) {\n          payloads[i] = randomPayload();\n        }\n      }\n\n      positionToTerms = new HashMap<Integer, Set<Integer>>(len);\n      startOffsetToTerms = new HashMap<Integer, Set<Integer>>(len);\n      for (int i = 0; i < len; ++i) {\n        if (!positionToTerms.containsKey(positions[i])) {\n          positionToTerms.put(positions[i], new HashSet<Integer>(1));\n        }\n        positionToTerms.get(positions[i]).add(i);\n        if (!startOffsetToTerms.containsKey(startOffsets[i])) {\n          startOffsetToTerms.put(startOffsets[i], new HashSet<Integer>(1));\n        }\n        startOffsetToTerms.get(startOffsets[i]).add(i);\n      }\n\n      freqs = new HashMap<String, Integer>();\n      for (String term : terms) {\n        if (freqs.containsKey(term)) {\n          freqs.put(term, freqs.get(term) + 1);\n        } else {\n          freqs.put(term, 1);\n        }\n      }\n\n      addAttributeImpl(new PermissiveOffsetAttributeImpl());\n\n      termAtt = addAttribute(CharTermAttribute.class);\n      piAtt = addAttribute(PositionIncrementAttribute.class);\n      oAtt = addAttribute(OffsetAttribute.class);\n      pAtt = addAttribute(PayloadAttribute.class);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae230518a1a68acc124bef8df61ef94bd7c1295e","date":1417181719,"type":3,"author":"David Wayne Smiley","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseTermVectorsFormatTestCase.RandomTokenStream#RandomTokenStream(int,String[],BytesRef[],boolean).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/BaseTermVectorsFormatTestCase.RandomTokenStream#RandomTokenStream(int,String[],BytesRef[],boolean).mjava","sourceNew":"    public RandomTokenStream(int len, String[] sampleTerms, BytesRef[] sampleTermBytes, boolean offsetsGoBackwards) {\n      terms = new String[len];\n      termBytes = new BytesRef[len];\n      positionsIncrements = new int[len];\n      positions = new int[len];\n      startOffsets = new int[len];\n      endOffsets = new int[len];\n      payloads = new BytesRef[len];\n      for (int i = 0; i < len; ++i) {\n        final int o = random().nextInt(sampleTerms.length);\n        terms[i] = sampleTerms[o];\n        termBytes[i] = sampleTermBytes[o];\n        positionsIncrements[i] = TestUtil.nextInt(random(), i == 0 ? 1 : 0, 10);\n        if (offsetsGoBackwards) {\n          startOffsets[i] = random().nextInt();\n          endOffsets[i] = random().nextInt();\n        } else {\n          if (i == 0) {\n            startOffsets[i] = TestUtil.nextInt(random(), 0, 1 << 16);\n          } else {\n            startOffsets[i] = startOffsets[i-1] + TestUtil.nextInt(random(), 0, rarely() ? 1 << 16 : 20);\n          }\n          endOffsets[i] = startOffsets[i] + TestUtil.nextInt(random(), 0, rarely() ? 1 << 10 : 20);\n        }\n      }\n\n      for (int i = 0; i < len; ++i) {\n        if (i == 0) {\n          positions[i] = positionsIncrements[i] - 1;\n        } else {\n          positions[i] = positions[i - 1] + positionsIncrements[i];\n        }\n      }\n      if (rarely()) {\n        Arrays.fill(payloads, randomPayload());\n      } else {\n        for (int i = 0; i < len; ++i) {\n          payloads[i] = randomPayload();\n        }\n      }\n\n      positionToTerms = new HashMap<>(len);\n      startOffsetToTerms = new HashMap<>(len);\n      for (int i = 0; i < len; ++i) {\n        if (!positionToTerms.containsKey(positions[i])) {\n          positionToTerms.put(positions[i], new HashSet<Integer>(1));\n        }\n        positionToTerms.get(positions[i]).add(i);\n        if (!startOffsetToTerms.containsKey(startOffsets[i])) {\n          startOffsetToTerms.put(startOffsets[i], new HashSet<Integer>(1));\n        }\n        startOffsetToTerms.get(startOffsets[i]).add(i);\n      }\n\n      freqs = new HashMap<>();\n      for (String term : terms) {\n        if (freqs.containsKey(term)) {\n          freqs.put(term, freqs.get(term) + 1);\n        } else {\n          freqs.put(term, 1);\n        }\n      }\n\n      addAttributeImpl(new PermissiveOffsetAttributeImpl());\n\n      termAtt = addAttribute(CharTermAttribute.class);\n      piAtt = addAttribute(PositionIncrementAttribute.class);\n      oAtt = addAttribute(OffsetAttribute.class);\n      pAtt = addAttribute(PayloadAttribute.class);\n    }\n\n","sourceOld":"    protected RandomTokenStream(int len, String[] sampleTerms, BytesRef[] sampleTermBytes, boolean offsetsGoBackwards) {\n      terms = new String[len];\n      termBytes = new BytesRef[len];\n      positionsIncrements = new int[len];\n      positions = new int[len];\n      startOffsets = new int[len];\n      endOffsets = new int[len];\n      payloads = new BytesRef[len];\n      for (int i = 0; i < len; ++i) {\n        final int o = random().nextInt(sampleTerms.length);\n        terms[i] = sampleTerms[o];\n        termBytes[i] = sampleTermBytes[o];\n        positionsIncrements[i] = TestUtil.nextInt(random(), i == 0 ? 1 : 0, 10);\n        if (offsetsGoBackwards) {\n          startOffsets[i] = random().nextInt();\n          endOffsets[i] = random().nextInt();\n        } else {\n          if (i == 0) {\n            startOffsets[i] = TestUtil.nextInt(random(), 0, 1 << 16);\n          } else {\n            startOffsets[i] = startOffsets[i-1] + TestUtil.nextInt(random(), 0, rarely() ? 1 << 16 : 20);\n          }\n          endOffsets[i] = startOffsets[i] + TestUtil.nextInt(random(), 0, rarely() ? 1 << 10 : 20);\n        }\n      }\n\n      for (int i = 0; i < len; ++i) {\n        if (i == 0) {\n          positions[i] = positionsIncrements[i] - 1;\n        } else {\n          positions[i] = positions[i - 1] + positionsIncrements[i];\n        }\n      }\n      if (rarely()) {\n        Arrays.fill(payloads, randomPayload());\n      } else {\n        for (int i = 0; i < len; ++i) {\n          payloads[i] = randomPayload();\n        }\n      }\n\n      positionToTerms = new HashMap<>(len);\n      startOffsetToTerms = new HashMap<>(len);\n      for (int i = 0; i < len; ++i) {\n        if (!positionToTerms.containsKey(positions[i])) {\n          positionToTerms.put(positions[i], new HashSet<Integer>(1));\n        }\n        positionToTerms.get(positions[i]).add(i);\n        if (!startOffsetToTerms.containsKey(startOffsets[i])) {\n          startOffsetToTerms.put(startOffsets[i], new HashSet<Integer>(1));\n        }\n        startOffsetToTerms.get(startOffsets[i]).add(i);\n      }\n\n      freqs = new HashMap<>();\n      for (String term : terms) {\n        if (freqs.containsKey(term)) {\n          freqs.put(term, freqs.get(term) + 1);\n        } else {\n          freqs.put(term, 1);\n        }\n      }\n\n      addAttributeImpl(new PermissiveOffsetAttributeImpl());\n\n      termAtt = addAttribute(CharTermAttribute.class);\n      piAtt = addAttribute(PositionIncrementAttribute.class);\n      oAtt = addAttribute(OffsetAttribute.class);\n      pAtt = addAttribute(PayloadAttribute.class);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"762c80e29fe0c3bb83aabe2e64af6379273cec7b","date":1484347562,"type":4,"author":"Mike McCandless","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/BaseTermVectorsFormatTestCase.RandomTokenStream#RandomTokenStream(int,String[],BytesRef[],boolean).mjava","sourceNew":null,"sourceOld":"    public RandomTokenStream(int len, String[] sampleTerms, BytesRef[] sampleTermBytes, boolean offsetsGoBackwards) {\n      terms = new String[len];\n      termBytes = new BytesRef[len];\n      positionsIncrements = new int[len];\n      positions = new int[len];\n      startOffsets = new int[len];\n      endOffsets = new int[len];\n      payloads = new BytesRef[len];\n      for (int i = 0; i < len; ++i) {\n        final int o = random().nextInt(sampleTerms.length);\n        terms[i] = sampleTerms[o];\n        termBytes[i] = sampleTermBytes[o];\n        positionsIncrements[i] = TestUtil.nextInt(random(), i == 0 ? 1 : 0, 10);\n        if (offsetsGoBackwards) {\n          startOffsets[i] = random().nextInt();\n          endOffsets[i] = random().nextInt();\n        } else {\n          if (i == 0) {\n            startOffsets[i] = TestUtil.nextInt(random(), 0, 1 << 16);\n          } else {\n            startOffsets[i] = startOffsets[i-1] + TestUtil.nextInt(random(), 0, rarely() ? 1 << 16 : 20);\n          }\n          endOffsets[i] = startOffsets[i] + TestUtil.nextInt(random(), 0, rarely() ? 1 << 10 : 20);\n        }\n      }\n\n      for (int i = 0; i < len; ++i) {\n        if (i == 0) {\n          positions[i] = positionsIncrements[i] - 1;\n        } else {\n          positions[i] = positions[i - 1] + positionsIncrements[i];\n        }\n      }\n      if (rarely()) {\n        Arrays.fill(payloads, randomPayload());\n      } else {\n        for (int i = 0; i < len; ++i) {\n          payloads[i] = randomPayload();\n        }\n      }\n\n      positionToTerms = new HashMap<>(len);\n      startOffsetToTerms = new HashMap<>(len);\n      for (int i = 0; i < len; ++i) {\n        if (!positionToTerms.containsKey(positions[i])) {\n          positionToTerms.put(positions[i], new HashSet<Integer>(1));\n        }\n        positionToTerms.get(positions[i]).add(i);\n        if (!startOffsetToTerms.containsKey(startOffsets[i])) {\n          startOffsetToTerms.put(startOffsets[i], new HashSet<Integer>(1));\n        }\n        startOffsetToTerms.get(startOffsets[i]).add(i);\n      }\n\n      freqs = new HashMap<>();\n      for (String term : terms) {\n        if (freqs.containsKey(term)) {\n          freqs.put(term, freqs.get(term) + 1);\n        } else {\n          freqs.put(term, 1);\n        }\n      }\n\n      addAttributeImpl(new PermissiveOffsetAttributeImpl());\n\n      termAtt = addAttribute(CharTermAttribute.class);\n      piAtt = addAttribute(PositionIncrementAttribute.class);\n      oAtt = addAttribute(OffsetAttribute.class);\n      pAtt = addAttribute(PayloadAttribute.class);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"507e7decdf00981d09a74632ea30299a4ce6ba72","date":1484600874,"type":4,"author":"Kevin Risden","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/BaseTermVectorsFormatTestCase.RandomTokenStream#RandomTokenStream(int,String[],BytesRef[],boolean).mjava","sourceNew":null,"sourceOld":"    public RandomTokenStream(int len, String[] sampleTerms, BytesRef[] sampleTermBytes, boolean offsetsGoBackwards) {\n      terms = new String[len];\n      termBytes = new BytesRef[len];\n      positionsIncrements = new int[len];\n      positions = new int[len];\n      startOffsets = new int[len];\n      endOffsets = new int[len];\n      payloads = new BytesRef[len];\n      for (int i = 0; i < len; ++i) {\n        final int o = random().nextInt(sampleTerms.length);\n        terms[i] = sampleTerms[o];\n        termBytes[i] = sampleTermBytes[o];\n        positionsIncrements[i] = TestUtil.nextInt(random(), i == 0 ? 1 : 0, 10);\n        if (offsetsGoBackwards) {\n          startOffsets[i] = random().nextInt();\n          endOffsets[i] = random().nextInt();\n        } else {\n          if (i == 0) {\n            startOffsets[i] = TestUtil.nextInt(random(), 0, 1 << 16);\n          } else {\n            startOffsets[i] = startOffsets[i-1] + TestUtil.nextInt(random(), 0, rarely() ? 1 << 16 : 20);\n          }\n          endOffsets[i] = startOffsets[i] + TestUtil.nextInt(random(), 0, rarely() ? 1 << 10 : 20);\n        }\n      }\n\n      for (int i = 0; i < len; ++i) {\n        if (i == 0) {\n          positions[i] = positionsIncrements[i] - 1;\n        } else {\n          positions[i] = positions[i - 1] + positionsIncrements[i];\n        }\n      }\n      if (rarely()) {\n        Arrays.fill(payloads, randomPayload());\n      } else {\n        for (int i = 0; i < len; ++i) {\n          payloads[i] = randomPayload();\n        }\n      }\n\n      positionToTerms = new HashMap<>(len);\n      startOffsetToTerms = new HashMap<>(len);\n      for (int i = 0; i < len; ++i) {\n        if (!positionToTerms.containsKey(positions[i])) {\n          positionToTerms.put(positions[i], new HashSet<Integer>(1));\n        }\n        positionToTerms.get(positions[i]).add(i);\n        if (!startOffsetToTerms.containsKey(startOffsets[i])) {\n          startOffsetToTerms.put(startOffsets[i], new HashSet<Integer>(1));\n        }\n        startOffsetToTerms.get(startOffsets[i]).add(i);\n      }\n\n      freqs = new HashMap<>();\n      for (String term : terms) {\n        if (freqs.containsKey(term)) {\n          freqs.put(term, freqs.get(term) + 1);\n        } else {\n          freqs.put(term, 1);\n        }\n      }\n\n      addAttributeImpl(new PermissiveOffsetAttributeImpl());\n\n      termAtt = addAttribute(CharTermAttribute.class);\n      piAtt = addAttribute(PositionIncrementAttribute.class);\n      oAtt = addAttribute(OffsetAttribute.class);\n      pAtt = addAttribute(PayloadAttribute.class);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["6613659748fe4411a7dcf85266e55db1f95f7315"],"0fa6955ed1b1007ded1349ab72cea4555640432f":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","f21ce13f410ee015e1ba14687ab4b8518ac52a11"],"ae230518a1a68acc124bef8df61ef94bd7c1295e":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"762c80e29fe0c3bb83aabe2e64af6379273cec7b":["ae230518a1a68acc124bef8df61ef94bd7c1295e"],"6613659748fe4411a7dcf85266e55db1f95f7315":["f21ce13f410ee015e1ba14687ab4b8518ac52a11"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"f21ce13f410ee015e1ba14687ab4b8518ac52a11":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"507e7decdf00981d09a74632ea30299a4ce6ba72":["ae230518a1a68acc124bef8df61ef94bd7c1295e","762c80e29fe0c3bb83aabe2e64af6379273cec7b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["762c80e29fe0c3bb83aabe2e64af6379273cec7b"]},"commit2Childs":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["ae230518a1a68acc124bef8df61ef94bd7c1295e"],"0fa6955ed1b1007ded1349ab72cea4555640432f":[],"ae230518a1a68acc124bef8df61ef94bd7c1295e":["762c80e29fe0c3bb83aabe2e64af6379273cec7b","507e7decdf00981d09a74632ea30299a4ce6ba72"],"6613659748fe4411a7dcf85266e55db1f95f7315":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"762c80e29fe0c3bb83aabe2e64af6379273cec7b":["507e7decdf00981d09a74632ea30299a4ce6ba72","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["0fa6955ed1b1007ded1349ab72cea4555640432f","f21ce13f410ee015e1ba14687ab4b8518ac52a11"],"f21ce13f410ee015e1ba14687ab4b8518ac52a11":["0fa6955ed1b1007ded1349ab72cea4555640432f","6613659748fe4411a7dcf85266e55db1f95f7315"],"507e7decdf00981d09a74632ea30299a4ce6ba72":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["0fa6955ed1b1007ded1349ab72cea4555640432f","507e7decdf00981d09a74632ea30299a4ce6ba72","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}