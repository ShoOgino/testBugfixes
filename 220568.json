{"path":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#updateDocuments(Iterable[#-extends-Iterable[#-extends-IndexableField]],Analyzer,DocumentsWriterDeleteQueue.Node[#]).mjava","commits":[{"id":"110125c995236a7f61057dd04b039ed2d267f3a1","date":1521014987,"type":1,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#updateDocuments(Iterable[#-extends-Iterable[#-extends-IndexableField]],Analyzer,DocumentsWriterDeleteQueue.Node[#]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#updateDocuments(Iterable[#-extends-Iterable[#-extends-IndexableField]],Analyzer,Term).mjava","sourceNew":"  public long updateDocuments(Iterable<? extends Iterable<? extends IndexableField>> docs, Analyzer analyzer, DocumentsWriterDeleteQueue.Node<?> deleteNode) throws IOException, AbortingException {\n    testPoint(\"DocumentsWriterPerThread addDocuments start\");\n    assert deleteQueue != null;\n    docState.analyzer = analyzer;\n    if (INFO_VERBOSE && infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", Thread.currentThread().getName() + \" update delNode=\" + deleteNode + \" docID=\" + docState.docID + \" seg=\" + segmentInfo.name);\n    }\n    int docCount = 0;\n    boolean allDocsIndexed = false;\n    try {\n      \n      for(Iterable<? extends IndexableField> doc : docs) {\n        // Even on exception, the document is still added (but marked\n        // deleted), so we don't need to un-reserve at that point.\n        // Aborting exceptions will actually \"lose\" more than one\n        // document, so the counter will be \"wrong\" in that case, but\n        // it's very hard to fix (we can't easily distinguish aborting\n        // vs non-aborting exceptions):\n        reserveOneDoc();\n        docState.doc = doc;\n        docState.docID = numDocsInRAM;\n        docCount++;\n\n        boolean success = false;\n        try {\n          consumer.processDocument();\n          success = true;\n        } finally {\n          if (!success) {\n            // Incr here because finishDocument will not\n            // be called (because an exc is being thrown):\n            numDocsInRAM++;\n          }\n        }\n\n        numDocsInRAM++;\n      }\n      allDocsIndexed = true;\n\n      // Apply delTerm only after all indexing has\n      // succeeded, but apply it only to docs prior to when\n      // this batch started:\n      long seqNo;\n      if (deleteNode != null) {\n        seqNo = deleteQueue.add(deleteNode, deleteSlice);\n        assert deleteSlice.isTail(deleteNode) : \"expected the delete node as the tail\";\n        deleteSlice.apply(pendingUpdates, numDocsInRAM-docCount);\n        return seqNo;\n      } else {\n        seqNo = deleteQueue.updateSlice(deleteSlice);\n        if (seqNo < 0) {\n          seqNo = -seqNo;\n          deleteSlice.apply(pendingUpdates, numDocsInRAM-docCount);\n        } else {\n          deleteSlice.reset();\n        }\n      }\n\n      return seqNo;\n\n    } finally {\n      if (!allDocsIndexed && !aborted) {\n        // the iterator threw an exception that is not aborting \n        // go and mark all docs from this block as deleted\n        int docID = numDocsInRAM-1;\n        final int endDocID = docID - docCount;\n        while (docID > endDocID) {\n          deleteDocID(docID);\n          docID--;\n        }\n      }\n      docState.clear();\n    }\n  }\n\n","sourceOld":"  public long updateDocuments(Iterable<? extends Iterable<? extends IndexableField>> docs, Analyzer analyzer, Term delTerm) throws IOException, AbortingException {\n    testPoint(\"DocumentsWriterPerThread addDocuments start\");\n    assert deleteQueue != null;\n    docState.analyzer = analyzer;\n    if (INFO_VERBOSE && infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", Thread.currentThread().getName() + \" update delTerm=\" + delTerm + \" docID=\" + docState.docID + \" seg=\" + segmentInfo.name);\n    }\n    int docCount = 0;\n    boolean allDocsIndexed = false;\n    try {\n      \n      for(Iterable<? extends IndexableField> doc : docs) {\n        // Even on exception, the document is still added (but marked\n        // deleted), so we don't need to un-reserve at that point.\n        // Aborting exceptions will actually \"lose\" more than one\n        // document, so the counter will be \"wrong\" in that case, but\n        // it's very hard to fix (we can't easily distinguish aborting\n        // vs non-aborting exceptions):\n        reserveOneDoc();\n        docState.doc = doc;\n        docState.docID = numDocsInRAM;\n        docCount++;\n\n        boolean success = false;\n        try {\n          consumer.processDocument();\n          success = true;\n        } finally {\n          if (!success) {\n            // Incr here because finishDocument will not\n            // be called (because an exc is being thrown):\n            numDocsInRAM++;\n          }\n        }\n\n        numDocsInRAM++;\n      }\n      allDocsIndexed = true;\n\n      // Apply delTerm only after all indexing has\n      // succeeded, but apply it only to docs prior to when\n      // this batch started:\n      long seqNo;\n      if (delTerm != null) {\n        seqNo = deleteQueue.add(delTerm, deleteSlice);\n        assert deleteSlice.isTailItem(delTerm) : \"expected the delete term as the tail item\";\n        deleteSlice.apply(pendingUpdates, numDocsInRAM-docCount);\n        return seqNo;\n      } else {\n        seqNo = deleteQueue.updateSlice(deleteSlice);\n        if (seqNo < 0) {\n          seqNo = -seqNo;\n          deleteSlice.apply(pendingUpdates, numDocsInRAM-docCount);\n        } else {\n          deleteSlice.reset();\n        }\n      }\n\n      return seqNo;\n\n    } finally {\n      if (!allDocsIndexed && !aborted) {\n        // the iterator threw an exception that is not aborting \n        // go and mark all docs from this block as deleted\n        int docID = numDocsInRAM-1;\n        final int endDocID = docID - docCount;\n        while (docID > endDocID) {\n          deleteDocID(docID);\n          docID--;\n        }\n      }\n      docState.clear();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"845b760a99e5f369fcd0a5d723a87b8def6a3f56","date":1521117993,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#updateDocuments(Iterable[#-extends-Iterable[#-extends-IndexableField]],Analyzer,DocumentsWriterDeleteQueue.Node[#]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#updateDocuments(Iterable[#-extends-Iterable[#-extends-IndexableField]],Analyzer,DocumentsWriterDeleteQueue.Node[#]).mjava","sourceNew":"  public long updateDocuments(Iterable<? extends Iterable<? extends IndexableField>> docs, Analyzer analyzer, DocumentsWriterDeleteQueue.Node<?> deleteNode) throws IOException {\n    try {\n      testPoint(\"DocumentsWriterPerThread addDocuments start\");\n      assert hasHitAbortingException() == false: \"DWPT has hit aborting exception but is still indexing\";\n      assert deleteQueue != null;\n      docState.analyzer = analyzer;\n      if (INFO_VERBOSE && infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", Thread.currentThread().getName() + \" update delTerm=\" + deleteNode + \" docID=\" + docState.docID + \" seg=\" + segmentInfo.name);\n      }\n      int docCount = 0;\n      boolean allDocsIndexed = false;\n      try {\n\n        for (Iterable<? extends IndexableField> doc : docs) {\n          // Even on exception, the document is still added (but marked\n          // deleted), so we don't need to un-reserve at that point.\n          // Aborting exceptions will actually \"lose\" more than one\n          // document, so the counter will be \"wrong\" in that case, but\n          // it's very hard to fix (we can't easily distinguish aborting\n          // vs non-aborting exceptions):\n          reserveOneDoc();\n          docState.doc = doc;\n          docState.docID = numDocsInRAM;\n          docCount++;\n\n          boolean success = false;\n          try {\n            consumer.processDocument();\n            success = true;\n          } finally {\n            if (!success) {\n              // Incr here because finishDocument will not\n              // be called (because an exc is being thrown):\n              numDocsInRAM++;\n            }\n          }\n\n          numDocsInRAM++;\n        }\n        allDocsIndexed = true;\n\n        // Apply delTerm only after all indexing has\n        // succeeded, but apply it only to docs prior to when\n        // this batch started:\n        long seqNo;\n        if (deleteNode != null) {\n          seqNo = deleteQueue.add(deleteNode, deleteSlice);\n          assert deleteSlice.isTail(deleteNode) : \"expected the delete term as the tail item\";\n          deleteSlice.apply(pendingUpdates, numDocsInRAM - docCount);\n          return seqNo;\n        } else {\n          seqNo = deleteQueue.updateSlice(deleteSlice);\n          if (seqNo < 0) {\n            seqNo = -seqNo;\n            deleteSlice.apply(pendingUpdates, numDocsInRAM - docCount);\n          } else {\n            deleteSlice.reset();\n          }\n        }\n\n        return seqNo;\n\n      } finally {\n        if (!allDocsIndexed && !aborted) {\n          // the iterator threw an exception that is not aborting\n          // go and mark all docs from this block as deleted\n          int docID = numDocsInRAM - 1;\n          final int endDocID = docID - docCount;\n          while (docID > endDocID) {\n            deleteDocID(docID);\n            docID--;\n          }\n        }\n        docState.clear();\n      }\n    } finally {\n      maybeAbort(\"updateDocuments\");\n    }\n  }\n\n","sourceOld":"  public long updateDocuments(Iterable<? extends Iterable<? extends IndexableField>> docs, Analyzer analyzer, DocumentsWriterDeleteQueue.Node<?> deleteNode) throws IOException, AbortingException {\n    testPoint(\"DocumentsWriterPerThread addDocuments start\");\n    assert deleteQueue != null;\n    docState.analyzer = analyzer;\n    if (INFO_VERBOSE && infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", Thread.currentThread().getName() + \" update delNode=\" + deleteNode + \" docID=\" + docState.docID + \" seg=\" + segmentInfo.name);\n    }\n    int docCount = 0;\n    boolean allDocsIndexed = false;\n    try {\n      \n      for(Iterable<? extends IndexableField> doc : docs) {\n        // Even on exception, the document is still added (but marked\n        // deleted), so we don't need to un-reserve at that point.\n        // Aborting exceptions will actually \"lose\" more than one\n        // document, so the counter will be \"wrong\" in that case, but\n        // it's very hard to fix (we can't easily distinguish aborting\n        // vs non-aborting exceptions):\n        reserveOneDoc();\n        docState.doc = doc;\n        docState.docID = numDocsInRAM;\n        docCount++;\n\n        boolean success = false;\n        try {\n          consumer.processDocument();\n          success = true;\n        } finally {\n          if (!success) {\n            // Incr here because finishDocument will not\n            // be called (because an exc is being thrown):\n            numDocsInRAM++;\n          }\n        }\n\n        numDocsInRAM++;\n      }\n      allDocsIndexed = true;\n\n      // Apply delTerm only after all indexing has\n      // succeeded, but apply it only to docs prior to when\n      // this batch started:\n      long seqNo;\n      if (deleteNode != null) {\n        seqNo = deleteQueue.add(deleteNode, deleteSlice);\n        assert deleteSlice.isTail(deleteNode) : \"expected the delete node as the tail\";\n        deleteSlice.apply(pendingUpdates, numDocsInRAM-docCount);\n        return seqNo;\n      } else {\n        seqNo = deleteQueue.updateSlice(deleteSlice);\n        if (seqNo < 0) {\n          seqNo = -seqNo;\n          deleteSlice.apply(pendingUpdates, numDocsInRAM-docCount);\n        } else {\n          deleteSlice.reset();\n        }\n      }\n\n      return seqNo;\n\n    } finally {\n      if (!allDocsIndexed && !aborted) {\n        // the iterator threw an exception that is not aborting \n        // go and mark all docs from this block as deleted\n        int docID = numDocsInRAM-1;\n        final int endDocID = docID - docCount;\n        while (docID > endDocID) {\n          deleteDocID(docID);\n          docID--;\n        }\n      }\n      docState.clear();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"86a2e8a56b368d37ef3ba7180541fa317d6fd6c7","date":1524496660,"type":5,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#updateDocuments(Iterable[#-extends-Iterable[#-extends-IndexableField]],Analyzer,DocumentsWriterDeleteQueue.Node[#],DocumentsWriter.FlushNotifications).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#updateDocuments(Iterable[#-extends-Iterable[#-extends-IndexableField]],Analyzer,DocumentsWriterDeleteQueue.Node[#]).mjava","sourceNew":"  public long updateDocuments(Iterable<? extends Iterable<? extends IndexableField>> docs, Analyzer analyzer, DocumentsWriterDeleteQueue.Node<?> deleteNode, DocumentsWriter.FlushNotifications flushNotifications) throws IOException {\n    try {\n      testPoint(\"DocumentsWriterPerThread addDocuments start\");\n      assert hasHitAbortingException() == false: \"DWPT has hit aborting exception but is still indexing\";\n      assert deleteQueue != null;\n      docState.analyzer = analyzer;\n      if (INFO_VERBOSE && infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", Thread.currentThread().getName() + \" update delTerm=\" + deleteNode + \" docID=\" + docState.docID + \" seg=\" + segmentInfo.name);\n      }\n      int docCount = 0;\n      boolean allDocsIndexed = false;\n      try {\n\n        for (Iterable<? extends IndexableField> doc : docs) {\n          // Even on exception, the document is still added (but marked\n          // deleted), so we don't need to un-reserve at that point.\n          // Aborting exceptions will actually \"lose\" more than one\n          // document, so the counter will be \"wrong\" in that case, but\n          // it's very hard to fix (we can't easily distinguish aborting\n          // vs non-aborting exceptions):\n          reserveOneDoc();\n          docState.doc = doc;\n          docState.docID = numDocsInRAM;\n          docCount++;\n\n          boolean success = false;\n          try {\n            consumer.processDocument();\n            success = true;\n          } finally {\n            if (!success) {\n              // Incr here because finishDocument will not\n              // be called (because an exc is being thrown):\n              numDocsInRAM++;\n            }\n          }\n\n          numDocsInRAM++;\n        }\n        allDocsIndexed = true;\n\n        // Apply delTerm only after all indexing has\n        // succeeded, but apply it only to docs prior to when\n        // this batch started:\n        long seqNo;\n        if (deleteNode != null) {\n          seqNo = deleteQueue.add(deleteNode, deleteSlice);\n          assert deleteSlice.isTail(deleteNode) : \"expected the delete term as the tail item\";\n          deleteSlice.apply(pendingUpdates, numDocsInRAM - docCount);\n          return seqNo;\n        } else {\n          seqNo = deleteQueue.updateSlice(deleteSlice);\n          if (seqNo < 0) {\n            seqNo = -seqNo;\n            deleteSlice.apply(pendingUpdates, numDocsInRAM - docCount);\n          } else {\n            deleteSlice.reset();\n          }\n        }\n\n        return seqNo;\n\n      } finally {\n        if (!allDocsIndexed && !aborted) {\n          // the iterator threw an exception that is not aborting\n          // go and mark all docs from this block as deleted\n          int docID = numDocsInRAM - 1;\n          final int endDocID = docID - docCount;\n          while (docID > endDocID) {\n            deleteDocID(docID);\n            docID--;\n          }\n        }\n        docState.clear();\n      }\n    } finally {\n      maybeAbort(\"updateDocuments\", flushNotifications);\n    }\n  }\n\n","sourceOld":"  public long updateDocuments(Iterable<? extends Iterable<? extends IndexableField>> docs, Analyzer analyzer, DocumentsWriterDeleteQueue.Node<?> deleteNode) throws IOException {\n    try {\n      testPoint(\"DocumentsWriterPerThread addDocuments start\");\n      assert hasHitAbortingException() == false: \"DWPT has hit aborting exception but is still indexing\";\n      assert deleteQueue != null;\n      docState.analyzer = analyzer;\n      if (INFO_VERBOSE && infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", Thread.currentThread().getName() + \" update delTerm=\" + deleteNode + \" docID=\" + docState.docID + \" seg=\" + segmentInfo.name);\n      }\n      int docCount = 0;\n      boolean allDocsIndexed = false;\n      try {\n\n        for (Iterable<? extends IndexableField> doc : docs) {\n          // Even on exception, the document is still added (but marked\n          // deleted), so we don't need to un-reserve at that point.\n          // Aborting exceptions will actually \"lose\" more than one\n          // document, so the counter will be \"wrong\" in that case, but\n          // it's very hard to fix (we can't easily distinguish aborting\n          // vs non-aborting exceptions):\n          reserveOneDoc();\n          docState.doc = doc;\n          docState.docID = numDocsInRAM;\n          docCount++;\n\n          boolean success = false;\n          try {\n            consumer.processDocument();\n            success = true;\n          } finally {\n            if (!success) {\n              // Incr here because finishDocument will not\n              // be called (because an exc is being thrown):\n              numDocsInRAM++;\n            }\n          }\n\n          numDocsInRAM++;\n        }\n        allDocsIndexed = true;\n\n        // Apply delTerm only after all indexing has\n        // succeeded, but apply it only to docs prior to when\n        // this batch started:\n        long seqNo;\n        if (deleteNode != null) {\n          seqNo = deleteQueue.add(deleteNode, deleteSlice);\n          assert deleteSlice.isTail(deleteNode) : \"expected the delete term as the tail item\";\n          deleteSlice.apply(pendingUpdates, numDocsInRAM - docCount);\n          return seqNo;\n        } else {\n          seqNo = deleteQueue.updateSlice(deleteSlice);\n          if (seqNo < 0) {\n            seqNo = -seqNo;\n            deleteSlice.apply(pendingUpdates, numDocsInRAM - docCount);\n          } else {\n            deleteSlice.reset();\n          }\n        }\n\n        return seqNo;\n\n      } finally {\n        if (!allDocsIndexed && !aborted) {\n          // the iterator threw an exception that is not aborting\n          // go and mark all docs from this block as deleted\n          int docID = numDocsInRAM - 1;\n          final int endDocID = docID - docCount;\n          while (docID > endDocID) {\n            deleteDocID(docID);\n            docID--;\n          }\n        }\n        docState.clear();\n      }\n    } finally {\n      maybeAbort(\"updateDocuments\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"845b760a99e5f369fcd0a5d723a87b8def6a3f56":["110125c995236a7f61057dd04b039ed2d267f3a1"],"86a2e8a56b368d37ef3ba7180541fa317d6fd6c7":["845b760a99e5f369fcd0a5d723a87b8def6a3f56"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"110125c995236a7f61057dd04b039ed2d267f3a1":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["86a2e8a56b368d37ef3ba7180541fa317d6fd6c7"]},"commit2Childs":{"845b760a99e5f369fcd0a5d723a87b8def6a3f56":["86a2e8a56b368d37ef3ba7180541fa317d6fd6c7"],"86a2e8a56b368d37ef3ba7180541fa317d6fd6c7":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["110125c995236a7f61057dd04b039ed2d267f3a1"],"110125c995236a7f61057dd04b039ed2d267f3a1":["845b760a99e5f369fcd0a5d723a87b8def6a3f56"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}