{"path":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimLargeCluster#testBasic().mjava","commits":[{"id":"a6a5c1c40529f15b445e6720dfde1967e139bff1","date":1535375643,"type":1,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimLargeCluster#testBasic().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestLargeCluster#testBasic().mjava","sourceNew":"  @Test\n  @LuceneTestCase.BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 2018-06-18\n  public void testBasic() throws Exception {\n    SolrClient solrClient = cluster.simGetSolrClient();\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger1',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [\" +\n        \"{'name':'start','class':'\" + StartTriggerAction.class.getName() + \"'},\" +\n        \"{'name':'compute','class':'\" + ComputePlanAction.class.getName() + \"'},\" +\n        \"{'name':'execute','class':'\" + ExecutePlanAction.class.getName() + \"'},\" +\n        \"{'name':'test','class':'\" + FinishTriggerAction.class.getName() + \"'}\" +\n        \"]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'foo',\" +\n        \"'trigger' : 'node_lost_trigger1',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED', 'FAILED'],\" +\n        \"'beforeAction' : ['compute', 'execute'],\" +\n        \"'afterAction' : ['compute', 'execute'],\" +\n        \"'class' : '\" + TestTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    cluster.getTimeSource().sleep(5000);\n\n    // pick a few random nodes\n    List<String> nodes = new ArrayList<>();\n    int limit = 75;\n    for (String node : cluster.getClusterStateProvider().getLiveNodes()) {\n      nodes.add(node);\n      if (nodes.size() > limit) {\n        break;\n      }\n    }\n    Collections.shuffle(nodes, random());\n    // create collection on these nodes\n    String collectionName = \"testBasic\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 5, 5, 5, 5);\n    create.setMaxShardsPerNode(1);\n    create.setAutoAddReplicas(false);\n    create.setCreateNodeSet(String.join(\",\", nodes));\n    create.process(solrClient);\n\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15, false, true)) + \"ms\");\n\n    int KILL_NODES = 8;\n    // kill off a number of nodes\n    for (int i = 0; i < KILL_NODES; i++) {\n      cluster.simRemoveNode(nodes.get(i), false);\n    }\n    // should fully recover\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 90 * KILL_NODES, TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15, false, true)) + \"ms\");\n\n    log.info(\"OP COUNTS: \" + cluster.simGetOpCounts());\n    long moveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n\n    // simulate a number of flaky nodes\n    int FLAKY_NODES = 10;\n    int flakyReplicas = 0;\n    for (int cnt = 0; cnt < 10; cnt++) {\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        flakyReplicas += cluster.getSimClusterStateProvider().simGetReplicaInfos(nodes.get(i))\n            .stream().filter(r -> r.getState().equals(Replica.State.ACTIVE)).count();\n        cluster.simRemoveNode(nodes.get(i), false);\n      }\n      cluster.getTimeSource().sleep(TimeUnit.SECONDS.toMillis(waitForSeconds) * 2);\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        final String nodeId = nodes.get(i);\n        cluster.submit(() -> cluster.getSimClusterStateProvider().simRestoreNode(nodeId));\n      }\n    }\n\n    // wait until started == finished\n    TimeOut timeOut = new TimeOut(20 * waitForSeconds * NUM_NODES, TimeUnit.SECONDS, cluster.getTimeSource());\n    while (!timeOut.hasTimedOut()) {\n      if (triggerStartedCount.get() == triggerFinishedCount.get()) {\n        break;\n      }\n      timeOut.sleep(1000);\n    }\n    if (timeOut.hasTimedOut()) {\n      fail(\"did not finish processing all events in time: started=\" + triggerStartedCount.get() + \", finished=\" + triggerFinishedCount.get());\n    }\n\n\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15, false, true)) + \"ms\");\n    long newMoveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n    log.info(\"==== Flaky replicas: {}. Additional MOVEREPLICA count: {}\", flakyReplicas, (newMoveReplicaOps - moveReplicaOps));\n    // flaky nodes lead to a number of MOVEREPLICA that is non-zero but lower than the number of flaky replicas\n    assertTrue(\"there should be new MOVERPLICA ops\", newMoveReplicaOps - moveReplicaOps > 0);\n    assertTrue(\"there should be less than flakyReplicas=\" + flakyReplicas + \" MOVEREPLICA ops\",\n        newMoveReplicaOps - moveReplicaOps < flakyReplicas);\n  }\n\n","sourceOld":"  @Test\n  @LuceneTestCase.BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 2018-06-18\n  public void testBasic() throws Exception {\n    SolrClient solrClient = cluster.simGetSolrClient();\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger1',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [\" +\n        \"{'name':'start','class':'\" + StartTriggerAction.class.getName() + \"'},\" +\n        \"{'name':'compute','class':'\" + ComputePlanAction.class.getName() + \"'},\" +\n        \"{'name':'execute','class':'\" + ExecutePlanAction.class.getName() + \"'},\" +\n        \"{'name':'test','class':'\" + FinishTriggerAction.class.getName() + \"'}\" +\n        \"]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'foo',\" +\n        \"'trigger' : 'node_lost_trigger1',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED', 'FAILED'],\" +\n        \"'beforeAction' : ['compute', 'execute'],\" +\n        \"'afterAction' : ['compute', 'execute'],\" +\n        \"'class' : '\" + TestTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    cluster.getTimeSource().sleep(5000);\n\n    // pick a few random nodes\n    List<String> nodes = new ArrayList<>();\n    int limit = 75;\n    for (String node : cluster.getClusterStateProvider().getLiveNodes()) {\n      nodes.add(node);\n      if (nodes.size() > limit) {\n        break;\n      }\n    }\n    Collections.shuffle(nodes, random());\n    // create collection on these nodes\n    String collectionName = \"testBasic\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 5, 5, 5, 5);\n    create.setMaxShardsPerNode(1);\n    create.setAutoAddReplicas(false);\n    create.setCreateNodeSet(String.join(\",\", nodes));\n    create.process(solrClient);\n\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15, false, true)) + \"ms\");\n\n    int KILL_NODES = 8;\n    // kill off a number of nodes\n    for (int i = 0; i < KILL_NODES; i++) {\n      cluster.simRemoveNode(nodes.get(i), false);\n    }\n    // should fully recover\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 90 * KILL_NODES, TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15, false, true)) + \"ms\");\n\n    log.info(\"OP COUNTS: \" + cluster.simGetOpCounts());\n    long moveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n\n    // simulate a number of flaky nodes\n    int FLAKY_NODES = 10;\n    int flakyReplicas = 0;\n    for (int cnt = 0; cnt < 10; cnt++) {\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        flakyReplicas += cluster.getSimClusterStateProvider().simGetReplicaInfos(nodes.get(i))\n            .stream().filter(r -> r.getState().equals(Replica.State.ACTIVE)).count();\n        cluster.simRemoveNode(nodes.get(i), false);\n      }\n      cluster.getTimeSource().sleep(TimeUnit.SECONDS.toMillis(waitForSeconds) * 2);\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        final String nodeId = nodes.get(i);\n        cluster.submit(() -> cluster.getSimClusterStateProvider().simRestoreNode(nodeId));\n      }\n    }\n\n    // wait until started == finished\n    TimeOut timeOut = new TimeOut(20 * waitForSeconds * NUM_NODES, TimeUnit.SECONDS, cluster.getTimeSource());\n    while (!timeOut.hasTimedOut()) {\n      if (triggerStartedCount.get() == triggerFinishedCount.get()) {\n        break;\n      }\n      timeOut.sleep(1000);\n    }\n    if (timeOut.hasTimedOut()) {\n      fail(\"did not finish processing all events in time: started=\" + triggerStartedCount.get() + \", finished=\" + triggerFinishedCount.get());\n    }\n\n\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15, false, true)) + \"ms\");\n    long newMoveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n    log.info(\"==== Flaky replicas: {}. Additional MOVEREPLICA count: {}\", flakyReplicas, (newMoveReplicaOps - moveReplicaOps));\n    // flaky nodes lead to a number of MOVEREPLICA that is non-zero but lower than the number of flaky replicas\n    assertTrue(\"there should be new MOVERPLICA ops\", newMoveReplicaOps - moveReplicaOps > 0);\n    assertTrue(\"there should be less than flakyReplicas=\" + flakyReplicas + \" MOVEREPLICA ops\",\n        newMoveReplicaOps - moveReplicaOps < flakyReplicas);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bb222a3f9d9421d5c95afce73013fbd8de07ea1f","date":1543514331,"type":3,"author":"markrmiller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimLargeCluster#testBasic().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimLargeCluster#testBasic().mjava","sourceNew":"  @Test\n  @AwaitsFix(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // this test hits a timeout easily\n  public void testBasic() throws Exception {\n    SolrClient solrClient = cluster.simGetSolrClient();\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger1',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [\" +\n        \"{'name':'start','class':'\" + StartTriggerAction.class.getName() + \"'},\" +\n        \"{'name':'compute','class':'\" + ComputePlanAction.class.getName() + \"'},\" +\n        \"{'name':'execute','class':'\" + ExecutePlanAction.class.getName() + \"'},\" +\n        \"{'name':'test','class':'\" + FinishTriggerAction.class.getName() + \"'}\" +\n        \"]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'foo',\" +\n        \"'trigger' : 'node_lost_trigger1',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED', 'FAILED'],\" +\n        \"'beforeAction' : ['compute', 'execute'],\" +\n        \"'afterAction' : ['compute', 'execute'],\" +\n        \"'class' : '\" + TestTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    cluster.getTimeSource().sleep(5000);\n\n    // pick a few random nodes\n    List<String> nodes = new ArrayList<>();\n    int limit = 75;\n    for (String node : cluster.getClusterStateProvider().getLiveNodes()) {\n      nodes.add(node);\n      if (nodes.size() > limit) {\n        break;\n      }\n    }\n    Collections.shuffle(nodes, random());\n    // create collection on these nodes\n    String collectionName = \"testBasic\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 5, 5, 5, 5);\n    create.setMaxShardsPerNode(1);\n    create.setAutoAddReplicas(false);\n    create.setCreateNodeSet(String.join(\",\", nodes));\n    create.process(solrClient);\n\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15, false, true)) + \"ms\");\n\n    int KILL_NODES = 8;\n    // kill off a number of nodes\n    for (int i = 0; i < KILL_NODES; i++) {\n      cluster.simRemoveNode(nodes.get(i), false);\n    }\n    // should fully recover\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 90 * KILL_NODES, TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15, false, true)) + \"ms\");\n\n    log.info(\"OP COUNTS: \" + cluster.simGetOpCounts());\n    long moveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n\n    // simulate a number of flaky nodes\n    int FLAKY_NODES = 10;\n    int flakyReplicas = 0;\n    for (int cnt = 0; cnt < 10; cnt++) {\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        flakyReplicas += cluster.getSimClusterStateProvider().simGetReplicaInfos(nodes.get(i))\n            .stream().filter(r -> r.getState().equals(Replica.State.ACTIVE)).count();\n        cluster.simRemoveNode(nodes.get(i), false);\n      }\n      cluster.getTimeSource().sleep(TimeUnit.SECONDS.toMillis(waitForSeconds) * 2);\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        final String nodeId = nodes.get(i);\n        cluster.submit(() -> cluster.getSimClusterStateProvider().simRestoreNode(nodeId));\n      }\n    }\n\n    // wait until started == finished\n    TimeOut timeOut = new TimeOut(20 * waitForSeconds * NUM_NODES, TimeUnit.SECONDS, cluster.getTimeSource());\n    while (!timeOut.hasTimedOut()) {\n      if (triggerStartedCount.get() == triggerFinishedCount.get()) {\n        break;\n      }\n      timeOut.sleep(1000);\n    }\n    if (timeOut.hasTimedOut()) {\n      fail(\"did not finish processing all events in time: started=\" + triggerStartedCount.get() + \", finished=\" + triggerFinishedCount.get());\n    }\n\n\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15, false, true)) + \"ms\");\n    long newMoveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n    log.info(\"==== Flaky replicas: {}. Additional MOVEREPLICA count: {}\", flakyReplicas, (newMoveReplicaOps - moveReplicaOps));\n    // flaky nodes lead to a number of MOVEREPLICA that is non-zero but lower than the number of flaky replicas\n    assertTrue(\"there should be new MOVERPLICA ops\", newMoveReplicaOps - moveReplicaOps > 0);\n    assertTrue(\"there should be less than flakyReplicas=\" + flakyReplicas + \" MOVEREPLICA ops\",\n        newMoveReplicaOps - moveReplicaOps < flakyReplicas);\n  }\n\n","sourceOld":"  @Test\n  @LuceneTestCase.BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 2018-06-18\n  public void testBasic() throws Exception {\n    SolrClient solrClient = cluster.simGetSolrClient();\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger1',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [\" +\n        \"{'name':'start','class':'\" + StartTriggerAction.class.getName() + \"'},\" +\n        \"{'name':'compute','class':'\" + ComputePlanAction.class.getName() + \"'},\" +\n        \"{'name':'execute','class':'\" + ExecutePlanAction.class.getName() + \"'},\" +\n        \"{'name':'test','class':'\" + FinishTriggerAction.class.getName() + \"'}\" +\n        \"]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'foo',\" +\n        \"'trigger' : 'node_lost_trigger1',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED', 'FAILED'],\" +\n        \"'beforeAction' : ['compute', 'execute'],\" +\n        \"'afterAction' : ['compute', 'execute'],\" +\n        \"'class' : '\" + TestTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    cluster.getTimeSource().sleep(5000);\n\n    // pick a few random nodes\n    List<String> nodes = new ArrayList<>();\n    int limit = 75;\n    for (String node : cluster.getClusterStateProvider().getLiveNodes()) {\n      nodes.add(node);\n      if (nodes.size() > limit) {\n        break;\n      }\n    }\n    Collections.shuffle(nodes, random());\n    // create collection on these nodes\n    String collectionName = \"testBasic\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 5, 5, 5, 5);\n    create.setMaxShardsPerNode(1);\n    create.setAutoAddReplicas(false);\n    create.setCreateNodeSet(String.join(\",\", nodes));\n    create.process(solrClient);\n\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15, false, true)) + \"ms\");\n\n    int KILL_NODES = 8;\n    // kill off a number of nodes\n    for (int i = 0; i < KILL_NODES; i++) {\n      cluster.simRemoveNode(nodes.get(i), false);\n    }\n    // should fully recover\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 90 * KILL_NODES, TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15, false, true)) + \"ms\");\n\n    log.info(\"OP COUNTS: \" + cluster.simGetOpCounts());\n    long moveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n\n    // simulate a number of flaky nodes\n    int FLAKY_NODES = 10;\n    int flakyReplicas = 0;\n    for (int cnt = 0; cnt < 10; cnt++) {\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        flakyReplicas += cluster.getSimClusterStateProvider().simGetReplicaInfos(nodes.get(i))\n            .stream().filter(r -> r.getState().equals(Replica.State.ACTIVE)).count();\n        cluster.simRemoveNode(nodes.get(i), false);\n      }\n      cluster.getTimeSource().sleep(TimeUnit.SECONDS.toMillis(waitForSeconds) * 2);\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        final String nodeId = nodes.get(i);\n        cluster.submit(() -> cluster.getSimClusterStateProvider().simRestoreNode(nodeId));\n      }\n    }\n\n    // wait until started == finished\n    TimeOut timeOut = new TimeOut(20 * waitForSeconds * NUM_NODES, TimeUnit.SECONDS, cluster.getTimeSource());\n    while (!timeOut.hasTimedOut()) {\n      if (triggerStartedCount.get() == triggerFinishedCount.get()) {\n        break;\n      }\n      timeOut.sleep(1000);\n    }\n    if (timeOut.hasTimedOut()) {\n      fail(\"did not finish processing all events in time: started=\" + triggerStartedCount.get() + \", finished=\" + triggerFinishedCount.get());\n    }\n\n\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15, false, true)) + \"ms\");\n    long newMoveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n    log.info(\"==== Flaky replicas: {}. Additional MOVEREPLICA count: {}\", flakyReplicas, (newMoveReplicaOps - moveReplicaOps));\n    // flaky nodes lead to a number of MOVEREPLICA that is non-zero but lower than the number of flaky replicas\n    assertTrue(\"there should be new MOVERPLICA ops\", newMoveReplicaOps - moveReplicaOps > 0);\n    assertTrue(\"there should be less than flakyReplicas=\" + flakyReplicas + \" MOVEREPLICA ops\",\n        newMoveReplicaOps - moveReplicaOps < flakyReplicas);\n  }\n\n","bugFix":["7a7544ad4b63d1b5f556c3da8f9c63d332aa034e"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"89948af0461fead48f44ba8fb7866f107ce83f22","date":1545157711,"type":3,"author":"Chris Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimLargeCluster#testBasic().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimLargeCluster#testBasic().mjava","sourceNew":"  @Test\n  @AwaitsFix(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // this test hits a timeout easily\n  public void testBasic() throws Exception {\n    SolrClient solrClient = cluster.simGetSolrClient();\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger1',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [\" +\n        \"{'name':'start','class':'\" + StartTriggerAction.class.getName() + \"'},\" +\n        \"{'name':'compute','class':'\" + ComputePlanAction.class.getName() + \"'},\" +\n        \"{'name':'execute','class':'\" + ExecutePlanAction.class.getName() + \"'},\" +\n        \"{'name':'test','class':'\" + FinishTriggerAction.class.getName() + \"'}\" +\n        \"]\" +\n        \"}}\";\n    SolrRequest req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'foo',\" +\n        \"'trigger' : 'node_lost_trigger1',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED', 'FAILED'],\" +\n        \"'beforeAction' : ['compute', 'execute'],\" +\n        \"'afterAction' : ['compute', 'execute'],\" +\n        \"'class' : '\" + TestTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    cluster.getTimeSource().sleep(5000);\n\n    // pick a few random nodes\n    List<String> nodes = new ArrayList<>();\n    int limit = 75;\n    for (String node : cluster.getClusterStateProvider().getLiveNodes()) {\n      nodes.add(node);\n      if (nodes.size() > limit) {\n        break;\n      }\n    }\n    Collections.shuffle(nodes, random());\n    // create collection on these nodes\n    String collectionName = \"testBasic\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 5, 5, 5, 5);\n    create.setMaxShardsPerNode(1);\n    create.setAutoAddReplicas(false);\n    create.setCreateNodeSet(String.join(\",\", nodes));\n    create.process(solrClient);\n\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15, false, true)) + \"ms\");\n\n    int KILL_NODES = 8;\n    // kill off a number of nodes\n    for (int i = 0; i < KILL_NODES; i++) {\n      cluster.simRemoveNode(nodes.get(i), false);\n    }\n    // should fully recover\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 90 * KILL_NODES, TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15, false, true)) + \"ms\");\n\n    log.info(\"OP COUNTS: \" + cluster.simGetOpCounts());\n    long moveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n\n    // simulate a number of flaky nodes\n    int FLAKY_NODES = 10;\n    int flakyReplicas = 0;\n    for (int cnt = 0; cnt < 10; cnt++) {\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        flakyReplicas += cluster.getSimClusterStateProvider().simGetReplicaInfos(nodes.get(i))\n            .stream().filter(r -> r.getState().equals(Replica.State.ACTIVE)).count();\n        cluster.simRemoveNode(nodes.get(i), false);\n      }\n      cluster.getTimeSource().sleep(TimeUnit.SECONDS.toMillis(waitForSeconds) * 2);\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        final String nodeId = nodes.get(i);\n        cluster.submit(() -> cluster.getSimClusterStateProvider().simRestoreNode(nodeId));\n      }\n    }\n\n    // wait until started == finished\n    TimeOut timeOut = new TimeOut(20 * waitForSeconds * NUM_NODES, TimeUnit.SECONDS, cluster.getTimeSource());\n    while (!timeOut.hasTimedOut()) {\n      if (triggerStartedCount.get() == triggerFinishedCount.get()) {\n        break;\n      }\n      timeOut.sleep(1000);\n    }\n    if (timeOut.hasTimedOut()) {\n      fail(\"did not finish processing all events in time: started=\" + triggerStartedCount.get() + \", finished=\" + triggerFinishedCount.get());\n    }\n\n\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15, false, true)) + \"ms\");\n    long newMoveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n    log.info(\"==== Flaky replicas: {}. Additional MOVEREPLICA count: {}\", flakyReplicas, (newMoveReplicaOps - moveReplicaOps));\n    // flaky nodes lead to a number of MOVEREPLICA that is non-zero but lower than the number of flaky replicas\n    assertTrue(\"there should be new MOVERPLICA ops\", newMoveReplicaOps - moveReplicaOps > 0);\n    assertTrue(\"there should be less than flakyReplicas=\" + flakyReplicas + \" MOVEREPLICA ops\",\n        newMoveReplicaOps - moveReplicaOps < flakyReplicas);\n  }\n\n","sourceOld":"  @Test\n  @AwaitsFix(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // this test hits a timeout easily\n  public void testBasic() throws Exception {\n    SolrClient solrClient = cluster.simGetSolrClient();\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger1',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [\" +\n        \"{'name':'start','class':'\" + StartTriggerAction.class.getName() + \"'},\" +\n        \"{'name':'compute','class':'\" + ComputePlanAction.class.getName() + \"'},\" +\n        \"{'name':'execute','class':'\" + ExecutePlanAction.class.getName() + \"'},\" +\n        \"{'name':'test','class':'\" + FinishTriggerAction.class.getName() + \"'}\" +\n        \"]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'foo',\" +\n        \"'trigger' : 'node_lost_trigger1',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED', 'FAILED'],\" +\n        \"'beforeAction' : ['compute', 'execute'],\" +\n        \"'afterAction' : ['compute', 'execute'],\" +\n        \"'class' : '\" + TestTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    cluster.getTimeSource().sleep(5000);\n\n    // pick a few random nodes\n    List<String> nodes = new ArrayList<>();\n    int limit = 75;\n    for (String node : cluster.getClusterStateProvider().getLiveNodes()) {\n      nodes.add(node);\n      if (nodes.size() > limit) {\n        break;\n      }\n    }\n    Collections.shuffle(nodes, random());\n    // create collection on these nodes\n    String collectionName = \"testBasic\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 5, 5, 5, 5);\n    create.setMaxShardsPerNode(1);\n    create.setAutoAddReplicas(false);\n    create.setCreateNodeSet(String.join(\",\", nodes));\n    create.process(solrClient);\n\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15, false, true)) + \"ms\");\n\n    int KILL_NODES = 8;\n    // kill off a number of nodes\n    for (int i = 0; i < KILL_NODES; i++) {\n      cluster.simRemoveNode(nodes.get(i), false);\n    }\n    // should fully recover\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 90 * KILL_NODES, TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15, false, true)) + \"ms\");\n\n    log.info(\"OP COUNTS: \" + cluster.simGetOpCounts());\n    long moveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n\n    // simulate a number of flaky nodes\n    int FLAKY_NODES = 10;\n    int flakyReplicas = 0;\n    for (int cnt = 0; cnt < 10; cnt++) {\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        flakyReplicas += cluster.getSimClusterStateProvider().simGetReplicaInfos(nodes.get(i))\n            .stream().filter(r -> r.getState().equals(Replica.State.ACTIVE)).count();\n        cluster.simRemoveNode(nodes.get(i), false);\n      }\n      cluster.getTimeSource().sleep(TimeUnit.SECONDS.toMillis(waitForSeconds) * 2);\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        final String nodeId = nodes.get(i);\n        cluster.submit(() -> cluster.getSimClusterStateProvider().simRestoreNode(nodeId));\n      }\n    }\n\n    // wait until started == finished\n    TimeOut timeOut = new TimeOut(20 * waitForSeconds * NUM_NODES, TimeUnit.SECONDS, cluster.getTimeSource());\n    while (!timeOut.hasTimedOut()) {\n      if (triggerStartedCount.get() == triggerFinishedCount.get()) {\n        break;\n      }\n      timeOut.sleep(1000);\n    }\n    if (timeOut.hasTimedOut()) {\n      fail(\"did not finish processing all events in time: started=\" + triggerStartedCount.get() + \", finished=\" + triggerFinishedCount.get());\n    }\n\n\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15, false, true)) + \"ms\");\n    long newMoveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n    log.info(\"==== Flaky replicas: {}. Additional MOVEREPLICA count: {}\", flakyReplicas, (newMoveReplicaOps - moveReplicaOps));\n    // flaky nodes lead to a number of MOVEREPLICA that is non-zero but lower than the number of flaky replicas\n    assertTrue(\"there should be new MOVERPLICA ops\", newMoveReplicaOps - moveReplicaOps > 0);\n    assertTrue(\"there should be less than flakyReplicas=\" + flakyReplicas + \" MOVEREPLICA ops\",\n        newMoveReplicaOps - moveReplicaOps < flakyReplicas);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ce85ed088dcf7aa1742105d4a8caa9aab3b491c1","date":1546971158,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimLargeCluster#testBasic().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimLargeCluster#testBasic().mjava","sourceNew":"  @Test\n  @AwaitsFix(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // this test hits a timeout easily\n  public void testBasic() throws Exception {\n    SolrClient solrClient = cluster.simGetSolrClient();\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger1',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [\" +\n        \"{'name':'start','class':'\" + StartTriggerAction.class.getName() + \"'},\" +\n        \"{'name':'compute','class':'\" + ComputePlanAction.class.getName() + \"'},\" +\n        \"{'name':'execute','class':'\" + ExecutePlanAction.class.getName() + \"'},\" +\n        \"{'name':'test','class':'\" + FinishTriggerAction.class.getName() + \"'}\" +\n        \"]\" +\n        \"}}\";\n    SolrRequest req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'foo',\" +\n        \"'trigger' : 'node_lost_trigger1',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED', 'FAILED'],\" +\n        \"'beforeAction' : ['compute', 'execute'],\" +\n        \"'afterAction' : ['compute', 'execute'],\" +\n        \"'class' : '\" + TestTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    assertAutoscalingUpdateComplete();\n\n    cluster.getTimeSource().sleep(5000);\n\n    // pick a few random nodes\n    List<String> nodes = new ArrayList<>();\n    int limit = 75;\n    for (String node : cluster.getClusterStateProvider().getLiveNodes()) {\n      nodes.add(node);\n      if (nodes.size() > limit) {\n        break;\n      }\n    }\n    Collections.shuffle(nodes, random());\n    // create collection on these nodes\n    String collectionName = \"testBasic\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 5, 5, 5, 5);\n    create.setMaxShardsPerNode(1);\n    create.setAutoAddReplicas(false);\n    create.setCreateNodeSet(String.join(\",\", nodes));\n    create.process(solrClient);\n\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15, false, true)) + \"ms\");\n\n    int KILL_NODES = 8;\n    // kill off a number of nodes\n    for (int i = 0; i < KILL_NODES; i++) {\n      cluster.simRemoveNode(nodes.get(i), false);\n    }\n    // should fully recover\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 90 * KILL_NODES, TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15, false, true)) + \"ms\");\n\n    log.info(\"OP COUNTS: \" + cluster.simGetOpCounts());\n    long moveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n\n    // simulate a number of flaky nodes\n    int FLAKY_NODES = 10;\n    int flakyReplicas = 0;\n    for (int cnt = 0; cnt < 10; cnt++) {\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        flakyReplicas += cluster.getSimClusterStateProvider().simGetReplicaInfos(nodes.get(i))\n            .stream().filter(r -> r.getState().equals(Replica.State.ACTIVE)).count();\n        cluster.simRemoveNode(nodes.get(i), false);\n      }\n      cluster.getTimeSource().sleep(TimeUnit.SECONDS.toMillis(waitForSeconds) * 2);\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        final String nodeId = nodes.get(i);\n        cluster.submit(() -> cluster.getSimClusterStateProvider().simRestoreNode(nodeId));\n      }\n    }\n\n    // wait until started == finished\n    TimeOut timeOut = new TimeOut(20 * waitForSeconds * NUM_NODES, TimeUnit.SECONDS, cluster.getTimeSource());\n    while (!timeOut.hasTimedOut()) {\n      if (triggerStartedCount.get() == triggerFinishedCount.get()) {\n        break;\n      }\n      timeOut.sleep(1000);\n    }\n    if (timeOut.hasTimedOut()) {\n      fail(\"did not finish processing all events in time: started=\" + triggerStartedCount.get() + \", finished=\" + triggerFinishedCount.get());\n    }\n\n\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15, false, true)) + \"ms\");\n    long newMoveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n    log.info(\"==== Flaky replicas: {}. Additional MOVEREPLICA count: {}\", flakyReplicas, (newMoveReplicaOps - moveReplicaOps));\n    // flaky nodes lead to a number of MOVEREPLICA that is non-zero but lower than the number of flaky replicas\n    assertTrue(\"there should be new MOVERPLICA ops\", newMoveReplicaOps - moveReplicaOps > 0);\n    assertTrue(\"there should be less than flakyReplicas=\" + flakyReplicas + \" MOVEREPLICA ops\",\n        newMoveReplicaOps - moveReplicaOps < flakyReplicas);\n  }\n\n","sourceOld":"  @Test\n  @AwaitsFix(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // this test hits a timeout easily\n  public void testBasic() throws Exception {\n    SolrClient solrClient = cluster.simGetSolrClient();\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger1',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [\" +\n        \"{'name':'start','class':'\" + StartTriggerAction.class.getName() + \"'},\" +\n        \"{'name':'compute','class':'\" + ComputePlanAction.class.getName() + \"'},\" +\n        \"{'name':'execute','class':'\" + ExecutePlanAction.class.getName() + \"'},\" +\n        \"{'name':'test','class':'\" + FinishTriggerAction.class.getName() + \"'}\" +\n        \"]\" +\n        \"}}\";\n    SolrRequest req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'foo',\" +\n        \"'trigger' : 'node_lost_trigger1',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED', 'FAILED'],\" +\n        \"'beforeAction' : ['compute', 'execute'],\" +\n        \"'afterAction' : ['compute', 'execute'],\" +\n        \"'class' : '\" + TestTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    cluster.getTimeSource().sleep(5000);\n\n    // pick a few random nodes\n    List<String> nodes = new ArrayList<>();\n    int limit = 75;\n    for (String node : cluster.getClusterStateProvider().getLiveNodes()) {\n      nodes.add(node);\n      if (nodes.size() > limit) {\n        break;\n      }\n    }\n    Collections.shuffle(nodes, random());\n    // create collection on these nodes\n    String collectionName = \"testBasic\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 5, 5, 5, 5);\n    create.setMaxShardsPerNode(1);\n    create.setAutoAddReplicas(false);\n    create.setCreateNodeSet(String.join(\",\", nodes));\n    create.process(solrClient);\n\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15, false, true)) + \"ms\");\n\n    int KILL_NODES = 8;\n    // kill off a number of nodes\n    for (int i = 0; i < KILL_NODES; i++) {\n      cluster.simRemoveNode(nodes.get(i), false);\n    }\n    // should fully recover\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 90 * KILL_NODES, TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15, false, true)) + \"ms\");\n\n    log.info(\"OP COUNTS: \" + cluster.simGetOpCounts());\n    long moveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n\n    // simulate a number of flaky nodes\n    int FLAKY_NODES = 10;\n    int flakyReplicas = 0;\n    for (int cnt = 0; cnt < 10; cnt++) {\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        flakyReplicas += cluster.getSimClusterStateProvider().simGetReplicaInfos(nodes.get(i))\n            .stream().filter(r -> r.getState().equals(Replica.State.ACTIVE)).count();\n        cluster.simRemoveNode(nodes.get(i), false);\n      }\n      cluster.getTimeSource().sleep(TimeUnit.SECONDS.toMillis(waitForSeconds) * 2);\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        final String nodeId = nodes.get(i);\n        cluster.submit(() -> cluster.getSimClusterStateProvider().simRestoreNode(nodeId));\n      }\n    }\n\n    // wait until started == finished\n    TimeOut timeOut = new TimeOut(20 * waitForSeconds * NUM_NODES, TimeUnit.SECONDS, cluster.getTimeSource());\n    while (!timeOut.hasTimedOut()) {\n      if (triggerStartedCount.get() == triggerFinishedCount.get()) {\n        break;\n      }\n      timeOut.sleep(1000);\n    }\n    if (timeOut.hasTimedOut()) {\n      fail(\"did not finish processing all events in time: started=\" + triggerStartedCount.get() + \", finished=\" + triggerFinishedCount.get());\n    }\n\n\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15, false, true)) + \"ms\");\n    long newMoveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n    log.info(\"==== Flaky replicas: {}. Additional MOVEREPLICA count: {}\", flakyReplicas, (newMoveReplicaOps - moveReplicaOps));\n    // flaky nodes lead to a number of MOVEREPLICA that is non-zero but lower than the number of flaky replicas\n    assertTrue(\"there should be new MOVERPLICA ops\", newMoveReplicaOps - moveReplicaOps > 0);\n    assertTrue(\"there should be less than flakyReplicas=\" + flakyReplicas + \" MOVEREPLICA ops\",\n        newMoveReplicaOps - moveReplicaOps < flakyReplicas);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"30004ef8212d169b5fc7d098ec7aa299c8b5f060","date":1551998457,"type":3,"author":"Chris Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimLargeCluster#testBasic().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimLargeCluster#testBasic().mjava","sourceNew":"  @Test\n  @AwaitsFix(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // this test hits a timeout easily\n  public void testBasic() throws Exception {\n    SolrClient solrClient = cluster.simGetSolrClient();\n    assertAutoScalingRequest\n      ( \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger1',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [\" +\n        \"{'name':'start','class':'\" + StartTriggerAction.class.getName() + \"'},\" +\n        \"{'name':'compute','class':'\" + ComputePlanAction.class.getName() + \"'},\" +\n        \"{'name':'execute','class':'\" + ExecutePlanAction.class.getName() + \"'},\" +\n        \"{'name':'test','class':'\" + FinishTriggerAction.class.getName() + \"'}\" +\n        \"]\" +\n        \"}}\");\n\n    assertAutoScalingRequest\n      ( \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'foo',\" +\n        \"'trigger' : 'node_lost_trigger1',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED', 'FAILED'],\" +\n        \"'beforeAction' : ['compute', 'execute'],\" +\n        \"'afterAction' : ['compute', 'execute'],\" +\n        \"'class' : '\" + TestTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\");\n\n    assertAutoscalingUpdateComplete();\n\n    // pick a few random nodes\n    List<String> nodes = new ArrayList<>();\n    int limit = 75;\n    for (String node : cluster.getClusterStateProvider().getLiveNodes()) {\n      nodes.add(node);\n      if (nodes.size() > limit) {\n        break;\n      }\n    }\n    Collections.shuffle(nodes, random());\n    // create collection on these nodes\n    String collectionName = \"testBasic\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 5, 5, 5, 5);\n    create.setMaxShardsPerNode(1);\n    create.setAutoAddReplicas(false);\n    create.setCreateNodeSet(String.join(\",\", nodes));\n    create.process(solrClient);\n\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15, false, true)) + \"ms\");\n\n    int KILL_NODES = 8;\n    // kill off a number of nodes\n    for (int i = 0; i < KILL_NODES; i++) {\n      cluster.simRemoveNode(nodes.get(i), false);\n    }\n    // should fully recover\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 90 * KILL_NODES, TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15, false, true)) + \"ms\");\n\n    log.info(\"OP COUNTS: \" + cluster.simGetOpCounts());\n    long moveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n\n    // simulate a number of flaky nodes\n    int FLAKY_NODES = 10;\n    int flakyReplicas = 0;\n    for (int cnt = 0; cnt < 10; cnt++) {\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        flakyReplicas += cluster.getSimClusterStateProvider().simGetReplicaInfos(nodes.get(i))\n            .stream().filter(r -> r.getState().equals(Replica.State.ACTIVE)).count();\n        cluster.simRemoveNode(nodes.get(i), false);\n      }\n      cluster.getTimeSource().sleep(TimeUnit.SECONDS.toMillis(waitForSeconds) * 2);\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        final String nodeId = nodes.get(i);\n        cluster.submit(() -> cluster.getSimClusterStateProvider().simRestoreNode(nodeId));\n      }\n    }\n\n    // wait until started == finished\n    TimeOut timeOut = new TimeOut(20 * waitForSeconds * NUM_NODES, TimeUnit.SECONDS, cluster.getTimeSource());\n    while (!timeOut.hasTimedOut()) {\n      if (triggerStartedCount.get() == triggerFinishedCount.get()) {\n        break;\n      }\n      timeOut.sleep(1000);\n    }\n    if (timeOut.hasTimedOut()) {\n      fail(\"did not finish processing all events in time: started=\" + triggerStartedCount.get() + \", finished=\" + triggerFinishedCount.get());\n    }\n\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15, false, true)) + \"ms\");\n    long newMoveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n    log.info(\"==== Flaky replicas: {}. Additional MOVEREPLICA count: {}\", flakyReplicas, (newMoveReplicaOps - moveReplicaOps));\n    // flaky nodes lead to a number of MOVEREPLICA that is non-zero but lower than the number of flaky replicas\n    assertTrue(\"there should be new MOVERPLICA ops\", newMoveReplicaOps - moveReplicaOps > 0);\n    assertTrue(\"there should be less than flakyReplicas=\" + flakyReplicas + \" MOVEREPLICA ops\",\n        newMoveReplicaOps - moveReplicaOps < flakyReplicas);\n  }\n\n","sourceOld":"  @Test\n  @AwaitsFix(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // this test hits a timeout easily\n  public void testBasic() throws Exception {\n    SolrClient solrClient = cluster.simGetSolrClient();\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger1',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [\" +\n        \"{'name':'start','class':'\" + StartTriggerAction.class.getName() + \"'},\" +\n        \"{'name':'compute','class':'\" + ComputePlanAction.class.getName() + \"'},\" +\n        \"{'name':'execute','class':'\" + ExecutePlanAction.class.getName() + \"'},\" +\n        \"{'name':'test','class':'\" + FinishTriggerAction.class.getName() + \"'}\" +\n        \"]\" +\n        \"}}\";\n    SolrRequest req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'foo',\" +\n        \"'trigger' : 'node_lost_trigger1',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED', 'FAILED'],\" +\n        \"'beforeAction' : ['compute', 'execute'],\" +\n        \"'afterAction' : ['compute', 'execute'],\" +\n        \"'class' : '\" + TestTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    assertAutoscalingUpdateComplete();\n\n    cluster.getTimeSource().sleep(5000);\n\n    // pick a few random nodes\n    List<String> nodes = new ArrayList<>();\n    int limit = 75;\n    for (String node : cluster.getClusterStateProvider().getLiveNodes()) {\n      nodes.add(node);\n      if (nodes.size() > limit) {\n        break;\n      }\n    }\n    Collections.shuffle(nodes, random());\n    // create collection on these nodes\n    String collectionName = \"testBasic\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 5, 5, 5, 5);\n    create.setMaxShardsPerNode(1);\n    create.setAutoAddReplicas(false);\n    create.setCreateNodeSet(String.join(\",\", nodes));\n    create.process(solrClient);\n\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15, false, true)) + \"ms\");\n\n    int KILL_NODES = 8;\n    // kill off a number of nodes\n    for (int i = 0; i < KILL_NODES; i++) {\n      cluster.simRemoveNode(nodes.get(i), false);\n    }\n    // should fully recover\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 90 * KILL_NODES, TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15, false, true)) + \"ms\");\n\n    log.info(\"OP COUNTS: \" + cluster.simGetOpCounts());\n    long moveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n\n    // simulate a number of flaky nodes\n    int FLAKY_NODES = 10;\n    int flakyReplicas = 0;\n    for (int cnt = 0; cnt < 10; cnt++) {\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        flakyReplicas += cluster.getSimClusterStateProvider().simGetReplicaInfos(nodes.get(i))\n            .stream().filter(r -> r.getState().equals(Replica.State.ACTIVE)).count();\n        cluster.simRemoveNode(nodes.get(i), false);\n      }\n      cluster.getTimeSource().sleep(TimeUnit.SECONDS.toMillis(waitForSeconds) * 2);\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        final String nodeId = nodes.get(i);\n        cluster.submit(() -> cluster.getSimClusterStateProvider().simRestoreNode(nodeId));\n      }\n    }\n\n    // wait until started == finished\n    TimeOut timeOut = new TimeOut(20 * waitForSeconds * NUM_NODES, TimeUnit.SECONDS, cluster.getTimeSource());\n    while (!timeOut.hasTimedOut()) {\n      if (triggerStartedCount.get() == triggerFinishedCount.get()) {\n        break;\n      }\n      timeOut.sleep(1000);\n    }\n    if (timeOut.hasTimedOut()) {\n      fail(\"did not finish processing all events in time: started=\" + triggerStartedCount.get() + \", finished=\" + triggerFinishedCount.get());\n    }\n\n\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15, false, true)) + \"ms\");\n    long newMoveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n    log.info(\"==== Flaky replicas: {}. Additional MOVEREPLICA count: {}\", flakyReplicas, (newMoveReplicaOps - moveReplicaOps));\n    // flaky nodes lead to a number of MOVEREPLICA that is non-zero but lower than the number of flaky replicas\n    assertTrue(\"there should be new MOVERPLICA ops\", newMoveReplicaOps - moveReplicaOps > 0);\n    assertTrue(\"there should be less than flakyReplicas=\" + flakyReplicas + \" MOVEREPLICA ops\",\n        newMoveReplicaOps - moveReplicaOps < flakyReplicas);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9ef8d00dbfbeb534eba8a219a5df9d99b2de6ab5","date":1556572478,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimLargeCluster#testBasic().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimLargeCluster#testBasic().mjava","sourceNew":"  @Test\n  @AwaitsFix(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // this test hits a timeout easily\n  public void testBasic() throws Exception {\n    SolrClient solrClient = cluster.simGetSolrClient();\n    assertAutoScalingRequest\n      ( \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger1',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [\" +\n        \"{'name':'start','class':'\" + StartTriggerAction.class.getName() + \"'},\" +\n        \"{'name':'compute','class':'\" + ComputePlanAction.class.getName() + \"'},\" +\n        \"{'name':'execute','class':'\" + ExecutePlanAction.class.getName() + \"'},\" +\n        \"{'name':'test','class':'\" + FinishTriggerAction.class.getName() + \"'}\" +\n        \"]\" +\n        \"}}\");\n\n    assertAutoScalingRequest\n      ( \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'foo',\" +\n        \"'trigger' : 'node_lost_trigger1',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED', 'FAILED'],\" +\n        \"'beforeAction' : ['compute', 'execute'],\" +\n        \"'afterAction' : ['compute', 'execute'],\" +\n        \"'class' : '\" + TestTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\");\n\n    assertAutoscalingUpdateComplete();\n\n    // pick a few random nodes\n    List<String> nodes = new ArrayList<>();\n    int limit = 75;\n    for (String node : cluster.getClusterStateProvider().getLiveNodes()) {\n      nodes.add(node);\n      if (nodes.size() > limit) {\n        break;\n      }\n    }\n    Collections.shuffle(nodes, random());\n    // create collection on these nodes\n    String collectionName = \"testBasic\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 5, 5, 5, 5);\n    create.setMaxShardsPerNode(1);\n    create.setAutoAddReplicas(false);\n    create.setCreateNodeSet(String.join(\",\", nodes));\n    create.process(solrClient);\n\n    log.info(\"Ready after \" + CloudUtil.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudUtil.clusterShape(5, 15, false, true)) + \"ms\");\n\n    int KILL_NODES = 8;\n    // kill off a number of nodes\n    for (int i = 0; i < KILL_NODES; i++) {\n      cluster.simRemoveNode(nodes.get(i), false);\n    }\n    // should fully recover\n    log.info(\"Ready after \" + CloudUtil.waitForState(cluster, collectionName, 90 * KILL_NODES, TimeUnit.SECONDS,\n        CloudUtil.clusterShape(5, 15, false, true)) + \"ms\");\n\n    log.info(\"OP COUNTS: \" + cluster.simGetOpCounts());\n    long moveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n\n    // simulate a number of flaky nodes\n    int FLAKY_NODES = 10;\n    int flakyReplicas = 0;\n    for (int cnt = 0; cnt < 10; cnt++) {\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        flakyReplicas += cluster.getSimClusterStateProvider().simGetReplicaInfos(nodes.get(i))\n            .stream().filter(r -> r.getState().equals(Replica.State.ACTIVE)).count();\n        cluster.simRemoveNode(nodes.get(i), false);\n      }\n      cluster.getTimeSource().sleep(TimeUnit.SECONDS.toMillis(waitForSeconds) * 2);\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        final String nodeId = nodes.get(i);\n        cluster.submit(() -> cluster.getSimClusterStateProvider().simRestoreNode(nodeId));\n      }\n    }\n\n    // wait until started == finished\n    TimeOut timeOut = new TimeOut(20 * waitForSeconds * NUM_NODES, TimeUnit.SECONDS, cluster.getTimeSource());\n    while (!timeOut.hasTimedOut()) {\n      if (triggerStartedCount.get() == triggerFinishedCount.get()) {\n        break;\n      }\n      timeOut.sleep(1000);\n    }\n    if (timeOut.hasTimedOut()) {\n      fail(\"did not finish processing all events in time: started=\" + triggerStartedCount.get() + \", finished=\" + triggerFinishedCount.get());\n    }\n\n    log.info(\"Ready after \" + CloudUtil.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudUtil.clusterShape(5, 15, false, true)) + \"ms\");\n    long newMoveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n    log.info(\"==== Flaky replicas: {}. Additional MOVEREPLICA count: {}\", flakyReplicas, (newMoveReplicaOps - moveReplicaOps));\n    // flaky nodes lead to a number of MOVEREPLICA that is non-zero but lower than the number of flaky replicas\n    assertTrue(\"there should be new MOVERPLICA ops\", newMoveReplicaOps - moveReplicaOps > 0);\n    assertTrue(\"there should be less than flakyReplicas=\" + flakyReplicas + \" MOVEREPLICA ops\",\n        newMoveReplicaOps - moveReplicaOps < flakyReplicas);\n  }\n\n","sourceOld":"  @Test\n  @AwaitsFix(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // this test hits a timeout easily\n  public void testBasic() throws Exception {\n    SolrClient solrClient = cluster.simGetSolrClient();\n    assertAutoScalingRequest\n      ( \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger1',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [\" +\n        \"{'name':'start','class':'\" + StartTriggerAction.class.getName() + \"'},\" +\n        \"{'name':'compute','class':'\" + ComputePlanAction.class.getName() + \"'},\" +\n        \"{'name':'execute','class':'\" + ExecutePlanAction.class.getName() + \"'},\" +\n        \"{'name':'test','class':'\" + FinishTriggerAction.class.getName() + \"'}\" +\n        \"]\" +\n        \"}}\");\n\n    assertAutoScalingRequest\n      ( \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'foo',\" +\n        \"'trigger' : 'node_lost_trigger1',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED', 'FAILED'],\" +\n        \"'beforeAction' : ['compute', 'execute'],\" +\n        \"'afterAction' : ['compute', 'execute'],\" +\n        \"'class' : '\" + TestTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\");\n\n    assertAutoscalingUpdateComplete();\n\n    // pick a few random nodes\n    List<String> nodes = new ArrayList<>();\n    int limit = 75;\n    for (String node : cluster.getClusterStateProvider().getLiveNodes()) {\n      nodes.add(node);\n      if (nodes.size() > limit) {\n        break;\n      }\n    }\n    Collections.shuffle(nodes, random());\n    // create collection on these nodes\n    String collectionName = \"testBasic\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 5, 5, 5, 5);\n    create.setMaxShardsPerNode(1);\n    create.setAutoAddReplicas(false);\n    create.setCreateNodeSet(String.join(\",\", nodes));\n    create.process(solrClient);\n\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15, false, true)) + \"ms\");\n\n    int KILL_NODES = 8;\n    // kill off a number of nodes\n    for (int i = 0; i < KILL_NODES; i++) {\n      cluster.simRemoveNode(nodes.get(i), false);\n    }\n    // should fully recover\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 90 * KILL_NODES, TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15, false, true)) + \"ms\");\n\n    log.info(\"OP COUNTS: \" + cluster.simGetOpCounts());\n    long moveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n\n    // simulate a number of flaky nodes\n    int FLAKY_NODES = 10;\n    int flakyReplicas = 0;\n    for (int cnt = 0; cnt < 10; cnt++) {\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        flakyReplicas += cluster.getSimClusterStateProvider().simGetReplicaInfos(nodes.get(i))\n            .stream().filter(r -> r.getState().equals(Replica.State.ACTIVE)).count();\n        cluster.simRemoveNode(nodes.get(i), false);\n      }\n      cluster.getTimeSource().sleep(TimeUnit.SECONDS.toMillis(waitForSeconds) * 2);\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        final String nodeId = nodes.get(i);\n        cluster.submit(() -> cluster.getSimClusterStateProvider().simRestoreNode(nodeId));\n      }\n    }\n\n    // wait until started == finished\n    TimeOut timeOut = new TimeOut(20 * waitForSeconds * NUM_NODES, TimeUnit.SECONDS, cluster.getTimeSource());\n    while (!timeOut.hasTimedOut()) {\n      if (triggerStartedCount.get() == triggerFinishedCount.get()) {\n        break;\n      }\n      timeOut.sleep(1000);\n    }\n    if (timeOut.hasTimedOut()) {\n      fail(\"did not finish processing all events in time: started=\" + triggerStartedCount.get() + \", finished=\" + triggerFinishedCount.get());\n    }\n\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15, false, true)) + \"ms\");\n    long newMoveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n    log.info(\"==== Flaky replicas: {}. Additional MOVEREPLICA count: {}\", flakyReplicas, (newMoveReplicaOps - moveReplicaOps));\n    // flaky nodes lead to a number of MOVEREPLICA that is non-zero but lower than the number of flaky replicas\n    assertTrue(\"there should be new MOVERPLICA ops\", newMoveReplicaOps - moveReplicaOps > 0);\n    assertTrue(\"there should be less than flakyReplicas=\" + flakyReplicas + \" MOVEREPLICA ops\",\n        newMoveReplicaOps - moveReplicaOps < flakyReplicas);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fe9f2c4a0d7ac164e4bdd4eee7f87131aec83fd4","date":1588172214,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimLargeCluster#testBasic().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimLargeCluster#testBasic().mjava","sourceNew":"  @Test\n  @AwaitsFix(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // this test hits a timeout easily\n  public void testBasic() throws Exception {\n    SolrClient solrClient = cluster.simGetSolrClient();\n    assertAutoScalingRequest\n      ( \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger1',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [\" +\n        \"{'name':'start','class':'\" + StartTriggerAction.class.getName() + \"'},\" +\n        \"{'name':'compute','class':'\" + ComputePlanAction.class.getName() + \"'},\" +\n        \"{'name':'execute','class':'\" + ExecutePlanAction.class.getName() + \"'},\" +\n        \"{'name':'test','class':'\" + FinishTriggerAction.class.getName() + \"'}\" +\n        \"]\" +\n        \"}}\");\n\n    assertAutoScalingRequest\n      ( \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'foo',\" +\n        \"'trigger' : 'node_lost_trigger1',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED', 'FAILED'],\" +\n        \"'beforeAction' : ['compute', 'execute'],\" +\n        \"'afterAction' : ['compute', 'execute'],\" +\n        \"'class' : '\" + TestTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\");\n\n    assertAutoscalingUpdateComplete();\n\n    // pick a few random nodes\n    List<String> nodes = new ArrayList<>();\n    int limit = 75;\n    for (String node : cluster.getClusterStateProvider().getLiveNodes()) {\n      nodes.add(node);\n      if (nodes.size() > limit) {\n        break;\n      }\n    }\n    Collections.shuffle(nodes, random());\n    // create collection on these nodes\n    String collectionName = \"testBasic\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 5, 5, 5, 5);\n    create.setMaxShardsPerNode(1);\n    create.setAutoAddReplicas(false);\n    create.setCreateNodeSet(String.join(\",\", nodes));\n    create.process(solrClient);\n\n    if (log.isInfoEnabled()) {\n      log.info(\"Ready after {} ms\", CloudUtil.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n          CloudUtil.clusterShape(5, 15, false, true)));\n    }\n\n    int KILL_NODES = 8;\n    // kill off a number of nodes\n    for (int i = 0; i < KILL_NODES; i++) {\n      cluster.simRemoveNode(nodes.get(i), false);\n    }\n    // should fully recover\n    if (log.isInfoEnabled()) {\n      log.info(\"Ready after {} ms\", CloudUtil.waitForState(cluster, collectionName, 90 * KILL_NODES, TimeUnit.SECONDS,\n          CloudUtil.clusterShape(5, 15, false, true)));\n      log.info(\"OP COUNTS: {}\", cluster.simGetOpCounts()); // logOk\n    }\n    long moveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n\n    // simulate a number of flaky nodes\n    int FLAKY_NODES = 10;\n    int flakyReplicas = 0;\n    for (int cnt = 0; cnt < 10; cnt++) {\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        flakyReplicas += cluster.getSimClusterStateProvider().simGetReplicaInfos(nodes.get(i))\n            .stream().filter(r -> r.getState().equals(Replica.State.ACTIVE)).count();\n        cluster.simRemoveNode(nodes.get(i), false);\n      }\n      cluster.getTimeSource().sleep(TimeUnit.SECONDS.toMillis(waitForSeconds) * 2);\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        final String nodeId = nodes.get(i);\n        cluster.submit(() -> cluster.getSimClusterStateProvider().simRestoreNode(nodeId));\n      }\n    }\n\n    // wait until started == finished\n    TimeOut timeOut = new TimeOut(20 * waitForSeconds * NUM_NODES, TimeUnit.SECONDS, cluster.getTimeSource());\n    while (!timeOut.hasTimedOut()) {\n      if (triggerStartedCount.get() == triggerFinishedCount.get()) {\n        break;\n      }\n      timeOut.sleep(1000);\n    }\n    if (timeOut.hasTimedOut()) {\n      fail(\"did not finish processing all events in time: started=\" + triggerStartedCount.get() + \", finished=\" + triggerFinishedCount.get());\n    }\n\n    if (log.isInfoEnabled()) {\n      log.info(\"Ready after {} ms\", CloudUtil.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n          CloudUtil.clusterShape(5, 15, false, true)));\n    }\n\n    long newMoveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n    if (log.isInfoEnabled()) {\n      log.info(\"==== Flaky replicas: {}. Additional MOVEREPLICA count: {}\", flakyReplicas, (newMoveReplicaOps - moveReplicaOps));\n    }\n    // flaky nodes lead to a number of MOVEREPLICA that is non-zero but lower than the number of flaky replicas\n    assertTrue(\"there should be new MOVERPLICA ops\", newMoveReplicaOps - moveReplicaOps > 0);\n    assertTrue(\"there should be less than flakyReplicas=\" + flakyReplicas + \" MOVEREPLICA ops\",\n        newMoveReplicaOps - moveReplicaOps < flakyReplicas);\n  }\n\n","sourceOld":"  @Test\n  @AwaitsFix(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // this test hits a timeout easily\n  public void testBasic() throws Exception {\n    SolrClient solrClient = cluster.simGetSolrClient();\n    assertAutoScalingRequest\n      ( \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger1',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [\" +\n        \"{'name':'start','class':'\" + StartTriggerAction.class.getName() + \"'},\" +\n        \"{'name':'compute','class':'\" + ComputePlanAction.class.getName() + \"'},\" +\n        \"{'name':'execute','class':'\" + ExecutePlanAction.class.getName() + \"'},\" +\n        \"{'name':'test','class':'\" + FinishTriggerAction.class.getName() + \"'}\" +\n        \"]\" +\n        \"}}\");\n\n    assertAutoScalingRequest\n      ( \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'foo',\" +\n        \"'trigger' : 'node_lost_trigger1',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED', 'FAILED'],\" +\n        \"'beforeAction' : ['compute', 'execute'],\" +\n        \"'afterAction' : ['compute', 'execute'],\" +\n        \"'class' : '\" + TestTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\");\n\n    assertAutoscalingUpdateComplete();\n\n    // pick a few random nodes\n    List<String> nodes = new ArrayList<>();\n    int limit = 75;\n    for (String node : cluster.getClusterStateProvider().getLiveNodes()) {\n      nodes.add(node);\n      if (nodes.size() > limit) {\n        break;\n      }\n    }\n    Collections.shuffle(nodes, random());\n    // create collection on these nodes\n    String collectionName = \"testBasic\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 5, 5, 5, 5);\n    create.setMaxShardsPerNode(1);\n    create.setAutoAddReplicas(false);\n    create.setCreateNodeSet(String.join(\",\", nodes));\n    create.process(solrClient);\n\n    log.info(\"Ready after \" + CloudUtil.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudUtil.clusterShape(5, 15, false, true)) + \"ms\");\n\n    int KILL_NODES = 8;\n    // kill off a number of nodes\n    for (int i = 0; i < KILL_NODES; i++) {\n      cluster.simRemoveNode(nodes.get(i), false);\n    }\n    // should fully recover\n    log.info(\"Ready after \" + CloudUtil.waitForState(cluster, collectionName, 90 * KILL_NODES, TimeUnit.SECONDS,\n        CloudUtil.clusterShape(5, 15, false, true)) + \"ms\");\n\n    log.info(\"OP COUNTS: \" + cluster.simGetOpCounts());\n    long moveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n\n    // simulate a number of flaky nodes\n    int FLAKY_NODES = 10;\n    int flakyReplicas = 0;\n    for (int cnt = 0; cnt < 10; cnt++) {\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        flakyReplicas += cluster.getSimClusterStateProvider().simGetReplicaInfos(nodes.get(i))\n            .stream().filter(r -> r.getState().equals(Replica.State.ACTIVE)).count();\n        cluster.simRemoveNode(nodes.get(i), false);\n      }\n      cluster.getTimeSource().sleep(TimeUnit.SECONDS.toMillis(waitForSeconds) * 2);\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        final String nodeId = nodes.get(i);\n        cluster.submit(() -> cluster.getSimClusterStateProvider().simRestoreNode(nodeId));\n      }\n    }\n\n    // wait until started == finished\n    TimeOut timeOut = new TimeOut(20 * waitForSeconds * NUM_NODES, TimeUnit.SECONDS, cluster.getTimeSource());\n    while (!timeOut.hasTimedOut()) {\n      if (triggerStartedCount.get() == triggerFinishedCount.get()) {\n        break;\n      }\n      timeOut.sleep(1000);\n    }\n    if (timeOut.hasTimedOut()) {\n      fail(\"did not finish processing all events in time: started=\" + triggerStartedCount.get() + \", finished=\" + triggerFinishedCount.get());\n    }\n\n    log.info(\"Ready after \" + CloudUtil.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudUtil.clusterShape(5, 15, false, true)) + \"ms\");\n    long newMoveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n    log.info(\"==== Flaky replicas: {}. Additional MOVEREPLICA count: {}\", flakyReplicas, (newMoveReplicaOps - moveReplicaOps));\n    // flaky nodes lead to a number of MOVEREPLICA that is non-zero but lower than the number of flaky replicas\n    assertTrue(\"there should be new MOVERPLICA ops\", newMoveReplicaOps - moveReplicaOps > 0);\n    assertTrue(\"there should be less than flakyReplicas=\" + flakyReplicas + \" MOVEREPLICA ops\",\n        newMoveReplicaOps - moveReplicaOps < flakyReplicas);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e46a76bb135597b8bf35930cfdb3702bdd1cbe6e","date":1594223844,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimLargeCluster#testBasic().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimLargeCluster#testBasic().mjava","sourceNew":"  @Test\n  @AwaitsFix(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // this test hits a timeout easily\n  public void testBasic() throws Exception {\n    SolrClient solrClient = cluster.simGetSolrClient();\n    assertAutoScalingRequest\n      ( \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger1',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [\" +\n        \"{'name':'start','class':'\" + StartTriggerAction.class.getName() + \"'},\" +\n        \"{'name':'compute','class':'\" + ComputePlanAction.class.getName() + \"'},\" +\n        \"{'name':'execute','class':'\" + ExecutePlanAction.class.getName() + \"'},\" +\n        \"{'name':'test','class':'\" + FinishTriggerAction.class.getName() + \"'}\" +\n        \"]\" +\n        \"}}\");\n\n    assertAutoScalingRequest\n      ( \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'foo',\" +\n        \"'trigger' : 'node_lost_trigger1',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED', 'FAILED'],\" +\n        \"'beforeAction' : ['compute', 'execute'],\" +\n        \"'afterAction' : ['compute', 'execute'],\" +\n        \"'class' : '\" + TestTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\");\n\n    assertAutoscalingUpdateComplete();\n\n    // pick a few random nodes\n    List<String> nodes = new ArrayList<>();\n    int limit = 75;\n    for (String node : cluster.getClusterStateProvider().getLiveNodes()) {\n      nodes.add(node);\n      if (nodes.size() > limit) {\n        break;\n      }\n    }\n    Collections.shuffle(nodes, random());\n    // create collection on these nodes\n    String collectionName = \"testBasic\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 5, 5, 5, 5);\n    create.setAutoAddReplicas(false);\n    create.setCreateNodeSet(String.join(\",\", nodes));\n    create.process(solrClient);\n\n    if (log.isInfoEnabled()) {\n      log.info(\"Ready after {} ms\", CloudUtil.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n          CloudUtil.clusterShape(5, 15, false, true)));\n    }\n\n    int KILL_NODES = 8;\n    // kill off a number of nodes\n    for (int i = 0; i < KILL_NODES; i++) {\n      cluster.simRemoveNode(nodes.get(i), false);\n    }\n    // should fully recover\n    if (log.isInfoEnabled()) {\n      log.info(\"Ready after {} ms\", CloudUtil.waitForState(cluster, collectionName, 90 * KILL_NODES, TimeUnit.SECONDS,\n          CloudUtil.clusterShape(5, 15, false, true)));\n      log.info(\"OP COUNTS: {}\", cluster.simGetOpCounts()); // logOk\n    }\n    long moveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n\n    // simulate a number of flaky nodes\n    int FLAKY_NODES = 10;\n    int flakyReplicas = 0;\n    for (int cnt = 0; cnt < 10; cnt++) {\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        flakyReplicas += cluster.getSimClusterStateProvider().simGetReplicaInfos(nodes.get(i))\n            .stream().filter(r -> r.getState().equals(Replica.State.ACTIVE)).count();\n        cluster.simRemoveNode(nodes.get(i), false);\n      }\n      cluster.getTimeSource().sleep(TimeUnit.SECONDS.toMillis(waitForSeconds) * 2);\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        final String nodeId = nodes.get(i);\n        cluster.submit(() -> cluster.getSimClusterStateProvider().simRestoreNode(nodeId));\n      }\n    }\n\n    // wait until started == finished\n    TimeOut timeOut = new TimeOut(20 * waitForSeconds * NUM_NODES, TimeUnit.SECONDS, cluster.getTimeSource());\n    while (!timeOut.hasTimedOut()) {\n      if (triggerStartedCount.get() == triggerFinishedCount.get()) {\n        break;\n      }\n      timeOut.sleep(1000);\n    }\n    if (timeOut.hasTimedOut()) {\n      fail(\"did not finish processing all events in time: started=\" + triggerStartedCount.get() + \", finished=\" + triggerFinishedCount.get());\n    }\n\n    if (log.isInfoEnabled()) {\n      log.info(\"Ready after {} ms\", CloudUtil.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n          CloudUtil.clusterShape(5, 15, false, true)));\n    }\n\n    long newMoveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n    if (log.isInfoEnabled()) {\n      log.info(\"==== Flaky replicas: {}. Additional MOVEREPLICA count: {}\", flakyReplicas, (newMoveReplicaOps - moveReplicaOps));\n    }\n    // flaky nodes lead to a number of MOVEREPLICA that is non-zero but lower than the number of flaky replicas\n    assertTrue(\"there should be new MOVERPLICA ops\", newMoveReplicaOps - moveReplicaOps > 0);\n    assertTrue(\"there should be less than flakyReplicas=\" + flakyReplicas + \" MOVEREPLICA ops\",\n        newMoveReplicaOps - moveReplicaOps < flakyReplicas);\n  }\n\n","sourceOld":"  @Test\n  @AwaitsFix(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // this test hits a timeout easily\n  public void testBasic() throws Exception {\n    SolrClient solrClient = cluster.simGetSolrClient();\n    assertAutoScalingRequest\n      ( \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger1',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [\" +\n        \"{'name':'start','class':'\" + StartTriggerAction.class.getName() + \"'},\" +\n        \"{'name':'compute','class':'\" + ComputePlanAction.class.getName() + \"'},\" +\n        \"{'name':'execute','class':'\" + ExecutePlanAction.class.getName() + \"'},\" +\n        \"{'name':'test','class':'\" + FinishTriggerAction.class.getName() + \"'}\" +\n        \"]\" +\n        \"}}\");\n\n    assertAutoScalingRequest\n      ( \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'foo',\" +\n        \"'trigger' : 'node_lost_trigger1',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED', 'FAILED'],\" +\n        \"'beforeAction' : ['compute', 'execute'],\" +\n        \"'afterAction' : ['compute', 'execute'],\" +\n        \"'class' : '\" + TestTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\");\n\n    assertAutoscalingUpdateComplete();\n\n    // pick a few random nodes\n    List<String> nodes = new ArrayList<>();\n    int limit = 75;\n    for (String node : cluster.getClusterStateProvider().getLiveNodes()) {\n      nodes.add(node);\n      if (nodes.size() > limit) {\n        break;\n      }\n    }\n    Collections.shuffle(nodes, random());\n    // create collection on these nodes\n    String collectionName = \"testBasic\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 5, 5, 5, 5);\n    create.setMaxShardsPerNode(1);\n    create.setAutoAddReplicas(false);\n    create.setCreateNodeSet(String.join(\",\", nodes));\n    create.process(solrClient);\n\n    if (log.isInfoEnabled()) {\n      log.info(\"Ready after {} ms\", CloudUtil.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n          CloudUtil.clusterShape(5, 15, false, true)));\n    }\n\n    int KILL_NODES = 8;\n    // kill off a number of nodes\n    for (int i = 0; i < KILL_NODES; i++) {\n      cluster.simRemoveNode(nodes.get(i), false);\n    }\n    // should fully recover\n    if (log.isInfoEnabled()) {\n      log.info(\"Ready after {} ms\", CloudUtil.waitForState(cluster, collectionName, 90 * KILL_NODES, TimeUnit.SECONDS,\n          CloudUtil.clusterShape(5, 15, false, true)));\n      log.info(\"OP COUNTS: {}\", cluster.simGetOpCounts()); // logOk\n    }\n    long moveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n\n    // simulate a number of flaky nodes\n    int FLAKY_NODES = 10;\n    int flakyReplicas = 0;\n    for (int cnt = 0; cnt < 10; cnt++) {\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        flakyReplicas += cluster.getSimClusterStateProvider().simGetReplicaInfos(nodes.get(i))\n            .stream().filter(r -> r.getState().equals(Replica.State.ACTIVE)).count();\n        cluster.simRemoveNode(nodes.get(i), false);\n      }\n      cluster.getTimeSource().sleep(TimeUnit.SECONDS.toMillis(waitForSeconds) * 2);\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        final String nodeId = nodes.get(i);\n        cluster.submit(() -> cluster.getSimClusterStateProvider().simRestoreNode(nodeId));\n      }\n    }\n\n    // wait until started == finished\n    TimeOut timeOut = new TimeOut(20 * waitForSeconds * NUM_NODES, TimeUnit.SECONDS, cluster.getTimeSource());\n    while (!timeOut.hasTimedOut()) {\n      if (triggerStartedCount.get() == triggerFinishedCount.get()) {\n        break;\n      }\n      timeOut.sleep(1000);\n    }\n    if (timeOut.hasTimedOut()) {\n      fail(\"did not finish processing all events in time: started=\" + triggerStartedCount.get() + \", finished=\" + triggerFinishedCount.get());\n    }\n\n    if (log.isInfoEnabled()) {\n      log.info(\"Ready after {} ms\", CloudUtil.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n          CloudUtil.clusterShape(5, 15, false, true)));\n    }\n\n    long newMoveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n    if (log.isInfoEnabled()) {\n      log.info(\"==== Flaky replicas: {}. Additional MOVEREPLICA count: {}\", flakyReplicas, (newMoveReplicaOps - moveReplicaOps));\n    }\n    // flaky nodes lead to a number of MOVEREPLICA that is non-zero but lower than the number of flaky replicas\n    assertTrue(\"there should be new MOVERPLICA ops\", newMoveReplicaOps - moveReplicaOps > 0);\n    assertTrue(\"there should be less than flakyReplicas=\" + flakyReplicas + \" MOVEREPLICA ops\",\n        newMoveReplicaOps - moveReplicaOps < flakyReplicas);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3f504512a03d978990cbff30db0522b354e846db","date":1595247421,"type":4,"author":"Ishan Chattopadhyaya","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimLargeCluster#testBasic().mjava","sourceNew":null,"sourceOld":"  @Test\n  @AwaitsFix(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // this test hits a timeout easily\n  public void testBasic() throws Exception {\n    SolrClient solrClient = cluster.simGetSolrClient();\n    assertAutoScalingRequest\n      ( \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger1',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [\" +\n        \"{'name':'start','class':'\" + StartTriggerAction.class.getName() + \"'},\" +\n        \"{'name':'compute','class':'\" + ComputePlanAction.class.getName() + \"'},\" +\n        \"{'name':'execute','class':'\" + ExecutePlanAction.class.getName() + \"'},\" +\n        \"{'name':'test','class':'\" + FinishTriggerAction.class.getName() + \"'}\" +\n        \"]\" +\n        \"}}\");\n\n    assertAutoScalingRequest\n      ( \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'foo',\" +\n        \"'trigger' : 'node_lost_trigger1',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED', 'FAILED'],\" +\n        \"'beforeAction' : ['compute', 'execute'],\" +\n        \"'afterAction' : ['compute', 'execute'],\" +\n        \"'class' : '\" + TestTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\");\n\n    assertAutoscalingUpdateComplete();\n\n    // pick a few random nodes\n    List<String> nodes = new ArrayList<>();\n    int limit = 75;\n    for (String node : cluster.getClusterStateProvider().getLiveNodes()) {\n      nodes.add(node);\n      if (nodes.size() > limit) {\n        break;\n      }\n    }\n    Collections.shuffle(nodes, random());\n    // create collection on these nodes\n    String collectionName = \"testBasic\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 5, 5, 5, 5);\n    create.setAutoAddReplicas(false);\n    create.setCreateNodeSet(String.join(\",\", nodes));\n    create.process(solrClient);\n\n    if (log.isInfoEnabled()) {\n      log.info(\"Ready after {} ms\", CloudUtil.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n          CloudUtil.clusterShape(5, 15, false, true)));\n    }\n\n    int KILL_NODES = 8;\n    // kill off a number of nodes\n    for (int i = 0; i < KILL_NODES; i++) {\n      cluster.simRemoveNode(nodes.get(i), false);\n    }\n    // should fully recover\n    if (log.isInfoEnabled()) {\n      log.info(\"Ready after {} ms\", CloudUtil.waitForState(cluster, collectionName, 90 * KILL_NODES, TimeUnit.SECONDS,\n          CloudUtil.clusterShape(5, 15, false, true)));\n      log.info(\"OP COUNTS: {}\", cluster.simGetOpCounts()); // logOk\n    }\n    long moveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n\n    // simulate a number of flaky nodes\n    int FLAKY_NODES = 10;\n    int flakyReplicas = 0;\n    for (int cnt = 0; cnt < 10; cnt++) {\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        flakyReplicas += cluster.getSimClusterStateProvider().simGetReplicaInfos(nodes.get(i))\n            .stream().filter(r -> r.getState().equals(Replica.State.ACTIVE)).count();\n        cluster.simRemoveNode(nodes.get(i), false);\n      }\n      cluster.getTimeSource().sleep(TimeUnit.SECONDS.toMillis(waitForSeconds) * 2);\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        final String nodeId = nodes.get(i);\n        cluster.submit(() -> cluster.getSimClusterStateProvider().simRestoreNode(nodeId));\n      }\n    }\n\n    // wait until started == finished\n    TimeOut timeOut = new TimeOut(20 * waitForSeconds * NUM_NODES, TimeUnit.SECONDS, cluster.getTimeSource());\n    while (!timeOut.hasTimedOut()) {\n      if (triggerStartedCount.get() == triggerFinishedCount.get()) {\n        break;\n      }\n      timeOut.sleep(1000);\n    }\n    if (timeOut.hasTimedOut()) {\n      fail(\"did not finish processing all events in time: started=\" + triggerStartedCount.get() + \", finished=\" + triggerFinishedCount.get());\n    }\n\n    if (log.isInfoEnabled()) {\n      log.info(\"Ready after {} ms\", CloudUtil.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n          CloudUtil.clusterShape(5, 15, false, true)));\n    }\n\n    long newMoveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n    if (log.isInfoEnabled()) {\n      log.info(\"==== Flaky replicas: {}. Additional MOVEREPLICA count: {}\", flakyReplicas, (newMoveReplicaOps - moveReplicaOps));\n    }\n    // flaky nodes lead to a number of MOVEREPLICA that is non-zero but lower than the number of flaky replicas\n    assertTrue(\"there should be new MOVERPLICA ops\", newMoveReplicaOps - moveReplicaOps > 0);\n    assertTrue(\"there should be less than flakyReplicas=\" + flakyReplicas + \" MOVEREPLICA ops\",\n        newMoveReplicaOps - moveReplicaOps < flakyReplicas);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a6a5c1c40529f15b445e6720dfde1967e139bff1":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"30004ef8212d169b5fc7d098ec7aa299c8b5f060":["ce85ed088dcf7aa1742105d4a8caa9aab3b491c1"],"3f504512a03d978990cbff30db0522b354e846db":["e46a76bb135597b8bf35930cfdb3702bdd1cbe6e"],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["a6a5c1c40529f15b445e6720dfde1967e139bff1"],"fe9f2c4a0d7ac164e4bdd4eee7f87131aec83fd4":["9ef8d00dbfbeb534eba8a219a5df9d99b2de6ab5"],"ce85ed088dcf7aa1742105d4a8caa9aab3b491c1":["89948af0461fead48f44ba8fb7866f107ce83f22"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"9ef8d00dbfbeb534eba8a219a5df9d99b2de6ab5":["30004ef8212d169b5fc7d098ec7aa299c8b5f060"],"89948af0461fead48f44ba8fb7866f107ce83f22":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"e46a76bb135597b8bf35930cfdb3702bdd1cbe6e":["fe9f2c4a0d7ac164e4bdd4eee7f87131aec83fd4"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3f504512a03d978990cbff30db0522b354e846db"]},"commit2Childs":{"a6a5c1c40529f15b445e6720dfde1967e139bff1":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"30004ef8212d169b5fc7d098ec7aa299c8b5f060":["9ef8d00dbfbeb534eba8a219a5df9d99b2de6ab5"],"3f504512a03d978990cbff30db0522b354e846db":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["89948af0461fead48f44ba8fb7866f107ce83f22"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["a6a5c1c40529f15b445e6720dfde1967e139bff1"],"ce85ed088dcf7aa1742105d4a8caa9aab3b491c1":["30004ef8212d169b5fc7d098ec7aa299c8b5f060"],"fe9f2c4a0d7ac164e4bdd4eee7f87131aec83fd4":["e46a76bb135597b8bf35930cfdb3702bdd1cbe6e"],"9ef8d00dbfbeb534eba8a219a5df9d99b2de6ab5":["fe9f2c4a0d7ac164e4bdd4eee7f87131aec83fd4"],"89948af0461fead48f44ba8fb7866f107ce83f22":["ce85ed088dcf7aa1742105d4a8caa9aab3b491c1"],"e46a76bb135597b8bf35930cfdb3702bdd1cbe6e":["3f504512a03d978990cbff30db0522b354e846db"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}