{"path":"lucene/core/src/java/org/apache/lucene/index/SortedBytesDVWriter#flush(FieldInfo,SegmentWriteState,SortedDocValuesConsumer).mjava","commits":[{"id":"71df1db89d3a713f022b58111aafd14a4b352da0","date":1352479848,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SortedBytesDVWriter#flush(FieldInfo,SegmentWriteState,SortedDocValuesConsumer).mjava","pathOld":"/dev/null","sourceNew":"  public void flush(FieldInfo fieldInfo, SegmentWriteState state, SortedDocValuesConsumer consumer) throws IOException {\n    int valueCount = hash.size();\n\n    final int maxDoc = state.segmentInfo.getDocCount();\n    int emptyOrd = -1;\n    if (pending.size() < maxDoc) {\n      // Make sure we added EMPTY value before sorting:\n      emptyOrd = hash.add(EMPTY);\n      if (emptyOrd < 0) {\n        emptyOrd = -emptyOrd-1;\n      }\n    }\n\n    int[] sortedValues = hash.sort(BytesRef.getUTF8SortedAsUnicodeComparator());\n    // nocommit must budget this into RAM consumption up front!\n    int[] ordMap = new int[valueCount];\n\n    // Write values, in sorted order:\n    BytesRef scratch = new BytesRef();\n    for(int ord=0;ord<valueCount;ord++) {\n      consumer.addValue(hash.get(sortedValues[ord], scratch));\n      ordMap[sortedValues[ord]] = ord;\n    }\n    final int bufferedDocCount = pending.size();\n\n    for(int docID=0;docID<bufferedDocCount;docID++) {\n      consumer.addDoc(ordMap[pending.get(docID)]);\n    }\n    for(int docID=bufferedDocCount;docID<maxDoc;docID++) {\n      consumer.addDoc(ordMap[emptyOrd]);\n    }\n    reset();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ce73f585d17f53055185a19beb46db23d76e0ad9","date":1353077110,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SortedBytesDVWriter#flush(FieldInfo,SegmentWriteState,SortedDocValuesConsumer).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SortedBytesDVWriter#flush(FieldInfo,SegmentWriteState,SortedDocValuesConsumer).mjava","sourceNew":"  public void flush(FieldInfo fieldInfo, SegmentWriteState state, SortedDocValuesConsumer consumer) throws IOException {\n    int valueCount = hash.size();\n\n    final int maxDoc = state.segmentInfo.getDocCount();\n    int emptyOrd = -1;\n    if (pendingIndex < maxDoc) {\n      // Make sure we added EMPTY value before sorting:\n      emptyOrd = hash.add(EMPTY);\n      if (emptyOrd < 0) {\n        emptyOrd = -emptyOrd-1;\n      }\n    }\n\n    int[] sortedValues = hash.sort(BytesRef.getUTF8SortedAsUnicodeComparator());\n    final int sortedValueRamUsage = RamUsageEstimator.NUM_BYTES_ARRAY_HEADER + RamUsageEstimator.NUM_BYTES_INT*valueCount;\n    iwBytesUsed.addAndGet(sortedValueRamUsage);\n    final int[] ordMap = new int[valueCount];\n    // Write values, in sorted order:\n    BytesRef scratch = new BytesRef();\n    for(int ord=0;ord<valueCount;ord++) {\n      consumer.addValue(hash.get(sortedValues[ord], scratch));\n      ordMap[sortedValues[ord]] = ord;\n    }\n    final int bufferedDocCount = pendingIndex;\n\n    for(int docID=0;docID<bufferedDocCount;docID++) {\n      consumer.addDoc(ordMap[pending[docID]]);\n    }\n    for(int docID=bufferedDocCount;docID<maxDoc;docID++) {\n      consumer.addDoc(ordMap[emptyOrd]);\n    }\n    iwBytesUsed.addAndGet(-sortedValueRamUsage);\n    reset();\n  }\n\n","sourceOld":"  public void flush(FieldInfo fieldInfo, SegmentWriteState state, SortedDocValuesConsumer consumer) throws IOException {\n    int valueCount = hash.size();\n\n    final int maxDoc = state.segmentInfo.getDocCount();\n    int emptyOrd = -1;\n    if (pending.size() < maxDoc) {\n      // Make sure we added EMPTY value before sorting:\n      emptyOrd = hash.add(EMPTY);\n      if (emptyOrd < 0) {\n        emptyOrd = -emptyOrd-1;\n      }\n    }\n\n    int[] sortedValues = hash.sort(BytesRef.getUTF8SortedAsUnicodeComparator());\n    // nocommit must budget this into RAM consumption up front!\n    int[] ordMap = new int[valueCount];\n\n    // Write values, in sorted order:\n    BytesRef scratch = new BytesRef();\n    for(int ord=0;ord<valueCount;ord++) {\n      consumer.addValue(hash.get(sortedValues[ord], scratch));\n      ordMap[sortedValues[ord]] = ord;\n    }\n    final int bufferedDocCount = pending.size();\n\n    for(int docID=0;docID<bufferedDocCount;docID++) {\n      consumer.addDoc(ordMap[pending.get(docID)]);\n    }\n    for(int docID=bufferedDocCount;docID<maxDoc;docID++) {\n      consumer.addDoc(ordMap[emptyOrd]);\n    }\n    reset();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f45457a742a53533c348c4b990b1c579ff364467","date":1353197071,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SortedBytesDVWriter#flush(FieldInfo,SegmentWriteState,SortedDocValuesConsumer).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SortedBytesDVWriter#flush(FieldInfo,SegmentWriteState,SortedDocValuesConsumer).mjava","sourceNew":"  public void flush(FieldInfo fieldInfo, SegmentWriteState state, SortedDocValuesConsumer consumer) throws IOException {\n\n    final int maxDoc = state.segmentInfo.getDocCount();\n    int emptyOrd = -1;\n    if (pendingIndex < maxDoc) {\n      // Make sure we added EMPTY value before sorting:\n      emptyOrd = hash.add(EMPTY);\n      if (emptyOrd < 0) {\n        emptyOrd = -emptyOrd-1;\n      }\n    }\n\n    int valueCount = hash.size();\n\n    int[] sortedValues = hash.sort(BytesRef.getUTF8SortedAsUnicodeComparator());\n    final int sortedValueRamUsage = RamUsageEstimator.NUM_BYTES_ARRAY_HEADER + RamUsageEstimator.NUM_BYTES_INT*valueCount;\n    iwBytesUsed.addAndGet(sortedValueRamUsage);\n    final int[] ordMap = new int[valueCount];\n    // Write values, in sorted order:\n    BytesRef scratch = new BytesRef();\n    for(int ord=0;ord<valueCount;ord++) {\n      consumer.addValue(hash.get(sortedValues[ord], scratch));\n      ordMap[sortedValues[ord]] = ord;\n    }\n    final int bufferedDocCount = pendingIndex;\n\n    for(int docID=0;docID<bufferedDocCount;docID++) {\n      consumer.addDoc(ordMap[pending[docID]]);\n    }\n    for(int docID=bufferedDocCount;docID<maxDoc;docID++) {\n      consumer.addDoc(ordMap[emptyOrd]);\n    }\n    iwBytesUsed.addAndGet(-sortedValueRamUsage);\n    reset();\n  }\n\n","sourceOld":"  public void flush(FieldInfo fieldInfo, SegmentWriteState state, SortedDocValuesConsumer consumer) throws IOException {\n    int valueCount = hash.size();\n\n    final int maxDoc = state.segmentInfo.getDocCount();\n    int emptyOrd = -1;\n    if (pendingIndex < maxDoc) {\n      // Make sure we added EMPTY value before sorting:\n      emptyOrd = hash.add(EMPTY);\n      if (emptyOrd < 0) {\n        emptyOrd = -emptyOrd-1;\n      }\n    }\n\n    int[] sortedValues = hash.sort(BytesRef.getUTF8SortedAsUnicodeComparator());\n    final int sortedValueRamUsage = RamUsageEstimator.NUM_BYTES_ARRAY_HEADER + RamUsageEstimator.NUM_BYTES_INT*valueCount;\n    iwBytesUsed.addAndGet(sortedValueRamUsage);\n    final int[] ordMap = new int[valueCount];\n    // Write values, in sorted order:\n    BytesRef scratch = new BytesRef();\n    for(int ord=0;ord<valueCount;ord++) {\n      consumer.addValue(hash.get(sortedValues[ord], scratch));\n      ordMap[sortedValues[ord]] = ord;\n    }\n    final int bufferedDocCount = pendingIndex;\n\n    for(int docID=0;docID<bufferedDocCount;docID++) {\n      consumer.addDoc(ordMap[pending[docID]]);\n    }\n    for(int docID=bufferedDocCount;docID<maxDoc;docID++) {\n      consumer.addDoc(ordMap[emptyOrd]);\n    }\n    iwBytesUsed.addAndGet(-sortedValueRamUsage);\n    reset();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ede45a461a2dcb573505ed9b6a5182dfebd3688f","date":1353338494,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SortedBytesDVWriter#flush(FieldInfo,SegmentWriteState,SortedDocValuesConsumer).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SortedBytesDVWriter#flush(FieldInfo,SegmentWriteState,SortedDocValuesConsumer).mjava","sourceNew":"  public void flush(FieldInfo fieldInfo, SegmentWriteState state, SortedDocValuesConsumer consumer) throws IOException {\n\n    final int maxDoc = state.segmentInfo.getDocCount();\n    int emptyOrd = -1;\n    if (pendingIndex < maxDoc) {\n      // Make sure we added EMPTY value before sorting:\n      emptyOrd = hash.add(EMPTY);\n      if (emptyOrd < 0) {\n        emptyOrd = -emptyOrd-1;\n      }\n    }\n\n    int valueCount = hash.size();\n\n    int[] sortedValues = hash.sort(BytesRef.getUTF8SortedAsUnicodeComparator());\n    final int sortedValueRamUsage = RamUsageEstimator.NUM_BYTES_ARRAY_HEADER + RamUsageEstimator.NUM_BYTES_INT*valueCount;\n    iwBytesUsed.addAndGet(sortedValueRamUsage);\n    final int[] ordMap = new int[valueCount];\n    // Write values, in sorted order:\n    BytesRef scratch = new BytesRef();\n    for(int ord=0;ord<valueCount;ord++) {\n      consumer.addValue(hash.get(sortedValues[ord], scratch));\n      ordMap[sortedValues[ord]] = ord;\n    }\n    final int bufferedDocCount = pendingIndex;\n\n    for(int docID=0;docID<bufferedDocCount;docID++) {\n      consumer.addDoc(ordMap[pending[docID]]);\n    }\n    for(int docID=bufferedDocCount;docID<maxDoc;docID++) {\n      consumer.addDoc(ordMap[emptyOrd]);\n    }\n    iwBytesUsed.addAndGet(-sortedValueRamUsage);\n    reset();\n    consumer.finish();\n  }\n\n","sourceOld":"  public void flush(FieldInfo fieldInfo, SegmentWriteState state, SortedDocValuesConsumer consumer) throws IOException {\n\n    final int maxDoc = state.segmentInfo.getDocCount();\n    int emptyOrd = -1;\n    if (pendingIndex < maxDoc) {\n      // Make sure we added EMPTY value before sorting:\n      emptyOrd = hash.add(EMPTY);\n      if (emptyOrd < 0) {\n        emptyOrd = -emptyOrd-1;\n      }\n    }\n\n    int valueCount = hash.size();\n\n    int[] sortedValues = hash.sort(BytesRef.getUTF8SortedAsUnicodeComparator());\n    final int sortedValueRamUsage = RamUsageEstimator.NUM_BYTES_ARRAY_HEADER + RamUsageEstimator.NUM_BYTES_INT*valueCount;\n    iwBytesUsed.addAndGet(sortedValueRamUsage);\n    final int[] ordMap = new int[valueCount];\n    // Write values, in sorted order:\n    BytesRef scratch = new BytesRef();\n    for(int ord=0;ord<valueCount;ord++) {\n      consumer.addValue(hash.get(sortedValues[ord], scratch));\n      ordMap[sortedValues[ord]] = ord;\n    }\n    final int bufferedDocCount = pendingIndex;\n\n    for(int docID=0;docID<bufferedDocCount;docID++) {\n      consumer.addDoc(ordMap[pending[docID]]);\n    }\n    for(int docID=bufferedDocCount;docID<maxDoc;docID++) {\n      consumer.addDoc(ordMap[emptyOrd]);\n    }\n    iwBytesUsed.addAndGet(-sortedValueRamUsage);\n    reset();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"127981e5a1e1d1425c5fdc816ceacf753ca70ee4","date":1354205321,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SortedBytesDVWriter#flush(SegmentWriteState,SimpleDVConsumer).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SortedBytesDVWriter#flush(FieldInfo,SegmentWriteState,SortedDocValuesConsumer).mjava","sourceNew":"  @Override\n  public void flush(SegmentWriteState state, SimpleDVConsumer dvConsumer) throws IOException {\n    SortedDocValuesConsumer consumer = dvConsumer.addSortedField(fieldInfo,\n                                                                 hash.size(),\n                                                                 fixedLength >= 0,\n                                                                 maxLength);\n    final int maxDoc = state.segmentInfo.getDocCount();\n    int emptyOrd = -1;\n    if (pendingIndex < maxDoc) {\n      // Make sure we added EMPTY value before sorting:\n      emptyOrd = hash.add(EMPTY);\n      if (emptyOrd < 0) {\n        emptyOrd = -emptyOrd-1;\n      }\n    }\n\n    int valueCount = hash.size();\n\n    int[] sortedValues = hash.sort(BytesRef.getUTF8SortedAsUnicodeComparator());\n    final int sortedValueRamUsage = RamUsageEstimator.NUM_BYTES_ARRAY_HEADER + RamUsageEstimator.NUM_BYTES_INT*valueCount;\n    iwBytesUsed.addAndGet(sortedValueRamUsage);\n    final int[] ordMap = new int[valueCount];\n    // Write values, in sorted order:\n    BytesRef scratch = new BytesRef();\n    for(int ord=0;ord<valueCount;ord++) {\n      consumer.addValue(hash.get(sortedValues[ord], scratch));\n      ordMap[sortedValues[ord]] = ord;\n    }\n    final int bufferedDocCount = pendingIndex;\n\n    for(int docID=0;docID<bufferedDocCount;docID++) {\n      consumer.addDoc(ordMap[pending[docID]]);\n    }\n    for(int docID=bufferedDocCount;docID<maxDoc;docID++) {\n      consumer.addDoc(ordMap[emptyOrd]);\n    }\n    iwBytesUsed.addAndGet(-sortedValueRamUsage);\n    reset();\n    consumer.finish();\n  }\n\n","sourceOld":"  public void flush(FieldInfo fieldInfo, SegmentWriteState state, SortedDocValuesConsumer consumer) throws IOException {\n\n    final int maxDoc = state.segmentInfo.getDocCount();\n    int emptyOrd = -1;\n    if (pendingIndex < maxDoc) {\n      // Make sure we added EMPTY value before sorting:\n      emptyOrd = hash.add(EMPTY);\n      if (emptyOrd < 0) {\n        emptyOrd = -emptyOrd-1;\n      }\n    }\n\n    int valueCount = hash.size();\n\n    int[] sortedValues = hash.sort(BytesRef.getUTF8SortedAsUnicodeComparator());\n    final int sortedValueRamUsage = RamUsageEstimator.NUM_BYTES_ARRAY_HEADER + RamUsageEstimator.NUM_BYTES_INT*valueCount;\n    iwBytesUsed.addAndGet(sortedValueRamUsage);\n    final int[] ordMap = new int[valueCount];\n    // Write values, in sorted order:\n    BytesRef scratch = new BytesRef();\n    for(int ord=0;ord<valueCount;ord++) {\n      consumer.addValue(hash.get(sortedValues[ord], scratch));\n      ordMap[sortedValues[ord]] = ord;\n    }\n    final int bufferedDocCount = pendingIndex;\n\n    for(int docID=0;docID<bufferedDocCount;docID++) {\n      consumer.addDoc(ordMap[pending[docID]]);\n    }\n    for(int docID=bufferedDocCount;docID<maxDoc;docID++) {\n      consumer.addDoc(ordMap[emptyOrd]);\n    }\n    iwBytesUsed.addAndGet(-sortedValueRamUsage);\n    reset();\n    consumer.finish();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"ede45a461a2dcb573505ed9b6a5182dfebd3688f":["f45457a742a53533c348c4b990b1c579ff364467"],"ce73f585d17f53055185a19beb46db23d76e0ad9":["71df1db89d3a713f022b58111aafd14a4b352da0"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"127981e5a1e1d1425c5fdc816ceacf753ca70ee4":["ede45a461a2dcb573505ed9b6a5182dfebd3688f"],"71df1db89d3a713f022b58111aafd14a4b352da0":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"f45457a742a53533c348c4b990b1c579ff364467":["ce73f585d17f53055185a19beb46db23d76e0ad9"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"ede45a461a2dcb573505ed9b6a5182dfebd3688f":["127981e5a1e1d1425c5fdc816ceacf753ca70ee4"],"ce73f585d17f53055185a19beb46db23d76e0ad9":["f45457a742a53533c348c4b990b1c579ff364467"],"71df1db89d3a713f022b58111aafd14a4b352da0":["ce73f585d17f53055185a19beb46db23d76e0ad9"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["71df1db89d3a713f022b58111aafd14a4b352da0","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"127981e5a1e1d1425c5fdc816ceacf753ca70ee4":[],"f45457a742a53533c348c4b990b1c579ff364467":["ede45a461a2dcb573505ed9b6a5182dfebd3688f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["127981e5a1e1d1425c5fdc816ceacf753ca70ee4","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}