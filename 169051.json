{"path":"solr/core/src/java/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simCreateCollection(ZkNodeProps,NamedList).mjava","commits":[{"id":"9ef8d00dbfbeb534eba8a219a5df9d99b2de6ab5","date":1556572478,"type":1,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simCreateCollection(ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simCreateCollection(ZkNodeProps,NamedList).mjava","sourceNew":"  /**\n   * Create a new collection. This operation uses policy framework for node and replica assignments.\n   * @param props collection details\n   * @param results results of the operation.\n   */\n  public void simCreateCollection(ZkNodeProps props, NamedList results) throws Exception {\n    ensureNotClosed();\n    if (props.getStr(CommonAdminParams.ASYNC) != null) {\n      results.add(CoreAdminParams.REQUESTID, props.getStr(CommonAdminParams.ASYNC));\n    }\n    boolean waitForFinalState = props.getBool(CommonAdminParams.WAIT_FOR_FINAL_STATE, false);\n    final String collectionName = props.getStr(NAME);\n    log.debug(\"-- simCreateCollection {}, currentVersion={}\", collectionName, clusterStateVersion);\n\n    String router = props.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n    String policy = props.getStr(Policy.POLICY);\n    AutoScalingConfig autoScalingConfig = cloudManager.getDistribStateManager().getAutoScalingConfig();\n    boolean usePolicyFramework = !autoScalingConfig.getPolicy().getClusterPolicy().isEmpty() || policy != null;\n\n    // fail fast if parameters are wrong or incomplete\n    List<String> shardNames = CreateCollectionCmd.populateShardNames(props, router);\n    int maxShardsPerNode = props.getInt(MAX_SHARDS_PER_NODE, 1);\n    if (maxShardsPerNode == -1) maxShardsPerNode = Integer.MAX_VALUE;\n    CreateCollectionCmd.checkReplicaTypes(props);\n\n    // always force getting fresh state\n    lock.lockInterruptibly();\n    try {\n      collectionsStatesRef.set(null);\n    } finally {\n      lock.unlock();\n    }\n    final ClusterState clusterState = getClusterState();\n\n    String withCollection = props.getStr(CollectionAdminParams.WITH_COLLECTION);\n    String wcShard = null;\n    if (withCollection != null) {\n      if (!clusterState.hasCollection(withCollection)) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"The 'withCollection' does not exist: \" + withCollection);\n      } else  {\n        DocCollection collection = clusterState.getCollection(withCollection);\n        if (collection.getActiveSlices().size() > 1)  {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"The `withCollection` must have only one shard, found: \" + collection.getActiveSlices().size());\n        }\n        wcShard = collection.getActiveSlices().iterator().next().getName();\n      }\n    }\n    final String withCollectionShard = wcShard;\n\n    ZkWriteCommand cmd = ZkWriteCommand.noop();\n    \n    lock.lockInterruptibly();\n    try {\n      cmd = new ClusterStateMutator(cloudManager).createCollection(clusterState, props);\n      if (cmd.noop) {\n        log.warn(\"Collection {} already exists. exit\", collectionName);\n        log.debug(\"-- collection: {}, clusterState: {}\", collectionName, clusterState);\n        results.add(\"success\", \"no-op\");\n        return;\n      }\n      // add collection props\n      DocCollection coll = cmd.collection;\n      collProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>()).putAll(coll.getProperties());\n      colShardReplicaMap.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>());\n      // add slice props\n      coll.getSlices().forEach(s -> {\n        Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(coll.getName(), c -> new ConcurrentHashMap<>())\n            .computeIfAbsent(s.getName(), slice -> new ConcurrentHashMap<>());\n        s.getProperties().forEach((k, v) -> {\n          if (k != null && v != null) {\n            sliceProps.put(k, v);\n          }\n        });\n        colShardReplicaMap.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n            .computeIfAbsent(s.getName(), sh -> new ArrayList<>());\n      });\n\n      // modify the `withCollection` and store this new collection's name with it\n      if (withCollection != null) {\n        ZkNodeProps message = new ZkNodeProps(\n            Overseer.QUEUE_OPERATION, MODIFYCOLLECTION.toString(),\n            ZkStateReader.COLLECTION_PROP, withCollection,\n            CollectionAdminParams.COLOCATED_WITH, collectionName);\n        cmd = new CollectionMutator(cloudManager).modifyCollection(clusterState,message);\n      }\n      // force recreation of collection states\n      collectionsStatesRef.set(null);\n\n    } finally {\n      lock.unlock();\n    }\n    opDelays.computeIfAbsent(collectionName, c -> new HashMap<>()).putAll(defaultOpDelays);\n\n    opDelay(collectionName, CollectionParams.CollectionAction.CREATE.name());\n\n    AtomicReference<PolicyHelper.SessionWrapper> sessionWrapper = new AtomicReference<>();\n    List<ReplicaPosition> replicaPositions = CreateCollectionCmd.buildReplicaPositions(cloudManager, getClusterState(), cmd.collection, props,\n        shardNames, sessionWrapper);\n    if (sessionWrapper.get() != null) {\n      sessionWrapper.get().release();\n    }\n    // calculate expected number of positions\n    int numTlogReplicas = props.getInt(TLOG_REPLICAS, 0);\n    int numNrtReplicas = props.getInt(NRT_REPLICAS, props.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n    int numPullReplicas = props.getInt(PULL_REPLICAS, 0);\n    int totalReplicas = shardNames.size() * (numNrtReplicas + numPullReplicas + numTlogReplicas);\n    if (totalReplicas != replicaPositions.size()) {\n      throw new RuntimeException(\"unexpected number of replica positions: expected \" + totalReplicas + \" but got \" + replicaPositions.size());\n    }\n    final CountDownLatch finalStateLatch = new CountDownLatch(replicaPositions.size());\n    AtomicInteger replicaNum = new AtomicInteger(1);\n    replicaPositions.forEach(pos -> {\n\n      if (withCollection != null) {\n        // check that we have a replica of `withCollection` on this node and if not, create one\n        DocCollection collection = clusterState.getCollection(withCollection);\n        List<Replica> replicas = collection.getReplicas(pos.node);\n        if (replicas == null || replicas.isEmpty()) {\n          Map<String, Object> replicaProps = new HashMap<>();\n          replicaProps.put(ZkStateReader.NODE_NAME_PROP, pos.node);\n          replicaProps.put(ZkStateReader.REPLICA_TYPE, pos.type.toString());\n          String coreName = String.format(Locale.ROOT, \"%s_%s_replica_%s%s\", withCollection, withCollectionShard, pos.type.name().substring(0,1).toLowerCase(Locale.ROOT),\n              collection.getReplicas().size() + 1);\n          try {\n            replicaProps.put(ZkStateReader.CORE_NAME_PROP, coreName);\n            replicaProps.put(\"SEARCHER.searcher.deletedDocs\", new AtomicLong(0));\n            replicaProps.put(\"SEARCHER.searcher.numDocs\", new AtomicLong(0));\n            replicaProps.put(\"SEARCHER.searcher.maxDoc\", new AtomicLong(0));\n            ReplicaInfo ri = new ReplicaInfo(\"core_node\" + Assign.incAndGetId(stateManager, withCollection, 0),\n                coreName, withCollection, withCollectionShard, pos.type, pos.node, replicaProps);\n            cloudManager.submit(() -> {\n              simAddReplica(pos.node, ri, false);\n              // do not count down the latch here\n              return true;\n            });\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      }\n\n      Map<String, Object> replicaProps = new HashMap<>();\n      replicaProps.put(ZkStateReader.NODE_NAME_PROP, pos.node);\n      replicaProps.put(ZkStateReader.REPLICA_TYPE, pos.type.toString());\n      String coreName = String.format(Locale.ROOT, \"%s_%s_replica_%s%s\", collectionName, pos.shard, pos.type.name().substring(0,1).toLowerCase(Locale.ROOT),\n          replicaNum.getAndIncrement());\n      try {\n        replicaProps.put(ZkStateReader.CORE_NAME_PROP, coreName);\n        replicaProps.put(\"SEARCHER.searcher.deletedDocs\", new AtomicLong(0));\n        replicaProps.put(\"SEARCHER.searcher.numDocs\", new AtomicLong(0));\n        replicaProps.put(\"SEARCHER.searcher.maxDoc\", new AtomicLong(0));\n        ReplicaInfo ri = new ReplicaInfo(\"core_node\" + Assign.incAndGetId(stateManager, collectionName, 0),\n            coreName, collectionName, pos.shard, pos.type, pos.node, replicaProps);\n        cloudManager.submit(() -> {\n          simAddReplica(pos.node, ri, true);\n          finalStateLatch.countDown();\n          return true;\n        });\n      } catch (Exception e) {\n        throw new RuntimeException(e);\n      }\n    });\n\n    // force recreation of collection states\n    lock.lockInterruptibly();\n    try {\n      collectionsStatesRef.set(null);\n    } finally {\n      lock.unlock();\n    }\n    //simRunLeaderElection(Collections.singleton(collectionName), true);\n    if (waitForFinalState) {\n      boolean finished = finalStateLatch.await(cloudManager.getTimeSource().convertDelay(TimeUnit.SECONDS, 60, TimeUnit.MILLISECONDS),\n          TimeUnit.MILLISECONDS);\n      if (!finished) {\n        results.add(\"failure\", \"Timeout waiting for all replicas to become active.\");\n        return;\n      }\n    }\n    results.add(\"success\", \"\");\n    log.debug(\"-- finished createCollection {}, currentVersion={}\", collectionName, clusterStateVersion);\n  }\n\n","sourceOld":"  /**\n   * Create a new collection. This operation uses policy framework for node and replica assignments.\n   * @param props collection details\n   * @param results results of the operation.\n   */\n  public void simCreateCollection(ZkNodeProps props, NamedList results) throws Exception {\n    ensureNotClosed();\n    if (props.getStr(CommonAdminParams.ASYNC) != null) {\n      results.add(CoreAdminParams.REQUESTID, props.getStr(CommonAdminParams.ASYNC));\n    }\n    boolean waitForFinalState = props.getBool(CommonAdminParams.WAIT_FOR_FINAL_STATE, false);\n    final String collectionName = props.getStr(NAME);\n    log.debug(\"-- simCreateCollection {}, currentVersion={}\", collectionName, clusterStateVersion);\n\n    String router = props.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n    String policy = props.getStr(Policy.POLICY);\n    AutoScalingConfig autoScalingConfig = cloudManager.getDistribStateManager().getAutoScalingConfig();\n    boolean usePolicyFramework = !autoScalingConfig.getPolicy().getClusterPolicy().isEmpty() || policy != null;\n\n    // fail fast if parameters are wrong or incomplete\n    List<String> shardNames = CreateCollectionCmd.populateShardNames(props, router);\n    int maxShardsPerNode = props.getInt(MAX_SHARDS_PER_NODE, 1);\n    if (maxShardsPerNode == -1) maxShardsPerNode = Integer.MAX_VALUE;\n    CreateCollectionCmd.checkReplicaTypes(props);\n\n    // always force getting fresh state\n    lock.lockInterruptibly();\n    try {\n      collectionsStatesRef.set(null);\n    } finally {\n      lock.unlock();\n    }\n    final ClusterState clusterState = getClusterState();\n\n    String withCollection = props.getStr(CollectionAdminParams.WITH_COLLECTION);\n    String wcShard = null;\n    if (withCollection != null) {\n      if (!clusterState.hasCollection(withCollection)) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"The 'withCollection' does not exist: \" + withCollection);\n      } else  {\n        DocCollection collection = clusterState.getCollection(withCollection);\n        if (collection.getActiveSlices().size() > 1)  {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"The `withCollection` must have only one shard, found: \" + collection.getActiveSlices().size());\n        }\n        wcShard = collection.getActiveSlices().iterator().next().getName();\n      }\n    }\n    final String withCollectionShard = wcShard;\n\n    ZkWriteCommand cmd = ZkWriteCommand.noop();\n    \n    lock.lockInterruptibly();\n    try {\n      cmd = new ClusterStateMutator(cloudManager).createCollection(clusterState, props);\n      if (cmd.noop) {\n        log.warn(\"Collection {} already exists. exit\", collectionName);\n        log.debug(\"-- collection: {}, clusterState: {}\", collectionName, clusterState);\n        results.add(\"success\", \"no-op\");\n        return;\n      }\n      // add collection props\n      DocCollection coll = cmd.collection;\n      collProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>()).putAll(coll.getProperties());\n      colShardReplicaMap.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>());\n      // add slice props\n      coll.getSlices().forEach(s -> {\n        Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(coll.getName(), c -> new ConcurrentHashMap<>())\n            .computeIfAbsent(s.getName(), slice -> new ConcurrentHashMap<>());\n        s.getProperties().forEach((k, v) -> {\n          if (k != null && v != null) {\n            sliceProps.put(k, v);\n          }\n        });\n        colShardReplicaMap.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n            .computeIfAbsent(s.getName(), sh -> new ArrayList<>());\n      });\n\n      // modify the `withCollection` and store this new collection's name with it\n      if (withCollection != null) {\n        ZkNodeProps message = new ZkNodeProps(\n            Overseer.QUEUE_OPERATION, MODIFYCOLLECTION.toString(),\n            ZkStateReader.COLLECTION_PROP, withCollection,\n            CollectionAdminParams.COLOCATED_WITH, collectionName);\n        cmd = new CollectionMutator(cloudManager).modifyCollection(clusterState,message);\n      }\n      // force recreation of collection states\n      collectionsStatesRef.set(null);\n\n    } finally {\n      lock.unlock();\n    }\n    opDelays.computeIfAbsent(collectionName, c -> new HashMap<>()).putAll(defaultOpDelays);\n\n    opDelay(collectionName, CollectionParams.CollectionAction.CREATE.name());\n\n    AtomicReference<PolicyHelper.SessionWrapper> sessionWrapper = new AtomicReference<>();\n    List<ReplicaPosition> replicaPositions = CreateCollectionCmd.buildReplicaPositions(cloudManager, getClusterState(), cmd.collection, props,\n        shardNames, sessionWrapper);\n    if (sessionWrapper.get() != null) {\n      sessionWrapper.get().release();\n    }\n    // calculate expected number of positions\n    int numTlogReplicas = props.getInt(TLOG_REPLICAS, 0);\n    int numNrtReplicas = props.getInt(NRT_REPLICAS, props.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n    int numPullReplicas = props.getInt(PULL_REPLICAS, 0);\n    int totalReplicas = shardNames.size() * (numNrtReplicas + numPullReplicas + numTlogReplicas);\n    Assert.assertEquals(\"unexpected number of replica positions\", totalReplicas, replicaPositions.size());\n    final CountDownLatch finalStateLatch = new CountDownLatch(replicaPositions.size());\n    AtomicInteger replicaNum = new AtomicInteger(1);\n    replicaPositions.forEach(pos -> {\n\n      if (withCollection != null) {\n        // check that we have a replica of `withCollection` on this node and if not, create one\n        DocCollection collection = clusterState.getCollection(withCollection);\n        List<Replica> replicas = collection.getReplicas(pos.node);\n        if (replicas == null || replicas.isEmpty()) {\n          Map<String, Object> replicaProps = new HashMap<>();\n          replicaProps.put(ZkStateReader.NODE_NAME_PROP, pos.node);\n          replicaProps.put(ZkStateReader.REPLICA_TYPE, pos.type.toString());\n          String coreName = String.format(Locale.ROOT, \"%s_%s_replica_%s%s\", withCollection, withCollectionShard, pos.type.name().substring(0,1).toLowerCase(Locale.ROOT),\n              collection.getReplicas().size() + 1);\n          try {\n            replicaProps.put(ZkStateReader.CORE_NAME_PROP, coreName);\n            replicaProps.put(\"SEARCHER.searcher.deletedDocs\", new AtomicLong(0));\n            replicaProps.put(\"SEARCHER.searcher.numDocs\", new AtomicLong(0));\n            replicaProps.put(\"SEARCHER.searcher.maxDoc\", new AtomicLong(0));\n            ReplicaInfo ri = new ReplicaInfo(\"core_node\" + Assign.incAndGetId(stateManager, withCollection, 0),\n                coreName, withCollection, withCollectionShard, pos.type, pos.node, replicaProps);\n            cloudManager.submit(() -> {\n              simAddReplica(pos.node, ri, false);\n              // do not count down the latch here\n              return true;\n            });\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      }\n\n      Map<String, Object> replicaProps = new HashMap<>();\n      replicaProps.put(ZkStateReader.NODE_NAME_PROP, pos.node);\n      replicaProps.put(ZkStateReader.REPLICA_TYPE, pos.type.toString());\n      String coreName = String.format(Locale.ROOT, \"%s_%s_replica_%s%s\", collectionName, pos.shard, pos.type.name().substring(0,1).toLowerCase(Locale.ROOT),\n          replicaNum.getAndIncrement());\n      try {\n        replicaProps.put(ZkStateReader.CORE_NAME_PROP, coreName);\n        replicaProps.put(\"SEARCHER.searcher.deletedDocs\", new AtomicLong(0));\n        replicaProps.put(\"SEARCHER.searcher.numDocs\", new AtomicLong(0));\n        replicaProps.put(\"SEARCHER.searcher.maxDoc\", new AtomicLong(0));\n        ReplicaInfo ri = new ReplicaInfo(\"core_node\" + Assign.incAndGetId(stateManager, collectionName, 0),\n            coreName, collectionName, pos.shard, pos.type, pos.node, replicaProps);\n        cloudManager.submit(() -> {\n          simAddReplica(pos.node, ri, true);\n          finalStateLatch.countDown();\n          return true;\n        });\n      } catch (Exception e) {\n        throw new RuntimeException(e);\n      }\n    });\n\n    // force recreation of collection states\n    lock.lockInterruptibly();\n    try {\n      collectionsStatesRef.set(null);\n    } finally {\n      lock.unlock();\n    }\n    //simRunLeaderElection(Collections.singleton(collectionName), true);\n    if (waitForFinalState) {\n      boolean finished = finalStateLatch.await(cloudManager.getTimeSource().convertDelay(TimeUnit.SECONDS, 60, TimeUnit.MILLISECONDS),\n          TimeUnit.MILLISECONDS);\n      if (!finished) {\n        results.add(\"failure\", \"Timeout waiting for all replicas to become active.\");\n        return;\n      }\n    }\n    results.add(\"success\", \"\");\n    log.debug(\"-- finished createCollection {}, currentVersion={}\", collectionName, clusterStateVersion);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"eb7a329be123e1f46f9d78d74f6d23f33ec81b0a","date":1589907167,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simCreateCollection(ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simCreateCollection(ZkNodeProps,NamedList).mjava","sourceNew":"  /**\n   * Create a new collection. This operation uses policy framework for node and replica assignments.\n   * @param props collection details\n   * @param results results of the operation.\n   */\n  public void simCreateCollection(ZkNodeProps props, NamedList results) throws Exception {\n    ensureNotClosed();\n    if (props.getStr(CommonAdminParams.ASYNC) != null) {\n      results.add(CoreAdminParams.REQUESTID, props.getStr(CommonAdminParams.ASYNC));\n    }\n    boolean waitForFinalState = props.getBool(CommonAdminParams.WAIT_FOR_FINAL_STATE, false);\n    final String collectionName = props.getStr(NAME);\n    log.debug(\"-- simCreateCollection {}\", collectionName);\n\n    String router = props.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n    String policy = props.getStr(Policy.POLICY);\n    AutoScalingConfig autoScalingConfig = cloudManager.getDistribStateManager().getAutoScalingConfig();\n    boolean usePolicyFramework = !autoScalingConfig.getPolicy().getClusterPolicy().isEmpty() || policy != null;\n\n    // fail fast if parameters are wrong or incomplete\n    List<String> shardNames = CreateCollectionCmd.populateShardNames(props, router);\n    int maxShardsPerNode = props.getInt(MAX_SHARDS_PER_NODE, 1);\n    if (maxShardsPerNode == -1) maxShardsPerNode = Integer.MAX_VALUE;\n    CreateCollectionCmd.checkReplicaTypes(props);\n\n    // always force getting fresh state\n    final ClusterState clusterState = getClusterState();\n\n    String withCollection = props.getStr(CollectionAdminParams.WITH_COLLECTION);\n    String wcShard = null;\n    if (withCollection != null) {\n      if (!clusterState.hasCollection(withCollection)) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"The 'withCollection' does not exist: \" + withCollection);\n      } else  {\n        DocCollection collection = clusterState.getCollection(withCollection);\n        if (collection.getActiveSlices().size() > 1)  {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"The `withCollection` must have only one shard, found: \" + collection.getActiveSlices().size());\n        }\n        wcShard = collection.getActiveSlices().iterator().next().getName();\n      }\n    }\n    final String withCollectionShard = wcShard;\n\n    ZkWriteCommand cmd = ZkWriteCommand.noop();\n    \n    lock.lockInterruptibly();\n    try {\n      cmd = new ClusterStateMutator(cloudManager).createCollection(clusterState, props);\n      if (cmd.noop) {\n        log.warn(\"Collection {} already exists. exit\", collectionName);\n        log.debug(\"-- collection: {}, clusterState: {}\", collectionName, clusterState);\n        results.add(\"success\", \"no-op\");\n        return;\n      }\n      // add collection props\n      DocCollection coll = cmd.collection;\n      collProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>()).putAll(coll.getProperties());\n      colShardReplicaMap.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>());\n      // add slice props\n      coll.getSlices().forEach(s -> {\n        Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(coll.getName(), c -> new ConcurrentHashMap<>())\n            .computeIfAbsent(s.getName(), slice -> new ConcurrentHashMap<>());\n        s.getProperties().forEach((k, v) -> {\n          if (k != null && v != null) {\n            sliceProps.put(k, v);\n          }\n        });\n        colShardReplicaMap.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n            .computeIfAbsent(s.getName(), sh -> new ArrayList<>());\n      });\n\n      // modify the `withCollection` and store this new collection's name with it\n      if (withCollection != null) {\n        ZkNodeProps message = new ZkNodeProps(\n            Overseer.QUEUE_OPERATION, MODIFYCOLLECTION.toString(),\n            ZkStateReader.COLLECTION_PROP, withCollection,\n            CollectionAdminParams.COLOCATED_WITH, collectionName);\n        cmd = new CollectionMutator(cloudManager).modifyCollection(clusterState,message);\n      }\n      collectionsStatesRef.put(collectionName, new CachedCollectionRef(collectionName, 0));\n\n    } finally {\n      lock.unlock();\n    }\n    opDelays.computeIfAbsent(collectionName, c -> new HashMap<>()).putAll(defaultOpDelays);\n\n    opDelay(collectionName, CollectionParams.CollectionAction.CREATE.name());\n\n    AtomicReference<PolicyHelper.SessionWrapper> sessionWrapper = new AtomicReference<>();\n    List<ReplicaPosition> replicaPositions = CreateCollectionCmd.buildReplicaPositions(cloudManager, getClusterState(), cmd.collection, props,\n        shardNames, sessionWrapper);\n    if (sessionWrapper.get() != null) {\n      sessionWrapper.get().release();\n    }\n    // calculate expected number of positions\n    int numTlogReplicas = props.getInt(TLOG_REPLICAS, 0);\n    int numNrtReplicas = props.getInt(NRT_REPLICAS, props.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n    int numPullReplicas = props.getInt(PULL_REPLICAS, 0);\n    int totalReplicas = shardNames.size() * (numNrtReplicas + numPullReplicas + numTlogReplicas);\n    if (totalReplicas != replicaPositions.size()) {\n      throw new RuntimeException(\"unexpected number of replica positions: expected \" + totalReplicas + \" but got \" + replicaPositions.size());\n    }\n    final CountDownLatch finalStateLatch = new CountDownLatch(replicaPositions.size());\n    AtomicInteger replicaNum = new AtomicInteger(1);\n    replicaPositions.forEach(pos -> {\n\n      if (withCollection != null) {\n        // check that we have a replica of `withCollection` on this node and if not, create one\n        DocCollection collection = clusterState.getCollection(withCollection);\n        List<Replica> replicas = collection.getReplicas(pos.node);\n        if (replicas == null || replicas.isEmpty()) {\n          Map<String, Object> replicaProps = new HashMap<>();\n          replicaProps.put(ZkStateReader.NODE_NAME_PROP, pos.node);\n          replicaProps.put(ZkStateReader.REPLICA_TYPE, pos.type.toString());\n          String coreName = String.format(Locale.ROOT, \"%s_%s_replica_%s%s\", withCollection, withCollectionShard, pos.type.name().substring(0,1).toLowerCase(Locale.ROOT),\n              collection.getReplicas().size() + 1);\n          try {\n            replicaProps.put(ZkStateReader.CORE_NAME_PROP, coreName);\n            replicaProps.put(\"SEARCHER.searcher.deletedDocs\", new AtomicLong(0));\n            replicaProps.put(\"SEARCHER.searcher.numDocs\", new AtomicLong(0));\n            replicaProps.put(\"SEARCHER.searcher.maxDoc\", new AtomicLong(0));\n            ReplicaInfo ri = new ReplicaInfo(\"core_node\" + Assign.incAndGetId(stateManager, withCollection, 0),\n                coreName, withCollection, withCollectionShard, pos.type, pos.node, replicaProps);\n            cloudManager.submit(() -> {\n              simAddReplica(pos.node, ri, false);\n              // do not count down the latch here\n              return true;\n            });\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      }\n\n      Map<String, Object> replicaProps = new HashMap<>();\n      replicaProps.put(ZkStateReader.NODE_NAME_PROP, pos.node);\n      replicaProps.put(ZkStateReader.REPLICA_TYPE, pos.type.toString());\n      String coreName = String.format(Locale.ROOT, \"%s_%s_replica_%s%s\", collectionName, pos.shard, pos.type.name().substring(0,1).toLowerCase(Locale.ROOT),\n          replicaNum.getAndIncrement());\n      try {\n        replicaProps.put(ZkStateReader.CORE_NAME_PROP, coreName);\n        replicaProps.put(\"SEARCHER.searcher.deletedDocs\", new AtomicLong(0));\n        replicaProps.put(\"SEARCHER.searcher.numDocs\", new AtomicLong(0));\n        replicaProps.put(\"SEARCHER.searcher.maxDoc\", new AtomicLong(0));\n        ReplicaInfo ri = new ReplicaInfo(\"core_node\" + Assign.incAndGetId(stateManager, collectionName, 0),\n            coreName, collectionName, pos.shard, pos.type, pos.node, replicaProps);\n        cloudManager.submit(() -> {\n          simAddReplica(pos.node, ri, true);\n          finalStateLatch.countDown();\n          return true;\n        });\n      } catch (Exception e) {\n        throw new RuntimeException(e);\n      }\n    });\n\n    // force recreation of collection states\n    lock.lockInterruptibly();\n    try {\n      collectionsStatesRef.get(collectionName).invalidate();\n    } finally {\n      lock.unlock();\n    }\n    //simRunLeaderElection(Collections.singleton(collectionName), true);\n    if (waitForFinalState) {\n      boolean finished = finalStateLatch.await(cloudManager.getTimeSource().convertDelay(TimeUnit.SECONDS, 60, TimeUnit.MILLISECONDS),\n          TimeUnit.MILLISECONDS);\n      if (!finished) {\n        results.add(\"failure\", \"Timeout waiting for all replicas to become active.\");\n        return;\n      }\n    }\n    results.add(\"success\", \"\");\n    log.debug(\"-- finished createCollection {}\", collectionName);\n  }\n\n","sourceOld":"  /**\n   * Create a new collection. This operation uses policy framework for node and replica assignments.\n   * @param props collection details\n   * @param results results of the operation.\n   */\n  public void simCreateCollection(ZkNodeProps props, NamedList results) throws Exception {\n    ensureNotClosed();\n    if (props.getStr(CommonAdminParams.ASYNC) != null) {\n      results.add(CoreAdminParams.REQUESTID, props.getStr(CommonAdminParams.ASYNC));\n    }\n    boolean waitForFinalState = props.getBool(CommonAdminParams.WAIT_FOR_FINAL_STATE, false);\n    final String collectionName = props.getStr(NAME);\n    log.debug(\"-- simCreateCollection {}, currentVersion={}\", collectionName, clusterStateVersion);\n\n    String router = props.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n    String policy = props.getStr(Policy.POLICY);\n    AutoScalingConfig autoScalingConfig = cloudManager.getDistribStateManager().getAutoScalingConfig();\n    boolean usePolicyFramework = !autoScalingConfig.getPolicy().getClusterPolicy().isEmpty() || policy != null;\n\n    // fail fast if parameters are wrong or incomplete\n    List<String> shardNames = CreateCollectionCmd.populateShardNames(props, router);\n    int maxShardsPerNode = props.getInt(MAX_SHARDS_PER_NODE, 1);\n    if (maxShardsPerNode == -1) maxShardsPerNode = Integer.MAX_VALUE;\n    CreateCollectionCmd.checkReplicaTypes(props);\n\n    // always force getting fresh state\n    lock.lockInterruptibly();\n    try {\n      collectionsStatesRef.set(null);\n    } finally {\n      lock.unlock();\n    }\n    final ClusterState clusterState = getClusterState();\n\n    String withCollection = props.getStr(CollectionAdminParams.WITH_COLLECTION);\n    String wcShard = null;\n    if (withCollection != null) {\n      if (!clusterState.hasCollection(withCollection)) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"The 'withCollection' does not exist: \" + withCollection);\n      } else  {\n        DocCollection collection = clusterState.getCollection(withCollection);\n        if (collection.getActiveSlices().size() > 1)  {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"The `withCollection` must have only one shard, found: \" + collection.getActiveSlices().size());\n        }\n        wcShard = collection.getActiveSlices().iterator().next().getName();\n      }\n    }\n    final String withCollectionShard = wcShard;\n\n    ZkWriteCommand cmd = ZkWriteCommand.noop();\n    \n    lock.lockInterruptibly();\n    try {\n      cmd = new ClusterStateMutator(cloudManager).createCollection(clusterState, props);\n      if (cmd.noop) {\n        log.warn(\"Collection {} already exists. exit\", collectionName);\n        log.debug(\"-- collection: {}, clusterState: {}\", collectionName, clusterState);\n        results.add(\"success\", \"no-op\");\n        return;\n      }\n      // add collection props\n      DocCollection coll = cmd.collection;\n      collProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>()).putAll(coll.getProperties());\n      colShardReplicaMap.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>());\n      // add slice props\n      coll.getSlices().forEach(s -> {\n        Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(coll.getName(), c -> new ConcurrentHashMap<>())\n            .computeIfAbsent(s.getName(), slice -> new ConcurrentHashMap<>());\n        s.getProperties().forEach((k, v) -> {\n          if (k != null && v != null) {\n            sliceProps.put(k, v);\n          }\n        });\n        colShardReplicaMap.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n            .computeIfAbsent(s.getName(), sh -> new ArrayList<>());\n      });\n\n      // modify the `withCollection` and store this new collection's name with it\n      if (withCollection != null) {\n        ZkNodeProps message = new ZkNodeProps(\n            Overseer.QUEUE_OPERATION, MODIFYCOLLECTION.toString(),\n            ZkStateReader.COLLECTION_PROP, withCollection,\n            CollectionAdminParams.COLOCATED_WITH, collectionName);\n        cmd = new CollectionMutator(cloudManager).modifyCollection(clusterState,message);\n      }\n      // force recreation of collection states\n      collectionsStatesRef.set(null);\n\n    } finally {\n      lock.unlock();\n    }\n    opDelays.computeIfAbsent(collectionName, c -> new HashMap<>()).putAll(defaultOpDelays);\n\n    opDelay(collectionName, CollectionParams.CollectionAction.CREATE.name());\n\n    AtomicReference<PolicyHelper.SessionWrapper> sessionWrapper = new AtomicReference<>();\n    List<ReplicaPosition> replicaPositions = CreateCollectionCmd.buildReplicaPositions(cloudManager, getClusterState(), cmd.collection, props,\n        shardNames, sessionWrapper);\n    if (sessionWrapper.get() != null) {\n      sessionWrapper.get().release();\n    }\n    // calculate expected number of positions\n    int numTlogReplicas = props.getInt(TLOG_REPLICAS, 0);\n    int numNrtReplicas = props.getInt(NRT_REPLICAS, props.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n    int numPullReplicas = props.getInt(PULL_REPLICAS, 0);\n    int totalReplicas = shardNames.size() * (numNrtReplicas + numPullReplicas + numTlogReplicas);\n    if (totalReplicas != replicaPositions.size()) {\n      throw new RuntimeException(\"unexpected number of replica positions: expected \" + totalReplicas + \" but got \" + replicaPositions.size());\n    }\n    final CountDownLatch finalStateLatch = new CountDownLatch(replicaPositions.size());\n    AtomicInteger replicaNum = new AtomicInteger(1);\n    replicaPositions.forEach(pos -> {\n\n      if (withCollection != null) {\n        // check that we have a replica of `withCollection` on this node and if not, create one\n        DocCollection collection = clusterState.getCollection(withCollection);\n        List<Replica> replicas = collection.getReplicas(pos.node);\n        if (replicas == null || replicas.isEmpty()) {\n          Map<String, Object> replicaProps = new HashMap<>();\n          replicaProps.put(ZkStateReader.NODE_NAME_PROP, pos.node);\n          replicaProps.put(ZkStateReader.REPLICA_TYPE, pos.type.toString());\n          String coreName = String.format(Locale.ROOT, \"%s_%s_replica_%s%s\", withCollection, withCollectionShard, pos.type.name().substring(0,1).toLowerCase(Locale.ROOT),\n              collection.getReplicas().size() + 1);\n          try {\n            replicaProps.put(ZkStateReader.CORE_NAME_PROP, coreName);\n            replicaProps.put(\"SEARCHER.searcher.deletedDocs\", new AtomicLong(0));\n            replicaProps.put(\"SEARCHER.searcher.numDocs\", new AtomicLong(0));\n            replicaProps.put(\"SEARCHER.searcher.maxDoc\", new AtomicLong(0));\n            ReplicaInfo ri = new ReplicaInfo(\"core_node\" + Assign.incAndGetId(stateManager, withCollection, 0),\n                coreName, withCollection, withCollectionShard, pos.type, pos.node, replicaProps);\n            cloudManager.submit(() -> {\n              simAddReplica(pos.node, ri, false);\n              // do not count down the latch here\n              return true;\n            });\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      }\n\n      Map<String, Object> replicaProps = new HashMap<>();\n      replicaProps.put(ZkStateReader.NODE_NAME_PROP, pos.node);\n      replicaProps.put(ZkStateReader.REPLICA_TYPE, pos.type.toString());\n      String coreName = String.format(Locale.ROOT, \"%s_%s_replica_%s%s\", collectionName, pos.shard, pos.type.name().substring(0,1).toLowerCase(Locale.ROOT),\n          replicaNum.getAndIncrement());\n      try {\n        replicaProps.put(ZkStateReader.CORE_NAME_PROP, coreName);\n        replicaProps.put(\"SEARCHER.searcher.deletedDocs\", new AtomicLong(0));\n        replicaProps.put(\"SEARCHER.searcher.numDocs\", new AtomicLong(0));\n        replicaProps.put(\"SEARCHER.searcher.maxDoc\", new AtomicLong(0));\n        ReplicaInfo ri = new ReplicaInfo(\"core_node\" + Assign.incAndGetId(stateManager, collectionName, 0),\n            coreName, collectionName, pos.shard, pos.type, pos.node, replicaProps);\n        cloudManager.submit(() -> {\n          simAddReplica(pos.node, ri, true);\n          finalStateLatch.countDown();\n          return true;\n        });\n      } catch (Exception e) {\n        throw new RuntimeException(e);\n      }\n    });\n\n    // force recreation of collection states\n    lock.lockInterruptibly();\n    try {\n      collectionsStatesRef.set(null);\n    } finally {\n      lock.unlock();\n    }\n    //simRunLeaderElection(Collections.singleton(collectionName), true);\n    if (waitForFinalState) {\n      boolean finished = finalStateLatch.await(cloudManager.getTimeSource().convertDelay(TimeUnit.SECONDS, 60, TimeUnit.MILLISECONDS),\n          TimeUnit.MILLISECONDS);\n      if (!finished) {\n        results.add(\"failure\", \"Timeout waiting for all replicas to become active.\");\n        return;\n      }\n    }\n    results.add(\"success\", \"\");\n    log.debug(\"-- finished createCollection {}, currentVersion={}\", collectionName, clusterStateVersion);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"daa0f21a44e235a2299ea1fa913898b182dd7cce","date":1590952026,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simCreateCollection(ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simCreateCollection(ZkNodeProps,NamedList).mjava","sourceNew":"  /**\n   * Create a new collection. This operation uses policy framework for node and replica assignments.\n   * @param props collection details\n   * @param results results of the operation.\n   */\n\n  @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n  public void simCreateCollection(ZkNodeProps props, NamedList results) throws Exception {\n    ensureNotClosed();\n    if (props.getStr(CommonAdminParams.ASYNC) != null) {\n      results.add(CoreAdminParams.REQUESTID, props.getStr(CommonAdminParams.ASYNC));\n    }\n    boolean waitForFinalState = props.getBool(CommonAdminParams.WAIT_FOR_FINAL_STATE, false);\n    final String collectionName = props.getStr(NAME);\n    log.debug(\"-- simCreateCollection {}\", collectionName);\n\n    String router = props.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n    String policy = props.getStr(Policy.POLICY);\n    AutoScalingConfig autoScalingConfig = cloudManager.getDistribStateManager().getAutoScalingConfig();\n    boolean usePolicyFramework = !autoScalingConfig.getPolicy().getClusterPolicy().isEmpty() || policy != null;\n\n    // fail fast if parameters are wrong or incomplete\n    List<String> shardNames = CreateCollectionCmd.populateShardNames(props, router);\n    int maxShardsPerNode = props.getInt(MAX_SHARDS_PER_NODE, 1);\n    if (maxShardsPerNode == -1) maxShardsPerNode = Integer.MAX_VALUE;\n    CreateCollectionCmd.checkReplicaTypes(props);\n\n    // always force getting fresh state\n    final ClusterState clusterState = getClusterState();\n\n    String withCollection = props.getStr(CollectionAdminParams.WITH_COLLECTION);\n    String wcShard = null;\n    if (withCollection != null) {\n      if (!clusterState.hasCollection(withCollection)) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"The 'withCollection' does not exist: \" + withCollection);\n      } else  {\n        DocCollection collection = clusterState.getCollection(withCollection);\n        if (collection.getActiveSlices().size() > 1)  {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"The `withCollection` must have only one shard, found: \" + collection.getActiveSlices().size());\n        }\n        wcShard = collection.getActiveSlices().iterator().next().getName();\n      }\n    }\n    final String withCollectionShard = wcShard;\n\n    ZkWriteCommand cmd = ZkWriteCommand.noop();\n    \n    lock.lockInterruptibly();\n    try {\n      cmd = new ClusterStateMutator(cloudManager).createCollection(clusterState, props);\n      if (cmd.noop) {\n        log.warn(\"Collection {} already exists. exit\", collectionName);\n        log.debug(\"-- collection: {}, clusterState: {}\", collectionName, clusterState);\n        results.add(\"success\", \"no-op\");\n        return;\n      }\n      // add collection props\n      DocCollection coll = cmd.collection;\n      collProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>()).putAll(coll.getProperties());\n      colShardReplicaMap.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>());\n      // add slice props\n      coll.getSlices().forEach(s -> {\n        Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(coll.getName(), c -> new ConcurrentHashMap<>())\n            .computeIfAbsent(s.getName(), slice -> new ConcurrentHashMap<>());\n        s.getProperties().forEach((k, v) -> {\n          if (k != null && v != null) {\n            sliceProps.put(k, v);\n          }\n        });\n        colShardReplicaMap.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n            .computeIfAbsent(s.getName(), sh -> new ArrayList<>());\n      });\n\n      // modify the `withCollection` and store this new collection's name with it\n      if (withCollection != null) {\n        ZkNodeProps message = new ZkNodeProps(\n            Overseer.QUEUE_OPERATION, MODIFYCOLLECTION.toString(),\n            ZkStateReader.COLLECTION_PROP, withCollection,\n            CollectionAdminParams.COLOCATED_WITH, collectionName);\n        cmd = new CollectionMutator(cloudManager).modifyCollection(clusterState,message);\n      }\n      collectionsStatesRef.put(collectionName, new CachedCollectionRef(collectionName, 0));\n\n    } finally {\n      lock.unlock();\n    }\n    opDelays.computeIfAbsent(collectionName, c -> new HashMap<>()).putAll(defaultOpDelays);\n\n    opDelay(collectionName, CollectionParams.CollectionAction.CREATE.name());\n\n    AtomicReference<PolicyHelper.SessionWrapper> sessionWrapper = new AtomicReference<>();\n    List<ReplicaPosition> replicaPositions = CreateCollectionCmd.buildReplicaPositions(cloudManager, getClusterState(), cmd.collection, props,\n        shardNames, sessionWrapper);\n    if (sessionWrapper.get() != null) {\n      sessionWrapper.get().release();\n    }\n    // calculate expected number of positions\n    int numTlogReplicas = props.getInt(TLOG_REPLICAS, 0);\n    int numNrtReplicas = props.getInt(NRT_REPLICAS, props.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n    int numPullReplicas = props.getInt(PULL_REPLICAS, 0);\n    int totalReplicas = shardNames.size() * (numNrtReplicas + numPullReplicas + numTlogReplicas);\n    if (totalReplicas != replicaPositions.size()) {\n      throw new RuntimeException(\"unexpected number of replica positions: expected \" + totalReplicas + \" but got \" + replicaPositions.size());\n    }\n    final CountDownLatch finalStateLatch = new CountDownLatch(replicaPositions.size());\n    AtomicInteger replicaNum = new AtomicInteger(1);\n    replicaPositions.forEach(pos -> {\n\n      if (withCollection != null) {\n        // check that we have a replica of `withCollection` on this node and if not, create one\n        DocCollection collection = clusterState.getCollection(withCollection);\n        List<Replica> replicas = collection.getReplicas(pos.node);\n        if (replicas == null || replicas.isEmpty()) {\n          Map<String, Object> replicaProps = new HashMap<>();\n          replicaProps.put(ZkStateReader.NODE_NAME_PROP, pos.node);\n          replicaProps.put(ZkStateReader.REPLICA_TYPE, pos.type.toString());\n          String coreName = String.format(Locale.ROOT, \"%s_%s_replica_%s%s\", withCollection, withCollectionShard, pos.type.name().substring(0,1).toLowerCase(Locale.ROOT),\n              collection.getReplicas().size() + 1);\n          try {\n            replicaProps.put(ZkStateReader.CORE_NAME_PROP, coreName);\n            replicaProps.put(\"SEARCHER.searcher.deletedDocs\", new AtomicLong(0));\n            replicaProps.put(\"SEARCHER.searcher.numDocs\", new AtomicLong(0));\n            replicaProps.put(\"SEARCHER.searcher.maxDoc\", new AtomicLong(0));\n            ReplicaInfo ri = new ReplicaInfo(\"core_node\" + Assign.incAndGetId(stateManager, withCollection, 0),\n                coreName, withCollection, withCollectionShard, pos.type, pos.node, replicaProps);\n            cloudManager.submit(() -> {\n              simAddReplica(pos.node, ri, false);\n              // do not count down the latch here\n              return true;\n            });\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      }\n\n      Map<String, Object> replicaProps = new HashMap<>();\n      replicaProps.put(ZkStateReader.NODE_NAME_PROP, pos.node);\n      replicaProps.put(ZkStateReader.REPLICA_TYPE, pos.type.toString());\n      String coreName = String.format(Locale.ROOT, \"%s_%s_replica_%s%s\", collectionName, pos.shard, pos.type.name().substring(0,1).toLowerCase(Locale.ROOT),\n          replicaNum.getAndIncrement());\n      try {\n        replicaProps.put(ZkStateReader.CORE_NAME_PROP, coreName);\n        replicaProps.put(\"SEARCHER.searcher.deletedDocs\", new AtomicLong(0));\n        replicaProps.put(\"SEARCHER.searcher.numDocs\", new AtomicLong(0));\n        replicaProps.put(\"SEARCHER.searcher.maxDoc\", new AtomicLong(0));\n        ReplicaInfo ri = new ReplicaInfo(\"core_node\" + Assign.incAndGetId(stateManager, collectionName, 0),\n            coreName, collectionName, pos.shard, pos.type, pos.node, replicaProps);\n        cloudManager.submit(() -> {\n          simAddReplica(pos.node, ri, true);\n          finalStateLatch.countDown();\n          return true;\n        });\n      } catch (Exception e) {\n        throw new RuntimeException(e);\n      }\n    });\n\n    // force recreation of collection states\n    lock.lockInterruptibly();\n    try {\n      collectionsStatesRef.get(collectionName).invalidate();\n    } finally {\n      lock.unlock();\n    }\n    //simRunLeaderElection(Collections.singleton(collectionName), true);\n    if (waitForFinalState) {\n      boolean finished = finalStateLatch.await(cloudManager.getTimeSource().convertDelay(TimeUnit.SECONDS, 60, TimeUnit.MILLISECONDS),\n          TimeUnit.MILLISECONDS);\n      if (!finished) {\n        results.add(\"failure\", \"Timeout waiting for all replicas to become active.\");\n        return;\n      }\n    }\n    results.add(\"success\", \"\");\n    log.debug(\"-- finished createCollection {}\", collectionName);\n  }\n\n","sourceOld":"  /**\n   * Create a new collection. This operation uses policy framework for node and replica assignments.\n   * @param props collection details\n   * @param results results of the operation.\n   */\n  public void simCreateCollection(ZkNodeProps props, NamedList results) throws Exception {\n    ensureNotClosed();\n    if (props.getStr(CommonAdminParams.ASYNC) != null) {\n      results.add(CoreAdminParams.REQUESTID, props.getStr(CommonAdminParams.ASYNC));\n    }\n    boolean waitForFinalState = props.getBool(CommonAdminParams.WAIT_FOR_FINAL_STATE, false);\n    final String collectionName = props.getStr(NAME);\n    log.debug(\"-- simCreateCollection {}\", collectionName);\n\n    String router = props.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n    String policy = props.getStr(Policy.POLICY);\n    AutoScalingConfig autoScalingConfig = cloudManager.getDistribStateManager().getAutoScalingConfig();\n    boolean usePolicyFramework = !autoScalingConfig.getPolicy().getClusterPolicy().isEmpty() || policy != null;\n\n    // fail fast if parameters are wrong or incomplete\n    List<String> shardNames = CreateCollectionCmd.populateShardNames(props, router);\n    int maxShardsPerNode = props.getInt(MAX_SHARDS_PER_NODE, 1);\n    if (maxShardsPerNode == -1) maxShardsPerNode = Integer.MAX_VALUE;\n    CreateCollectionCmd.checkReplicaTypes(props);\n\n    // always force getting fresh state\n    final ClusterState clusterState = getClusterState();\n\n    String withCollection = props.getStr(CollectionAdminParams.WITH_COLLECTION);\n    String wcShard = null;\n    if (withCollection != null) {\n      if (!clusterState.hasCollection(withCollection)) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"The 'withCollection' does not exist: \" + withCollection);\n      } else  {\n        DocCollection collection = clusterState.getCollection(withCollection);\n        if (collection.getActiveSlices().size() > 1)  {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"The `withCollection` must have only one shard, found: \" + collection.getActiveSlices().size());\n        }\n        wcShard = collection.getActiveSlices().iterator().next().getName();\n      }\n    }\n    final String withCollectionShard = wcShard;\n\n    ZkWriteCommand cmd = ZkWriteCommand.noop();\n    \n    lock.lockInterruptibly();\n    try {\n      cmd = new ClusterStateMutator(cloudManager).createCollection(clusterState, props);\n      if (cmd.noop) {\n        log.warn(\"Collection {} already exists. exit\", collectionName);\n        log.debug(\"-- collection: {}, clusterState: {}\", collectionName, clusterState);\n        results.add(\"success\", \"no-op\");\n        return;\n      }\n      // add collection props\n      DocCollection coll = cmd.collection;\n      collProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>()).putAll(coll.getProperties());\n      colShardReplicaMap.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>());\n      // add slice props\n      coll.getSlices().forEach(s -> {\n        Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(coll.getName(), c -> new ConcurrentHashMap<>())\n            .computeIfAbsent(s.getName(), slice -> new ConcurrentHashMap<>());\n        s.getProperties().forEach((k, v) -> {\n          if (k != null && v != null) {\n            sliceProps.put(k, v);\n          }\n        });\n        colShardReplicaMap.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n            .computeIfAbsent(s.getName(), sh -> new ArrayList<>());\n      });\n\n      // modify the `withCollection` and store this new collection's name with it\n      if (withCollection != null) {\n        ZkNodeProps message = new ZkNodeProps(\n            Overseer.QUEUE_OPERATION, MODIFYCOLLECTION.toString(),\n            ZkStateReader.COLLECTION_PROP, withCollection,\n            CollectionAdminParams.COLOCATED_WITH, collectionName);\n        cmd = new CollectionMutator(cloudManager).modifyCollection(clusterState,message);\n      }\n      collectionsStatesRef.put(collectionName, new CachedCollectionRef(collectionName, 0));\n\n    } finally {\n      lock.unlock();\n    }\n    opDelays.computeIfAbsent(collectionName, c -> new HashMap<>()).putAll(defaultOpDelays);\n\n    opDelay(collectionName, CollectionParams.CollectionAction.CREATE.name());\n\n    AtomicReference<PolicyHelper.SessionWrapper> sessionWrapper = new AtomicReference<>();\n    List<ReplicaPosition> replicaPositions = CreateCollectionCmd.buildReplicaPositions(cloudManager, getClusterState(), cmd.collection, props,\n        shardNames, sessionWrapper);\n    if (sessionWrapper.get() != null) {\n      sessionWrapper.get().release();\n    }\n    // calculate expected number of positions\n    int numTlogReplicas = props.getInt(TLOG_REPLICAS, 0);\n    int numNrtReplicas = props.getInt(NRT_REPLICAS, props.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n    int numPullReplicas = props.getInt(PULL_REPLICAS, 0);\n    int totalReplicas = shardNames.size() * (numNrtReplicas + numPullReplicas + numTlogReplicas);\n    if (totalReplicas != replicaPositions.size()) {\n      throw new RuntimeException(\"unexpected number of replica positions: expected \" + totalReplicas + \" but got \" + replicaPositions.size());\n    }\n    final CountDownLatch finalStateLatch = new CountDownLatch(replicaPositions.size());\n    AtomicInteger replicaNum = new AtomicInteger(1);\n    replicaPositions.forEach(pos -> {\n\n      if (withCollection != null) {\n        // check that we have a replica of `withCollection` on this node and if not, create one\n        DocCollection collection = clusterState.getCollection(withCollection);\n        List<Replica> replicas = collection.getReplicas(pos.node);\n        if (replicas == null || replicas.isEmpty()) {\n          Map<String, Object> replicaProps = new HashMap<>();\n          replicaProps.put(ZkStateReader.NODE_NAME_PROP, pos.node);\n          replicaProps.put(ZkStateReader.REPLICA_TYPE, pos.type.toString());\n          String coreName = String.format(Locale.ROOT, \"%s_%s_replica_%s%s\", withCollection, withCollectionShard, pos.type.name().substring(0,1).toLowerCase(Locale.ROOT),\n              collection.getReplicas().size() + 1);\n          try {\n            replicaProps.put(ZkStateReader.CORE_NAME_PROP, coreName);\n            replicaProps.put(\"SEARCHER.searcher.deletedDocs\", new AtomicLong(0));\n            replicaProps.put(\"SEARCHER.searcher.numDocs\", new AtomicLong(0));\n            replicaProps.put(\"SEARCHER.searcher.maxDoc\", new AtomicLong(0));\n            ReplicaInfo ri = new ReplicaInfo(\"core_node\" + Assign.incAndGetId(stateManager, withCollection, 0),\n                coreName, withCollection, withCollectionShard, pos.type, pos.node, replicaProps);\n            cloudManager.submit(() -> {\n              simAddReplica(pos.node, ri, false);\n              // do not count down the latch here\n              return true;\n            });\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      }\n\n      Map<String, Object> replicaProps = new HashMap<>();\n      replicaProps.put(ZkStateReader.NODE_NAME_PROP, pos.node);\n      replicaProps.put(ZkStateReader.REPLICA_TYPE, pos.type.toString());\n      String coreName = String.format(Locale.ROOT, \"%s_%s_replica_%s%s\", collectionName, pos.shard, pos.type.name().substring(0,1).toLowerCase(Locale.ROOT),\n          replicaNum.getAndIncrement());\n      try {\n        replicaProps.put(ZkStateReader.CORE_NAME_PROP, coreName);\n        replicaProps.put(\"SEARCHER.searcher.deletedDocs\", new AtomicLong(0));\n        replicaProps.put(\"SEARCHER.searcher.numDocs\", new AtomicLong(0));\n        replicaProps.put(\"SEARCHER.searcher.maxDoc\", new AtomicLong(0));\n        ReplicaInfo ri = new ReplicaInfo(\"core_node\" + Assign.incAndGetId(stateManager, collectionName, 0),\n            coreName, collectionName, pos.shard, pos.type, pos.node, replicaProps);\n        cloudManager.submit(() -> {\n          simAddReplica(pos.node, ri, true);\n          finalStateLatch.countDown();\n          return true;\n        });\n      } catch (Exception e) {\n        throw new RuntimeException(e);\n      }\n    });\n\n    // force recreation of collection states\n    lock.lockInterruptibly();\n    try {\n      collectionsStatesRef.get(collectionName).invalidate();\n    } finally {\n      lock.unlock();\n    }\n    //simRunLeaderElection(Collections.singleton(collectionName), true);\n    if (waitForFinalState) {\n      boolean finished = finalStateLatch.await(cloudManager.getTimeSource().convertDelay(TimeUnit.SECONDS, 60, TimeUnit.MILLISECONDS),\n          TimeUnit.MILLISECONDS);\n      if (!finished) {\n        results.add(\"failure\", \"Timeout waiting for all replicas to become active.\");\n        return;\n      }\n    }\n    results.add(\"success\", \"\");\n    log.debug(\"-- finished createCollection {}\", collectionName);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e46a76bb135597b8bf35930cfdb3702bdd1cbe6e","date":1594223844,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simCreateCollection(ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simCreateCollection(ZkNodeProps,NamedList).mjava","sourceNew":"  /**\n   * Create a new collection. This operation uses policy framework for node and replica assignments.\n   * @param props collection details\n   * @param results results of the operation.\n   */\n\n  @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n  public void simCreateCollection(ZkNodeProps props, NamedList results) throws Exception {\n    ensureNotClosed();\n    if (props.getStr(CommonAdminParams.ASYNC) != null) {\n      results.add(CoreAdminParams.REQUESTID, props.getStr(CommonAdminParams.ASYNC));\n    }\n    boolean waitForFinalState = props.getBool(CommonAdminParams.WAIT_FOR_FINAL_STATE, false);\n    final String collectionName = props.getStr(NAME);\n    log.debug(\"-- simCreateCollection {}\", collectionName);\n\n    String router = props.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n    String policy = props.getStr(Policy.POLICY);\n    AutoScalingConfig autoScalingConfig = cloudManager.getDistribStateManager().getAutoScalingConfig();\n    boolean usePolicyFramework = !autoScalingConfig.getPolicy().getClusterPolicy().isEmpty() || policy != null;\n\n    // fail fast if parameters are wrong or incomplete\n    List<String> shardNames = CreateCollectionCmd.populateShardNames(props, router);\n    CreateCollectionCmd.checkReplicaTypes(props);\n\n    // always force getting fresh state\n    final ClusterState clusterState = getClusterState();\n\n    String withCollection = props.getStr(CollectionAdminParams.WITH_COLLECTION);\n    String wcShard = null;\n    if (withCollection != null) {\n      if (!clusterState.hasCollection(withCollection)) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"The 'withCollection' does not exist: \" + withCollection);\n      } else  {\n        DocCollection collection = clusterState.getCollection(withCollection);\n        if (collection.getActiveSlices().size() > 1)  {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"The `withCollection` must have only one shard, found: \" + collection.getActiveSlices().size());\n        }\n        wcShard = collection.getActiveSlices().iterator().next().getName();\n      }\n    }\n    final String withCollectionShard = wcShard;\n\n    ZkWriteCommand cmd = ZkWriteCommand.noop();\n    \n    lock.lockInterruptibly();\n    try {\n      cmd = new ClusterStateMutator(cloudManager).createCollection(clusterState, props);\n      if (cmd.noop) {\n        log.warn(\"Collection {} already exists. exit\", collectionName);\n        log.debug(\"-- collection: {}, clusterState: {}\", collectionName, clusterState);\n        results.add(\"success\", \"no-op\");\n        return;\n      }\n      // add collection props\n      DocCollection coll = cmd.collection;\n      collProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>()).putAll(coll.getProperties());\n      colShardReplicaMap.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>());\n      // add slice props\n      coll.getSlices().forEach(s -> {\n        Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(coll.getName(), c -> new ConcurrentHashMap<>())\n            .computeIfAbsent(s.getName(), slice -> new ConcurrentHashMap<>());\n        s.getProperties().forEach((k, v) -> {\n          if (k != null && v != null) {\n            sliceProps.put(k, v);\n          }\n        });\n        colShardReplicaMap.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n            .computeIfAbsent(s.getName(), sh -> new ArrayList<>());\n      });\n\n      // modify the `withCollection` and store this new collection's name with it\n      if (withCollection != null) {\n        ZkNodeProps message = new ZkNodeProps(\n            Overseer.QUEUE_OPERATION, MODIFYCOLLECTION.toString(),\n            ZkStateReader.COLLECTION_PROP, withCollection,\n            CollectionAdminParams.COLOCATED_WITH, collectionName);\n        cmd = new CollectionMutator(cloudManager).modifyCollection(clusterState,message);\n      }\n      collectionsStatesRef.put(collectionName, new CachedCollectionRef(collectionName, 0));\n\n    } finally {\n      lock.unlock();\n    }\n    opDelays.computeIfAbsent(collectionName, c -> new HashMap<>()).putAll(defaultOpDelays);\n\n    opDelay(collectionName, CollectionParams.CollectionAction.CREATE.name());\n\n    AtomicReference<PolicyHelper.SessionWrapper> sessionWrapper = new AtomicReference<>();\n    List<ReplicaPosition> replicaPositions = CreateCollectionCmd.buildReplicaPositions(cloudManager, getClusterState(), cmd.collection, props,\n        shardNames, sessionWrapper);\n    if (sessionWrapper.get() != null) {\n      sessionWrapper.get().release();\n    }\n    // calculate expected number of positions\n    int numTlogReplicas = props.getInt(TLOG_REPLICAS, 0);\n    int numNrtReplicas = props.getInt(NRT_REPLICAS, props.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n    int numPullReplicas = props.getInt(PULL_REPLICAS, 0);\n    int totalReplicas = shardNames.size() * (numNrtReplicas + numPullReplicas + numTlogReplicas);\n    if (totalReplicas != replicaPositions.size()) {\n      throw new RuntimeException(\"unexpected number of replica positions: expected \" + totalReplicas + \" but got \" + replicaPositions.size());\n    }\n    final CountDownLatch finalStateLatch = new CountDownLatch(replicaPositions.size());\n    AtomicInteger replicaNum = new AtomicInteger(1);\n    replicaPositions.forEach(pos -> {\n\n      if (withCollection != null) {\n        // check that we have a replica of `withCollection` on this node and if not, create one\n        DocCollection collection = clusterState.getCollection(withCollection);\n        List<Replica> replicas = collection.getReplicas(pos.node);\n        if (replicas == null || replicas.isEmpty()) {\n          Map<String, Object> replicaProps = new HashMap<>();\n          replicaProps.put(ZkStateReader.NODE_NAME_PROP, pos.node);\n          replicaProps.put(ZkStateReader.REPLICA_TYPE, pos.type.toString());\n          String coreName = String.format(Locale.ROOT, \"%s_%s_replica_%s%s\", withCollection, withCollectionShard, pos.type.name().substring(0,1).toLowerCase(Locale.ROOT),\n              collection.getReplicas().size() + 1);\n          try {\n            replicaProps.put(ZkStateReader.CORE_NAME_PROP, coreName);\n            replicaProps.put(\"SEARCHER.searcher.deletedDocs\", new AtomicLong(0));\n            replicaProps.put(\"SEARCHER.searcher.numDocs\", new AtomicLong(0));\n            replicaProps.put(\"SEARCHER.searcher.maxDoc\", new AtomicLong(0));\n            ReplicaInfo ri = new ReplicaInfo(\"core_node\" + Assign.incAndGetId(stateManager, withCollection, 0),\n                coreName, withCollection, withCollectionShard, pos.type, pos.node, replicaProps);\n            cloudManager.submit(() -> {\n              simAddReplica(pos.node, ri, false);\n              // do not count down the latch here\n              return true;\n            });\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      }\n\n      Map<String, Object> replicaProps = new HashMap<>();\n      replicaProps.put(ZkStateReader.NODE_NAME_PROP, pos.node);\n      replicaProps.put(ZkStateReader.REPLICA_TYPE, pos.type.toString());\n      String coreName = String.format(Locale.ROOT, \"%s_%s_replica_%s%s\", collectionName, pos.shard, pos.type.name().substring(0,1).toLowerCase(Locale.ROOT),\n          replicaNum.getAndIncrement());\n      try {\n        replicaProps.put(ZkStateReader.CORE_NAME_PROP, coreName);\n        replicaProps.put(\"SEARCHER.searcher.deletedDocs\", new AtomicLong(0));\n        replicaProps.put(\"SEARCHER.searcher.numDocs\", new AtomicLong(0));\n        replicaProps.put(\"SEARCHER.searcher.maxDoc\", new AtomicLong(0));\n        ReplicaInfo ri = new ReplicaInfo(\"core_node\" + Assign.incAndGetId(stateManager, collectionName, 0),\n            coreName, collectionName, pos.shard, pos.type, pos.node, replicaProps);\n        cloudManager.submit(() -> {\n          simAddReplica(pos.node, ri, true);\n          finalStateLatch.countDown();\n          return true;\n        });\n      } catch (Exception e) {\n        throw new RuntimeException(e);\n      }\n    });\n\n    // force recreation of collection states\n    lock.lockInterruptibly();\n    try {\n      collectionsStatesRef.get(collectionName).invalidate();\n    } finally {\n      lock.unlock();\n    }\n    //simRunLeaderElection(Collections.singleton(collectionName), true);\n    if (waitForFinalState) {\n      boolean finished = finalStateLatch.await(cloudManager.getTimeSource().convertDelay(TimeUnit.SECONDS, 60, TimeUnit.MILLISECONDS),\n          TimeUnit.MILLISECONDS);\n      if (!finished) {\n        results.add(\"failure\", \"Timeout waiting for all replicas to become active.\");\n        return;\n      }\n    }\n    results.add(\"success\", \"\");\n    log.debug(\"-- finished createCollection {}\", collectionName);\n  }\n\n","sourceOld":"  /**\n   * Create a new collection. This operation uses policy framework for node and replica assignments.\n   * @param props collection details\n   * @param results results of the operation.\n   */\n\n  @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n  public void simCreateCollection(ZkNodeProps props, NamedList results) throws Exception {\n    ensureNotClosed();\n    if (props.getStr(CommonAdminParams.ASYNC) != null) {\n      results.add(CoreAdminParams.REQUESTID, props.getStr(CommonAdminParams.ASYNC));\n    }\n    boolean waitForFinalState = props.getBool(CommonAdminParams.WAIT_FOR_FINAL_STATE, false);\n    final String collectionName = props.getStr(NAME);\n    log.debug(\"-- simCreateCollection {}\", collectionName);\n\n    String router = props.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n    String policy = props.getStr(Policy.POLICY);\n    AutoScalingConfig autoScalingConfig = cloudManager.getDistribStateManager().getAutoScalingConfig();\n    boolean usePolicyFramework = !autoScalingConfig.getPolicy().getClusterPolicy().isEmpty() || policy != null;\n\n    // fail fast if parameters are wrong or incomplete\n    List<String> shardNames = CreateCollectionCmd.populateShardNames(props, router);\n    int maxShardsPerNode = props.getInt(MAX_SHARDS_PER_NODE, 1);\n    if (maxShardsPerNode == -1) maxShardsPerNode = Integer.MAX_VALUE;\n    CreateCollectionCmd.checkReplicaTypes(props);\n\n    // always force getting fresh state\n    final ClusterState clusterState = getClusterState();\n\n    String withCollection = props.getStr(CollectionAdminParams.WITH_COLLECTION);\n    String wcShard = null;\n    if (withCollection != null) {\n      if (!clusterState.hasCollection(withCollection)) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"The 'withCollection' does not exist: \" + withCollection);\n      } else  {\n        DocCollection collection = clusterState.getCollection(withCollection);\n        if (collection.getActiveSlices().size() > 1)  {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"The `withCollection` must have only one shard, found: \" + collection.getActiveSlices().size());\n        }\n        wcShard = collection.getActiveSlices().iterator().next().getName();\n      }\n    }\n    final String withCollectionShard = wcShard;\n\n    ZkWriteCommand cmd = ZkWriteCommand.noop();\n    \n    lock.lockInterruptibly();\n    try {\n      cmd = new ClusterStateMutator(cloudManager).createCollection(clusterState, props);\n      if (cmd.noop) {\n        log.warn(\"Collection {} already exists. exit\", collectionName);\n        log.debug(\"-- collection: {}, clusterState: {}\", collectionName, clusterState);\n        results.add(\"success\", \"no-op\");\n        return;\n      }\n      // add collection props\n      DocCollection coll = cmd.collection;\n      collProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>()).putAll(coll.getProperties());\n      colShardReplicaMap.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>());\n      // add slice props\n      coll.getSlices().forEach(s -> {\n        Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(coll.getName(), c -> new ConcurrentHashMap<>())\n            .computeIfAbsent(s.getName(), slice -> new ConcurrentHashMap<>());\n        s.getProperties().forEach((k, v) -> {\n          if (k != null && v != null) {\n            sliceProps.put(k, v);\n          }\n        });\n        colShardReplicaMap.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n            .computeIfAbsent(s.getName(), sh -> new ArrayList<>());\n      });\n\n      // modify the `withCollection` and store this new collection's name with it\n      if (withCollection != null) {\n        ZkNodeProps message = new ZkNodeProps(\n            Overseer.QUEUE_OPERATION, MODIFYCOLLECTION.toString(),\n            ZkStateReader.COLLECTION_PROP, withCollection,\n            CollectionAdminParams.COLOCATED_WITH, collectionName);\n        cmd = new CollectionMutator(cloudManager).modifyCollection(clusterState,message);\n      }\n      collectionsStatesRef.put(collectionName, new CachedCollectionRef(collectionName, 0));\n\n    } finally {\n      lock.unlock();\n    }\n    opDelays.computeIfAbsent(collectionName, c -> new HashMap<>()).putAll(defaultOpDelays);\n\n    opDelay(collectionName, CollectionParams.CollectionAction.CREATE.name());\n\n    AtomicReference<PolicyHelper.SessionWrapper> sessionWrapper = new AtomicReference<>();\n    List<ReplicaPosition> replicaPositions = CreateCollectionCmd.buildReplicaPositions(cloudManager, getClusterState(), cmd.collection, props,\n        shardNames, sessionWrapper);\n    if (sessionWrapper.get() != null) {\n      sessionWrapper.get().release();\n    }\n    // calculate expected number of positions\n    int numTlogReplicas = props.getInt(TLOG_REPLICAS, 0);\n    int numNrtReplicas = props.getInt(NRT_REPLICAS, props.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n    int numPullReplicas = props.getInt(PULL_REPLICAS, 0);\n    int totalReplicas = shardNames.size() * (numNrtReplicas + numPullReplicas + numTlogReplicas);\n    if (totalReplicas != replicaPositions.size()) {\n      throw new RuntimeException(\"unexpected number of replica positions: expected \" + totalReplicas + \" but got \" + replicaPositions.size());\n    }\n    final CountDownLatch finalStateLatch = new CountDownLatch(replicaPositions.size());\n    AtomicInteger replicaNum = new AtomicInteger(1);\n    replicaPositions.forEach(pos -> {\n\n      if (withCollection != null) {\n        // check that we have a replica of `withCollection` on this node and if not, create one\n        DocCollection collection = clusterState.getCollection(withCollection);\n        List<Replica> replicas = collection.getReplicas(pos.node);\n        if (replicas == null || replicas.isEmpty()) {\n          Map<String, Object> replicaProps = new HashMap<>();\n          replicaProps.put(ZkStateReader.NODE_NAME_PROP, pos.node);\n          replicaProps.put(ZkStateReader.REPLICA_TYPE, pos.type.toString());\n          String coreName = String.format(Locale.ROOT, \"%s_%s_replica_%s%s\", withCollection, withCollectionShard, pos.type.name().substring(0,1).toLowerCase(Locale.ROOT),\n              collection.getReplicas().size() + 1);\n          try {\n            replicaProps.put(ZkStateReader.CORE_NAME_PROP, coreName);\n            replicaProps.put(\"SEARCHER.searcher.deletedDocs\", new AtomicLong(0));\n            replicaProps.put(\"SEARCHER.searcher.numDocs\", new AtomicLong(0));\n            replicaProps.put(\"SEARCHER.searcher.maxDoc\", new AtomicLong(0));\n            ReplicaInfo ri = new ReplicaInfo(\"core_node\" + Assign.incAndGetId(stateManager, withCollection, 0),\n                coreName, withCollection, withCollectionShard, pos.type, pos.node, replicaProps);\n            cloudManager.submit(() -> {\n              simAddReplica(pos.node, ri, false);\n              // do not count down the latch here\n              return true;\n            });\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      }\n\n      Map<String, Object> replicaProps = new HashMap<>();\n      replicaProps.put(ZkStateReader.NODE_NAME_PROP, pos.node);\n      replicaProps.put(ZkStateReader.REPLICA_TYPE, pos.type.toString());\n      String coreName = String.format(Locale.ROOT, \"%s_%s_replica_%s%s\", collectionName, pos.shard, pos.type.name().substring(0,1).toLowerCase(Locale.ROOT),\n          replicaNum.getAndIncrement());\n      try {\n        replicaProps.put(ZkStateReader.CORE_NAME_PROP, coreName);\n        replicaProps.put(\"SEARCHER.searcher.deletedDocs\", new AtomicLong(0));\n        replicaProps.put(\"SEARCHER.searcher.numDocs\", new AtomicLong(0));\n        replicaProps.put(\"SEARCHER.searcher.maxDoc\", new AtomicLong(0));\n        ReplicaInfo ri = new ReplicaInfo(\"core_node\" + Assign.incAndGetId(stateManager, collectionName, 0),\n            coreName, collectionName, pos.shard, pos.type, pos.node, replicaProps);\n        cloudManager.submit(() -> {\n          simAddReplica(pos.node, ri, true);\n          finalStateLatch.countDown();\n          return true;\n        });\n      } catch (Exception e) {\n        throw new RuntimeException(e);\n      }\n    });\n\n    // force recreation of collection states\n    lock.lockInterruptibly();\n    try {\n      collectionsStatesRef.get(collectionName).invalidate();\n    } finally {\n      lock.unlock();\n    }\n    //simRunLeaderElection(Collections.singleton(collectionName), true);\n    if (waitForFinalState) {\n      boolean finished = finalStateLatch.await(cloudManager.getTimeSource().convertDelay(TimeUnit.SECONDS, 60, TimeUnit.MILLISECONDS),\n          TimeUnit.MILLISECONDS);\n      if (!finished) {\n        results.add(\"failure\", \"Timeout waiting for all replicas to become active.\");\n        return;\n      }\n    }\n    results.add(\"success\", \"\");\n    log.debug(\"-- finished createCollection {}\", collectionName);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7e8ce2f9d2ddfcf5cfa7e73b8b2af287a2a276fd","date":1594731683,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simCreateCollection(ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simCreateCollection(ZkNodeProps,NamedList).mjava","sourceNew":"  /**\n   * Create a new collection. This operation uses policy framework for node and replica assignments.\n   * @param props collection details\n   * @param results results of the operation.\n   */\n\n  @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n  public void simCreateCollection(ZkNodeProps props, NamedList results) throws Exception {\n    ensureNotClosed();\n    if (props.getStr(CommonAdminParams.ASYNC) != null) {\n      results.add(CoreAdminParams.REQUESTID, props.getStr(CommonAdminParams.ASYNC));\n    }\n    boolean waitForFinalState = props.getBool(CommonAdminParams.WAIT_FOR_FINAL_STATE, false);\n    final String collectionName = props.getStr(NAME);\n    log.debug(\"-- simCreateCollection {}\", collectionName);\n\n    String router = props.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n    String policy = props.getStr(Policy.POLICY);\n    AutoScalingConfig autoScalingConfig = cloudManager.getDistribStateManager().getAutoScalingConfig();\n    boolean usePolicyFramework = !autoScalingConfig.getPolicy().getClusterPolicy().isEmpty() || policy != null;\n\n    // fail fast if parameters are wrong or incomplete\n    List<String> shardNames = CreateCollectionCmd.populateShardNames(props, router);\n    CreateCollectionCmd.checkReplicaTypes(props);\n\n    // always force getting fresh state\n    final ClusterState clusterState = getClusterState();\n\n    String withCollection = props.getStr(CollectionAdminParams.WITH_COLLECTION);\n    String wcShard = null;\n    if (withCollection != null) {\n      if (!clusterState.hasCollection(withCollection)) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"The 'withCollection' does not exist: \" + withCollection);\n      } else  {\n        DocCollection collection = clusterState.getCollection(withCollection);\n        if (collection.getActiveSlices().size() > 1)  {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"The `withCollection` must have only one shard, found: \" + collection.getActiveSlices().size());\n        }\n        wcShard = collection.getActiveSlices().iterator().next().getName();\n      }\n    }\n    final String withCollectionShard = wcShard;\n\n    ZkWriteCommand cmd = ZkWriteCommand.noop();\n    \n    lock.lockInterruptibly();\n    try {\n      cmd = new ClusterStateMutator(cloudManager).createCollection(clusterState, props);\n      if (cmd.noop) {\n        log.warn(\"Collection {} already exists. exit\", collectionName);\n        log.debug(\"-- collection: {}, clusterState: {}\", collectionName, clusterState);\n        results.add(\"success\", \"no-op\");\n        return;\n      }\n      // add collection props\n      DocCollection coll = cmd.collection;\n      collProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>()).putAll(coll.getProperties());\n      colShardReplicaMap.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>());\n      // add slice props\n      coll.getSlices().forEach(s -> {\n        Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(coll.getName(), c -> new ConcurrentHashMap<>())\n            .computeIfAbsent(s.getName(), slice -> new ConcurrentHashMap<>());\n        s.getProperties().forEach((k, v) -> {\n          if (k != null && v != null) {\n            sliceProps.put(k, v);\n          }\n        });\n        colShardReplicaMap.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n            .computeIfAbsent(s.getName(), sh -> new ArrayList<>());\n      });\n\n      // modify the `withCollection` and store this new collection's name with it\n      if (withCollection != null) {\n        ZkNodeProps message = new ZkNodeProps(\n            Overseer.QUEUE_OPERATION, MODIFYCOLLECTION.toString(),\n            ZkStateReader.COLLECTION_PROP, withCollection,\n            CollectionAdminParams.COLOCATED_WITH, collectionName);\n        cmd = new CollectionMutator(cloudManager).modifyCollection(clusterState,message);\n      }\n      collectionsStatesRef.put(collectionName, new CachedCollectionRef(collectionName, 0));\n\n    } finally {\n      lock.unlock();\n    }\n    opDelays.computeIfAbsent(collectionName, c -> new HashMap<>()).putAll(defaultOpDelays);\n\n    opDelay(collectionName, CollectionParams.CollectionAction.CREATE.name());\n\n    AtomicReference<PolicyHelper.SessionWrapper> sessionWrapper = new AtomicReference<>();\n    List<ReplicaPosition> replicaPositions = CreateCollectionCmd.buildReplicaPositions(cloudManager, getClusterState(), cmd.collection, props,\n        shardNames, sessionWrapper);\n    if (sessionWrapper.get() != null) {\n      sessionWrapper.get().release();\n    }\n    // calculate expected number of positions\n    int numTlogReplicas = props.getInt(TLOG_REPLICAS, 0);\n    int numNrtReplicas = props.getInt(NRT_REPLICAS, props.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n    int numPullReplicas = props.getInt(PULL_REPLICAS, 0);\n    int totalReplicas = shardNames.size() * (numNrtReplicas + numPullReplicas + numTlogReplicas);\n    if (totalReplicas != replicaPositions.size()) {\n      throw new RuntimeException(\"unexpected number of replica positions: expected \" + totalReplicas + \" but got \" + replicaPositions.size());\n    }\n    final CountDownLatch finalStateLatch = new CountDownLatch(replicaPositions.size());\n    AtomicInteger replicaNum = new AtomicInteger(1);\n    replicaPositions.forEach(pos -> {\n\n      if (withCollection != null) {\n        // check that we have a replica of `withCollection` on this node and if not, create one\n        DocCollection collection = clusterState.getCollection(withCollection);\n        List<Replica> replicas = collection.getReplicas(pos.node);\n        if (replicas == null || replicas.isEmpty()) {\n          Map<String, Object> replicaProps = new HashMap<>();\n          replicaProps.put(ZkStateReader.NODE_NAME_PROP, pos.node);\n          replicaProps.put(ZkStateReader.REPLICA_TYPE, pos.type.toString());\n          String coreName = String.format(Locale.ROOT, \"%s_%s_replica_%s%s\", withCollection, withCollectionShard, pos.type.name().substring(0,1).toLowerCase(Locale.ROOT),\n              collection.getReplicas().size() + 1);\n          try {\n            replicaProps.put(ZkStateReader.CORE_NAME_PROP, coreName);\n            replicaProps.put(\"SEARCHER.searcher.deletedDocs\", new AtomicLong(0));\n            replicaProps.put(\"SEARCHER.searcher.numDocs\", new AtomicLong(0));\n            replicaProps.put(\"SEARCHER.searcher.maxDoc\", new AtomicLong(0));\n            Replica ri = new Replica(\"core_node\" + Assign.incAndGetId(stateManager, withCollection, 0),\n                pos.node, withCollection, withCollectionShard, coreName, Replica.State.DOWN,\n                pos.type, replicaProps);\n            cloudManager.submit(() -> {\n              simAddReplica(pos.node, ri, false);\n              // do not count down the latch here\n              return true;\n            });\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      }\n\n      Map<String, Object> replicaProps = new HashMap<>();\n      replicaProps.put(ZkStateReader.NODE_NAME_PROP, pos.node);\n      replicaProps.put(ZkStateReader.REPLICA_TYPE, pos.type.toString());\n      String coreName = String.format(Locale.ROOT, \"%s_%s_replica_%s%s\", collectionName, pos.shard, pos.type.name().substring(0,1).toLowerCase(Locale.ROOT),\n          replicaNum.getAndIncrement());\n      try {\n        replicaProps.put(ZkStateReader.CORE_NAME_PROP, coreName);\n        replicaProps.put(\"SEARCHER.searcher.deletedDocs\", new AtomicLong(0));\n        replicaProps.put(\"SEARCHER.searcher.numDocs\", new AtomicLong(0));\n        replicaProps.put(\"SEARCHER.searcher.maxDoc\", new AtomicLong(0));\n        Replica ri = new Replica(\"core_node\" + Assign.incAndGetId(stateManager, collectionName, 0),\n            pos.node, collectionName, pos.shard, coreName, Replica.State.DOWN,\n            pos.type, replicaProps);\n        cloudManager.submit(() -> {\n          simAddReplica(pos.node, ri, true);\n          finalStateLatch.countDown();\n          return true;\n        });\n      } catch (Exception e) {\n        throw new RuntimeException(e);\n      }\n    });\n\n    // force recreation of collection states\n    lock.lockInterruptibly();\n    try {\n      collectionsStatesRef.get(collectionName).invalidate();\n    } finally {\n      lock.unlock();\n    }\n    //simRunLeaderElection(Collections.singleton(collectionName), true);\n    if (waitForFinalState) {\n      boolean finished = finalStateLatch.await(cloudManager.getTimeSource().convertDelay(TimeUnit.SECONDS, 60, TimeUnit.MILLISECONDS),\n          TimeUnit.MILLISECONDS);\n      if (!finished) {\n        results.add(\"failure\", \"Timeout waiting for all replicas to become active.\");\n        return;\n      }\n    }\n    results.add(\"success\", \"\");\n    log.debug(\"-- finished createCollection {}\", collectionName);\n  }\n\n","sourceOld":"  /**\n   * Create a new collection. This operation uses policy framework for node and replica assignments.\n   * @param props collection details\n   * @param results results of the operation.\n   */\n\n  @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n  public void simCreateCollection(ZkNodeProps props, NamedList results) throws Exception {\n    ensureNotClosed();\n    if (props.getStr(CommonAdminParams.ASYNC) != null) {\n      results.add(CoreAdminParams.REQUESTID, props.getStr(CommonAdminParams.ASYNC));\n    }\n    boolean waitForFinalState = props.getBool(CommonAdminParams.WAIT_FOR_FINAL_STATE, false);\n    final String collectionName = props.getStr(NAME);\n    log.debug(\"-- simCreateCollection {}\", collectionName);\n\n    String router = props.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n    String policy = props.getStr(Policy.POLICY);\n    AutoScalingConfig autoScalingConfig = cloudManager.getDistribStateManager().getAutoScalingConfig();\n    boolean usePolicyFramework = !autoScalingConfig.getPolicy().getClusterPolicy().isEmpty() || policy != null;\n\n    // fail fast if parameters are wrong or incomplete\n    List<String> shardNames = CreateCollectionCmd.populateShardNames(props, router);\n    CreateCollectionCmd.checkReplicaTypes(props);\n\n    // always force getting fresh state\n    final ClusterState clusterState = getClusterState();\n\n    String withCollection = props.getStr(CollectionAdminParams.WITH_COLLECTION);\n    String wcShard = null;\n    if (withCollection != null) {\n      if (!clusterState.hasCollection(withCollection)) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"The 'withCollection' does not exist: \" + withCollection);\n      } else  {\n        DocCollection collection = clusterState.getCollection(withCollection);\n        if (collection.getActiveSlices().size() > 1)  {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"The `withCollection` must have only one shard, found: \" + collection.getActiveSlices().size());\n        }\n        wcShard = collection.getActiveSlices().iterator().next().getName();\n      }\n    }\n    final String withCollectionShard = wcShard;\n\n    ZkWriteCommand cmd = ZkWriteCommand.noop();\n    \n    lock.lockInterruptibly();\n    try {\n      cmd = new ClusterStateMutator(cloudManager).createCollection(clusterState, props);\n      if (cmd.noop) {\n        log.warn(\"Collection {} already exists. exit\", collectionName);\n        log.debug(\"-- collection: {}, clusterState: {}\", collectionName, clusterState);\n        results.add(\"success\", \"no-op\");\n        return;\n      }\n      // add collection props\n      DocCollection coll = cmd.collection;\n      collProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>()).putAll(coll.getProperties());\n      colShardReplicaMap.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>());\n      // add slice props\n      coll.getSlices().forEach(s -> {\n        Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(coll.getName(), c -> new ConcurrentHashMap<>())\n            .computeIfAbsent(s.getName(), slice -> new ConcurrentHashMap<>());\n        s.getProperties().forEach((k, v) -> {\n          if (k != null && v != null) {\n            sliceProps.put(k, v);\n          }\n        });\n        colShardReplicaMap.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n            .computeIfAbsent(s.getName(), sh -> new ArrayList<>());\n      });\n\n      // modify the `withCollection` and store this new collection's name with it\n      if (withCollection != null) {\n        ZkNodeProps message = new ZkNodeProps(\n            Overseer.QUEUE_OPERATION, MODIFYCOLLECTION.toString(),\n            ZkStateReader.COLLECTION_PROP, withCollection,\n            CollectionAdminParams.COLOCATED_WITH, collectionName);\n        cmd = new CollectionMutator(cloudManager).modifyCollection(clusterState,message);\n      }\n      collectionsStatesRef.put(collectionName, new CachedCollectionRef(collectionName, 0));\n\n    } finally {\n      lock.unlock();\n    }\n    opDelays.computeIfAbsent(collectionName, c -> new HashMap<>()).putAll(defaultOpDelays);\n\n    opDelay(collectionName, CollectionParams.CollectionAction.CREATE.name());\n\n    AtomicReference<PolicyHelper.SessionWrapper> sessionWrapper = new AtomicReference<>();\n    List<ReplicaPosition> replicaPositions = CreateCollectionCmd.buildReplicaPositions(cloudManager, getClusterState(), cmd.collection, props,\n        shardNames, sessionWrapper);\n    if (sessionWrapper.get() != null) {\n      sessionWrapper.get().release();\n    }\n    // calculate expected number of positions\n    int numTlogReplicas = props.getInt(TLOG_REPLICAS, 0);\n    int numNrtReplicas = props.getInt(NRT_REPLICAS, props.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n    int numPullReplicas = props.getInt(PULL_REPLICAS, 0);\n    int totalReplicas = shardNames.size() * (numNrtReplicas + numPullReplicas + numTlogReplicas);\n    if (totalReplicas != replicaPositions.size()) {\n      throw new RuntimeException(\"unexpected number of replica positions: expected \" + totalReplicas + \" but got \" + replicaPositions.size());\n    }\n    final CountDownLatch finalStateLatch = new CountDownLatch(replicaPositions.size());\n    AtomicInteger replicaNum = new AtomicInteger(1);\n    replicaPositions.forEach(pos -> {\n\n      if (withCollection != null) {\n        // check that we have a replica of `withCollection` on this node and if not, create one\n        DocCollection collection = clusterState.getCollection(withCollection);\n        List<Replica> replicas = collection.getReplicas(pos.node);\n        if (replicas == null || replicas.isEmpty()) {\n          Map<String, Object> replicaProps = new HashMap<>();\n          replicaProps.put(ZkStateReader.NODE_NAME_PROP, pos.node);\n          replicaProps.put(ZkStateReader.REPLICA_TYPE, pos.type.toString());\n          String coreName = String.format(Locale.ROOT, \"%s_%s_replica_%s%s\", withCollection, withCollectionShard, pos.type.name().substring(0,1).toLowerCase(Locale.ROOT),\n              collection.getReplicas().size() + 1);\n          try {\n            replicaProps.put(ZkStateReader.CORE_NAME_PROP, coreName);\n            replicaProps.put(\"SEARCHER.searcher.deletedDocs\", new AtomicLong(0));\n            replicaProps.put(\"SEARCHER.searcher.numDocs\", new AtomicLong(0));\n            replicaProps.put(\"SEARCHER.searcher.maxDoc\", new AtomicLong(0));\n            ReplicaInfo ri = new ReplicaInfo(\"core_node\" + Assign.incAndGetId(stateManager, withCollection, 0),\n                coreName, withCollection, withCollectionShard, pos.type, pos.node, replicaProps);\n            cloudManager.submit(() -> {\n              simAddReplica(pos.node, ri, false);\n              // do not count down the latch here\n              return true;\n            });\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      }\n\n      Map<String, Object> replicaProps = new HashMap<>();\n      replicaProps.put(ZkStateReader.NODE_NAME_PROP, pos.node);\n      replicaProps.put(ZkStateReader.REPLICA_TYPE, pos.type.toString());\n      String coreName = String.format(Locale.ROOT, \"%s_%s_replica_%s%s\", collectionName, pos.shard, pos.type.name().substring(0,1).toLowerCase(Locale.ROOT),\n          replicaNum.getAndIncrement());\n      try {\n        replicaProps.put(ZkStateReader.CORE_NAME_PROP, coreName);\n        replicaProps.put(\"SEARCHER.searcher.deletedDocs\", new AtomicLong(0));\n        replicaProps.put(\"SEARCHER.searcher.numDocs\", new AtomicLong(0));\n        replicaProps.put(\"SEARCHER.searcher.maxDoc\", new AtomicLong(0));\n        ReplicaInfo ri = new ReplicaInfo(\"core_node\" + Assign.incAndGetId(stateManager, collectionName, 0),\n            coreName, collectionName, pos.shard, pos.type, pos.node, replicaProps);\n        cloudManager.submit(() -> {\n          simAddReplica(pos.node, ri, true);\n          finalStateLatch.countDown();\n          return true;\n        });\n      } catch (Exception e) {\n        throw new RuntimeException(e);\n      }\n    });\n\n    // force recreation of collection states\n    lock.lockInterruptibly();\n    try {\n      collectionsStatesRef.get(collectionName).invalidate();\n    } finally {\n      lock.unlock();\n    }\n    //simRunLeaderElection(Collections.singleton(collectionName), true);\n    if (waitForFinalState) {\n      boolean finished = finalStateLatch.await(cloudManager.getTimeSource().convertDelay(TimeUnit.SECONDS, 60, TimeUnit.MILLISECONDS),\n          TimeUnit.MILLISECONDS);\n      if (!finished) {\n        results.add(\"failure\", \"Timeout waiting for all replicas to become active.\");\n        return;\n      }\n    }\n    results.add(\"success\", \"\");\n    log.debug(\"-- finished createCollection {}\", collectionName);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3f504512a03d978990cbff30db0522b354e846db","date":1595247421,"type":4,"author":"Ishan Chattopadhyaya","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simCreateCollection(ZkNodeProps,NamedList).mjava","sourceNew":null,"sourceOld":"  /**\n   * Create a new collection. This operation uses policy framework for node and replica assignments.\n   * @param props collection details\n   * @param results results of the operation.\n   */\n\n  @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n  public void simCreateCollection(ZkNodeProps props, NamedList results) throws Exception {\n    ensureNotClosed();\n    if (props.getStr(CommonAdminParams.ASYNC) != null) {\n      results.add(CoreAdminParams.REQUESTID, props.getStr(CommonAdminParams.ASYNC));\n    }\n    boolean waitForFinalState = props.getBool(CommonAdminParams.WAIT_FOR_FINAL_STATE, false);\n    final String collectionName = props.getStr(NAME);\n    log.debug(\"-- simCreateCollection {}\", collectionName);\n\n    String router = props.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n    String policy = props.getStr(Policy.POLICY);\n    AutoScalingConfig autoScalingConfig = cloudManager.getDistribStateManager().getAutoScalingConfig();\n    boolean usePolicyFramework = !autoScalingConfig.getPolicy().getClusterPolicy().isEmpty() || policy != null;\n\n    // fail fast if parameters are wrong or incomplete\n    List<String> shardNames = CreateCollectionCmd.populateShardNames(props, router);\n    CreateCollectionCmd.checkReplicaTypes(props);\n\n    // always force getting fresh state\n    final ClusterState clusterState = getClusterState();\n\n    String withCollection = props.getStr(CollectionAdminParams.WITH_COLLECTION);\n    String wcShard = null;\n    if (withCollection != null) {\n      if (!clusterState.hasCollection(withCollection)) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"The 'withCollection' does not exist: \" + withCollection);\n      } else  {\n        DocCollection collection = clusterState.getCollection(withCollection);\n        if (collection.getActiveSlices().size() > 1)  {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"The `withCollection` must have only one shard, found: \" + collection.getActiveSlices().size());\n        }\n        wcShard = collection.getActiveSlices().iterator().next().getName();\n      }\n    }\n    final String withCollectionShard = wcShard;\n\n    ZkWriteCommand cmd = ZkWriteCommand.noop();\n    \n    lock.lockInterruptibly();\n    try {\n      cmd = new ClusterStateMutator(cloudManager).createCollection(clusterState, props);\n      if (cmd.noop) {\n        log.warn(\"Collection {} already exists. exit\", collectionName);\n        log.debug(\"-- collection: {}, clusterState: {}\", collectionName, clusterState);\n        results.add(\"success\", \"no-op\");\n        return;\n      }\n      // add collection props\n      DocCollection coll = cmd.collection;\n      collProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>()).putAll(coll.getProperties());\n      colShardReplicaMap.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>());\n      // add slice props\n      coll.getSlices().forEach(s -> {\n        Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(coll.getName(), c -> new ConcurrentHashMap<>())\n            .computeIfAbsent(s.getName(), slice -> new ConcurrentHashMap<>());\n        s.getProperties().forEach((k, v) -> {\n          if (k != null && v != null) {\n            sliceProps.put(k, v);\n          }\n        });\n        colShardReplicaMap.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n            .computeIfAbsent(s.getName(), sh -> new ArrayList<>());\n      });\n\n      // modify the `withCollection` and store this new collection's name with it\n      if (withCollection != null) {\n        ZkNodeProps message = new ZkNodeProps(\n            Overseer.QUEUE_OPERATION, MODIFYCOLLECTION.toString(),\n            ZkStateReader.COLLECTION_PROP, withCollection,\n            CollectionAdminParams.COLOCATED_WITH, collectionName);\n        cmd = new CollectionMutator(cloudManager).modifyCollection(clusterState,message);\n      }\n      collectionsStatesRef.put(collectionName, new CachedCollectionRef(collectionName, 0));\n\n    } finally {\n      lock.unlock();\n    }\n    opDelays.computeIfAbsent(collectionName, c -> new HashMap<>()).putAll(defaultOpDelays);\n\n    opDelay(collectionName, CollectionParams.CollectionAction.CREATE.name());\n\n    AtomicReference<PolicyHelper.SessionWrapper> sessionWrapper = new AtomicReference<>();\n    List<ReplicaPosition> replicaPositions = CreateCollectionCmd.buildReplicaPositions(cloudManager, getClusterState(), cmd.collection, props,\n        shardNames, sessionWrapper);\n    if (sessionWrapper.get() != null) {\n      sessionWrapper.get().release();\n    }\n    // calculate expected number of positions\n    int numTlogReplicas = props.getInt(TLOG_REPLICAS, 0);\n    int numNrtReplicas = props.getInt(NRT_REPLICAS, props.getInt(REPLICATION_FACTOR, numTlogReplicas>0?0:1));\n    int numPullReplicas = props.getInt(PULL_REPLICAS, 0);\n    int totalReplicas = shardNames.size() * (numNrtReplicas + numPullReplicas + numTlogReplicas);\n    if (totalReplicas != replicaPositions.size()) {\n      throw new RuntimeException(\"unexpected number of replica positions: expected \" + totalReplicas + \" but got \" + replicaPositions.size());\n    }\n    final CountDownLatch finalStateLatch = new CountDownLatch(replicaPositions.size());\n    AtomicInteger replicaNum = new AtomicInteger(1);\n    replicaPositions.forEach(pos -> {\n\n      if (withCollection != null) {\n        // check that we have a replica of `withCollection` on this node and if not, create one\n        DocCollection collection = clusterState.getCollection(withCollection);\n        List<Replica> replicas = collection.getReplicas(pos.node);\n        if (replicas == null || replicas.isEmpty()) {\n          Map<String, Object> replicaProps = new HashMap<>();\n          replicaProps.put(ZkStateReader.NODE_NAME_PROP, pos.node);\n          replicaProps.put(ZkStateReader.REPLICA_TYPE, pos.type.toString());\n          String coreName = String.format(Locale.ROOT, \"%s_%s_replica_%s%s\", withCollection, withCollectionShard, pos.type.name().substring(0,1).toLowerCase(Locale.ROOT),\n              collection.getReplicas().size() + 1);\n          try {\n            replicaProps.put(ZkStateReader.CORE_NAME_PROP, coreName);\n            replicaProps.put(\"SEARCHER.searcher.deletedDocs\", new AtomicLong(0));\n            replicaProps.put(\"SEARCHER.searcher.numDocs\", new AtomicLong(0));\n            replicaProps.put(\"SEARCHER.searcher.maxDoc\", new AtomicLong(0));\n            Replica ri = new Replica(\"core_node\" + Assign.incAndGetId(stateManager, withCollection, 0),\n                pos.node, withCollection, withCollectionShard, coreName, Replica.State.DOWN,\n                pos.type, replicaProps);\n            cloudManager.submit(() -> {\n              simAddReplica(pos.node, ri, false);\n              // do not count down the latch here\n              return true;\n            });\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      }\n\n      Map<String, Object> replicaProps = new HashMap<>();\n      replicaProps.put(ZkStateReader.NODE_NAME_PROP, pos.node);\n      replicaProps.put(ZkStateReader.REPLICA_TYPE, pos.type.toString());\n      String coreName = String.format(Locale.ROOT, \"%s_%s_replica_%s%s\", collectionName, pos.shard, pos.type.name().substring(0,1).toLowerCase(Locale.ROOT),\n          replicaNum.getAndIncrement());\n      try {\n        replicaProps.put(ZkStateReader.CORE_NAME_PROP, coreName);\n        replicaProps.put(\"SEARCHER.searcher.deletedDocs\", new AtomicLong(0));\n        replicaProps.put(\"SEARCHER.searcher.numDocs\", new AtomicLong(0));\n        replicaProps.put(\"SEARCHER.searcher.maxDoc\", new AtomicLong(0));\n        Replica ri = new Replica(\"core_node\" + Assign.incAndGetId(stateManager, collectionName, 0),\n            pos.node, collectionName, pos.shard, coreName, Replica.State.DOWN,\n            pos.type, replicaProps);\n        cloudManager.submit(() -> {\n          simAddReplica(pos.node, ri, true);\n          finalStateLatch.countDown();\n          return true;\n        });\n      } catch (Exception e) {\n        throw new RuntimeException(e);\n      }\n    });\n\n    // force recreation of collection states\n    lock.lockInterruptibly();\n    try {\n      collectionsStatesRef.get(collectionName).invalidate();\n    } finally {\n      lock.unlock();\n    }\n    //simRunLeaderElection(Collections.singleton(collectionName), true);\n    if (waitForFinalState) {\n      boolean finished = finalStateLatch.await(cloudManager.getTimeSource().convertDelay(TimeUnit.SECONDS, 60, TimeUnit.MILLISECONDS),\n          TimeUnit.MILLISECONDS);\n      if (!finished) {\n        results.add(\"failure\", \"Timeout waiting for all replicas to become active.\");\n        return;\n      }\n    }\n    results.add(\"success\", \"\");\n    log.debug(\"-- finished createCollection {}\", collectionName);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"7e8ce2f9d2ddfcf5cfa7e73b8b2af287a2a276fd":["e46a76bb135597b8bf35930cfdb3702bdd1cbe6e"],"3f504512a03d978990cbff30db0522b354e846db":["7e8ce2f9d2ddfcf5cfa7e73b8b2af287a2a276fd"],"daa0f21a44e235a2299ea1fa913898b182dd7cce":["eb7a329be123e1f46f9d78d74f6d23f33ec81b0a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"eb7a329be123e1f46f9d78d74f6d23f33ec81b0a":["9ef8d00dbfbeb534eba8a219a5df9d99b2de6ab5"],"9ef8d00dbfbeb534eba8a219a5df9d99b2de6ab5":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"e46a76bb135597b8bf35930cfdb3702bdd1cbe6e":["daa0f21a44e235a2299ea1fa913898b182dd7cce"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3f504512a03d978990cbff30db0522b354e846db"]},"commit2Childs":{"7e8ce2f9d2ddfcf5cfa7e73b8b2af287a2a276fd":["3f504512a03d978990cbff30db0522b354e846db"],"3f504512a03d978990cbff30db0522b354e846db":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"daa0f21a44e235a2299ea1fa913898b182dd7cce":["e46a76bb135597b8bf35930cfdb3702bdd1cbe6e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9ef8d00dbfbeb534eba8a219a5df9d99b2de6ab5"],"eb7a329be123e1f46f9d78d74f6d23f33ec81b0a":["daa0f21a44e235a2299ea1fa913898b182dd7cce"],"9ef8d00dbfbeb534eba8a219a5df9d99b2de6ab5":["eb7a329be123e1f46f9d78d74f6d23f33ec81b0a"],"e46a76bb135597b8bf35930cfdb3702bdd1cbe6e":["7e8ce2f9d2ddfcf5cfa7e73b8b2af287a2a276fd"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}