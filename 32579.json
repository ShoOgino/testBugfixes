{"path":"lucene/backward-codecs/src/test/org/apache/lucene/codecs/lucene41/Lucene41StoredFieldsIndexWriter#writeBlock().mjava","commits":[{"id":"3d5291145ae0cea7e6e6a2379f3a32643bf71bf6","date":1411857884,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/backward-codecs/src/test/org/apache/lucene/codecs/lucene41/Lucene41StoredFieldsIndexWriter#writeBlock().mjava","pathOld":"/dev/null","sourceNew":"  private void writeBlock() throws IOException {\n    assert blockChunks > 0;\n    fieldsIndexOut.writeVInt(blockChunks);\n\n    // The trick here is that we only store the difference from the average start\n    // pointer or doc base, this helps save bits per value.\n    // And in order to prevent a few chunks that would be far from the average to\n    // raise the number of bits per value for all of them, we only encode blocks\n    // of 1024 chunks at once\n    // See LUCENE-4512\n\n    // doc bases\n    final int avgChunkDocs;\n    if (blockChunks == 1) {\n      avgChunkDocs = 0;\n    } else {\n      avgChunkDocs = Math.round((float) (blockDocs - docBaseDeltas[blockChunks - 1]) / (blockChunks - 1));\n    }\n    fieldsIndexOut.writeVInt(totalDocs - blockDocs); // docBase\n    fieldsIndexOut.writeVInt(avgChunkDocs);\n    int docBase = 0;\n    long maxDelta = 0;\n    for (int i = 0; i < blockChunks; ++i) {\n      final int delta = docBase - avgChunkDocs * i;\n      maxDelta |= zigZagEncode(delta);\n      docBase += docBaseDeltas[i];\n    }\n\n    final int bitsPerDocBase = PackedInts.bitsRequired(maxDelta);\n    fieldsIndexOut.writeVInt(bitsPerDocBase);\n    PackedInts.Writer writer = PackedInts.getWriterNoHeader(fieldsIndexOut,\n        PackedInts.Format.PACKED, blockChunks, bitsPerDocBase, 1);\n    docBase = 0;\n    for (int i = 0; i < blockChunks; ++i) {\n      final long delta = docBase - avgChunkDocs * i;\n      assert PackedInts.bitsRequired(zigZagEncode(delta)) <= writer.bitsPerValue();\n      writer.add(zigZagEncode(delta));\n      docBase += docBaseDeltas[i];\n    }\n    writer.finish();\n\n    // start pointers\n    fieldsIndexOut.writeVLong(firstStartPointer);\n    final long avgChunkSize;\n    if (blockChunks == 1) {\n      avgChunkSize = 0;\n    } else {\n      avgChunkSize = (maxStartPointer - firstStartPointer) / (blockChunks - 1);\n    }\n    fieldsIndexOut.writeVLong(avgChunkSize);\n    long startPointer = 0;\n    maxDelta = 0;\n    for (int i = 0; i < blockChunks; ++i) {\n      startPointer += startPointerDeltas[i];\n      final long delta = startPointer - avgChunkSize * i;\n      maxDelta |= zigZagEncode(delta);\n    }\n\n    final int bitsPerStartPointer = PackedInts.bitsRequired(maxDelta);\n    fieldsIndexOut.writeVInt(bitsPerStartPointer);\n    writer = PackedInts.getWriterNoHeader(fieldsIndexOut, PackedInts.Format.PACKED,\n        blockChunks, bitsPerStartPointer, 1);\n    startPointer = 0;\n    for (int i = 0; i < blockChunks; ++i) {\n      startPointer += startPointerDeltas[i];\n      final long delta = startPointer - avgChunkSize * i;\n      assert PackedInts.bitsRequired(zigZagEncode(delta)) <= writer.bitsPerValue();\n      writer.add(zigZagEncode(delta));\n    }\n    writer.finish();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9bb9a29a5e71a90295f175df8919802993142c9a","date":1412517673,"type":0,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/backward-codecs/src/test/org/apache/lucene/codecs/lucene41/Lucene41StoredFieldsIndexWriter#writeBlock().mjava","pathOld":"/dev/null","sourceNew":"  private void writeBlock() throws IOException {\n    assert blockChunks > 0;\n    fieldsIndexOut.writeVInt(blockChunks);\n\n    // The trick here is that we only store the difference from the average start\n    // pointer or doc base, this helps save bits per value.\n    // And in order to prevent a few chunks that would be far from the average to\n    // raise the number of bits per value for all of them, we only encode blocks\n    // of 1024 chunks at once\n    // See LUCENE-4512\n\n    // doc bases\n    final int avgChunkDocs;\n    if (blockChunks == 1) {\n      avgChunkDocs = 0;\n    } else {\n      avgChunkDocs = Math.round((float) (blockDocs - docBaseDeltas[blockChunks - 1]) / (blockChunks - 1));\n    }\n    fieldsIndexOut.writeVInt(totalDocs - blockDocs); // docBase\n    fieldsIndexOut.writeVInt(avgChunkDocs);\n    int docBase = 0;\n    long maxDelta = 0;\n    for (int i = 0; i < blockChunks; ++i) {\n      final int delta = docBase - avgChunkDocs * i;\n      maxDelta |= zigZagEncode(delta);\n      docBase += docBaseDeltas[i];\n    }\n\n    final int bitsPerDocBase = PackedInts.bitsRequired(maxDelta);\n    fieldsIndexOut.writeVInt(bitsPerDocBase);\n    PackedInts.Writer writer = PackedInts.getWriterNoHeader(fieldsIndexOut,\n        PackedInts.Format.PACKED, blockChunks, bitsPerDocBase, 1);\n    docBase = 0;\n    for (int i = 0; i < blockChunks; ++i) {\n      final long delta = docBase - avgChunkDocs * i;\n      assert PackedInts.bitsRequired(zigZagEncode(delta)) <= writer.bitsPerValue();\n      writer.add(zigZagEncode(delta));\n      docBase += docBaseDeltas[i];\n    }\n    writer.finish();\n\n    // start pointers\n    fieldsIndexOut.writeVLong(firstStartPointer);\n    final long avgChunkSize;\n    if (blockChunks == 1) {\n      avgChunkSize = 0;\n    } else {\n      avgChunkSize = (maxStartPointer - firstStartPointer) / (blockChunks - 1);\n    }\n    fieldsIndexOut.writeVLong(avgChunkSize);\n    long startPointer = 0;\n    maxDelta = 0;\n    for (int i = 0; i < blockChunks; ++i) {\n      startPointer += startPointerDeltas[i];\n      final long delta = startPointer - avgChunkSize * i;\n      maxDelta |= zigZagEncode(delta);\n    }\n\n    final int bitsPerStartPointer = PackedInts.bitsRequired(maxDelta);\n    fieldsIndexOut.writeVInt(bitsPerStartPointer);\n    writer = PackedInts.getWriterNoHeader(fieldsIndexOut, PackedInts.Format.PACKED,\n        blockChunks, bitsPerStartPointer, 1);\n    startPointer = 0;\n    for (int i = 0; i < blockChunks; ++i) {\n      startPointer += startPointerDeltas[i];\n      final long delta = startPointer - avgChunkSize * i;\n      assert PackedInts.bitsRequired(zigZagEncode(delta)) <= writer.bitsPerValue();\n      writer.add(zigZagEncode(delta));\n    }\n    writer.finish();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"71387d8cb6923eb831b17a8b734608ba2e21c653","date":1414126093,"type":4,"author":"Robert Muir","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/backward-codecs/src/test/org/apache/lucene/codecs/lucene41/Lucene41StoredFieldsIndexWriter#writeBlock().mjava","sourceNew":null,"sourceOld":"  private void writeBlock() throws IOException {\n    assert blockChunks > 0;\n    fieldsIndexOut.writeVInt(blockChunks);\n\n    // The trick here is that we only store the difference from the average start\n    // pointer or doc base, this helps save bits per value.\n    // And in order to prevent a few chunks that would be far from the average to\n    // raise the number of bits per value for all of them, we only encode blocks\n    // of 1024 chunks at once\n    // See LUCENE-4512\n\n    // doc bases\n    final int avgChunkDocs;\n    if (blockChunks == 1) {\n      avgChunkDocs = 0;\n    } else {\n      avgChunkDocs = Math.round((float) (blockDocs - docBaseDeltas[blockChunks - 1]) / (blockChunks - 1));\n    }\n    fieldsIndexOut.writeVInt(totalDocs - blockDocs); // docBase\n    fieldsIndexOut.writeVInt(avgChunkDocs);\n    int docBase = 0;\n    long maxDelta = 0;\n    for (int i = 0; i < blockChunks; ++i) {\n      final int delta = docBase - avgChunkDocs * i;\n      maxDelta |= zigZagEncode(delta);\n      docBase += docBaseDeltas[i];\n    }\n\n    final int bitsPerDocBase = PackedInts.bitsRequired(maxDelta);\n    fieldsIndexOut.writeVInt(bitsPerDocBase);\n    PackedInts.Writer writer = PackedInts.getWriterNoHeader(fieldsIndexOut,\n        PackedInts.Format.PACKED, blockChunks, bitsPerDocBase, 1);\n    docBase = 0;\n    for (int i = 0; i < blockChunks; ++i) {\n      final long delta = docBase - avgChunkDocs * i;\n      assert PackedInts.bitsRequired(zigZagEncode(delta)) <= writer.bitsPerValue();\n      writer.add(zigZagEncode(delta));\n      docBase += docBaseDeltas[i];\n    }\n    writer.finish();\n\n    // start pointers\n    fieldsIndexOut.writeVLong(firstStartPointer);\n    final long avgChunkSize;\n    if (blockChunks == 1) {\n      avgChunkSize = 0;\n    } else {\n      avgChunkSize = (maxStartPointer - firstStartPointer) / (blockChunks - 1);\n    }\n    fieldsIndexOut.writeVLong(avgChunkSize);\n    long startPointer = 0;\n    maxDelta = 0;\n    for (int i = 0; i < blockChunks; ++i) {\n      startPointer += startPointerDeltas[i];\n      final long delta = startPointer - avgChunkSize * i;\n      maxDelta |= zigZagEncode(delta);\n    }\n\n    final int bitsPerStartPointer = PackedInts.bitsRequired(maxDelta);\n    fieldsIndexOut.writeVInt(bitsPerStartPointer);\n    writer = PackedInts.getWriterNoHeader(fieldsIndexOut, PackedInts.Format.PACKED,\n        blockChunks, bitsPerStartPointer, 1);\n    startPointer = 0;\n    for (int i = 0; i < blockChunks; ++i) {\n      startPointer += startPointerDeltas[i];\n      final long delta = startPointer - avgChunkSize * i;\n      assert PackedInts.bitsRequired(zigZagEncode(delta)) <= writer.bitsPerValue();\n      writer.add(zigZagEncode(delta));\n    }\n    writer.finish();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"9bb9a29a5e71a90295f175df8919802993142c9a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","3d5291145ae0cea7e6e6a2379f3a32643bf71bf6"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3d5291145ae0cea7e6e6a2379f3a32643bf71bf6":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"71387d8cb6923eb831b17a8b734608ba2e21c653":["9bb9a29a5e71a90295f175df8919802993142c9a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["71387d8cb6923eb831b17a8b734608ba2e21c653"]},"commit2Childs":{"9bb9a29a5e71a90295f175df8919802993142c9a":["71387d8cb6923eb831b17a8b734608ba2e21c653"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9bb9a29a5e71a90295f175df8919802993142c9a","3d5291145ae0cea7e6e6a2379f3a32643bf71bf6"],"3d5291145ae0cea7e6e6a2379f3a32643bf71bf6":["9bb9a29a5e71a90295f175df8919802993142c9a"],"71387d8cb6923eb831b17a8b734608ba2e21c653":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}