{"path":"solr/core/src/test/org/apache/solr/cloud/hdfs/HdfsTestUtil#checkOverriddenHadoopClasses().mjava","commits":[{"id":"409345735eb58c07b0f83122ae6f13899831234e","date":1576204058,"type":0,"author":"Kevin Risden","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/hdfs/HdfsTestUtil#checkOverriddenHadoopClasses().mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Ensure that the tests are picking up the modified Hadoop classes\n   */\n  private static void checkOverriddenHadoopClasses() {\n    List<Class<?>> modifiedHadoopClasses = Arrays.asList(BlockPoolSlice.class, DiskChecker.class,\n        FileUtil.class, HardLink.class, HttpServer2.class, NameNodeResourceChecker.class, RawLocalFileSystem.class);\n    for (Class<?> clazz : modifiedHadoopClasses) {\n      try {\n        LuceneTestCase.assertNotNull(\"Field on \" + clazz.getCanonicalName() + \" should not have been null\",\n            clazz.getField(SOLR_HACK_FOR_CLASS_VERIFICATION_FIELD));\n      } catch (NoSuchFieldException e) {\n        LuceneTestCase.fail(\"Expected to load Solr modified Hadoop class \" + clazz.getCanonicalName() +\n            \" , but it was not found.\");\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f6abc35f056fb21f759228d3abc8a471a8721b4a","date":1576230674,"type":0,"author":"Dawid Weiss","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/hdfs/HdfsTestUtil#checkOverriddenHadoopClasses().mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Ensure that the tests are picking up the modified Hadoop classes\n   */\n  private static void checkOverriddenHadoopClasses() {\n    List<Class<?>> modifiedHadoopClasses = Arrays.asList(BlockPoolSlice.class, DiskChecker.class,\n        FileUtil.class, HardLink.class, HttpServer2.class, NameNodeResourceChecker.class, RawLocalFileSystem.class);\n    for (Class<?> clazz : modifiedHadoopClasses) {\n      try {\n        LuceneTestCase.assertNotNull(\"Field on \" + clazz.getCanonicalName() + \" should not have been null\",\n            clazz.getField(SOLR_HACK_FOR_CLASS_VERIFICATION_FIELD));\n      } catch (NoSuchFieldException e) {\n        LuceneTestCase.fail(\"Expected to load Solr modified Hadoop class \" + clazz.getCanonicalName() +\n            \" , but it was not found.\");\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fef3d5dcf4ec9d8c72eecabfca32435e3a33f759","date":1599769533,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/hdfs/HdfsTestUtil#checkOverriddenHadoopClasses().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/hdfs/HdfsTestUtil#checkOverriddenHadoopClasses().mjava","sourceNew":"  /**\n   * Ensure that the tests are picking up the modified Hadoop classes\n   */\n  private static void checkOverriddenHadoopClasses() {\n    List<Class<?>> modifiedHadoopClasses = new ArrayList<>(Arrays.asList(\n        DiskChecker.class,\n        FileUtil.class,\n        HardLink.class,\n        HttpServer2.class,\n        NameNodeResourceChecker.class,\n        RawLocalFileSystem.class));\n    // Dodge weird scope errors from the compiler (SOLR-14417)\n    try {\n      modifiedHadoopClasses.add(\n          Class.forName(\"org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice\"));\n    } catch (Exception e) {\n      throw new RuntimeException(e);\n    }\n\n    for (Class<?> clazz : modifiedHadoopClasses) {\n      try {\n        LuceneTestCase.assertNotNull(\"Field on \" + clazz.getCanonicalName() + \" should not have been null\",\n            clazz.getField(SOLR_HACK_FOR_CLASS_VERIFICATION_FIELD));\n      } catch (NoSuchFieldException e) {\n        LuceneTestCase.fail(\"Expected to load Solr modified Hadoop class \" + clazz.getCanonicalName() +\n            \" , but it was not found.\");\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Ensure that the tests are picking up the modified Hadoop classes\n   */\n  private static void checkOverriddenHadoopClasses() {\n    List<Class<?>> modifiedHadoopClasses = Arrays.asList(BlockPoolSlice.class, DiskChecker.class,\n        FileUtil.class, HardLink.class, HttpServer2.class, NameNodeResourceChecker.class, RawLocalFileSystem.class);\n    for (Class<?> clazz : modifiedHadoopClasses) {\n      try {\n        LuceneTestCase.assertNotNull(\"Field on \" + clazz.getCanonicalName() + \" should not have been null\",\n            clazz.getField(SOLR_HACK_FOR_CLASS_VERIFICATION_FIELD));\n      } catch (NoSuchFieldException e) {\n        LuceneTestCase.fail(\"Expected to load Solr modified Hadoop class \" + clazz.getCanonicalName() +\n            \" , but it was not found.\");\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"fef3d5dcf4ec9d8c72eecabfca32435e3a33f759":["409345735eb58c07b0f83122ae6f13899831234e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"f6abc35f056fb21f759228d3abc8a471a8721b4a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","409345735eb58c07b0f83122ae6f13899831234e"],"409345735eb58c07b0f83122ae6f13899831234e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["fef3d5dcf4ec9d8c72eecabfca32435e3a33f759"]},"commit2Childs":{"fef3d5dcf4ec9d8c72eecabfca32435e3a33f759":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["f6abc35f056fb21f759228d3abc8a471a8721b4a","409345735eb58c07b0f83122ae6f13899831234e"],"f6abc35f056fb21f759228d3abc8a471a8721b4a":[],"409345735eb58c07b0f83122ae6f13899831234e":["fef3d5dcf4ec9d8c72eecabfca32435e3a33f759","f6abc35f056fb21f759228d3abc8a471a8721b4a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["f6abc35f056fb21f759228d3abc8a471a8721b4a","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}