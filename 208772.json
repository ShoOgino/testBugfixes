{"path":"solr/core/src/java/org/apache/solr/spelling/FileBasedSpellChecker#loadExternalFileDictionary(SolrCore).mjava","commits":[{"id":"c903c3d15906a3da96b8c0c2fb704491005fdbdb","date":1453508227,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/spelling/FileBasedSpellChecker#loadExternalFileDictionary(SolrCore).mjava","pathOld":"solr/src/java/org/apache/solr/spelling/FileBasedSpellChecker#loadExternalFileDictionary(SolrCore).mjava","sourceNew":"  private void loadExternalFileDictionary(SolrCore core) {\n    try {\n\n      // Get the field's analyzer\n      if (fieldTypeName != null && core.getSchema().getFieldTypeNoEx(fieldTypeName) != null) {\n        FieldType fieldType = core.getSchema().getFieldTypes().get(fieldTypeName);\n        // Do index-time analysis using the given fieldType's analyzer\n        RAMDirectory ramDir = new RAMDirectory();\n\n        LogMergePolicy mp = new LogByteSizeMergePolicy();\n        mp.setMergeFactor(300);\n\n        IndexWriter writer = new IndexWriter(\n            ramDir,\n            new IndexWriterConfig(core.getSolrConfig().luceneMatchVersion, fieldType.getAnalyzer()).\n                setMaxBufferedDocs(150).\n                setMergePolicy(mp).\n                setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n        );\n\n        List<String> lines = core.getResourceLoader().getLines(sourceLocation, characterEncoding);\n\n        for (String s : lines) {\n          Document d = new Document();\n          d.add(new Field(WORD_FIELD_NAME, s, Field.Store.NO, Field.Index.ANALYZED));\n          writer.addDocument(d);\n        }\n        writer.optimize();\n        writer.close();\n\n        dictionary = new HighFrequencyDictionary(IndexReader.open(ramDir),\n                WORD_FIELD_NAME, 0.0f);\n      } else {\n        // check if character encoding is defined\n        if (characterEncoding == null) {\n          dictionary = new PlainTextDictionary(core.getResourceLoader().openResource(sourceLocation));\n        } else {\n          dictionary = new PlainTextDictionary(new InputStreamReader(core.getResourceLoader().openResource(sourceLocation), characterEncoding));\n        }\n      }\n\n\n    } catch (IOException e) {\n      log.error( \"Unable to load spellings\", e);\n    }\n  }\n\n","sourceOld":"  private void loadExternalFileDictionary(SolrCore core) {\n    try {\n\n      // Get the field's analyzer\n      if (fieldTypeName != null && core.getSchema().getFieldTypeNoEx(fieldTypeName) != null) {\n        FieldType fieldType = core.getSchema().getFieldTypes().get(fieldTypeName);\n        // Do index-time analysis using the given fieldType's analyzer\n        RAMDirectory ramDir = new RAMDirectory();\n\n        LogMergePolicy mp = new LogByteSizeMergePolicy();\n        mp.setMergeFactor(300);\n\n        IndexWriter writer = new IndexWriter(\n            ramDir,\n            new IndexWriterConfig(core.getSolrConfig().luceneMatchVersion, fieldType.getAnalyzer()).\n                setMaxBufferedDocs(150).\n                setMergePolicy(mp).\n                setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n        );\n\n        List<String> lines = core.getResourceLoader().getLines(sourceLocation, characterEncoding);\n\n        for (String s : lines) {\n          Document d = new Document();\n          d.add(new Field(WORD_FIELD_NAME, s, Field.Store.NO, Field.Index.ANALYZED));\n          writer.addDocument(d);\n        }\n        writer.optimize();\n        writer.close();\n\n        dictionary = new HighFrequencyDictionary(IndexReader.open(ramDir),\n                WORD_FIELD_NAME, 0.0f);\n      } else {\n        // check if character encoding is defined\n        if (characterEncoding == null) {\n          dictionary = new PlainTextDictionary(core.getResourceLoader().openResource(sourceLocation));\n        } else {\n          dictionary = new PlainTextDictionary(new InputStreamReader(core.getResourceLoader().openResource(sourceLocation), characterEncoding));\n        }\n      }\n\n\n    } catch (IOException e) {\n      log.error( \"Unable to load spellings\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a258fbb26824fd104ed795e5d9033d2d040049ee","date":1453508252,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/spelling/FileBasedSpellChecker#loadExternalFileDictionary(SolrCore).mjava","pathOld":"solr/src/java/org/apache/solr/spelling/FileBasedSpellChecker#loadExternalFileDictionary(SolrCore).mjava","sourceNew":"  private void loadExternalFileDictionary(SolrCore core) {\n    try {\n\n      // Get the field's analyzer\n      if (fieldTypeName != null && core.getSchema().getFieldTypeNoEx(fieldTypeName) != null) {\n        FieldType fieldType = core.getSchema().getFieldTypes().get(fieldTypeName);\n        // Do index-time analysis using the given fieldType's analyzer\n        RAMDirectory ramDir = new RAMDirectory();\n\n        LogMergePolicy mp = new LogByteSizeMergePolicy();\n        mp.setMergeFactor(300);\n\n        IndexWriter writer = new IndexWriter(\n            ramDir,\n            new IndexWriterConfig(core.getSolrConfig().luceneMatchVersion, fieldType.getAnalyzer()).\n                setMaxBufferedDocs(150).\n                setMergePolicy(mp).\n                setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n        );\n\n        List<String> lines = core.getResourceLoader().getLines(sourceLocation, characterEncoding);\n\n        for (String s : lines) {\n          Document d = new Document();\n          d.add(new Field(WORD_FIELD_NAME, s, Field.Store.NO, Field.Index.ANALYZED));\n          writer.addDocument(d);\n        }\n        writer.optimize();\n        writer.close();\n\n        dictionary = new HighFrequencyDictionary(IndexReader.open(ramDir),\n                WORD_FIELD_NAME, 0.0f);\n      } else {\n        // check if character encoding is defined\n        if (characterEncoding == null) {\n          dictionary = new PlainTextDictionary(core.getResourceLoader().openResource(sourceLocation));\n        } else {\n          dictionary = new PlainTextDictionary(new InputStreamReader(core.getResourceLoader().openResource(sourceLocation), characterEncoding));\n        }\n      }\n\n\n    } catch (IOException e) {\n      log.error( \"Unable to load spellings\", e);\n    }\n  }\n\n","sourceOld":"  private void loadExternalFileDictionary(SolrCore core) {\n    try {\n\n      // Get the field's analyzer\n      if (fieldTypeName != null && core.getSchema().getFieldTypeNoEx(fieldTypeName) != null) {\n        FieldType fieldType = core.getSchema().getFieldTypes().get(fieldTypeName);\n        // Do index-time analysis using the given fieldType's analyzer\n        RAMDirectory ramDir = new RAMDirectory();\n\n        LogMergePolicy mp = new LogByteSizeMergePolicy();\n        mp.setMergeFactor(300);\n\n        IndexWriter writer = new IndexWriter(\n            ramDir,\n            new IndexWriterConfig(core.getSolrConfig().luceneMatchVersion, fieldType.getAnalyzer()).\n                setMaxBufferedDocs(150).\n                setMergePolicy(mp).\n                setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n        );\n\n        List<String> lines = core.getResourceLoader().getLines(sourceLocation, characterEncoding);\n\n        for (String s : lines) {\n          Document d = new Document();\n          d.add(new Field(WORD_FIELD_NAME, s, Field.Store.NO, Field.Index.ANALYZED));\n          writer.addDocument(d);\n        }\n        writer.optimize();\n        writer.close();\n\n        dictionary = new HighFrequencyDictionary(IndexReader.open(ramDir),\n                WORD_FIELD_NAME, 0.0f);\n      } else {\n        // check if character encoding is defined\n        if (characterEncoding == null) {\n          dictionary = new PlainTextDictionary(core.getResourceLoader().openResource(sourceLocation));\n        } else {\n          dictionary = new PlainTextDictionary(new InputStreamReader(core.getResourceLoader().openResource(sourceLocation), characterEncoding));\n        }\n      }\n\n\n    } catch (IOException e) {\n      log.error( \"Unable to load spellings\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c26f00b574427b55127e869b935845554afde1fa","date":1310252513,"type":1,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/spelling/FileBasedSpellChecker#loadExternalFileDictionary(SolrCore).mjava","pathOld":"solr/src/java/org/apache/solr/spelling/FileBasedSpellChecker#loadExternalFileDictionary(SolrCore).mjava","sourceNew":"  private void loadExternalFileDictionary(SolrCore core) {\n    try {\n\n      // Get the field's analyzer\n      if (fieldTypeName != null && core.getSchema().getFieldTypeNoEx(fieldTypeName) != null) {\n        FieldType fieldType = core.getSchema().getFieldTypes().get(fieldTypeName);\n        // Do index-time analysis using the given fieldType's analyzer\n        RAMDirectory ramDir = new RAMDirectory();\n\n        LogMergePolicy mp = new LogByteSizeMergePolicy();\n        mp.setMergeFactor(300);\n\n        IndexWriter writer = new IndexWriter(\n            ramDir,\n            new IndexWriterConfig(core.getSolrConfig().luceneMatchVersion, fieldType.getAnalyzer()).\n                setMaxBufferedDocs(150).\n                setMergePolicy(mp).\n                setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n        );\n\n        List<String> lines = core.getResourceLoader().getLines(sourceLocation, characterEncoding);\n\n        for (String s : lines) {\n          Document d = new Document();\n          d.add(new Field(WORD_FIELD_NAME, s, Field.Store.NO, Field.Index.ANALYZED));\n          writer.addDocument(d);\n        }\n        writer.optimize();\n        writer.close();\n\n        dictionary = new HighFrequencyDictionary(IndexReader.open(ramDir),\n                WORD_FIELD_NAME, 0.0f);\n      } else {\n        // check if character encoding is defined\n        if (characterEncoding == null) {\n          dictionary = new PlainTextDictionary(core.getResourceLoader().openResource(sourceLocation));\n        } else {\n          dictionary = new PlainTextDictionary(new InputStreamReader(core.getResourceLoader().openResource(sourceLocation), characterEncoding));\n        }\n      }\n\n\n    } catch (IOException e) {\n      log.error( \"Unable to load spellings\", e);\n    }\n  }\n\n","sourceOld":"  private void loadExternalFileDictionary(SolrCore core) {\n    try {\n\n      // Get the field's analyzer\n      if (fieldTypeName != null && core.getSchema().getFieldTypeNoEx(fieldTypeName) != null) {\n        FieldType fieldType = core.getSchema().getFieldTypes().get(fieldTypeName);\n        // Do index-time analysis using the given fieldType's analyzer\n        RAMDirectory ramDir = new RAMDirectory();\n\n        LogMergePolicy mp = new LogByteSizeMergePolicy();\n        mp.setMergeFactor(300);\n\n        IndexWriter writer = new IndexWriter(\n            ramDir,\n            new IndexWriterConfig(core.getSolrConfig().luceneMatchVersion, fieldType.getAnalyzer()).\n                setMaxBufferedDocs(150).\n                setMergePolicy(mp).\n                setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n        );\n\n        List<String> lines = core.getResourceLoader().getLines(sourceLocation, characterEncoding);\n\n        for (String s : lines) {\n          Document d = new Document();\n          d.add(new Field(WORD_FIELD_NAME, s, Field.Store.NO, Field.Index.ANALYZED));\n          writer.addDocument(d);\n        }\n        writer.optimize();\n        writer.close();\n\n        dictionary = new HighFrequencyDictionary(IndexReader.open(ramDir),\n                WORD_FIELD_NAME, 0.0f);\n      } else {\n        // check if character encoding is defined\n        if (characterEncoding == null) {\n          dictionary = new PlainTextDictionary(core.getResourceLoader().openResource(sourceLocation));\n        } else {\n          dictionary = new PlainTextDictionary(new InputStreamReader(core.getResourceLoader().openResource(sourceLocation), characterEncoding));\n        }\n      }\n\n\n    } catch (IOException e) {\n      log.error( \"Unable to load spellings\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1509f151d7692d84fae414b2b799ac06ba60fcb4","date":1314451621,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/spelling/FileBasedSpellChecker#loadExternalFileDictionary(SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/spelling/FileBasedSpellChecker#loadExternalFileDictionary(SolrCore).mjava","sourceNew":"  private void loadExternalFileDictionary(SolrCore core) {\n    try {\n\n      // Get the field's analyzer\n      if (fieldTypeName != null && core.getSchema().getFieldTypeNoEx(fieldTypeName) != null) {\n        FieldType fieldType = core.getSchema().getFieldTypes().get(fieldTypeName);\n        // Do index-time analysis using the given fieldType's analyzer\n        RAMDirectory ramDir = new RAMDirectory();\n\n        LogMergePolicy mp = new LogByteSizeMergePolicy();\n        mp.setMergeFactor(300);\n\n        IndexWriter writer = new IndexWriter(\n            ramDir,\n            new IndexWriterConfig(core.getSolrConfig().luceneMatchVersion, fieldType.getAnalyzer()).\n                setMaxBufferedDocs(150).\n                setMergePolicy(mp).\n                setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n        );\n\n        List<String> lines = core.getResourceLoader().getLines(sourceLocation, characterEncoding);\n\n        for (String s : lines) {\n          Document d = new Document();\n          d.add(new TextField(WORD_FIELD_NAME, s));\n          writer.addDocument(d);\n        }\n        writer.optimize();\n        writer.close();\n\n        dictionary = new HighFrequencyDictionary(IndexReader.open(ramDir),\n                WORD_FIELD_NAME, 0.0f);\n      } else {\n        // check if character encoding is defined\n        if (characterEncoding == null) {\n          dictionary = new PlainTextDictionary(core.getResourceLoader().openResource(sourceLocation));\n        } else {\n          dictionary = new PlainTextDictionary(new InputStreamReader(core.getResourceLoader().openResource(sourceLocation), characterEncoding));\n        }\n      }\n\n\n    } catch (IOException e) {\n      log.error( \"Unable to load spellings\", e);\n    }\n  }\n\n","sourceOld":"  private void loadExternalFileDictionary(SolrCore core) {\n    try {\n\n      // Get the field's analyzer\n      if (fieldTypeName != null && core.getSchema().getFieldTypeNoEx(fieldTypeName) != null) {\n        FieldType fieldType = core.getSchema().getFieldTypes().get(fieldTypeName);\n        // Do index-time analysis using the given fieldType's analyzer\n        RAMDirectory ramDir = new RAMDirectory();\n\n        LogMergePolicy mp = new LogByteSizeMergePolicy();\n        mp.setMergeFactor(300);\n\n        IndexWriter writer = new IndexWriter(\n            ramDir,\n            new IndexWriterConfig(core.getSolrConfig().luceneMatchVersion, fieldType.getAnalyzer()).\n                setMaxBufferedDocs(150).\n                setMergePolicy(mp).\n                setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n        );\n\n        List<String> lines = core.getResourceLoader().getLines(sourceLocation, characterEncoding);\n\n        for (String s : lines) {\n          Document d = new Document();\n          d.add(new Field(WORD_FIELD_NAME, s, Field.Store.NO, Field.Index.ANALYZED));\n          writer.addDocument(d);\n        }\n        writer.optimize();\n        writer.close();\n\n        dictionary = new HighFrequencyDictionary(IndexReader.open(ramDir),\n                WORD_FIELD_NAME, 0.0f);\n      } else {\n        // check if character encoding is defined\n        if (characterEncoding == null) {\n          dictionary = new PlainTextDictionary(core.getResourceLoader().openResource(sourceLocation));\n        } else {\n          dictionary = new PlainTextDictionary(new InputStreamReader(core.getResourceLoader().openResource(sourceLocation), characterEncoding));\n        }\n      }\n\n\n    } catch (IOException e) {\n      log.error( \"Unable to load spellings\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7b91922b55d15444d554721b352861d028eb8278","date":1320421415,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/spelling/FileBasedSpellChecker#loadExternalFileDictionary(SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/spelling/FileBasedSpellChecker#loadExternalFileDictionary(SolrCore).mjava","sourceNew":"  private void loadExternalFileDictionary(SolrCore core) {\n    try {\n\n      // Get the field's analyzer\n      if (fieldTypeName != null && core.getSchema().getFieldTypeNoEx(fieldTypeName) != null) {\n        FieldType fieldType = core.getSchema().getFieldTypes().get(fieldTypeName);\n        // Do index-time analysis using the given fieldType's analyzer\n        RAMDirectory ramDir = new RAMDirectory();\n\n        LogMergePolicy mp = new LogByteSizeMergePolicy();\n        mp.setMergeFactor(300);\n\n        IndexWriter writer = new IndexWriter(\n            ramDir,\n            new IndexWriterConfig(core.getSolrConfig().luceneMatchVersion, fieldType.getAnalyzer()).\n                setMaxBufferedDocs(150).\n                setMergePolicy(mp).\n                setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n                // TODO: if we enable this, codec gets angry since field won't exist in the schema\n                // .setCodec(core.getCodec())\n        );\n\n        List<String> lines = core.getResourceLoader().getLines(sourceLocation, characterEncoding);\n\n        for (String s : lines) {\n          Document d = new Document();\n          d.add(new TextField(WORD_FIELD_NAME, s));\n          writer.addDocument(d);\n        }\n        writer.optimize();\n        writer.close();\n\n        dictionary = new HighFrequencyDictionary(IndexReader.open(ramDir, true),\n                WORD_FIELD_NAME, 0.0f);\n      } else {\n        // check if character encoding is defined\n        if (characterEncoding == null) {\n          dictionary = new PlainTextDictionary(core.getResourceLoader().openResource(sourceLocation));\n        } else {\n          dictionary = new PlainTextDictionary(new InputStreamReader(core.getResourceLoader().openResource(sourceLocation), characterEncoding));\n        }\n      }\n\n\n    } catch (IOException e) {\n      log.error( \"Unable to load spellings\", e);\n    }\n  }\n\n","sourceOld":"  private void loadExternalFileDictionary(SolrCore core) {\n    try {\n\n      // Get the field's analyzer\n      if (fieldTypeName != null && core.getSchema().getFieldTypeNoEx(fieldTypeName) != null) {\n        FieldType fieldType = core.getSchema().getFieldTypes().get(fieldTypeName);\n        // Do index-time analysis using the given fieldType's analyzer\n        RAMDirectory ramDir = new RAMDirectory();\n\n        LogMergePolicy mp = new LogByteSizeMergePolicy();\n        mp.setMergeFactor(300);\n\n        IndexWriter writer = new IndexWriter(\n            ramDir,\n            new IndexWriterConfig(core.getSolrConfig().luceneMatchVersion, fieldType.getAnalyzer()).\n                setMaxBufferedDocs(150).\n                setMergePolicy(mp).\n                setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n        );\n\n        List<String> lines = core.getResourceLoader().getLines(sourceLocation, characterEncoding);\n\n        for (String s : lines) {\n          Document d = new Document();\n          d.add(new TextField(WORD_FIELD_NAME, s));\n          writer.addDocument(d);\n        }\n        writer.optimize();\n        writer.close();\n\n        dictionary = new HighFrequencyDictionary(IndexReader.open(ramDir),\n                WORD_FIELD_NAME, 0.0f);\n      } else {\n        // check if character encoding is defined\n        if (characterEncoding == null) {\n          dictionary = new PlainTextDictionary(core.getResourceLoader().openResource(sourceLocation));\n        } else {\n          dictionary = new PlainTextDictionary(new InputStreamReader(core.getResourceLoader().openResource(sourceLocation), characterEncoding));\n        }\n      }\n\n\n    } catch (IOException e) {\n      log.error( \"Unable to load spellings\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d14e8d18c0e3970c20354dbeeb49da11bd587fbd","date":1321041051,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/spelling/FileBasedSpellChecker#loadExternalFileDictionary(SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/spelling/FileBasedSpellChecker#loadExternalFileDictionary(SolrCore).mjava","sourceNew":"  private void loadExternalFileDictionary(SolrCore core) {\n    try {\n\n      // Get the field's analyzer\n      if (fieldTypeName != null && core.getSchema().getFieldTypeNoEx(fieldTypeName) != null) {\n        FieldType fieldType = core.getSchema().getFieldTypes().get(fieldTypeName);\n        // Do index-time analysis using the given fieldType's analyzer\n        RAMDirectory ramDir = new RAMDirectory();\n\n        LogMergePolicy mp = new LogByteSizeMergePolicy();\n        mp.setMergeFactor(300);\n\n        IndexWriter writer = new IndexWriter(\n            ramDir,\n            new IndexWriterConfig(core.getSolrConfig().luceneMatchVersion, fieldType.getAnalyzer()).\n                setMaxBufferedDocs(150).\n                setMergePolicy(mp).\n                setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n                // TODO: if we enable this, codec gets angry since field won't exist in the schema\n                // .setCodec(core.getCodec())\n        );\n\n        List<String> lines = core.getResourceLoader().getLines(sourceLocation, characterEncoding);\n\n        for (String s : lines) {\n          Document d = new Document();\n          d.add(new TextField(WORD_FIELD_NAME, s));\n          writer.addDocument(d);\n        }\n        writer.forceMerge(1);\n        writer.close();\n\n        dictionary = new HighFrequencyDictionary(IndexReader.open(ramDir, true),\n                WORD_FIELD_NAME, 0.0f);\n      } else {\n        // check if character encoding is defined\n        if (characterEncoding == null) {\n          dictionary = new PlainTextDictionary(core.getResourceLoader().openResource(sourceLocation));\n        } else {\n          dictionary = new PlainTextDictionary(new InputStreamReader(core.getResourceLoader().openResource(sourceLocation), characterEncoding));\n        }\n      }\n\n\n    } catch (IOException e) {\n      log.error( \"Unable to load spellings\", e);\n    }\n  }\n\n","sourceOld":"  private void loadExternalFileDictionary(SolrCore core) {\n    try {\n\n      // Get the field's analyzer\n      if (fieldTypeName != null && core.getSchema().getFieldTypeNoEx(fieldTypeName) != null) {\n        FieldType fieldType = core.getSchema().getFieldTypes().get(fieldTypeName);\n        // Do index-time analysis using the given fieldType's analyzer\n        RAMDirectory ramDir = new RAMDirectory();\n\n        LogMergePolicy mp = new LogByteSizeMergePolicy();\n        mp.setMergeFactor(300);\n\n        IndexWriter writer = new IndexWriter(\n            ramDir,\n            new IndexWriterConfig(core.getSolrConfig().luceneMatchVersion, fieldType.getAnalyzer()).\n                setMaxBufferedDocs(150).\n                setMergePolicy(mp).\n                setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n                // TODO: if we enable this, codec gets angry since field won't exist in the schema\n                // .setCodec(core.getCodec())\n        );\n\n        List<String> lines = core.getResourceLoader().getLines(sourceLocation, characterEncoding);\n\n        for (String s : lines) {\n          Document d = new Document();\n          d.add(new TextField(WORD_FIELD_NAME, s));\n          writer.addDocument(d);\n        }\n        writer.optimize();\n        writer.close();\n\n        dictionary = new HighFrequencyDictionary(IndexReader.open(ramDir, true),\n                WORD_FIELD_NAME, 0.0f);\n      } else {\n        // check if character encoding is defined\n        if (characterEncoding == null) {\n          dictionary = new PlainTextDictionary(core.getResourceLoader().openResource(sourceLocation));\n        } else {\n          dictionary = new PlainTextDictionary(new InputStreamReader(core.getResourceLoader().openResource(sourceLocation), characterEncoding));\n        }\n      }\n\n\n    } catch (IOException e) {\n      log.error( \"Unable to load spellings\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1c5b026d03cbbb03ca4c0b97d14e9839682281dc","date":1323049298,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/spelling/FileBasedSpellChecker#loadExternalFileDictionary(SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/spelling/FileBasedSpellChecker#loadExternalFileDictionary(SolrCore).mjava","sourceNew":"  private void loadExternalFileDictionary(SolrCore core) {\n    try {\n\n      // Get the field's analyzer\n      if (fieldTypeName != null && core.getSchema().getFieldTypeNoEx(fieldTypeName) != null) {\n        FieldType fieldType = core.getSchema().getFieldTypes().get(fieldTypeName);\n        // Do index-time analysis using the given fieldType's analyzer\n        RAMDirectory ramDir = new RAMDirectory();\n\n        LogMergePolicy mp = new LogByteSizeMergePolicy();\n        mp.setMergeFactor(300);\n\n        IndexWriter writer = new IndexWriter(\n            ramDir,\n            new IndexWriterConfig(core.getSolrConfig().luceneMatchVersion, fieldType.getAnalyzer()).\n                setMaxBufferedDocs(150).\n                setMergePolicy(mp).\n                setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n                // TODO: if we enable this, codec gets angry since field won't exist in the schema\n                // .setCodec(core.getCodec())\n        );\n\n        List<String> lines = core.getResourceLoader().getLines(sourceLocation, characterEncoding);\n\n        for (String s : lines) {\n          Document d = new Document();\n          d.add(new TextField(WORD_FIELD_NAME, s));\n          writer.addDocument(d);\n        }\n        writer.forceMerge(1);\n        writer.close();\n\n        dictionary = new HighFrequencyDictionary(IndexReader.open(ramDir),\n                WORD_FIELD_NAME, 0.0f);\n      } else {\n        // check if character encoding is defined\n        if (characterEncoding == null) {\n          dictionary = new PlainTextDictionary(core.getResourceLoader().openResource(sourceLocation));\n        } else {\n          dictionary = new PlainTextDictionary(new InputStreamReader(core.getResourceLoader().openResource(sourceLocation), characterEncoding));\n        }\n      }\n\n\n    } catch (IOException e) {\n      log.error( \"Unable to load spellings\", e);\n    }\n  }\n\n","sourceOld":"  private void loadExternalFileDictionary(SolrCore core) {\n    try {\n\n      // Get the field's analyzer\n      if (fieldTypeName != null && core.getSchema().getFieldTypeNoEx(fieldTypeName) != null) {\n        FieldType fieldType = core.getSchema().getFieldTypes().get(fieldTypeName);\n        // Do index-time analysis using the given fieldType's analyzer\n        RAMDirectory ramDir = new RAMDirectory();\n\n        LogMergePolicy mp = new LogByteSizeMergePolicy();\n        mp.setMergeFactor(300);\n\n        IndexWriter writer = new IndexWriter(\n            ramDir,\n            new IndexWriterConfig(core.getSolrConfig().luceneMatchVersion, fieldType.getAnalyzer()).\n                setMaxBufferedDocs(150).\n                setMergePolicy(mp).\n                setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n                // TODO: if we enable this, codec gets angry since field won't exist in the schema\n                // .setCodec(core.getCodec())\n        );\n\n        List<String> lines = core.getResourceLoader().getLines(sourceLocation, characterEncoding);\n\n        for (String s : lines) {\n          Document d = new Document();\n          d.add(new TextField(WORD_FIELD_NAME, s));\n          writer.addDocument(d);\n        }\n        writer.forceMerge(1);\n        writer.close();\n\n        dictionary = new HighFrequencyDictionary(IndexReader.open(ramDir, true),\n                WORD_FIELD_NAME, 0.0f);\n      } else {\n        // check if character encoding is defined\n        if (characterEncoding == null) {\n          dictionary = new PlainTextDictionary(core.getResourceLoader().openResource(sourceLocation));\n        } else {\n          dictionary = new PlainTextDictionary(new InputStreamReader(core.getResourceLoader().openResource(sourceLocation), characterEncoding));\n        }\n      }\n\n\n    } catch (IOException e) {\n      log.error( \"Unable to load spellings\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3615ce4a1f785ae1b779244de52c6a7d99227e60","date":1323422019,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/spelling/FileBasedSpellChecker#loadExternalFileDictionary(SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/spelling/FileBasedSpellChecker#loadExternalFileDictionary(SolrCore).mjava","sourceNew":"  private void loadExternalFileDictionary(SolrCore core) {\n    try {\n\n      // Get the field's analyzer\n      if (fieldTypeName != null && core.getSchema().getFieldTypeNoEx(fieldTypeName) != null) {\n        FieldType fieldType = core.getSchema().getFieldTypes().get(fieldTypeName);\n        // Do index-time analysis using the given fieldType's analyzer\n        RAMDirectory ramDir = new RAMDirectory();\n\n        LogMergePolicy mp = new LogByteSizeMergePolicy();\n        mp.setMergeFactor(300);\n\n        IndexWriter writer = new IndexWriter(\n            ramDir,\n            new IndexWriterConfig(core.getSolrConfig().luceneMatchVersion, fieldType.getAnalyzer()).\n                setMaxBufferedDocs(150).\n                setMergePolicy(mp).\n                setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n                // TODO: if we enable this, codec gets angry since field won't exist in the schema\n                // .setCodec(core.getCodec())\n        );\n\n        List<String> lines = core.getResourceLoader().getLines(sourceLocation, characterEncoding);\n\n        for (String s : lines) {\n          Document d = new Document();\n          d.add(new TextField(WORD_FIELD_NAME, s));\n          writer.addDocument(d);\n        }\n        writer.forceMerge(1);\n        writer.close();\n\n        dictionary = new HighFrequencyDictionary(IndexReader.open(ramDir),\n                WORD_FIELD_NAME, 0.0f);\n      } else {\n        // check if character encoding is defined\n        if (characterEncoding == null) {\n          dictionary = new PlainTextDictionary(core.getResourceLoader().openResource(sourceLocation));\n        } else {\n          dictionary = new PlainTextDictionary(new InputStreamReader(core.getResourceLoader().openResource(sourceLocation), characterEncoding));\n        }\n      }\n\n\n    } catch (IOException e) {\n      log.error( \"Unable to load spellings\", e);\n    }\n  }\n\n","sourceOld":"  private void loadExternalFileDictionary(SolrCore core) {\n    try {\n\n      // Get the field's analyzer\n      if (fieldTypeName != null && core.getSchema().getFieldTypeNoEx(fieldTypeName) != null) {\n        FieldType fieldType = core.getSchema().getFieldTypes().get(fieldTypeName);\n        // Do index-time analysis using the given fieldType's analyzer\n        RAMDirectory ramDir = new RAMDirectory();\n\n        LogMergePolicy mp = new LogByteSizeMergePolicy();\n        mp.setMergeFactor(300);\n\n        IndexWriter writer = new IndexWriter(\n            ramDir,\n            new IndexWriterConfig(core.getSolrConfig().luceneMatchVersion, fieldType.getAnalyzer()).\n                setMaxBufferedDocs(150).\n                setMergePolicy(mp).\n                setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n                // TODO: if we enable this, codec gets angry since field won't exist in the schema\n                // .setCodec(core.getCodec())\n        );\n\n        List<String> lines = core.getResourceLoader().getLines(sourceLocation, characterEncoding);\n\n        for (String s : lines) {\n          Document d = new Document();\n          d.add(new TextField(WORD_FIELD_NAME, s));\n          writer.addDocument(d);\n        }\n        writer.forceMerge(1);\n        writer.close();\n\n        dictionary = new HighFrequencyDictionary(IndexReader.open(ramDir, true),\n                WORD_FIELD_NAME, 0.0f);\n      } else {\n        // check if character encoding is defined\n        if (characterEncoding == null) {\n          dictionary = new PlainTextDictionary(core.getResourceLoader().openResource(sourceLocation));\n        } else {\n          dictionary = new PlainTextDictionary(new InputStreamReader(core.getResourceLoader().openResource(sourceLocation), characterEncoding));\n        }\n      }\n\n\n    } catch (IOException e) {\n      log.error( \"Unable to load spellings\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","date":1323437438,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/spelling/FileBasedSpellChecker#loadExternalFileDictionary(SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/spelling/FileBasedSpellChecker#loadExternalFileDictionary(SolrCore).mjava","sourceNew":"  private void loadExternalFileDictionary(SolrCore core) {\n    try {\n\n      // Get the field's analyzer\n      if (fieldTypeName != null && core.getSchema().getFieldTypeNoEx(fieldTypeName) != null) {\n        FieldType fieldType = core.getSchema().getFieldTypes().get(fieldTypeName);\n        // Do index-time analysis using the given fieldType's analyzer\n        RAMDirectory ramDir = new RAMDirectory();\n\n        LogMergePolicy mp = new LogByteSizeMergePolicy();\n        mp.setMergeFactor(300);\n\n        IndexWriter writer = new IndexWriter(\n            ramDir,\n            new IndexWriterConfig(core.getSolrConfig().luceneMatchVersion, fieldType.getAnalyzer()).\n                setMaxBufferedDocs(150).\n                setMergePolicy(mp).\n                setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n                // TODO: if we enable this, codec gets angry since field won't exist in the schema\n                // .setCodec(core.getCodec())\n        );\n\n        List<String> lines = core.getResourceLoader().getLines(sourceLocation, characterEncoding);\n\n        for (String s : lines) {\n          Document d = new Document();\n          d.add(new TextField(WORD_FIELD_NAME, s));\n          writer.addDocument(d);\n        }\n        writer.forceMerge(1);\n        writer.close();\n\n        dictionary = new HighFrequencyDictionary(IndexReader.open(ramDir),\n                WORD_FIELD_NAME, 0.0f);\n      } else {\n        // check if character encoding is defined\n        if (characterEncoding == null) {\n          dictionary = new PlainTextDictionary(core.getResourceLoader().openResource(sourceLocation));\n        } else {\n          dictionary = new PlainTextDictionary(new InputStreamReader(core.getResourceLoader().openResource(sourceLocation), characterEncoding));\n        }\n      }\n\n\n    } catch (IOException e) {\n      log.error( \"Unable to load spellings\", e);\n    }\n  }\n\n","sourceOld":"  private void loadExternalFileDictionary(SolrCore core) {\n    try {\n\n      // Get the field's analyzer\n      if (fieldTypeName != null && core.getSchema().getFieldTypeNoEx(fieldTypeName) != null) {\n        FieldType fieldType = core.getSchema().getFieldTypes().get(fieldTypeName);\n        // Do index-time analysis using the given fieldType's analyzer\n        RAMDirectory ramDir = new RAMDirectory();\n\n        LogMergePolicy mp = new LogByteSizeMergePolicy();\n        mp.setMergeFactor(300);\n\n        IndexWriter writer = new IndexWriter(\n            ramDir,\n            new IndexWriterConfig(core.getSolrConfig().luceneMatchVersion, fieldType.getAnalyzer()).\n                setMaxBufferedDocs(150).\n                setMergePolicy(mp).\n                setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n                // TODO: if we enable this, codec gets angry since field won't exist in the schema\n                // .setCodec(core.getCodec())\n        );\n\n        List<String> lines = core.getResourceLoader().getLines(sourceLocation, characterEncoding);\n\n        for (String s : lines) {\n          Document d = new Document();\n          d.add(new TextField(WORD_FIELD_NAME, s));\n          writer.addDocument(d);\n        }\n        writer.forceMerge(1);\n        writer.close();\n\n        dictionary = new HighFrequencyDictionary(IndexReader.open(ramDir, true),\n                WORD_FIELD_NAME, 0.0f);\n      } else {\n        // check if character encoding is defined\n        if (characterEncoding == null) {\n          dictionary = new PlainTextDictionary(core.getResourceLoader().openResource(sourceLocation));\n        } else {\n          dictionary = new PlainTextDictionary(new InputStreamReader(core.getResourceLoader().openResource(sourceLocation), characterEncoding));\n        }\n      }\n\n\n    } catch (IOException e) {\n      log.error( \"Unable to load spellings\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f","date":1338430031,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/spelling/FileBasedSpellChecker#loadExternalFileDictionary(SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/spelling/FileBasedSpellChecker#loadExternalFileDictionary(SolrCore).mjava","sourceNew":"  private void loadExternalFileDictionary(SolrCore core) {\n    try {\n\n      // Get the field's analyzer\n      if (fieldTypeName != null && core.getSchema().getFieldTypeNoEx(fieldTypeName) != null) {\n        FieldType fieldType = core.getSchema().getFieldTypes().get(fieldTypeName);\n        // Do index-time analysis using the given fieldType's analyzer\n        RAMDirectory ramDir = new RAMDirectory();\n\n        LogMergePolicy mp = new LogByteSizeMergePolicy();\n        mp.setMergeFactor(300);\n\n        IndexWriter writer = new IndexWriter(\n            ramDir,\n            new IndexWriterConfig(core.getSolrConfig().luceneMatchVersion, fieldType.getAnalyzer()).\n                setMaxBufferedDocs(150).\n                setMergePolicy(mp).\n                setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n                // TODO: if we enable this, codec gets angry since field won't exist in the schema\n                // .setCodec(core.getCodec())\n        );\n\n        List<String> lines = core.getResourceLoader().getLines(sourceLocation, characterEncoding);\n\n        for (String s : lines) {\n          Document d = new Document();\n          d.add(new TextField(WORD_FIELD_NAME, s));\n          writer.addDocument(d);\n        }\n        writer.forceMerge(1);\n        writer.close();\n\n        dictionary = new HighFrequencyDictionary(DirectoryReader.open(ramDir),\n                WORD_FIELD_NAME, 0.0f);\n      } else {\n        // check if character encoding is defined\n        if (characterEncoding == null) {\n          dictionary = new PlainTextDictionary(core.getResourceLoader().openResource(sourceLocation));\n        } else {\n          dictionary = new PlainTextDictionary(new InputStreamReader(core.getResourceLoader().openResource(sourceLocation), characterEncoding));\n        }\n      }\n\n\n    } catch (IOException e) {\n      log.error( \"Unable to load spellings\", e);\n    }\n  }\n\n","sourceOld":"  private void loadExternalFileDictionary(SolrCore core) {\n    try {\n\n      // Get the field's analyzer\n      if (fieldTypeName != null && core.getSchema().getFieldTypeNoEx(fieldTypeName) != null) {\n        FieldType fieldType = core.getSchema().getFieldTypes().get(fieldTypeName);\n        // Do index-time analysis using the given fieldType's analyzer\n        RAMDirectory ramDir = new RAMDirectory();\n\n        LogMergePolicy mp = new LogByteSizeMergePolicy();\n        mp.setMergeFactor(300);\n\n        IndexWriter writer = new IndexWriter(\n            ramDir,\n            new IndexWriterConfig(core.getSolrConfig().luceneMatchVersion, fieldType.getAnalyzer()).\n                setMaxBufferedDocs(150).\n                setMergePolicy(mp).\n                setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n                // TODO: if we enable this, codec gets angry since field won't exist in the schema\n                // .setCodec(core.getCodec())\n        );\n\n        List<String> lines = core.getResourceLoader().getLines(sourceLocation, characterEncoding);\n\n        for (String s : lines) {\n          Document d = new Document();\n          d.add(new TextField(WORD_FIELD_NAME, s));\n          writer.addDocument(d);\n        }\n        writer.forceMerge(1);\n        writer.close();\n\n        dictionary = new HighFrequencyDictionary(IndexReader.open(ramDir),\n                WORD_FIELD_NAME, 0.0f);\n      } else {\n        // check if character encoding is defined\n        if (characterEncoding == null) {\n          dictionary = new PlainTextDictionary(core.getResourceLoader().openResource(sourceLocation));\n        } else {\n          dictionary = new PlainTextDictionary(new InputStreamReader(core.getResourceLoader().openResource(sourceLocation), characterEncoding));\n        }\n      }\n\n\n    } catch (IOException e) {\n      log.error( \"Unable to load spellings\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"04f07771a2a7dd3a395700665ed839c3dae2def2","date":1339350139,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/spelling/FileBasedSpellChecker#loadExternalFileDictionary(SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/spelling/FileBasedSpellChecker#loadExternalFileDictionary(SolrCore).mjava","sourceNew":"  private void loadExternalFileDictionary(SolrCore core) {\n    try {\n\n      // Get the field's analyzer\n      if (fieldTypeName != null && core.getSchema().getFieldTypeNoEx(fieldTypeName) != null) {\n        FieldType fieldType = core.getSchema().getFieldTypes().get(fieldTypeName);\n        // Do index-time analysis using the given fieldType's analyzer\n        RAMDirectory ramDir = new RAMDirectory();\n\n        LogMergePolicy mp = new LogByteSizeMergePolicy();\n        mp.setMergeFactor(300);\n\n        IndexWriter writer = new IndexWriter(\n            ramDir,\n            new IndexWriterConfig(core.getSolrConfig().luceneMatchVersion, fieldType.getAnalyzer()).\n                setMaxBufferedDocs(150).\n                setMergePolicy(mp).\n                setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n                // TODO: if we enable this, codec gets angry since field won't exist in the schema\n                // .setCodec(core.getCodec())\n        );\n\n        List<String> lines = core.getResourceLoader().getLines(sourceLocation, characterEncoding);\n\n        for (String s : lines) {\n          Document d = new Document();\n          d.add(new TextField(WORD_FIELD_NAME, s, Field.Store.NO));\n          writer.addDocument(d);\n        }\n        writer.forceMerge(1);\n        writer.close();\n\n        dictionary = new HighFrequencyDictionary(DirectoryReader.open(ramDir),\n                WORD_FIELD_NAME, 0.0f);\n      } else {\n        // check if character encoding is defined\n        if (characterEncoding == null) {\n          dictionary = new PlainTextDictionary(core.getResourceLoader().openResource(sourceLocation));\n        } else {\n          dictionary = new PlainTextDictionary(new InputStreamReader(core.getResourceLoader().openResource(sourceLocation), characterEncoding));\n        }\n      }\n\n\n    } catch (IOException e) {\n      log.error( \"Unable to load spellings\", e);\n    }\n  }\n\n","sourceOld":"  private void loadExternalFileDictionary(SolrCore core) {\n    try {\n\n      // Get the field's analyzer\n      if (fieldTypeName != null && core.getSchema().getFieldTypeNoEx(fieldTypeName) != null) {\n        FieldType fieldType = core.getSchema().getFieldTypes().get(fieldTypeName);\n        // Do index-time analysis using the given fieldType's analyzer\n        RAMDirectory ramDir = new RAMDirectory();\n\n        LogMergePolicy mp = new LogByteSizeMergePolicy();\n        mp.setMergeFactor(300);\n\n        IndexWriter writer = new IndexWriter(\n            ramDir,\n            new IndexWriterConfig(core.getSolrConfig().luceneMatchVersion, fieldType.getAnalyzer()).\n                setMaxBufferedDocs(150).\n                setMergePolicy(mp).\n                setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n                // TODO: if we enable this, codec gets angry since field won't exist in the schema\n                // .setCodec(core.getCodec())\n        );\n\n        List<String> lines = core.getResourceLoader().getLines(sourceLocation, characterEncoding);\n\n        for (String s : lines) {\n          Document d = new Document();\n          d.add(new TextField(WORD_FIELD_NAME, s));\n          writer.addDocument(d);\n        }\n        writer.forceMerge(1);\n        writer.close();\n\n        dictionary = new HighFrequencyDictionary(DirectoryReader.open(ramDir),\n                WORD_FIELD_NAME, 0.0f);\n      } else {\n        // check if character encoding is defined\n        if (characterEncoding == null) {\n          dictionary = new PlainTextDictionary(core.getResourceLoader().openResource(sourceLocation));\n        } else {\n          dictionary = new PlainTextDictionary(new InputStreamReader(core.getResourceLoader().openResource(sourceLocation), characterEncoding));\n        }\n      }\n\n\n    } catch (IOException e) {\n      log.error( \"Unable to load spellings\", e);\n    }\n  }\n\n","bugFix":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"08970e5b8411182a29412c177eff67ec1110095b","date":1366640815,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/spelling/FileBasedSpellChecker#loadExternalFileDictionary(SolrCore,SolrIndexSearcher).mjava","pathOld":"solr/core/src/java/org/apache/solr/spelling/FileBasedSpellChecker#loadExternalFileDictionary(SolrCore).mjava","sourceNew":"  private void loadExternalFileDictionary(SolrCore core, SolrIndexSearcher searcher) {\n    try {\n      IndexSchema schema = null == searcher ? core.getLatestSchema() : searcher.getSchema();\n      // Get the field's analyzer\n      if (fieldTypeName != null && schema.getFieldTypeNoEx(fieldTypeName) != null) {\n        FieldType fieldType = schema.getFieldTypes().get(fieldTypeName);\n        // Do index-time analysis using the given fieldType's analyzer\n        RAMDirectory ramDir = new RAMDirectory();\n\n        LogMergePolicy mp = new LogByteSizeMergePolicy();\n        mp.setMergeFactor(300);\n\n        IndexWriter writer = new IndexWriter(\n            ramDir,\n            new IndexWriterConfig(core.getSolrConfig().luceneMatchVersion, fieldType.getAnalyzer()).\n                setMaxBufferedDocs(150).\n                setMergePolicy(mp).\n                setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n                // TODO: if we enable this, codec gets angry since field won't exist in the schema\n                // .setCodec(core.getCodec())\n        );\n\n        List<String> lines = core.getResourceLoader().getLines(sourceLocation, characterEncoding);\n\n        for (String s : lines) {\n          Document d = new Document();\n          d.add(new TextField(WORD_FIELD_NAME, s, Field.Store.NO));\n          writer.addDocument(d);\n        }\n        writer.forceMerge(1);\n        writer.close();\n\n        dictionary = new HighFrequencyDictionary(DirectoryReader.open(ramDir),\n                WORD_FIELD_NAME, 0.0f);\n      } else {\n        // check if character encoding is defined\n        if (characterEncoding == null) {\n          dictionary = new PlainTextDictionary(core.getResourceLoader().openResource(sourceLocation));\n        } else {\n          dictionary = new PlainTextDictionary(new InputStreamReader(core.getResourceLoader().openResource(sourceLocation), characterEncoding));\n        }\n      }\n\n\n    } catch (IOException e) {\n      log.error( \"Unable to load spellings\", e);\n    }\n  }\n\n","sourceOld":"  private void loadExternalFileDictionary(SolrCore core) {\n    try {\n\n      // Get the field's analyzer\n      if (fieldTypeName != null && core.getSchema().getFieldTypeNoEx(fieldTypeName) != null) {\n        FieldType fieldType = core.getSchema().getFieldTypes().get(fieldTypeName);\n        // Do index-time analysis using the given fieldType's analyzer\n        RAMDirectory ramDir = new RAMDirectory();\n\n        LogMergePolicy mp = new LogByteSizeMergePolicy();\n        mp.setMergeFactor(300);\n\n        IndexWriter writer = new IndexWriter(\n            ramDir,\n            new IndexWriterConfig(core.getSolrConfig().luceneMatchVersion, fieldType.getAnalyzer()).\n                setMaxBufferedDocs(150).\n                setMergePolicy(mp).\n                setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n                // TODO: if we enable this, codec gets angry since field won't exist in the schema\n                // .setCodec(core.getCodec())\n        );\n\n        List<String> lines = core.getResourceLoader().getLines(sourceLocation, characterEncoding);\n\n        for (String s : lines) {\n          Document d = new Document();\n          d.add(new TextField(WORD_FIELD_NAME, s, Field.Store.NO));\n          writer.addDocument(d);\n        }\n        writer.forceMerge(1);\n        writer.close();\n\n        dictionary = new HighFrequencyDictionary(DirectoryReader.open(ramDir),\n                WORD_FIELD_NAME, 0.0f);\n      } else {\n        // check if character encoding is defined\n        if (characterEncoding == null) {\n          dictionary = new PlainTextDictionary(core.getResourceLoader().openResource(sourceLocation));\n        } else {\n          dictionary = new PlainTextDictionary(new InputStreamReader(core.getResourceLoader().openResource(sourceLocation), characterEncoding));\n        }\n      }\n\n\n    } catch (IOException e) {\n      log.error( \"Unable to load spellings\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00":["d14e8d18c0e3970c20354dbeeb49da11bd587fbd","3615ce4a1f785ae1b779244de52c6a7d99227e60"],"c26f00b574427b55127e869b935845554afde1fa":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","c903c3d15906a3da96b8c0c2fb704491005fdbdb"],"1c5b026d03cbbb03ca4c0b97d14e9839682281dc":["d14e8d18c0e3970c20354dbeeb49da11bd587fbd"],"d14e8d18c0e3970c20354dbeeb49da11bd587fbd":["7b91922b55d15444d554721b352861d028eb8278"],"08970e5b8411182a29412c177eff67ec1110095b":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"04f07771a2a7dd3a395700665ed839c3dae2def2":["e7e8d6f15900ee22ac3cb0a503f15dc952a3580f"],"7b91922b55d15444d554721b352861d028eb8278":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f":["3615ce4a1f785ae1b779244de52c6a7d99227e60"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3615ce4a1f785ae1b779244de52c6a7d99227e60":["d14e8d18c0e3970c20354dbeeb49da11bd587fbd","1c5b026d03cbbb03ca4c0b97d14e9839682281dc"],"a258fbb26824fd104ed795e5d9033d2d040049ee":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["c26f00b574427b55127e869b935845554afde1fa"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["08970e5b8411182a29412c177eff67ec1110095b"]},"commit2Childs":{"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00":[],"c26f00b574427b55127e869b935845554afde1fa":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"1c5b026d03cbbb03ca4c0b97d14e9839682281dc":["3615ce4a1f785ae1b779244de52c6a7d99227e60"],"d14e8d18c0e3970c20354dbeeb49da11bd587fbd":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","1c5b026d03cbbb03ca4c0b97d14e9839682281dc","3615ce4a1f785ae1b779244de52c6a7d99227e60"],"08970e5b8411182a29412c177eff67ec1110095b":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"04f07771a2a7dd3a395700665ed839c3dae2def2":["08970e5b8411182a29412c177eff67ec1110095b"],"7b91922b55d15444d554721b352861d028eb8278":["d14e8d18c0e3970c20354dbeeb49da11bd587fbd"],"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["c26f00b574427b55127e869b935845554afde1fa"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c26f00b574427b55127e869b935845554afde1fa","c903c3d15906a3da96b8c0c2fb704491005fdbdb","a258fbb26824fd104ed795e5d9033d2d040049ee"],"3615ce4a1f785ae1b779244de52c6a7d99227e60":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","e7e8d6f15900ee22ac3cb0a503f15dc952a3580f"],"a258fbb26824fd104ed795e5d9033d2d040049ee":[],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["7b91922b55d15444d554721b352861d028eb8278"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","a258fbb26824fd104ed795e5d9033d2d040049ee","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}