{"path":"src/java/org/apache/solr/util/MultiValueTokenStream[HighlightingUtils]#next().mjava","commits":[{"id":"090f8d702b753c18c64a6fd5fb550596c68861ce","date":1172108327,"type":1,"author":"Mike Klaas","isMerge":false,"pathNew":"src/java/org/apache/solr/util/MultiValueTokenStream[HighlightingUtils]#next().mjava","pathOld":"src/java/org/apache/solr/util/MultiValueTokenStream[SolrPluginUtils]#next().mjava","sourceNew":"  /** Returns the next token in the stream, or null at EOS. */\n  public Token next() throws IOException {\n    int extra = 0;\n    if(currentStream == null) {\n      curIndex++;        \n      if(curIndex < values.length) {\n        currentStream = analyzer.tokenStream(fieldName, \n                                             new StringReader(values[curIndex]));\n        if (orderTokenOffsets) currentStream = new TokenOrderingFilter(currentStream,10);\n        // add extra space between multiple values\n        if(curIndex > 0) \n          extra = analyzer.getPositionIncrementGap(fieldName);\n      } else {\n        return null;\n      }\n    }\n    Token nextToken = currentStream.next();\n    if(nextToken == null) {\n      curOffset += values[curIndex].length();\n      currentStream = null;\n      return next();\n    }\n    // create an modified token which is the offset into the concatenated\n    // string of all values\n    Token offsetToken = new Token(nextToken.termText(), \n                                  nextToken.startOffset() + curOffset,\n                                  nextToken.endOffset() + curOffset);\n    offsetToken.setPositionIncrement(nextToken.getPositionIncrement() + extra*10);\n    return offsetToken;\n  }\n\n","sourceOld":"  /** Returns the next token in the stream, or null at EOS. */\n  public Token next() throws IOException {\n    int extra = 0;\n    if(currentStream == null) {\n      curIndex++;        \n      if(curIndex < values.length) {\n        currentStream = analyzer.tokenStream(fieldName, \n                                             new StringReader(values[curIndex]));\n        if (orderTokenOffsets) currentStream = new TokenOrderingFilter(currentStream,10);\n        // add extra space between multiple values\n        if(curIndex > 0) \n          extra = analyzer.getPositionIncrementGap(fieldName);\n      } else {\n        return null;\n      }\n    }\n    Token nextToken = currentStream.next();\n    if(nextToken == null) {\n      curOffset += values[curIndex].length();\n      currentStream = null;\n      return next();\n    }\n    // create an modified token which is the offset into the concatenated\n    // string of all values\n    Token offsetToken = new Token(nextToken.termText(), \n                                  nextToken.startOffset() + curOffset,\n                                  nextToken.endOffset() + curOffset);\n    offsetToken.setPositionIncrement(nextToken.getPositionIncrement() + extra*10);\n    return offsetToken;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a4114a9012ed90fa73da6201bb0aeec818808848","date":1183444190,"type":3,"author":"Ryan McKinley","isMerge":false,"pathNew":"src/java/org/apache/solr/util/MultiValueTokenStream[HighlightingUtils]#next().mjava","pathOld":"src/java/org/apache/solr/util/MultiValueTokenStream[HighlightingUtils]#next().mjava","sourceNew":"  /** Returns the next token in the stream, or null at EOS. */\n  @Override\n  public Token next() throws IOException {\n    int extra = 0;\n    if(currentStream == null) {\n      curIndex++;        \n      if(curIndex < values.length) {\n        currentStream = analyzer.tokenStream(fieldName, \n                                             new StringReader(values[curIndex]));\n        if (orderTokenOffsets) currentStream = new TokenOrderingFilter(currentStream,10);\n        // add extra space between multiple values\n        if(curIndex > 0) \n          extra = analyzer.getPositionIncrementGap(fieldName);\n      } else {\n        return null;\n      }\n    }\n    Token nextToken = currentStream.next();\n    if(nextToken == null) {\n      curOffset += values[curIndex].length();\n      currentStream = null;\n      return next();\n    }\n    // create an modified token which is the offset into the concatenated\n    // string of all values\n    Token offsetToken = new Token(nextToken.termText(), \n                                  nextToken.startOffset() + curOffset,\n                                  nextToken.endOffset() + curOffset);\n    offsetToken.setPositionIncrement(nextToken.getPositionIncrement() + extra*10);\n    return offsetToken;\n  }\n\n","sourceOld":"  /** Returns the next token in the stream, or null at EOS. */\n  public Token next() throws IOException {\n    int extra = 0;\n    if(currentStream == null) {\n      curIndex++;        \n      if(curIndex < values.length) {\n        currentStream = analyzer.tokenStream(fieldName, \n                                             new StringReader(values[curIndex]));\n        if (orderTokenOffsets) currentStream = new TokenOrderingFilter(currentStream,10);\n        // add extra space between multiple values\n        if(curIndex > 0) \n          extra = analyzer.getPositionIncrementGap(fieldName);\n      } else {\n        return null;\n      }\n    }\n    Token nextToken = currentStream.next();\n    if(nextToken == null) {\n      curOffset += values[curIndex].length();\n      currentStream = null;\n      return next();\n    }\n    // create an modified token which is the offset into the concatenated\n    // string of all values\n    Token offsetToken = new Token(nextToken.termText(), \n                                  nextToken.startOffset() + curOffset,\n                                  nextToken.endOffset() + curOffset);\n    offsetToken.setPositionIncrement(nextToken.getPositionIncrement() + extra*10);\n    return offsetToken;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c90f01e1c0f11ee52212ab38c6d4393b3be8a646","date":1223059437,"type":3,"author":"Ryan McKinley","isMerge":false,"pathNew":"src/java/org/apache/solr/util/MultiValueTokenStream[HighlightingUtils]#next().mjava","pathOld":"src/java/org/apache/solr/util/MultiValueTokenStream[HighlightingUtils]#next().mjava","sourceNew":"  /** Returns the next token in the stream, or null at EOS. */\n  @Override\n  public Token next() throws IOException {\n    int extra = 0;\n    if(currentStream == null) {\n      curIndex++;        \n      if(curIndex < values.length) {\n        currentStream = analyzer.tokenStream(fieldName, \n                                             new StringReader(values[curIndex]));\n        if (orderTokenOffsets) currentStream = new TokenOrderingFilter(currentStream,10);\n        // add extra space between multiple values\n        if(curIndex > 0) \n          extra = analyzer.getPositionIncrementGap(fieldName);\n      } else {\n        return null;\n      }\n    }\n    Token nextToken = currentStream.next();\n    if(nextToken == null) {\n      curOffset += values[curIndex].length();\n      currentStream = null;\n      return next();\n    }\n    // create an modified token which is the offset into the concatenated\n    // string of all values\n    Token offsetToken = new Token(new String(nextToken.termBuffer(), 0, nextToken.termLength()), \n                                  nextToken.startOffset() + curOffset,\n                                  nextToken.endOffset() + curOffset);\n    offsetToken.setPositionIncrement(nextToken.getPositionIncrement() + extra*10);\n    return offsetToken;\n  }\n\n","sourceOld":"  /** Returns the next token in the stream, or null at EOS. */\n  @Override\n  public Token next() throws IOException {\n    int extra = 0;\n    if(currentStream == null) {\n      curIndex++;        \n      if(curIndex < values.length) {\n        currentStream = analyzer.tokenStream(fieldName, \n                                             new StringReader(values[curIndex]));\n        if (orderTokenOffsets) currentStream = new TokenOrderingFilter(currentStream,10);\n        // add extra space between multiple values\n        if(curIndex > 0) \n          extra = analyzer.getPositionIncrementGap(fieldName);\n      } else {\n        return null;\n      }\n    }\n    Token nextToken = currentStream.next();\n    if(nextToken == null) {\n      curOffset += values[curIndex].length();\n      currentStream = null;\n      return next();\n    }\n    // create an modified token which is the offset into the concatenated\n    // string of all values\n    Token offsetToken = new Token(nextToken.termText(), \n                                  nextToken.startOffset() + curOffset,\n                                  nextToken.endOffset() + curOffset);\n    offsetToken.setPositionIncrement(nextToken.getPositionIncrement() + extra*10);\n    return offsetToken;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"33e6ce261fb71637077f5afb0521a898795a4340","date":1238092945,"type":4,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"/dev/null","pathOld":"src/java/org/apache/solr/util/MultiValueTokenStream[HighlightingUtils]#next().mjava","sourceNew":null,"sourceOld":"  /** Returns the next token in the stream, or null at EOS. */\n  @Override\n  public Token next() throws IOException {\n    int extra = 0;\n    if(currentStream == null) {\n      curIndex++;        \n      if(curIndex < values.length) {\n        currentStream = analyzer.tokenStream(fieldName, \n                                             new StringReader(values[curIndex]));\n        if (orderTokenOffsets) currentStream = new TokenOrderingFilter(currentStream,10);\n        // add extra space between multiple values\n        if(curIndex > 0) \n          extra = analyzer.getPositionIncrementGap(fieldName);\n      } else {\n        return null;\n      }\n    }\n    Token nextToken = currentStream.next();\n    if(nextToken == null) {\n      curOffset += values[curIndex].length();\n      currentStream = null;\n      return next();\n    }\n    // create an modified token which is the offset into the concatenated\n    // string of all values\n    Token offsetToken = new Token(new String(nextToken.termBuffer(), 0, nextToken.termLength()), \n                                  nextToken.startOffset() + curOffset,\n                                  nextToken.endOffset() + curOffset);\n    offsetToken.setPositionIncrement(nextToken.getPositionIncrement() + extra*10);\n    return offsetToken;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"33e6ce261fb71637077f5afb0521a898795a4340":["c90f01e1c0f11ee52212ab38c6d4393b3be8a646"],"c90f01e1c0f11ee52212ab38c6d4393b3be8a646":["a4114a9012ed90fa73da6201bb0aeec818808848"],"a4114a9012ed90fa73da6201bb0aeec818808848":["090f8d702b753c18c64a6fd5fb550596c68861ce"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":[],"090f8d702b753c18c64a6fd5fb550596c68861ce":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"33e6ce261fb71637077f5afb0521a898795a4340":[],"c90f01e1c0f11ee52212ab38c6d4393b3be8a646":["33e6ce261fb71637077f5afb0521a898795a4340"],"a4114a9012ed90fa73da6201bb0aeec818808848":["c90f01e1c0f11ee52212ab38c6d4393b3be8a646"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":["090f8d702b753c18c64a6fd5fb550596c68861ce"],"090f8d702b753c18c64a6fd5fb550596c68861ce":["a4114a9012ed90fa73da6201bb0aeec818808848"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["33e6ce261fb71637077f5afb0521a898795a4340","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"pathCommit":null}