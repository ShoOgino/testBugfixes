{"path":"src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,boolean,SegmentReader[],int[],Map,boolean,boolean).mjava","commits":[{"id":"0f4b0a12e9aa5d9fd24932c99a893fb6a04c74c1","date":1244392278,"type":1,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,boolean,SegmentReader[],int[],Map,boolean,boolean).mjava","pathOld":"src/java/org/apache/lucene/index/MultiSegmentReader#MultiSegmentReader(Directory,SegmentInfos,boolean,SegmentReader[],int[],Map,boolean,boolean).mjava","sourceNew":"  /** This contructor is only used for {@link #reopen()} */\n  DirectoryReader(Directory directory, SegmentInfos infos, boolean closeDirectory, SegmentReader[] oldReaders, int[] oldStarts,\n                     Map oldNormsCache, boolean readOnly, boolean doClone) throws IOException {\n    this.directory = directory;\n    this.readOnly = readOnly;\n    this.closeDirectory = closeDirectory;\n    this.segmentInfos = infos;\n    if (!readOnly) {\n      // We assume that this segments_N was previously\n      // properly sync'd:\n      synced.addAll(infos.files(directory, true));\n    }\n\n    // we put the old SegmentReaders in a map, that allows us\n    // to lookup a reader using its segment name\n    Map segmentReaders = new HashMap();\n\n    if (oldReaders != null) {\n      // create a Map SegmentName->SegmentReader\n      for (int i = 0; i < oldReaders.length; i++) {\n        segmentReaders.put(oldReaders[i].getSegmentName(), new Integer(i));\n      }\n    }\n    \n    SegmentReader[] newReaders = new SegmentReader[infos.size()];\n    \n    // remember which readers are shared between the old and the re-opened\n    // DirectoryReader - we have to incRef those readers\n    boolean[] readerShared = new boolean[infos.size()];\n    \n    for (int i = infos.size() - 1; i>=0; i--) {\n      // find SegmentReader for this segment\n      Integer oldReaderIndex = (Integer) segmentReaders.get(infos.info(i).name);\n      if (oldReaderIndex == null) {\n        // this is a new segment, no old SegmentReader can be reused\n        newReaders[i] = null;\n      } else {\n        // there is an old reader for this segment - we'll try to reopen it\n        newReaders[i] = oldReaders[oldReaderIndex.intValue()];\n      }\n\n      boolean success = false;\n      try {\n        SegmentReader newReader;\n        if (newReaders[i] == null || infos.info(i).getUseCompoundFile() != newReaders[i].getSegmentInfo().getUseCompoundFile()) {\n\n          // We should never see a totally new segment during cloning\n          assert !doClone;\n\n          // this is a new reader; in case we hit an exception we can close it safely\n          newReader = SegmentReader.get(readOnly, infos.info(i));\n        } else {\n          newReader = newReaders[i].reopenSegment(infos.info(i), doClone, readOnly);\n        }\n        if (newReader == newReaders[i]) {\n          // this reader will be shared between the old and the new one,\n          // so we must incRef it\n          readerShared[i] = true;\n          newReader.incRef();\n        } else {\n          readerShared[i] = false;\n          newReaders[i] = newReader;\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          for (i++; i < infos.size(); i++) {\n            if (newReaders[i] != null) {\n              try {\n                if (!readerShared[i]) {\n                  // this is a new subReader that is not used by the old one,\n                  // we can close it\n                  newReaders[i].close();\n                } else {\n                  // this subReader is also used by the old reader, so instead\n                  // closing we must decRef it\n                  newReaders[i].decRef();\n                }\n              } catch (IOException ignore) {\n                // keep going - we want to clean up as much as possible\n              }\n            }\n          }\n        }\n      }\n    }    \n    \n    // initialize the readers to calculate maxDoc before we try to reuse the old normsCache\n    initialize(newReaders);\n    \n    // try to copy unchanged norms from the old normsCache to the new one\n    if (oldNormsCache != null) {\n      Iterator it = oldNormsCache.entrySet().iterator();\n      while (it.hasNext()) {\n        Map.Entry entry = (Map.Entry) it.next();\n        String field = (String) entry.getKey();\n        if (!hasNorms(field)) {\n          continue;\n        }\n\n        byte[] oldBytes = (byte[]) entry.getValue();\n\n        byte[] bytes = new byte[maxDoc()];\n\n        for (int i = 0; i < subReaders.length; i++) {\n          Integer oldReaderIndex = ((Integer) segmentReaders.get(subReaders[i].getSegmentName()));\n\n          // this SegmentReader was not re-opened, we can copy all of its norms \n          if (oldReaderIndex != null &&\n               (oldReaders[oldReaderIndex.intValue()] == subReaders[i] \n                 || oldReaders[oldReaderIndex.intValue()].norms.get(field) == subReaders[i].norms.get(field))) {\n            // we don't have to synchronize here: either this constructor is called from a SegmentReader,\n            // in which case no old norms cache is present, or it is called from MultiReader.reopen(),\n            // which is synchronized\n            System.arraycopy(oldBytes, oldStarts[oldReaderIndex.intValue()], bytes, starts[i], starts[i+1] - starts[i]);\n          } else {\n            subReaders[i].norms(field, bytes, starts[i]);\n          }\n        }\n\n        normsCache.put(field, bytes);      // update cache\n      }\n    }\n  }\n\n","sourceOld":"  /** This contructor is only used for {@link #reopen()} */\n  MultiSegmentReader(Directory directory, SegmentInfos infos, boolean closeDirectory, SegmentReader[] oldReaders, int[] oldStarts,\n                     Map oldNormsCache, boolean readOnly, boolean doClone) throws IOException {\n    super(directory, infos, closeDirectory, readOnly);\n\n    // we put the old SegmentReaders in a map, that allows us\n    // to lookup a reader using its segment name\n    Map segmentReaders = new HashMap();\n\n    if (oldReaders != null) {\n      // create a Map SegmentName->SegmentReader\n      for (int i = 0; i < oldReaders.length; i++) {\n        segmentReaders.put(oldReaders[i].getSegmentName(), new Integer(i));\n      }\n    }\n    \n    SegmentReader[] newReaders = new SegmentReader[infos.size()];\n    \n    // remember which readers are shared between the old and the re-opened\n    // MultiSegmentReader - we have to incRef those readers\n    boolean[] readerShared = new boolean[infos.size()];\n    \n    for (int i = infos.size() - 1; i>=0; i--) {\n      // find SegmentReader for this segment\n      Integer oldReaderIndex = (Integer) segmentReaders.get(infos.info(i).name);\n      if (oldReaderIndex == null) {\n        // this is a new segment, no old SegmentReader can be reused\n        newReaders[i] = null;\n      } else {\n        // there is an old reader for this segment - we'll try to reopen it\n        newReaders[i] = oldReaders[oldReaderIndex.intValue()];\n      }\n\n      boolean success = false;\n      try {\n        SegmentReader newReader;\n        if (newReaders[i] == null || infos.info(i).getUseCompoundFile() != newReaders[i].getSegmentInfo().getUseCompoundFile()) {\n\n          // We should never see a totally new segment during cloning\n          assert !doClone;\n\n          // this is a new reader; in case we hit an exception we can close it safely\n          newReader = SegmentReader.get(readOnly, infos.info(i));\n        } else {\n          newReader = (SegmentReader) newReaders[i].reopenSegment(infos.info(i), doClone, readOnly);\n          if (newReader == newReaders[i] && newReaders[i].hasSegmentInfos()) {\n            // Special case when a single-segment reader was\n            // reopened to a multi-segment reader -- we must\n            // get a private clone, to clear its\n            // SegmentInfos, so it does not attempt to\n            // obtain the write lock\n            newReader = (SegmentReader) newReaders[i].clone(readOnly);\n            newReader.init(directory, null, false, readOnly);\n          } \n\n          // Make sure reopenSegment did not carry over a\n          // segmentInfos instance\n          assert !newReader.hasSegmentInfos();\n        }\n        if (newReader == newReaders[i]) {\n          // this reader will be shared between the old and the new one,\n          // so we must incRef it\n          readerShared[i] = true;\n          newReader.incRef();\n        } else {\n          readerShared[i] = false;\n          newReaders[i] = newReader;\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          for (i++; i < infos.size(); i++) {\n            if (newReaders[i] != null) {\n              try {\n                if (!readerShared[i]) {\n                  // this is a new subReader that is not used by the old one,\n                  // we can close it\n                  newReaders[i].close();\n                } else {\n                  // this subReader is also used by the old reader, so instead\n                  // closing we must decRef it\n                  newReaders[i].decRef();\n                }\n              } catch (IOException ignore) {\n                // keep going - we want to clean up as much as possible\n              }\n            }\n          }\n        }\n      }\n    }    \n    \n    // initialize the readers to calculate maxDoc before we try to reuse the old normsCache\n    initialize(newReaders);\n    \n    // try to copy unchanged norms from the old normsCache to the new one\n    if (oldNormsCache != null) {\n      Iterator it = oldNormsCache.entrySet().iterator();\n      while (it.hasNext()) {\n        Map.Entry entry = (Map.Entry) it.next();\n        String field = (String) entry.getKey();\n        if (!hasNorms(field)) {\n          continue;\n        }\n\n        byte[] oldBytes = (byte[]) entry.getValue();\n\n        byte[] bytes = new byte[maxDoc()];\n\n        for (int i = 0; i < subReaders.length; i++) {\n          Integer oldReaderIndex = ((Integer) segmentReaders.get(subReaders[i].getSegmentName()));\n\n          // this SegmentReader was not re-opened, we can copy all of its norms \n          if (oldReaderIndex != null &&\n               (oldReaders[oldReaderIndex.intValue()] == subReaders[i] \n                 || oldReaders[oldReaderIndex.intValue()].norms.get(field) == subReaders[i].norms.get(field))) {\n            // we don't have to synchronize here: either this constructor is called from a SegmentReader,\n            // in which case no old norms cache is present, or it is called from MultiReader.reopen(),\n            // which is synchronized\n            System.arraycopy(oldBytes, oldStarts[oldReaderIndex.intValue()], bytes, starts[i], starts[i+1] - starts[i]);\n          } else {\n            subReaders[i].norms(field, bytes, starts[i]);\n          }\n        }\n\n        normsCache.put(field, bytes);      // update cache\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4e54e4a9a2442944e55f58e835877841cdac1271","date":1244628560,"type":5,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,SegmentReader[],int[],Map,boolean,boolean).mjava","pathOld":"src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,boolean,SegmentReader[],int[],Map,boolean,boolean).mjava","sourceNew":"  /** This contructor is only used for {@link #reopen()} */\n  DirectoryReader(Directory directory, SegmentInfos infos, SegmentReader[] oldReaders, int[] oldStarts,\n                     Map oldNormsCache, boolean readOnly, boolean doClone) throws IOException {\n    this.directory = directory;\n    this.readOnly = readOnly;\n    this.segmentInfos = infos;\n    if (!readOnly) {\n      // We assume that this segments_N was previously\n      // properly sync'd:\n      synced.addAll(infos.files(directory, true));\n    }\n\n    // we put the old SegmentReaders in a map, that allows us\n    // to lookup a reader using its segment name\n    Map segmentReaders = new HashMap();\n\n    if (oldReaders != null) {\n      // create a Map SegmentName->SegmentReader\n      for (int i = 0; i < oldReaders.length; i++) {\n        segmentReaders.put(oldReaders[i].getSegmentName(), new Integer(i));\n      }\n    }\n    \n    SegmentReader[] newReaders = new SegmentReader[infos.size()];\n    \n    // remember which readers are shared between the old and the re-opened\n    // DirectoryReader - we have to incRef those readers\n    boolean[] readerShared = new boolean[infos.size()];\n    \n    for (int i = infos.size() - 1; i>=0; i--) {\n      // find SegmentReader for this segment\n      Integer oldReaderIndex = (Integer) segmentReaders.get(infos.info(i).name);\n      if (oldReaderIndex == null) {\n        // this is a new segment, no old SegmentReader can be reused\n        newReaders[i] = null;\n      } else {\n        // there is an old reader for this segment - we'll try to reopen it\n        newReaders[i] = oldReaders[oldReaderIndex.intValue()];\n      }\n\n      boolean success = false;\n      try {\n        SegmentReader newReader;\n        if (newReaders[i] == null || infos.info(i).getUseCompoundFile() != newReaders[i].getSegmentInfo().getUseCompoundFile()) {\n\n          // We should never see a totally new segment during cloning\n          assert !doClone;\n\n          // this is a new reader; in case we hit an exception we can close it safely\n          newReader = SegmentReader.get(readOnly, infos.info(i));\n        } else {\n          newReader = newReaders[i].reopenSegment(infos.info(i), doClone, readOnly);\n        }\n        if (newReader == newReaders[i]) {\n          // this reader will be shared between the old and the new one,\n          // so we must incRef it\n          readerShared[i] = true;\n          newReader.incRef();\n        } else {\n          readerShared[i] = false;\n          newReaders[i] = newReader;\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          for (i++; i < infos.size(); i++) {\n            if (newReaders[i] != null) {\n              try {\n                if (!readerShared[i]) {\n                  // this is a new subReader that is not used by the old one,\n                  // we can close it\n                  newReaders[i].close();\n                } else {\n                  // this subReader is also used by the old reader, so instead\n                  // closing we must decRef it\n                  newReaders[i].decRef();\n                }\n              } catch (IOException ignore) {\n                // keep going - we want to clean up as much as possible\n              }\n            }\n          }\n        }\n      }\n    }    \n    \n    // initialize the readers to calculate maxDoc before we try to reuse the old normsCache\n    initialize(newReaders);\n    \n    // try to copy unchanged norms from the old normsCache to the new one\n    if (oldNormsCache != null) {\n      Iterator it = oldNormsCache.entrySet().iterator();\n      while (it.hasNext()) {\n        Map.Entry entry = (Map.Entry) it.next();\n        String field = (String) entry.getKey();\n        if (!hasNorms(field)) {\n          continue;\n        }\n\n        byte[] oldBytes = (byte[]) entry.getValue();\n\n        byte[] bytes = new byte[maxDoc()];\n\n        for (int i = 0; i < subReaders.length; i++) {\n          Integer oldReaderIndex = ((Integer) segmentReaders.get(subReaders[i].getSegmentName()));\n\n          // this SegmentReader was not re-opened, we can copy all of its norms \n          if (oldReaderIndex != null &&\n               (oldReaders[oldReaderIndex.intValue()] == subReaders[i] \n                 || oldReaders[oldReaderIndex.intValue()].norms.get(field) == subReaders[i].norms.get(field))) {\n            // we don't have to synchronize here: either this constructor is called from a SegmentReader,\n            // in which case no old norms cache is present, or it is called from MultiReader.reopen(),\n            // which is synchronized\n            System.arraycopy(oldBytes, oldStarts[oldReaderIndex.intValue()], bytes, starts[i], starts[i+1] - starts[i]);\n          } else {\n            subReaders[i].norms(field, bytes, starts[i]);\n          }\n        }\n\n        normsCache.put(field, bytes);      // update cache\n      }\n    }\n  }\n\n","sourceOld":"  /** This contructor is only used for {@link #reopen()} */\n  DirectoryReader(Directory directory, SegmentInfos infos, boolean closeDirectory, SegmentReader[] oldReaders, int[] oldStarts,\n                     Map oldNormsCache, boolean readOnly, boolean doClone) throws IOException {\n    this.directory = directory;\n    this.readOnly = readOnly;\n    this.closeDirectory = closeDirectory;\n    this.segmentInfos = infos;\n    if (!readOnly) {\n      // We assume that this segments_N was previously\n      // properly sync'd:\n      synced.addAll(infos.files(directory, true));\n    }\n\n    // we put the old SegmentReaders in a map, that allows us\n    // to lookup a reader using its segment name\n    Map segmentReaders = new HashMap();\n\n    if (oldReaders != null) {\n      // create a Map SegmentName->SegmentReader\n      for (int i = 0; i < oldReaders.length; i++) {\n        segmentReaders.put(oldReaders[i].getSegmentName(), new Integer(i));\n      }\n    }\n    \n    SegmentReader[] newReaders = new SegmentReader[infos.size()];\n    \n    // remember which readers are shared between the old and the re-opened\n    // DirectoryReader - we have to incRef those readers\n    boolean[] readerShared = new boolean[infos.size()];\n    \n    for (int i = infos.size() - 1; i>=0; i--) {\n      // find SegmentReader for this segment\n      Integer oldReaderIndex = (Integer) segmentReaders.get(infos.info(i).name);\n      if (oldReaderIndex == null) {\n        // this is a new segment, no old SegmentReader can be reused\n        newReaders[i] = null;\n      } else {\n        // there is an old reader for this segment - we'll try to reopen it\n        newReaders[i] = oldReaders[oldReaderIndex.intValue()];\n      }\n\n      boolean success = false;\n      try {\n        SegmentReader newReader;\n        if (newReaders[i] == null || infos.info(i).getUseCompoundFile() != newReaders[i].getSegmentInfo().getUseCompoundFile()) {\n\n          // We should never see a totally new segment during cloning\n          assert !doClone;\n\n          // this is a new reader; in case we hit an exception we can close it safely\n          newReader = SegmentReader.get(readOnly, infos.info(i));\n        } else {\n          newReader = newReaders[i].reopenSegment(infos.info(i), doClone, readOnly);\n        }\n        if (newReader == newReaders[i]) {\n          // this reader will be shared between the old and the new one,\n          // so we must incRef it\n          readerShared[i] = true;\n          newReader.incRef();\n        } else {\n          readerShared[i] = false;\n          newReaders[i] = newReader;\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          for (i++; i < infos.size(); i++) {\n            if (newReaders[i] != null) {\n              try {\n                if (!readerShared[i]) {\n                  // this is a new subReader that is not used by the old one,\n                  // we can close it\n                  newReaders[i].close();\n                } else {\n                  // this subReader is also used by the old reader, so instead\n                  // closing we must decRef it\n                  newReaders[i].decRef();\n                }\n              } catch (IOException ignore) {\n                // keep going - we want to clean up as much as possible\n              }\n            }\n          }\n        }\n      }\n    }    \n    \n    // initialize the readers to calculate maxDoc before we try to reuse the old normsCache\n    initialize(newReaders);\n    \n    // try to copy unchanged norms from the old normsCache to the new one\n    if (oldNormsCache != null) {\n      Iterator it = oldNormsCache.entrySet().iterator();\n      while (it.hasNext()) {\n        Map.Entry entry = (Map.Entry) it.next();\n        String field = (String) entry.getKey();\n        if (!hasNorms(field)) {\n          continue;\n        }\n\n        byte[] oldBytes = (byte[]) entry.getValue();\n\n        byte[] bytes = new byte[maxDoc()];\n\n        for (int i = 0; i < subReaders.length; i++) {\n          Integer oldReaderIndex = ((Integer) segmentReaders.get(subReaders[i].getSegmentName()));\n\n          // this SegmentReader was not re-opened, we can copy all of its norms \n          if (oldReaderIndex != null &&\n               (oldReaders[oldReaderIndex.intValue()] == subReaders[i] \n                 || oldReaders[oldReaderIndex.intValue()].norms.get(field) == subReaders[i].norms.get(field))) {\n            // we don't have to synchronize here: either this constructor is called from a SegmentReader,\n            // in which case no old norms cache is present, or it is called from MultiReader.reopen(),\n            // which is synchronized\n            System.arraycopy(oldBytes, oldStarts[oldReaderIndex.intValue()], bytes, starts[i], starts[i+1] - starts[i]);\n          } else {\n            subReaders[i].norms(field, bytes, starts[i]);\n          }\n        }\n\n        normsCache.put(field, bytes);      // update cache\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"0f4b0a12e9aa5d9fd24932c99a893fb6a04c74c1":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"4e54e4a9a2442944e55f58e835877841cdac1271":["0f4b0a12e9aa5d9fd24932c99a893fb6a04c74c1"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["4e54e4a9a2442944e55f58e835877841cdac1271"]},"commit2Childs":{"0f4b0a12e9aa5d9fd24932c99a893fb6a04c74c1":["4e54e4a9a2442944e55f58e835877841cdac1271"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["0f4b0a12e9aa5d9fd24932c99a893fb6a04c74c1"],"4e54e4a9a2442944e55f58e835877841cdac1271":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}