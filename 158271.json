{"path":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet,DocsEnumState).mjava","commits":[{"id":"b4cd50ad7936c0f3a0851313b4e0ab861c7a6b17","date":1277233255,"type":0,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet,DocsEnumState).mjava","pathOld":"/dev/null","sourceNew":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter, DocsEnumState deState) throws IOException {\n    if (filter != null) return getDocSetNC(query, filter, null);\n\n    int smallSetSize = maxDoc()>>6;\n    int largestPossible = deState.termsEnum.docFreq();\n\n    int[] docs = new int[Math.min(smallSetSize, largestPossible)];\n    int upto = 0;\n    int bitsSet = 0;\n    OpenBitSet obs = null;\n\n    DocsEnum docsEnum = deState.termsEnum.docs(deState.deletedDocs, deState.reuse);\n    if (deState.reuse == null) {\n      deState.reuse = docsEnum;\n    }\n\n    if (docsEnum instanceof MultiDocsEnum) {\n      MultiDocsEnum.EnumWithSlice[] subs = ((MultiDocsEnum)docsEnum).getSubs();\n      int numSubs = ((MultiDocsEnum)docsEnum).getNumSubs();\n      for (int subindex = 0; subindex<numSubs; subindex++) {\n        MultiDocsEnum.EnumWithSlice sub = subs[subindex];\n        if (sub.docsEnum == null) continue;\n        DocsEnum.BulkReadResult bulk = sub.docsEnum.getBulkResult();\n        int base = sub.slice.start;\n\n        for (;;) {\n          int nDocs = sub.docsEnum.read();\n          if (nDocs == 0) break;\n          int[] docArr = bulk.docs.ints;\n          int end = bulk.docs.offset + nDocs;\n          if (upto + nDocs > docs.length) {\n            if (obs == null) obs = new OpenBitSet(maxDoc());\n            for (int i=bulk.docs.offset; i<end; i++) {\n              obs.fastSet(docArr[i]+base);\n            }\n            bitsSet += nDocs;\n          } else {\n            for (int i=bulk.docs.offset; i<end; i++) {\n              docs[upto++] = docArr[i]+base;\n            }\n          }\n        }\n      }\n    } else {\n      DocsEnum.BulkReadResult bulk = docsEnum.getBulkResult();\n      for (;;) {\n        int nDocs = docsEnum.read();\n        if (nDocs == 0) break;\n        int[] docArr = bulk.docs.ints;\n        int end = bulk.docs.offset + nDocs;\n\n        if (upto + nDocs > docs.length) {\n          if (obs == null) obs = new OpenBitSet(maxDoc());\n          for (int i=bulk.docs.offset; i<end; i++) {\n            obs.fastSet(docArr[i]);\n          }\n          bitsSet += nDocs;\n        } else {\n          for (int i=bulk.docs.offset; i<end; i++) {\n            docs[upto++] = docArr[i];\n          }\n        }\n      }\n    }\n\n    if (obs != null) {\n      for (int i=0; i<upto; i++) {\n        obs.fastSet(docs[i]);  \n      }\n      bitsSet += upto;\n      return new BitDocSet(obs, bitsSet);\n    }\n\n    return new SortedIntDocSet(docs, upto);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5f4e87790277826a2aea119328600dfb07761f32","date":1279827275,"type":0,"author":"Michael Busch","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet,DocsEnumState).mjava","pathOld":"/dev/null","sourceNew":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter, DocsEnumState deState) throws IOException {\n    if (filter != null) return getDocSetNC(query, filter, null);\n\n    int smallSetSize = maxDoc()>>6;\n    int largestPossible = deState.termsEnum.docFreq();\n\n    int[] docs = new int[Math.min(smallSetSize, largestPossible)];\n    int upto = 0;\n    int bitsSet = 0;\n    OpenBitSet obs = null;\n\n    DocsEnum docsEnum = deState.termsEnum.docs(deState.deletedDocs, deState.reuse);\n    if (deState.reuse == null) {\n      deState.reuse = docsEnum;\n    }\n\n    if (docsEnum instanceof MultiDocsEnum) {\n      MultiDocsEnum.EnumWithSlice[] subs = ((MultiDocsEnum)docsEnum).getSubs();\n      int numSubs = ((MultiDocsEnum)docsEnum).getNumSubs();\n      for (int subindex = 0; subindex<numSubs; subindex++) {\n        MultiDocsEnum.EnumWithSlice sub = subs[subindex];\n        if (sub.docsEnum == null) continue;\n        DocsEnum.BulkReadResult bulk = sub.docsEnum.getBulkResult();\n        int base = sub.slice.start;\n\n        for (;;) {\n          int nDocs = sub.docsEnum.read();\n          if (nDocs == 0) break;\n          int[] docArr = bulk.docs.ints;\n          int end = bulk.docs.offset + nDocs;\n          if (upto + nDocs > docs.length) {\n            if (obs == null) obs = new OpenBitSet(maxDoc());\n            for (int i=bulk.docs.offset; i<end; i++) {\n              obs.fastSet(docArr[i]+base);\n            }\n            bitsSet += nDocs;\n          } else {\n            for (int i=bulk.docs.offset; i<end; i++) {\n              docs[upto++] = docArr[i]+base;\n            }\n          }\n        }\n      }\n    } else {\n      DocsEnum.BulkReadResult bulk = docsEnum.getBulkResult();\n      for (;;) {\n        int nDocs = docsEnum.read();\n        if (nDocs == 0) break;\n        int[] docArr = bulk.docs.ints;\n        int end = bulk.docs.offset + nDocs;\n\n        if (upto + nDocs > docs.length) {\n          if (obs == null) obs = new OpenBitSet(maxDoc());\n          for (int i=bulk.docs.offset; i<end; i++) {\n            obs.fastSet(docArr[i]);\n          }\n          bitsSet += nDocs;\n        } else {\n          for (int i=bulk.docs.offset; i<end; i++) {\n            docs[upto++] = docArr[i];\n          }\n        }\n      }\n    }\n\n    if (obs != null) {\n      for (int i=0; i<upto; i++) {\n        obs.fastSet(docs[i]);  \n      }\n      bitsSet += upto;\n      return new BitDocSet(obs, bitsSet);\n    }\n\n    return new SortedIntDocSet(docs, upto);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f20bb72b0dfa147c6f1fcd7693102c63a2714eae","date":1303767270,"type":5,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSet(DocsEnumState).mjava","pathOld":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet,DocsEnumState).mjava","sourceNew":"  /** lucene.internal */\n  public DocSet getDocSet(DocsEnumState deState) throws IOException {\n    int largestPossible = deState.termsEnum.docFreq();\n    boolean useCache = filterCache != null && largestPossible >= deState.minSetSizeCached;\n    TermQuery key = null;\n\n    if (useCache) {\n      key = new TermQuery(new Term(deState.fieldName, new BytesRef(deState.termsEnum.term()), false));\n      DocSet result = filterCache.get(key);\n      if (result != null) return result;\n    }\n\n    int smallSetSize = maxDoc()>>6;\n    int scratchSize = Math.min(smallSetSize, largestPossible);\n    if (deState.scratch == null || deState.scratch.length < scratchSize)\n      deState.scratch = new int[scratchSize];\n\n    final int[] docs = deState.scratch;\n    int upto = 0;\n    int bitsSet = 0;\n    OpenBitSet obs = null;\n\n    DocsEnum docsEnum = deState.termsEnum.docs(deState.deletedDocs, deState.docsEnum);\n    if (deState.docsEnum == null) {\n      deState.docsEnum = docsEnum;\n    }\n\n    if (docsEnum instanceof MultiDocsEnum) {\n      MultiDocsEnum.EnumWithSlice[] subs = ((MultiDocsEnum)docsEnum).getSubs();\n      int numSubs = ((MultiDocsEnum)docsEnum).getNumSubs();\n      for (int subindex = 0; subindex<numSubs; subindex++) {\n        MultiDocsEnum.EnumWithSlice sub = subs[subindex];\n        if (sub.docsEnum == null) continue;\n        DocsEnum.BulkReadResult bulk = sub.docsEnum.getBulkResult();\n        int base = sub.slice.start;\n\n        for (;;) {\n          int nDocs = sub.docsEnum.read();\n          if (nDocs == 0) break;\n          int[] docArr = bulk.docs.ints;\n          int end = bulk.docs.offset + nDocs;\n          if (upto + nDocs > docs.length) {\n            if (obs == null) obs = new OpenBitSet(maxDoc());\n            for (int i=bulk.docs.offset; i<end; i++) {\n              obs.fastSet(docArr[i]+base);\n            }\n            bitsSet += nDocs;\n          } else {\n            for (int i=bulk.docs.offset; i<end; i++) {\n              docs[upto++] = docArr[i]+base;\n            }\n          }\n        }\n      }\n    } else {\n      DocsEnum.BulkReadResult bulk = docsEnum.getBulkResult();\n      for (;;) {\n        int nDocs = docsEnum.read();\n        if (nDocs == 0) break;\n        int[] docArr = bulk.docs.ints;\n        int end = bulk.docs.offset + nDocs;\n\n        if (upto + nDocs > docs.length) {\n          if (obs == null) obs = new OpenBitSet(maxDoc());\n          for (int i=bulk.docs.offset; i<end; i++) {\n            obs.fastSet(docArr[i]);\n          }\n          bitsSet += nDocs;\n        } else {\n          for (int i=bulk.docs.offset; i<end; i++) {\n            docs[upto++] = docArr[i];\n          }\n        }\n      }\n    }\n\n    DocSet result;\n    if (obs != null) {\n      for (int i=0; i<upto; i++) {\n        obs.fastSet(docs[i]);  \n      }\n      bitsSet += upto;\n      result = new BitDocSet(obs, bitsSet);\n    } else {\n      result = new SortedIntDocSet(Arrays.copyOf(docs, upto));\n    }\n\n    if (useCache) {\n      filterCache.put(key, result);\n    }\n    \n    return result;\n  }\n\n","sourceOld":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter, DocsEnumState deState) throws IOException {\n    if (filter != null) return getDocSetNC(query, filter, null);\n\n    int smallSetSize = maxDoc()>>6;\n    int largestPossible = deState.termsEnum.docFreq();\n\n    int[] docs = new int[Math.min(smallSetSize, largestPossible)];\n    int upto = 0;\n    int bitsSet = 0;\n    OpenBitSet obs = null;\n\n    DocsEnum docsEnum = deState.termsEnum.docs(deState.deletedDocs, deState.reuse);\n    if (deState.reuse == null) {\n      deState.reuse = docsEnum;\n    }\n\n    if (docsEnum instanceof MultiDocsEnum) {\n      MultiDocsEnum.EnumWithSlice[] subs = ((MultiDocsEnum)docsEnum).getSubs();\n      int numSubs = ((MultiDocsEnum)docsEnum).getNumSubs();\n      for (int subindex = 0; subindex<numSubs; subindex++) {\n        MultiDocsEnum.EnumWithSlice sub = subs[subindex];\n        if (sub.docsEnum == null) continue;\n        DocsEnum.BulkReadResult bulk = sub.docsEnum.getBulkResult();\n        int base = sub.slice.start;\n\n        for (;;) {\n          int nDocs = sub.docsEnum.read();\n          if (nDocs == 0) break;\n          int[] docArr = bulk.docs.ints;\n          int end = bulk.docs.offset + nDocs;\n          if (upto + nDocs > docs.length) {\n            if (obs == null) obs = new OpenBitSet(maxDoc());\n            for (int i=bulk.docs.offset; i<end; i++) {\n              obs.fastSet(docArr[i]+base);\n            }\n            bitsSet += nDocs;\n          } else {\n            for (int i=bulk.docs.offset; i<end; i++) {\n              docs[upto++] = docArr[i]+base;\n            }\n          }\n        }\n      }\n    } else {\n      DocsEnum.BulkReadResult bulk = docsEnum.getBulkResult();\n      for (;;) {\n        int nDocs = docsEnum.read();\n        if (nDocs == 0) break;\n        int[] docArr = bulk.docs.ints;\n        int end = bulk.docs.offset + nDocs;\n\n        if (upto + nDocs > docs.length) {\n          if (obs == null) obs = new OpenBitSet(maxDoc());\n          for (int i=bulk.docs.offset; i<end; i++) {\n            obs.fastSet(docArr[i]);\n          }\n          bitsSet += nDocs;\n        } else {\n          for (int i=bulk.docs.offset; i<end; i++) {\n            docs[upto++] = docArr[i];\n          }\n        }\n      }\n    }\n\n    if (obs != null) {\n      for (int i=0; i<upto; i++) {\n        obs.fastSet(docs[i]);  \n      }\n      bitsSet += upto;\n      return new BitDocSet(obs, bitsSet);\n    }\n\n    return new SortedIntDocSet(docs, upto);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0663cc678850ea2c51151f9fd217342ea35b8568","date":1303828523,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet,DocsEnumState).mjava","pathOld":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSet(DocsEnumState).mjava","sourceNew":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter, DocsEnumState deState) throws IOException {\n    if (filter != null) return getDocSetNC(query, filter, null);\n\n    int smallSetSize = maxDoc()>>6;\n    int largestPossible = deState.termsEnum.docFreq();\n\n    int[] docs = new int[Math.min(smallSetSize, largestPossible)];\n    int upto = 0;\n    int bitsSet = 0;\n    OpenBitSet obs = null;\n\n    DocsEnum docsEnum = deState.termsEnum.docs(deState.deletedDocs, deState.reuse);\n    if (deState.reuse == null) {\n      deState.reuse = docsEnum;\n    }\n\n    if (docsEnum instanceof MultiDocsEnum) {\n      MultiDocsEnum.EnumWithSlice[] subs = ((MultiDocsEnum)docsEnum).getSubs();\n      int numSubs = ((MultiDocsEnum)docsEnum).getNumSubs();\n      for (int subindex = 0; subindex<numSubs; subindex++) {\n        MultiDocsEnum.EnumWithSlice sub = subs[subindex];\n        if (sub.docsEnum == null) continue;\n        DocsEnum.BulkReadResult bulk = sub.docsEnum.getBulkResult();\n        int base = sub.slice.start;\n\n        for (;;) {\n          int nDocs = sub.docsEnum.read();\n          if (nDocs == 0) break;\n          int[] docArr = bulk.docs.ints;\n          int end = bulk.docs.offset + nDocs;\n          if (upto + nDocs > docs.length) {\n            if (obs == null) obs = new OpenBitSet(maxDoc());\n            for (int i=bulk.docs.offset; i<end; i++) {\n              obs.fastSet(docArr[i]+base);\n            }\n            bitsSet += nDocs;\n          } else {\n            for (int i=bulk.docs.offset; i<end; i++) {\n              docs[upto++] = docArr[i]+base;\n            }\n          }\n        }\n      }\n    } else {\n      DocsEnum.BulkReadResult bulk = docsEnum.getBulkResult();\n      for (;;) {\n        int nDocs = docsEnum.read();\n        if (nDocs == 0) break;\n        int[] docArr = bulk.docs.ints;\n        int end = bulk.docs.offset + nDocs;\n\n        if (upto + nDocs > docs.length) {\n          if (obs == null) obs = new OpenBitSet(maxDoc());\n          for (int i=bulk.docs.offset; i<end; i++) {\n            obs.fastSet(docArr[i]);\n          }\n          bitsSet += nDocs;\n        } else {\n          for (int i=bulk.docs.offset; i<end; i++) {\n            docs[upto++] = docArr[i];\n          }\n        }\n      }\n    }\n\n    if (obs != null) {\n      for (int i=0; i<upto; i++) {\n        obs.fastSet(docs[i]);  \n      }\n      bitsSet += upto;\n      return new BitDocSet(obs, bitsSet);\n    }\n\n    return new SortedIntDocSet(docs, upto);\n  }\n\n","sourceOld":"  /** lucene.internal */\n  public DocSet getDocSet(DocsEnumState deState) throws IOException {\n    int largestPossible = deState.termsEnum.docFreq();\n    boolean useCache = filterCache != null && largestPossible >= deState.minSetSizeCached;\n    TermQuery key = null;\n\n    if (useCache) {\n      key = new TermQuery(new Term(deState.fieldName, new BytesRef(deState.termsEnum.term()), false));\n      DocSet result = filterCache.get(key);\n      if (result != null) return result;\n    }\n\n    int smallSetSize = maxDoc()>>6;\n    int scratchSize = Math.min(smallSetSize, largestPossible);\n    if (deState.scratch == null || deState.scratch.length < scratchSize)\n      deState.scratch = new int[scratchSize];\n\n    final int[] docs = deState.scratch;\n    int upto = 0;\n    int bitsSet = 0;\n    OpenBitSet obs = null;\n\n    DocsEnum docsEnum = deState.termsEnum.docs(deState.deletedDocs, deState.docsEnum);\n    if (deState.docsEnum == null) {\n      deState.docsEnum = docsEnum;\n    }\n\n    if (docsEnum instanceof MultiDocsEnum) {\n      MultiDocsEnum.EnumWithSlice[] subs = ((MultiDocsEnum)docsEnum).getSubs();\n      int numSubs = ((MultiDocsEnum)docsEnum).getNumSubs();\n      for (int subindex = 0; subindex<numSubs; subindex++) {\n        MultiDocsEnum.EnumWithSlice sub = subs[subindex];\n        if (sub.docsEnum == null) continue;\n        DocsEnum.BulkReadResult bulk = sub.docsEnum.getBulkResult();\n        int base = sub.slice.start;\n\n        for (;;) {\n          int nDocs = sub.docsEnum.read();\n          if (nDocs == 0) break;\n          int[] docArr = bulk.docs.ints;\n          int end = bulk.docs.offset + nDocs;\n          if (upto + nDocs > docs.length) {\n            if (obs == null) obs = new OpenBitSet(maxDoc());\n            for (int i=bulk.docs.offset; i<end; i++) {\n              obs.fastSet(docArr[i]+base);\n            }\n            bitsSet += nDocs;\n          } else {\n            for (int i=bulk.docs.offset; i<end; i++) {\n              docs[upto++] = docArr[i]+base;\n            }\n          }\n        }\n      }\n    } else {\n      DocsEnum.BulkReadResult bulk = docsEnum.getBulkResult();\n      for (;;) {\n        int nDocs = docsEnum.read();\n        if (nDocs == 0) break;\n        int[] docArr = bulk.docs.ints;\n        int end = bulk.docs.offset + nDocs;\n\n        if (upto + nDocs > docs.length) {\n          if (obs == null) obs = new OpenBitSet(maxDoc());\n          for (int i=bulk.docs.offset; i<end; i++) {\n            obs.fastSet(docArr[i]);\n          }\n          bitsSet += nDocs;\n        } else {\n          for (int i=bulk.docs.offset; i<end; i++) {\n            docs[upto++] = docArr[i];\n          }\n        }\n      }\n    }\n\n    DocSet result;\n    if (obs != null) {\n      for (int i=0; i<upto; i++) {\n        obs.fastSet(docs[i]);  \n      }\n      bitsSet += upto;\n      result = new BitDocSet(obs, bitsSet);\n    } else {\n      result = new SortedIntDocSet(Arrays.copyOf(docs, upto));\n    }\n\n    if (useCache) {\n      filterCache.put(key, result);\n    }\n    \n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"21486a8058ee8d7503c7d7a5e55b6c3a218d0942","date":1303841712,"type":5,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSet(DocsEnumState).mjava","pathOld":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet,DocsEnumState).mjava","sourceNew":"  /** lucene.internal */\n  public DocSet getDocSet(DocsEnumState deState) throws IOException {\n    int largestPossible = deState.termsEnum.docFreq();\n    boolean useCache = filterCache != null && largestPossible >= deState.minSetSizeCached;\n    TermQuery key = null;\n\n    if (useCache) {\n      key = new TermQuery(new Term(deState.fieldName, new BytesRef(deState.termsEnum.term()), false));\n      DocSet result = filterCache.get(key);\n      if (result != null) return result;\n    }\n\n    int smallSetSize = maxDoc()>>6;\n    int scratchSize = Math.min(smallSetSize, largestPossible);\n    if (deState.scratch == null || deState.scratch.length < scratchSize)\n      deState.scratch = new int[scratchSize];\n\n    final int[] docs = deState.scratch;\n    int upto = 0;\n    int bitsSet = 0;\n    OpenBitSet obs = null;\n\n    DocsEnum docsEnum = deState.termsEnum.docs(deState.deletedDocs, deState.docsEnum);\n    if (deState.docsEnum == null) {\n      deState.docsEnum = docsEnum;\n    }\n\n    if (docsEnum instanceof MultiDocsEnum) {\n      MultiDocsEnum.EnumWithSlice[] subs = ((MultiDocsEnum)docsEnum).getSubs();\n      int numSubs = ((MultiDocsEnum)docsEnum).getNumSubs();\n      for (int subindex = 0; subindex<numSubs; subindex++) {\n        MultiDocsEnum.EnumWithSlice sub = subs[subindex];\n        if (sub.docsEnum == null) continue;\n        DocsEnum.BulkReadResult bulk = sub.docsEnum.getBulkResult();\n        int base = sub.slice.start;\n\n        for (;;) {\n          int nDocs = sub.docsEnum.read();\n          if (nDocs == 0) break;\n          int[] docArr = bulk.docs.ints;\n          int end = bulk.docs.offset + nDocs;\n          if (upto + nDocs > docs.length) {\n            if (obs == null) obs = new OpenBitSet(maxDoc());\n            for (int i=bulk.docs.offset; i<end; i++) {\n              obs.fastSet(docArr[i]+base);\n            }\n            bitsSet += nDocs;\n          } else {\n            for (int i=bulk.docs.offset; i<end; i++) {\n              docs[upto++] = docArr[i]+base;\n            }\n          }\n        }\n      }\n    } else {\n      DocsEnum.BulkReadResult bulk = docsEnum.getBulkResult();\n      for (;;) {\n        int nDocs = docsEnum.read();\n        if (nDocs == 0) break;\n        int[] docArr = bulk.docs.ints;\n        int end = bulk.docs.offset + nDocs;\n\n        if (upto + nDocs > docs.length) {\n          if (obs == null) obs = new OpenBitSet(maxDoc());\n          for (int i=bulk.docs.offset; i<end; i++) {\n            obs.fastSet(docArr[i]);\n          }\n          bitsSet += nDocs;\n        } else {\n          for (int i=bulk.docs.offset; i<end; i++) {\n            docs[upto++] = docArr[i];\n          }\n        }\n      }\n    }\n\n    DocSet result;\n    if (obs != null) {\n      for (int i=0; i<upto; i++) {\n        obs.fastSet(docs[i]);  \n      }\n      bitsSet += upto;\n      result = new BitDocSet(obs, bitsSet);\n    } else {\n      result = new SortedIntDocSet(Arrays.copyOf(docs, upto));\n    }\n\n    if (useCache) {\n      filterCache.put(key, result);\n    }\n    \n    return result;\n  }\n\n","sourceOld":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter, DocsEnumState deState) throws IOException {\n    if (filter != null) return getDocSetNC(query, filter, null);\n\n    int smallSetSize = maxDoc()>>6;\n    int largestPossible = deState.termsEnum.docFreq();\n\n    int[] docs = new int[Math.min(smallSetSize, largestPossible)];\n    int upto = 0;\n    int bitsSet = 0;\n    OpenBitSet obs = null;\n\n    DocsEnum docsEnum = deState.termsEnum.docs(deState.deletedDocs, deState.reuse);\n    if (deState.reuse == null) {\n      deState.reuse = docsEnum;\n    }\n\n    if (docsEnum instanceof MultiDocsEnum) {\n      MultiDocsEnum.EnumWithSlice[] subs = ((MultiDocsEnum)docsEnum).getSubs();\n      int numSubs = ((MultiDocsEnum)docsEnum).getNumSubs();\n      for (int subindex = 0; subindex<numSubs; subindex++) {\n        MultiDocsEnum.EnumWithSlice sub = subs[subindex];\n        if (sub.docsEnum == null) continue;\n        DocsEnum.BulkReadResult bulk = sub.docsEnum.getBulkResult();\n        int base = sub.slice.start;\n\n        for (;;) {\n          int nDocs = sub.docsEnum.read();\n          if (nDocs == 0) break;\n          int[] docArr = bulk.docs.ints;\n          int end = bulk.docs.offset + nDocs;\n          if (upto + nDocs > docs.length) {\n            if (obs == null) obs = new OpenBitSet(maxDoc());\n            for (int i=bulk.docs.offset; i<end; i++) {\n              obs.fastSet(docArr[i]+base);\n            }\n            bitsSet += nDocs;\n          } else {\n            for (int i=bulk.docs.offset; i<end; i++) {\n              docs[upto++] = docArr[i]+base;\n            }\n          }\n        }\n      }\n    } else {\n      DocsEnum.BulkReadResult bulk = docsEnum.getBulkResult();\n      for (;;) {\n        int nDocs = docsEnum.read();\n        if (nDocs == 0) break;\n        int[] docArr = bulk.docs.ints;\n        int end = bulk.docs.offset + nDocs;\n\n        if (upto + nDocs > docs.length) {\n          if (obs == null) obs = new OpenBitSet(maxDoc());\n          for (int i=bulk.docs.offset; i<end; i++) {\n            obs.fastSet(docArr[i]);\n          }\n          bitsSet += nDocs;\n        } else {\n          for (int i=bulk.docs.offset; i<end; i++) {\n            docs[upto++] = docArr[i];\n          }\n        }\n      }\n    }\n\n    if (obs != null) {\n      for (int i=0; i<upto; i++) {\n        obs.fastSet(docs[i]);  \n      }\n      bitsSet += upto;\n      return new BitDocSet(obs, bitsSet);\n    }\n\n    return new SortedIntDocSet(docs, upto);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7a405e749df166cf8c456ac9381f77f6c99a6270","date":1303842176,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet,DocsEnumState).mjava","pathOld":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSet(DocsEnumState).mjava","sourceNew":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter, DocsEnumState deState) throws IOException {\n    if (filter != null) return getDocSetNC(query, filter, null);\n\n    int smallSetSize = maxDoc()>>6;\n    int largestPossible = deState.termsEnum.docFreq();\n\n    int[] docs = new int[Math.min(smallSetSize, largestPossible)];\n    int upto = 0;\n    int bitsSet = 0;\n    OpenBitSet obs = null;\n\n    DocsEnum docsEnum = deState.termsEnum.docs(deState.deletedDocs, deState.reuse);\n    if (deState.reuse == null) {\n      deState.reuse = docsEnum;\n    }\n\n    if (docsEnum instanceof MultiDocsEnum) {\n      MultiDocsEnum.EnumWithSlice[] subs = ((MultiDocsEnum)docsEnum).getSubs();\n      int numSubs = ((MultiDocsEnum)docsEnum).getNumSubs();\n      for (int subindex = 0; subindex<numSubs; subindex++) {\n        MultiDocsEnum.EnumWithSlice sub = subs[subindex];\n        if (sub.docsEnum == null) continue;\n        DocsEnum.BulkReadResult bulk = sub.docsEnum.getBulkResult();\n        int base = sub.slice.start;\n\n        for (;;) {\n          int nDocs = sub.docsEnum.read();\n          if (nDocs == 0) break;\n          int[] docArr = bulk.docs.ints;\n          int end = bulk.docs.offset + nDocs;\n          if (upto + nDocs > docs.length) {\n            if (obs == null) obs = new OpenBitSet(maxDoc());\n            for (int i=bulk.docs.offset; i<end; i++) {\n              obs.fastSet(docArr[i]+base);\n            }\n            bitsSet += nDocs;\n          } else {\n            for (int i=bulk.docs.offset; i<end; i++) {\n              docs[upto++] = docArr[i]+base;\n            }\n          }\n        }\n      }\n    } else {\n      DocsEnum.BulkReadResult bulk = docsEnum.getBulkResult();\n      for (;;) {\n        int nDocs = docsEnum.read();\n        if (nDocs == 0) break;\n        int[] docArr = bulk.docs.ints;\n        int end = bulk.docs.offset + nDocs;\n\n        if (upto + nDocs > docs.length) {\n          if (obs == null) obs = new OpenBitSet(maxDoc());\n          for (int i=bulk.docs.offset; i<end; i++) {\n            obs.fastSet(docArr[i]);\n          }\n          bitsSet += nDocs;\n        } else {\n          for (int i=bulk.docs.offset; i<end; i++) {\n            docs[upto++] = docArr[i];\n          }\n        }\n      }\n    }\n\n    if (obs != null) {\n      for (int i=0; i<upto; i++) {\n        obs.fastSet(docs[i]);  \n      }\n      bitsSet += upto;\n      return new BitDocSet(obs, bitsSet);\n    }\n\n    return new SortedIntDocSet(docs, upto);\n  }\n\n","sourceOld":"  /** lucene.internal */\n  public DocSet getDocSet(DocsEnumState deState) throws IOException {\n    int largestPossible = deState.termsEnum.docFreq();\n    boolean useCache = filterCache != null && largestPossible >= deState.minSetSizeCached;\n    TermQuery key = null;\n\n    if (useCache) {\n      key = new TermQuery(new Term(deState.fieldName, new BytesRef(deState.termsEnum.term()), false));\n      DocSet result = filterCache.get(key);\n      if (result != null) return result;\n    }\n\n    int smallSetSize = maxDoc()>>6;\n    int scratchSize = Math.min(smallSetSize, largestPossible);\n    if (deState.scratch == null || deState.scratch.length < scratchSize)\n      deState.scratch = new int[scratchSize];\n\n    final int[] docs = deState.scratch;\n    int upto = 0;\n    int bitsSet = 0;\n    OpenBitSet obs = null;\n\n    DocsEnum docsEnum = deState.termsEnum.docs(deState.deletedDocs, deState.docsEnum);\n    if (deState.docsEnum == null) {\n      deState.docsEnum = docsEnum;\n    }\n\n    if (docsEnum instanceof MultiDocsEnum) {\n      MultiDocsEnum.EnumWithSlice[] subs = ((MultiDocsEnum)docsEnum).getSubs();\n      int numSubs = ((MultiDocsEnum)docsEnum).getNumSubs();\n      for (int subindex = 0; subindex<numSubs; subindex++) {\n        MultiDocsEnum.EnumWithSlice sub = subs[subindex];\n        if (sub.docsEnum == null) continue;\n        DocsEnum.BulkReadResult bulk = sub.docsEnum.getBulkResult();\n        int base = sub.slice.start;\n\n        for (;;) {\n          int nDocs = sub.docsEnum.read();\n          if (nDocs == 0) break;\n          int[] docArr = bulk.docs.ints;\n          int end = bulk.docs.offset + nDocs;\n          if (upto + nDocs > docs.length) {\n            if (obs == null) obs = new OpenBitSet(maxDoc());\n            for (int i=bulk.docs.offset; i<end; i++) {\n              obs.fastSet(docArr[i]+base);\n            }\n            bitsSet += nDocs;\n          } else {\n            for (int i=bulk.docs.offset; i<end; i++) {\n              docs[upto++] = docArr[i]+base;\n            }\n          }\n        }\n      }\n    } else {\n      DocsEnum.BulkReadResult bulk = docsEnum.getBulkResult();\n      for (;;) {\n        int nDocs = docsEnum.read();\n        if (nDocs == 0) break;\n        int[] docArr = bulk.docs.ints;\n        int end = bulk.docs.offset + nDocs;\n\n        if (upto + nDocs > docs.length) {\n          if (obs == null) obs = new OpenBitSet(maxDoc());\n          for (int i=bulk.docs.offset; i<end; i++) {\n            obs.fastSet(docArr[i]);\n          }\n          bitsSet += nDocs;\n        } else {\n          for (int i=bulk.docs.offset; i<end; i++) {\n            docs[upto++] = docArr[i];\n          }\n        }\n      }\n    }\n\n    DocSet result;\n    if (obs != null) {\n      for (int i=0; i<upto; i++) {\n        obs.fastSet(docs[i]);  \n      }\n      bitsSet += upto;\n      result = new BitDocSet(obs, bitsSet);\n    } else {\n      result = new SortedIntDocSet(Arrays.copyOf(docs, upto));\n    }\n\n    if (useCache) {\n      filterCache.put(key, result);\n    }\n    \n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f8f944ac3fe3f9d40d825177507fb381d2b106b3","date":1303868525,"type":5,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSet(DocsEnumState).mjava","pathOld":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet,DocsEnumState).mjava","sourceNew":"  /** lucene.internal */\n  public DocSet getDocSet(DocsEnumState deState) throws IOException {\n    int largestPossible = deState.termsEnum.docFreq();\n    boolean useCache = filterCache != null && largestPossible >= deState.minSetSizeCached;\n    TermQuery key = null;\n\n    if (useCache) {\n      key = new TermQuery(new Term(deState.fieldName, new BytesRef(deState.termsEnum.term()), false));\n      DocSet result = filterCache.get(key);\n      if (result != null) return result;\n    }\n\n    int smallSetSize = maxDoc()>>6;\n    int scratchSize = Math.min(smallSetSize, largestPossible);\n    if (deState.scratch == null || deState.scratch.length < scratchSize)\n      deState.scratch = new int[scratchSize];\n\n    final int[] docs = deState.scratch;\n    int upto = 0;\n    int bitsSet = 0;\n    OpenBitSet obs = null;\n\n    DocsEnum docsEnum = deState.termsEnum.docs(deState.deletedDocs, deState.docsEnum);\n    if (deState.docsEnum == null) {\n      deState.docsEnum = docsEnum;\n    }\n\n    if (docsEnum instanceof MultiDocsEnum) {\n      MultiDocsEnum.EnumWithSlice[] subs = ((MultiDocsEnum)docsEnum).getSubs();\n      int numSubs = ((MultiDocsEnum)docsEnum).getNumSubs();\n      for (int subindex = 0; subindex<numSubs; subindex++) {\n        MultiDocsEnum.EnumWithSlice sub = subs[subindex];\n        if (sub.docsEnum == null) continue;\n        DocsEnum.BulkReadResult bulk = sub.docsEnum.getBulkResult();\n        int base = sub.slice.start;\n\n        for (;;) {\n          int nDocs = sub.docsEnum.read();\n          if (nDocs == 0) break;\n          int[] docArr = bulk.docs.ints;\n          int end = bulk.docs.offset + nDocs;\n          if (upto + nDocs > docs.length) {\n            if (obs == null) obs = new OpenBitSet(maxDoc());\n            for (int i=bulk.docs.offset; i<end; i++) {\n              obs.fastSet(docArr[i]+base);\n            }\n            bitsSet += nDocs;\n          } else {\n            for (int i=bulk.docs.offset; i<end; i++) {\n              docs[upto++] = docArr[i]+base;\n            }\n          }\n        }\n      }\n    } else {\n      DocsEnum.BulkReadResult bulk = docsEnum.getBulkResult();\n      for (;;) {\n        int nDocs = docsEnum.read();\n        if (nDocs == 0) break;\n        int[] docArr = bulk.docs.ints;\n        int end = bulk.docs.offset + nDocs;\n\n        if (upto + nDocs > docs.length) {\n          if (obs == null) obs = new OpenBitSet(maxDoc());\n          for (int i=bulk.docs.offset; i<end; i++) {\n            obs.fastSet(docArr[i]);\n          }\n          bitsSet += nDocs;\n        } else {\n          for (int i=bulk.docs.offset; i<end; i++) {\n            docs[upto++] = docArr[i];\n          }\n        }\n      }\n    }\n\n    DocSet result;\n    if (obs != null) {\n      for (int i=0; i<upto; i++) {\n        obs.fastSet(docs[i]);  \n      }\n      bitsSet += upto;\n      result = new BitDocSet(obs, bitsSet);\n    } else {\n      result = new SortedIntDocSet(Arrays.copyOf(docs, upto));\n    }\n\n    if (useCache) {\n      filterCache.put(key, result);\n    }\n    \n    return result;\n  }\n\n","sourceOld":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter, DocsEnumState deState) throws IOException {\n    if (filter != null) return getDocSetNC(query, filter, null);\n\n    int smallSetSize = maxDoc()>>6;\n    int largestPossible = deState.termsEnum.docFreq();\n\n    int[] docs = new int[Math.min(smallSetSize, largestPossible)];\n    int upto = 0;\n    int bitsSet = 0;\n    OpenBitSet obs = null;\n\n    DocsEnum docsEnum = deState.termsEnum.docs(deState.deletedDocs, deState.reuse);\n    if (deState.reuse == null) {\n      deState.reuse = docsEnum;\n    }\n\n    if (docsEnum instanceof MultiDocsEnum) {\n      MultiDocsEnum.EnumWithSlice[] subs = ((MultiDocsEnum)docsEnum).getSubs();\n      int numSubs = ((MultiDocsEnum)docsEnum).getNumSubs();\n      for (int subindex = 0; subindex<numSubs; subindex++) {\n        MultiDocsEnum.EnumWithSlice sub = subs[subindex];\n        if (sub.docsEnum == null) continue;\n        DocsEnum.BulkReadResult bulk = sub.docsEnum.getBulkResult();\n        int base = sub.slice.start;\n\n        for (;;) {\n          int nDocs = sub.docsEnum.read();\n          if (nDocs == 0) break;\n          int[] docArr = bulk.docs.ints;\n          int end = bulk.docs.offset + nDocs;\n          if (upto + nDocs > docs.length) {\n            if (obs == null) obs = new OpenBitSet(maxDoc());\n            for (int i=bulk.docs.offset; i<end; i++) {\n              obs.fastSet(docArr[i]+base);\n            }\n            bitsSet += nDocs;\n          } else {\n            for (int i=bulk.docs.offset; i<end; i++) {\n              docs[upto++] = docArr[i]+base;\n            }\n          }\n        }\n      }\n    } else {\n      DocsEnum.BulkReadResult bulk = docsEnum.getBulkResult();\n      for (;;) {\n        int nDocs = docsEnum.read();\n        if (nDocs == 0) break;\n        int[] docArr = bulk.docs.ints;\n        int end = bulk.docs.offset + nDocs;\n\n        if (upto + nDocs > docs.length) {\n          if (obs == null) obs = new OpenBitSet(maxDoc());\n          for (int i=bulk.docs.offset; i<end; i++) {\n            obs.fastSet(docArr[i]);\n          }\n          bitsSet += nDocs;\n        } else {\n          for (int i=bulk.docs.offset; i<end; i++) {\n            docs[upto++] = docArr[i];\n          }\n        }\n      }\n    }\n\n    if (obs != null) {\n      for (int i=0; i<upto; i++) {\n        obs.fastSet(docs[i]);  \n      }\n      bitsSet += upto;\n      return new BitDocSet(obs, bitsSet);\n    }\n\n    return new SortedIntDocSet(docs, upto);\n  }\n\n","bugFix":null,"bugIntro":["843b845d397272dbafe8b80ebb8f9336d94568ef","843b845d397272dbafe8b80ebb8f9336d94568ef"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d4d5df8e07c035d62d982894b439322da40e0938","date":1303923139,"type":5,"author":"Robert Muir","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSet(DocsEnumState).mjava","pathOld":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet,DocsEnumState).mjava","sourceNew":"  /** lucene.internal */\n  public DocSet getDocSet(DocsEnumState deState) throws IOException {\n    int largestPossible = deState.termsEnum.docFreq();\n    boolean useCache = filterCache != null && largestPossible >= deState.minSetSizeCached;\n    TermQuery key = null;\n\n    if (useCache) {\n      key = new TermQuery(new Term(deState.fieldName, new BytesRef(deState.termsEnum.term()), false));\n      DocSet result = filterCache.get(key);\n      if (result != null) return result;\n    }\n\n    int smallSetSize = maxDoc()>>6;\n    int scratchSize = Math.min(smallSetSize, largestPossible);\n    if (deState.scratch == null || deState.scratch.length < scratchSize)\n      deState.scratch = new int[scratchSize];\n\n    final int[] docs = deState.scratch;\n    int upto = 0;\n    int bitsSet = 0;\n    OpenBitSet obs = null;\n\n    DocsEnum docsEnum = deState.termsEnum.docs(deState.deletedDocs, deState.docsEnum);\n    if (deState.docsEnum == null) {\n      deState.docsEnum = docsEnum;\n    }\n\n    if (docsEnum instanceof MultiDocsEnum) {\n      MultiDocsEnum.EnumWithSlice[] subs = ((MultiDocsEnum)docsEnum).getSubs();\n      int numSubs = ((MultiDocsEnum)docsEnum).getNumSubs();\n      for (int subindex = 0; subindex<numSubs; subindex++) {\n        MultiDocsEnum.EnumWithSlice sub = subs[subindex];\n        if (sub.docsEnum == null) continue;\n        DocsEnum.BulkReadResult bulk = sub.docsEnum.getBulkResult();\n        int base = sub.slice.start;\n\n        for (;;) {\n          int nDocs = sub.docsEnum.read();\n          if (nDocs == 0) break;\n          int[] docArr = bulk.docs.ints;\n          int end = bulk.docs.offset + nDocs;\n          if (upto + nDocs > docs.length) {\n            if (obs == null) obs = new OpenBitSet(maxDoc());\n            for (int i=bulk.docs.offset; i<end; i++) {\n              obs.fastSet(docArr[i]+base);\n            }\n            bitsSet += nDocs;\n          } else {\n            for (int i=bulk.docs.offset; i<end; i++) {\n              docs[upto++] = docArr[i]+base;\n            }\n          }\n        }\n      }\n    } else {\n      DocsEnum.BulkReadResult bulk = docsEnum.getBulkResult();\n      for (;;) {\n        int nDocs = docsEnum.read();\n        if (nDocs == 0) break;\n        int[] docArr = bulk.docs.ints;\n        int end = bulk.docs.offset + nDocs;\n\n        if (upto + nDocs > docs.length) {\n          if (obs == null) obs = new OpenBitSet(maxDoc());\n          for (int i=bulk.docs.offset; i<end; i++) {\n            obs.fastSet(docArr[i]);\n          }\n          bitsSet += nDocs;\n        } else {\n          for (int i=bulk.docs.offset; i<end; i++) {\n            docs[upto++] = docArr[i];\n          }\n        }\n      }\n    }\n\n    DocSet result;\n    if (obs != null) {\n      for (int i=0; i<upto; i++) {\n        obs.fastSet(docs[i]);  \n      }\n      bitsSet += upto;\n      result = new BitDocSet(obs, bitsSet);\n    } else {\n      result = new SortedIntDocSet(Arrays.copyOf(docs, upto));\n    }\n\n    if (useCache) {\n      filterCache.put(key, result);\n    }\n    \n    return result;\n  }\n\n","sourceOld":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter, DocsEnumState deState) throws IOException {\n    if (filter != null) return getDocSetNC(query, filter, null);\n\n    int smallSetSize = maxDoc()>>6;\n    int largestPossible = deState.termsEnum.docFreq();\n\n    int[] docs = new int[Math.min(smallSetSize, largestPossible)];\n    int upto = 0;\n    int bitsSet = 0;\n    OpenBitSet obs = null;\n\n    DocsEnum docsEnum = deState.termsEnum.docs(deState.deletedDocs, deState.reuse);\n    if (deState.reuse == null) {\n      deState.reuse = docsEnum;\n    }\n\n    if (docsEnum instanceof MultiDocsEnum) {\n      MultiDocsEnum.EnumWithSlice[] subs = ((MultiDocsEnum)docsEnum).getSubs();\n      int numSubs = ((MultiDocsEnum)docsEnum).getNumSubs();\n      for (int subindex = 0; subindex<numSubs; subindex++) {\n        MultiDocsEnum.EnumWithSlice sub = subs[subindex];\n        if (sub.docsEnum == null) continue;\n        DocsEnum.BulkReadResult bulk = sub.docsEnum.getBulkResult();\n        int base = sub.slice.start;\n\n        for (;;) {\n          int nDocs = sub.docsEnum.read();\n          if (nDocs == 0) break;\n          int[] docArr = bulk.docs.ints;\n          int end = bulk.docs.offset + nDocs;\n          if (upto + nDocs > docs.length) {\n            if (obs == null) obs = new OpenBitSet(maxDoc());\n            for (int i=bulk.docs.offset; i<end; i++) {\n              obs.fastSet(docArr[i]+base);\n            }\n            bitsSet += nDocs;\n          } else {\n            for (int i=bulk.docs.offset; i<end; i++) {\n              docs[upto++] = docArr[i]+base;\n            }\n          }\n        }\n      }\n    } else {\n      DocsEnum.BulkReadResult bulk = docsEnum.getBulkResult();\n      for (;;) {\n        int nDocs = docsEnum.read();\n        if (nDocs == 0) break;\n        int[] docArr = bulk.docs.ints;\n        int end = bulk.docs.offset + nDocs;\n\n        if (upto + nDocs > docs.length) {\n          if (obs == null) obs = new OpenBitSet(maxDoc());\n          for (int i=bulk.docs.offset; i<end; i++) {\n            obs.fastSet(docArr[i]);\n          }\n          bitsSet += nDocs;\n        } else {\n          for (int i=bulk.docs.offset; i<end; i++) {\n            docs[upto++] = docArr[i];\n          }\n        }\n      }\n    }\n\n    if (obs != null) {\n      for (int i=0; i<upto; i++) {\n        obs.fastSet(docs[i]);  \n      }\n      bitsSet += upto;\n      return new BitDocSet(obs, bitsSet);\n    }\n\n    return new SortedIntDocSet(docs, upto);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"135621f3a0670a9394eb563224a3b76cc4dddc0f","date":1304344257,"type":4,"author":"Simon Willnauer","isMerge":true,"pathNew":"/dev/null","pathOld":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet,DocsEnumState).mjava","sourceNew":null,"sourceOld":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter, DocsEnumState deState) throws IOException {\n    if (filter != null) return getDocSetNC(query, filter, null);\n\n    int smallSetSize = maxDoc()>>6;\n    int largestPossible = deState.termsEnum.docFreq();\n\n    int[] docs = new int[Math.min(smallSetSize, largestPossible)];\n    int upto = 0;\n    int bitsSet = 0;\n    OpenBitSet obs = null;\n\n    DocsEnum docsEnum = deState.termsEnum.docs(deState.deletedDocs, deState.reuse);\n    if (deState.reuse == null) {\n      deState.reuse = docsEnum;\n    }\n\n    if (docsEnum instanceof MultiDocsEnum) {\n      MultiDocsEnum.EnumWithSlice[] subs = ((MultiDocsEnum)docsEnum).getSubs();\n      int numSubs = ((MultiDocsEnum)docsEnum).getNumSubs();\n      for (int subindex = 0; subindex<numSubs; subindex++) {\n        MultiDocsEnum.EnumWithSlice sub = subs[subindex];\n        if (sub.docsEnum == null) continue;\n        DocsEnum.BulkReadResult bulk = sub.docsEnum.getBulkResult();\n        int base = sub.slice.start;\n\n        for (;;) {\n          int nDocs = sub.docsEnum.read();\n          if (nDocs == 0) break;\n          int[] docArr = bulk.docs.ints;\n          int end = bulk.docs.offset + nDocs;\n          if (upto + nDocs > docs.length) {\n            if (obs == null) obs = new OpenBitSet(maxDoc());\n            for (int i=bulk.docs.offset; i<end; i++) {\n              obs.fastSet(docArr[i]+base);\n            }\n            bitsSet += nDocs;\n          } else {\n            for (int i=bulk.docs.offset; i<end; i++) {\n              docs[upto++] = docArr[i]+base;\n            }\n          }\n        }\n      }\n    } else {\n      DocsEnum.BulkReadResult bulk = docsEnum.getBulkResult();\n      for (;;) {\n        int nDocs = docsEnum.read();\n        if (nDocs == 0) break;\n        int[] docArr = bulk.docs.ints;\n        int end = bulk.docs.offset + nDocs;\n\n        if (upto + nDocs > docs.length) {\n          if (obs == null) obs = new OpenBitSet(maxDoc());\n          for (int i=bulk.docs.offset; i<end; i++) {\n            obs.fastSet(docArr[i]);\n          }\n          bitsSet += nDocs;\n        } else {\n          for (int i=bulk.docs.offset; i<end; i++) {\n            docs[upto++] = docArr[i];\n          }\n        }\n      }\n    }\n\n    if (obs != null) {\n      for (int i=0; i<upto; i++) {\n        obs.fastSet(docs[i]);  \n      }\n      bitsSet += upto;\n      return new BitDocSet(obs, bitsSet);\n    }\n\n    return new SortedIntDocSet(docs, upto);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":4,"author":"Steven Rowe","isMerge":true,"pathNew":"/dev/null","pathOld":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet,DocsEnumState).mjava","sourceNew":null,"sourceOld":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter, DocsEnumState deState) throws IOException {\n    if (filter != null) return getDocSetNC(query, filter, null);\n\n    int smallSetSize = maxDoc()>>6;\n    int largestPossible = deState.termsEnum.docFreq();\n\n    int[] docs = new int[Math.min(smallSetSize, largestPossible)];\n    int upto = 0;\n    int bitsSet = 0;\n    OpenBitSet obs = null;\n\n    DocsEnum docsEnum = deState.termsEnum.docs(deState.deletedDocs, deState.reuse);\n    if (deState.reuse == null) {\n      deState.reuse = docsEnum;\n    }\n\n    if (docsEnum instanceof MultiDocsEnum) {\n      MultiDocsEnum.EnumWithSlice[] subs = ((MultiDocsEnum)docsEnum).getSubs();\n      int numSubs = ((MultiDocsEnum)docsEnum).getNumSubs();\n      for (int subindex = 0; subindex<numSubs; subindex++) {\n        MultiDocsEnum.EnumWithSlice sub = subs[subindex];\n        if (sub.docsEnum == null) continue;\n        DocsEnum.BulkReadResult bulk = sub.docsEnum.getBulkResult();\n        int base = sub.slice.start;\n\n        for (;;) {\n          int nDocs = sub.docsEnum.read();\n          if (nDocs == 0) break;\n          int[] docArr = bulk.docs.ints;\n          int end = bulk.docs.offset + nDocs;\n          if (upto + nDocs > docs.length) {\n            if (obs == null) obs = new OpenBitSet(maxDoc());\n            for (int i=bulk.docs.offset; i<end; i++) {\n              obs.fastSet(docArr[i]+base);\n            }\n            bitsSet += nDocs;\n          } else {\n            for (int i=bulk.docs.offset; i<end; i++) {\n              docs[upto++] = docArr[i]+base;\n            }\n          }\n        }\n      }\n    } else {\n      DocsEnum.BulkReadResult bulk = docsEnum.getBulkResult();\n      for (;;) {\n        int nDocs = docsEnum.read();\n        if (nDocs == 0) break;\n        int[] docArr = bulk.docs.ints;\n        int end = bulk.docs.offset + nDocs;\n\n        if (upto + nDocs > docs.length) {\n          if (obs == null) obs = new OpenBitSet(maxDoc());\n          for (int i=bulk.docs.offset; i<end; i++) {\n            obs.fastSet(docArr[i]);\n          }\n          bitsSet += nDocs;\n        } else {\n          for (int i=bulk.docs.offset; i<end; i++) {\n            docs[upto++] = docArr[i];\n          }\n        }\n      }\n    }\n\n    if (obs != null) {\n      for (int i=0; i<upto; i++) {\n        obs.fastSet(docs[i]);  \n      }\n      bitsSet += upto;\n      return new BitDocSet(obs, bitsSet);\n    }\n\n    return new SortedIntDocSet(docs, upto);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"b4cd50ad7936c0f3a0851313b4e0ab861c7a6b17":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"d4d5df8e07c035d62d982894b439322da40e0938":["5f4e87790277826a2aea119328600dfb07761f32","f8f944ac3fe3f9d40d825177507fb381d2b106b3"],"7a405e749df166cf8c456ac9381f77f6c99a6270":["21486a8058ee8d7503c7d7a5e55b6c3a218d0942"],"f20bb72b0dfa147c6f1fcd7693102c63a2714eae":["b4cd50ad7936c0f3a0851313b4e0ab861c7a6b17"],"a3776dccca01c11e7046323cfad46a3b4a471233":["b4cd50ad7936c0f3a0851313b4e0ab861c7a6b17","f8f944ac3fe3f9d40d825177507fb381d2b106b3"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["b4cd50ad7936c0f3a0851313b4e0ab861c7a6b17","f8f944ac3fe3f9d40d825177507fb381d2b106b3"],"0663cc678850ea2c51151f9fd217342ea35b8568":["f20bb72b0dfa147c6f1fcd7693102c63a2714eae"],"5f4e87790277826a2aea119328600dfb07761f32":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","b4cd50ad7936c0f3a0851313b4e0ab861c7a6b17"],"f8f944ac3fe3f9d40d825177507fb381d2b106b3":["7a405e749df166cf8c456ac9381f77f6c99a6270"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["f8f944ac3fe3f9d40d825177507fb381d2b106b3"],"21486a8058ee8d7503c7d7a5e55b6c3a218d0942":["0663cc678850ea2c51151f9fd217342ea35b8568"]},"commit2Childs":{"b4cd50ad7936c0f3a0851313b4e0ab861c7a6b17":["f20bb72b0dfa147c6f1fcd7693102c63a2714eae","a3776dccca01c11e7046323cfad46a3b4a471233","135621f3a0670a9394eb563224a3b76cc4dddc0f","5f4e87790277826a2aea119328600dfb07761f32"],"d4d5df8e07c035d62d982894b439322da40e0938":[],"7a405e749df166cf8c456ac9381f77f6c99a6270":["f8f944ac3fe3f9d40d825177507fb381d2b106b3"],"f20bb72b0dfa147c6f1fcd7693102c63a2714eae":["0663cc678850ea2c51151f9fd217342ea35b8568"],"a3776dccca01c11e7046323cfad46a3b4a471233":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b4cd50ad7936c0f3a0851313b4e0ab861c7a6b17","5f4e87790277826a2aea119328600dfb07761f32"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":[],"0663cc678850ea2c51151f9fd217342ea35b8568":["21486a8058ee8d7503c7d7a5e55b6c3a218d0942"],"5f4e87790277826a2aea119328600dfb07761f32":["d4d5df8e07c035d62d982894b439322da40e0938"],"f8f944ac3fe3f9d40d825177507fb381d2b106b3":["d4d5df8e07c035d62d982894b439322da40e0938","a3776dccca01c11e7046323cfad46a3b4a471233","135621f3a0670a9394eb563224a3b76cc4dddc0f","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"21486a8058ee8d7503c7d7a5e55b6c3a218d0942":["7a405e749df166cf8c456ac9381f77f6c99a6270"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["d4d5df8e07c035d62d982894b439322da40e0938","a3776dccca01c11e7046323cfad46a3b4a471233","135621f3a0670a9394eb563224a3b76cc4dddc0f","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}