{"path":"lucene/src/java/org/apache/lucene/index/SegmentMerger#mergeTerms(SegmentWriteState).mjava","commits":[{"id":"06584e6e98d592b34e1329b384182f368d2025e8","date":1320850353,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#mergeTerms(SegmentWriteState).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentMerger#mergeTerms().mjava","sourceNew":"  private final void mergeTerms(SegmentWriteState segmentWriteState) throws CorruptIndexException, IOException {\n    int docBase = 0;\n    \n    final List<Fields> fields = new ArrayList<Fields>();\n    final List<ReaderUtil.Slice> slices = new ArrayList<ReaderUtil.Slice>();\n\n    for(MergeState.IndexReaderAndLiveDocs r : mergeState.readers) {\n      final Fields f = r.reader.fields();\n      final int maxDoc = r.reader.maxDoc();\n      if (f != null) {\n        slices.add(new ReaderUtil.Slice(docBase, maxDoc, fields.size()));\n        fields.add(f);\n      }\n      docBase += maxDoc;\n    }\n\n    final int numReaders = mergeState.readers.size();\n\n    docBase = 0;\n\n    for(int i=0;i<numReaders;i++) {\n\n      final MergeState.IndexReaderAndLiveDocs reader = mergeState.readers.get(i);\n\n      mergeState.docBase[i] = docBase;\n      final int maxDoc = reader.reader.maxDoc();\n      if (reader.liveDocs != null) {\n        int delCount = 0;\n        final Bits liveDocs = reader.liveDocs;\n        assert liveDocs != null;\n        final int[] docMap = mergeState.docMaps[i] = new int[maxDoc];\n        int newDocID = 0;\n        for(int j=0;j<maxDoc;j++) {\n          if (!liveDocs.get(j)) {\n            docMap[j] = -1;\n            delCount++;\n          } else {\n            docMap[j] = newDocID++;\n          }\n        }\n        docBase += maxDoc - delCount;\n      } else {\n        docBase += maxDoc;\n      }\n\n      if (mergeState.payloadProcessorProvider != null) {\n        mergeState.dirPayloadProcessor[i] = mergeState.payloadProcessorProvider.getDirProcessor(reader.reader.directory());\n      }\n    }\n\n    final FieldsConsumer consumer = codec.postingsFormat().fieldsConsumer(segmentWriteState);\n    boolean success = false;\n    try {\n      consumer.merge(mergeState,\n                     new MultiFields(fields.toArray(Fields.EMPTY_ARRAY),\n                                     slices.toArray(ReaderUtil.Slice.EMPTY_ARRAY)));\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(consumer);\n      } else {\n        IOUtils.closeWhileHandlingException(consumer);\n      }\n    }\n  }\n\n","sourceOld":"  private final void mergeTerms() throws CorruptIndexException, IOException {\n\n    // Let CodecProvider decide which codec will be used to write\n    // the new segment:\n\n    int docBase = 0;\n    \n    final List<Fields> fields = new ArrayList<Fields>();\n    final List<ReaderUtil.Slice> slices = new ArrayList<ReaderUtil.Slice>();\n\n    for(MergeState.IndexReaderAndLiveDocs r : readers) {\n      final Fields f = r.reader.fields();\n      final int maxDoc = r.reader.maxDoc();\n      if (f != null) {\n        slices.add(new ReaderUtil.Slice(docBase, maxDoc, fields.size()));\n        fields.add(f);\n      }\n      docBase += maxDoc;\n    }\n\n    // we may gather more readers than mergeState.readerCount\n    mergeState = new MergeState();\n    mergeState.readers = readers;\n    mergeState.readerCount = readers.size();\n    mergeState.fieldInfos = fieldInfos;\n    mergeState.mergedDocCount = mergedDocs;\n\n    // Remap docIDs\n    mergeState.docMaps = new int[mergeState.readerCount][];\n    mergeState.docBase = new int[mergeState.readerCount];\n    mergeState.hasPayloadProcessorProvider = payloadProcessorProvider != null;\n    mergeState.dirPayloadProcessor = new PayloadProcessorProvider.DirPayloadProcessor[mergeState.readerCount];\n    mergeState.currentPayloadProcessor = new PayloadProcessorProvider.PayloadProcessor[mergeState.readerCount];\n    mergeState.checkAbort = checkAbort;\n\n    docBase = 0;\n    int inputDocBase = 0;\n\n    for(int i=0;i<mergeState.readerCount;i++) {\n\n      final MergeState.IndexReaderAndLiveDocs reader = readers.get(i);\n\n      mergeState.docBase[i] = docBase;\n      inputDocBase += reader.reader.maxDoc();\n      final int maxDoc = reader.reader.maxDoc();\n      if (reader.liveDocs != null) {\n        int delCount = 0;\n        final Bits liveDocs = reader.liveDocs;\n        assert liveDocs != null;\n        final int[] docMap = mergeState.docMaps[i] = new int[maxDoc];\n        int newDocID = 0;\n        for(int j=0;j<maxDoc;j++) {\n          if (!liveDocs.get(j)) {\n            docMap[j] = -1;\n            delCount++;\n          } else {\n            docMap[j] = newDocID++;\n          }\n        }\n        docBase += maxDoc - delCount;\n      } else {\n        docBase += maxDoc;\n      }\n\n      if (payloadProcessorProvider != null) {\n        mergeState.dirPayloadProcessor[i] = payloadProcessorProvider.getDirProcessor(reader.reader.directory());\n      }\n    }\n\n    final FieldsConsumer consumer = codec.postingsFormat().fieldsConsumer(segmentWriteState);\n    boolean success = false;\n    try {\n      consumer.merge(mergeState,\n                     new MultiFields(fields.toArray(Fields.EMPTY_ARRAY),\n                                     slices.toArray(ReaderUtil.Slice.EMPTY_ARRAY)));\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(consumer);\n      } else {\n        IOUtils.closeWhileHandlingException(consumer);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"893d07555f01912f57b453a320e4d46363a31b50","date":1327312526,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#mergeTerms(SegmentWriteState).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentMerger#mergeTerms(SegmentWriteState).mjava","sourceNew":"  private final void mergeTerms(SegmentWriteState segmentWriteState) throws CorruptIndexException, IOException {\n    int docBase = 0;\n    \n    final List<Fields> fields = new ArrayList<Fields>();\n    final List<ReaderUtil.Slice> slices = new ArrayList<ReaderUtil.Slice>();\n\n    for(MergeState.IndexReaderAndLiveDocs r : mergeState.readers) {\n      final Fields f = r.reader.fields();\n      final int maxDoc = r.reader.maxDoc();\n      if (f != null) {\n        slices.add(new ReaderUtil.Slice(docBase, maxDoc, fields.size()));\n        fields.add(f);\n      }\n      docBase += maxDoc;\n    }\n\n    final int numReaders = mergeState.readers.size();\n\n    docBase = 0;\n\n    for(int i=0;i<numReaders;i++) {\n\n      final MergeState.IndexReaderAndLiveDocs reader = mergeState.readers.get(i);\n\n      mergeState.docBase[i] = docBase;\n      final int maxDoc = reader.reader.maxDoc();\n      if (reader.liveDocs != null) {\n        int delCount = 0;\n        final Bits liveDocs = reader.liveDocs;\n        assert liveDocs != null;\n        final int[] docMap = mergeState.docMaps[i] = new int[maxDoc];\n        int newDocID = 0;\n        for(int j=0;j<maxDoc;j++) {\n          if (!liveDocs.get(j)) {\n            docMap[j] = -1;\n            delCount++;\n          } else {\n            docMap[j] = newDocID++;\n          }\n        }\n        docBase += maxDoc - delCount;\n      } else {\n        docBase += maxDoc;\n      }\n\n      if (mergeState.payloadProcessorProvider != null) {\n        // nocommit: this was original, is the change correct:\n        // mergeState.dirPayloadProcessor[i] = mergeState.payloadProcessorProvider.getDirProcessor(reader.reader.directory());\n        mergeState.dirPayloadProcessor[i] = mergeState.payloadProcessorProvider.getDirProcessor(directory);\n      }\n    }\n\n    final FieldsConsumer consumer = codec.postingsFormat().fieldsConsumer(segmentWriteState);\n    boolean success = false;\n    try {\n      consumer.merge(mergeState,\n                     new MultiFields(fields.toArray(Fields.EMPTY_ARRAY),\n                                     slices.toArray(ReaderUtil.Slice.EMPTY_ARRAY)));\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(consumer);\n      } else {\n        IOUtils.closeWhileHandlingException(consumer);\n      }\n    }\n  }\n\n","sourceOld":"  private final void mergeTerms(SegmentWriteState segmentWriteState) throws CorruptIndexException, IOException {\n    int docBase = 0;\n    \n    final List<Fields> fields = new ArrayList<Fields>();\n    final List<ReaderUtil.Slice> slices = new ArrayList<ReaderUtil.Slice>();\n\n    for(MergeState.IndexReaderAndLiveDocs r : mergeState.readers) {\n      final Fields f = r.reader.fields();\n      final int maxDoc = r.reader.maxDoc();\n      if (f != null) {\n        slices.add(new ReaderUtil.Slice(docBase, maxDoc, fields.size()));\n        fields.add(f);\n      }\n      docBase += maxDoc;\n    }\n\n    final int numReaders = mergeState.readers.size();\n\n    docBase = 0;\n\n    for(int i=0;i<numReaders;i++) {\n\n      final MergeState.IndexReaderAndLiveDocs reader = mergeState.readers.get(i);\n\n      mergeState.docBase[i] = docBase;\n      final int maxDoc = reader.reader.maxDoc();\n      if (reader.liveDocs != null) {\n        int delCount = 0;\n        final Bits liveDocs = reader.liveDocs;\n        assert liveDocs != null;\n        final int[] docMap = mergeState.docMaps[i] = new int[maxDoc];\n        int newDocID = 0;\n        for(int j=0;j<maxDoc;j++) {\n          if (!liveDocs.get(j)) {\n            docMap[j] = -1;\n            delCount++;\n          } else {\n            docMap[j] = newDocID++;\n          }\n        }\n        docBase += maxDoc - delCount;\n      } else {\n        docBase += maxDoc;\n      }\n\n      if (mergeState.payloadProcessorProvider != null) {\n        mergeState.dirPayloadProcessor[i] = mergeState.payloadProcessorProvider.getDirProcessor(reader.reader.directory());\n      }\n    }\n\n    final FieldsConsumer consumer = codec.postingsFormat().fieldsConsumer(segmentWriteState);\n    boolean success = false;\n    try {\n      consumer.merge(mergeState,\n                     new MultiFields(fields.toArray(Fields.EMPTY_ARRAY),\n                                     slices.toArray(ReaderUtil.Slice.EMPTY_ARRAY)));\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(consumer);\n      } else {\n        IOUtils.closeWhileHandlingException(consumer);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ccad4bab070f323ce610caa0040346d4a87213dc","date":1327747432,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#mergeTerms(SegmentWriteState).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentMerger#mergeTerms(SegmentWriteState).mjava","sourceNew":"  private final void mergeTerms(SegmentWriteState segmentWriteState) throws CorruptIndexException, IOException {\n    \n    final List<Fields> fields = new ArrayList<Fields>();\n    final List<ReaderUtil.Slice> slices = new ArrayList<ReaderUtil.Slice>();\n\n    int docBase = 0;\n\n    for(int readerIndex=0;readerIndex<mergeState.readers.size();readerIndex++) {\n      final MergeState.IndexReaderAndLiveDocs r = mergeState.readers.get(readerIndex);\n      final Fields f = r.reader.fields();\n      final int maxDoc = r.reader.maxDoc();\n      if (f != null) {\n        slices.add(new ReaderUtil.Slice(docBase, maxDoc, readerIndex));\n        fields.add(f);\n      }\n      docBase += maxDoc;\n    }\n\n    final FieldsConsumer consumer = codec.postingsFormat().fieldsConsumer(segmentWriteState);\n    boolean success = false;\n    try {\n      consumer.merge(mergeState,\n                     new MultiFields(fields.toArray(Fields.EMPTY_ARRAY),\n                                     slices.toArray(ReaderUtil.Slice.EMPTY_ARRAY)));\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(consumer);\n      } else {\n        IOUtils.closeWhileHandlingException(consumer);\n      }\n    }\n  }\n\n","sourceOld":"  private final void mergeTerms(SegmentWriteState segmentWriteState) throws CorruptIndexException, IOException {\n    int docBase = 0;\n    \n    final List<Fields> fields = new ArrayList<Fields>();\n    final List<ReaderUtil.Slice> slices = new ArrayList<ReaderUtil.Slice>();\n\n    for(MergeState.IndexReaderAndLiveDocs r : mergeState.readers) {\n      final Fields f = r.reader.fields();\n      final int maxDoc = r.reader.maxDoc();\n      if (f != null) {\n        slices.add(new ReaderUtil.Slice(docBase, maxDoc, fields.size()));\n        fields.add(f);\n      }\n      docBase += maxDoc;\n    }\n\n    final int numReaders = mergeState.readers.size();\n\n    docBase = 0;\n\n    for(int i=0;i<numReaders;i++) {\n\n      final MergeState.IndexReaderAndLiveDocs reader = mergeState.readers.get(i);\n\n      mergeState.docBase[i] = docBase;\n      final int maxDoc = reader.reader.maxDoc();\n      if (reader.liveDocs != null) {\n        int delCount = 0;\n        final Bits liveDocs = reader.liveDocs;\n        assert liveDocs != null;\n        final int[] docMap = mergeState.docMaps[i] = new int[maxDoc];\n        int newDocID = 0;\n        for(int j=0;j<maxDoc;j++) {\n          if (!liveDocs.get(j)) {\n            docMap[j] = -1;\n            delCount++;\n          } else {\n            docMap[j] = newDocID++;\n          }\n        }\n        docBase += maxDoc - delCount;\n      } else {\n        docBase += maxDoc;\n      }\n\n      if (mergeState.payloadProcessorProvider != null) {\n        mergeState.dirPayloadProcessor[i] = mergeState.payloadProcessorProvider.getDirProcessor(reader.reader.directory());\n      }\n    }\n\n    final FieldsConsumer consumer = codec.postingsFormat().fieldsConsumer(segmentWriteState);\n    boolean success = false;\n    try {\n      consumer.merge(mergeState,\n                     new MultiFields(fields.toArray(Fields.EMPTY_ARRAY),\n                                     slices.toArray(ReaderUtil.Slice.EMPTY_ARRAY)));\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(consumer);\n      } else {\n        IOUtils.closeWhileHandlingException(consumer);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["c95a819869502635864dac0a788f874787e3395b"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c9f2d6bb11ccaac366d9b7652b2feb0c715d9c31","date":1327836826,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#mergeTerms(SegmentWriteState).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentMerger#mergeTerms(SegmentWriteState).mjava","sourceNew":"  private final void mergeTerms(SegmentWriteState segmentWriteState) throws CorruptIndexException, IOException {\n    \n    final List<Fields> fields = new ArrayList<Fields>();\n    final List<ReaderUtil.Slice> slices = new ArrayList<ReaderUtil.Slice>();\n\n    int docBase = 0;\n\n    for(int readerIndex=0;readerIndex<mergeState.readers.size();readerIndex++) {\n      final MergeState.IndexReaderAndLiveDocs r = mergeState.readers.get(readerIndex);\n      final Fields f = r.reader.fields();\n      final int maxDoc = r.reader.maxDoc();\n      if (f != null) {\n        slices.add(new ReaderUtil.Slice(docBase, maxDoc, readerIndex));\n        fields.add(f);\n      }\n      docBase += maxDoc;\n    }\n\n    final FieldsConsumer consumer = codec.postingsFormat().fieldsConsumer(segmentWriteState);\n    boolean success = false;\n    try {\n      consumer.merge(mergeState,\n                     new MultiFields(fields.toArray(Fields.EMPTY_ARRAY),\n                                     slices.toArray(ReaderUtil.Slice.EMPTY_ARRAY)));\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(consumer);\n      } else {\n        IOUtils.closeWhileHandlingException(consumer);\n      }\n    }\n  }\n\n","sourceOld":"  private final void mergeTerms(SegmentWriteState segmentWriteState) throws CorruptIndexException, IOException {\n    int docBase = 0;\n    \n    final List<Fields> fields = new ArrayList<Fields>();\n    final List<ReaderUtil.Slice> slices = new ArrayList<ReaderUtil.Slice>();\n\n    for(MergeState.IndexReaderAndLiveDocs r : mergeState.readers) {\n      final Fields f = r.reader.fields();\n      final int maxDoc = r.reader.maxDoc();\n      if (f != null) {\n        slices.add(new ReaderUtil.Slice(docBase, maxDoc, fields.size()));\n        fields.add(f);\n      }\n      docBase += maxDoc;\n    }\n\n    final int numReaders = mergeState.readers.size();\n\n    docBase = 0;\n\n    for(int i=0;i<numReaders;i++) {\n\n      final MergeState.IndexReaderAndLiveDocs reader = mergeState.readers.get(i);\n\n      mergeState.docBase[i] = docBase;\n      final int maxDoc = reader.reader.maxDoc();\n      if (reader.liveDocs != null) {\n        int delCount = 0;\n        final Bits liveDocs = reader.liveDocs;\n        assert liveDocs != null;\n        final int[] docMap = mergeState.docMaps[i] = new int[maxDoc];\n        int newDocID = 0;\n        for(int j=0;j<maxDoc;j++) {\n          if (!liveDocs.get(j)) {\n            docMap[j] = -1;\n            delCount++;\n          } else {\n            docMap[j] = newDocID++;\n          }\n        }\n        docBase += maxDoc - delCount;\n      } else {\n        docBase += maxDoc;\n      }\n\n      if (mergeState.payloadProcessorProvider != null) {\n        mergeState.dirPayloadProcessor[i] = mergeState.payloadProcessorProvider.getDirProcessor(reader.reader.directory());\n      }\n    }\n\n    final FieldsConsumer consumer = codec.postingsFormat().fieldsConsumer(segmentWriteState);\n    boolean success = false;\n    try {\n      consumer.merge(mergeState,\n                     new MultiFields(fields.toArray(Fields.EMPTY_ARRAY),\n                                     slices.toArray(ReaderUtil.Slice.EMPTY_ARRAY)));\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(consumer);\n      } else {\n        IOUtils.closeWhileHandlingException(consumer);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fd92b8bcc88e969302510acf77bd6970da3994c4","date":1327839530,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#mergeTerms(SegmentWriteState).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentMerger#mergeTerms(SegmentWriteState).mjava","sourceNew":"  private final void mergeTerms(SegmentWriteState segmentWriteState) throws CorruptIndexException, IOException {\n    \n    final List<Fields> fields = new ArrayList<Fields>();\n    final List<ReaderUtil.Slice> slices = new ArrayList<ReaderUtil.Slice>();\n\n    int docBase = 0;\n\n    for(int readerIndex=0;readerIndex<mergeState.readers.size();readerIndex++) {\n      final MergeState.IndexReaderAndLiveDocs r = mergeState.readers.get(readerIndex);\n      final Fields f = r.reader.fields();\n      final int maxDoc = r.reader.maxDoc();\n      if (f != null) {\n        slices.add(new ReaderUtil.Slice(docBase, maxDoc, readerIndex));\n        fields.add(f);\n      }\n      docBase += maxDoc;\n    }\n\n    final FieldsConsumer consumer = codec.postingsFormat().fieldsConsumer(segmentWriteState);\n    boolean success = false;\n    try {\n      consumer.merge(mergeState,\n                     new MultiFields(fields.toArray(Fields.EMPTY_ARRAY),\n                                     slices.toArray(ReaderUtil.Slice.EMPTY_ARRAY)));\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(consumer);\n      } else {\n        IOUtils.closeWhileHandlingException(consumer);\n      }\n    }\n  }\n\n","sourceOld":"  private final void mergeTerms(SegmentWriteState segmentWriteState) throws CorruptIndexException, IOException {\n    int docBase = 0;\n    \n    final List<Fields> fields = new ArrayList<Fields>();\n    final List<ReaderUtil.Slice> slices = new ArrayList<ReaderUtil.Slice>();\n\n    for(MergeState.IndexReaderAndLiveDocs r : mergeState.readers) {\n      final Fields f = r.reader.fields();\n      final int maxDoc = r.reader.maxDoc();\n      if (f != null) {\n        slices.add(new ReaderUtil.Slice(docBase, maxDoc, fields.size()));\n        fields.add(f);\n      }\n      docBase += maxDoc;\n    }\n\n    final int numReaders = mergeState.readers.size();\n\n    docBase = 0;\n\n    for(int i=0;i<numReaders;i++) {\n\n      final MergeState.IndexReaderAndLiveDocs reader = mergeState.readers.get(i);\n\n      mergeState.docBase[i] = docBase;\n      final int maxDoc = reader.reader.maxDoc();\n      if (reader.liveDocs != null) {\n        int delCount = 0;\n        final Bits liveDocs = reader.liveDocs;\n        assert liveDocs != null;\n        final int[] docMap = mergeState.docMaps[i] = new int[maxDoc];\n        int newDocID = 0;\n        for(int j=0;j<maxDoc;j++) {\n          if (!liveDocs.get(j)) {\n            docMap[j] = -1;\n            delCount++;\n          } else {\n            docMap[j] = newDocID++;\n          }\n        }\n        docBase += maxDoc - delCount;\n      } else {\n        docBase += maxDoc;\n      }\n\n      if (mergeState.payloadProcessorProvider != null) {\n        // nocommit: this was original, is the change correct:\n        // mergeState.dirPayloadProcessor[i] = mergeState.payloadProcessorProvider.getDirProcessor(reader.reader.directory());\n        mergeState.dirPayloadProcessor[i] = mergeState.payloadProcessorProvider.getDirProcessor(directory);\n      }\n    }\n\n    final FieldsConsumer consumer = codec.postingsFormat().fieldsConsumer(segmentWriteState);\n    boolean success = false;\n    try {\n      consumer.merge(mergeState,\n                     new MultiFields(fields.toArray(Fields.EMPTY_ARRAY),\n                                     slices.toArray(ReaderUtil.Slice.EMPTY_ARRAY)));\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(consumer);\n      } else {\n        IOUtils.closeWhileHandlingException(consumer);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentMerger#mergeTerms(SegmentWriteState).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentMerger#mergeTerms(SegmentWriteState).mjava","sourceNew":"  private final void mergeTerms(SegmentWriteState segmentWriteState) throws CorruptIndexException, IOException {\n    \n    final List<Fields> fields = new ArrayList<Fields>();\n    final List<ReaderUtil.Slice> slices = new ArrayList<ReaderUtil.Slice>();\n\n    int docBase = 0;\n\n    for(int readerIndex=0;readerIndex<mergeState.readers.size();readerIndex++) {\n      final MergeState.IndexReaderAndLiveDocs r = mergeState.readers.get(readerIndex);\n      final Fields f = r.reader.fields();\n      final int maxDoc = r.reader.maxDoc();\n      if (f != null) {\n        slices.add(new ReaderUtil.Slice(docBase, maxDoc, readerIndex));\n        fields.add(f);\n      }\n      docBase += maxDoc;\n    }\n\n    final FieldsConsumer consumer = codec.postingsFormat().fieldsConsumer(segmentWriteState);\n    boolean success = false;\n    try {\n      consumer.merge(mergeState,\n                     new MultiFields(fields.toArray(Fields.EMPTY_ARRAY),\n                                     slices.toArray(ReaderUtil.Slice.EMPTY_ARRAY)));\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(consumer);\n      } else {\n        IOUtils.closeWhileHandlingException(consumer);\n      }\n    }\n  }\n\n","sourceOld":"  private final void mergeTerms(SegmentWriteState segmentWriteState) throws CorruptIndexException, IOException {\n    \n    final List<Fields> fields = new ArrayList<Fields>();\n    final List<ReaderUtil.Slice> slices = new ArrayList<ReaderUtil.Slice>();\n\n    int docBase = 0;\n\n    for(int readerIndex=0;readerIndex<mergeState.readers.size();readerIndex++) {\n      final MergeState.IndexReaderAndLiveDocs r = mergeState.readers.get(readerIndex);\n      final Fields f = r.reader.fields();\n      final int maxDoc = r.reader.maxDoc();\n      if (f != null) {\n        slices.add(new ReaderUtil.Slice(docBase, maxDoc, readerIndex));\n        fields.add(f);\n      }\n      docBase += maxDoc;\n    }\n\n    final FieldsConsumer consumer = codec.postingsFormat().fieldsConsumer(segmentWriteState);\n    boolean success = false;\n    try {\n      consumer.merge(mergeState,\n                     new MultiFields(fields.toArray(Fields.EMPTY_ARRAY),\n                                     slices.toArray(ReaderUtil.Slice.EMPTY_ARRAY)));\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(consumer);\n      } else {\n        IOUtils.closeWhileHandlingException(consumer);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["c9f2d6bb11ccaac366d9b7652b2feb0c715d9c31"],"06584e6e98d592b34e1329b384182f368d2025e8":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"893d07555f01912f57b453a320e4d46363a31b50":["06584e6e98d592b34e1329b384182f368d2025e8"],"fd92b8bcc88e969302510acf77bd6970da3994c4":["893d07555f01912f57b453a320e4d46363a31b50","c9f2d6bb11ccaac366d9b7652b2feb0c715d9c31"],"c9f2d6bb11ccaac366d9b7652b2feb0c715d9c31":["06584e6e98d592b34e1329b384182f368d2025e8","ccad4bab070f323ce610caa0040346d4a87213dc"],"ccad4bab070f323ce610caa0040346d4a87213dc":["06584e6e98d592b34e1329b384182f368d2025e8"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"]},"commit2Childs":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"06584e6e98d592b34e1329b384182f368d2025e8":["893d07555f01912f57b453a320e4d46363a31b50","c9f2d6bb11ccaac366d9b7652b2feb0c715d9c31","ccad4bab070f323ce610caa0040346d4a87213dc"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["06584e6e98d592b34e1329b384182f368d2025e8"],"893d07555f01912f57b453a320e4d46363a31b50":["fd92b8bcc88e969302510acf77bd6970da3994c4"],"fd92b8bcc88e969302510acf77bd6970da3994c4":[],"c9f2d6bb11ccaac366d9b7652b2feb0c715d9c31":["3a119bbc8703c10faa329ec201c654b3a35a1e3e","fd92b8bcc88e969302510acf77bd6970da3994c4"],"ccad4bab070f323ce610caa0040346d4a87213dc":["c9f2d6bb11ccaac366d9b7652b2feb0c715d9c31"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["fd92b8bcc88e969302510acf77bd6970da3994c4","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}