{"path":"modules/suggest/src/java/org/apache/lucene/search/spell/DirectSpellChecker#suggestSimilar(Term,int,IndexReader,boolean,float).mjava","commits":[{"id":"e230a61047bc041516c811baa08a7174d6f8322a","date":1306175633,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"modules/suggest/src/java/org/apache/lucene/search/spell/DirectSpellChecker#suggestSimilar(Term,int,IndexReader,boolean,float).mjava","pathOld":"lucene/contrib/spellchecker/src/java/org/apache/lucene/search/spell/DirectSpellChecker#suggestSimilar(Term,int,IndexReader,boolean,float).mjava","sourceNew":"  /**\n   * Suggest similar words.\n   * \n   * <p>Unlike {@link SpellChecker}, the similarity used to fetch the most\n   * relevant terms is an edit distance, therefore typically a low value\n   * for numSug will work very well.\n   * \n   * @param term Term you want to spell check on\n   * @param numSug the maximum number of suggested words\n   * @param ir IndexReader to find terms from\n   * @param morePopular return only suggested words that are as frequent or more frequent than the searched word\n   * @param accuracy return only suggested words that match with this similarity\n   * @return sorted list of the suggested words according to the comparator\n   * @throws IOException\n   */\n  public SuggestWord[] suggestSimilar(Term term, int numSug, IndexReader ir, \n      boolean morePopular, float accuracy) throws IOException {\n    \n    String text = term.text();\n    if (minQueryLength > 0 && text.codePointCount(0, text.length()) < minQueryLength)\n      return new SuggestWord[0];\n    \n    if (lowerCaseTerms)\n      term = term.createTerm(text.toLowerCase(Locale.ENGLISH));\n    \n    int docfreq = ir.docFreq(term);\n    \n    // see line 341 of spellchecker. this is certainly very very nice for perf,\n    // but is it really the right way to go?\n    if (!morePopular && docfreq > 0) {\n      return new SuggestWord[0];\n    }\n    \n    int maxDoc = ir.maxDoc();\n    \n    if (maxQueryFrequency >= 1f && docfreq > maxQueryFrequency) {\n      return new SuggestWord[0];\n    } else if (docfreq > (int) Math.ceil(maxQueryFrequency * (float)maxDoc)) {\n      return new SuggestWord[0];\n    }\n    \n    if (!morePopular) docfreq = 0;\n    \n    if (thresholdFrequency >= 1f) {\n      docfreq = Math.max(docfreq, (int) thresholdFrequency);\n    } else if (thresholdFrequency > 0f) {\n      docfreq = Math.max(docfreq, (int)(thresholdFrequency * (float)maxDoc)-1);\n    }\n    \n    Collection<ScoreTerm> terms = null;\n    int inspections = numSug * maxInspections;\n    \n    // try ed=1 first, in case we get lucky\n    terms = suggestSimilar(term, inspections, ir, docfreq, 1, accuracy);\n    if (maxEdits > 1 && terms.size() < inspections) {\n      HashSet<ScoreTerm> moreTerms = new HashSet<ScoreTerm>();\n      moreTerms.addAll(terms);\n      moreTerms.addAll(suggestSimilar(term, inspections, ir, docfreq, maxEdits, accuracy));\n      terms = moreTerms;\n    }\n    \n    // create the suggestword response, sort it, and trim it to size.\n    \n    SuggestWord suggestions[] = new SuggestWord[terms.size()];\n    int index = suggestions.length - 1;\n    for (ScoreTerm s : terms) {\n      SuggestWord suggestion = new SuggestWord();\n      suggestion.string = s.termAsString != null ? s.termAsString : s.term.utf8ToString();\n      suggestion.score = s.score;\n      suggestion.freq = s.docfreq;\n      suggestions[index--] = suggestion;\n    }\n    \n    ArrayUtil.mergeSort(suggestions, Collections.reverseOrder(comparator));\n    if (numSug < suggestions.length) {\n      SuggestWord trimmed[] = new SuggestWord[numSug];\n      System.arraycopy(suggestions, 0, trimmed, 0, numSug);\n      suggestions = trimmed;\n    }\n    return suggestions;\n  }\n\n","sourceOld":"  /**\n   * Suggest similar words.\n   * \n   * <p>Unlike {@link SpellChecker}, the similarity used to fetch the most\n   * relevant terms is an edit distance, therefore typically a low value\n   * for numSug will work very well.\n   * \n   * @param term Term you want to spell check on\n   * @param numSug the maximum number of suggested words\n   * @param ir IndexReader to find terms from\n   * @param morePopular return only suggested words that are as frequent or more frequent than the searched word\n   * @param accuracy return only suggested words that match with this similarity\n   * @return sorted list of the suggested words according to the comparator\n   * @throws IOException\n   */\n  public SuggestWord[] suggestSimilar(Term term, int numSug, IndexReader ir, \n      boolean morePopular, float accuracy) throws IOException {\n    \n    String text = term.text();\n    if (minQueryLength > 0 && text.codePointCount(0, text.length()) < minQueryLength)\n      return new SuggestWord[0];\n    \n    if (lowerCaseTerms)\n      term = term.createTerm(text.toLowerCase(Locale.ENGLISH));\n    \n    int docfreq = ir.docFreq(term);\n    \n    // see line 341 of spellchecker. this is certainly very very nice for perf,\n    // but is it really the right way to go?\n    if (!morePopular && docfreq > 0) {\n      return new SuggestWord[0];\n    }\n    \n    int maxDoc = ir.maxDoc();\n    \n    if (maxQueryFrequency >= 1f && docfreq > maxQueryFrequency) {\n      return new SuggestWord[0];\n    } else if (docfreq > (int) Math.ceil(maxQueryFrequency * (float)maxDoc)) {\n      return new SuggestWord[0];\n    }\n    \n    if (!morePopular) docfreq = 0;\n    \n    if (thresholdFrequency >= 1f) {\n      docfreq = Math.max(docfreq, (int) thresholdFrequency);\n    } else if (thresholdFrequency > 0f) {\n      docfreq = Math.max(docfreq, (int)(thresholdFrequency * (float)maxDoc)-1);\n    }\n    \n    Collection<ScoreTerm> terms = null;\n    int inspections = numSug * maxInspections;\n    \n    // try ed=1 first, in case we get lucky\n    terms = suggestSimilar(term, inspections, ir, docfreq, 1, accuracy);\n    if (maxEdits > 1 && terms.size() < inspections) {\n      HashSet<ScoreTerm> moreTerms = new HashSet<ScoreTerm>();\n      moreTerms.addAll(terms);\n      moreTerms.addAll(suggestSimilar(term, inspections, ir, docfreq, maxEdits, accuracy));\n      terms = moreTerms;\n    }\n    \n    // create the suggestword response, sort it, and trim it to size.\n    \n    SuggestWord suggestions[] = new SuggestWord[terms.size()];\n    int index = suggestions.length - 1;\n    for (ScoreTerm s : terms) {\n      SuggestWord suggestion = new SuggestWord();\n      suggestion.string = s.termAsString != null ? s.termAsString : s.term.utf8ToString();\n      suggestion.score = s.score;\n      suggestion.freq = s.docfreq;\n      suggestions[index--] = suggestion;\n    }\n    \n    ArrayUtil.mergeSort(suggestions, Collections.reverseOrder(comparator));\n    if (numSug < suggestions.length) {\n      SuggestWord trimmed[] = new SuggestWord[numSug];\n      System.arraycopy(suggestions, 0, trimmed, 0, numSug);\n      suggestions = trimmed;\n    }\n    return suggestions;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a1b3a24d5d9b47345473ff564f5cc127a7b526b4","date":1306277076,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"modules/suggest/src/java/org/apache/lucene/search/spell/DirectSpellChecker#suggestSimilar(Term,int,IndexReader,boolean,float).mjava","pathOld":"modules/suggest/src/java/org/apache/lucene/search/spell/DirectSpellChecker#suggestSimilar(Term,int,IndexReader,boolean,float).mjava","sourceNew":"  /**\n   * Suggest similar words.\n   * \n   * <p>Unlike {@link SpellChecker}, the similarity used to fetch the most\n   * relevant terms is an edit distance, therefore typically a low value\n   * for numSug will work very well.\n   * \n   * @param term Term you want to spell check on\n   * @param numSug the maximum number of suggested words\n   * @param ir IndexReader to find terms from\n   * @param morePopular return only suggested words that are as frequent or more frequent than the searched word\n   * @param accuracy return only suggested words that match with this similarity\n   * @return sorted list of the suggested words according to the comparator\n   * @throws IOException\n   */\n  public SuggestWord[] suggestSimilar(Term term, int numSug, IndexReader ir, \n      boolean morePopular, float accuracy) throws IOException {\n    final CharsRef spare = new CharsRef();\n    String text = term.text();\n    if (minQueryLength > 0 && text.codePointCount(0, text.length()) < minQueryLength)\n      return new SuggestWord[0];\n    \n    if (lowerCaseTerms)\n      term = term.createTerm(text.toLowerCase(Locale.ENGLISH));\n    \n    int docfreq = ir.docFreq(term);\n    \n    // see line 341 of spellchecker. this is certainly very very nice for perf,\n    // but is it really the right way to go?\n    if (!morePopular && docfreq > 0) {\n      return new SuggestWord[0];\n    }\n    \n    int maxDoc = ir.maxDoc();\n    \n    if (maxQueryFrequency >= 1f && docfreq > maxQueryFrequency) {\n      return new SuggestWord[0];\n    } else if (docfreq > (int) Math.ceil(maxQueryFrequency * (float)maxDoc)) {\n      return new SuggestWord[0];\n    }\n    \n    if (!morePopular) docfreq = 0;\n    \n    if (thresholdFrequency >= 1f) {\n      docfreq = Math.max(docfreq, (int) thresholdFrequency);\n    } else if (thresholdFrequency > 0f) {\n      docfreq = Math.max(docfreq, (int)(thresholdFrequency * (float)maxDoc)-1);\n    }\n    \n    Collection<ScoreTerm> terms = null;\n    int inspections = numSug * maxInspections;\n    \n    // try ed=1 first, in case we get lucky\n    terms = suggestSimilar(term, inspections, ir, docfreq, 1, accuracy, spare);\n    if (maxEdits > 1 && terms.size() < inspections) {\n      HashSet<ScoreTerm> moreTerms = new HashSet<ScoreTerm>();\n      moreTerms.addAll(terms);\n      moreTerms.addAll(suggestSimilar(term, inspections, ir, docfreq, maxEdits, accuracy, spare));\n      terms = moreTerms;\n    }\n    \n    // create the suggestword response, sort it, and trim it to size.\n    \n    SuggestWord suggestions[] = new SuggestWord[terms.size()];\n    int index = suggestions.length - 1;\n    for (ScoreTerm s : terms) {\n      SuggestWord suggestion = new SuggestWord();\n      suggestion.string = s.termAsString != null ? s.termAsString : s.term.utf8ToChars(spare).toString();\n      suggestion.score = s.score;\n      suggestion.freq = s.docfreq;\n      suggestions[index--] = suggestion;\n    }\n    \n    ArrayUtil.mergeSort(suggestions, Collections.reverseOrder(comparator));\n    if (numSug < suggestions.length) {\n      SuggestWord trimmed[] = new SuggestWord[numSug];\n      System.arraycopy(suggestions, 0, trimmed, 0, numSug);\n      suggestions = trimmed;\n    }\n    return suggestions;\n  }\n\n","sourceOld":"  /**\n   * Suggest similar words.\n   * \n   * <p>Unlike {@link SpellChecker}, the similarity used to fetch the most\n   * relevant terms is an edit distance, therefore typically a low value\n   * for numSug will work very well.\n   * \n   * @param term Term you want to spell check on\n   * @param numSug the maximum number of suggested words\n   * @param ir IndexReader to find terms from\n   * @param morePopular return only suggested words that are as frequent or more frequent than the searched word\n   * @param accuracy return only suggested words that match with this similarity\n   * @return sorted list of the suggested words according to the comparator\n   * @throws IOException\n   */\n  public SuggestWord[] suggestSimilar(Term term, int numSug, IndexReader ir, \n      boolean morePopular, float accuracy) throws IOException {\n    \n    String text = term.text();\n    if (minQueryLength > 0 && text.codePointCount(0, text.length()) < minQueryLength)\n      return new SuggestWord[0];\n    \n    if (lowerCaseTerms)\n      term = term.createTerm(text.toLowerCase(Locale.ENGLISH));\n    \n    int docfreq = ir.docFreq(term);\n    \n    // see line 341 of spellchecker. this is certainly very very nice for perf,\n    // but is it really the right way to go?\n    if (!morePopular && docfreq > 0) {\n      return new SuggestWord[0];\n    }\n    \n    int maxDoc = ir.maxDoc();\n    \n    if (maxQueryFrequency >= 1f && docfreq > maxQueryFrequency) {\n      return new SuggestWord[0];\n    } else if (docfreq > (int) Math.ceil(maxQueryFrequency * (float)maxDoc)) {\n      return new SuggestWord[0];\n    }\n    \n    if (!morePopular) docfreq = 0;\n    \n    if (thresholdFrequency >= 1f) {\n      docfreq = Math.max(docfreq, (int) thresholdFrequency);\n    } else if (thresholdFrequency > 0f) {\n      docfreq = Math.max(docfreq, (int)(thresholdFrequency * (float)maxDoc)-1);\n    }\n    \n    Collection<ScoreTerm> terms = null;\n    int inspections = numSug * maxInspections;\n    \n    // try ed=1 first, in case we get lucky\n    terms = suggestSimilar(term, inspections, ir, docfreq, 1, accuracy);\n    if (maxEdits > 1 && terms.size() < inspections) {\n      HashSet<ScoreTerm> moreTerms = new HashSet<ScoreTerm>();\n      moreTerms.addAll(terms);\n      moreTerms.addAll(suggestSimilar(term, inspections, ir, docfreq, maxEdits, accuracy));\n      terms = moreTerms;\n    }\n    \n    // create the suggestword response, sort it, and trim it to size.\n    \n    SuggestWord suggestions[] = new SuggestWord[terms.size()];\n    int index = suggestions.length - 1;\n    for (ScoreTerm s : terms) {\n      SuggestWord suggestion = new SuggestWord();\n      suggestion.string = s.termAsString != null ? s.termAsString : s.term.utf8ToString();\n      suggestion.score = s.score;\n      suggestion.freq = s.docfreq;\n      suggestions[index--] = suggestion;\n    }\n    \n    ArrayUtil.mergeSort(suggestions, Collections.reverseOrder(comparator));\n    if (numSug < suggestions.length) {\n      SuggestWord trimmed[] = new SuggestWord[numSug];\n      System.arraycopy(suggestions, 0, trimmed, 0, numSug);\n      suggestions = trimmed;\n    }\n    return suggestions;\n  }\n\n","bugFix":null,"bugIntro":["7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5128b7b3b73fedff05fdc5ea2e6be53c1020bb91","date":1306767085,"type":1,"author":"Steven Rowe","isMerge":true,"pathNew":"modules/suggest/src/java/org/apache/lucene/search/spell/DirectSpellChecker#suggestSimilar(Term,int,IndexReader,boolean,float).mjava","pathOld":"lucene/contrib/spellchecker/src/java/org/apache/lucene/search/spell/DirectSpellChecker#suggestSimilar(Term,int,IndexReader,boolean,float).mjava","sourceNew":"  /**\n   * Suggest similar words.\n   * \n   * <p>Unlike {@link SpellChecker}, the similarity used to fetch the most\n   * relevant terms is an edit distance, therefore typically a low value\n   * for numSug will work very well.\n   * \n   * @param term Term you want to spell check on\n   * @param numSug the maximum number of suggested words\n   * @param ir IndexReader to find terms from\n   * @param morePopular return only suggested words that are as frequent or more frequent than the searched word\n   * @param accuracy return only suggested words that match with this similarity\n   * @return sorted list of the suggested words according to the comparator\n   * @throws IOException\n   */\n  public SuggestWord[] suggestSimilar(Term term, int numSug, IndexReader ir, \n      boolean morePopular, float accuracy) throws IOException {\n    final CharsRef spare = new CharsRef();\n    String text = term.text();\n    if (minQueryLength > 0 && text.codePointCount(0, text.length()) < minQueryLength)\n      return new SuggestWord[0];\n    \n    if (lowerCaseTerms)\n      term = term.createTerm(text.toLowerCase(Locale.ENGLISH));\n    \n    int docfreq = ir.docFreq(term);\n    \n    // see line 341 of spellchecker. this is certainly very very nice for perf,\n    // but is it really the right way to go?\n    if (!morePopular && docfreq > 0) {\n      return new SuggestWord[0];\n    }\n    \n    int maxDoc = ir.maxDoc();\n    \n    if (maxQueryFrequency >= 1f && docfreq > maxQueryFrequency) {\n      return new SuggestWord[0];\n    } else if (docfreq > (int) Math.ceil(maxQueryFrequency * (float)maxDoc)) {\n      return new SuggestWord[0];\n    }\n    \n    if (!morePopular) docfreq = 0;\n    \n    if (thresholdFrequency >= 1f) {\n      docfreq = Math.max(docfreq, (int) thresholdFrequency);\n    } else if (thresholdFrequency > 0f) {\n      docfreq = Math.max(docfreq, (int)(thresholdFrequency * (float)maxDoc)-1);\n    }\n    \n    Collection<ScoreTerm> terms = null;\n    int inspections = numSug * maxInspections;\n    \n    // try ed=1 first, in case we get lucky\n    terms = suggestSimilar(term, inspections, ir, docfreq, 1, accuracy, spare);\n    if (maxEdits > 1 && terms.size() < inspections) {\n      HashSet<ScoreTerm> moreTerms = new HashSet<ScoreTerm>();\n      moreTerms.addAll(terms);\n      moreTerms.addAll(suggestSimilar(term, inspections, ir, docfreq, maxEdits, accuracy, spare));\n      terms = moreTerms;\n    }\n    \n    // create the suggestword response, sort it, and trim it to size.\n    \n    SuggestWord suggestions[] = new SuggestWord[terms.size()];\n    int index = suggestions.length - 1;\n    for (ScoreTerm s : terms) {\n      SuggestWord suggestion = new SuggestWord();\n      suggestion.string = s.termAsString != null ? s.termAsString : s.term.utf8ToChars(spare).toString();\n      suggestion.score = s.score;\n      suggestion.freq = s.docfreq;\n      suggestions[index--] = suggestion;\n    }\n    \n    ArrayUtil.mergeSort(suggestions, Collections.reverseOrder(comparator));\n    if (numSug < suggestions.length) {\n      SuggestWord trimmed[] = new SuggestWord[numSug];\n      System.arraycopy(suggestions, 0, trimmed, 0, numSug);\n      suggestions = trimmed;\n    }\n    return suggestions;\n  }\n\n","sourceOld":"  /**\n   * Suggest similar words.\n   * \n   * <p>Unlike {@link SpellChecker}, the similarity used to fetch the most\n   * relevant terms is an edit distance, therefore typically a low value\n   * for numSug will work very well.\n   * \n   * @param term Term you want to spell check on\n   * @param numSug the maximum number of suggested words\n   * @param ir IndexReader to find terms from\n   * @param morePopular return only suggested words that are as frequent or more frequent than the searched word\n   * @param accuracy return only suggested words that match with this similarity\n   * @return sorted list of the suggested words according to the comparator\n   * @throws IOException\n   */\n  public SuggestWord[] suggestSimilar(Term term, int numSug, IndexReader ir, \n      boolean morePopular, float accuracy) throws IOException {\n    \n    String text = term.text();\n    if (minQueryLength > 0 && text.codePointCount(0, text.length()) < minQueryLength)\n      return new SuggestWord[0];\n    \n    if (lowerCaseTerms)\n      term = term.createTerm(text.toLowerCase(Locale.ENGLISH));\n    \n    int docfreq = ir.docFreq(term);\n    \n    // see line 341 of spellchecker. this is certainly very very nice for perf,\n    // but is it really the right way to go?\n    if (!morePopular && docfreq > 0) {\n      return new SuggestWord[0];\n    }\n    \n    int maxDoc = ir.maxDoc();\n    \n    if (maxQueryFrequency >= 1f && docfreq > maxQueryFrequency) {\n      return new SuggestWord[0];\n    } else if (docfreq > (int) Math.ceil(maxQueryFrequency * (float)maxDoc)) {\n      return new SuggestWord[0];\n    }\n    \n    if (!morePopular) docfreq = 0;\n    \n    if (thresholdFrequency >= 1f) {\n      docfreq = Math.max(docfreq, (int) thresholdFrequency);\n    } else if (thresholdFrequency > 0f) {\n      docfreq = Math.max(docfreq, (int)(thresholdFrequency * (float)maxDoc)-1);\n    }\n    \n    Collection<ScoreTerm> terms = null;\n    int inspections = numSug * maxInspections;\n    \n    // try ed=1 first, in case we get lucky\n    terms = suggestSimilar(term, inspections, ir, docfreq, 1, accuracy);\n    if (maxEdits > 1 && terms.size() < inspections) {\n      HashSet<ScoreTerm> moreTerms = new HashSet<ScoreTerm>();\n      moreTerms.addAll(terms);\n      moreTerms.addAll(suggestSimilar(term, inspections, ir, docfreq, maxEdits, accuracy));\n      terms = moreTerms;\n    }\n    \n    // create the suggestword response, sort it, and trim it to size.\n    \n    SuggestWord suggestions[] = new SuggestWord[terms.size()];\n    int index = suggestions.length - 1;\n    for (ScoreTerm s : terms) {\n      SuggestWord suggestion = new SuggestWord();\n      suggestion.string = s.termAsString != null ? s.termAsString : s.term.utf8ToString();\n      suggestion.score = s.score;\n      suggestion.freq = s.docfreq;\n      suggestions[index--] = suggestion;\n    }\n    \n    ArrayUtil.mergeSort(suggestions, Collections.reverseOrder(comparator));\n    if (numSug < suggestions.length) {\n      SuggestWord trimmed[] = new SuggestWord[numSug];\n      System.arraycopy(suggestions, 0, trimmed, 0, numSug);\n      suggestions = trimmed;\n    }\n    return suggestions;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2e10cb22a8bdb44339e282925a29182bb2f3174d","date":1306841137,"type":1,"author":"Simon Willnauer","isMerge":true,"pathNew":"modules/suggest/src/java/org/apache/lucene/search/spell/DirectSpellChecker#suggestSimilar(Term,int,IndexReader,boolean,float).mjava","pathOld":"lucene/contrib/spellchecker/src/java/org/apache/lucene/search/spell/DirectSpellChecker#suggestSimilar(Term,int,IndexReader,boolean,float).mjava","sourceNew":"  /**\n   * Suggest similar words.\n   * \n   * <p>Unlike {@link SpellChecker}, the similarity used to fetch the most\n   * relevant terms is an edit distance, therefore typically a low value\n   * for numSug will work very well.\n   * \n   * @param term Term you want to spell check on\n   * @param numSug the maximum number of suggested words\n   * @param ir IndexReader to find terms from\n   * @param morePopular return only suggested words that are as frequent or more frequent than the searched word\n   * @param accuracy return only suggested words that match with this similarity\n   * @return sorted list of the suggested words according to the comparator\n   * @throws IOException\n   */\n  public SuggestWord[] suggestSimilar(Term term, int numSug, IndexReader ir, \n      boolean morePopular, float accuracy) throws IOException {\n    final CharsRef spare = new CharsRef();\n    String text = term.text();\n    if (minQueryLength > 0 && text.codePointCount(0, text.length()) < minQueryLength)\n      return new SuggestWord[0];\n    \n    if (lowerCaseTerms)\n      term = term.createTerm(text.toLowerCase(Locale.ENGLISH));\n    \n    int docfreq = ir.docFreq(term);\n    \n    // see line 341 of spellchecker. this is certainly very very nice for perf,\n    // but is it really the right way to go?\n    if (!morePopular && docfreq > 0) {\n      return new SuggestWord[0];\n    }\n    \n    int maxDoc = ir.maxDoc();\n    \n    if (maxQueryFrequency >= 1f && docfreq > maxQueryFrequency) {\n      return new SuggestWord[0];\n    } else if (docfreq > (int) Math.ceil(maxQueryFrequency * (float)maxDoc)) {\n      return new SuggestWord[0];\n    }\n    \n    if (!morePopular) docfreq = 0;\n    \n    if (thresholdFrequency >= 1f) {\n      docfreq = Math.max(docfreq, (int) thresholdFrequency);\n    } else if (thresholdFrequency > 0f) {\n      docfreq = Math.max(docfreq, (int)(thresholdFrequency * (float)maxDoc)-1);\n    }\n    \n    Collection<ScoreTerm> terms = null;\n    int inspections = numSug * maxInspections;\n    \n    // try ed=1 first, in case we get lucky\n    terms = suggestSimilar(term, inspections, ir, docfreq, 1, accuracy, spare);\n    if (maxEdits > 1 && terms.size() < inspections) {\n      HashSet<ScoreTerm> moreTerms = new HashSet<ScoreTerm>();\n      moreTerms.addAll(terms);\n      moreTerms.addAll(suggestSimilar(term, inspections, ir, docfreq, maxEdits, accuracy, spare));\n      terms = moreTerms;\n    }\n    \n    // create the suggestword response, sort it, and trim it to size.\n    \n    SuggestWord suggestions[] = new SuggestWord[terms.size()];\n    int index = suggestions.length - 1;\n    for (ScoreTerm s : terms) {\n      SuggestWord suggestion = new SuggestWord();\n      suggestion.string = s.termAsString != null ? s.termAsString : s.term.utf8ToChars(spare).toString();\n      suggestion.score = s.score;\n      suggestion.freq = s.docfreq;\n      suggestions[index--] = suggestion;\n    }\n    \n    ArrayUtil.mergeSort(suggestions, Collections.reverseOrder(comparator));\n    if (numSug < suggestions.length) {\n      SuggestWord trimmed[] = new SuggestWord[numSug];\n      System.arraycopy(suggestions, 0, trimmed, 0, numSug);\n      suggestions = trimmed;\n    }\n    return suggestions;\n  }\n\n","sourceOld":"  /**\n   * Suggest similar words.\n   * \n   * <p>Unlike {@link SpellChecker}, the similarity used to fetch the most\n   * relevant terms is an edit distance, therefore typically a low value\n   * for numSug will work very well.\n   * \n   * @param term Term you want to spell check on\n   * @param numSug the maximum number of suggested words\n   * @param ir IndexReader to find terms from\n   * @param morePopular return only suggested words that are as frequent or more frequent than the searched word\n   * @param accuracy return only suggested words that match with this similarity\n   * @return sorted list of the suggested words according to the comparator\n   * @throws IOException\n   */\n  public SuggestWord[] suggestSimilar(Term term, int numSug, IndexReader ir, \n      boolean morePopular, float accuracy) throws IOException {\n    \n    String text = term.text();\n    if (minQueryLength > 0 && text.codePointCount(0, text.length()) < minQueryLength)\n      return new SuggestWord[0];\n    \n    if (lowerCaseTerms)\n      term = term.createTerm(text.toLowerCase(Locale.ENGLISH));\n    \n    int docfreq = ir.docFreq(term);\n    \n    // see line 341 of spellchecker. this is certainly very very nice for perf,\n    // but is it really the right way to go?\n    if (!morePopular && docfreq > 0) {\n      return new SuggestWord[0];\n    }\n    \n    int maxDoc = ir.maxDoc();\n    \n    if (maxQueryFrequency >= 1f && docfreq > maxQueryFrequency) {\n      return new SuggestWord[0];\n    } else if (docfreq > (int) Math.ceil(maxQueryFrequency * (float)maxDoc)) {\n      return new SuggestWord[0];\n    }\n    \n    if (!morePopular) docfreq = 0;\n    \n    if (thresholdFrequency >= 1f) {\n      docfreq = Math.max(docfreq, (int) thresholdFrequency);\n    } else if (thresholdFrequency > 0f) {\n      docfreq = Math.max(docfreq, (int)(thresholdFrequency * (float)maxDoc)-1);\n    }\n    \n    Collection<ScoreTerm> terms = null;\n    int inspections = numSug * maxInspections;\n    \n    // try ed=1 first, in case we get lucky\n    terms = suggestSimilar(term, inspections, ir, docfreq, 1, accuracy);\n    if (maxEdits > 1 && terms.size() < inspections) {\n      HashSet<ScoreTerm> moreTerms = new HashSet<ScoreTerm>();\n      moreTerms.addAll(terms);\n      moreTerms.addAll(suggestSimilar(term, inspections, ir, docfreq, maxEdits, accuracy));\n      terms = moreTerms;\n    }\n    \n    // create the suggestword response, sort it, and trim it to size.\n    \n    SuggestWord suggestions[] = new SuggestWord[terms.size()];\n    int index = suggestions.length - 1;\n    for (ScoreTerm s : terms) {\n      SuggestWord suggestion = new SuggestWord();\n      suggestion.string = s.termAsString != null ? s.termAsString : s.term.utf8ToString();\n      suggestion.score = s.score;\n      suggestion.freq = s.docfreq;\n      suggestions[index--] = suggestion;\n    }\n    \n    ArrayUtil.mergeSort(suggestions, Collections.reverseOrder(comparator));\n    if (numSug < suggestions.length) {\n      SuggestWord trimmed[] = new SuggestWord[numSug];\n      System.arraycopy(suggestions, 0, trimmed, 0, numSug);\n      suggestions = trimmed;\n    }\n    return suggestions;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fafef7c83fe8e0b3ca9298d5d75d6b943dc28153","date":1308670974,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"modules/suggest/src/java/org/apache/lucene/search/spell/DirectSpellChecker#suggestSimilar(Term,int,IndexReader,boolean,float).mjava","pathOld":"modules/suggest/src/java/org/apache/lucene/search/spell/DirectSpellChecker#suggestSimilar(Term,int,IndexReader,boolean,float).mjava","sourceNew":"  /**\n   * Suggest similar words.\n   * \n   * <p>Unlike {@link SpellChecker}, the similarity used to fetch the most\n   * relevant terms is an edit distance, therefore typically a low value\n   * for numSug will work very well.\n   * \n   * @param term Term you want to spell check on\n   * @param numSug the maximum number of suggested words\n   * @param ir IndexReader to find terms from\n   * @param morePopular return only suggested words that are as frequent or more frequent than the searched word\n   * @param accuracy return only suggested words that match with this similarity\n   * @return sorted list of the suggested words according to the comparator\n   * @throws IOException\n   */\n  public SuggestWord[] suggestSimilar(Term term, int numSug, IndexReader ir, \n      boolean morePopular, float accuracy) throws IOException {\n    final CharsRef spare = new CharsRef();\n    String text = term.text();\n    if (minQueryLength > 0 && text.codePointCount(0, text.length()) < minQueryLength)\n      return new SuggestWord[0];\n    \n    if (lowerCaseTerms) {\n      term = new Term(term.field(), text.toLowerCase(Locale.ENGLISH));\n    }\n    \n    int docfreq = ir.docFreq(term);\n    \n    // see line 341 of spellchecker. this is certainly very very nice for perf,\n    // but is it really the right way to go?\n    if (!morePopular && docfreq > 0) {\n      return new SuggestWord[0];\n    }\n    \n    int maxDoc = ir.maxDoc();\n    \n    if (maxQueryFrequency >= 1f && docfreq > maxQueryFrequency) {\n      return new SuggestWord[0];\n    } else if (docfreq > (int) Math.ceil(maxQueryFrequency * (float)maxDoc)) {\n      return new SuggestWord[0];\n    }\n    \n    if (!morePopular) docfreq = 0;\n    \n    if (thresholdFrequency >= 1f) {\n      docfreq = Math.max(docfreq, (int) thresholdFrequency);\n    } else if (thresholdFrequency > 0f) {\n      docfreq = Math.max(docfreq, (int)(thresholdFrequency * (float)maxDoc)-1);\n    }\n    \n    Collection<ScoreTerm> terms = null;\n    int inspections = numSug * maxInspections;\n    \n    // try ed=1 first, in case we get lucky\n    terms = suggestSimilar(term, inspections, ir, docfreq, 1, accuracy, spare);\n    if (maxEdits > 1 && terms.size() < inspections) {\n      HashSet<ScoreTerm> moreTerms = new HashSet<ScoreTerm>();\n      moreTerms.addAll(terms);\n      moreTerms.addAll(suggestSimilar(term, inspections, ir, docfreq, maxEdits, accuracy, spare));\n      terms = moreTerms;\n    }\n    \n    // create the suggestword response, sort it, and trim it to size.\n    \n    SuggestWord suggestions[] = new SuggestWord[terms.size()];\n    int index = suggestions.length - 1;\n    for (ScoreTerm s : terms) {\n      SuggestWord suggestion = new SuggestWord();\n      suggestion.string = s.termAsString != null ? s.termAsString : s.term.utf8ToChars(spare).toString();\n      suggestion.score = s.score;\n      suggestion.freq = s.docfreq;\n      suggestions[index--] = suggestion;\n    }\n    \n    ArrayUtil.mergeSort(suggestions, Collections.reverseOrder(comparator));\n    if (numSug < suggestions.length) {\n      SuggestWord trimmed[] = new SuggestWord[numSug];\n      System.arraycopy(suggestions, 0, trimmed, 0, numSug);\n      suggestions = trimmed;\n    }\n    return suggestions;\n  }\n\n","sourceOld":"  /**\n   * Suggest similar words.\n   * \n   * <p>Unlike {@link SpellChecker}, the similarity used to fetch the most\n   * relevant terms is an edit distance, therefore typically a low value\n   * for numSug will work very well.\n   * \n   * @param term Term you want to spell check on\n   * @param numSug the maximum number of suggested words\n   * @param ir IndexReader to find terms from\n   * @param morePopular return only suggested words that are as frequent or more frequent than the searched word\n   * @param accuracy return only suggested words that match with this similarity\n   * @return sorted list of the suggested words according to the comparator\n   * @throws IOException\n   */\n  public SuggestWord[] suggestSimilar(Term term, int numSug, IndexReader ir, \n      boolean morePopular, float accuracy) throws IOException {\n    final CharsRef spare = new CharsRef();\n    String text = term.text();\n    if (minQueryLength > 0 && text.codePointCount(0, text.length()) < minQueryLength)\n      return new SuggestWord[0];\n    \n    if (lowerCaseTerms)\n      term = term.createTerm(text.toLowerCase(Locale.ENGLISH));\n    \n    int docfreq = ir.docFreq(term);\n    \n    // see line 341 of spellchecker. this is certainly very very nice for perf,\n    // but is it really the right way to go?\n    if (!morePopular && docfreq > 0) {\n      return new SuggestWord[0];\n    }\n    \n    int maxDoc = ir.maxDoc();\n    \n    if (maxQueryFrequency >= 1f && docfreq > maxQueryFrequency) {\n      return new SuggestWord[0];\n    } else if (docfreq > (int) Math.ceil(maxQueryFrequency * (float)maxDoc)) {\n      return new SuggestWord[0];\n    }\n    \n    if (!morePopular) docfreq = 0;\n    \n    if (thresholdFrequency >= 1f) {\n      docfreq = Math.max(docfreq, (int) thresholdFrequency);\n    } else if (thresholdFrequency > 0f) {\n      docfreq = Math.max(docfreq, (int)(thresholdFrequency * (float)maxDoc)-1);\n    }\n    \n    Collection<ScoreTerm> terms = null;\n    int inspections = numSug * maxInspections;\n    \n    // try ed=1 first, in case we get lucky\n    terms = suggestSimilar(term, inspections, ir, docfreq, 1, accuracy, spare);\n    if (maxEdits > 1 && terms.size() < inspections) {\n      HashSet<ScoreTerm> moreTerms = new HashSet<ScoreTerm>();\n      moreTerms.addAll(terms);\n      moreTerms.addAll(suggestSimilar(term, inspections, ir, docfreq, maxEdits, accuracy, spare));\n      terms = moreTerms;\n    }\n    \n    // create the suggestword response, sort it, and trim it to size.\n    \n    SuggestWord suggestions[] = new SuggestWord[terms.size()];\n    int index = suggestions.length - 1;\n    for (ScoreTerm s : terms) {\n      SuggestWord suggestion = new SuggestWord();\n      suggestion.string = s.termAsString != null ? s.termAsString : s.term.utf8ToChars(spare).toString();\n      suggestion.score = s.score;\n      suggestion.freq = s.docfreq;\n      suggestions[index--] = suggestion;\n    }\n    \n    ArrayUtil.mergeSort(suggestions, Collections.reverseOrder(comparator));\n    if (numSug < suggestions.length) {\n      SuggestWord trimmed[] = new SuggestWord[numSug];\n      System.arraycopy(suggestions, 0, trimmed, 0, numSug);\n      suggestions = trimmed;\n    }\n    return suggestions;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2553b00f699380c64959ccb27991289aae87be2e","date":1309290151,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"modules/suggest/src/java/org/apache/lucene/search/spell/DirectSpellChecker#suggestSimilar(Term,int,IndexReader,boolean,float).mjava","pathOld":"modules/suggest/src/java/org/apache/lucene/search/spell/DirectSpellChecker#suggestSimilar(Term,int,IndexReader,boolean,float).mjava","sourceNew":"  /**\n   * Suggest similar words.\n   * \n   * <p>Unlike {@link SpellChecker}, the similarity used to fetch the most\n   * relevant terms is an edit distance, therefore typically a low value\n   * for numSug will work very well.\n   * \n   * @param term Term you want to spell check on\n   * @param numSug the maximum number of suggested words\n   * @param ir IndexReader to find terms from\n   * @param morePopular return only suggested words that are as frequent or more frequent than the searched word\n   * @param accuracy return only suggested words that match with this similarity\n   * @return sorted list of the suggested words according to the comparator\n   * @throws IOException\n   */\n  public SuggestWord[] suggestSimilar(Term term, int numSug, IndexReader ir, \n      boolean morePopular, float accuracy) throws IOException {\n    final CharsRef spare = new CharsRef();\n    String text = term.text();\n    if (minQueryLength > 0 && text.codePointCount(0, text.length()) < minQueryLength)\n      return new SuggestWord[0];\n    \n    if (lowerCaseTerms) {\n      term = new Term(term.field(), text.toLowerCase(Locale.ENGLISH));\n    }\n    \n    int docfreq = ir.docFreq(term);\n    \n    // see line 341 of spellchecker. this is certainly very very nice for perf,\n    // but is it really the right way to go?\n    if (!morePopular && docfreq > 0) {\n      return new SuggestWord[0];\n    }\n    \n    int maxDoc = ir.maxDoc();\n    \n    if (maxQueryFrequency >= 1f && docfreq > maxQueryFrequency) {\n      return new SuggestWord[0];\n    } else if (docfreq > (int) Math.ceil(maxQueryFrequency * (float)maxDoc)) {\n      return new SuggestWord[0];\n    }\n    \n    if (!morePopular) docfreq = 0;\n    \n    if (thresholdFrequency >= 1f) {\n      docfreq = Math.max(docfreq, (int) thresholdFrequency);\n    } else if (thresholdFrequency > 0f) {\n      docfreq = Math.max(docfreq, (int)(thresholdFrequency * (float)maxDoc)-1);\n    }\n    \n    Collection<ScoreTerm> terms = null;\n    int inspections = numSug * maxInspections;\n    \n    // try ed=1 first, in case we get lucky\n    terms = suggestSimilar(term, inspections, ir, docfreq, 1, accuracy, spare);\n    if (maxEdits > 1 && terms.size() < inspections) {\n      HashSet<ScoreTerm> moreTerms = new HashSet<ScoreTerm>();\n      moreTerms.addAll(terms);\n      moreTerms.addAll(suggestSimilar(term, inspections, ir, docfreq, maxEdits, accuracy, spare));\n      terms = moreTerms;\n    }\n    \n    // create the suggestword response, sort it, and trim it to size.\n    \n    SuggestWord suggestions[] = new SuggestWord[terms.size()];\n    int index = suggestions.length - 1;\n    for (ScoreTerm s : terms) {\n      SuggestWord suggestion = new SuggestWord();\n      suggestion.string = s.termAsString != null ? s.termAsString : s.term.utf8ToChars(spare).toString();\n      suggestion.score = s.score;\n      suggestion.freq = s.docfreq;\n      suggestions[index--] = suggestion;\n    }\n    \n    ArrayUtil.mergeSort(suggestions, Collections.reverseOrder(comparator));\n    if (numSug < suggestions.length) {\n      SuggestWord trimmed[] = new SuggestWord[numSug];\n      System.arraycopy(suggestions, 0, trimmed, 0, numSug);\n      suggestions = trimmed;\n    }\n    return suggestions;\n  }\n\n","sourceOld":"  /**\n   * Suggest similar words.\n   * \n   * <p>Unlike {@link SpellChecker}, the similarity used to fetch the most\n   * relevant terms is an edit distance, therefore typically a low value\n   * for numSug will work very well.\n   * \n   * @param term Term you want to spell check on\n   * @param numSug the maximum number of suggested words\n   * @param ir IndexReader to find terms from\n   * @param morePopular return only suggested words that are as frequent or more frequent than the searched word\n   * @param accuracy return only suggested words that match with this similarity\n   * @return sorted list of the suggested words according to the comparator\n   * @throws IOException\n   */\n  public SuggestWord[] suggestSimilar(Term term, int numSug, IndexReader ir, \n      boolean morePopular, float accuracy) throws IOException {\n    final CharsRef spare = new CharsRef();\n    String text = term.text();\n    if (minQueryLength > 0 && text.codePointCount(0, text.length()) < minQueryLength)\n      return new SuggestWord[0];\n    \n    if (lowerCaseTerms)\n      term = term.createTerm(text.toLowerCase(Locale.ENGLISH));\n    \n    int docfreq = ir.docFreq(term);\n    \n    // see line 341 of spellchecker. this is certainly very very nice for perf,\n    // but is it really the right way to go?\n    if (!morePopular && docfreq > 0) {\n      return new SuggestWord[0];\n    }\n    \n    int maxDoc = ir.maxDoc();\n    \n    if (maxQueryFrequency >= 1f && docfreq > maxQueryFrequency) {\n      return new SuggestWord[0];\n    } else if (docfreq > (int) Math.ceil(maxQueryFrequency * (float)maxDoc)) {\n      return new SuggestWord[0];\n    }\n    \n    if (!morePopular) docfreq = 0;\n    \n    if (thresholdFrequency >= 1f) {\n      docfreq = Math.max(docfreq, (int) thresholdFrequency);\n    } else if (thresholdFrequency > 0f) {\n      docfreq = Math.max(docfreq, (int)(thresholdFrequency * (float)maxDoc)-1);\n    }\n    \n    Collection<ScoreTerm> terms = null;\n    int inspections = numSug * maxInspections;\n    \n    // try ed=1 first, in case we get lucky\n    terms = suggestSimilar(term, inspections, ir, docfreq, 1, accuracy, spare);\n    if (maxEdits > 1 && terms.size() < inspections) {\n      HashSet<ScoreTerm> moreTerms = new HashSet<ScoreTerm>();\n      moreTerms.addAll(terms);\n      moreTerms.addAll(suggestSimilar(term, inspections, ir, docfreq, maxEdits, accuracy, spare));\n      terms = moreTerms;\n    }\n    \n    // create the suggestword response, sort it, and trim it to size.\n    \n    SuggestWord suggestions[] = new SuggestWord[terms.size()];\n    int index = suggestions.length - 1;\n    for (ScoreTerm s : terms) {\n      SuggestWord suggestion = new SuggestWord();\n      suggestion.string = s.termAsString != null ? s.termAsString : s.term.utf8ToChars(spare).toString();\n      suggestion.score = s.score;\n      suggestion.freq = s.docfreq;\n      suggestions[index--] = suggestion;\n    }\n    \n    ArrayUtil.mergeSort(suggestions, Collections.reverseOrder(comparator));\n    if (numSug < suggestions.length) {\n      SuggestWord trimmed[] = new SuggestWord[numSug];\n      System.arraycopy(suggestions, 0, trimmed, 0, numSug);\n      suggestions = trimmed;\n    }\n    return suggestions;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d083e83f225b11e5fdd900e83d26ddb385b6955c","date":1310029438,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"modules/suggest/src/java/org/apache/lucene/search/spell/DirectSpellChecker#suggestSimilar(Term,int,IndexReader,boolean,float).mjava","pathOld":"modules/suggest/src/java/org/apache/lucene/search/spell/DirectSpellChecker#suggestSimilar(Term,int,IndexReader,boolean,float).mjava","sourceNew":"  /**\n   * Suggest similar words.\n   * \n   * <p>Unlike {@link SpellChecker}, the similarity used to fetch the most\n   * relevant terms is an edit distance, therefore typically a low value\n   * for numSug will work very well.\n   * \n   * @param term Term you want to spell check on\n   * @param numSug the maximum number of suggested words\n   * @param ir IndexReader to find terms from\n   * @param morePopular return only suggested words that are as frequent or more frequent than the searched word\n   * @param accuracy return only suggested words that match with this similarity\n   * @return sorted list of the suggested words according to the comparator\n   * @throws IOException\n   */\n  public SuggestWord[] suggestSimilar(Term term, int numSug, IndexReader ir, \n      boolean morePopular, float accuracy) throws IOException {\n    final CharsRef spare = new CharsRef();\n    String text = term.text();\n    if (minQueryLength > 0 && text.codePointCount(0, text.length()) < minQueryLength)\n      return new SuggestWord[0];\n    \n    if (lowerCaseTerms) {\n      term = new Term(term.field(), text.toLowerCase(Locale.ENGLISH));\n    }\n    \n    int docfreq = ir.docFreq(term);\n    \n    // see line 341 of spellchecker. this is certainly very very nice for perf,\n    // but is it really the right way to go?\n    if (!morePopular && docfreq > 0) {\n      return new SuggestWord[0];\n    }\n    \n    int maxDoc = ir.maxDoc();\n    \n    if (maxQueryFrequency >= 1f && docfreq > maxQueryFrequency) {\n      return new SuggestWord[0];\n    } else if (docfreq > (int) Math.ceil(maxQueryFrequency * (float)maxDoc)) {\n      return new SuggestWord[0];\n    }\n    \n    if (!morePopular) docfreq = 0;\n    \n    if (thresholdFrequency >= 1f) {\n      docfreq = Math.max(docfreq, (int) thresholdFrequency);\n    } else if (thresholdFrequency > 0f) {\n      docfreq = Math.max(docfreq, (int)(thresholdFrequency * (float)maxDoc)-1);\n    }\n    \n    Collection<ScoreTerm> terms = null;\n    int inspections = numSug * maxInspections;\n    \n    // try ed=1 first, in case we get lucky\n    terms = suggestSimilar(term, inspections, ir, docfreq, 1, accuracy, spare);\n    if (maxEdits > 1 && terms.size() < inspections) {\n      HashSet<ScoreTerm> moreTerms = new HashSet<ScoreTerm>();\n      moreTerms.addAll(terms);\n      moreTerms.addAll(suggestSimilar(term, inspections, ir, docfreq, maxEdits, accuracy, spare));\n      terms = moreTerms;\n    }\n    \n    // create the suggestword response, sort it, and trim it to size.\n    \n    SuggestWord suggestions[] = new SuggestWord[terms.size()];\n    int index = suggestions.length - 1;\n    for (ScoreTerm s : terms) {\n      SuggestWord suggestion = new SuggestWord();\n      suggestion.string = s.termAsString != null ? s.termAsString : s.term.utf8ToChars(spare).toString();\n      suggestion.score = s.score;\n      suggestion.freq = s.docfreq;\n      suggestions[index--] = suggestion;\n    }\n    \n    ArrayUtil.mergeSort(suggestions, Collections.reverseOrder(comparator));\n    if (numSug < suggestions.length) {\n      SuggestWord trimmed[] = new SuggestWord[numSug];\n      System.arraycopy(suggestions, 0, trimmed, 0, numSug);\n      suggestions = trimmed;\n    }\n    return suggestions;\n  }\n\n","sourceOld":"  /**\n   * Suggest similar words.\n   * \n   * <p>Unlike {@link SpellChecker}, the similarity used to fetch the most\n   * relevant terms is an edit distance, therefore typically a low value\n   * for numSug will work very well.\n   * \n   * @param term Term you want to spell check on\n   * @param numSug the maximum number of suggested words\n   * @param ir IndexReader to find terms from\n   * @param morePopular return only suggested words that are as frequent or more frequent than the searched word\n   * @param accuracy return only suggested words that match with this similarity\n   * @return sorted list of the suggested words according to the comparator\n   * @throws IOException\n   */\n  public SuggestWord[] suggestSimilar(Term term, int numSug, IndexReader ir, \n      boolean morePopular, float accuracy) throws IOException {\n    final CharsRef spare = new CharsRef();\n    String text = term.text();\n    if (minQueryLength > 0 && text.codePointCount(0, text.length()) < minQueryLength)\n      return new SuggestWord[0];\n    \n    if (lowerCaseTerms)\n      term = term.createTerm(text.toLowerCase(Locale.ENGLISH));\n    \n    int docfreq = ir.docFreq(term);\n    \n    // see line 341 of spellchecker. this is certainly very very nice for perf,\n    // but is it really the right way to go?\n    if (!morePopular && docfreq > 0) {\n      return new SuggestWord[0];\n    }\n    \n    int maxDoc = ir.maxDoc();\n    \n    if (maxQueryFrequency >= 1f && docfreq > maxQueryFrequency) {\n      return new SuggestWord[0];\n    } else if (docfreq > (int) Math.ceil(maxQueryFrequency * (float)maxDoc)) {\n      return new SuggestWord[0];\n    }\n    \n    if (!morePopular) docfreq = 0;\n    \n    if (thresholdFrequency >= 1f) {\n      docfreq = Math.max(docfreq, (int) thresholdFrequency);\n    } else if (thresholdFrequency > 0f) {\n      docfreq = Math.max(docfreq, (int)(thresholdFrequency * (float)maxDoc)-1);\n    }\n    \n    Collection<ScoreTerm> terms = null;\n    int inspections = numSug * maxInspections;\n    \n    // try ed=1 first, in case we get lucky\n    terms = suggestSimilar(term, inspections, ir, docfreq, 1, accuracy, spare);\n    if (maxEdits > 1 && terms.size() < inspections) {\n      HashSet<ScoreTerm> moreTerms = new HashSet<ScoreTerm>();\n      moreTerms.addAll(terms);\n      moreTerms.addAll(suggestSimilar(term, inspections, ir, docfreq, maxEdits, accuracy, spare));\n      terms = moreTerms;\n    }\n    \n    // create the suggestword response, sort it, and trim it to size.\n    \n    SuggestWord suggestions[] = new SuggestWord[terms.size()];\n    int index = suggestions.length - 1;\n    for (ScoreTerm s : terms) {\n      SuggestWord suggestion = new SuggestWord();\n      suggestion.string = s.termAsString != null ? s.termAsString : s.term.utf8ToChars(spare).toString();\n      suggestion.score = s.score;\n      suggestion.freq = s.docfreq;\n      suggestions[index--] = suggestion;\n    }\n    \n    ArrayUtil.mergeSort(suggestions, Collections.reverseOrder(comparator));\n    if (numSug < suggestions.length) {\n      SuggestWord trimmed[] = new SuggestWord[numSug];\n      System.arraycopy(suggestions, 0, trimmed, 0, numSug);\n      suggestions = trimmed;\n    }\n    return suggestions;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b0f2476332da483dc2ea1fdd80b5968380653166","date":1316180489,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"modules/suggest/src/java/org/apache/lucene/search/spell/DirectSpellChecker#suggestSimilar(Term,int,IndexReader,SuggestMode,float).mjava","pathOld":"modules/suggest/src/java/org/apache/lucene/search/spell/DirectSpellChecker#suggestSimilar(Term,int,IndexReader,boolean,float).mjava","sourceNew":"  /**\n   * Suggest similar words.\n   * \n   * <p>Unlike {@link SpellChecker}, the similarity used to fetch the most\n   * relevant terms is an edit distance, therefore typically a low value\n   * for numSug will work very well.\n   * \n   * @param term Term you want to spell check on\n   * @param numSug the maximum number of suggested words\n   * @param ir IndexReader to find terms from\n   * @param morePopular return only suggested words that are as frequent or more frequent than the searched word\n   * @param accuracy return only suggested words that match with this similarity\n   * @return sorted list of the suggested words according to the comparator\n   * @throws IOException\n   */\n  public SuggestWord[] suggestSimilar(Term term, int numSug, IndexReader ir, \n      SuggestMode suggestMode, float accuracy) throws IOException {\n    final CharsRef spare = new CharsRef();\n    String text = term.text();\n    if (minQueryLength > 0 && text.codePointCount(0, text.length()) < minQueryLength)\n      return new SuggestWord[0];\n    \n    if (lowerCaseTerms) {\n      term = new Term(term.field(), text.toLowerCase(Locale.ENGLISH));\n    }\n    \n    int docfreq = ir.docFreq(term);\n    \n    if (suggestMode==SuggestMode.SUGGEST_WHEN_NOT_IN_INDEX && docfreq > 0) {\n      return new SuggestWord[0];\n    }\n    \n    int maxDoc = ir.maxDoc();\n    \n    if (maxQueryFrequency >= 1f && docfreq > maxQueryFrequency) {\n      return new SuggestWord[0];\n    } else if (docfreq > (int) Math.ceil(maxQueryFrequency * (float)maxDoc)) {\n      return new SuggestWord[0];\n    }\n    \n    if (suggestMode!=SuggestMode.SUGGEST_MORE_POPULAR) docfreq = 0;\n    \n    if (thresholdFrequency >= 1f) {\n      docfreq = Math.max(docfreq, (int) thresholdFrequency);\n    } else if (thresholdFrequency > 0f) {\n      docfreq = Math.max(docfreq, (int)(thresholdFrequency * (float)maxDoc)-1);\n    }\n    \n    Collection<ScoreTerm> terms = null;\n    int inspections = numSug * maxInspections;\n    \n    // try ed=1 first, in case we get lucky\n    terms = suggestSimilar(term, inspections, ir, docfreq, 1, accuracy, spare);\n    if (maxEdits > 1 && terms.size() < inspections) {\n      HashSet<ScoreTerm> moreTerms = new HashSet<ScoreTerm>();\n      moreTerms.addAll(terms);\n      moreTerms.addAll(suggestSimilar(term, inspections, ir, docfreq, maxEdits, accuracy, spare));\n      terms = moreTerms;\n    }\n    \n    // create the suggestword response, sort it, and trim it to size.\n    \n    SuggestWord suggestions[] = new SuggestWord[terms.size()];\n    int index = suggestions.length - 1;\n    for (ScoreTerm s : terms) {\n      SuggestWord suggestion = new SuggestWord();\n      suggestion.string = s.termAsString != null ? s.termAsString : s.term.utf8ToChars(spare).toString();\n      suggestion.score = s.score;\n      suggestion.freq = s.docfreq;\n      suggestions[index--] = suggestion;\n    }\n    \n    ArrayUtil.mergeSort(suggestions, Collections.reverseOrder(comparator));\n    if (numSug < suggestions.length) {\n      SuggestWord trimmed[] = new SuggestWord[numSug];\n      System.arraycopy(suggestions, 0, trimmed, 0, numSug);\n      suggestions = trimmed;\n    }\n    return suggestions;\n  }\n\n","sourceOld":"  /**\n   * Suggest similar words.\n   * \n   * <p>Unlike {@link SpellChecker}, the similarity used to fetch the most\n   * relevant terms is an edit distance, therefore typically a low value\n   * for numSug will work very well.\n   * \n   * @param term Term you want to spell check on\n   * @param numSug the maximum number of suggested words\n   * @param ir IndexReader to find terms from\n   * @param morePopular return only suggested words that are as frequent or more frequent than the searched word\n   * @param accuracy return only suggested words that match with this similarity\n   * @return sorted list of the suggested words according to the comparator\n   * @throws IOException\n   */\n  public SuggestWord[] suggestSimilar(Term term, int numSug, IndexReader ir, \n      boolean morePopular, float accuracy) throws IOException {\n    final CharsRef spare = new CharsRef();\n    String text = term.text();\n    if (minQueryLength > 0 && text.codePointCount(0, text.length()) < minQueryLength)\n      return new SuggestWord[0];\n    \n    if (lowerCaseTerms) {\n      term = new Term(term.field(), text.toLowerCase(Locale.ENGLISH));\n    }\n    \n    int docfreq = ir.docFreq(term);\n    \n    // see line 341 of spellchecker. this is certainly very very nice for perf,\n    // but is it really the right way to go?\n    if (!morePopular && docfreq > 0) {\n      return new SuggestWord[0];\n    }\n    \n    int maxDoc = ir.maxDoc();\n    \n    if (maxQueryFrequency >= 1f && docfreq > maxQueryFrequency) {\n      return new SuggestWord[0];\n    } else if (docfreq > (int) Math.ceil(maxQueryFrequency * (float)maxDoc)) {\n      return new SuggestWord[0];\n    }\n    \n    if (!morePopular) docfreq = 0;\n    \n    if (thresholdFrequency >= 1f) {\n      docfreq = Math.max(docfreq, (int) thresholdFrequency);\n    } else if (thresholdFrequency > 0f) {\n      docfreq = Math.max(docfreq, (int)(thresholdFrequency * (float)maxDoc)-1);\n    }\n    \n    Collection<ScoreTerm> terms = null;\n    int inspections = numSug * maxInspections;\n    \n    // try ed=1 first, in case we get lucky\n    terms = suggestSimilar(term, inspections, ir, docfreq, 1, accuracy, spare);\n    if (maxEdits > 1 && terms.size() < inspections) {\n      HashSet<ScoreTerm> moreTerms = new HashSet<ScoreTerm>();\n      moreTerms.addAll(terms);\n      moreTerms.addAll(suggestSimilar(term, inspections, ir, docfreq, maxEdits, accuracy, spare));\n      terms = moreTerms;\n    }\n    \n    // create the suggestword response, sort it, and trim it to size.\n    \n    SuggestWord suggestions[] = new SuggestWord[terms.size()];\n    int index = suggestions.length - 1;\n    for (ScoreTerm s : terms) {\n      SuggestWord suggestion = new SuggestWord();\n      suggestion.string = s.termAsString != null ? s.termAsString : s.term.utf8ToChars(spare).toString();\n      suggestion.score = s.score;\n      suggestion.freq = s.docfreq;\n      suggestions[index--] = suggestion;\n    }\n    \n    ArrayUtil.mergeSort(suggestions, Collections.reverseOrder(comparator));\n    if (numSug < suggestions.length) {\n      SuggestWord trimmed[] = new SuggestWord[numSug];\n      System.arraycopy(suggestions, 0, trimmed, 0, numSug);\n      suggestions = trimmed;\n    }\n    return suggestions;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"b0f2476332da483dc2ea1fdd80b5968380653166":["fafef7c83fe8e0b3ca9298d5d75d6b943dc28153"],"e230a61047bc041516c811baa08a7174d6f8322a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"5128b7b3b73fedff05fdc5ea2e6be53c1020bb91":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","a1b3a24d5d9b47345473ff564f5cc127a7b526b4"],"fafef7c83fe8e0b3ca9298d5d75d6b943dc28153":["a1b3a24d5d9b47345473ff564f5cc127a7b526b4"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a1b3a24d5d9b47345473ff564f5cc127a7b526b4":["e230a61047bc041516c811baa08a7174d6f8322a"],"2553b00f699380c64959ccb27991289aae87be2e":["5128b7b3b73fedff05fdc5ea2e6be53c1020bb91","fafef7c83fe8e0b3ca9298d5d75d6b943dc28153"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":["a1b3a24d5d9b47345473ff564f5cc127a7b526b4","fafef7c83fe8e0b3ca9298d5d75d6b943dc28153"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b0f2476332da483dc2ea1fdd80b5968380653166"],"2e10cb22a8bdb44339e282925a29182bb2f3174d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","a1b3a24d5d9b47345473ff564f5cc127a7b526b4"]},"commit2Childs":{"b0f2476332da483dc2ea1fdd80b5968380653166":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"e230a61047bc041516c811baa08a7174d6f8322a":["a1b3a24d5d9b47345473ff564f5cc127a7b526b4"],"5128b7b3b73fedff05fdc5ea2e6be53c1020bb91":["2553b00f699380c64959ccb27991289aae87be2e"],"fafef7c83fe8e0b3ca9298d5d75d6b943dc28153":["b0f2476332da483dc2ea1fdd80b5968380653166","2553b00f699380c64959ccb27991289aae87be2e","d083e83f225b11e5fdd900e83d26ddb385b6955c"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["e230a61047bc041516c811baa08a7174d6f8322a","5128b7b3b73fedff05fdc5ea2e6be53c1020bb91","2e10cb22a8bdb44339e282925a29182bb2f3174d"],"a1b3a24d5d9b47345473ff564f5cc127a7b526b4":["5128b7b3b73fedff05fdc5ea2e6be53c1020bb91","fafef7c83fe8e0b3ca9298d5d75d6b943dc28153","d083e83f225b11e5fdd900e83d26ddb385b6955c","2e10cb22a8bdb44339e282925a29182bb2f3174d"],"2553b00f699380c64959ccb27991289aae87be2e":[],"d083e83f225b11e5fdd900e83d26ddb385b6955c":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"2e10cb22a8bdb44339e282925a29182bb2f3174d":[]},"heads":["2553b00f699380c64959ccb27991289aae87be2e","d083e83f225b11e5fdd900e83d26ddb385b6955c","cd5edd1f2b162a5cfa08efd17851a07373a96817","2e10cb22a8bdb44339e282925a29182bb2f3174d"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}