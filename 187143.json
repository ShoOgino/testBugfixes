{"path":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#lookup(CharSequence,BooleanQuery,int,boolean,boolean).mjava","commits":[{"id":"d2204dea8cf3dcfbffdf7b4d3459cf5287cc1c30","date":1431701935,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#lookup(CharSequence,BooleanQuery,int,boolean,boolean).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * This is an advanced method providing the capability to send down to the suggester any \n   * arbitrary lucene query to be used to filter the result of the suggester\n   * \n   * @param key the keyword being looked for\n   * @param contextQuery an arbitrary Lucene query to be used to filter the result of the suggester. {@link #addContextToQuery} could be used to build this contextQuery.\n   * @param num number of items to return\n   * @param allTermsRequired all searched terms must match or not\n   * @param doHighlight if true, the matching term will be highlighted in the search result\n   * @return the result of the suggester\n   * @throws IOException f the is IO exception while reading data from the index\n   */\n  public List<LookupResult> lookup(CharSequence key, BooleanQuery contextQuery, int num, boolean allTermsRequired, boolean doHighlight) throws IOException {\n\n    if (searcherMgr == null) {\n      throw new IllegalStateException(\"suggester was not built\");\n    }\n\n    final BooleanClause.Occur occur;\n    if (allTermsRequired) {\n      occur = BooleanClause.Occur.MUST;\n    } else {\n      occur = BooleanClause.Occur.SHOULD;\n    }\n\n    BooleanQuery query;\n    Set<String> matchedTokens;\n    String prefixToken = null;\n\n    try (TokenStream ts = queryAnalyzer.tokenStream(\"\", new StringReader(key.toString()))) {\n      //long t0 = System.currentTimeMillis();\n      ts.reset();\n      final CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      final OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      String lastToken = null;\n      query = new BooleanQuery();\n      int maxEndOffset = -1;\n      matchedTokens = new HashSet<>();\n      while (ts.incrementToken()) {\n        if (lastToken != null) {  \n          matchedTokens.add(lastToken);\n          query.add(new TermQuery(new Term(TEXT_FIELD_NAME, lastToken)), occur);\n        }\n        lastToken = termAtt.toString();\n        if (lastToken != null) {\n          maxEndOffset = Math.max(maxEndOffset, offsetAtt.endOffset());\n        }\n      }\n      ts.end();\n\n      if (lastToken != null) {\n        Query lastQuery;\n        if (maxEndOffset == offsetAtt.endOffset()) {\n          // Use PrefixQuery (or the ngram equivalent) when\n          // there was no trailing discarded chars in the\n          // string (e.g. whitespace), so that if query does\n          // not end with a space we show prefix matches for\n          // that token:\n          lastQuery = getLastTokenQuery(lastToken);\n          prefixToken = lastToken;\n        } else {\n          // Use TermQuery for an exact match if there were\n          // trailing discarded chars (e.g. whitespace), so\n          // that if query ends with a space we only show\n          // exact matches for that term:\n          matchedTokens.add(lastToken);\n          lastQuery = new TermQuery(new Term(TEXT_FIELD_NAME, lastToken));\n        }\n        \n        if (lastQuery != null) {\n          query.add(lastQuery, occur);\n        }\n      }\n\n      if (contextQuery != null) {\n        boolean allMustNot = true;\n        for (BooleanClause clause : contextQuery.clauses()) {\n          if (clause.getOccur() != BooleanClause.Occur.MUST_NOT) {\n            allMustNot = false;\n            break;\n          }\n        }\n        \n        if (allMustNot) {\n          //all are MUST_NOT: add the contextQuery to the main query instead (not as sub-query)\n          for (BooleanClause clause : contextQuery.clauses()) {\n            query.add(clause);\n          }\n        } else {\n          //Add contextQuery as sub-query\n          query.add(contextQuery, BooleanClause.Occur.MUST);\n        }\n      }\n    }\n    \n    // TODO: we could allow blended sort here, combining\n    // weight w/ score.  Now we ignore score and sort only\n    // by weight:\n\n    Query finalQuery = finishQuery(query, allTermsRequired);\n\n    //System.out.println(\"finalQuery=\" + query);\n\n    // Sort by weight, descending:\n    TopFieldCollector c = TopFieldCollector.create(SORT, num, true, false, false);\n\n    // We sorted postings by weight during indexing, so we\n    // only retrieve the first num hits now:\n    final MergePolicy mergePolicy = writer.getConfig().getMergePolicy();\n    Collector c2 = new EarlyTerminatingSortingCollector(c, SORT, num, (SortingMergePolicy) mergePolicy);\n    IndexSearcher searcher = searcherMgr.acquire();\n    List<LookupResult> results = null;\n    try {\n      //System.out.println(\"got searcher=\" + searcher);\n      searcher.search(finalQuery, c2);\n\n      TopFieldDocs hits = c.topDocs();\n\n      // Slower way if postings are not pre-sorted by weight:\n      // hits = searcher.search(query, null, num, SORT);\n      results = createResults(searcher, hits, num, key, doHighlight, matchedTokens, prefixToken);\n    } finally {\n      searcherMgr.release(searcher);\n    }\n\n    //System.out.println((System.currentTimeMillis() - t0) + \" msec for infix suggest\");\n    //System.out.println(results);\n\n    return results;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["3ddd7fe363a03b018dd62c48017d9997657a111e"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3f68d01cf19df971dcdcb05e30247f4ad7ec9747","date":1434611645,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#lookup(CharSequence,BooleanQuery,int,boolean,boolean).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#lookup(CharSequence,BooleanQuery,int,boolean,boolean).mjava","sourceNew":"  /**\n   * This is an advanced method providing the capability to send down to the suggester any \n   * arbitrary lucene query to be used to filter the result of the suggester\n   * \n   * @param key the keyword being looked for\n   * @param contextQuery an arbitrary Lucene query to be used to filter the result of the suggester. {@link #addContextToQuery} could be used to build this contextQuery.\n   * @param num number of items to return\n   * @param allTermsRequired all searched terms must match or not\n   * @param doHighlight if true, the matching term will be highlighted in the search result\n   * @return the result of the suggester\n   * @throws IOException f the is IO exception while reading data from the index\n   */\n  public List<LookupResult> lookup(CharSequence key, BooleanQuery contextQuery, int num, boolean allTermsRequired, boolean doHighlight) throws IOException {\n\n    if (searcherMgr == null) {\n      throw new IllegalStateException(\"suggester was not built\");\n    }\n\n    final BooleanClause.Occur occur;\n    if (allTermsRequired) {\n      occur = BooleanClause.Occur.MUST;\n    } else {\n      occur = BooleanClause.Occur.SHOULD;\n    }\n\n    BooleanQuery.Builder query;\n    Set<String> matchedTokens;\n    String prefixToken = null;\n\n    try (TokenStream ts = queryAnalyzer.tokenStream(\"\", new StringReader(key.toString()))) {\n      //long t0 = System.currentTimeMillis();\n      ts.reset();\n      final CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      final OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      String lastToken = null;\n      query = new BooleanQuery.Builder();\n      int maxEndOffset = -1;\n      matchedTokens = new HashSet<>();\n      while (ts.incrementToken()) {\n        if (lastToken != null) {  \n          matchedTokens.add(lastToken);\n          query.add(new TermQuery(new Term(TEXT_FIELD_NAME, lastToken)), occur);\n        }\n        lastToken = termAtt.toString();\n        if (lastToken != null) {\n          maxEndOffset = Math.max(maxEndOffset, offsetAtt.endOffset());\n        }\n      }\n      ts.end();\n\n      if (lastToken != null) {\n        Query lastQuery;\n        if (maxEndOffset == offsetAtt.endOffset()) {\n          // Use PrefixQuery (or the ngram equivalent) when\n          // there was no trailing discarded chars in the\n          // string (e.g. whitespace), so that if query does\n          // not end with a space we show prefix matches for\n          // that token:\n          lastQuery = getLastTokenQuery(lastToken);\n          prefixToken = lastToken;\n        } else {\n          // Use TermQuery for an exact match if there were\n          // trailing discarded chars (e.g. whitespace), so\n          // that if query ends with a space we only show\n          // exact matches for that term:\n          matchedTokens.add(lastToken);\n          lastQuery = new TermQuery(new Term(TEXT_FIELD_NAME, lastToken));\n        }\n        \n        if (lastQuery != null) {\n          query.add(lastQuery, occur);\n        }\n      }\n\n      if (contextQuery != null) {\n        boolean allMustNot = true;\n        for (BooleanClause clause : contextQuery.clauses()) {\n          if (clause.getOccur() != BooleanClause.Occur.MUST_NOT) {\n            allMustNot = false;\n            break;\n          }\n        }\n        \n        if (allMustNot) {\n          //all are MUST_NOT: add the contextQuery to the main query instead (not as sub-query)\n          for (BooleanClause clause : contextQuery.clauses()) {\n            query.add(clause);\n          }\n        } else {\n          //Add contextQuery as sub-query\n          query.add(contextQuery, BooleanClause.Occur.MUST);\n        }\n      }\n    }\n    \n    // TODO: we could allow blended sort here, combining\n    // weight w/ score.  Now we ignore score and sort only\n    // by weight:\n\n    Query finalQuery = finishQuery(query, allTermsRequired);\n\n    //System.out.println(\"finalQuery=\" + query);\n\n    // Sort by weight, descending:\n    TopFieldCollector c = TopFieldCollector.create(SORT, num, true, false, false);\n\n    // We sorted postings by weight during indexing, so we\n    // only retrieve the first num hits now:\n    final MergePolicy mergePolicy = writer.getConfig().getMergePolicy();\n    Collector c2 = new EarlyTerminatingSortingCollector(c, SORT, num, (SortingMergePolicy) mergePolicy);\n    IndexSearcher searcher = searcherMgr.acquire();\n    List<LookupResult> results = null;\n    try {\n      //System.out.println(\"got searcher=\" + searcher);\n      searcher.search(finalQuery, c2);\n\n      TopFieldDocs hits = c.topDocs();\n\n      // Slower way if postings are not pre-sorted by weight:\n      // hits = searcher.search(query, null, num, SORT);\n      results = createResults(searcher, hits, num, key, doHighlight, matchedTokens, prefixToken);\n    } finally {\n      searcherMgr.release(searcher);\n    }\n\n    //System.out.println((System.currentTimeMillis() - t0) + \" msec for infix suggest\");\n    //System.out.println(results);\n\n    return results;\n  }\n\n","sourceOld":"  /**\n   * This is an advanced method providing the capability to send down to the suggester any \n   * arbitrary lucene query to be used to filter the result of the suggester\n   * \n   * @param key the keyword being looked for\n   * @param contextQuery an arbitrary Lucene query to be used to filter the result of the suggester. {@link #addContextToQuery} could be used to build this contextQuery.\n   * @param num number of items to return\n   * @param allTermsRequired all searched terms must match or not\n   * @param doHighlight if true, the matching term will be highlighted in the search result\n   * @return the result of the suggester\n   * @throws IOException f the is IO exception while reading data from the index\n   */\n  public List<LookupResult> lookup(CharSequence key, BooleanQuery contextQuery, int num, boolean allTermsRequired, boolean doHighlight) throws IOException {\n\n    if (searcherMgr == null) {\n      throw new IllegalStateException(\"suggester was not built\");\n    }\n\n    final BooleanClause.Occur occur;\n    if (allTermsRequired) {\n      occur = BooleanClause.Occur.MUST;\n    } else {\n      occur = BooleanClause.Occur.SHOULD;\n    }\n\n    BooleanQuery query;\n    Set<String> matchedTokens;\n    String prefixToken = null;\n\n    try (TokenStream ts = queryAnalyzer.tokenStream(\"\", new StringReader(key.toString()))) {\n      //long t0 = System.currentTimeMillis();\n      ts.reset();\n      final CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      final OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      String lastToken = null;\n      query = new BooleanQuery();\n      int maxEndOffset = -1;\n      matchedTokens = new HashSet<>();\n      while (ts.incrementToken()) {\n        if (lastToken != null) {  \n          matchedTokens.add(lastToken);\n          query.add(new TermQuery(new Term(TEXT_FIELD_NAME, lastToken)), occur);\n        }\n        lastToken = termAtt.toString();\n        if (lastToken != null) {\n          maxEndOffset = Math.max(maxEndOffset, offsetAtt.endOffset());\n        }\n      }\n      ts.end();\n\n      if (lastToken != null) {\n        Query lastQuery;\n        if (maxEndOffset == offsetAtt.endOffset()) {\n          // Use PrefixQuery (or the ngram equivalent) when\n          // there was no trailing discarded chars in the\n          // string (e.g. whitespace), so that if query does\n          // not end with a space we show prefix matches for\n          // that token:\n          lastQuery = getLastTokenQuery(lastToken);\n          prefixToken = lastToken;\n        } else {\n          // Use TermQuery for an exact match if there were\n          // trailing discarded chars (e.g. whitespace), so\n          // that if query ends with a space we only show\n          // exact matches for that term:\n          matchedTokens.add(lastToken);\n          lastQuery = new TermQuery(new Term(TEXT_FIELD_NAME, lastToken));\n        }\n        \n        if (lastQuery != null) {\n          query.add(lastQuery, occur);\n        }\n      }\n\n      if (contextQuery != null) {\n        boolean allMustNot = true;\n        for (BooleanClause clause : contextQuery.clauses()) {\n          if (clause.getOccur() != BooleanClause.Occur.MUST_NOT) {\n            allMustNot = false;\n            break;\n          }\n        }\n        \n        if (allMustNot) {\n          //all are MUST_NOT: add the contextQuery to the main query instead (not as sub-query)\n          for (BooleanClause clause : contextQuery.clauses()) {\n            query.add(clause);\n          }\n        } else {\n          //Add contextQuery as sub-query\n          query.add(contextQuery, BooleanClause.Occur.MUST);\n        }\n      }\n    }\n    \n    // TODO: we could allow blended sort here, combining\n    // weight w/ score.  Now we ignore score and sort only\n    // by weight:\n\n    Query finalQuery = finishQuery(query, allTermsRequired);\n\n    //System.out.println(\"finalQuery=\" + query);\n\n    // Sort by weight, descending:\n    TopFieldCollector c = TopFieldCollector.create(SORT, num, true, false, false);\n\n    // We sorted postings by weight during indexing, so we\n    // only retrieve the first num hits now:\n    final MergePolicy mergePolicy = writer.getConfig().getMergePolicy();\n    Collector c2 = new EarlyTerminatingSortingCollector(c, SORT, num, (SortingMergePolicy) mergePolicy);\n    IndexSearcher searcher = searcherMgr.acquire();\n    List<LookupResult> results = null;\n    try {\n      //System.out.println(\"got searcher=\" + searcher);\n      searcher.search(finalQuery, c2);\n\n      TopFieldDocs hits = c.topDocs();\n\n      // Slower way if postings are not pre-sorted by weight:\n      // hits = searcher.search(query, null, num, SORT);\n      results = createResults(searcher, hits, num, key, doHighlight, matchedTokens, prefixToken);\n    } finally {\n      searcherMgr.release(searcher);\n    }\n\n    //System.out.println((System.currentTimeMillis() - t0) + \" msec for infix suggest\");\n    //System.out.println(results);\n\n    return results;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5732fca7cb88bd0841ccc6f8c8901b9cc1a7ce76","date":1435865633,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#lookup(CharSequence,BooleanQuery,int,boolean,boolean).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#lookup(CharSequence,BooleanQuery,int,boolean,boolean).mjava","sourceNew":"  /**\n   * This is an advanced method providing the capability to send down to the suggester any \n   * arbitrary lucene query to be used to filter the result of the suggester\n   * \n   * @param key the keyword being looked for\n   * @param contextQuery an arbitrary Lucene query to be used to filter the result of the suggester. {@link #addContextToQuery} could be used to build this contextQuery.\n   * @param num number of items to return\n   * @param allTermsRequired all searched terms must match or not\n   * @param doHighlight if true, the matching term will be highlighted in the search result\n   * @return the result of the suggester\n   * @throws IOException f the is IO exception while reading data from the index\n   */\n  public List<LookupResult> lookup(CharSequence key, BooleanQuery contextQuery, int num, boolean allTermsRequired, boolean doHighlight) throws IOException {\n\n    if (searcherMgr == null) {\n      throw new IllegalStateException(\"suggester was not built\");\n    }\n\n    final BooleanClause.Occur occur;\n    if (allTermsRequired) {\n      occur = BooleanClause.Occur.MUST;\n    } else {\n      occur = BooleanClause.Occur.SHOULD;\n    }\n\n    BooleanQuery.Builder query;\n    Set<String> matchedTokens;\n    String prefixToken = null;\n\n    try (TokenStream ts = queryAnalyzer.tokenStream(\"\", new StringReader(key.toString()))) {\n      //long t0 = System.currentTimeMillis();\n      ts.reset();\n      final CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      final OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      String lastToken = null;\n      query = new BooleanQuery.Builder();\n      int maxEndOffset = -1;\n      matchedTokens = new HashSet<>();\n      while (ts.incrementToken()) {\n        if (lastToken != null) {  \n          matchedTokens.add(lastToken);\n          query.add(new TermQuery(new Term(TEXT_FIELD_NAME, lastToken)), occur);\n        }\n        lastToken = termAtt.toString();\n        if (lastToken != null) {\n          maxEndOffset = Math.max(maxEndOffset, offsetAtt.endOffset());\n        }\n      }\n      ts.end();\n\n      if (lastToken != null) {\n        Query lastQuery;\n        if (maxEndOffset == offsetAtt.endOffset()) {\n          // Use PrefixQuery (or the ngram equivalent) when\n          // there was no trailing discarded chars in the\n          // string (e.g. whitespace), so that if query does\n          // not end with a space we show prefix matches for\n          // that token:\n          lastQuery = getLastTokenQuery(lastToken);\n          prefixToken = lastToken;\n        } else {\n          // Use TermQuery for an exact match if there were\n          // trailing discarded chars (e.g. whitespace), so\n          // that if query ends with a space we only show\n          // exact matches for that term:\n          matchedTokens.add(lastToken);\n          lastQuery = new TermQuery(new Term(TEXT_FIELD_NAME, lastToken));\n        }\n        \n        if (lastQuery != null) {\n          query.add(lastQuery, occur);\n        }\n      }\n\n      if (contextQuery != null) {\n        boolean allMustNot = true;\n        for (BooleanClause clause : contextQuery.clauses()) {\n          if (clause.getOccur() != BooleanClause.Occur.MUST_NOT) {\n            allMustNot = false;\n            break;\n          }\n        }\n        \n        if (allMustNot) {\n          //all are MUST_NOT: add the contextQuery to the main query instead (not as sub-query)\n          for (BooleanClause clause : contextQuery.clauses()) {\n            query.add(clause);\n          }\n        } else {\n          //Add contextQuery as sub-query\n          query.add(contextQuery, BooleanClause.Occur.MUST);\n        }\n      }\n    }\n    \n    // TODO: we could allow blended sort here, combining\n    // weight w/ score.  Now we ignore score and sort only\n    // by weight:\n\n    Query finalQuery = finishQuery(query, allTermsRequired);\n\n    //System.out.println(\"finalQuery=\" + query);\n\n    // Sort by weight, descending:\n    TopFieldCollector c = TopFieldCollector.create(SORT, num, true, false, false);\n\n    // We sorted postings by weight during indexing, so we\n    // only retrieve the first num hits now:\n    final SortingMergePolicy sortingMergePolicy = (SortingMergePolicy) writer.getConfig().getMergePolicy();\n    Collector c2 = new EarlyTerminatingSortingCollector(c, SORT, num, sortingMergePolicy.getSort());\n    IndexSearcher searcher = searcherMgr.acquire();\n    List<LookupResult> results = null;\n    try {\n      //System.out.println(\"got searcher=\" + searcher);\n      searcher.search(finalQuery, c2);\n\n      TopFieldDocs hits = c.topDocs();\n\n      // Slower way if postings are not pre-sorted by weight:\n      // hits = searcher.search(query, null, num, SORT);\n      results = createResults(searcher, hits, num, key, doHighlight, matchedTokens, prefixToken);\n    } finally {\n      searcherMgr.release(searcher);\n    }\n\n    //System.out.println((System.currentTimeMillis() - t0) + \" msec for infix suggest\");\n    //System.out.println(results);\n\n    return results;\n  }\n\n","sourceOld":"  /**\n   * This is an advanced method providing the capability to send down to the suggester any \n   * arbitrary lucene query to be used to filter the result of the suggester\n   * \n   * @param key the keyword being looked for\n   * @param contextQuery an arbitrary Lucene query to be used to filter the result of the suggester. {@link #addContextToQuery} could be used to build this contextQuery.\n   * @param num number of items to return\n   * @param allTermsRequired all searched terms must match or not\n   * @param doHighlight if true, the matching term will be highlighted in the search result\n   * @return the result of the suggester\n   * @throws IOException f the is IO exception while reading data from the index\n   */\n  public List<LookupResult> lookup(CharSequence key, BooleanQuery contextQuery, int num, boolean allTermsRequired, boolean doHighlight) throws IOException {\n\n    if (searcherMgr == null) {\n      throw new IllegalStateException(\"suggester was not built\");\n    }\n\n    final BooleanClause.Occur occur;\n    if (allTermsRequired) {\n      occur = BooleanClause.Occur.MUST;\n    } else {\n      occur = BooleanClause.Occur.SHOULD;\n    }\n\n    BooleanQuery.Builder query;\n    Set<String> matchedTokens;\n    String prefixToken = null;\n\n    try (TokenStream ts = queryAnalyzer.tokenStream(\"\", new StringReader(key.toString()))) {\n      //long t0 = System.currentTimeMillis();\n      ts.reset();\n      final CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      final OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      String lastToken = null;\n      query = new BooleanQuery.Builder();\n      int maxEndOffset = -1;\n      matchedTokens = new HashSet<>();\n      while (ts.incrementToken()) {\n        if (lastToken != null) {  \n          matchedTokens.add(lastToken);\n          query.add(new TermQuery(new Term(TEXT_FIELD_NAME, lastToken)), occur);\n        }\n        lastToken = termAtt.toString();\n        if (lastToken != null) {\n          maxEndOffset = Math.max(maxEndOffset, offsetAtt.endOffset());\n        }\n      }\n      ts.end();\n\n      if (lastToken != null) {\n        Query lastQuery;\n        if (maxEndOffset == offsetAtt.endOffset()) {\n          // Use PrefixQuery (or the ngram equivalent) when\n          // there was no trailing discarded chars in the\n          // string (e.g. whitespace), so that if query does\n          // not end with a space we show prefix matches for\n          // that token:\n          lastQuery = getLastTokenQuery(lastToken);\n          prefixToken = lastToken;\n        } else {\n          // Use TermQuery for an exact match if there were\n          // trailing discarded chars (e.g. whitespace), so\n          // that if query ends with a space we only show\n          // exact matches for that term:\n          matchedTokens.add(lastToken);\n          lastQuery = new TermQuery(new Term(TEXT_FIELD_NAME, lastToken));\n        }\n        \n        if (lastQuery != null) {\n          query.add(lastQuery, occur);\n        }\n      }\n\n      if (contextQuery != null) {\n        boolean allMustNot = true;\n        for (BooleanClause clause : contextQuery.clauses()) {\n          if (clause.getOccur() != BooleanClause.Occur.MUST_NOT) {\n            allMustNot = false;\n            break;\n          }\n        }\n        \n        if (allMustNot) {\n          //all are MUST_NOT: add the contextQuery to the main query instead (not as sub-query)\n          for (BooleanClause clause : contextQuery.clauses()) {\n            query.add(clause);\n          }\n        } else {\n          //Add contextQuery as sub-query\n          query.add(contextQuery, BooleanClause.Occur.MUST);\n        }\n      }\n    }\n    \n    // TODO: we could allow blended sort here, combining\n    // weight w/ score.  Now we ignore score and sort only\n    // by weight:\n\n    Query finalQuery = finishQuery(query, allTermsRequired);\n\n    //System.out.println(\"finalQuery=\" + query);\n\n    // Sort by weight, descending:\n    TopFieldCollector c = TopFieldCollector.create(SORT, num, true, false, false);\n\n    // We sorted postings by weight during indexing, so we\n    // only retrieve the first num hits now:\n    final MergePolicy mergePolicy = writer.getConfig().getMergePolicy();\n    Collector c2 = new EarlyTerminatingSortingCollector(c, SORT, num, (SortingMergePolicy) mergePolicy);\n    IndexSearcher searcher = searcherMgr.acquire();\n    List<LookupResult> results = null;\n    try {\n      //System.out.println(\"got searcher=\" + searcher);\n      searcher.search(finalQuery, c2);\n\n      TopFieldDocs hits = c.topDocs();\n\n      // Slower way if postings are not pre-sorted by weight:\n      // hits = searcher.search(query, null, num, SORT);\n      results = createResults(searcher, hits, num, key, doHighlight, matchedTokens, prefixToken);\n    } finally {\n      searcherMgr.release(searcher);\n    }\n\n    //System.out.println((System.currentTimeMillis() - t0) + \" msec for infix suggest\");\n    //System.out.println(results);\n\n    return results;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fbe8fc0e68a5e2e7acce82ba880a982bd15cfab8","date":1462567286,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#lookup(CharSequence,BooleanQuery,int,boolean,boolean).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#lookup(CharSequence,BooleanQuery,int,boolean,boolean).mjava","sourceNew":"  /**\n   * This is an advanced method providing the capability to send down to the suggester any \n   * arbitrary lucene query to be used to filter the result of the suggester\n   * \n   * @param key the keyword being looked for\n   * @param contextQuery an arbitrary Lucene query to be used to filter the result of the suggester. {@link #addContextToQuery} could be used to build this contextQuery.\n   * @param num number of items to return\n   * @param allTermsRequired all searched terms must match or not\n   * @param doHighlight if true, the matching term will be highlighted in the search result\n   * @return the result of the suggester\n   * @throws IOException f the is IO exception while reading data from the index\n   */\n  public List<LookupResult> lookup(CharSequence key, BooleanQuery contextQuery, int num, boolean allTermsRequired, boolean doHighlight) throws IOException {\n\n    if (searcherMgr == null) {\n      throw new IllegalStateException(\"suggester was not built\");\n    }\n\n    final BooleanClause.Occur occur;\n    if (allTermsRequired) {\n      occur = BooleanClause.Occur.MUST;\n    } else {\n      occur = BooleanClause.Occur.SHOULD;\n    }\n\n    BooleanQuery.Builder query;\n    Set<String> matchedTokens;\n    String prefixToken = null;\n\n    try (TokenStream ts = queryAnalyzer.tokenStream(\"\", new StringReader(key.toString()))) {\n      //long t0 = System.currentTimeMillis();\n      ts.reset();\n      final CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      final OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      String lastToken = null;\n      query = new BooleanQuery.Builder();\n      int maxEndOffset = -1;\n      matchedTokens = new HashSet<>();\n      while (ts.incrementToken()) {\n        if (lastToken != null) {  \n          matchedTokens.add(lastToken);\n          query.add(new TermQuery(new Term(TEXT_FIELD_NAME, lastToken)), occur);\n        }\n        lastToken = termAtt.toString();\n        if (lastToken != null) {\n          maxEndOffset = Math.max(maxEndOffset, offsetAtt.endOffset());\n        }\n      }\n      ts.end();\n\n      if (lastToken != null) {\n        Query lastQuery;\n        if (maxEndOffset == offsetAtt.endOffset()) {\n          // Use PrefixQuery (or the ngram equivalent) when\n          // there was no trailing discarded chars in the\n          // string (e.g. whitespace), so that if query does\n          // not end with a space we show prefix matches for\n          // that token:\n          lastQuery = getLastTokenQuery(lastToken);\n          prefixToken = lastToken;\n        } else {\n          // Use TermQuery for an exact match if there were\n          // trailing discarded chars (e.g. whitespace), so\n          // that if query ends with a space we only show\n          // exact matches for that term:\n          matchedTokens.add(lastToken);\n          lastQuery = new TermQuery(new Term(TEXT_FIELD_NAME, lastToken));\n        }\n        \n        if (lastQuery != null) {\n          query.add(lastQuery, occur);\n        }\n      }\n\n      if (contextQuery != null) {\n        boolean allMustNot = true;\n        for (BooleanClause clause : contextQuery.clauses()) {\n          if (clause.getOccur() != BooleanClause.Occur.MUST_NOT) {\n            allMustNot = false;\n            break;\n          }\n        }\n        \n        if (allMustNot) {\n          //all are MUST_NOT: add the contextQuery to the main query instead (not as sub-query)\n          for (BooleanClause clause : contextQuery.clauses()) {\n            query.add(clause);\n          }\n        } else {\n          //Add contextQuery as sub-query\n          query.add(contextQuery, BooleanClause.Occur.MUST);\n        }\n      }\n    }\n    \n    // TODO: we could allow blended sort here, combining\n    // weight w/ score.  Now we ignore score and sort only\n    // by weight:\n\n    Query finalQuery = finishQuery(query, allTermsRequired);\n\n    //System.out.println(\"finalQuery=\" + query);\n\n    // Sort by weight, descending:\n    TopFieldCollector c = TopFieldCollector.create(SORT, num, true, false, false);\n\n    // We sorted postings by weight during indexing, so we\n    // only retrieve the first num hits now:\n    Collector c2 = new EarlyTerminatingSortingCollector(c, SORT, num);\n    IndexSearcher searcher = searcherMgr.acquire();\n    List<LookupResult> results = null;\n    try {\n      //System.out.println(\"got searcher=\" + searcher);\n      searcher.search(finalQuery, c2);\n\n      TopFieldDocs hits = c.topDocs();\n\n      // Slower way if postings are not pre-sorted by weight:\n      // hits = searcher.search(query, null, num, SORT);\n      results = createResults(searcher, hits, num, key, doHighlight, matchedTokens, prefixToken);\n    } finally {\n      searcherMgr.release(searcher);\n    }\n\n    //System.out.println((System.currentTimeMillis() - t0) + \" msec for infix suggest\");\n    //System.out.println(results);\n\n    return results;\n  }\n\n","sourceOld":"  /**\n   * This is an advanced method providing the capability to send down to the suggester any \n   * arbitrary lucene query to be used to filter the result of the suggester\n   * \n   * @param key the keyword being looked for\n   * @param contextQuery an arbitrary Lucene query to be used to filter the result of the suggester. {@link #addContextToQuery} could be used to build this contextQuery.\n   * @param num number of items to return\n   * @param allTermsRequired all searched terms must match or not\n   * @param doHighlight if true, the matching term will be highlighted in the search result\n   * @return the result of the suggester\n   * @throws IOException f the is IO exception while reading data from the index\n   */\n  public List<LookupResult> lookup(CharSequence key, BooleanQuery contextQuery, int num, boolean allTermsRequired, boolean doHighlight) throws IOException {\n\n    if (searcherMgr == null) {\n      throw new IllegalStateException(\"suggester was not built\");\n    }\n\n    final BooleanClause.Occur occur;\n    if (allTermsRequired) {\n      occur = BooleanClause.Occur.MUST;\n    } else {\n      occur = BooleanClause.Occur.SHOULD;\n    }\n\n    BooleanQuery.Builder query;\n    Set<String> matchedTokens;\n    String prefixToken = null;\n\n    try (TokenStream ts = queryAnalyzer.tokenStream(\"\", new StringReader(key.toString()))) {\n      //long t0 = System.currentTimeMillis();\n      ts.reset();\n      final CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      final OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      String lastToken = null;\n      query = new BooleanQuery.Builder();\n      int maxEndOffset = -1;\n      matchedTokens = new HashSet<>();\n      while (ts.incrementToken()) {\n        if (lastToken != null) {  \n          matchedTokens.add(lastToken);\n          query.add(new TermQuery(new Term(TEXT_FIELD_NAME, lastToken)), occur);\n        }\n        lastToken = termAtt.toString();\n        if (lastToken != null) {\n          maxEndOffset = Math.max(maxEndOffset, offsetAtt.endOffset());\n        }\n      }\n      ts.end();\n\n      if (lastToken != null) {\n        Query lastQuery;\n        if (maxEndOffset == offsetAtt.endOffset()) {\n          // Use PrefixQuery (or the ngram equivalent) when\n          // there was no trailing discarded chars in the\n          // string (e.g. whitespace), so that if query does\n          // not end with a space we show prefix matches for\n          // that token:\n          lastQuery = getLastTokenQuery(lastToken);\n          prefixToken = lastToken;\n        } else {\n          // Use TermQuery for an exact match if there were\n          // trailing discarded chars (e.g. whitespace), so\n          // that if query ends with a space we only show\n          // exact matches for that term:\n          matchedTokens.add(lastToken);\n          lastQuery = new TermQuery(new Term(TEXT_FIELD_NAME, lastToken));\n        }\n        \n        if (lastQuery != null) {\n          query.add(lastQuery, occur);\n        }\n      }\n\n      if (contextQuery != null) {\n        boolean allMustNot = true;\n        for (BooleanClause clause : contextQuery.clauses()) {\n          if (clause.getOccur() != BooleanClause.Occur.MUST_NOT) {\n            allMustNot = false;\n            break;\n          }\n        }\n        \n        if (allMustNot) {\n          //all are MUST_NOT: add the contextQuery to the main query instead (not as sub-query)\n          for (BooleanClause clause : contextQuery.clauses()) {\n            query.add(clause);\n          }\n        } else {\n          //Add contextQuery as sub-query\n          query.add(contextQuery, BooleanClause.Occur.MUST);\n        }\n      }\n    }\n    \n    // TODO: we could allow blended sort here, combining\n    // weight w/ score.  Now we ignore score and sort only\n    // by weight:\n\n    Query finalQuery = finishQuery(query, allTermsRequired);\n\n    //System.out.println(\"finalQuery=\" + query);\n\n    // Sort by weight, descending:\n    TopFieldCollector c = TopFieldCollector.create(SORT, num, true, false, false);\n\n    // We sorted postings by weight during indexing, so we\n    // only retrieve the first num hits now:\n    final SortingMergePolicy sortingMergePolicy = (SortingMergePolicy) writer.getConfig().getMergePolicy();\n    Collector c2 = new EarlyTerminatingSortingCollector(c, SORT, num, sortingMergePolicy.getSort());\n    IndexSearcher searcher = searcherMgr.acquire();\n    List<LookupResult> results = null;\n    try {\n      //System.out.println(\"got searcher=\" + searcher);\n      searcher.search(finalQuery, c2);\n\n      TopFieldDocs hits = c.topDocs();\n\n      // Slower way if postings are not pre-sorted by weight:\n      // hits = searcher.search(query, null, num, SORT);\n      results = createResults(searcher, hits, num, key, doHighlight, matchedTokens, prefixToken);\n    } finally {\n      searcherMgr.release(searcher);\n    }\n\n    //System.out.println((System.currentTimeMillis() - t0) + \" msec for infix suggest\");\n    //System.out.println(results);\n\n    return results;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"22aab7a3b640b0dba26cc5e9416bc7af93614b46","date":1462575761,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#lookup(CharSequence,BooleanQuery,int,boolean,boolean).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#lookup(CharSequence,BooleanQuery,int,boolean,boolean).mjava","sourceNew":"  /**\n   * This is an advanced method providing the capability to send down to the suggester any \n   * arbitrary lucene query to be used to filter the result of the suggester\n   * \n   * @param key the keyword being looked for\n   * @param contextQuery an arbitrary Lucene query to be used to filter the result of the suggester. {@link #addContextToQuery} could be used to build this contextQuery.\n   * @param num number of items to return\n   * @param allTermsRequired all searched terms must match or not\n   * @param doHighlight if true, the matching term will be highlighted in the search result\n   * @return the result of the suggester\n   * @throws IOException f the is IO exception while reading data from the index\n   */\n  public List<LookupResult> lookup(CharSequence key, BooleanQuery contextQuery, int num, boolean allTermsRequired, boolean doHighlight) throws IOException {\n\n    if (searcherMgr == null) {\n      throw new IllegalStateException(\"suggester was not built\");\n    }\n\n    final BooleanClause.Occur occur;\n    if (allTermsRequired) {\n      occur = BooleanClause.Occur.MUST;\n    } else {\n      occur = BooleanClause.Occur.SHOULD;\n    }\n\n    BooleanQuery.Builder query;\n    Set<String> matchedTokens;\n    String prefixToken = null;\n\n    try (TokenStream ts = queryAnalyzer.tokenStream(\"\", new StringReader(key.toString()))) {\n      //long t0 = System.currentTimeMillis();\n      ts.reset();\n      final CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      final OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      String lastToken = null;\n      query = new BooleanQuery.Builder();\n      int maxEndOffset = -1;\n      matchedTokens = new HashSet<>();\n      while (ts.incrementToken()) {\n        if (lastToken != null) {  \n          matchedTokens.add(lastToken);\n          query.add(new TermQuery(new Term(TEXT_FIELD_NAME, lastToken)), occur);\n        }\n        lastToken = termAtt.toString();\n        if (lastToken != null) {\n          maxEndOffset = Math.max(maxEndOffset, offsetAtt.endOffset());\n        }\n      }\n      ts.end();\n\n      if (lastToken != null) {\n        Query lastQuery;\n        if (maxEndOffset == offsetAtt.endOffset()) {\n          // Use PrefixQuery (or the ngram equivalent) when\n          // there was no trailing discarded chars in the\n          // string (e.g. whitespace), so that if query does\n          // not end with a space we show prefix matches for\n          // that token:\n          lastQuery = getLastTokenQuery(lastToken);\n          prefixToken = lastToken;\n        } else {\n          // Use TermQuery for an exact match if there were\n          // trailing discarded chars (e.g. whitespace), so\n          // that if query ends with a space we only show\n          // exact matches for that term:\n          matchedTokens.add(lastToken);\n          lastQuery = new TermQuery(new Term(TEXT_FIELD_NAME, lastToken));\n        }\n        \n        if (lastQuery != null) {\n          query.add(lastQuery, occur);\n        }\n      }\n\n      if (contextQuery != null) {\n        boolean allMustNot = true;\n        for (BooleanClause clause : contextQuery.clauses()) {\n          if (clause.getOccur() != BooleanClause.Occur.MUST_NOT) {\n            allMustNot = false;\n            break;\n          }\n        }\n        \n        if (allMustNot) {\n          //all are MUST_NOT: add the contextQuery to the main query instead (not as sub-query)\n          for (BooleanClause clause : contextQuery.clauses()) {\n            query.add(clause);\n          }\n        } else {\n          //Add contextQuery as sub-query\n          query.add(contextQuery, BooleanClause.Occur.MUST);\n        }\n      }\n    }\n    \n    // TODO: we could allow blended sort here, combining\n    // weight w/ score.  Now we ignore score and sort only\n    // by weight:\n\n    Query finalQuery = finishQuery(query, allTermsRequired);\n\n    //System.out.println(\"finalQuery=\" + query);\n\n    // Sort by weight, descending:\n    TopFieldCollector c = TopFieldCollector.create(SORT, num, true, false, false);\n\n    // We sorted postings by weight during indexing, so we\n    // only retrieve the first num hits now:\n    Collector c2 = new EarlyTerminatingSortingCollector(c, SORT, num);\n    List<LookupResult> results = null;\n    IndexSearcher searcher = searcherMgr.acquire();\n    try {\n      //System.out.println(\"got searcher=\" + searcher);\n      searcher.search(finalQuery, c2);\n\n      TopFieldDocs hits = c.topDocs();\n\n      // Slower way if postings are not pre-sorted by weight:\n      // hits = searcher.search(query, null, num, SORT);\n      results = createResults(searcher, hits, num, key, doHighlight, matchedTokens, prefixToken);\n    } finally {\n      searcherMgr.release(searcher);\n    }\n\n    //System.out.println((System.currentTimeMillis() - t0) + \" msec for infix suggest\");\n    //System.out.println(results);\n\n    return results;\n  }\n\n","sourceOld":"  /**\n   * This is an advanced method providing the capability to send down to the suggester any \n   * arbitrary lucene query to be used to filter the result of the suggester\n   * \n   * @param key the keyword being looked for\n   * @param contextQuery an arbitrary Lucene query to be used to filter the result of the suggester. {@link #addContextToQuery} could be used to build this contextQuery.\n   * @param num number of items to return\n   * @param allTermsRequired all searched terms must match or not\n   * @param doHighlight if true, the matching term will be highlighted in the search result\n   * @return the result of the suggester\n   * @throws IOException f the is IO exception while reading data from the index\n   */\n  public List<LookupResult> lookup(CharSequence key, BooleanQuery contextQuery, int num, boolean allTermsRequired, boolean doHighlight) throws IOException {\n\n    if (searcherMgr == null) {\n      throw new IllegalStateException(\"suggester was not built\");\n    }\n\n    final BooleanClause.Occur occur;\n    if (allTermsRequired) {\n      occur = BooleanClause.Occur.MUST;\n    } else {\n      occur = BooleanClause.Occur.SHOULD;\n    }\n\n    BooleanQuery.Builder query;\n    Set<String> matchedTokens;\n    String prefixToken = null;\n\n    try (TokenStream ts = queryAnalyzer.tokenStream(\"\", new StringReader(key.toString()))) {\n      //long t0 = System.currentTimeMillis();\n      ts.reset();\n      final CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      final OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      String lastToken = null;\n      query = new BooleanQuery.Builder();\n      int maxEndOffset = -1;\n      matchedTokens = new HashSet<>();\n      while (ts.incrementToken()) {\n        if (lastToken != null) {  \n          matchedTokens.add(lastToken);\n          query.add(new TermQuery(new Term(TEXT_FIELD_NAME, lastToken)), occur);\n        }\n        lastToken = termAtt.toString();\n        if (lastToken != null) {\n          maxEndOffset = Math.max(maxEndOffset, offsetAtt.endOffset());\n        }\n      }\n      ts.end();\n\n      if (lastToken != null) {\n        Query lastQuery;\n        if (maxEndOffset == offsetAtt.endOffset()) {\n          // Use PrefixQuery (or the ngram equivalent) when\n          // there was no trailing discarded chars in the\n          // string (e.g. whitespace), so that if query does\n          // not end with a space we show prefix matches for\n          // that token:\n          lastQuery = getLastTokenQuery(lastToken);\n          prefixToken = lastToken;\n        } else {\n          // Use TermQuery for an exact match if there were\n          // trailing discarded chars (e.g. whitespace), so\n          // that if query ends with a space we only show\n          // exact matches for that term:\n          matchedTokens.add(lastToken);\n          lastQuery = new TermQuery(new Term(TEXT_FIELD_NAME, lastToken));\n        }\n        \n        if (lastQuery != null) {\n          query.add(lastQuery, occur);\n        }\n      }\n\n      if (contextQuery != null) {\n        boolean allMustNot = true;\n        for (BooleanClause clause : contextQuery.clauses()) {\n          if (clause.getOccur() != BooleanClause.Occur.MUST_NOT) {\n            allMustNot = false;\n            break;\n          }\n        }\n        \n        if (allMustNot) {\n          //all are MUST_NOT: add the contextQuery to the main query instead (not as sub-query)\n          for (BooleanClause clause : contextQuery.clauses()) {\n            query.add(clause);\n          }\n        } else {\n          //Add contextQuery as sub-query\n          query.add(contextQuery, BooleanClause.Occur.MUST);\n        }\n      }\n    }\n    \n    // TODO: we could allow blended sort here, combining\n    // weight w/ score.  Now we ignore score and sort only\n    // by weight:\n\n    Query finalQuery = finishQuery(query, allTermsRequired);\n\n    //System.out.println(\"finalQuery=\" + query);\n\n    // Sort by weight, descending:\n    TopFieldCollector c = TopFieldCollector.create(SORT, num, true, false, false);\n\n    // We sorted postings by weight during indexing, so we\n    // only retrieve the first num hits now:\n    Collector c2 = new EarlyTerminatingSortingCollector(c, SORT, num);\n    IndexSearcher searcher = searcherMgr.acquire();\n    List<LookupResult> results = null;\n    try {\n      //System.out.println(\"got searcher=\" + searcher);\n      searcher.search(finalQuery, c2);\n\n      TopFieldDocs hits = c.topDocs();\n\n      // Slower way if postings are not pre-sorted by weight:\n      // hits = searcher.search(query, null, num, SORT);\n      results = createResults(searcher, hits, num, key, doHighlight, matchedTokens, prefixToken);\n    } finally {\n      searcherMgr.release(searcher);\n    }\n\n    //System.out.println((System.currentTimeMillis() - t0) + \" msec for infix suggest\");\n    //System.out.println(results);\n\n    return results;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3d33e731a93d4b57e662ff094f64f94a745422d4","date":1463128289,"type":3,"author":"Mike McCandless","isMerge":true,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#lookup(CharSequence,BooleanQuery,int,boolean,boolean).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#lookup(CharSequence,BooleanQuery,int,boolean,boolean).mjava","sourceNew":"  /**\n   * This is an advanced method providing the capability to send down to the suggester any \n   * arbitrary lucene query to be used to filter the result of the suggester\n   * \n   * @param key the keyword being looked for\n   * @param contextQuery an arbitrary Lucene query to be used to filter the result of the suggester. {@link #addContextToQuery} could be used to build this contextQuery.\n   * @param num number of items to return\n   * @param allTermsRequired all searched terms must match or not\n   * @param doHighlight if true, the matching term will be highlighted in the search result\n   * @return the result of the suggester\n   * @throws IOException f the is IO exception while reading data from the index\n   */\n  public List<LookupResult> lookup(CharSequence key, BooleanQuery contextQuery, int num, boolean allTermsRequired, boolean doHighlight) throws IOException {\n\n    if (searcherMgr == null) {\n      throw new IllegalStateException(\"suggester was not built\");\n    }\n\n    final BooleanClause.Occur occur;\n    if (allTermsRequired) {\n      occur = BooleanClause.Occur.MUST;\n    } else {\n      occur = BooleanClause.Occur.SHOULD;\n    }\n\n    BooleanQuery.Builder query;\n    Set<String> matchedTokens;\n    String prefixToken = null;\n\n    try (TokenStream ts = queryAnalyzer.tokenStream(\"\", new StringReader(key.toString()))) {\n      //long t0 = System.currentTimeMillis();\n      ts.reset();\n      final CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      final OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      String lastToken = null;\n      query = new BooleanQuery.Builder();\n      int maxEndOffset = -1;\n      matchedTokens = new HashSet<>();\n      while (ts.incrementToken()) {\n        if (lastToken != null) {  \n          matchedTokens.add(lastToken);\n          query.add(new TermQuery(new Term(TEXT_FIELD_NAME, lastToken)), occur);\n        }\n        lastToken = termAtt.toString();\n        if (lastToken != null) {\n          maxEndOffset = Math.max(maxEndOffset, offsetAtt.endOffset());\n        }\n      }\n      ts.end();\n\n      if (lastToken != null) {\n        Query lastQuery;\n        if (maxEndOffset == offsetAtt.endOffset()) {\n          // Use PrefixQuery (or the ngram equivalent) when\n          // there was no trailing discarded chars in the\n          // string (e.g. whitespace), so that if query does\n          // not end with a space we show prefix matches for\n          // that token:\n          lastQuery = getLastTokenQuery(lastToken);\n          prefixToken = lastToken;\n        } else {\n          // Use TermQuery for an exact match if there were\n          // trailing discarded chars (e.g. whitespace), so\n          // that if query ends with a space we only show\n          // exact matches for that term:\n          matchedTokens.add(lastToken);\n          lastQuery = new TermQuery(new Term(TEXT_FIELD_NAME, lastToken));\n        }\n        \n        if (lastQuery != null) {\n          query.add(lastQuery, occur);\n        }\n      }\n\n      if (contextQuery != null) {\n        boolean allMustNot = true;\n        for (BooleanClause clause : contextQuery.clauses()) {\n          if (clause.getOccur() != BooleanClause.Occur.MUST_NOT) {\n            allMustNot = false;\n            break;\n          }\n        }\n        \n        if (allMustNot) {\n          //all are MUST_NOT: add the contextQuery to the main query instead (not as sub-query)\n          for (BooleanClause clause : contextQuery.clauses()) {\n            query.add(clause);\n          }\n        } else {\n          //Add contextQuery as sub-query\n          query.add(contextQuery, BooleanClause.Occur.MUST);\n        }\n      }\n    }\n    \n    // TODO: we could allow blended sort here, combining\n    // weight w/ score.  Now we ignore score and sort only\n    // by weight:\n\n    Query finalQuery = finishQuery(query, allTermsRequired);\n\n    //System.out.println(\"finalQuery=\" + query);\n\n    // Sort by weight, descending:\n    TopFieldCollector c = TopFieldCollector.create(SORT, num, true, false, false);\n\n    // We sorted postings by weight during indexing, so we\n    // only retrieve the first num hits now:\n    Collector c2 = new EarlyTerminatingSortingCollector(c, SORT, num);\n    List<LookupResult> results = null;\n    IndexSearcher searcher = searcherMgr.acquire();\n    try {\n      //System.out.println(\"got searcher=\" + searcher);\n      searcher.search(finalQuery, c2);\n\n      TopFieldDocs hits = c.topDocs();\n\n      // Slower way if postings are not pre-sorted by weight:\n      // hits = searcher.search(query, null, num, SORT);\n      results = createResults(searcher, hits, num, key, doHighlight, matchedTokens, prefixToken);\n    } finally {\n      searcherMgr.release(searcher);\n    }\n\n    //System.out.println((System.currentTimeMillis() - t0) + \" msec for infix suggest\");\n    //System.out.println(results);\n\n    return results;\n  }\n\n","sourceOld":"  /**\n   * This is an advanced method providing the capability to send down to the suggester any \n   * arbitrary lucene query to be used to filter the result of the suggester\n   * \n   * @param key the keyword being looked for\n   * @param contextQuery an arbitrary Lucene query to be used to filter the result of the suggester. {@link #addContextToQuery} could be used to build this contextQuery.\n   * @param num number of items to return\n   * @param allTermsRequired all searched terms must match or not\n   * @param doHighlight if true, the matching term will be highlighted in the search result\n   * @return the result of the suggester\n   * @throws IOException f the is IO exception while reading data from the index\n   */\n  public List<LookupResult> lookup(CharSequence key, BooleanQuery contextQuery, int num, boolean allTermsRequired, boolean doHighlight) throws IOException {\n\n    if (searcherMgr == null) {\n      throw new IllegalStateException(\"suggester was not built\");\n    }\n\n    final BooleanClause.Occur occur;\n    if (allTermsRequired) {\n      occur = BooleanClause.Occur.MUST;\n    } else {\n      occur = BooleanClause.Occur.SHOULD;\n    }\n\n    BooleanQuery.Builder query;\n    Set<String> matchedTokens;\n    String prefixToken = null;\n\n    try (TokenStream ts = queryAnalyzer.tokenStream(\"\", new StringReader(key.toString()))) {\n      //long t0 = System.currentTimeMillis();\n      ts.reset();\n      final CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      final OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      String lastToken = null;\n      query = new BooleanQuery.Builder();\n      int maxEndOffset = -1;\n      matchedTokens = new HashSet<>();\n      while (ts.incrementToken()) {\n        if (lastToken != null) {  \n          matchedTokens.add(lastToken);\n          query.add(new TermQuery(new Term(TEXT_FIELD_NAME, lastToken)), occur);\n        }\n        lastToken = termAtt.toString();\n        if (lastToken != null) {\n          maxEndOffset = Math.max(maxEndOffset, offsetAtt.endOffset());\n        }\n      }\n      ts.end();\n\n      if (lastToken != null) {\n        Query lastQuery;\n        if (maxEndOffset == offsetAtt.endOffset()) {\n          // Use PrefixQuery (or the ngram equivalent) when\n          // there was no trailing discarded chars in the\n          // string (e.g. whitespace), so that if query does\n          // not end with a space we show prefix matches for\n          // that token:\n          lastQuery = getLastTokenQuery(lastToken);\n          prefixToken = lastToken;\n        } else {\n          // Use TermQuery for an exact match if there were\n          // trailing discarded chars (e.g. whitespace), so\n          // that if query ends with a space we only show\n          // exact matches for that term:\n          matchedTokens.add(lastToken);\n          lastQuery = new TermQuery(new Term(TEXT_FIELD_NAME, lastToken));\n        }\n        \n        if (lastQuery != null) {\n          query.add(lastQuery, occur);\n        }\n      }\n\n      if (contextQuery != null) {\n        boolean allMustNot = true;\n        for (BooleanClause clause : contextQuery.clauses()) {\n          if (clause.getOccur() != BooleanClause.Occur.MUST_NOT) {\n            allMustNot = false;\n            break;\n          }\n        }\n        \n        if (allMustNot) {\n          //all are MUST_NOT: add the contextQuery to the main query instead (not as sub-query)\n          for (BooleanClause clause : contextQuery.clauses()) {\n            query.add(clause);\n          }\n        } else {\n          //Add contextQuery as sub-query\n          query.add(contextQuery, BooleanClause.Occur.MUST);\n        }\n      }\n    }\n    \n    // TODO: we could allow blended sort here, combining\n    // weight w/ score.  Now we ignore score and sort only\n    // by weight:\n\n    Query finalQuery = finishQuery(query, allTermsRequired);\n\n    //System.out.println(\"finalQuery=\" + query);\n\n    // Sort by weight, descending:\n    TopFieldCollector c = TopFieldCollector.create(SORT, num, true, false, false);\n\n    // We sorted postings by weight during indexing, so we\n    // only retrieve the first num hits now:\n    final SortingMergePolicy sortingMergePolicy = (SortingMergePolicy) writer.getConfig().getMergePolicy();\n    Collector c2 = new EarlyTerminatingSortingCollector(c, SORT, num, sortingMergePolicy.getSort());\n    IndexSearcher searcher = searcherMgr.acquire();\n    List<LookupResult> results = null;\n    try {\n      //System.out.println(\"got searcher=\" + searcher);\n      searcher.search(finalQuery, c2);\n\n      TopFieldDocs hits = c.topDocs();\n\n      // Slower way if postings are not pre-sorted by weight:\n      // hits = searcher.search(query, null, num, SORT);\n      results = createResults(searcher, hits, num, key, doHighlight, matchedTokens, prefixToken);\n    } finally {\n      searcherMgr.release(searcher);\n    }\n\n    //System.out.println((System.currentTimeMillis() - t0) + \" msec for infix suggest\");\n    //System.out.println(results);\n\n    return results;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0ad30c6a479e764150a3316e57263319775f1df2","date":1463395403,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#lookup(CharSequence,BooleanQuery,int,boolean,boolean).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#lookup(CharSequence,BooleanQuery,int,boolean,boolean).mjava","sourceNew":"  /**\n   * This is an advanced method providing the capability to send down to the suggester any \n   * arbitrary lucene query to be used to filter the result of the suggester\n   * \n   * @param key the keyword being looked for\n   * @param contextQuery an arbitrary Lucene query to be used to filter the result of the suggester. {@link #addContextToQuery} could be used to build this contextQuery.\n   * @param num number of items to return\n   * @param allTermsRequired all searched terms must match or not\n   * @param doHighlight if true, the matching term will be highlighted in the search result\n   * @return the result of the suggester\n   * @throws IOException f the is IO exception while reading data from the index\n   */\n  public List<LookupResult> lookup(CharSequence key, BooleanQuery contextQuery, int num, boolean allTermsRequired, boolean doHighlight) throws IOException {\n\n    if (searcherMgr == null) {\n      throw new IllegalStateException(\"suggester was not built\");\n    }\n\n    final BooleanClause.Occur occur;\n    if (allTermsRequired) {\n      occur = BooleanClause.Occur.MUST;\n    } else {\n      occur = BooleanClause.Occur.SHOULD;\n    }\n\n    BooleanQuery.Builder query;\n    Set<String> matchedTokens;\n    String prefixToken = null;\n\n    try (TokenStream ts = queryAnalyzer.tokenStream(\"\", new StringReader(key.toString()))) {\n      //long t0 = System.currentTimeMillis();\n      ts.reset();\n      final CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      final OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      String lastToken = null;\n      query = new BooleanQuery.Builder();\n      int maxEndOffset = -1;\n      matchedTokens = new HashSet<>();\n      while (ts.incrementToken()) {\n        if (lastToken != null) {  \n          matchedTokens.add(lastToken);\n          query.add(new TermQuery(new Term(TEXT_FIELD_NAME, lastToken)), occur);\n        }\n        lastToken = termAtt.toString();\n        if (lastToken != null) {\n          maxEndOffset = Math.max(maxEndOffset, offsetAtt.endOffset());\n        }\n      }\n      ts.end();\n\n      if (lastToken != null) {\n        Query lastQuery;\n        if (maxEndOffset == offsetAtt.endOffset()) {\n          // Use PrefixQuery (or the ngram equivalent) when\n          // there was no trailing discarded chars in the\n          // string (e.g. whitespace), so that if query does\n          // not end with a space we show prefix matches for\n          // that token:\n          lastQuery = getLastTokenQuery(lastToken);\n          prefixToken = lastToken;\n        } else {\n          // Use TermQuery for an exact match if there were\n          // trailing discarded chars (e.g. whitespace), so\n          // that if query ends with a space we only show\n          // exact matches for that term:\n          matchedTokens.add(lastToken);\n          lastQuery = new TermQuery(new Term(TEXT_FIELD_NAME, lastToken));\n        }\n        \n        if (lastQuery != null) {\n          query.add(lastQuery, occur);\n        }\n      }\n\n      if (contextQuery != null) {\n        boolean allMustNot = true;\n        for (BooleanClause clause : contextQuery.clauses()) {\n          if (clause.getOccur() != BooleanClause.Occur.MUST_NOT) {\n            allMustNot = false;\n            break;\n          }\n        }\n        \n        if (allMustNot) {\n          //all are MUST_NOT: add the contextQuery to the main query instead (not as sub-query)\n          for (BooleanClause clause : contextQuery.clauses()) {\n            query.add(clause);\n          }\n        } else {\n          //Add contextQuery as sub-query\n          query.add(contextQuery, BooleanClause.Occur.MUST);\n        }\n      }\n    }\n    \n    // TODO: we could allow blended sort here, combining\n    // weight w/ score.  Now we ignore score and sort only\n    // by weight:\n\n    Query finalQuery = finishQuery(query, allTermsRequired);\n\n    //System.out.println(\"finalQuery=\" + query);\n\n    // Sort by weight, descending:\n    TopFieldCollector c = TopFieldCollector.create(SORT, num, true, false, false);\n\n    // We sorted postings by weight during indexing, so we\n    // only retrieve the first num hits now:\n    Collector c2 = new EarlyTerminatingSortingCollector(c, SORT, num);\n    List<LookupResult> results = null;\n    IndexSearcher searcher = searcherMgr.acquire();\n    try {\n      //System.out.println(\"got searcher=\" + searcher);\n      searcher.search(finalQuery, c2);\n\n      TopFieldDocs hits = c.topDocs();\n\n      // Slower way if postings are not pre-sorted by weight:\n      // hits = searcher.search(query, null, num, SORT);\n      results = createResults(searcher, hits, num, key, doHighlight, matchedTokens, prefixToken);\n    } finally {\n      searcherMgr.release(searcher);\n    }\n\n    //System.out.println((System.currentTimeMillis() - t0) + \" msec for infix suggest\");\n    //System.out.println(results);\n\n    return results;\n  }\n\n","sourceOld":"  /**\n   * This is an advanced method providing the capability to send down to the suggester any \n   * arbitrary lucene query to be used to filter the result of the suggester\n   * \n   * @param key the keyword being looked for\n   * @param contextQuery an arbitrary Lucene query to be used to filter the result of the suggester. {@link #addContextToQuery} could be used to build this contextQuery.\n   * @param num number of items to return\n   * @param allTermsRequired all searched terms must match or not\n   * @param doHighlight if true, the matching term will be highlighted in the search result\n   * @return the result of the suggester\n   * @throws IOException f the is IO exception while reading data from the index\n   */\n  public List<LookupResult> lookup(CharSequence key, BooleanQuery contextQuery, int num, boolean allTermsRequired, boolean doHighlight) throws IOException {\n\n    if (searcherMgr == null) {\n      throw new IllegalStateException(\"suggester was not built\");\n    }\n\n    final BooleanClause.Occur occur;\n    if (allTermsRequired) {\n      occur = BooleanClause.Occur.MUST;\n    } else {\n      occur = BooleanClause.Occur.SHOULD;\n    }\n\n    BooleanQuery.Builder query;\n    Set<String> matchedTokens;\n    String prefixToken = null;\n\n    try (TokenStream ts = queryAnalyzer.tokenStream(\"\", new StringReader(key.toString()))) {\n      //long t0 = System.currentTimeMillis();\n      ts.reset();\n      final CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      final OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      String lastToken = null;\n      query = new BooleanQuery.Builder();\n      int maxEndOffset = -1;\n      matchedTokens = new HashSet<>();\n      while (ts.incrementToken()) {\n        if (lastToken != null) {  \n          matchedTokens.add(lastToken);\n          query.add(new TermQuery(new Term(TEXT_FIELD_NAME, lastToken)), occur);\n        }\n        lastToken = termAtt.toString();\n        if (lastToken != null) {\n          maxEndOffset = Math.max(maxEndOffset, offsetAtt.endOffset());\n        }\n      }\n      ts.end();\n\n      if (lastToken != null) {\n        Query lastQuery;\n        if (maxEndOffset == offsetAtt.endOffset()) {\n          // Use PrefixQuery (or the ngram equivalent) when\n          // there was no trailing discarded chars in the\n          // string (e.g. whitespace), so that if query does\n          // not end with a space we show prefix matches for\n          // that token:\n          lastQuery = getLastTokenQuery(lastToken);\n          prefixToken = lastToken;\n        } else {\n          // Use TermQuery for an exact match if there were\n          // trailing discarded chars (e.g. whitespace), so\n          // that if query ends with a space we only show\n          // exact matches for that term:\n          matchedTokens.add(lastToken);\n          lastQuery = new TermQuery(new Term(TEXT_FIELD_NAME, lastToken));\n        }\n        \n        if (lastQuery != null) {\n          query.add(lastQuery, occur);\n        }\n      }\n\n      if (contextQuery != null) {\n        boolean allMustNot = true;\n        for (BooleanClause clause : contextQuery.clauses()) {\n          if (clause.getOccur() != BooleanClause.Occur.MUST_NOT) {\n            allMustNot = false;\n            break;\n          }\n        }\n        \n        if (allMustNot) {\n          //all are MUST_NOT: add the contextQuery to the main query instead (not as sub-query)\n          for (BooleanClause clause : contextQuery.clauses()) {\n            query.add(clause);\n          }\n        } else {\n          //Add contextQuery as sub-query\n          query.add(contextQuery, BooleanClause.Occur.MUST);\n        }\n      }\n    }\n    \n    // TODO: we could allow blended sort here, combining\n    // weight w/ score.  Now we ignore score and sort only\n    // by weight:\n\n    Query finalQuery = finishQuery(query, allTermsRequired);\n\n    //System.out.println(\"finalQuery=\" + query);\n\n    // Sort by weight, descending:\n    TopFieldCollector c = TopFieldCollector.create(SORT, num, true, false, false);\n\n    // We sorted postings by weight during indexing, so we\n    // only retrieve the first num hits now:\n    final SortingMergePolicy sortingMergePolicy = (SortingMergePolicy) writer.getConfig().getMergePolicy();\n    Collector c2 = new EarlyTerminatingSortingCollector(c, SORT, num, sortingMergePolicy.getSort());\n    IndexSearcher searcher = searcherMgr.acquire();\n    List<LookupResult> results = null;\n    try {\n      //System.out.println(\"got searcher=\" + searcher);\n      searcher.search(finalQuery, c2);\n\n      TopFieldDocs hits = c.topDocs();\n\n      // Slower way if postings are not pre-sorted by weight:\n      // hits = searcher.search(query, null, num, SORT);\n      results = createResults(searcher, hits, num, key, doHighlight, matchedTokens, prefixToken);\n    } finally {\n      searcherMgr.release(searcher);\n    }\n\n    //System.out.println((System.currentTimeMillis() - t0) + \" msec for infix suggest\");\n    //System.out.println(results);\n\n    return results;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d470c8182e92b264680e34081b75e70a9f2b3c89","date":1463985353,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#lookup(CharSequence,BooleanQuery,int,boolean,boolean).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#lookup(CharSequence,BooleanQuery,int,boolean,boolean).mjava","sourceNew":"  /**\n   * This is an advanced method providing the capability to send down to the suggester any \n   * arbitrary lucene query to be used to filter the result of the suggester\n   * \n   * @param key the keyword being looked for\n   * @param contextQuery an arbitrary Lucene query to be used to filter the result of the suggester. {@link #addContextToQuery} could be used to build this contextQuery.\n   * @param num number of items to return\n   * @param allTermsRequired all searched terms must match or not\n   * @param doHighlight if true, the matching term will be highlighted in the search result\n   * @return the result of the suggester\n   * @throws IOException f the is IO exception while reading data from the index\n   */\n  public List<LookupResult> lookup(CharSequence key, BooleanQuery contextQuery, int num, boolean allTermsRequired, boolean doHighlight) throws IOException {\n\n    if (searcherMgr == null) {\n      throw new IllegalStateException(\"suggester was not built\");\n    }\n\n    final BooleanClause.Occur occur;\n    if (allTermsRequired) {\n      occur = BooleanClause.Occur.MUST;\n    } else {\n      occur = BooleanClause.Occur.SHOULD;\n    }\n\n    BooleanQuery.Builder query;\n    Set<String> matchedTokens;\n    String prefixToken = null;\n\n    try (TokenStream ts = queryAnalyzer.tokenStream(\"\", new StringReader(key.toString()))) {\n      //long t0 = System.currentTimeMillis();\n      ts.reset();\n      final CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      final OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      String lastToken = null;\n      query = new BooleanQuery.Builder();\n      int maxEndOffset = -1;\n      matchedTokens = new HashSet<>();\n      while (ts.incrementToken()) {\n        if (lastToken != null) {  \n          matchedTokens.add(lastToken);\n          query.add(new TermQuery(new Term(TEXT_FIELD_NAME, lastToken)), occur);\n        }\n        lastToken = termAtt.toString();\n        if (lastToken != null) {\n          maxEndOffset = Math.max(maxEndOffset, offsetAtt.endOffset());\n        }\n      }\n      ts.end();\n\n      if (lastToken != null) {\n        Query lastQuery;\n        if (maxEndOffset == offsetAtt.endOffset()) {\n          // Use PrefixQuery (or the ngram equivalent) when\n          // there was no trailing discarded chars in the\n          // string (e.g. whitespace), so that if query does\n          // not end with a space we show prefix matches for\n          // that token:\n          lastQuery = getLastTokenQuery(lastToken);\n          prefixToken = lastToken;\n        } else {\n          // Use TermQuery for an exact match if there were\n          // trailing discarded chars (e.g. whitespace), so\n          // that if query ends with a space we only show\n          // exact matches for that term:\n          matchedTokens.add(lastToken);\n          lastQuery = new TermQuery(new Term(TEXT_FIELD_NAME, lastToken));\n        }\n        \n        if (lastQuery != null) {\n          query.add(lastQuery, occur);\n        }\n      }\n\n      if (contextQuery != null) {\n        boolean allMustNot = true;\n        for (BooleanClause clause : contextQuery.clauses()) {\n          if (clause.getOccur() != BooleanClause.Occur.MUST_NOT) {\n            allMustNot = false;\n            break;\n          }\n        }\n        \n        if (allMustNot) {\n          //all are MUST_NOT: add the contextQuery to the main query instead (not as sub-query)\n          for (BooleanClause clause : contextQuery.clauses()) {\n            query.add(clause);\n          }\n        } else {\n          //Add contextQuery as sub-query\n          query.add(contextQuery, BooleanClause.Occur.MUST);\n        }\n      }\n    }\n    \n    // TODO: we could allow blended sort here, combining\n    // weight w/ score.  Now we ignore score and sort only\n    // by weight:\n\n    Query finalQuery = finishQuery(query, allTermsRequired);\n\n    //System.out.println(\"finalQuery=\" + query);\n\n    // Sort by weight, descending:\n    TopFieldCollector c = TopFieldCollector.create(SORT, num, true, false, false);\n\n    // We sorted postings by weight during indexing, so we\n    // only retrieve the first num hits now:\n    Collector c2 = new EarlyTerminatingSortingCollector(c, SORT, num);\n    List<LookupResult> results = null;\n    IndexSearcher searcher = searcherMgr.acquire();\n    try {\n      //System.out.println(\"got searcher=\" + searcher);\n      searcher.search(finalQuery, c2);\n\n      TopFieldDocs hits = c.topDocs();\n\n      // Slower way if postings are not pre-sorted by weight:\n      // hits = searcher.search(query, null, num, SORT);\n      results = createResults(searcher, hits, num, key, doHighlight, matchedTokens, prefixToken);\n    } finally {\n      searcherMgr.release(searcher);\n    }\n\n    //System.out.println((System.currentTimeMillis() - t0) + \" msec for infix suggest\");\n    //System.out.println(results);\n\n    return results;\n  }\n\n","sourceOld":"  /**\n   * This is an advanced method providing the capability to send down to the suggester any \n   * arbitrary lucene query to be used to filter the result of the suggester\n   * \n   * @param key the keyword being looked for\n   * @param contextQuery an arbitrary Lucene query to be used to filter the result of the suggester. {@link #addContextToQuery} could be used to build this contextQuery.\n   * @param num number of items to return\n   * @param allTermsRequired all searched terms must match or not\n   * @param doHighlight if true, the matching term will be highlighted in the search result\n   * @return the result of the suggester\n   * @throws IOException f the is IO exception while reading data from the index\n   */\n  public List<LookupResult> lookup(CharSequence key, BooleanQuery contextQuery, int num, boolean allTermsRequired, boolean doHighlight) throws IOException {\n\n    if (searcherMgr == null) {\n      throw new IllegalStateException(\"suggester was not built\");\n    }\n\n    final BooleanClause.Occur occur;\n    if (allTermsRequired) {\n      occur = BooleanClause.Occur.MUST;\n    } else {\n      occur = BooleanClause.Occur.SHOULD;\n    }\n\n    BooleanQuery.Builder query;\n    Set<String> matchedTokens;\n    String prefixToken = null;\n\n    try (TokenStream ts = queryAnalyzer.tokenStream(\"\", new StringReader(key.toString()))) {\n      //long t0 = System.currentTimeMillis();\n      ts.reset();\n      final CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      final OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      String lastToken = null;\n      query = new BooleanQuery.Builder();\n      int maxEndOffset = -1;\n      matchedTokens = new HashSet<>();\n      while (ts.incrementToken()) {\n        if (lastToken != null) {  \n          matchedTokens.add(lastToken);\n          query.add(new TermQuery(new Term(TEXT_FIELD_NAME, lastToken)), occur);\n        }\n        lastToken = termAtt.toString();\n        if (lastToken != null) {\n          maxEndOffset = Math.max(maxEndOffset, offsetAtt.endOffset());\n        }\n      }\n      ts.end();\n\n      if (lastToken != null) {\n        Query lastQuery;\n        if (maxEndOffset == offsetAtt.endOffset()) {\n          // Use PrefixQuery (or the ngram equivalent) when\n          // there was no trailing discarded chars in the\n          // string (e.g. whitespace), so that if query does\n          // not end with a space we show prefix matches for\n          // that token:\n          lastQuery = getLastTokenQuery(lastToken);\n          prefixToken = lastToken;\n        } else {\n          // Use TermQuery for an exact match if there were\n          // trailing discarded chars (e.g. whitespace), so\n          // that if query ends with a space we only show\n          // exact matches for that term:\n          matchedTokens.add(lastToken);\n          lastQuery = new TermQuery(new Term(TEXT_FIELD_NAME, lastToken));\n        }\n        \n        if (lastQuery != null) {\n          query.add(lastQuery, occur);\n        }\n      }\n\n      if (contextQuery != null) {\n        boolean allMustNot = true;\n        for (BooleanClause clause : contextQuery.clauses()) {\n          if (clause.getOccur() != BooleanClause.Occur.MUST_NOT) {\n            allMustNot = false;\n            break;\n          }\n        }\n        \n        if (allMustNot) {\n          //all are MUST_NOT: add the contextQuery to the main query instead (not as sub-query)\n          for (BooleanClause clause : contextQuery.clauses()) {\n            query.add(clause);\n          }\n        } else {\n          //Add contextQuery as sub-query\n          query.add(contextQuery, BooleanClause.Occur.MUST);\n        }\n      }\n    }\n    \n    // TODO: we could allow blended sort here, combining\n    // weight w/ score.  Now we ignore score and sort only\n    // by weight:\n\n    Query finalQuery = finishQuery(query, allTermsRequired);\n\n    //System.out.println(\"finalQuery=\" + query);\n\n    // Sort by weight, descending:\n    TopFieldCollector c = TopFieldCollector.create(SORT, num, true, false, false);\n\n    // We sorted postings by weight during indexing, so we\n    // only retrieve the first num hits now:\n    final SortingMergePolicy sortingMergePolicy = (SortingMergePolicy) writer.getConfig().getMergePolicy();\n    Collector c2 = new EarlyTerminatingSortingCollector(c, SORT, num, sortingMergePolicy.getSort());\n    IndexSearcher searcher = searcherMgr.acquire();\n    List<LookupResult> results = null;\n    try {\n      //System.out.println(\"got searcher=\" + searcher);\n      searcher.search(finalQuery, c2);\n\n      TopFieldDocs hits = c.topDocs();\n\n      // Slower way if postings are not pre-sorted by weight:\n      // hits = searcher.search(query, null, num, SORT);\n      results = createResults(searcher, hits, num, key, doHighlight, matchedTokens, prefixToken);\n    } finally {\n      searcherMgr.release(searcher);\n    }\n\n    //System.out.println((System.currentTimeMillis() - t0) + \" msec for infix suggest\");\n    //System.out.println(results);\n\n    return results;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3ddd7fe363a03b018dd62c48017d9997657a111e","date":1476884674,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#lookup(CharSequence,BooleanQuery,int,boolean,boolean).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#lookup(CharSequence,BooleanQuery,int,boolean,boolean).mjava","sourceNew":"  /**\n   * This is an advanced method providing the capability to send down to the suggester any \n   * arbitrary lucene query to be used to filter the result of the suggester\n   * \n   * @param key the keyword being looked for\n   * @param contextQuery an arbitrary Lucene query to be used to filter the result of the suggester. {@link #addContextToQuery} could be used to build this contextQuery.\n   * @param num number of items to return\n   * @param allTermsRequired all searched terms must match or not\n   * @param doHighlight if true, the matching term will be highlighted in the search result\n   * @return the result of the suggester\n   * @throws IOException f the is IO exception while reading data from the index\n   */\n  public List<LookupResult> lookup(CharSequence key, BooleanQuery contextQuery, int num, boolean allTermsRequired, boolean doHighlight) throws IOException {\n\n    if (searcherMgr == null) {\n      throw new IllegalStateException(\"suggester was not built\");\n    }\n\n    final BooleanClause.Occur occur;\n    if (allTermsRequired) {\n      occur = BooleanClause.Occur.MUST;\n    } else {\n      occur = BooleanClause.Occur.SHOULD;\n    }\n\n    BooleanQuery.Builder query;\n    Set<String> matchedTokens;\n    String prefixToken = null;\n\n    try (TokenStream ts = queryAnalyzer.tokenStream(\"\", new StringReader(key.toString()))) {\n      //long t0 = System.currentTimeMillis();\n      ts.reset();\n      final CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      final OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      String lastToken = null;\n      query = new BooleanQuery.Builder();\n      int maxEndOffset = -1;\n      matchedTokens = new HashSet<>();\n      while (ts.incrementToken()) {\n        if (lastToken != null) {  \n          matchedTokens.add(lastToken);\n          query.add(new TermQuery(new Term(TEXT_FIELD_NAME, lastToken)), occur);\n        }\n        lastToken = termAtt.toString();\n        if (lastToken != null) {\n          maxEndOffset = Math.max(maxEndOffset, offsetAtt.endOffset());\n        }\n      }\n      ts.end();\n\n      if (lastToken != null) {\n        Query lastQuery;\n        if (maxEndOffset == offsetAtt.endOffset()) {\n          // Use PrefixQuery (or the ngram equivalent) when\n          // there was no trailing discarded chars in the\n          // string (e.g. whitespace), so that if query does\n          // not end with a space we show prefix matches for\n          // that token:\n          lastQuery = getLastTokenQuery(lastToken);\n          prefixToken = lastToken;\n        } else {\n          // Use TermQuery for an exact match if there were\n          // trailing discarded chars (e.g. whitespace), so\n          // that if query ends with a space we only show\n          // exact matches for that term:\n          matchedTokens.add(lastToken);\n          lastQuery = new TermQuery(new Term(TEXT_FIELD_NAME, lastToken));\n        }\n        \n        if (lastQuery != null) {\n          query.add(lastQuery, occur);\n        }\n      }\n\n      if (contextQuery != null) {\n        boolean allMustNot = true;\n        for (BooleanClause clause : contextQuery.clauses()) {\n          if (clause.getOccur() != BooleanClause.Occur.MUST_NOT) {\n            allMustNot = false;\n            break;\n          }\n        }\n        \n        if (allMustNot) {\n          // All are MUST_NOT: add the contextQuery to the main query instead (not as sub-query)\n          for (BooleanClause clause : contextQuery.clauses()) {\n            query.add(clause);\n          }\n        } else if (allTermsRequired == false) {\n          // We must carefully upgrade the query clauses to MUST:\n          BooleanQuery.Builder newQuery = new BooleanQuery.Builder();\n          newQuery.add(query.build(), BooleanClause.Occur.MUST);\n          newQuery.add(contextQuery, BooleanClause.Occur.MUST);\n          query = newQuery;\n        } else {\n          // Add contextQuery as sub-query\n          query.add(contextQuery, BooleanClause.Occur.MUST);\n        }\n      }\n    }\n    \n    // TODO: we could allow blended sort here, combining\n    // weight w/ score.  Now we ignore score and sort only\n    // by weight:\n\n    Query finalQuery = finishQuery(query, allTermsRequired);\n\n    //System.out.println(\"finalQuery=\" + finalQuery);\n\n    // Sort by weight, descending:\n    TopFieldCollector c = TopFieldCollector.create(SORT, num, true, false, false);\n\n    // We sorted postings by weight during indexing, so we\n    // only retrieve the first num hits now:\n    Collector c2 = new EarlyTerminatingSortingCollector(c, SORT, num);\n    List<LookupResult> results = null;\n    IndexSearcher searcher = searcherMgr.acquire();\n    try {\n      //System.out.println(\"got searcher=\" + searcher);\n      searcher.search(finalQuery, c2);\n\n      TopFieldDocs hits = c.topDocs();\n\n      // Slower way if postings are not pre-sorted by weight:\n      // hits = searcher.search(query, null, num, SORT);\n      results = createResults(searcher, hits, num, key, doHighlight, matchedTokens, prefixToken);\n    } finally {\n      searcherMgr.release(searcher);\n    }\n\n    //System.out.println((System.currentTimeMillis() - t0) + \" msec for infix suggest\");\n    //System.out.println(results);\n\n    return results;\n  }\n\n","sourceOld":"  /**\n   * This is an advanced method providing the capability to send down to the suggester any \n   * arbitrary lucene query to be used to filter the result of the suggester\n   * \n   * @param key the keyword being looked for\n   * @param contextQuery an arbitrary Lucene query to be used to filter the result of the suggester. {@link #addContextToQuery} could be used to build this contextQuery.\n   * @param num number of items to return\n   * @param allTermsRequired all searched terms must match or not\n   * @param doHighlight if true, the matching term will be highlighted in the search result\n   * @return the result of the suggester\n   * @throws IOException f the is IO exception while reading data from the index\n   */\n  public List<LookupResult> lookup(CharSequence key, BooleanQuery contextQuery, int num, boolean allTermsRequired, boolean doHighlight) throws IOException {\n\n    if (searcherMgr == null) {\n      throw new IllegalStateException(\"suggester was not built\");\n    }\n\n    final BooleanClause.Occur occur;\n    if (allTermsRequired) {\n      occur = BooleanClause.Occur.MUST;\n    } else {\n      occur = BooleanClause.Occur.SHOULD;\n    }\n\n    BooleanQuery.Builder query;\n    Set<String> matchedTokens;\n    String prefixToken = null;\n\n    try (TokenStream ts = queryAnalyzer.tokenStream(\"\", new StringReader(key.toString()))) {\n      //long t0 = System.currentTimeMillis();\n      ts.reset();\n      final CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      final OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      String lastToken = null;\n      query = new BooleanQuery.Builder();\n      int maxEndOffset = -1;\n      matchedTokens = new HashSet<>();\n      while (ts.incrementToken()) {\n        if (lastToken != null) {  \n          matchedTokens.add(lastToken);\n          query.add(new TermQuery(new Term(TEXT_FIELD_NAME, lastToken)), occur);\n        }\n        lastToken = termAtt.toString();\n        if (lastToken != null) {\n          maxEndOffset = Math.max(maxEndOffset, offsetAtt.endOffset());\n        }\n      }\n      ts.end();\n\n      if (lastToken != null) {\n        Query lastQuery;\n        if (maxEndOffset == offsetAtt.endOffset()) {\n          // Use PrefixQuery (or the ngram equivalent) when\n          // there was no trailing discarded chars in the\n          // string (e.g. whitespace), so that if query does\n          // not end with a space we show prefix matches for\n          // that token:\n          lastQuery = getLastTokenQuery(lastToken);\n          prefixToken = lastToken;\n        } else {\n          // Use TermQuery for an exact match if there were\n          // trailing discarded chars (e.g. whitespace), so\n          // that if query ends with a space we only show\n          // exact matches for that term:\n          matchedTokens.add(lastToken);\n          lastQuery = new TermQuery(new Term(TEXT_FIELD_NAME, lastToken));\n        }\n        \n        if (lastQuery != null) {\n          query.add(lastQuery, occur);\n        }\n      }\n\n      if (contextQuery != null) {\n        boolean allMustNot = true;\n        for (BooleanClause clause : contextQuery.clauses()) {\n          if (clause.getOccur() != BooleanClause.Occur.MUST_NOT) {\n            allMustNot = false;\n            break;\n          }\n        }\n        \n        if (allMustNot) {\n          //all are MUST_NOT: add the contextQuery to the main query instead (not as sub-query)\n          for (BooleanClause clause : contextQuery.clauses()) {\n            query.add(clause);\n          }\n        } else {\n          //Add contextQuery as sub-query\n          query.add(contextQuery, BooleanClause.Occur.MUST);\n        }\n      }\n    }\n    \n    // TODO: we could allow blended sort here, combining\n    // weight w/ score.  Now we ignore score and sort only\n    // by weight:\n\n    Query finalQuery = finishQuery(query, allTermsRequired);\n\n    //System.out.println(\"finalQuery=\" + query);\n\n    // Sort by weight, descending:\n    TopFieldCollector c = TopFieldCollector.create(SORT, num, true, false, false);\n\n    // We sorted postings by weight during indexing, so we\n    // only retrieve the first num hits now:\n    Collector c2 = new EarlyTerminatingSortingCollector(c, SORT, num);\n    List<LookupResult> results = null;\n    IndexSearcher searcher = searcherMgr.acquire();\n    try {\n      //System.out.println(\"got searcher=\" + searcher);\n      searcher.search(finalQuery, c2);\n\n      TopFieldDocs hits = c.topDocs();\n\n      // Slower way if postings are not pre-sorted by weight:\n      // hits = searcher.search(query, null, num, SORT);\n      results = createResults(searcher, hits, num, key, doHighlight, matchedTokens, prefixToken);\n    } finally {\n      searcherMgr.release(searcher);\n    }\n\n    //System.out.println((System.currentTimeMillis() - t0) + \" msec for infix suggest\");\n    //System.out.println(results);\n\n    return results;\n  }\n\n","bugFix":["d2204dea8cf3dcfbffdf7b4d3459cf5287cc1c30"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2305f39a86a068f1cee6fc5fbdfb760b153ac138","date":1476906991,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#lookup(CharSequence,BooleanQuery,int,boolean,boolean).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#lookup(CharSequence,BooleanQuery,int,boolean,boolean).mjava","sourceNew":"  /**\n   * This is an advanced method providing the capability to send down to the suggester any \n   * arbitrary lucene query to be used to filter the result of the suggester\n   * \n   * @param key the keyword being looked for\n   * @param contextQuery an arbitrary Lucene query to be used to filter the result of the suggester. {@link #addContextToQuery} could be used to build this contextQuery.\n   * @param num number of items to return\n   * @param allTermsRequired all searched terms must match or not\n   * @param doHighlight if true, the matching term will be highlighted in the search result\n   * @return the result of the suggester\n   * @throws IOException f the is IO exception while reading data from the index\n   */\n  public List<LookupResult> lookup(CharSequence key, BooleanQuery contextQuery, int num, boolean allTermsRequired, boolean doHighlight) throws IOException {\n\n    if (searcherMgr == null) {\n      throw new IllegalStateException(\"suggester was not built\");\n    }\n\n    final BooleanClause.Occur occur;\n    if (allTermsRequired) {\n      occur = BooleanClause.Occur.MUST;\n    } else {\n      occur = BooleanClause.Occur.SHOULD;\n    }\n\n    BooleanQuery.Builder query;\n    Set<String> matchedTokens;\n    String prefixToken = null;\n\n    try (TokenStream ts = queryAnalyzer.tokenStream(\"\", new StringReader(key.toString()))) {\n      //long t0 = System.currentTimeMillis();\n      ts.reset();\n      final CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      final OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      String lastToken = null;\n      query = new BooleanQuery.Builder();\n      int maxEndOffset = -1;\n      matchedTokens = new HashSet<>();\n      while (ts.incrementToken()) {\n        if (lastToken != null) {  \n          matchedTokens.add(lastToken);\n          query.add(new TermQuery(new Term(TEXT_FIELD_NAME, lastToken)), occur);\n        }\n        lastToken = termAtt.toString();\n        if (lastToken != null) {\n          maxEndOffset = Math.max(maxEndOffset, offsetAtt.endOffset());\n        }\n      }\n      ts.end();\n\n      if (lastToken != null) {\n        Query lastQuery;\n        if (maxEndOffset == offsetAtt.endOffset()) {\n          // Use PrefixQuery (or the ngram equivalent) when\n          // there was no trailing discarded chars in the\n          // string (e.g. whitespace), so that if query does\n          // not end with a space we show prefix matches for\n          // that token:\n          lastQuery = getLastTokenQuery(lastToken);\n          prefixToken = lastToken;\n        } else {\n          // Use TermQuery for an exact match if there were\n          // trailing discarded chars (e.g. whitespace), so\n          // that if query ends with a space we only show\n          // exact matches for that term:\n          matchedTokens.add(lastToken);\n          lastQuery = new TermQuery(new Term(TEXT_FIELD_NAME, lastToken));\n        }\n        \n        if (lastQuery != null) {\n          query.add(lastQuery, occur);\n        }\n      }\n\n      if (contextQuery != null) {\n        boolean allMustNot = true;\n        for (BooleanClause clause : contextQuery.clauses()) {\n          if (clause.getOccur() != BooleanClause.Occur.MUST_NOT) {\n            allMustNot = false;\n            break;\n          }\n        }\n        \n        if (allMustNot) {\n          // All are MUST_NOT: add the contextQuery to the main query instead (not as sub-query)\n          for (BooleanClause clause : contextQuery.clauses()) {\n            query.add(clause);\n          }\n        } else if (allTermsRequired == false) {\n          // We must carefully upgrade the query clauses to MUST:\n          BooleanQuery.Builder newQuery = new BooleanQuery.Builder();\n          newQuery.add(query.build(), BooleanClause.Occur.MUST);\n          newQuery.add(contextQuery, BooleanClause.Occur.MUST);\n          query = newQuery;\n        } else {\n          // Add contextQuery as sub-query\n          query.add(contextQuery, BooleanClause.Occur.MUST);\n        }\n      }\n    }\n    \n    // TODO: we could allow blended sort here, combining\n    // weight w/ score.  Now we ignore score and sort only\n    // by weight:\n\n    Query finalQuery = finishQuery(query, allTermsRequired);\n\n    //System.out.println(\"finalQuery=\" + finalQuery);\n\n    // Sort by weight, descending:\n    TopFieldCollector c = TopFieldCollector.create(SORT, num, true, false, false);\n\n    // We sorted postings by weight during indexing, so we\n    // only retrieve the first num hits now:\n    Collector c2 = new EarlyTerminatingSortingCollector(c, SORT, num);\n    List<LookupResult> results = null;\n    IndexSearcher searcher = searcherMgr.acquire();\n    try {\n      //System.out.println(\"got searcher=\" + searcher);\n      searcher.search(finalQuery, c2);\n\n      TopFieldDocs hits = c.topDocs();\n\n      // Slower way if postings are not pre-sorted by weight:\n      // hits = searcher.search(query, null, num, SORT);\n      results = createResults(searcher, hits, num, key, doHighlight, matchedTokens, prefixToken);\n    } finally {\n      searcherMgr.release(searcher);\n    }\n\n    //System.out.println((System.currentTimeMillis() - t0) + \" msec for infix suggest\");\n    //System.out.println(results);\n\n    return results;\n  }\n\n","sourceOld":"  /**\n   * This is an advanced method providing the capability to send down to the suggester any \n   * arbitrary lucene query to be used to filter the result of the suggester\n   * \n   * @param key the keyword being looked for\n   * @param contextQuery an arbitrary Lucene query to be used to filter the result of the suggester. {@link #addContextToQuery} could be used to build this contextQuery.\n   * @param num number of items to return\n   * @param allTermsRequired all searched terms must match or not\n   * @param doHighlight if true, the matching term will be highlighted in the search result\n   * @return the result of the suggester\n   * @throws IOException f the is IO exception while reading data from the index\n   */\n  public List<LookupResult> lookup(CharSequence key, BooleanQuery contextQuery, int num, boolean allTermsRequired, boolean doHighlight) throws IOException {\n\n    if (searcherMgr == null) {\n      throw new IllegalStateException(\"suggester was not built\");\n    }\n\n    final BooleanClause.Occur occur;\n    if (allTermsRequired) {\n      occur = BooleanClause.Occur.MUST;\n    } else {\n      occur = BooleanClause.Occur.SHOULD;\n    }\n\n    BooleanQuery.Builder query;\n    Set<String> matchedTokens;\n    String prefixToken = null;\n\n    try (TokenStream ts = queryAnalyzer.tokenStream(\"\", new StringReader(key.toString()))) {\n      //long t0 = System.currentTimeMillis();\n      ts.reset();\n      final CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      final OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      String lastToken = null;\n      query = new BooleanQuery.Builder();\n      int maxEndOffset = -1;\n      matchedTokens = new HashSet<>();\n      while (ts.incrementToken()) {\n        if (lastToken != null) {  \n          matchedTokens.add(lastToken);\n          query.add(new TermQuery(new Term(TEXT_FIELD_NAME, lastToken)), occur);\n        }\n        lastToken = termAtt.toString();\n        if (lastToken != null) {\n          maxEndOffset = Math.max(maxEndOffset, offsetAtt.endOffset());\n        }\n      }\n      ts.end();\n\n      if (lastToken != null) {\n        Query lastQuery;\n        if (maxEndOffset == offsetAtt.endOffset()) {\n          // Use PrefixQuery (or the ngram equivalent) when\n          // there was no trailing discarded chars in the\n          // string (e.g. whitespace), so that if query does\n          // not end with a space we show prefix matches for\n          // that token:\n          lastQuery = getLastTokenQuery(lastToken);\n          prefixToken = lastToken;\n        } else {\n          // Use TermQuery for an exact match if there were\n          // trailing discarded chars (e.g. whitespace), so\n          // that if query ends with a space we only show\n          // exact matches for that term:\n          matchedTokens.add(lastToken);\n          lastQuery = new TermQuery(new Term(TEXT_FIELD_NAME, lastToken));\n        }\n        \n        if (lastQuery != null) {\n          query.add(lastQuery, occur);\n        }\n      }\n\n      if (contextQuery != null) {\n        boolean allMustNot = true;\n        for (BooleanClause clause : contextQuery.clauses()) {\n          if (clause.getOccur() != BooleanClause.Occur.MUST_NOT) {\n            allMustNot = false;\n            break;\n          }\n        }\n        \n        if (allMustNot) {\n          //all are MUST_NOT: add the contextQuery to the main query instead (not as sub-query)\n          for (BooleanClause clause : contextQuery.clauses()) {\n            query.add(clause);\n          }\n        } else {\n          //Add contextQuery as sub-query\n          query.add(contextQuery, BooleanClause.Occur.MUST);\n        }\n      }\n    }\n    \n    // TODO: we could allow blended sort here, combining\n    // weight w/ score.  Now we ignore score and sort only\n    // by weight:\n\n    Query finalQuery = finishQuery(query, allTermsRequired);\n\n    //System.out.println(\"finalQuery=\" + query);\n\n    // Sort by weight, descending:\n    TopFieldCollector c = TopFieldCollector.create(SORT, num, true, false, false);\n\n    // We sorted postings by weight during indexing, so we\n    // only retrieve the first num hits now:\n    Collector c2 = new EarlyTerminatingSortingCollector(c, SORT, num);\n    List<LookupResult> results = null;\n    IndexSearcher searcher = searcherMgr.acquire();\n    try {\n      //System.out.println(\"got searcher=\" + searcher);\n      searcher.search(finalQuery, c2);\n\n      TopFieldDocs hits = c.topDocs();\n\n      // Slower way if postings are not pre-sorted by weight:\n      // hits = searcher.search(query, null, num, SORT);\n      results = createResults(searcher, hits, num, key, doHighlight, matchedTokens, prefixToken);\n    } finally {\n      searcherMgr.release(searcher);\n    }\n\n    //System.out.println((System.currentTimeMillis() - t0) + \" msec for infix suggest\");\n    //System.out.println(results);\n\n    return results;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#lookup(CharSequence,BooleanQuery,int,boolean,boolean).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#lookup(CharSequence,BooleanQuery,int,boolean,boolean).mjava","sourceNew":"  /**\n   * This is an advanced method providing the capability to send down to the suggester any \n   * arbitrary lucene query to be used to filter the result of the suggester\n   * \n   * @param key the keyword being looked for\n   * @param contextQuery an arbitrary Lucene query to be used to filter the result of the suggester. {@link #addContextToQuery} could be used to build this contextQuery.\n   * @param num number of items to return\n   * @param allTermsRequired all searched terms must match or not\n   * @param doHighlight if true, the matching term will be highlighted in the search result\n   * @return the result of the suggester\n   * @throws IOException f the is IO exception while reading data from the index\n   */\n  public List<LookupResult> lookup(CharSequence key, BooleanQuery contextQuery, int num, boolean allTermsRequired, boolean doHighlight) throws IOException {\n\n    if (searcherMgr == null) {\n      throw new IllegalStateException(\"suggester was not built\");\n    }\n\n    final BooleanClause.Occur occur;\n    if (allTermsRequired) {\n      occur = BooleanClause.Occur.MUST;\n    } else {\n      occur = BooleanClause.Occur.SHOULD;\n    }\n\n    BooleanQuery.Builder query;\n    Set<String> matchedTokens;\n    String prefixToken = null;\n\n    try (TokenStream ts = queryAnalyzer.tokenStream(\"\", new StringReader(key.toString()))) {\n      //long t0 = System.currentTimeMillis();\n      ts.reset();\n      final CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      final OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      String lastToken = null;\n      query = new BooleanQuery.Builder();\n      int maxEndOffset = -1;\n      matchedTokens = new HashSet<>();\n      while (ts.incrementToken()) {\n        if (lastToken != null) {  \n          matchedTokens.add(lastToken);\n          query.add(new TermQuery(new Term(TEXT_FIELD_NAME, lastToken)), occur);\n        }\n        lastToken = termAtt.toString();\n        if (lastToken != null) {\n          maxEndOffset = Math.max(maxEndOffset, offsetAtt.endOffset());\n        }\n      }\n      ts.end();\n\n      if (lastToken != null) {\n        Query lastQuery;\n        if (maxEndOffset == offsetAtt.endOffset()) {\n          // Use PrefixQuery (or the ngram equivalent) when\n          // there was no trailing discarded chars in the\n          // string (e.g. whitespace), so that if query does\n          // not end with a space we show prefix matches for\n          // that token:\n          lastQuery = getLastTokenQuery(lastToken);\n          prefixToken = lastToken;\n        } else {\n          // Use TermQuery for an exact match if there were\n          // trailing discarded chars (e.g. whitespace), so\n          // that if query ends with a space we only show\n          // exact matches for that term:\n          matchedTokens.add(lastToken);\n          lastQuery = new TermQuery(new Term(TEXT_FIELD_NAME, lastToken));\n        }\n        \n        if (lastQuery != null) {\n          query.add(lastQuery, occur);\n        }\n      }\n\n      if (contextQuery != null) {\n        boolean allMustNot = true;\n        for (BooleanClause clause : contextQuery.clauses()) {\n          if (clause.getOccur() != BooleanClause.Occur.MUST_NOT) {\n            allMustNot = false;\n            break;\n          }\n        }\n        \n        if (allMustNot) {\n          // All are MUST_NOT: add the contextQuery to the main query instead (not as sub-query)\n          for (BooleanClause clause : contextQuery.clauses()) {\n            query.add(clause);\n          }\n        } else if (allTermsRequired == false) {\n          // We must carefully upgrade the query clauses to MUST:\n          BooleanQuery.Builder newQuery = new BooleanQuery.Builder();\n          newQuery.add(query.build(), BooleanClause.Occur.MUST);\n          newQuery.add(contextQuery, BooleanClause.Occur.MUST);\n          query = newQuery;\n        } else {\n          // Add contextQuery as sub-query\n          query.add(contextQuery, BooleanClause.Occur.MUST);\n        }\n      }\n    }\n    \n    // TODO: we could allow blended sort here, combining\n    // weight w/ score.  Now we ignore score and sort only\n    // by weight:\n\n    Query finalQuery = finishQuery(query, allTermsRequired);\n\n    //System.out.println(\"finalQuery=\" + finalQuery);\n\n    // Sort by weight, descending:\n    TopFieldCollector c = TopFieldCollector.create(SORT, num, true, false, false);\n\n    // We sorted postings by weight during indexing, so we\n    // only retrieve the first num hits now:\n    Collector c2 = new EarlyTerminatingSortingCollector(c, SORT, num);\n    List<LookupResult> results = null;\n    IndexSearcher searcher = searcherMgr.acquire();\n    try {\n      //System.out.println(\"got searcher=\" + searcher);\n      searcher.search(finalQuery, c2);\n\n      TopFieldDocs hits = c.topDocs();\n\n      // Slower way if postings are not pre-sorted by weight:\n      // hits = searcher.search(query, null, num, SORT);\n      results = createResults(searcher, hits, num, key, doHighlight, matchedTokens, prefixToken);\n    } finally {\n      searcherMgr.release(searcher);\n    }\n\n    //System.out.println((System.currentTimeMillis() - t0) + \" msec for infix suggest\");\n    //System.out.println(results);\n\n    return results;\n  }\n\n","sourceOld":"  /**\n   * This is an advanced method providing the capability to send down to the suggester any \n   * arbitrary lucene query to be used to filter the result of the suggester\n   * \n   * @param key the keyword being looked for\n   * @param contextQuery an arbitrary Lucene query to be used to filter the result of the suggester. {@link #addContextToQuery} could be used to build this contextQuery.\n   * @param num number of items to return\n   * @param allTermsRequired all searched terms must match or not\n   * @param doHighlight if true, the matching term will be highlighted in the search result\n   * @return the result of the suggester\n   * @throws IOException f the is IO exception while reading data from the index\n   */\n  public List<LookupResult> lookup(CharSequence key, BooleanQuery contextQuery, int num, boolean allTermsRequired, boolean doHighlight) throws IOException {\n\n    if (searcherMgr == null) {\n      throw new IllegalStateException(\"suggester was not built\");\n    }\n\n    final BooleanClause.Occur occur;\n    if (allTermsRequired) {\n      occur = BooleanClause.Occur.MUST;\n    } else {\n      occur = BooleanClause.Occur.SHOULD;\n    }\n\n    BooleanQuery.Builder query;\n    Set<String> matchedTokens;\n    String prefixToken = null;\n\n    try (TokenStream ts = queryAnalyzer.tokenStream(\"\", new StringReader(key.toString()))) {\n      //long t0 = System.currentTimeMillis();\n      ts.reset();\n      final CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      final OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      String lastToken = null;\n      query = new BooleanQuery.Builder();\n      int maxEndOffset = -1;\n      matchedTokens = new HashSet<>();\n      while (ts.incrementToken()) {\n        if (lastToken != null) {  \n          matchedTokens.add(lastToken);\n          query.add(new TermQuery(new Term(TEXT_FIELD_NAME, lastToken)), occur);\n        }\n        lastToken = termAtt.toString();\n        if (lastToken != null) {\n          maxEndOffset = Math.max(maxEndOffset, offsetAtt.endOffset());\n        }\n      }\n      ts.end();\n\n      if (lastToken != null) {\n        Query lastQuery;\n        if (maxEndOffset == offsetAtt.endOffset()) {\n          // Use PrefixQuery (or the ngram equivalent) when\n          // there was no trailing discarded chars in the\n          // string (e.g. whitespace), so that if query does\n          // not end with a space we show prefix matches for\n          // that token:\n          lastQuery = getLastTokenQuery(lastToken);\n          prefixToken = lastToken;\n        } else {\n          // Use TermQuery for an exact match if there were\n          // trailing discarded chars (e.g. whitespace), so\n          // that if query ends with a space we only show\n          // exact matches for that term:\n          matchedTokens.add(lastToken);\n          lastQuery = new TermQuery(new Term(TEXT_FIELD_NAME, lastToken));\n        }\n        \n        if (lastQuery != null) {\n          query.add(lastQuery, occur);\n        }\n      }\n\n      if (contextQuery != null) {\n        boolean allMustNot = true;\n        for (BooleanClause clause : contextQuery.clauses()) {\n          if (clause.getOccur() != BooleanClause.Occur.MUST_NOT) {\n            allMustNot = false;\n            break;\n          }\n        }\n        \n        if (allMustNot) {\n          //all are MUST_NOT: add the contextQuery to the main query instead (not as sub-query)\n          for (BooleanClause clause : contextQuery.clauses()) {\n            query.add(clause);\n          }\n        } else {\n          //Add contextQuery as sub-query\n          query.add(contextQuery, BooleanClause.Occur.MUST);\n        }\n      }\n    }\n    \n    // TODO: we could allow blended sort here, combining\n    // weight w/ score.  Now we ignore score and sort only\n    // by weight:\n\n    Query finalQuery = finishQuery(query, allTermsRequired);\n\n    //System.out.println(\"finalQuery=\" + query);\n\n    // Sort by weight, descending:\n    TopFieldCollector c = TopFieldCollector.create(SORT, num, true, false, false);\n\n    // We sorted postings by weight during indexing, so we\n    // only retrieve the first num hits now:\n    final SortingMergePolicy sortingMergePolicy = (SortingMergePolicy) writer.getConfig().getMergePolicy();\n    Collector c2 = new EarlyTerminatingSortingCollector(c, SORT, num, sortingMergePolicy.getSort());\n    IndexSearcher searcher = searcherMgr.acquire();\n    List<LookupResult> results = null;\n    try {\n      //System.out.println(\"got searcher=\" + searcher);\n      searcher.search(finalQuery, c2);\n\n      TopFieldDocs hits = c.topDocs();\n\n      // Slower way if postings are not pre-sorted by weight:\n      // hits = searcher.search(query, null, num, SORT);\n      results = createResults(searcher, hits, num, key, doHighlight, matchedTokens, prefixToken);\n    } finally {\n      searcherMgr.release(searcher);\n    }\n\n    //System.out.println((System.currentTimeMillis() - t0) + \" msec for infix suggest\");\n    //System.out.println(results);\n\n    return results;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5cbf4928b28a4db03465b529b38a64ef29c91735","date":1483044697,"type":3,"author":"Steve Rowe","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#lookup(CharSequence,BooleanQuery,int,boolean,boolean).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#lookup(CharSequence,BooleanQuery,int,boolean,boolean).mjava","sourceNew":"  /**\n   * This is an advanced method providing the capability to send down to the suggester any \n   * arbitrary lucene query to be used to filter the result of the suggester\n   * \n   * @param key the keyword being looked for\n   * @param contextQuery an arbitrary Lucene query to be used to filter the result of the suggester. {@link #addContextToQuery} could be used to build this contextQuery.\n   * @param num number of items to return\n   * @param allTermsRequired all searched terms must match or not\n   * @param doHighlight if true, the matching term will be highlighted in the search result\n   * @return the result of the suggester\n   * @throws IOException f the is IO exception while reading data from the index\n   */\n  public List<LookupResult> lookup(CharSequence key, BooleanQuery contextQuery, int num, boolean allTermsRequired, boolean doHighlight) throws IOException {\n\n    if (searcherMgr == null) {\n      throw new IllegalStateException(\"suggester was not built\");\n    }\n\n    final BooleanClause.Occur occur;\n    if (allTermsRequired) {\n      occur = BooleanClause.Occur.MUST;\n    } else {\n      occur = BooleanClause.Occur.SHOULD;\n    }\n\n    BooleanQuery.Builder query;\n    Set<String> matchedTokens;\n    String prefixToken = null;\n\n    try (TokenStream ts = queryAnalyzer.tokenStream(\"\", new StringReader(key.toString()))) {\n      //long t0 = System.currentTimeMillis();\n      ts.reset();\n      final CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      final OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      String lastToken = null;\n      query = new BooleanQuery.Builder();\n      int maxEndOffset = -1;\n      matchedTokens = new HashSet<>();\n      while (ts.incrementToken()) {\n        if (lastToken != null) {  \n          matchedTokens.add(lastToken);\n          query.add(new TermQuery(new Term(TEXT_FIELD_NAME, lastToken)), occur);\n        }\n        lastToken = termAtt.toString();\n        if (lastToken != null) {\n          maxEndOffset = Math.max(maxEndOffset, offsetAtt.endOffset());\n        }\n      }\n      ts.end();\n\n      if (lastToken != null) {\n        Query lastQuery;\n        if (maxEndOffset == offsetAtt.endOffset()) {\n          // Use PrefixQuery (or the ngram equivalent) when\n          // there was no trailing discarded chars in the\n          // string (e.g. whitespace), so that if query does\n          // not end with a space we show prefix matches for\n          // that token:\n          lastQuery = getLastTokenQuery(lastToken);\n          prefixToken = lastToken;\n        } else {\n          // Use TermQuery for an exact match if there were\n          // trailing discarded chars (e.g. whitespace), so\n          // that if query ends with a space we only show\n          // exact matches for that term:\n          matchedTokens.add(lastToken);\n          lastQuery = new TermQuery(new Term(TEXT_FIELD_NAME, lastToken));\n        }\n        \n        if (lastQuery != null) {\n          query.add(lastQuery, occur);\n        }\n      }\n\n      if (contextQuery != null) {\n        boolean allMustNot = true;\n        for (BooleanClause clause : contextQuery.clauses()) {\n          if (clause.getOccur() != BooleanClause.Occur.MUST_NOT) {\n            allMustNot = false;\n            break;\n          }\n        }\n        \n        if (allMustNot) {\n          // All are MUST_NOT: add the contextQuery to the main query instead (not as sub-query)\n          for (BooleanClause clause : contextQuery.clauses()) {\n            query.add(clause);\n          }\n        } else if (allTermsRequired == false) {\n          // We must carefully upgrade the query clauses to MUST:\n          BooleanQuery.Builder newQuery = new BooleanQuery.Builder();\n          newQuery.add(query.build(), BooleanClause.Occur.MUST);\n          newQuery.add(contextQuery, BooleanClause.Occur.MUST);\n          query = newQuery;\n        } else {\n          // Add contextQuery as sub-query\n          query.add(contextQuery, BooleanClause.Occur.MUST);\n        }\n      }\n    }\n    \n    // TODO: we could allow blended sort here, combining\n    // weight w/ score.  Now we ignore score and sort only\n    // by weight:\n\n    Query finalQuery = finishQuery(query, allTermsRequired);\n\n    //System.out.println(\"finalQuery=\" + finalQuery);\n\n    // Sort by weight, descending:\n    TopFieldCollector c = TopFieldCollector.create(SORT, num, true, false, false);\n\n    // We sorted postings by weight during indexing, so we\n    // only retrieve the first num hits now:\n    Collector c2 = new EarlyTerminatingSortingCollector(c, SORT, num);\n    List<LookupResult> results = null;\n    SearcherManager mgr;\n    IndexSearcher searcher;\n    synchronized (searcherMgrLock) {\n      mgr = searcherMgr; // acquire & release on same SearcherManager, via local reference\n      searcher = mgr.acquire();\n    }\n    try {\n      //System.out.println(\"got searcher=\" + searcher);\n      searcher.search(finalQuery, c2);\n\n      TopFieldDocs hits = c.topDocs();\n\n      // Slower way if postings are not pre-sorted by weight:\n      // hits = searcher.search(query, null, num, SORT);\n      results = createResults(searcher, hits, num, key, doHighlight, matchedTokens, prefixToken);\n    } finally {\n      mgr.release(searcher);\n    }\n\n    //System.out.println((System.currentTimeMillis() - t0) + \" msec for infix suggest\");\n    //System.out.println(results);\n\n    return results;\n  }\n\n","sourceOld":"  /**\n   * This is an advanced method providing the capability to send down to the suggester any \n   * arbitrary lucene query to be used to filter the result of the suggester\n   * \n   * @param key the keyword being looked for\n   * @param contextQuery an arbitrary Lucene query to be used to filter the result of the suggester. {@link #addContextToQuery} could be used to build this contextQuery.\n   * @param num number of items to return\n   * @param allTermsRequired all searched terms must match or not\n   * @param doHighlight if true, the matching term will be highlighted in the search result\n   * @return the result of the suggester\n   * @throws IOException f the is IO exception while reading data from the index\n   */\n  public List<LookupResult> lookup(CharSequence key, BooleanQuery contextQuery, int num, boolean allTermsRequired, boolean doHighlight) throws IOException {\n\n    if (searcherMgr == null) {\n      throw new IllegalStateException(\"suggester was not built\");\n    }\n\n    final BooleanClause.Occur occur;\n    if (allTermsRequired) {\n      occur = BooleanClause.Occur.MUST;\n    } else {\n      occur = BooleanClause.Occur.SHOULD;\n    }\n\n    BooleanQuery.Builder query;\n    Set<String> matchedTokens;\n    String prefixToken = null;\n\n    try (TokenStream ts = queryAnalyzer.tokenStream(\"\", new StringReader(key.toString()))) {\n      //long t0 = System.currentTimeMillis();\n      ts.reset();\n      final CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      final OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      String lastToken = null;\n      query = new BooleanQuery.Builder();\n      int maxEndOffset = -1;\n      matchedTokens = new HashSet<>();\n      while (ts.incrementToken()) {\n        if (lastToken != null) {  \n          matchedTokens.add(lastToken);\n          query.add(new TermQuery(new Term(TEXT_FIELD_NAME, lastToken)), occur);\n        }\n        lastToken = termAtt.toString();\n        if (lastToken != null) {\n          maxEndOffset = Math.max(maxEndOffset, offsetAtt.endOffset());\n        }\n      }\n      ts.end();\n\n      if (lastToken != null) {\n        Query lastQuery;\n        if (maxEndOffset == offsetAtt.endOffset()) {\n          // Use PrefixQuery (or the ngram equivalent) when\n          // there was no trailing discarded chars in the\n          // string (e.g. whitespace), so that if query does\n          // not end with a space we show prefix matches for\n          // that token:\n          lastQuery = getLastTokenQuery(lastToken);\n          prefixToken = lastToken;\n        } else {\n          // Use TermQuery for an exact match if there were\n          // trailing discarded chars (e.g. whitespace), so\n          // that if query ends with a space we only show\n          // exact matches for that term:\n          matchedTokens.add(lastToken);\n          lastQuery = new TermQuery(new Term(TEXT_FIELD_NAME, lastToken));\n        }\n        \n        if (lastQuery != null) {\n          query.add(lastQuery, occur);\n        }\n      }\n\n      if (contextQuery != null) {\n        boolean allMustNot = true;\n        for (BooleanClause clause : contextQuery.clauses()) {\n          if (clause.getOccur() != BooleanClause.Occur.MUST_NOT) {\n            allMustNot = false;\n            break;\n          }\n        }\n        \n        if (allMustNot) {\n          // All are MUST_NOT: add the contextQuery to the main query instead (not as sub-query)\n          for (BooleanClause clause : contextQuery.clauses()) {\n            query.add(clause);\n          }\n        } else if (allTermsRequired == false) {\n          // We must carefully upgrade the query clauses to MUST:\n          BooleanQuery.Builder newQuery = new BooleanQuery.Builder();\n          newQuery.add(query.build(), BooleanClause.Occur.MUST);\n          newQuery.add(contextQuery, BooleanClause.Occur.MUST);\n          query = newQuery;\n        } else {\n          // Add contextQuery as sub-query\n          query.add(contextQuery, BooleanClause.Occur.MUST);\n        }\n      }\n    }\n    \n    // TODO: we could allow blended sort here, combining\n    // weight w/ score.  Now we ignore score and sort only\n    // by weight:\n\n    Query finalQuery = finishQuery(query, allTermsRequired);\n\n    //System.out.println(\"finalQuery=\" + finalQuery);\n\n    // Sort by weight, descending:\n    TopFieldCollector c = TopFieldCollector.create(SORT, num, true, false, false);\n\n    // We sorted postings by weight during indexing, so we\n    // only retrieve the first num hits now:\n    Collector c2 = new EarlyTerminatingSortingCollector(c, SORT, num);\n    List<LookupResult> results = null;\n    IndexSearcher searcher = searcherMgr.acquire();\n    try {\n      //System.out.println(\"got searcher=\" + searcher);\n      searcher.search(finalQuery, c2);\n\n      TopFieldDocs hits = c.topDocs();\n\n      // Slower way if postings are not pre-sorted by weight:\n      // hits = searcher.search(query, null, num, SORT);\n      results = createResults(searcher, hits, num, key, doHighlight, matchedTokens, prefixToken);\n    } finally {\n      searcherMgr.release(searcher);\n    }\n\n    //System.out.println((System.currentTimeMillis() - t0) + \" msec for infix suggest\");\n    //System.out.println(results);\n\n    return results;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"de0b5d8cac74be1676bcc2f805bc0d0630176659","date":1483048659,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#lookup(CharSequence,BooleanQuery,int,boolean,boolean).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#lookup(CharSequence,BooleanQuery,int,boolean,boolean).mjava","sourceNew":"  /**\n   * This is an advanced method providing the capability to send down to the suggester any \n   * arbitrary lucene query to be used to filter the result of the suggester\n   * \n   * @param key the keyword being looked for\n   * @param contextQuery an arbitrary Lucene query to be used to filter the result of the suggester. {@link #addContextToQuery} could be used to build this contextQuery.\n   * @param num number of items to return\n   * @param allTermsRequired all searched terms must match or not\n   * @param doHighlight if true, the matching term will be highlighted in the search result\n   * @return the result of the suggester\n   * @throws IOException f the is IO exception while reading data from the index\n   */\n  public List<LookupResult> lookup(CharSequence key, BooleanQuery contextQuery, int num, boolean allTermsRequired, boolean doHighlight) throws IOException {\n\n    if (searcherMgr == null) {\n      throw new IllegalStateException(\"suggester was not built\");\n    }\n\n    final BooleanClause.Occur occur;\n    if (allTermsRequired) {\n      occur = BooleanClause.Occur.MUST;\n    } else {\n      occur = BooleanClause.Occur.SHOULD;\n    }\n\n    BooleanQuery.Builder query;\n    Set<String> matchedTokens;\n    String prefixToken = null;\n\n    try (TokenStream ts = queryAnalyzer.tokenStream(\"\", new StringReader(key.toString()))) {\n      //long t0 = System.currentTimeMillis();\n      ts.reset();\n      final CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      final OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      String lastToken = null;\n      query = new BooleanQuery.Builder();\n      int maxEndOffset = -1;\n      matchedTokens = new HashSet<>();\n      while (ts.incrementToken()) {\n        if (lastToken != null) {  \n          matchedTokens.add(lastToken);\n          query.add(new TermQuery(new Term(TEXT_FIELD_NAME, lastToken)), occur);\n        }\n        lastToken = termAtt.toString();\n        if (lastToken != null) {\n          maxEndOffset = Math.max(maxEndOffset, offsetAtt.endOffset());\n        }\n      }\n      ts.end();\n\n      if (lastToken != null) {\n        Query lastQuery;\n        if (maxEndOffset == offsetAtt.endOffset()) {\n          // Use PrefixQuery (or the ngram equivalent) when\n          // there was no trailing discarded chars in the\n          // string (e.g. whitespace), so that if query does\n          // not end with a space we show prefix matches for\n          // that token:\n          lastQuery = getLastTokenQuery(lastToken);\n          prefixToken = lastToken;\n        } else {\n          // Use TermQuery for an exact match if there were\n          // trailing discarded chars (e.g. whitespace), so\n          // that if query ends with a space we only show\n          // exact matches for that term:\n          matchedTokens.add(lastToken);\n          lastQuery = new TermQuery(new Term(TEXT_FIELD_NAME, lastToken));\n        }\n        \n        if (lastQuery != null) {\n          query.add(lastQuery, occur);\n        }\n      }\n\n      if (contextQuery != null) {\n        boolean allMustNot = true;\n        for (BooleanClause clause : contextQuery.clauses()) {\n          if (clause.getOccur() != BooleanClause.Occur.MUST_NOT) {\n            allMustNot = false;\n            break;\n          }\n        }\n        \n        if (allMustNot) {\n          // All are MUST_NOT: add the contextQuery to the main query instead (not as sub-query)\n          for (BooleanClause clause : contextQuery.clauses()) {\n            query.add(clause);\n          }\n        } else if (allTermsRequired == false) {\n          // We must carefully upgrade the query clauses to MUST:\n          BooleanQuery.Builder newQuery = new BooleanQuery.Builder();\n          newQuery.add(query.build(), BooleanClause.Occur.MUST);\n          newQuery.add(contextQuery, BooleanClause.Occur.MUST);\n          query = newQuery;\n        } else {\n          // Add contextQuery as sub-query\n          query.add(contextQuery, BooleanClause.Occur.MUST);\n        }\n      }\n    }\n    \n    // TODO: we could allow blended sort here, combining\n    // weight w/ score.  Now we ignore score and sort only\n    // by weight:\n\n    Query finalQuery = finishQuery(query, allTermsRequired);\n\n    //System.out.println(\"finalQuery=\" + finalQuery);\n\n    // Sort by weight, descending:\n    TopFieldCollector c = TopFieldCollector.create(SORT, num, true, false, false);\n\n    // We sorted postings by weight during indexing, so we\n    // only retrieve the first num hits now:\n    Collector c2 = new EarlyTerminatingSortingCollector(c, SORT, num);\n    List<LookupResult> results = null;\n    SearcherManager mgr;\n    IndexSearcher searcher;\n    synchronized (searcherMgrLock) {\n      mgr = searcherMgr; // acquire & release on same SearcherManager, via local reference\n      searcher = mgr.acquire();\n    }\n    try {\n      //System.out.println(\"got searcher=\" + searcher);\n      searcher.search(finalQuery, c2);\n\n      TopFieldDocs hits = c.topDocs();\n\n      // Slower way if postings are not pre-sorted by weight:\n      // hits = searcher.search(query, null, num, SORT);\n      results = createResults(searcher, hits, num, key, doHighlight, matchedTokens, prefixToken);\n    } finally {\n      mgr.release(searcher);\n    }\n\n    //System.out.println((System.currentTimeMillis() - t0) + \" msec for infix suggest\");\n    //System.out.println(results);\n\n    return results;\n  }\n\n","sourceOld":"  /**\n   * This is an advanced method providing the capability to send down to the suggester any \n   * arbitrary lucene query to be used to filter the result of the suggester\n   * \n   * @param key the keyword being looked for\n   * @param contextQuery an arbitrary Lucene query to be used to filter the result of the suggester. {@link #addContextToQuery} could be used to build this contextQuery.\n   * @param num number of items to return\n   * @param allTermsRequired all searched terms must match or not\n   * @param doHighlight if true, the matching term will be highlighted in the search result\n   * @return the result of the suggester\n   * @throws IOException f the is IO exception while reading data from the index\n   */\n  public List<LookupResult> lookup(CharSequence key, BooleanQuery contextQuery, int num, boolean allTermsRequired, boolean doHighlight) throws IOException {\n\n    if (searcherMgr == null) {\n      throw new IllegalStateException(\"suggester was not built\");\n    }\n\n    final BooleanClause.Occur occur;\n    if (allTermsRequired) {\n      occur = BooleanClause.Occur.MUST;\n    } else {\n      occur = BooleanClause.Occur.SHOULD;\n    }\n\n    BooleanQuery.Builder query;\n    Set<String> matchedTokens;\n    String prefixToken = null;\n\n    try (TokenStream ts = queryAnalyzer.tokenStream(\"\", new StringReader(key.toString()))) {\n      //long t0 = System.currentTimeMillis();\n      ts.reset();\n      final CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      final OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      String lastToken = null;\n      query = new BooleanQuery.Builder();\n      int maxEndOffset = -1;\n      matchedTokens = new HashSet<>();\n      while (ts.incrementToken()) {\n        if (lastToken != null) {  \n          matchedTokens.add(lastToken);\n          query.add(new TermQuery(new Term(TEXT_FIELD_NAME, lastToken)), occur);\n        }\n        lastToken = termAtt.toString();\n        if (lastToken != null) {\n          maxEndOffset = Math.max(maxEndOffset, offsetAtt.endOffset());\n        }\n      }\n      ts.end();\n\n      if (lastToken != null) {\n        Query lastQuery;\n        if (maxEndOffset == offsetAtt.endOffset()) {\n          // Use PrefixQuery (or the ngram equivalent) when\n          // there was no trailing discarded chars in the\n          // string (e.g. whitespace), so that if query does\n          // not end with a space we show prefix matches for\n          // that token:\n          lastQuery = getLastTokenQuery(lastToken);\n          prefixToken = lastToken;\n        } else {\n          // Use TermQuery for an exact match if there were\n          // trailing discarded chars (e.g. whitespace), so\n          // that if query ends with a space we only show\n          // exact matches for that term:\n          matchedTokens.add(lastToken);\n          lastQuery = new TermQuery(new Term(TEXT_FIELD_NAME, lastToken));\n        }\n        \n        if (lastQuery != null) {\n          query.add(lastQuery, occur);\n        }\n      }\n\n      if (contextQuery != null) {\n        boolean allMustNot = true;\n        for (BooleanClause clause : contextQuery.clauses()) {\n          if (clause.getOccur() != BooleanClause.Occur.MUST_NOT) {\n            allMustNot = false;\n            break;\n          }\n        }\n        \n        if (allMustNot) {\n          // All are MUST_NOT: add the contextQuery to the main query instead (not as sub-query)\n          for (BooleanClause clause : contextQuery.clauses()) {\n            query.add(clause);\n          }\n        } else if (allTermsRequired == false) {\n          // We must carefully upgrade the query clauses to MUST:\n          BooleanQuery.Builder newQuery = new BooleanQuery.Builder();\n          newQuery.add(query.build(), BooleanClause.Occur.MUST);\n          newQuery.add(contextQuery, BooleanClause.Occur.MUST);\n          query = newQuery;\n        } else {\n          // Add contextQuery as sub-query\n          query.add(contextQuery, BooleanClause.Occur.MUST);\n        }\n      }\n    }\n    \n    // TODO: we could allow blended sort here, combining\n    // weight w/ score.  Now we ignore score and sort only\n    // by weight:\n\n    Query finalQuery = finishQuery(query, allTermsRequired);\n\n    //System.out.println(\"finalQuery=\" + finalQuery);\n\n    // Sort by weight, descending:\n    TopFieldCollector c = TopFieldCollector.create(SORT, num, true, false, false);\n\n    // We sorted postings by weight during indexing, so we\n    // only retrieve the first num hits now:\n    Collector c2 = new EarlyTerminatingSortingCollector(c, SORT, num);\n    List<LookupResult> results = null;\n    IndexSearcher searcher = searcherMgr.acquire();\n    try {\n      //System.out.println(\"got searcher=\" + searcher);\n      searcher.search(finalQuery, c2);\n\n      TopFieldDocs hits = c.topDocs();\n\n      // Slower way if postings are not pre-sorted by weight:\n      // hits = searcher.search(query, null, num, SORT);\n      results = createResults(searcher, hits, num, key, doHighlight, matchedTokens, prefixToken);\n    } finally {\n      searcherMgr.release(searcher);\n    }\n\n    //System.out.println((System.currentTimeMillis() - t0) + \" msec for infix suggest\");\n    //System.out.println(results);\n\n    return results;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f03e4bed5023ec3ef93a771b8888cae991cf448d","date":1483469262,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#lookup(CharSequence,BooleanQuery,int,boolean,boolean).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#lookup(CharSequence,BooleanQuery,int,boolean,boolean).mjava","sourceNew":"  /**\n   * This is an advanced method providing the capability to send down to the suggester any \n   * arbitrary lucene query to be used to filter the result of the suggester\n   * \n   * @param key the keyword being looked for\n   * @param contextQuery an arbitrary Lucene query to be used to filter the result of the suggester. {@link #addContextToQuery} could be used to build this contextQuery.\n   * @param num number of items to return\n   * @param allTermsRequired all searched terms must match or not\n   * @param doHighlight if true, the matching term will be highlighted in the search result\n   * @return the result of the suggester\n   * @throws IOException f the is IO exception while reading data from the index\n   */\n  public List<LookupResult> lookup(CharSequence key, BooleanQuery contextQuery, int num, boolean allTermsRequired, boolean doHighlight) throws IOException {\n\n    if (searcherMgr == null) {\n      throw new IllegalStateException(\"suggester was not built\");\n    }\n\n    final BooleanClause.Occur occur;\n    if (allTermsRequired) {\n      occur = BooleanClause.Occur.MUST;\n    } else {\n      occur = BooleanClause.Occur.SHOULD;\n    }\n\n    BooleanQuery.Builder query;\n    Set<String> matchedTokens;\n    String prefixToken = null;\n\n    try (TokenStream ts = queryAnalyzer.tokenStream(\"\", new StringReader(key.toString()))) {\n      //long t0 = System.currentTimeMillis();\n      ts.reset();\n      final CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      final OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      String lastToken = null;\n      query = new BooleanQuery.Builder();\n      int maxEndOffset = -1;\n      matchedTokens = new HashSet<>();\n      while (ts.incrementToken()) {\n        if (lastToken != null) {  \n          matchedTokens.add(lastToken);\n          query.add(new TermQuery(new Term(TEXT_FIELD_NAME, lastToken)), occur);\n        }\n        lastToken = termAtt.toString();\n        if (lastToken != null) {\n          maxEndOffset = Math.max(maxEndOffset, offsetAtt.endOffset());\n        }\n      }\n      ts.end();\n\n      if (lastToken != null) {\n        Query lastQuery;\n        if (maxEndOffset == offsetAtt.endOffset()) {\n          // Use PrefixQuery (or the ngram equivalent) when\n          // there was no trailing discarded chars in the\n          // string (e.g. whitespace), so that if query does\n          // not end with a space we show prefix matches for\n          // that token:\n          lastQuery = getLastTokenQuery(lastToken);\n          prefixToken = lastToken;\n        } else {\n          // Use TermQuery for an exact match if there were\n          // trailing discarded chars (e.g. whitespace), so\n          // that if query ends with a space we only show\n          // exact matches for that term:\n          matchedTokens.add(lastToken);\n          lastQuery = new TermQuery(new Term(TEXT_FIELD_NAME, lastToken));\n        }\n        \n        if (lastQuery != null) {\n          query.add(lastQuery, occur);\n        }\n      }\n\n      if (contextQuery != null) {\n        boolean allMustNot = true;\n        for (BooleanClause clause : contextQuery.clauses()) {\n          if (clause.getOccur() != BooleanClause.Occur.MUST_NOT) {\n            allMustNot = false;\n            break;\n          }\n        }\n        \n        if (allMustNot) {\n          // All are MUST_NOT: add the contextQuery to the main query instead (not as sub-query)\n          for (BooleanClause clause : contextQuery.clauses()) {\n            query.add(clause);\n          }\n        } else if (allTermsRequired == false) {\n          // We must carefully upgrade the query clauses to MUST:\n          BooleanQuery.Builder newQuery = new BooleanQuery.Builder();\n          newQuery.add(query.build(), BooleanClause.Occur.MUST);\n          newQuery.add(contextQuery, BooleanClause.Occur.MUST);\n          query = newQuery;\n        } else {\n          // Add contextQuery as sub-query\n          query.add(contextQuery, BooleanClause.Occur.MUST);\n        }\n      }\n    }\n    \n    // TODO: we could allow blended sort here, combining\n    // weight w/ score.  Now we ignore score and sort only\n    // by weight:\n\n    Query finalQuery = finishQuery(query, allTermsRequired);\n\n    //System.out.println(\"finalQuery=\" + finalQuery);\n\n    // Sort by weight, descending:\n    TopFieldCollector c = TopFieldCollector.create(SORT, num, true, false, false);\n\n    // We sorted postings by weight during indexing, so we\n    // only retrieve the first num hits now:\n    Collector c2 = new EarlyTerminatingSortingCollector(c, SORT, num);\n    List<LookupResult> results = null;\n    SearcherManager mgr;\n    IndexSearcher searcher;\n    synchronized (searcherMgrLock) {\n      mgr = searcherMgr; // acquire & release on same SearcherManager, via local reference\n      searcher = mgr.acquire();\n    }\n    try {\n      //System.out.println(\"got searcher=\" + searcher);\n      searcher.search(finalQuery, c2);\n\n      TopFieldDocs hits = c.topDocs();\n\n      // Slower way if postings are not pre-sorted by weight:\n      // hits = searcher.search(query, null, num, SORT);\n      results = createResults(searcher, hits, num, key, doHighlight, matchedTokens, prefixToken);\n    } finally {\n      mgr.release(searcher);\n    }\n\n    //System.out.println((System.currentTimeMillis() - t0) + \" msec for infix suggest\");\n    //System.out.println(results);\n\n    return results;\n  }\n\n","sourceOld":"  /**\n   * This is an advanced method providing the capability to send down to the suggester any \n   * arbitrary lucene query to be used to filter the result of the suggester\n   * \n   * @param key the keyword being looked for\n   * @param contextQuery an arbitrary Lucene query to be used to filter the result of the suggester. {@link #addContextToQuery} could be used to build this contextQuery.\n   * @param num number of items to return\n   * @param allTermsRequired all searched terms must match or not\n   * @param doHighlight if true, the matching term will be highlighted in the search result\n   * @return the result of the suggester\n   * @throws IOException f the is IO exception while reading data from the index\n   */\n  public List<LookupResult> lookup(CharSequence key, BooleanQuery contextQuery, int num, boolean allTermsRequired, boolean doHighlight) throws IOException {\n\n    if (searcherMgr == null) {\n      throw new IllegalStateException(\"suggester was not built\");\n    }\n\n    final BooleanClause.Occur occur;\n    if (allTermsRequired) {\n      occur = BooleanClause.Occur.MUST;\n    } else {\n      occur = BooleanClause.Occur.SHOULD;\n    }\n\n    BooleanQuery.Builder query;\n    Set<String> matchedTokens;\n    String prefixToken = null;\n\n    try (TokenStream ts = queryAnalyzer.tokenStream(\"\", new StringReader(key.toString()))) {\n      //long t0 = System.currentTimeMillis();\n      ts.reset();\n      final CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      final OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      String lastToken = null;\n      query = new BooleanQuery.Builder();\n      int maxEndOffset = -1;\n      matchedTokens = new HashSet<>();\n      while (ts.incrementToken()) {\n        if (lastToken != null) {  \n          matchedTokens.add(lastToken);\n          query.add(new TermQuery(new Term(TEXT_FIELD_NAME, lastToken)), occur);\n        }\n        lastToken = termAtt.toString();\n        if (lastToken != null) {\n          maxEndOffset = Math.max(maxEndOffset, offsetAtt.endOffset());\n        }\n      }\n      ts.end();\n\n      if (lastToken != null) {\n        Query lastQuery;\n        if (maxEndOffset == offsetAtt.endOffset()) {\n          // Use PrefixQuery (or the ngram equivalent) when\n          // there was no trailing discarded chars in the\n          // string (e.g. whitespace), so that if query does\n          // not end with a space we show prefix matches for\n          // that token:\n          lastQuery = getLastTokenQuery(lastToken);\n          prefixToken = lastToken;\n        } else {\n          // Use TermQuery for an exact match if there were\n          // trailing discarded chars (e.g. whitespace), so\n          // that if query ends with a space we only show\n          // exact matches for that term:\n          matchedTokens.add(lastToken);\n          lastQuery = new TermQuery(new Term(TEXT_FIELD_NAME, lastToken));\n        }\n        \n        if (lastQuery != null) {\n          query.add(lastQuery, occur);\n        }\n      }\n\n      if (contextQuery != null) {\n        boolean allMustNot = true;\n        for (BooleanClause clause : contextQuery.clauses()) {\n          if (clause.getOccur() != BooleanClause.Occur.MUST_NOT) {\n            allMustNot = false;\n            break;\n          }\n        }\n        \n        if (allMustNot) {\n          // All are MUST_NOT: add the contextQuery to the main query instead (not as sub-query)\n          for (BooleanClause clause : contextQuery.clauses()) {\n            query.add(clause);\n          }\n        } else if (allTermsRequired == false) {\n          // We must carefully upgrade the query clauses to MUST:\n          BooleanQuery.Builder newQuery = new BooleanQuery.Builder();\n          newQuery.add(query.build(), BooleanClause.Occur.MUST);\n          newQuery.add(contextQuery, BooleanClause.Occur.MUST);\n          query = newQuery;\n        } else {\n          // Add contextQuery as sub-query\n          query.add(contextQuery, BooleanClause.Occur.MUST);\n        }\n      }\n    }\n    \n    // TODO: we could allow blended sort here, combining\n    // weight w/ score.  Now we ignore score and sort only\n    // by weight:\n\n    Query finalQuery = finishQuery(query, allTermsRequired);\n\n    //System.out.println(\"finalQuery=\" + finalQuery);\n\n    // Sort by weight, descending:\n    TopFieldCollector c = TopFieldCollector.create(SORT, num, true, false, false);\n\n    // We sorted postings by weight during indexing, so we\n    // only retrieve the first num hits now:\n    Collector c2 = new EarlyTerminatingSortingCollector(c, SORT, num);\n    List<LookupResult> results = null;\n    IndexSearcher searcher = searcherMgr.acquire();\n    try {\n      //System.out.println(\"got searcher=\" + searcher);\n      searcher.search(finalQuery, c2);\n\n      TopFieldDocs hits = c.topDocs();\n\n      // Slower way if postings are not pre-sorted by weight:\n      // hits = searcher.search(query, null, num, SORT);\n      results = createResults(searcher, hits, num, key, doHighlight, matchedTokens, prefixToken);\n    } finally {\n      searcherMgr.release(searcher);\n    }\n\n    //System.out.println((System.currentTimeMillis() - t0) + \" msec for infix suggest\");\n    //System.out.println(results);\n\n    return results;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"404d1ab7f6f396235047017c88d545fec15dafb7","date":1511975378,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#lookup(CharSequence,BooleanQuery,int,boolean,boolean).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#lookup(CharSequence,BooleanQuery,int,boolean,boolean).mjava","sourceNew":"  /**\n   * This is an advanced method providing the capability to send down to the suggester any \n   * arbitrary lucene query to be used to filter the result of the suggester\n   * \n   * @param key the keyword being looked for\n   * @param contextQuery an arbitrary Lucene query to be used to filter the result of the suggester. {@link #addContextToQuery} could be used to build this contextQuery.\n   * @param num number of items to return\n   * @param allTermsRequired all searched terms must match or not\n   * @param doHighlight if true, the matching term will be highlighted in the search result\n   * @return the result of the suggester\n   * @throws IOException f the is IO exception while reading data from the index\n   */\n  public List<LookupResult> lookup(CharSequence key, BooleanQuery contextQuery, int num, boolean allTermsRequired, boolean doHighlight) throws IOException {\n\n    if (searcherMgr == null) {\n      throw new IllegalStateException(\"suggester was not built\");\n    }\n\n    final BooleanClause.Occur occur;\n    if (allTermsRequired) {\n      occur = BooleanClause.Occur.MUST;\n    } else {\n      occur = BooleanClause.Occur.SHOULD;\n    }\n\n    BooleanQuery.Builder query;\n    Set<String> matchedTokens;\n    String prefixToken = null;\n\n    try (TokenStream ts = queryAnalyzer.tokenStream(\"\", new StringReader(key.toString()))) {\n      //long t0 = System.currentTimeMillis();\n      ts.reset();\n      final CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      final OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      String lastToken = null;\n      query = new BooleanQuery.Builder();\n      int maxEndOffset = -1;\n      matchedTokens = new HashSet<>();\n      while (ts.incrementToken()) {\n        if (lastToken != null) {  \n          matchedTokens.add(lastToken);\n          query.add(new TermQuery(new Term(TEXT_FIELD_NAME, lastToken)), occur);\n        }\n        lastToken = termAtt.toString();\n        if (lastToken != null) {\n          maxEndOffset = Math.max(maxEndOffset, offsetAtt.endOffset());\n        }\n      }\n      ts.end();\n\n      if (lastToken != null) {\n        Query lastQuery;\n        if (maxEndOffset == offsetAtt.endOffset()) {\n          // Use PrefixQuery (or the ngram equivalent) when\n          // there was no trailing discarded chars in the\n          // string (e.g. whitespace), so that if query does\n          // not end with a space we show prefix matches for\n          // that token:\n          lastQuery = getLastTokenQuery(lastToken);\n          prefixToken = lastToken;\n        } else {\n          // Use TermQuery for an exact match if there were\n          // trailing discarded chars (e.g. whitespace), so\n          // that if query ends with a space we only show\n          // exact matches for that term:\n          matchedTokens.add(lastToken);\n          lastQuery = new TermQuery(new Term(TEXT_FIELD_NAME, lastToken));\n        }\n        \n        if (lastQuery != null) {\n          query.add(lastQuery, occur);\n        }\n      }\n\n      if (contextQuery != null) {\n        boolean allMustNot = true;\n        for (BooleanClause clause : contextQuery.clauses()) {\n          if (clause.getOccur() != BooleanClause.Occur.MUST_NOT) {\n            allMustNot = false;\n            break;\n          }\n        }\n        \n        if (allMustNot) {\n          // All are MUST_NOT: add the contextQuery to the main query instead (not as sub-query)\n          for (BooleanClause clause : contextQuery.clauses()) {\n            query.add(clause);\n          }\n        } else if (allTermsRequired == false) {\n          // We must carefully upgrade the query clauses to MUST:\n          BooleanQuery.Builder newQuery = new BooleanQuery.Builder();\n          newQuery.add(query.build(), BooleanClause.Occur.MUST);\n          newQuery.add(contextQuery, BooleanClause.Occur.MUST);\n          query = newQuery;\n        } else {\n          // Add contextQuery as sub-query\n          query.add(contextQuery, BooleanClause.Occur.MUST);\n        }\n      }\n    }\n    \n    // TODO: we could allow blended sort here, combining\n    // weight w/ score.  Now we ignore score and sort only\n    // by weight:\n\n    Query finalQuery = finishQuery(query, allTermsRequired);\n\n    //System.out.println(\"finalQuery=\" + finalQuery);\n\n    // Sort by weight, descending:\n    TopFieldCollector c = TopFieldCollector.create(SORT, num, true, false, false, false);\n    List<LookupResult> results = null;\n    SearcherManager mgr;\n    IndexSearcher searcher;\n    synchronized (searcherMgrLock) {\n      mgr = searcherMgr; // acquire & release on same SearcherManager, via local reference\n      searcher = mgr.acquire();\n    }\n    try {\n      //System.out.println(\"got searcher=\" + searcher);\n      searcher.search(finalQuery, c);\n\n      TopFieldDocs hits = c.topDocs();\n\n      // Slower way if postings are not pre-sorted by weight:\n      // hits = searcher.search(query, null, num, SORT);\n      results = createResults(searcher, hits, num, key, doHighlight, matchedTokens, prefixToken);\n    } finally {\n      mgr.release(searcher);\n    }\n\n    //System.out.println((System.currentTimeMillis() - t0) + \" msec for infix suggest\");\n    //System.out.println(results);\n\n    return results;\n  }\n\n","sourceOld":"  /**\n   * This is an advanced method providing the capability to send down to the suggester any \n   * arbitrary lucene query to be used to filter the result of the suggester\n   * \n   * @param key the keyword being looked for\n   * @param contextQuery an arbitrary Lucene query to be used to filter the result of the suggester. {@link #addContextToQuery} could be used to build this contextQuery.\n   * @param num number of items to return\n   * @param allTermsRequired all searched terms must match or not\n   * @param doHighlight if true, the matching term will be highlighted in the search result\n   * @return the result of the suggester\n   * @throws IOException f the is IO exception while reading data from the index\n   */\n  public List<LookupResult> lookup(CharSequence key, BooleanQuery contextQuery, int num, boolean allTermsRequired, boolean doHighlight) throws IOException {\n\n    if (searcherMgr == null) {\n      throw new IllegalStateException(\"suggester was not built\");\n    }\n\n    final BooleanClause.Occur occur;\n    if (allTermsRequired) {\n      occur = BooleanClause.Occur.MUST;\n    } else {\n      occur = BooleanClause.Occur.SHOULD;\n    }\n\n    BooleanQuery.Builder query;\n    Set<String> matchedTokens;\n    String prefixToken = null;\n\n    try (TokenStream ts = queryAnalyzer.tokenStream(\"\", new StringReader(key.toString()))) {\n      //long t0 = System.currentTimeMillis();\n      ts.reset();\n      final CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      final OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      String lastToken = null;\n      query = new BooleanQuery.Builder();\n      int maxEndOffset = -1;\n      matchedTokens = new HashSet<>();\n      while (ts.incrementToken()) {\n        if (lastToken != null) {  \n          matchedTokens.add(lastToken);\n          query.add(new TermQuery(new Term(TEXT_FIELD_NAME, lastToken)), occur);\n        }\n        lastToken = termAtt.toString();\n        if (lastToken != null) {\n          maxEndOffset = Math.max(maxEndOffset, offsetAtt.endOffset());\n        }\n      }\n      ts.end();\n\n      if (lastToken != null) {\n        Query lastQuery;\n        if (maxEndOffset == offsetAtt.endOffset()) {\n          // Use PrefixQuery (or the ngram equivalent) when\n          // there was no trailing discarded chars in the\n          // string (e.g. whitespace), so that if query does\n          // not end with a space we show prefix matches for\n          // that token:\n          lastQuery = getLastTokenQuery(lastToken);\n          prefixToken = lastToken;\n        } else {\n          // Use TermQuery for an exact match if there were\n          // trailing discarded chars (e.g. whitespace), so\n          // that if query ends with a space we only show\n          // exact matches for that term:\n          matchedTokens.add(lastToken);\n          lastQuery = new TermQuery(new Term(TEXT_FIELD_NAME, lastToken));\n        }\n        \n        if (lastQuery != null) {\n          query.add(lastQuery, occur);\n        }\n      }\n\n      if (contextQuery != null) {\n        boolean allMustNot = true;\n        for (BooleanClause clause : contextQuery.clauses()) {\n          if (clause.getOccur() != BooleanClause.Occur.MUST_NOT) {\n            allMustNot = false;\n            break;\n          }\n        }\n        \n        if (allMustNot) {\n          // All are MUST_NOT: add the contextQuery to the main query instead (not as sub-query)\n          for (BooleanClause clause : contextQuery.clauses()) {\n            query.add(clause);\n          }\n        } else if (allTermsRequired == false) {\n          // We must carefully upgrade the query clauses to MUST:\n          BooleanQuery.Builder newQuery = new BooleanQuery.Builder();\n          newQuery.add(query.build(), BooleanClause.Occur.MUST);\n          newQuery.add(contextQuery, BooleanClause.Occur.MUST);\n          query = newQuery;\n        } else {\n          // Add contextQuery as sub-query\n          query.add(contextQuery, BooleanClause.Occur.MUST);\n        }\n      }\n    }\n    \n    // TODO: we could allow blended sort here, combining\n    // weight w/ score.  Now we ignore score and sort only\n    // by weight:\n\n    Query finalQuery = finishQuery(query, allTermsRequired);\n\n    //System.out.println(\"finalQuery=\" + finalQuery);\n\n    // Sort by weight, descending:\n    TopFieldCollector c = TopFieldCollector.create(SORT, num, true, false, false);\n\n    // We sorted postings by weight during indexing, so we\n    // only retrieve the first num hits now:\n    Collector c2 = new EarlyTerminatingSortingCollector(c, SORT, num);\n    List<LookupResult> results = null;\n    SearcherManager mgr;\n    IndexSearcher searcher;\n    synchronized (searcherMgrLock) {\n      mgr = searcherMgr; // acquire & release on same SearcherManager, via local reference\n      searcher = mgr.acquire();\n    }\n    try {\n      //System.out.println(\"got searcher=\" + searcher);\n      searcher.search(finalQuery, c2);\n\n      TopFieldDocs hits = c.topDocs();\n\n      // Slower way if postings are not pre-sorted by weight:\n      // hits = searcher.search(query, null, num, SORT);\n      results = createResults(searcher, hits, num, key, doHighlight, matchedTokens, prefixToken);\n    } finally {\n      mgr.release(searcher);\n    }\n\n    //System.out.println((System.currentTimeMillis() - t0) + \" msec for infix suggest\");\n    //System.out.println(results);\n\n    return results;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1aad05eeff7818b0833c02ac6b743aa72054963b","date":1512093122,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#lookup(CharSequence,BooleanQuery,int,boolean,boolean).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#lookup(CharSequence,BooleanQuery,int,boolean,boolean).mjava","sourceNew":"  /**\n   * This is an advanced method providing the capability to send down to the suggester any \n   * arbitrary lucene query to be used to filter the result of the suggester\n   * \n   * @param key the keyword being looked for\n   * @param contextQuery an arbitrary Lucene query to be used to filter the result of the suggester. {@link #addContextToQuery} could be used to build this contextQuery.\n   * @param num number of items to return\n   * @param allTermsRequired all searched terms must match or not\n   * @param doHighlight if true, the matching term will be highlighted in the search result\n   * @return the result of the suggester\n   * @throws IOException f the is IO exception while reading data from the index\n   */\n  public List<LookupResult> lookup(CharSequence key, BooleanQuery contextQuery, int num, boolean allTermsRequired, boolean doHighlight) throws IOException {\n\n    if (searcherMgr == null) {\n      throw new IllegalStateException(\"suggester was not built\");\n    }\n\n    final BooleanClause.Occur occur;\n    if (allTermsRequired) {\n      occur = BooleanClause.Occur.MUST;\n    } else {\n      occur = BooleanClause.Occur.SHOULD;\n    }\n\n    BooleanQuery.Builder query;\n    Set<String> matchedTokens;\n    String prefixToken = null;\n\n    try (TokenStream ts = queryAnalyzer.tokenStream(\"\", new StringReader(key.toString()))) {\n      //long t0 = System.currentTimeMillis();\n      ts.reset();\n      final CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      final OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      String lastToken = null;\n      query = new BooleanQuery.Builder();\n      int maxEndOffset = -1;\n      matchedTokens = new HashSet<>();\n      while (ts.incrementToken()) {\n        if (lastToken != null) {  \n          matchedTokens.add(lastToken);\n          query.add(new TermQuery(new Term(TEXT_FIELD_NAME, lastToken)), occur);\n        }\n        lastToken = termAtt.toString();\n        if (lastToken != null) {\n          maxEndOffset = Math.max(maxEndOffset, offsetAtt.endOffset());\n        }\n      }\n      ts.end();\n\n      if (lastToken != null) {\n        Query lastQuery;\n        if (maxEndOffset == offsetAtt.endOffset()) {\n          // Use PrefixQuery (or the ngram equivalent) when\n          // there was no trailing discarded chars in the\n          // string (e.g. whitespace), so that if query does\n          // not end with a space we show prefix matches for\n          // that token:\n          lastQuery = getLastTokenQuery(lastToken);\n          prefixToken = lastToken;\n        } else {\n          // Use TermQuery for an exact match if there were\n          // trailing discarded chars (e.g. whitespace), so\n          // that if query ends with a space we only show\n          // exact matches for that term:\n          matchedTokens.add(lastToken);\n          lastQuery = new TermQuery(new Term(TEXT_FIELD_NAME, lastToken));\n        }\n        \n        if (lastQuery != null) {\n          query.add(lastQuery, occur);\n        }\n      }\n\n      if (contextQuery != null) {\n        boolean allMustNot = true;\n        for (BooleanClause clause : contextQuery.clauses()) {\n          if (clause.getOccur() != BooleanClause.Occur.MUST_NOT) {\n            allMustNot = false;\n            break;\n          }\n        }\n        \n        if (allMustNot) {\n          // All are MUST_NOT: add the contextQuery to the main query instead (not as sub-query)\n          for (BooleanClause clause : contextQuery.clauses()) {\n            query.add(clause);\n          }\n        } else if (allTermsRequired == false) {\n          // We must carefully upgrade the query clauses to MUST:\n          BooleanQuery.Builder newQuery = new BooleanQuery.Builder();\n          newQuery.add(query.build(), BooleanClause.Occur.MUST);\n          newQuery.add(contextQuery, BooleanClause.Occur.MUST);\n          query = newQuery;\n        } else {\n          // Add contextQuery as sub-query\n          query.add(contextQuery, BooleanClause.Occur.MUST);\n        }\n      }\n    }\n    \n    // TODO: we could allow blended sort here, combining\n    // weight w/ score.  Now we ignore score and sort only\n    // by weight:\n\n    Query finalQuery = finishQuery(query, allTermsRequired);\n\n    //System.out.println(\"finalQuery=\" + finalQuery);\n\n    // Sort by weight, descending:\n    TopFieldCollector c = TopFieldCollector.create(SORT, num, true, false, false, false);\n    List<LookupResult> results = null;\n    SearcherManager mgr;\n    IndexSearcher searcher;\n    synchronized (searcherMgrLock) {\n      mgr = searcherMgr; // acquire & release on same SearcherManager, via local reference\n      searcher = mgr.acquire();\n    }\n    try {\n      //System.out.println(\"got searcher=\" + searcher);\n      searcher.search(finalQuery, c);\n\n      TopFieldDocs hits = c.topDocs();\n\n      // Slower way if postings are not pre-sorted by weight:\n      // hits = searcher.search(query, null, num, SORT);\n      results = createResults(searcher, hits, num, key, doHighlight, matchedTokens, prefixToken);\n    } finally {\n      mgr.release(searcher);\n    }\n\n    //System.out.println((System.currentTimeMillis() - t0) + \" msec for infix suggest\");\n    //System.out.println(results);\n\n    return results;\n  }\n\n","sourceOld":"  /**\n   * This is an advanced method providing the capability to send down to the suggester any \n   * arbitrary lucene query to be used to filter the result of the suggester\n   * \n   * @param key the keyword being looked for\n   * @param contextQuery an arbitrary Lucene query to be used to filter the result of the suggester. {@link #addContextToQuery} could be used to build this contextQuery.\n   * @param num number of items to return\n   * @param allTermsRequired all searched terms must match or not\n   * @param doHighlight if true, the matching term will be highlighted in the search result\n   * @return the result of the suggester\n   * @throws IOException f the is IO exception while reading data from the index\n   */\n  public List<LookupResult> lookup(CharSequence key, BooleanQuery contextQuery, int num, boolean allTermsRequired, boolean doHighlight) throws IOException {\n\n    if (searcherMgr == null) {\n      throw new IllegalStateException(\"suggester was not built\");\n    }\n\n    final BooleanClause.Occur occur;\n    if (allTermsRequired) {\n      occur = BooleanClause.Occur.MUST;\n    } else {\n      occur = BooleanClause.Occur.SHOULD;\n    }\n\n    BooleanQuery.Builder query;\n    Set<String> matchedTokens;\n    String prefixToken = null;\n\n    try (TokenStream ts = queryAnalyzer.tokenStream(\"\", new StringReader(key.toString()))) {\n      //long t0 = System.currentTimeMillis();\n      ts.reset();\n      final CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      final OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      String lastToken = null;\n      query = new BooleanQuery.Builder();\n      int maxEndOffset = -1;\n      matchedTokens = new HashSet<>();\n      while (ts.incrementToken()) {\n        if (lastToken != null) {  \n          matchedTokens.add(lastToken);\n          query.add(new TermQuery(new Term(TEXT_FIELD_NAME, lastToken)), occur);\n        }\n        lastToken = termAtt.toString();\n        if (lastToken != null) {\n          maxEndOffset = Math.max(maxEndOffset, offsetAtt.endOffset());\n        }\n      }\n      ts.end();\n\n      if (lastToken != null) {\n        Query lastQuery;\n        if (maxEndOffset == offsetAtt.endOffset()) {\n          // Use PrefixQuery (or the ngram equivalent) when\n          // there was no trailing discarded chars in the\n          // string (e.g. whitespace), so that if query does\n          // not end with a space we show prefix matches for\n          // that token:\n          lastQuery = getLastTokenQuery(lastToken);\n          prefixToken = lastToken;\n        } else {\n          // Use TermQuery for an exact match if there were\n          // trailing discarded chars (e.g. whitespace), so\n          // that if query ends with a space we only show\n          // exact matches for that term:\n          matchedTokens.add(lastToken);\n          lastQuery = new TermQuery(new Term(TEXT_FIELD_NAME, lastToken));\n        }\n        \n        if (lastQuery != null) {\n          query.add(lastQuery, occur);\n        }\n      }\n\n      if (contextQuery != null) {\n        boolean allMustNot = true;\n        for (BooleanClause clause : contextQuery.clauses()) {\n          if (clause.getOccur() != BooleanClause.Occur.MUST_NOT) {\n            allMustNot = false;\n            break;\n          }\n        }\n        \n        if (allMustNot) {\n          // All are MUST_NOT: add the contextQuery to the main query instead (not as sub-query)\n          for (BooleanClause clause : contextQuery.clauses()) {\n            query.add(clause);\n          }\n        } else if (allTermsRequired == false) {\n          // We must carefully upgrade the query clauses to MUST:\n          BooleanQuery.Builder newQuery = new BooleanQuery.Builder();\n          newQuery.add(query.build(), BooleanClause.Occur.MUST);\n          newQuery.add(contextQuery, BooleanClause.Occur.MUST);\n          query = newQuery;\n        } else {\n          // Add contextQuery as sub-query\n          query.add(contextQuery, BooleanClause.Occur.MUST);\n        }\n      }\n    }\n    \n    // TODO: we could allow blended sort here, combining\n    // weight w/ score.  Now we ignore score and sort only\n    // by weight:\n\n    Query finalQuery = finishQuery(query, allTermsRequired);\n\n    //System.out.println(\"finalQuery=\" + finalQuery);\n\n    // Sort by weight, descending:\n    TopFieldCollector c = TopFieldCollector.create(SORT, num, true, false, false);\n\n    // We sorted postings by weight during indexing, so we\n    // only retrieve the first num hits now:\n    Collector c2 = new EarlyTerminatingSortingCollector(c, SORT, num);\n    List<LookupResult> results = null;\n    SearcherManager mgr;\n    IndexSearcher searcher;\n    synchronized (searcherMgrLock) {\n      mgr = searcherMgr; // acquire & release on same SearcherManager, via local reference\n      searcher = mgr.acquire();\n    }\n    try {\n      //System.out.println(\"got searcher=\" + searcher);\n      searcher.search(finalQuery, c2);\n\n      TopFieldDocs hits = c.topDocs();\n\n      // Slower way if postings are not pre-sorted by weight:\n      // hits = searcher.search(query, null, num, SORT);\n      results = createResults(searcher, hits, num, key, doHighlight, matchedTokens, prefixToken);\n    } finally {\n      mgr.release(searcher);\n    }\n\n    //System.out.println((System.currentTimeMillis() - t0) + \" msec for infix suggest\");\n    //System.out.println(results);\n\n    return results;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"81fff83bdb893c1471efd78f6a9a3ce4f98120b9","date":1531895937,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#lookup(CharSequence,BooleanQuery,int,boolean,boolean).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#lookup(CharSequence,BooleanQuery,int,boolean,boolean).mjava","sourceNew":"  /**\n   * This is an advanced method providing the capability to send down to the suggester any \n   * arbitrary lucene query to be used to filter the result of the suggester\n   * \n   * @param key the keyword being looked for\n   * @param contextQuery an arbitrary Lucene query to be used to filter the result of the suggester. {@link #addContextToQuery} could be used to build this contextQuery.\n   * @param num number of items to return\n   * @param allTermsRequired all searched terms must match or not\n   * @param doHighlight if true, the matching term will be highlighted in the search result\n   * @return the result of the suggester\n   * @throws IOException f the is IO exception while reading data from the index\n   */\n  public List<LookupResult> lookup(CharSequence key, BooleanQuery contextQuery, int num, boolean allTermsRequired, boolean doHighlight) throws IOException {\n\n    if (searcherMgr == null) {\n      throw new IllegalStateException(\"suggester was not built\");\n    }\n\n    final BooleanClause.Occur occur;\n    if (allTermsRequired) {\n      occur = BooleanClause.Occur.MUST;\n    } else {\n      occur = BooleanClause.Occur.SHOULD;\n    }\n\n    BooleanQuery.Builder query;\n    Set<String> matchedTokens;\n    String prefixToken = null;\n\n    try (TokenStream ts = queryAnalyzer.tokenStream(\"\", new StringReader(key.toString()))) {\n      //long t0 = System.currentTimeMillis();\n      ts.reset();\n      final CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      final OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      String lastToken = null;\n      query = new BooleanQuery.Builder();\n      int maxEndOffset = -1;\n      matchedTokens = new HashSet<>();\n      while (ts.incrementToken()) {\n        if (lastToken != null) {  \n          matchedTokens.add(lastToken);\n          query.add(new TermQuery(new Term(TEXT_FIELD_NAME, lastToken)), occur);\n        }\n        lastToken = termAtt.toString();\n        if (lastToken != null) {\n          maxEndOffset = Math.max(maxEndOffset, offsetAtt.endOffset());\n        }\n      }\n      ts.end();\n\n      if (lastToken != null) {\n        Query lastQuery;\n        if (maxEndOffset == offsetAtt.endOffset()) {\n          // Use PrefixQuery (or the ngram equivalent) when\n          // there was no trailing discarded chars in the\n          // string (e.g. whitespace), so that if query does\n          // not end with a space we show prefix matches for\n          // that token:\n          lastQuery = getLastTokenQuery(lastToken);\n          prefixToken = lastToken;\n        } else {\n          // Use TermQuery for an exact match if there were\n          // trailing discarded chars (e.g. whitespace), so\n          // that if query ends with a space we only show\n          // exact matches for that term:\n          matchedTokens.add(lastToken);\n          lastQuery = new TermQuery(new Term(TEXT_FIELD_NAME, lastToken));\n        }\n        \n        if (lastQuery != null) {\n          query.add(lastQuery, occur);\n        }\n      }\n\n      if (contextQuery != null) {\n        boolean allMustNot = true;\n        for (BooleanClause clause : contextQuery.clauses()) {\n          if (clause.getOccur() != BooleanClause.Occur.MUST_NOT) {\n            allMustNot = false;\n            break;\n          }\n        }\n        \n        if (allMustNot) {\n          // All are MUST_NOT: add the contextQuery to the main query instead (not as sub-query)\n          for (BooleanClause clause : contextQuery.clauses()) {\n            query.add(clause);\n          }\n        } else if (allTermsRequired == false) {\n          // We must carefully upgrade the query clauses to MUST:\n          BooleanQuery.Builder newQuery = new BooleanQuery.Builder();\n          newQuery.add(query.build(), BooleanClause.Occur.MUST);\n          newQuery.add(contextQuery, BooleanClause.Occur.MUST);\n          query = newQuery;\n        } else {\n          // Add contextQuery as sub-query\n          query.add(contextQuery, BooleanClause.Occur.MUST);\n        }\n      }\n    }\n    \n    // TODO: we could allow blended sort here, combining\n    // weight w/ score.  Now we ignore score and sort only\n    // by weight:\n\n    Query finalQuery = finishQuery(query, allTermsRequired);\n\n    //System.out.println(\"finalQuery=\" + finalQuery);\n\n    // Sort by weight, descending:\n    TopFieldCollector c = TopFieldCollector.create(SORT, num, true, false, false);\n    List<LookupResult> results = null;\n    SearcherManager mgr;\n    IndexSearcher searcher;\n    synchronized (searcherMgrLock) {\n      mgr = searcherMgr; // acquire & release on same SearcherManager, via local reference\n      searcher = mgr.acquire();\n    }\n    try {\n      //System.out.println(\"got searcher=\" + searcher);\n      searcher.search(finalQuery, c);\n\n      TopFieldDocs hits = c.topDocs();\n\n      // Slower way if postings are not pre-sorted by weight:\n      // hits = searcher.search(query, null, num, SORT);\n      results = createResults(searcher, hits, num, key, doHighlight, matchedTokens, prefixToken);\n    } finally {\n      mgr.release(searcher);\n    }\n\n    //System.out.println((System.currentTimeMillis() - t0) + \" msec for infix suggest\");\n    //System.out.println(results);\n\n    return results;\n  }\n\n","sourceOld":"  /**\n   * This is an advanced method providing the capability to send down to the suggester any \n   * arbitrary lucene query to be used to filter the result of the suggester\n   * \n   * @param key the keyword being looked for\n   * @param contextQuery an arbitrary Lucene query to be used to filter the result of the suggester. {@link #addContextToQuery} could be used to build this contextQuery.\n   * @param num number of items to return\n   * @param allTermsRequired all searched terms must match or not\n   * @param doHighlight if true, the matching term will be highlighted in the search result\n   * @return the result of the suggester\n   * @throws IOException f the is IO exception while reading data from the index\n   */\n  public List<LookupResult> lookup(CharSequence key, BooleanQuery contextQuery, int num, boolean allTermsRequired, boolean doHighlight) throws IOException {\n\n    if (searcherMgr == null) {\n      throw new IllegalStateException(\"suggester was not built\");\n    }\n\n    final BooleanClause.Occur occur;\n    if (allTermsRequired) {\n      occur = BooleanClause.Occur.MUST;\n    } else {\n      occur = BooleanClause.Occur.SHOULD;\n    }\n\n    BooleanQuery.Builder query;\n    Set<String> matchedTokens;\n    String prefixToken = null;\n\n    try (TokenStream ts = queryAnalyzer.tokenStream(\"\", new StringReader(key.toString()))) {\n      //long t0 = System.currentTimeMillis();\n      ts.reset();\n      final CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      final OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      String lastToken = null;\n      query = new BooleanQuery.Builder();\n      int maxEndOffset = -1;\n      matchedTokens = new HashSet<>();\n      while (ts.incrementToken()) {\n        if (lastToken != null) {  \n          matchedTokens.add(lastToken);\n          query.add(new TermQuery(new Term(TEXT_FIELD_NAME, lastToken)), occur);\n        }\n        lastToken = termAtt.toString();\n        if (lastToken != null) {\n          maxEndOffset = Math.max(maxEndOffset, offsetAtt.endOffset());\n        }\n      }\n      ts.end();\n\n      if (lastToken != null) {\n        Query lastQuery;\n        if (maxEndOffset == offsetAtt.endOffset()) {\n          // Use PrefixQuery (or the ngram equivalent) when\n          // there was no trailing discarded chars in the\n          // string (e.g. whitespace), so that if query does\n          // not end with a space we show prefix matches for\n          // that token:\n          lastQuery = getLastTokenQuery(lastToken);\n          prefixToken = lastToken;\n        } else {\n          // Use TermQuery for an exact match if there were\n          // trailing discarded chars (e.g. whitespace), so\n          // that if query ends with a space we only show\n          // exact matches for that term:\n          matchedTokens.add(lastToken);\n          lastQuery = new TermQuery(new Term(TEXT_FIELD_NAME, lastToken));\n        }\n        \n        if (lastQuery != null) {\n          query.add(lastQuery, occur);\n        }\n      }\n\n      if (contextQuery != null) {\n        boolean allMustNot = true;\n        for (BooleanClause clause : contextQuery.clauses()) {\n          if (clause.getOccur() != BooleanClause.Occur.MUST_NOT) {\n            allMustNot = false;\n            break;\n          }\n        }\n        \n        if (allMustNot) {\n          // All are MUST_NOT: add the contextQuery to the main query instead (not as sub-query)\n          for (BooleanClause clause : contextQuery.clauses()) {\n            query.add(clause);\n          }\n        } else if (allTermsRequired == false) {\n          // We must carefully upgrade the query clauses to MUST:\n          BooleanQuery.Builder newQuery = new BooleanQuery.Builder();\n          newQuery.add(query.build(), BooleanClause.Occur.MUST);\n          newQuery.add(contextQuery, BooleanClause.Occur.MUST);\n          query = newQuery;\n        } else {\n          // Add contextQuery as sub-query\n          query.add(contextQuery, BooleanClause.Occur.MUST);\n        }\n      }\n    }\n    \n    // TODO: we could allow blended sort here, combining\n    // weight w/ score.  Now we ignore score and sort only\n    // by weight:\n\n    Query finalQuery = finishQuery(query, allTermsRequired);\n\n    //System.out.println(\"finalQuery=\" + finalQuery);\n\n    // Sort by weight, descending:\n    TopFieldCollector c = TopFieldCollector.create(SORT, num, true, false, false, false);\n    List<LookupResult> results = null;\n    SearcherManager mgr;\n    IndexSearcher searcher;\n    synchronized (searcherMgrLock) {\n      mgr = searcherMgr; // acquire & release on same SearcherManager, via local reference\n      searcher = mgr.acquire();\n    }\n    try {\n      //System.out.println(\"got searcher=\" + searcher);\n      searcher.search(finalQuery, c);\n\n      TopFieldDocs hits = c.topDocs();\n\n      // Slower way if postings are not pre-sorted by weight:\n      // hits = searcher.search(query, null, num, SORT);\n      results = createResults(searcher, hits, num, key, doHighlight, matchedTokens, prefixToken);\n    } finally {\n      mgr.release(searcher);\n    }\n\n    //System.out.println((System.currentTimeMillis() - t0) + \" msec for infix suggest\");\n    //System.out.println(results);\n\n    return results;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","date":1531905561,"type":3,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#lookup(CharSequence,BooleanQuery,int,boolean,boolean).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#lookup(CharSequence,BooleanQuery,int,boolean,boolean).mjava","sourceNew":"  /**\n   * This is an advanced method providing the capability to send down to the suggester any \n   * arbitrary lucene query to be used to filter the result of the suggester\n   * \n   * @param key the keyword being looked for\n   * @param contextQuery an arbitrary Lucene query to be used to filter the result of the suggester. {@link #addContextToQuery} could be used to build this contextQuery.\n   * @param num number of items to return\n   * @param allTermsRequired all searched terms must match or not\n   * @param doHighlight if true, the matching term will be highlighted in the search result\n   * @return the result of the suggester\n   * @throws IOException f the is IO exception while reading data from the index\n   */\n  public List<LookupResult> lookup(CharSequence key, BooleanQuery contextQuery, int num, boolean allTermsRequired, boolean doHighlight) throws IOException {\n\n    if (searcherMgr == null) {\n      throw new IllegalStateException(\"suggester was not built\");\n    }\n\n    final BooleanClause.Occur occur;\n    if (allTermsRequired) {\n      occur = BooleanClause.Occur.MUST;\n    } else {\n      occur = BooleanClause.Occur.SHOULD;\n    }\n\n    BooleanQuery.Builder query;\n    Set<String> matchedTokens;\n    String prefixToken = null;\n\n    try (TokenStream ts = queryAnalyzer.tokenStream(\"\", new StringReader(key.toString()))) {\n      //long t0 = System.currentTimeMillis();\n      ts.reset();\n      final CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      final OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      String lastToken = null;\n      query = new BooleanQuery.Builder();\n      int maxEndOffset = -1;\n      matchedTokens = new HashSet<>();\n      while (ts.incrementToken()) {\n        if (lastToken != null) {  \n          matchedTokens.add(lastToken);\n          query.add(new TermQuery(new Term(TEXT_FIELD_NAME, lastToken)), occur);\n        }\n        lastToken = termAtt.toString();\n        if (lastToken != null) {\n          maxEndOffset = Math.max(maxEndOffset, offsetAtt.endOffset());\n        }\n      }\n      ts.end();\n\n      if (lastToken != null) {\n        Query lastQuery;\n        if (maxEndOffset == offsetAtt.endOffset()) {\n          // Use PrefixQuery (or the ngram equivalent) when\n          // there was no trailing discarded chars in the\n          // string (e.g. whitespace), so that if query does\n          // not end with a space we show prefix matches for\n          // that token:\n          lastQuery = getLastTokenQuery(lastToken);\n          prefixToken = lastToken;\n        } else {\n          // Use TermQuery for an exact match if there were\n          // trailing discarded chars (e.g. whitespace), so\n          // that if query ends with a space we only show\n          // exact matches for that term:\n          matchedTokens.add(lastToken);\n          lastQuery = new TermQuery(new Term(TEXT_FIELD_NAME, lastToken));\n        }\n        \n        if (lastQuery != null) {\n          query.add(lastQuery, occur);\n        }\n      }\n\n      if (contextQuery != null) {\n        boolean allMustNot = true;\n        for (BooleanClause clause : contextQuery.clauses()) {\n          if (clause.getOccur() != BooleanClause.Occur.MUST_NOT) {\n            allMustNot = false;\n            break;\n          }\n        }\n        \n        if (allMustNot) {\n          // All are MUST_NOT: add the contextQuery to the main query instead (not as sub-query)\n          for (BooleanClause clause : contextQuery.clauses()) {\n            query.add(clause);\n          }\n        } else if (allTermsRequired == false) {\n          // We must carefully upgrade the query clauses to MUST:\n          BooleanQuery.Builder newQuery = new BooleanQuery.Builder();\n          newQuery.add(query.build(), BooleanClause.Occur.MUST);\n          newQuery.add(contextQuery, BooleanClause.Occur.MUST);\n          query = newQuery;\n        } else {\n          // Add contextQuery as sub-query\n          query.add(contextQuery, BooleanClause.Occur.MUST);\n        }\n      }\n    }\n    \n    // TODO: we could allow blended sort here, combining\n    // weight w/ score.  Now we ignore score and sort only\n    // by weight:\n\n    Query finalQuery = finishQuery(query, allTermsRequired);\n\n    //System.out.println(\"finalQuery=\" + finalQuery);\n\n    // Sort by weight, descending:\n    TopFieldCollector c = TopFieldCollector.create(SORT, num, true, false, false);\n    List<LookupResult> results = null;\n    SearcherManager mgr;\n    IndexSearcher searcher;\n    synchronized (searcherMgrLock) {\n      mgr = searcherMgr; // acquire & release on same SearcherManager, via local reference\n      searcher = mgr.acquire();\n    }\n    try {\n      //System.out.println(\"got searcher=\" + searcher);\n      searcher.search(finalQuery, c);\n\n      TopFieldDocs hits = c.topDocs();\n\n      // Slower way if postings are not pre-sorted by weight:\n      // hits = searcher.search(query, null, num, SORT);\n      results = createResults(searcher, hits, num, key, doHighlight, matchedTokens, prefixToken);\n    } finally {\n      mgr.release(searcher);\n    }\n\n    //System.out.println((System.currentTimeMillis() - t0) + \" msec for infix suggest\");\n    //System.out.println(results);\n\n    return results;\n  }\n\n","sourceOld":"  /**\n   * This is an advanced method providing the capability to send down to the suggester any \n   * arbitrary lucene query to be used to filter the result of the suggester\n   * \n   * @param key the keyword being looked for\n   * @param contextQuery an arbitrary Lucene query to be used to filter the result of the suggester. {@link #addContextToQuery} could be used to build this contextQuery.\n   * @param num number of items to return\n   * @param allTermsRequired all searched terms must match or not\n   * @param doHighlight if true, the matching term will be highlighted in the search result\n   * @return the result of the suggester\n   * @throws IOException f the is IO exception while reading data from the index\n   */\n  public List<LookupResult> lookup(CharSequence key, BooleanQuery contextQuery, int num, boolean allTermsRequired, boolean doHighlight) throws IOException {\n\n    if (searcherMgr == null) {\n      throw new IllegalStateException(\"suggester was not built\");\n    }\n\n    final BooleanClause.Occur occur;\n    if (allTermsRequired) {\n      occur = BooleanClause.Occur.MUST;\n    } else {\n      occur = BooleanClause.Occur.SHOULD;\n    }\n\n    BooleanQuery.Builder query;\n    Set<String> matchedTokens;\n    String prefixToken = null;\n\n    try (TokenStream ts = queryAnalyzer.tokenStream(\"\", new StringReader(key.toString()))) {\n      //long t0 = System.currentTimeMillis();\n      ts.reset();\n      final CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      final OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      String lastToken = null;\n      query = new BooleanQuery.Builder();\n      int maxEndOffset = -1;\n      matchedTokens = new HashSet<>();\n      while (ts.incrementToken()) {\n        if (lastToken != null) {  \n          matchedTokens.add(lastToken);\n          query.add(new TermQuery(new Term(TEXT_FIELD_NAME, lastToken)), occur);\n        }\n        lastToken = termAtt.toString();\n        if (lastToken != null) {\n          maxEndOffset = Math.max(maxEndOffset, offsetAtt.endOffset());\n        }\n      }\n      ts.end();\n\n      if (lastToken != null) {\n        Query lastQuery;\n        if (maxEndOffset == offsetAtt.endOffset()) {\n          // Use PrefixQuery (or the ngram equivalent) when\n          // there was no trailing discarded chars in the\n          // string (e.g. whitespace), so that if query does\n          // not end with a space we show prefix matches for\n          // that token:\n          lastQuery = getLastTokenQuery(lastToken);\n          prefixToken = lastToken;\n        } else {\n          // Use TermQuery for an exact match if there were\n          // trailing discarded chars (e.g. whitespace), so\n          // that if query ends with a space we only show\n          // exact matches for that term:\n          matchedTokens.add(lastToken);\n          lastQuery = new TermQuery(new Term(TEXT_FIELD_NAME, lastToken));\n        }\n        \n        if (lastQuery != null) {\n          query.add(lastQuery, occur);\n        }\n      }\n\n      if (contextQuery != null) {\n        boolean allMustNot = true;\n        for (BooleanClause clause : contextQuery.clauses()) {\n          if (clause.getOccur() != BooleanClause.Occur.MUST_NOT) {\n            allMustNot = false;\n            break;\n          }\n        }\n        \n        if (allMustNot) {\n          // All are MUST_NOT: add the contextQuery to the main query instead (not as sub-query)\n          for (BooleanClause clause : contextQuery.clauses()) {\n            query.add(clause);\n          }\n        } else if (allTermsRequired == false) {\n          // We must carefully upgrade the query clauses to MUST:\n          BooleanQuery.Builder newQuery = new BooleanQuery.Builder();\n          newQuery.add(query.build(), BooleanClause.Occur.MUST);\n          newQuery.add(contextQuery, BooleanClause.Occur.MUST);\n          query = newQuery;\n        } else {\n          // Add contextQuery as sub-query\n          query.add(contextQuery, BooleanClause.Occur.MUST);\n        }\n      }\n    }\n    \n    // TODO: we could allow blended sort here, combining\n    // weight w/ score.  Now we ignore score and sort only\n    // by weight:\n\n    Query finalQuery = finishQuery(query, allTermsRequired);\n\n    //System.out.println(\"finalQuery=\" + finalQuery);\n\n    // Sort by weight, descending:\n    TopFieldCollector c = TopFieldCollector.create(SORT, num, true, false, false, false);\n    List<LookupResult> results = null;\n    SearcherManager mgr;\n    IndexSearcher searcher;\n    synchronized (searcherMgrLock) {\n      mgr = searcherMgr; // acquire & release on same SearcherManager, via local reference\n      searcher = mgr.acquire();\n    }\n    try {\n      //System.out.println(\"got searcher=\" + searcher);\n      searcher.search(finalQuery, c);\n\n      TopFieldDocs hits = c.topDocs();\n\n      // Slower way if postings are not pre-sorted by weight:\n      // hits = searcher.search(query, null, num, SORT);\n      results = createResults(searcher, hits, num, key, doHighlight, matchedTokens, prefixToken);\n    } finally {\n      mgr.release(searcher);\n    }\n\n    //System.out.println((System.currentTimeMillis() - t0) + \" msec for infix suggest\");\n    //System.out.println(results);\n\n    return results;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"04c370507e5521b2eb998530736f1c19b851ed5a","date":1531911305,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#lookup(CharSequence,BooleanQuery,int,boolean,boolean).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#lookup(CharSequence,BooleanQuery,int,boolean,boolean).mjava","sourceNew":"  /**\n   * This is an advanced method providing the capability to send down to the suggester any \n   * arbitrary lucene query to be used to filter the result of the suggester\n   * \n   * @param key the keyword being looked for\n   * @param contextQuery an arbitrary Lucene query to be used to filter the result of the suggester. {@link #addContextToQuery} could be used to build this contextQuery.\n   * @param num number of items to return\n   * @param allTermsRequired all searched terms must match or not\n   * @param doHighlight if true, the matching term will be highlighted in the search result\n   * @return the result of the suggester\n   * @throws IOException f the is IO exception while reading data from the index\n   */\n  public List<LookupResult> lookup(CharSequence key, BooleanQuery contextQuery, int num, boolean allTermsRequired, boolean doHighlight) throws IOException {\n\n    if (searcherMgr == null) {\n      throw new IllegalStateException(\"suggester was not built\");\n    }\n\n    final BooleanClause.Occur occur;\n    if (allTermsRequired) {\n      occur = BooleanClause.Occur.MUST;\n    } else {\n      occur = BooleanClause.Occur.SHOULD;\n    }\n\n    BooleanQuery.Builder query;\n    Set<String> matchedTokens;\n    String prefixToken = null;\n\n    try (TokenStream ts = queryAnalyzer.tokenStream(\"\", new StringReader(key.toString()))) {\n      //long t0 = System.currentTimeMillis();\n      ts.reset();\n      final CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      final OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      String lastToken = null;\n      query = new BooleanQuery.Builder();\n      int maxEndOffset = -1;\n      matchedTokens = new HashSet<>();\n      while (ts.incrementToken()) {\n        if (lastToken != null) {  \n          matchedTokens.add(lastToken);\n          query.add(new TermQuery(new Term(TEXT_FIELD_NAME, lastToken)), occur);\n        }\n        lastToken = termAtt.toString();\n        if (lastToken != null) {\n          maxEndOffset = Math.max(maxEndOffset, offsetAtt.endOffset());\n        }\n      }\n      ts.end();\n\n      if (lastToken != null) {\n        Query lastQuery;\n        if (maxEndOffset == offsetAtt.endOffset()) {\n          // Use PrefixQuery (or the ngram equivalent) when\n          // there was no trailing discarded chars in the\n          // string (e.g. whitespace), so that if query does\n          // not end with a space we show prefix matches for\n          // that token:\n          lastQuery = getLastTokenQuery(lastToken);\n          prefixToken = lastToken;\n        } else {\n          // Use TermQuery for an exact match if there were\n          // trailing discarded chars (e.g. whitespace), so\n          // that if query ends with a space we only show\n          // exact matches for that term:\n          matchedTokens.add(lastToken);\n          lastQuery = new TermQuery(new Term(TEXT_FIELD_NAME, lastToken));\n        }\n        \n        if (lastQuery != null) {\n          query.add(lastQuery, occur);\n        }\n      }\n\n      if (contextQuery != null) {\n        boolean allMustNot = true;\n        for (BooleanClause clause : contextQuery.clauses()) {\n          if (clause.getOccur() != BooleanClause.Occur.MUST_NOT) {\n            allMustNot = false;\n            break;\n          }\n        }\n        \n        if (allMustNot) {\n          // All are MUST_NOT: add the contextQuery to the main query instead (not as sub-query)\n          for (BooleanClause clause : contextQuery.clauses()) {\n            query.add(clause);\n          }\n        } else if (allTermsRequired == false) {\n          // We must carefully upgrade the query clauses to MUST:\n          BooleanQuery.Builder newQuery = new BooleanQuery.Builder();\n          newQuery.add(query.build(), BooleanClause.Occur.MUST);\n          newQuery.add(contextQuery, BooleanClause.Occur.MUST);\n          query = newQuery;\n        } else {\n          // Add contextQuery as sub-query\n          query.add(contextQuery, BooleanClause.Occur.MUST);\n        }\n      }\n    }\n    \n    // TODO: we could allow blended sort here, combining\n    // weight w/ score.  Now we ignore score and sort only\n    // by weight:\n\n    Query finalQuery = finishQuery(query, allTermsRequired);\n\n    //System.out.println(\"finalQuery=\" + finalQuery);\n\n    // Sort by weight, descending:\n    TopFieldCollector c = TopFieldCollector.create(SORT, num, false, false);\n    List<LookupResult> results = null;\n    SearcherManager mgr;\n    IndexSearcher searcher;\n    synchronized (searcherMgrLock) {\n      mgr = searcherMgr; // acquire & release on same SearcherManager, via local reference\n      searcher = mgr.acquire();\n    }\n    try {\n      //System.out.println(\"got searcher=\" + searcher);\n      searcher.search(finalQuery, c);\n\n      TopFieldDocs hits = c.topDocs();\n\n      // Slower way if postings are not pre-sorted by weight:\n      // hits = searcher.search(query, null, num, SORT);\n      results = createResults(searcher, hits, num, key, doHighlight, matchedTokens, prefixToken);\n    } finally {\n      mgr.release(searcher);\n    }\n\n    //System.out.println((System.currentTimeMillis() - t0) + \" msec for infix suggest\");\n    //System.out.println(results);\n\n    return results;\n  }\n\n","sourceOld":"  /**\n   * This is an advanced method providing the capability to send down to the suggester any \n   * arbitrary lucene query to be used to filter the result of the suggester\n   * \n   * @param key the keyword being looked for\n   * @param contextQuery an arbitrary Lucene query to be used to filter the result of the suggester. {@link #addContextToQuery} could be used to build this contextQuery.\n   * @param num number of items to return\n   * @param allTermsRequired all searched terms must match or not\n   * @param doHighlight if true, the matching term will be highlighted in the search result\n   * @return the result of the suggester\n   * @throws IOException f the is IO exception while reading data from the index\n   */\n  public List<LookupResult> lookup(CharSequence key, BooleanQuery contextQuery, int num, boolean allTermsRequired, boolean doHighlight) throws IOException {\n\n    if (searcherMgr == null) {\n      throw new IllegalStateException(\"suggester was not built\");\n    }\n\n    final BooleanClause.Occur occur;\n    if (allTermsRequired) {\n      occur = BooleanClause.Occur.MUST;\n    } else {\n      occur = BooleanClause.Occur.SHOULD;\n    }\n\n    BooleanQuery.Builder query;\n    Set<String> matchedTokens;\n    String prefixToken = null;\n\n    try (TokenStream ts = queryAnalyzer.tokenStream(\"\", new StringReader(key.toString()))) {\n      //long t0 = System.currentTimeMillis();\n      ts.reset();\n      final CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      final OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      String lastToken = null;\n      query = new BooleanQuery.Builder();\n      int maxEndOffset = -1;\n      matchedTokens = new HashSet<>();\n      while (ts.incrementToken()) {\n        if (lastToken != null) {  \n          matchedTokens.add(lastToken);\n          query.add(new TermQuery(new Term(TEXT_FIELD_NAME, lastToken)), occur);\n        }\n        lastToken = termAtt.toString();\n        if (lastToken != null) {\n          maxEndOffset = Math.max(maxEndOffset, offsetAtt.endOffset());\n        }\n      }\n      ts.end();\n\n      if (lastToken != null) {\n        Query lastQuery;\n        if (maxEndOffset == offsetAtt.endOffset()) {\n          // Use PrefixQuery (or the ngram equivalent) when\n          // there was no trailing discarded chars in the\n          // string (e.g. whitespace), so that if query does\n          // not end with a space we show prefix matches for\n          // that token:\n          lastQuery = getLastTokenQuery(lastToken);\n          prefixToken = lastToken;\n        } else {\n          // Use TermQuery for an exact match if there were\n          // trailing discarded chars (e.g. whitespace), so\n          // that if query ends with a space we only show\n          // exact matches for that term:\n          matchedTokens.add(lastToken);\n          lastQuery = new TermQuery(new Term(TEXT_FIELD_NAME, lastToken));\n        }\n        \n        if (lastQuery != null) {\n          query.add(lastQuery, occur);\n        }\n      }\n\n      if (contextQuery != null) {\n        boolean allMustNot = true;\n        for (BooleanClause clause : contextQuery.clauses()) {\n          if (clause.getOccur() != BooleanClause.Occur.MUST_NOT) {\n            allMustNot = false;\n            break;\n          }\n        }\n        \n        if (allMustNot) {\n          // All are MUST_NOT: add the contextQuery to the main query instead (not as sub-query)\n          for (BooleanClause clause : contextQuery.clauses()) {\n            query.add(clause);\n          }\n        } else if (allTermsRequired == false) {\n          // We must carefully upgrade the query clauses to MUST:\n          BooleanQuery.Builder newQuery = new BooleanQuery.Builder();\n          newQuery.add(query.build(), BooleanClause.Occur.MUST);\n          newQuery.add(contextQuery, BooleanClause.Occur.MUST);\n          query = newQuery;\n        } else {\n          // Add contextQuery as sub-query\n          query.add(contextQuery, BooleanClause.Occur.MUST);\n        }\n      }\n    }\n    \n    // TODO: we could allow blended sort here, combining\n    // weight w/ score.  Now we ignore score and sort only\n    // by weight:\n\n    Query finalQuery = finishQuery(query, allTermsRequired);\n\n    //System.out.println(\"finalQuery=\" + finalQuery);\n\n    // Sort by weight, descending:\n    TopFieldCollector c = TopFieldCollector.create(SORT, num, true, false, false);\n    List<LookupResult> results = null;\n    SearcherManager mgr;\n    IndexSearcher searcher;\n    synchronized (searcherMgrLock) {\n      mgr = searcherMgr; // acquire & release on same SearcherManager, via local reference\n      searcher = mgr.acquire();\n    }\n    try {\n      //System.out.println(\"got searcher=\" + searcher);\n      searcher.search(finalQuery, c);\n\n      TopFieldDocs hits = c.topDocs();\n\n      // Slower way if postings are not pre-sorted by weight:\n      // hits = searcher.search(query, null, num, SORT);\n      results = createResults(searcher, hits, num, key, doHighlight, matchedTokens, prefixToken);\n    } finally {\n      mgr.release(searcher);\n    }\n\n    //System.out.println((System.currentTimeMillis() - t0) + \" msec for infix suggest\");\n    //System.out.println(results);\n\n    return results;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1d3f7ab1a502671bbdb03bcced21e764d2483221","date":1532329609,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#lookup(CharSequence,BooleanQuery,int,boolean,boolean).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#lookup(CharSequence,BooleanQuery,int,boolean,boolean).mjava","sourceNew":"  /**\n   * This is an advanced method providing the capability to send down to the suggester any \n   * arbitrary lucene query to be used to filter the result of the suggester\n   * \n   * @param key the keyword being looked for\n   * @param contextQuery an arbitrary Lucene query to be used to filter the result of the suggester. {@link #addContextToQuery} could be used to build this contextQuery.\n   * @param num number of items to return\n   * @param allTermsRequired all searched terms must match or not\n   * @param doHighlight if true, the matching term will be highlighted in the search result\n   * @return the result of the suggester\n   * @throws IOException f the is IO exception while reading data from the index\n   */\n  public List<LookupResult> lookup(CharSequence key, BooleanQuery contextQuery, int num, boolean allTermsRequired, boolean doHighlight) throws IOException {\n\n    if (searcherMgr == null) {\n      throw new IllegalStateException(\"suggester was not built\");\n    }\n\n    final BooleanClause.Occur occur;\n    if (allTermsRequired) {\n      occur = BooleanClause.Occur.MUST;\n    } else {\n      occur = BooleanClause.Occur.SHOULD;\n    }\n\n    BooleanQuery.Builder query;\n    Set<String> matchedTokens;\n    String prefixToken = null;\n\n    try (TokenStream ts = queryAnalyzer.tokenStream(\"\", new StringReader(key.toString()))) {\n      //long t0 = System.currentTimeMillis();\n      ts.reset();\n      final CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      final OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      String lastToken = null;\n      query = new BooleanQuery.Builder();\n      int maxEndOffset = -1;\n      matchedTokens = new HashSet<>();\n      while (ts.incrementToken()) {\n        if (lastToken != null) {  \n          matchedTokens.add(lastToken);\n          query.add(new TermQuery(new Term(TEXT_FIELD_NAME, lastToken)), occur);\n        }\n        lastToken = termAtt.toString();\n        if (lastToken != null) {\n          maxEndOffset = Math.max(maxEndOffset, offsetAtt.endOffset());\n        }\n      }\n      ts.end();\n\n      if (lastToken != null) {\n        Query lastQuery;\n        if (maxEndOffset == offsetAtt.endOffset()) {\n          // Use PrefixQuery (or the ngram equivalent) when\n          // there was no trailing discarded chars in the\n          // string (e.g. whitespace), so that if query does\n          // not end with a space we show prefix matches for\n          // that token:\n          lastQuery = getLastTokenQuery(lastToken);\n          prefixToken = lastToken;\n        } else {\n          // Use TermQuery for an exact match if there were\n          // trailing discarded chars (e.g. whitespace), so\n          // that if query ends with a space we only show\n          // exact matches for that term:\n          matchedTokens.add(lastToken);\n          lastQuery = new TermQuery(new Term(TEXT_FIELD_NAME, lastToken));\n        }\n        \n        if (lastQuery != null) {\n          query.add(lastQuery, occur);\n        }\n      }\n\n      if (contextQuery != null) {\n        boolean allMustNot = true;\n        for (BooleanClause clause : contextQuery.clauses()) {\n          if (clause.getOccur() != BooleanClause.Occur.MUST_NOT) {\n            allMustNot = false;\n            break;\n          }\n        }\n        \n        if (allMustNot) {\n          // All are MUST_NOT: add the contextQuery to the main query instead (not as sub-query)\n          for (BooleanClause clause : contextQuery.clauses()) {\n            query.add(clause);\n          }\n        } else if (allTermsRequired == false) {\n          // We must carefully upgrade the query clauses to MUST:\n          BooleanQuery.Builder newQuery = new BooleanQuery.Builder();\n          newQuery.add(query.build(), BooleanClause.Occur.MUST);\n          newQuery.add(contextQuery, BooleanClause.Occur.MUST);\n          query = newQuery;\n        } else {\n          // Add contextQuery as sub-query\n          query.add(contextQuery, BooleanClause.Occur.MUST);\n        }\n      }\n    }\n    \n    // TODO: we could allow blended sort here, combining\n    // weight w/ score.  Now we ignore score and sort only\n    // by weight:\n\n    Query finalQuery = finishQuery(query, allTermsRequired);\n\n    //System.out.println(\"finalQuery=\" + finalQuery);\n\n    // Sort by weight, descending:\n    TopFieldCollector c = TopFieldCollector.create(SORT, num, false);\n    List<LookupResult> results = null;\n    SearcherManager mgr;\n    IndexSearcher searcher;\n    synchronized (searcherMgrLock) {\n      mgr = searcherMgr; // acquire & release on same SearcherManager, via local reference\n      searcher = mgr.acquire();\n    }\n    try {\n      //System.out.println(\"got searcher=\" + searcher);\n      searcher.search(finalQuery, c);\n\n      TopFieldDocs hits = c.topDocs();\n\n      // Slower way if postings are not pre-sorted by weight:\n      // hits = searcher.search(query, null, num, SORT);\n      results = createResults(searcher, hits, num, key, doHighlight, matchedTokens, prefixToken);\n    } finally {\n      mgr.release(searcher);\n    }\n\n    //System.out.println((System.currentTimeMillis() - t0) + \" msec for infix suggest\");\n    //System.out.println(results);\n\n    return results;\n  }\n\n","sourceOld":"  /**\n   * This is an advanced method providing the capability to send down to the suggester any \n   * arbitrary lucene query to be used to filter the result of the suggester\n   * \n   * @param key the keyword being looked for\n   * @param contextQuery an arbitrary Lucene query to be used to filter the result of the suggester. {@link #addContextToQuery} could be used to build this contextQuery.\n   * @param num number of items to return\n   * @param allTermsRequired all searched terms must match or not\n   * @param doHighlight if true, the matching term will be highlighted in the search result\n   * @return the result of the suggester\n   * @throws IOException f the is IO exception while reading data from the index\n   */\n  public List<LookupResult> lookup(CharSequence key, BooleanQuery contextQuery, int num, boolean allTermsRequired, boolean doHighlight) throws IOException {\n\n    if (searcherMgr == null) {\n      throw new IllegalStateException(\"suggester was not built\");\n    }\n\n    final BooleanClause.Occur occur;\n    if (allTermsRequired) {\n      occur = BooleanClause.Occur.MUST;\n    } else {\n      occur = BooleanClause.Occur.SHOULD;\n    }\n\n    BooleanQuery.Builder query;\n    Set<String> matchedTokens;\n    String prefixToken = null;\n\n    try (TokenStream ts = queryAnalyzer.tokenStream(\"\", new StringReader(key.toString()))) {\n      //long t0 = System.currentTimeMillis();\n      ts.reset();\n      final CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      final OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      String lastToken = null;\n      query = new BooleanQuery.Builder();\n      int maxEndOffset = -1;\n      matchedTokens = new HashSet<>();\n      while (ts.incrementToken()) {\n        if (lastToken != null) {  \n          matchedTokens.add(lastToken);\n          query.add(new TermQuery(new Term(TEXT_FIELD_NAME, lastToken)), occur);\n        }\n        lastToken = termAtt.toString();\n        if (lastToken != null) {\n          maxEndOffset = Math.max(maxEndOffset, offsetAtt.endOffset());\n        }\n      }\n      ts.end();\n\n      if (lastToken != null) {\n        Query lastQuery;\n        if (maxEndOffset == offsetAtt.endOffset()) {\n          // Use PrefixQuery (or the ngram equivalent) when\n          // there was no trailing discarded chars in the\n          // string (e.g. whitespace), so that if query does\n          // not end with a space we show prefix matches for\n          // that token:\n          lastQuery = getLastTokenQuery(lastToken);\n          prefixToken = lastToken;\n        } else {\n          // Use TermQuery for an exact match if there were\n          // trailing discarded chars (e.g. whitespace), so\n          // that if query ends with a space we only show\n          // exact matches for that term:\n          matchedTokens.add(lastToken);\n          lastQuery = new TermQuery(new Term(TEXT_FIELD_NAME, lastToken));\n        }\n        \n        if (lastQuery != null) {\n          query.add(lastQuery, occur);\n        }\n      }\n\n      if (contextQuery != null) {\n        boolean allMustNot = true;\n        for (BooleanClause clause : contextQuery.clauses()) {\n          if (clause.getOccur() != BooleanClause.Occur.MUST_NOT) {\n            allMustNot = false;\n            break;\n          }\n        }\n        \n        if (allMustNot) {\n          // All are MUST_NOT: add the contextQuery to the main query instead (not as sub-query)\n          for (BooleanClause clause : contextQuery.clauses()) {\n            query.add(clause);\n          }\n        } else if (allTermsRequired == false) {\n          // We must carefully upgrade the query clauses to MUST:\n          BooleanQuery.Builder newQuery = new BooleanQuery.Builder();\n          newQuery.add(query.build(), BooleanClause.Occur.MUST);\n          newQuery.add(contextQuery, BooleanClause.Occur.MUST);\n          query = newQuery;\n        } else {\n          // Add contextQuery as sub-query\n          query.add(contextQuery, BooleanClause.Occur.MUST);\n        }\n      }\n    }\n    \n    // TODO: we could allow blended sort here, combining\n    // weight w/ score.  Now we ignore score and sort only\n    // by weight:\n\n    Query finalQuery = finishQuery(query, allTermsRequired);\n\n    //System.out.println(\"finalQuery=\" + finalQuery);\n\n    // Sort by weight, descending:\n    TopFieldCollector c = TopFieldCollector.create(SORT, num, false, false);\n    List<LookupResult> results = null;\n    SearcherManager mgr;\n    IndexSearcher searcher;\n    synchronized (searcherMgrLock) {\n      mgr = searcherMgr; // acquire & release on same SearcherManager, via local reference\n      searcher = mgr.acquire();\n    }\n    try {\n      //System.out.println(\"got searcher=\" + searcher);\n      searcher.search(finalQuery, c);\n\n      TopFieldDocs hits = c.topDocs();\n\n      // Slower way if postings are not pre-sorted by weight:\n      // hits = searcher.search(query, null, num, SORT);\n      results = createResults(searcher, hits, num, key, doHighlight, matchedTokens, prefixToken);\n    } finally {\n      mgr.release(searcher);\n    }\n\n    //System.out.println((System.currentTimeMillis() - t0) + \" msec for infix suggest\");\n    //System.out.println(results);\n\n    return results;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fe3c6364bed04a73ad0884b05401d80ce96027a9","date":1532961485,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#lookup(CharSequence,BooleanQuery,int,boolean,boolean).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#lookup(CharSequence,BooleanQuery,int,boolean,boolean).mjava","sourceNew":"  /**\n   * This is an advanced method providing the capability to send down to the suggester any \n   * arbitrary lucene query to be used to filter the result of the suggester\n   * \n   * @param key the keyword being looked for\n   * @param contextQuery an arbitrary Lucene query to be used to filter the result of the suggester. {@link #addContextToQuery} could be used to build this contextQuery.\n   * @param num number of items to return\n   * @param allTermsRequired all searched terms must match or not\n   * @param doHighlight if true, the matching term will be highlighted in the search result\n   * @return the result of the suggester\n   * @throws IOException f the is IO exception while reading data from the index\n   */\n  public List<LookupResult> lookup(CharSequence key, BooleanQuery contextQuery, int num, boolean allTermsRequired, boolean doHighlight) throws IOException {\n\n    if (searcherMgr == null) {\n      throw new IllegalStateException(\"suggester was not built\");\n    }\n\n    final BooleanClause.Occur occur;\n    if (allTermsRequired) {\n      occur = BooleanClause.Occur.MUST;\n    } else {\n      occur = BooleanClause.Occur.SHOULD;\n    }\n\n    BooleanQuery.Builder query;\n    Set<String> matchedTokens;\n    String prefixToken = null;\n\n    try (TokenStream ts = queryAnalyzer.tokenStream(\"\", new StringReader(key.toString()))) {\n      //long t0 = System.currentTimeMillis();\n      ts.reset();\n      final CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      final OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      String lastToken = null;\n      query = new BooleanQuery.Builder();\n      int maxEndOffset = -1;\n      matchedTokens = new HashSet<>();\n      while (ts.incrementToken()) {\n        if (lastToken != null) {  \n          matchedTokens.add(lastToken);\n          query.add(new TermQuery(new Term(TEXT_FIELD_NAME, lastToken)), occur);\n        }\n        lastToken = termAtt.toString();\n        if (lastToken != null) {\n          maxEndOffset = Math.max(maxEndOffset, offsetAtt.endOffset());\n        }\n      }\n      ts.end();\n\n      if (lastToken != null) {\n        Query lastQuery;\n        if (maxEndOffset == offsetAtt.endOffset()) {\n          // Use PrefixQuery (or the ngram equivalent) when\n          // there was no trailing discarded chars in the\n          // string (e.g. whitespace), so that if query does\n          // not end with a space we show prefix matches for\n          // that token:\n          lastQuery = getLastTokenQuery(lastToken);\n          prefixToken = lastToken;\n        } else {\n          // Use TermQuery for an exact match if there were\n          // trailing discarded chars (e.g. whitespace), so\n          // that if query ends with a space we only show\n          // exact matches for that term:\n          matchedTokens.add(lastToken);\n          lastQuery = new TermQuery(new Term(TEXT_FIELD_NAME, lastToken));\n        }\n        \n        if (lastQuery != null) {\n          query.add(lastQuery, occur);\n        }\n      }\n\n      if (contextQuery != null) {\n        boolean allMustNot = true;\n        for (BooleanClause clause : contextQuery.clauses()) {\n          if (clause.getOccur() != BooleanClause.Occur.MUST_NOT) {\n            allMustNot = false;\n            break;\n          }\n        }\n        \n        if (allMustNot) {\n          // All are MUST_NOT: add the contextQuery to the main query instead (not as sub-query)\n          for (BooleanClause clause : contextQuery.clauses()) {\n            query.add(clause);\n          }\n        } else if (allTermsRequired == false) {\n          // We must carefully upgrade the query clauses to MUST:\n          BooleanQuery.Builder newQuery = new BooleanQuery.Builder();\n          newQuery.add(query.build(), BooleanClause.Occur.MUST);\n          newQuery.add(contextQuery, BooleanClause.Occur.MUST);\n          query = newQuery;\n        } else {\n          // Add contextQuery as sub-query\n          query.add(contextQuery, BooleanClause.Occur.MUST);\n        }\n      }\n    }\n    \n    // TODO: we could allow blended sort here, combining\n    // weight w/ score.  Now we ignore score and sort only\n    // by weight:\n\n    Query finalQuery = finishQuery(query, allTermsRequired);\n\n    //System.out.println(\"finalQuery=\" + finalQuery);\n\n    // Sort by weight, descending:\n    TopFieldCollector c = TopFieldCollector.create(SORT, num, 1);\n    List<LookupResult> results = null;\n    SearcherManager mgr;\n    IndexSearcher searcher;\n    synchronized (searcherMgrLock) {\n      mgr = searcherMgr; // acquire & release on same SearcherManager, via local reference\n      searcher = mgr.acquire();\n    }\n    try {\n      //System.out.println(\"got searcher=\" + searcher);\n      searcher.search(finalQuery, c);\n\n      TopFieldDocs hits = c.topDocs();\n\n      // Slower way if postings are not pre-sorted by weight:\n      // hits = searcher.search(query, null, num, SORT);\n      results = createResults(searcher, hits, num, key, doHighlight, matchedTokens, prefixToken);\n    } finally {\n      mgr.release(searcher);\n    }\n\n    //System.out.println((System.currentTimeMillis() - t0) + \" msec for infix suggest\");\n    //System.out.println(results);\n\n    return results;\n  }\n\n","sourceOld":"  /**\n   * This is an advanced method providing the capability to send down to the suggester any \n   * arbitrary lucene query to be used to filter the result of the suggester\n   * \n   * @param key the keyword being looked for\n   * @param contextQuery an arbitrary Lucene query to be used to filter the result of the suggester. {@link #addContextToQuery} could be used to build this contextQuery.\n   * @param num number of items to return\n   * @param allTermsRequired all searched terms must match or not\n   * @param doHighlight if true, the matching term will be highlighted in the search result\n   * @return the result of the suggester\n   * @throws IOException f the is IO exception while reading data from the index\n   */\n  public List<LookupResult> lookup(CharSequence key, BooleanQuery contextQuery, int num, boolean allTermsRequired, boolean doHighlight) throws IOException {\n\n    if (searcherMgr == null) {\n      throw new IllegalStateException(\"suggester was not built\");\n    }\n\n    final BooleanClause.Occur occur;\n    if (allTermsRequired) {\n      occur = BooleanClause.Occur.MUST;\n    } else {\n      occur = BooleanClause.Occur.SHOULD;\n    }\n\n    BooleanQuery.Builder query;\n    Set<String> matchedTokens;\n    String prefixToken = null;\n\n    try (TokenStream ts = queryAnalyzer.tokenStream(\"\", new StringReader(key.toString()))) {\n      //long t0 = System.currentTimeMillis();\n      ts.reset();\n      final CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      final OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      String lastToken = null;\n      query = new BooleanQuery.Builder();\n      int maxEndOffset = -1;\n      matchedTokens = new HashSet<>();\n      while (ts.incrementToken()) {\n        if (lastToken != null) {  \n          matchedTokens.add(lastToken);\n          query.add(new TermQuery(new Term(TEXT_FIELD_NAME, lastToken)), occur);\n        }\n        lastToken = termAtt.toString();\n        if (lastToken != null) {\n          maxEndOffset = Math.max(maxEndOffset, offsetAtt.endOffset());\n        }\n      }\n      ts.end();\n\n      if (lastToken != null) {\n        Query lastQuery;\n        if (maxEndOffset == offsetAtt.endOffset()) {\n          // Use PrefixQuery (or the ngram equivalent) when\n          // there was no trailing discarded chars in the\n          // string (e.g. whitespace), so that if query does\n          // not end with a space we show prefix matches for\n          // that token:\n          lastQuery = getLastTokenQuery(lastToken);\n          prefixToken = lastToken;\n        } else {\n          // Use TermQuery for an exact match if there were\n          // trailing discarded chars (e.g. whitespace), so\n          // that if query ends with a space we only show\n          // exact matches for that term:\n          matchedTokens.add(lastToken);\n          lastQuery = new TermQuery(new Term(TEXT_FIELD_NAME, lastToken));\n        }\n        \n        if (lastQuery != null) {\n          query.add(lastQuery, occur);\n        }\n      }\n\n      if (contextQuery != null) {\n        boolean allMustNot = true;\n        for (BooleanClause clause : contextQuery.clauses()) {\n          if (clause.getOccur() != BooleanClause.Occur.MUST_NOT) {\n            allMustNot = false;\n            break;\n          }\n        }\n        \n        if (allMustNot) {\n          // All are MUST_NOT: add the contextQuery to the main query instead (not as sub-query)\n          for (BooleanClause clause : contextQuery.clauses()) {\n            query.add(clause);\n          }\n        } else if (allTermsRequired == false) {\n          // We must carefully upgrade the query clauses to MUST:\n          BooleanQuery.Builder newQuery = new BooleanQuery.Builder();\n          newQuery.add(query.build(), BooleanClause.Occur.MUST);\n          newQuery.add(contextQuery, BooleanClause.Occur.MUST);\n          query = newQuery;\n        } else {\n          // Add contextQuery as sub-query\n          query.add(contextQuery, BooleanClause.Occur.MUST);\n        }\n      }\n    }\n    \n    // TODO: we could allow blended sort here, combining\n    // weight w/ score.  Now we ignore score and sort only\n    // by weight:\n\n    Query finalQuery = finishQuery(query, allTermsRequired);\n\n    //System.out.println(\"finalQuery=\" + finalQuery);\n\n    // Sort by weight, descending:\n    TopFieldCollector c = TopFieldCollector.create(SORT, num, false);\n    List<LookupResult> results = null;\n    SearcherManager mgr;\n    IndexSearcher searcher;\n    synchronized (searcherMgrLock) {\n      mgr = searcherMgr; // acquire & release on same SearcherManager, via local reference\n      searcher = mgr.acquire();\n    }\n    try {\n      //System.out.println(\"got searcher=\" + searcher);\n      searcher.search(finalQuery, c);\n\n      TopFieldDocs hits = c.topDocs();\n\n      // Slower way if postings are not pre-sorted by weight:\n      // hits = searcher.search(query, null, num, SORT);\n      results = createResults(searcher, hits, num, key, doHighlight, matchedTokens, prefixToken);\n    } finally {\n      mgr.release(searcher);\n    }\n\n    //System.out.println((System.currentTimeMillis() - t0) + \" msec for infix suggest\");\n    //System.out.println(results);\n\n    return results;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"de0b5d8cac74be1676bcc2f805bc0d0630176659":["2305f39a86a068f1cee6fc5fbdfb760b153ac138","5cbf4928b28a4db03465b529b38a64ef29c91735"],"404d1ab7f6f396235047017c88d545fec15dafb7":["de0b5d8cac74be1676bcc2f805bc0d0630176659"],"04c370507e5521b2eb998530736f1c19b851ed5a":["81fff83bdb893c1471efd78f6a9a3ce4f98120b9"],"0ad30c6a479e764150a3316e57263319775f1df2":["5732fca7cb88bd0841ccc6f8c8901b9cc1a7ce76","3d33e731a93d4b57e662ff094f64f94a745422d4"],"5732fca7cb88bd0841ccc6f8c8901b9cc1a7ce76":["3f68d01cf19df971dcdcb05e30247f4ad7ec9747"],"5cbf4928b28a4db03465b529b38a64ef29c91735":["2305f39a86a068f1cee6fc5fbdfb760b153ac138"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["5732fca7cb88bd0841ccc6f8c8901b9cc1a7ce76","2305f39a86a068f1cee6fc5fbdfb760b153ac138"],"1d3f7ab1a502671bbdb03bcced21e764d2483221":["04c370507e5521b2eb998530736f1c19b851ed5a"],"d470c8182e92b264680e34081b75e70a9f2b3c89":["5732fca7cb88bd0841ccc6f8c8901b9cc1a7ce76","0ad30c6a479e764150a3316e57263319775f1df2"],"22aab7a3b640b0dba26cc5e9416bc7af93614b46":["fbe8fc0e68a5e2e7acce82ba880a982bd15cfab8"],"2305f39a86a068f1cee6fc5fbdfb760b153ac138":["d470c8182e92b264680e34081b75e70a9f2b3c89","3ddd7fe363a03b018dd62c48017d9997657a111e"],"3ddd7fe363a03b018dd62c48017d9997657a111e":["d470c8182e92b264680e34081b75e70a9f2b3c89"],"f03e4bed5023ec3ef93a771b8888cae991cf448d":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","de0b5d8cac74be1676bcc2f805bc0d0630176659"],"3f68d01cf19df971dcdcb05e30247f4ad7ec9747":["d2204dea8cf3dcfbffdf7b4d3459cf5287cc1c30"],"1aad05eeff7818b0833c02ac6b743aa72054963b":["de0b5d8cac74be1676bcc2f805bc0d0630176659","404d1ab7f6f396235047017c88d545fec15dafb7"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":["1aad05eeff7818b0833c02ac6b743aa72054963b","81fff83bdb893c1471efd78f6a9a3ce4f98120b9"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"81fff83bdb893c1471efd78f6a9a3ce4f98120b9":["1aad05eeff7818b0833c02ac6b743aa72054963b"],"d2204dea8cf3dcfbffdf7b4d3459cf5287cc1c30":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"3d33e731a93d4b57e662ff094f64f94a745422d4":["5732fca7cb88bd0841ccc6f8c8901b9cc1a7ce76","22aab7a3b640b0dba26cc5e9416bc7af93614b46"],"fbe8fc0e68a5e2e7acce82ba880a982bd15cfab8":["5732fca7cb88bd0841ccc6f8c8901b9cc1a7ce76"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["fe3c6364bed04a73ad0884b05401d80ce96027a9"],"fe3c6364bed04a73ad0884b05401d80ce96027a9":["1d3f7ab1a502671bbdb03bcced21e764d2483221"]},"commit2Childs":{"de0b5d8cac74be1676bcc2f805bc0d0630176659":["404d1ab7f6f396235047017c88d545fec15dafb7","f03e4bed5023ec3ef93a771b8888cae991cf448d","1aad05eeff7818b0833c02ac6b743aa72054963b"],"404d1ab7f6f396235047017c88d545fec15dafb7":["1aad05eeff7818b0833c02ac6b743aa72054963b"],"04c370507e5521b2eb998530736f1c19b851ed5a":["1d3f7ab1a502671bbdb03bcced21e764d2483221"],"0ad30c6a479e764150a3316e57263319775f1df2":["d470c8182e92b264680e34081b75e70a9f2b3c89"],"5cbf4928b28a4db03465b529b38a64ef29c91735":["de0b5d8cac74be1676bcc2f805bc0d0630176659"],"5732fca7cb88bd0841ccc6f8c8901b9cc1a7ce76":["0ad30c6a479e764150a3316e57263319775f1df2","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","d470c8182e92b264680e34081b75e70a9f2b3c89","3d33e731a93d4b57e662ff094f64f94a745422d4","fbe8fc0e68a5e2e7acce82ba880a982bd15cfab8"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["f03e4bed5023ec3ef93a771b8888cae991cf448d"],"2305f39a86a068f1cee6fc5fbdfb760b153ac138":["de0b5d8cac74be1676bcc2f805bc0d0630176659","5cbf4928b28a4db03465b529b38a64ef29c91735","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"1d3f7ab1a502671bbdb03bcced21e764d2483221":["fe3c6364bed04a73ad0884b05401d80ce96027a9"],"d470c8182e92b264680e34081b75e70a9f2b3c89":["2305f39a86a068f1cee6fc5fbdfb760b153ac138","3ddd7fe363a03b018dd62c48017d9997657a111e"],"22aab7a3b640b0dba26cc5e9416bc7af93614b46":["3d33e731a93d4b57e662ff094f64f94a745422d4"],"3ddd7fe363a03b018dd62c48017d9997657a111e":["2305f39a86a068f1cee6fc5fbdfb760b153ac138"],"f03e4bed5023ec3ef93a771b8888cae991cf448d":[],"3f68d01cf19df971dcdcb05e30247f4ad7ec9747":["5732fca7cb88bd0841ccc6f8c8901b9cc1a7ce76"],"1aad05eeff7818b0833c02ac6b743aa72054963b":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","81fff83bdb893c1471efd78f6a9a3ce4f98120b9"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["d2204dea8cf3dcfbffdf7b4d3459cf5287cc1c30"],"81fff83bdb893c1471efd78f6a9a3ce4f98120b9":["04c370507e5521b2eb998530736f1c19b851ed5a","0efc9f2cae117418f13ba9035f5e1d516ea7a2b5"],"d2204dea8cf3dcfbffdf7b4d3459cf5287cc1c30":["3f68d01cf19df971dcdcb05e30247f4ad7ec9747"],"3d33e731a93d4b57e662ff094f64f94a745422d4":["0ad30c6a479e764150a3316e57263319775f1df2"],"fbe8fc0e68a5e2e7acce82ba880a982bd15cfab8":["22aab7a3b640b0dba26cc5e9416bc7af93614b46"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"fe3c6364bed04a73ad0884b05401d80ce96027a9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["f03e4bed5023ec3ef93a771b8888cae991cf448d","0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}