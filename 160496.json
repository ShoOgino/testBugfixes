{"path":"solr/core/src/java/org/apache/solr/schema/IndexSchema#readAnalyzer(Node).mjava","commits":[{"id":"c903c3d15906a3da96b8c0c2fb704491005fdbdb","date":1453508227,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/schema/IndexSchema#readAnalyzer(Node).mjava","pathOld":"solr/src/java/org/apache/solr/schema/IndexSchema#readAnalyzer(Node).mjava","sourceNew":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n\n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass\n          (analyzerName).asSubclass(Analyzer.class);\n\n        try {\n          // first try to use a ctor with version parameter \n          // (needed for many new Analyzers that have no default one anymore)\n          Constructor<? extends Analyzer> cnstr = clazz.getConstructor(Version.class);\n          final String matchVersionStr = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n          final Version luceneMatchVersion = (matchVersionStr == null) ?\n            solrConfig.luceneMatchVersion : Config.parseLuceneVersionString(matchVersionStr);\n          if (luceneMatchVersion == null) {\n            throw new SolrException\n              ( SolrException.ErrorCode.SERVER_ERROR,\n                \"Configuration Error: Analyzer '\" + clazz.getName() +\n                \"' needs a 'luceneMatchVersion' parameter\");\n          }\n          return cnstr.newInstance(luceneMatchVersion);\n        } catch (NoSuchMethodException nsme) {\n          // otherwise use default ctor\n          return clazz.newInstance();\n        }\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: \"+analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    XPath xpath = XPathFactory.newInstance().newXPath();\n\n    // Load the CharFilters\n    // --------------------------------------------------------------------------------\n    final ArrayList<CharFilterFactory> charFilters = new ArrayList<CharFilterFactory>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>( \"[schema.xml] analyzer/charFilter\", false, false )\n    {\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, CharFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    charFilterLoader.load( solrConfig.getResourceLoader(), (NodeList)xpath.evaluate(\"./charFilter\", node, XPathConstants.NODESET) );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenizerFactory> tokenizers = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>( \"[schema.xml] analyzer/tokenizer\", false, false )\n    {\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n        // copy the luceneMatchVersion from config, if not set\n        if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n          params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n        plugin.init( params );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    tokenizerLoader.load( loader, (NodeList)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODESET) );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    \n\n    // Load the Filters\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenFilterFactory> filters = new ArrayList<TokenFilterFactory>();\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>( \"[schema.xml] analyzer/filter\", false, false )\n    {\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET) );\n\n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n        tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n","sourceOld":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n\n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass\n          (analyzerName).asSubclass(Analyzer.class);\n\n        try {\n          // first try to use a ctor with version parameter \n          // (needed for many new Analyzers that have no default one anymore)\n          Constructor<? extends Analyzer> cnstr = clazz.getConstructor(Version.class);\n          final String matchVersionStr = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n          final Version luceneMatchVersion = (matchVersionStr == null) ?\n            solrConfig.luceneMatchVersion : Config.parseLuceneVersionString(matchVersionStr);\n          if (luceneMatchVersion == null) {\n            throw new SolrException\n              ( SolrException.ErrorCode.SERVER_ERROR,\n                \"Configuration Error: Analyzer '\" + clazz.getName() +\n                \"' needs a 'luceneMatchVersion' parameter\");\n          }\n          return cnstr.newInstance(luceneMatchVersion);\n        } catch (NoSuchMethodException nsme) {\n          // otherwise use default ctor\n          return clazz.newInstance();\n        }\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: \"+analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    XPath xpath = XPathFactory.newInstance().newXPath();\n\n    // Load the CharFilters\n    // --------------------------------------------------------------------------------\n    final ArrayList<CharFilterFactory> charFilters = new ArrayList<CharFilterFactory>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>( \"[schema.xml] analyzer/charFilter\", false, false )\n    {\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, CharFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    charFilterLoader.load( solrConfig.getResourceLoader(), (NodeList)xpath.evaluate(\"./charFilter\", node, XPathConstants.NODESET) );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenizerFactory> tokenizers = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>( \"[schema.xml] analyzer/tokenizer\", false, false )\n    {\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n        // copy the luceneMatchVersion from config, if not set\n        if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n          params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n        plugin.init( params );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    tokenizerLoader.load( loader, (NodeList)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODESET) );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    \n\n    // Load the Filters\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenFilterFactory> filters = new ArrayList<TokenFilterFactory>();\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>( \"[schema.xml] analyzer/filter\", false, false )\n    {\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET) );\n\n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n        tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a258fbb26824fd104ed795e5d9033d2d040049ee","date":1453508252,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/schema/IndexSchema#readAnalyzer(Node).mjava","pathOld":"solr/src/java/org/apache/solr/schema/IndexSchema#readAnalyzer(Node).mjava","sourceNew":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n\n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass\n          (analyzerName).asSubclass(Analyzer.class);\n\n        try {\n          // first try to use a ctor with version parameter \n          // (needed for many new Analyzers that have no default one anymore)\n          Constructor<? extends Analyzer> cnstr = clazz.getConstructor(Version.class);\n          final String matchVersionStr = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n          final Version luceneMatchVersion = (matchVersionStr == null) ?\n            solrConfig.luceneMatchVersion : Config.parseLuceneVersionString(matchVersionStr);\n          if (luceneMatchVersion == null) {\n            throw new SolrException\n              ( SolrException.ErrorCode.SERVER_ERROR,\n                \"Configuration Error: Analyzer '\" + clazz.getName() +\n                \"' needs a 'luceneMatchVersion' parameter\");\n          }\n          return cnstr.newInstance(luceneMatchVersion);\n        } catch (NoSuchMethodException nsme) {\n          // otherwise use default ctor\n          return clazz.newInstance();\n        }\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: \"+analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    XPath xpath = XPathFactory.newInstance().newXPath();\n\n    // Load the CharFilters\n    // --------------------------------------------------------------------------------\n    final ArrayList<CharFilterFactory> charFilters = new ArrayList<CharFilterFactory>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>( \"[schema.xml] analyzer/charFilter\", false, false )\n    {\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, CharFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    charFilterLoader.load( solrConfig.getResourceLoader(), (NodeList)xpath.evaluate(\"./charFilter\", node, XPathConstants.NODESET) );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenizerFactory> tokenizers = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>( \"[schema.xml] analyzer/tokenizer\", false, false )\n    {\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n        // copy the luceneMatchVersion from config, if not set\n        if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n          params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n        plugin.init( params );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    tokenizerLoader.load( loader, (NodeList)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODESET) );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    \n\n    // Load the Filters\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenFilterFactory> filters = new ArrayList<TokenFilterFactory>();\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>( \"[schema.xml] analyzer/filter\", false, false )\n    {\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET) );\n\n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n        tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n","sourceOld":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n\n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass\n          (analyzerName).asSubclass(Analyzer.class);\n\n        try {\n          // first try to use a ctor with version parameter \n          // (needed for many new Analyzers that have no default one anymore)\n          Constructor<? extends Analyzer> cnstr = clazz.getConstructor(Version.class);\n          final String matchVersionStr = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n          final Version luceneMatchVersion = (matchVersionStr == null) ?\n            solrConfig.luceneMatchVersion : Config.parseLuceneVersionString(matchVersionStr);\n          if (luceneMatchVersion == null) {\n            throw new SolrException\n              ( SolrException.ErrorCode.SERVER_ERROR,\n                \"Configuration Error: Analyzer '\" + clazz.getName() +\n                \"' needs a 'luceneMatchVersion' parameter\");\n          }\n          return cnstr.newInstance(luceneMatchVersion);\n        } catch (NoSuchMethodException nsme) {\n          // otherwise use default ctor\n          return clazz.newInstance();\n        }\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: \"+analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    XPath xpath = XPathFactory.newInstance().newXPath();\n\n    // Load the CharFilters\n    // --------------------------------------------------------------------------------\n    final ArrayList<CharFilterFactory> charFilters = new ArrayList<CharFilterFactory>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>( \"[schema.xml] analyzer/charFilter\", false, false )\n    {\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, CharFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    charFilterLoader.load( solrConfig.getResourceLoader(), (NodeList)xpath.evaluate(\"./charFilter\", node, XPathConstants.NODESET) );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenizerFactory> tokenizers = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>( \"[schema.xml] analyzer/tokenizer\", false, false )\n    {\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n        // copy the luceneMatchVersion from config, if not set\n        if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n          params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n        plugin.init( params );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    tokenizerLoader.load( loader, (NodeList)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODESET) );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    \n\n    // Load the Filters\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenFilterFactory> filters = new ArrayList<TokenFilterFactory>();\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>( \"[schema.xml] analyzer/filter\", false, false )\n    {\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET) );\n\n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n        tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c26f00b574427b55127e869b935845554afde1fa","date":1310252513,"type":1,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/schema/IndexSchema#readAnalyzer(Node).mjava","pathOld":"solr/src/java/org/apache/solr/schema/IndexSchema#readAnalyzer(Node).mjava","sourceNew":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n\n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass\n          (analyzerName).asSubclass(Analyzer.class);\n\n        try {\n          // first try to use a ctor with version parameter \n          // (needed for many new Analyzers that have no default one anymore)\n          Constructor<? extends Analyzer> cnstr = clazz.getConstructor(Version.class);\n          final String matchVersionStr = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n          final Version luceneMatchVersion = (matchVersionStr == null) ?\n            solrConfig.luceneMatchVersion : Config.parseLuceneVersionString(matchVersionStr);\n          if (luceneMatchVersion == null) {\n            throw new SolrException\n              ( SolrException.ErrorCode.SERVER_ERROR,\n                \"Configuration Error: Analyzer '\" + clazz.getName() +\n                \"' needs a 'luceneMatchVersion' parameter\");\n          }\n          return cnstr.newInstance(luceneMatchVersion);\n        } catch (NoSuchMethodException nsme) {\n          // otherwise use default ctor\n          return clazz.newInstance();\n        }\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: \"+analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    XPath xpath = XPathFactory.newInstance().newXPath();\n\n    // Load the CharFilters\n    // --------------------------------------------------------------------------------\n    final ArrayList<CharFilterFactory> charFilters = new ArrayList<CharFilterFactory>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>( \"[schema.xml] analyzer/charFilter\", false, false )\n    {\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, CharFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    charFilterLoader.load( solrConfig.getResourceLoader(), (NodeList)xpath.evaluate(\"./charFilter\", node, XPathConstants.NODESET) );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenizerFactory> tokenizers = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>( \"[schema.xml] analyzer/tokenizer\", false, false )\n    {\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n        // copy the luceneMatchVersion from config, if not set\n        if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n          params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n        plugin.init( params );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    tokenizerLoader.load( loader, (NodeList)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODESET) );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    \n\n    // Load the Filters\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenFilterFactory> filters = new ArrayList<TokenFilterFactory>();\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>( \"[schema.xml] analyzer/filter\", false, false )\n    {\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET) );\n\n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n        tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n","sourceOld":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n\n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass\n          (analyzerName).asSubclass(Analyzer.class);\n\n        try {\n          // first try to use a ctor with version parameter \n          // (needed for many new Analyzers that have no default one anymore)\n          Constructor<? extends Analyzer> cnstr = clazz.getConstructor(Version.class);\n          final String matchVersionStr = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n          final Version luceneMatchVersion = (matchVersionStr == null) ?\n            solrConfig.luceneMatchVersion : Config.parseLuceneVersionString(matchVersionStr);\n          if (luceneMatchVersion == null) {\n            throw new SolrException\n              ( SolrException.ErrorCode.SERVER_ERROR,\n                \"Configuration Error: Analyzer '\" + clazz.getName() +\n                \"' needs a 'luceneMatchVersion' parameter\");\n          }\n          return cnstr.newInstance(luceneMatchVersion);\n        } catch (NoSuchMethodException nsme) {\n          // otherwise use default ctor\n          return clazz.newInstance();\n        }\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: \"+analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    XPath xpath = XPathFactory.newInstance().newXPath();\n\n    // Load the CharFilters\n    // --------------------------------------------------------------------------------\n    final ArrayList<CharFilterFactory> charFilters = new ArrayList<CharFilterFactory>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>( \"[schema.xml] analyzer/charFilter\", false, false )\n    {\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, CharFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    charFilterLoader.load( solrConfig.getResourceLoader(), (NodeList)xpath.evaluate(\"./charFilter\", node, XPathConstants.NODESET) );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenizerFactory> tokenizers = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>( \"[schema.xml] analyzer/tokenizer\", false, false )\n    {\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n        // copy the luceneMatchVersion from config, if not set\n        if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n          params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n        plugin.init( params );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    tokenizerLoader.load( loader, (NodeList)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODESET) );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    \n\n    // Load the Filters\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenFilterFactory> filters = new ArrayList<TokenFilterFactory>();\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>( \"[schema.xml] analyzer/filter\", false, false )\n    {\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET) );\n\n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n        tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f09ac0abea5345f77c4cf8d9f0d531da9139debc","date":1311103501,"type":5,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/schema/FieldTypePluginLoader#readAnalyzer(Node).mjava","pathOld":"solr/core/src/java/org/apache/solr/schema/IndexSchema#readAnalyzer(Node).mjava","sourceNew":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n                                \n    final SolrResourceLoader loader = schema.getResourceLoader();\n\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n    \n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass\n          (analyzerName).asSubclass(Analyzer.class);\n        \n        try {\n          // first try to use a ctor with version parameter \n          // (needed for many new Analyzers that have no default one anymore)\n          Constructor<? extends Analyzer> cnstr \n            = clazz.getConstructor(Version.class);\n          final String matchVersionStr \n            = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n          final Version luceneMatchVersion = (matchVersionStr == null) ?\n            schema.getDefaultLuceneMatchVersion() : \n            Config.parseLuceneVersionString(matchVersionStr);\n          if (luceneMatchVersion == null) {\n            throw new SolrException\n              ( SolrException.ErrorCode.SERVER_ERROR,\n                \"Configuration Error: Analyzer '\" + clazz.getName() +\n                \"' needs a 'luceneMatchVersion' parameter\");\n          }\n          return cnstr.newInstance(luceneMatchVersion);\n        } catch (NoSuchMethodException nsme) {\n          // otherwise use default ctor\n          return clazz.newInstance();\n        }\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: \"+analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    // Load the CharFilters\n\n    final ArrayList<CharFilterFactory> charFilters \n      = new ArrayList<CharFilterFactory>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>\n      ( \"[schema.xml] analyzer/charFilter\", false, false ) {\n\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, \n                       schema.getDefaultLuceneMatchVersion().toString());\n          plugin.init( params );\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, \n                                           CharFilterFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    charFilterLoader.load( loader, (NodeList)xpath.evaluate(\"./charFilter\",  node, XPathConstants.NODESET) );\n                            \n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n\n    final ArrayList<TokenizerFactory> tokenizers \n      = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>\n      ( \"[schema.xml] analyzer/tokenizer\", false, false ) {\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n\n        // copy the luceneMatchVersion from config, if not set\n        if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n          params.put(LUCENE_MATCH_VERSION_PARAM, \n                     schema.getDefaultLuceneMatchVersion().toString());\n        plugin.init( params );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    tokenizerLoader.load( loader, (NodeList)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODESET) );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    \n\n    // Load the Filters\n\n    final ArrayList<TokenFilterFactory> filters \n      = new ArrayList<TokenFilterFactory>();\n\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>( \"[schema.xml] analyzer/filter\", false, false )\n    {\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, \n                       schema.getDefaultLuceneMatchVersion().toString());\n          plugin.init( params );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET) );\n    \n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n                              tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n\n","sourceOld":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n\n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass\n          (analyzerName).asSubclass(Analyzer.class);\n\n        try {\n          // first try to use a ctor with version parameter \n          // (needed for many new Analyzers that have no default one anymore)\n          Constructor<? extends Analyzer> cnstr = clazz.getConstructor(Version.class);\n          final String matchVersionStr = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n          final Version luceneMatchVersion = (matchVersionStr == null) ?\n            solrConfig.luceneMatchVersion : Config.parseLuceneVersionString(matchVersionStr);\n          if (luceneMatchVersion == null) {\n            throw new SolrException\n              ( SolrException.ErrorCode.SERVER_ERROR,\n                \"Configuration Error: Analyzer '\" + clazz.getName() +\n                \"' needs a 'luceneMatchVersion' parameter\");\n          }\n          return cnstr.newInstance(luceneMatchVersion);\n        } catch (NoSuchMethodException nsme) {\n          // otherwise use default ctor\n          return clazz.newInstance();\n        }\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: \"+analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    XPath xpath = XPathFactory.newInstance().newXPath();\n\n    // Load the CharFilters\n    // --------------------------------------------------------------------------------\n    final ArrayList<CharFilterFactory> charFilters = new ArrayList<CharFilterFactory>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>( \"[schema.xml] analyzer/charFilter\", false, false )\n    {\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, CharFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    charFilterLoader.load( solrConfig.getResourceLoader(), (NodeList)xpath.evaluate(\"./charFilter\", node, XPathConstants.NODESET) );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenizerFactory> tokenizers = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>( \"[schema.xml] analyzer/tokenizer\", false, false )\n    {\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n        // copy the luceneMatchVersion from config, if not set\n        if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n          params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n        plugin.init( params );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    tokenizerLoader.load( loader, (NodeList)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODESET) );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    \n\n    // Load the Filters\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenFilterFactory> filters = new ArrayList<TokenFilterFactory>();\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>( \"[schema.xml] analyzer/filter\", false, false )\n    {\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET) );\n\n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n        tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"c26f00b574427b55127e869b935845554afde1fa":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","c903c3d15906a3da96b8c0c2fb704491005fdbdb"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a258fbb26824fd104ed795e5d9033d2d040049ee":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["f09ac0abea5345f77c4cf8d9f0d531da9139debc"],"f09ac0abea5345f77c4cf8d9f0d531da9139debc":["c26f00b574427b55127e869b935845554afde1fa"]},"commit2Childs":{"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["c26f00b574427b55127e869b935845554afde1fa"],"c26f00b574427b55127e869b935845554afde1fa":["f09ac0abea5345f77c4cf8d9f0d531da9139debc"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c903c3d15906a3da96b8c0c2fb704491005fdbdb","c26f00b574427b55127e869b935845554afde1fa","a258fbb26824fd104ed795e5d9033d2d040049ee"],"a258fbb26824fd104ed795e5d9033d2d040049ee":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"f09ac0abea5345f77c4cf8d9f0d531da9139debc":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["a258fbb26824fd104ed795e5d9033d2d040049ee","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}