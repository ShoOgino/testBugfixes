{"path":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","commits":[{"id":"bd0ef6574805f3cb9880e0983b7548a6aa933508","date":1315345052,"type":0,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    String id[] = params.getParams(\"id\");\n    String ids[] = params.getParams(\"ids\");\n\n    if (id == null && ids == null) {\n      return;\n    }\n\n    String[] allIds = id==null ? new String[0] : id;\n\n    if (ids != null) {\n      List<String> lst = new ArrayList<String>();\n      for (String s : allIds) {\n        lst.add(s);\n      }\n      for (String idList : ids) {\n        lst.addAll( StrUtils.splitSmart(idList, \",\", true) );\n      }\n      allIds = lst.toArray(new String[lst.size()]);\n    }\n\n    SchemaField idField = req.getSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = req.getCore().getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRef idBytes = new BytesRef();\n     for (String idStr : allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes);\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0);\n           switch (oper) {\n             case UpdateLog.ADD:\n              docList.add(toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), req.getSchema()));\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder =  req.getCore().getNewestSearcher(false);\n         searcher = searcherHolder.get();\n       }\n\n       int docid = searcher.getFirstMatch(new Term(idField.getName(), idBytes));\n       if (docid < 0) continue;\n       Document luceneDocument = searcher.doc(docid);\n       docList.add(toSolrDoc(luceneDocument,  req.getSchema()));\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n\n   // if the client specified a single id=foo, then use \"doc\":{\n   // otherwise use a standard doclist\n\n   if (ids ==  null && allIds.length <= 1) {\n     // if the doc was not found, then use a value of null.\n     rsp.add(\"doc\", docList.size() > 0 ? docList.get(0) : null);\n   } else {\n     docList.setNumFound(docList.size());\n     rsp.add(\"response\", docList);\n   }\n\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["e511b092029d56e0d4e30204fba8509c1c2647b6","29918ccc4b27ebd261d8446761e5e02666abe893","7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50","e99829242bceda4cf974ec0eb5d82d713615b3da","4c58bab35e821e15dc6b8669d2f15c2e3cc6d9ce"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"29918ccc4b27ebd261d8446761e5e02666abe893","date":1318552434,"type":3,"author":"Ryan McKinley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    String id[] = params.getParams(\"id\");\n    String ids[] = params.getParams(\"ids\");\n\n    if (id == null && ids == null) {\n      return;\n    }\n\n    String[] allIds = id==null ? new String[0] : id;\n\n    if (ids != null) {\n      List<String> lst = new ArrayList<String>();\n      for (String s : allIds) {\n        lst.add(s);\n      }\n      for (String idList : ids) {\n        lst.addAll( StrUtils.splitSmart(idList, \",\", true) );\n      }\n      allIds = lst.toArray(new String[lst.size()]);\n    }\n\n    SchemaField idField = req.getSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = req.getCore().getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n\n    DocTransformer transformer = rsp.getReturnFields().getTransformer();\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRef idBytes = new BytesRef();\n     for (String idStr : allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes);\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0);\n           switch (oper) {\n             case UpdateLog.ADD:\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), req.getSchema());\n               if(transformer!=null) {\n                 transformer.transform(doc, -1); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder =  req.getCore().getNewestSearcher(false);\n         searcher = searcherHolder.get();\n       }\n\n       int docid = searcher.getFirstMatch(new Term(idField.getName(), idBytes));\n       if (docid < 0) continue;\n       Document luceneDocument = searcher.doc(docid);\n       SolrDocument doc = toSolrDoc(luceneDocument,  req.getSchema());\n       if( transformer != null ) {\n         transformer.transform(doc, docid);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n\n   // if the client specified a single id=foo, then use \"doc\":{\n   // otherwise use a standard doclist\n\n   if (ids ==  null && allIds.length <= 1) {\n     // if the doc was not found, then use a value of null.\n     rsp.add(\"doc\", docList.size() > 0 ? docList.get(0) : null);\n   } else {\n     docList.setNumFound(docList.size());\n     rsp.add(\"response\", docList);\n   }\n\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    String id[] = params.getParams(\"id\");\n    String ids[] = params.getParams(\"ids\");\n\n    if (id == null && ids == null) {\n      return;\n    }\n\n    String[] allIds = id==null ? new String[0] : id;\n\n    if (ids != null) {\n      List<String> lst = new ArrayList<String>();\n      for (String s : allIds) {\n        lst.add(s);\n      }\n      for (String idList : ids) {\n        lst.addAll( StrUtils.splitSmart(idList, \",\", true) );\n      }\n      allIds = lst.toArray(new String[lst.size()]);\n    }\n\n    SchemaField idField = req.getSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = req.getCore().getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRef idBytes = new BytesRef();\n     for (String idStr : allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes);\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0);\n           switch (oper) {\n             case UpdateLog.ADD:\n              docList.add(toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), req.getSchema()));\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder =  req.getCore().getNewestSearcher(false);\n         searcher = searcherHolder.get();\n       }\n\n       int docid = searcher.getFirstMatch(new Term(idField.getName(), idBytes));\n       if (docid < 0) continue;\n       Document luceneDocument = searcher.doc(docid);\n       docList.add(toSolrDoc(luceneDocument,  req.getSchema()));\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n\n   // if the client specified a single id=foo, then use \"doc\":{\n   // otherwise use a standard doclist\n\n   if (ids ==  null && allIds.length <= 1) {\n     // if the doc was not found, then use a value of null.\n     rsp.add(\"doc\", docList.size() > 0 ? docList.get(0) : null);\n   } else {\n     docList.setNumFound(docList.size());\n     rsp.add(\"response\", docList);\n   }\n\n  }\n\n","bugFix":["bd0ef6574805f3cb9880e0983b7548a6aa933508"],"bugIntro":["136796946c32863f11b97ebec6b4091cdfe3a20b"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7a3554ff15950ad0e3bcbb4e4e2ddb45b0b0f27e","date":1320267737,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    String id[] = params.getParams(\"id\");\n    String ids[] = params.getParams(\"ids\");\n\n    if (id == null && ids == null) {\n      return;\n    }\n\n    String[] allIds = id==null ? new String[0] : id;\n\n    if (ids != null) {\n      List<String> lst = new ArrayList<String>();\n      for (String s : allIds) {\n        lst.add(s);\n      }\n      for (String idList : ids) {\n        lst.addAll( StrUtils.splitSmart(idList, \",\", true) );\n      }\n      allIds = lst.toArray(new String[lst.size()]);\n    }\n\n    SchemaField idField = req.getSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = req.getCore().getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n\n    DocTransformer transformer = rsp.getReturnFields().getTransformer();\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRef idBytes = new BytesRef();\n     for (String idStr : allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes);\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0);\n           switch (oper) {\n             case UpdateLog.ADD:\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), req.getSchema());\n               if(transformer!=null) {\n                 transformer.transform(doc, -1); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder =  req.getCore().getNewestSearcher(false);\n         searcher = searcherHolder.get();\n       }\n\n       // SolrCore.verbose(\"RealTimeGet using searcher \", searcher);\n\n       int docid = searcher.getFirstMatch(new Term(idField.getName(), idBytes));\n       if (docid < 0) continue;\n       Document luceneDocument = searcher.doc(docid);\n       SolrDocument doc = toSolrDoc(luceneDocument,  req.getSchema());\n       if( transformer != null ) {\n         transformer.transform(doc, docid);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n\n   // if the client specified a single id=foo, then use \"doc\":{\n   // otherwise use a standard doclist\n\n   if (ids ==  null && allIds.length <= 1) {\n     // if the doc was not found, then use a value of null.\n     rsp.add(\"doc\", docList.size() > 0 ? docList.get(0) : null);\n   } else {\n     docList.setNumFound(docList.size());\n     rsp.add(\"response\", docList);\n   }\n\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    String id[] = params.getParams(\"id\");\n    String ids[] = params.getParams(\"ids\");\n\n    if (id == null && ids == null) {\n      return;\n    }\n\n    String[] allIds = id==null ? new String[0] : id;\n\n    if (ids != null) {\n      List<String> lst = new ArrayList<String>();\n      for (String s : allIds) {\n        lst.add(s);\n      }\n      for (String idList : ids) {\n        lst.addAll( StrUtils.splitSmart(idList, \",\", true) );\n      }\n      allIds = lst.toArray(new String[lst.size()]);\n    }\n\n    SchemaField idField = req.getSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = req.getCore().getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n\n    DocTransformer transformer = rsp.getReturnFields().getTransformer();\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRef idBytes = new BytesRef();\n     for (String idStr : allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes);\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0);\n           switch (oper) {\n             case UpdateLog.ADD:\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), req.getSchema());\n               if(transformer!=null) {\n                 transformer.transform(doc, -1); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder =  req.getCore().getNewestSearcher(false);\n         searcher = searcherHolder.get();\n       }\n\n       int docid = searcher.getFirstMatch(new Term(idField.getName(), idBytes));\n       if (docid < 0) continue;\n       Document luceneDocument = searcher.doc(docid);\n       SolrDocument doc = toSolrDoc(luceneDocument,  req.getSchema());\n       if( transformer != null ) {\n         transformer.transform(doc, docid);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n\n   // if the client specified a single id=foo, then use \"doc\":{\n   // otherwise use a standard doclist\n\n   if (ids ==  null && allIds.length <= 1) {\n     // if the doc was not found, then use a value of null.\n     rsp.add(\"doc\", docList.size() > 0 ? docList.get(0) : null);\n   } else {\n     docList.setNumFound(docList.size());\n     rsp.add(\"response\", docList);\n   }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b68df8b95f3ea758a8dc21cb20a50a01db973e8e","date":1321650433,"type":3,"author":"Grant Ingersoll","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    String id[] = params.getParams(\"id\");\n    String ids[] = params.getParams(\"ids\");\n\n    if (id == null && ids == null) {\n      return;\n    }\n\n    String[] allIds = id==null ? new String[0] : id;\n\n    if (ids != null) {\n      List<String> lst = new ArrayList<String>();\n      for (String s : allIds) {\n        lst.add(s);\n      }\n      for (String idList : ids) {\n        lst.addAll( StrUtils.splitSmart(idList, \",\", true) );\n      }\n      allIds = lst.toArray(new String[lst.size()]);\n    }\n\n    SchemaField idField = req.getSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = req.getCore().getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n\n    DocTransformer transformer = rsp.getReturnFields().getTransformer();\n    if (transformer != null) {\n      TransformContext context = new TransformContext();\n      context.req = req;\n      transformer.setContext(context);\n    }\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRef idBytes = new BytesRef();\n     for (String idStr : allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes);\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0);\n           switch (oper) {\n             case UpdateLog.ADD:\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), req.getSchema());\n               if(transformer!=null) {\n                 transformer.transform(doc, -1); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder =  req.getCore().getNewestSearcher(false);\n         searcher = searcherHolder.get();\n       }\n\n       // SolrCore.verbose(\"RealTimeGet using searcher \", searcher);\n\n       int docid = searcher.getFirstMatch(new Term(idField.getName(), idBytes));\n       if (docid < 0) continue;\n       Document luceneDocument = searcher.doc(docid);\n       SolrDocument doc = toSolrDoc(luceneDocument,  req.getSchema());\n       if( transformer != null ) {\n         transformer.transform(doc, docid);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n\n   // if the client specified a single id=foo, then use \"doc\":{\n   // otherwise use a standard doclist\n\n   if (ids ==  null && allIds.length <= 1) {\n     // if the doc was not found, then use a value of null.\n     rsp.add(\"doc\", docList.size() > 0 ? docList.get(0) : null);\n   } else {\n     docList.setNumFound(docList.size());\n     rsp.add(\"response\", docList);\n   }\n\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    String id[] = params.getParams(\"id\");\n    String ids[] = params.getParams(\"ids\");\n\n    if (id == null && ids == null) {\n      return;\n    }\n\n    String[] allIds = id==null ? new String[0] : id;\n\n    if (ids != null) {\n      List<String> lst = new ArrayList<String>();\n      for (String s : allIds) {\n        lst.add(s);\n      }\n      for (String idList : ids) {\n        lst.addAll( StrUtils.splitSmart(idList, \",\", true) );\n      }\n      allIds = lst.toArray(new String[lst.size()]);\n    }\n\n    SchemaField idField = req.getSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = req.getCore().getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n\n    DocTransformer transformer = rsp.getReturnFields().getTransformer();\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRef idBytes = new BytesRef();\n     for (String idStr : allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes);\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0);\n           switch (oper) {\n             case UpdateLog.ADD:\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), req.getSchema());\n               if(transformer!=null) {\n                 transformer.transform(doc, -1); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder =  req.getCore().getNewestSearcher(false);\n         searcher = searcherHolder.get();\n       }\n\n       // SolrCore.verbose(\"RealTimeGet using searcher \", searcher);\n\n       int docid = searcher.getFirstMatch(new Term(idField.getName(), idBytes));\n       if (docid < 0) continue;\n       Document luceneDocument = searcher.doc(docid);\n       SolrDocument doc = toSolrDoc(luceneDocument,  req.getSchema());\n       if( transformer != null ) {\n         transformer.transform(doc, docid);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n\n   // if the client specified a single id=foo, then use \"doc\":{\n   // otherwise use a standard doclist\n\n   if (ids ==  null && allIds.length <= 1) {\n     // if the doc was not found, then use a value of null.\n     rsp.add(\"doc\", docList.size() > 0 ? docList.get(0) : null);\n   } else {\n     docList.setNumFound(docList.size());\n     rsp.add(\"response\", docList);\n   }\n\n  }\n\n","bugFix":null,"bugIntro":["136796946c32863f11b97ebec6b4091cdfe3a20b"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2c007e7c4cf8c55bc2a5884e315123afaaeec87f","date":1327520966,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    String val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      processGetUpdates(rb);\n      return;\n    }\n\n    String id[] = params.getParams(\"id\");\n    String ids[] = params.getParams(\"ids\");\n\n    if (id == null && ids == null) {\n      return;\n    }\n\n    String[] allIds = id==null ? new String[0] : id;\n\n    if (ids != null) {\n      List<String> lst = new ArrayList<String>();\n      for (String s : allIds) {\n        lst.add(s);\n      }\n      for (String idList : ids) {\n        lst.addAll( StrUtils.splitSmart(idList, \",\", true) );\n      }\n      allIds = lst.toArray(new String[lst.size()]);\n    }\n\n    SchemaField idField = req.getSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = req.getCore().getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n\n    DocTransformer transformer = rsp.getReturnFields().getTransformer();\n    if (transformer != null) {\n      TransformContext context = new TransformContext();\n      context.req = req;\n      transformer.setContext(context);\n    }\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRef idBytes = new BytesRef();\n     for (String idStr : allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes);\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0);\n           switch (oper) {\n             case UpdateLog.ADD:\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), req.getSchema());\n               if(transformer!=null) {\n                 transformer.transform(doc, -1); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = req.getCore().getRealtimeSearcher();\n         searcher = searcherHolder.get();\n       }\n\n       // SolrCore.verbose(\"RealTimeGet using searcher \", searcher);\n\n       int docid = searcher.getFirstMatch(new Term(idField.getName(), idBytes));\n       if (docid < 0) continue;\n       Document luceneDocument = searcher.doc(docid);\n       SolrDocument doc = toSolrDoc(luceneDocument,  req.getSchema());\n       if( transformer != null ) {\n         transformer.transform(doc, docid);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n\n   // if the client specified a single id=foo, then use \"doc\":{\n   // otherwise use a standard doclist\n\n   if (ids ==  null && allIds.length <= 1) {\n     // if the doc was not found, then use a value of null.\n     rsp.add(\"doc\", docList.size() > 0 ? docList.get(0) : null);\n   } else {\n     docList.setNumFound(docList.size());\n     rsp.add(\"response\", docList);\n   }\n\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    String id[] = params.getParams(\"id\");\n    String ids[] = params.getParams(\"ids\");\n\n    if (id == null && ids == null) {\n      return;\n    }\n\n    String[] allIds = id==null ? new String[0] : id;\n\n    if (ids != null) {\n      List<String> lst = new ArrayList<String>();\n      for (String s : allIds) {\n        lst.add(s);\n      }\n      for (String idList : ids) {\n        lst.addAll( StrUtils.splitSmart(idList, \",\", true) );\n      }\n      allIds = lst.toArray(new String[lst.size()]);\n    }\n\n    SchemaField idField = req.getSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = req.getCore().getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n\n    DocTransformer transformer = rsp.getReturnFields().getTransformer();\n    if (transformer != null) {\n      TransformContext context = new TransformContext();\n      context.req = req;\n      transformer.setContext(context);\n    }\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRef idBytes = new BytesRef();\n     for (String idStr : allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes);\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0);\n           switch (oper) {\n             case UpdateLog.ADD:\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), req.getSchema());\n               if(transformer!=null) {\n                 transformer.transform(doc, -1); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder =  req.getCore().getNewestSearcher(false);\n         searcher = searcherHolder.get();\n       }\n\n       // SolrCore.verbose(\"RealTimeGet using searcher \", searcher);\n\n       int docid = searcher.getFirstMatch(new Term(idField.getName(), idBytes));\n       if (docid < 0) continue;\n       Document luceneDocument = searcher.doc(docid);\n       SolrDocument doc = toSolrDoc(luceneDocument,  req.getSchema());\n       if( transformer != null ) {\n         transformer.transform(doc, docid);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n\n   // if the client specified a single id=foo, then use \"doc\":{\n   // otherwise use a standard doclist\n\n   if (ids ==  null && allIds.length <= 1) {\n     // if the doc was not found, then use a value of null.\n     rsp.add(\"doc\", docList.size() > 0 ? docList.get(0) : null);\n   } else {\n     docList.setNumFound(docList.size());\n     rsp.add(\"response\", docList);\n   }\n\n  }\n\n","bugFix":null,"bugIntro":["e511b092029d56e0d4e30204fba8509c1c2647b6"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d","date":1327523564,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    String val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      processGetUpdates(rb);\n      return;\n    }\n\n    String id[] = params.getParams(\"id\");\n    String ids[] = params.getParams(\"ids\");\n\n    if (id == null && ids == null) {\n      return;\n    }\n\n    String[] allIds = id==null ? new String[0] : id;\n\n    if (ids != null) {\n      List<String> lst = new ArrayList<String>();\n      for (String s : allIds) {\n        lst.add(s);\n      }\n      for (String idList : ids) {\n        lst.addAll( StrUtils.splitSmart(idList, \",\", true) );\n      }\n      allIds = lst.toArray(new String[lst.size()]);\n    }\n\n    SchemaField idField = req.getSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = req.getCore().getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n\n    DocTransformer transformer = rsp.getReturnFields().getTransformer();\n    if (transformer != null) {\n      TransformContext context = new TransformContext();\n      context.req = req;\n      transformer.setContext(context);\n    }\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRef idBytes = new BytesRef();\n     for (String idStr : allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes);\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0);\n           switch (oper) {\n             case UpdateLog.ADD:\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), req.getSchema());\n               if(transformer!=null) {\n                 transformer.transform(doc, -1); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = req.getCore().getRealtimeSearcher();\n         searcher = searcherHolder.get();\n       }\n\n       // SolrCore.verbose(\"RealTimeGet using searcher \", searcher);\n\n       int docid = searcher.getFirstMatch(new Term(idField.getName(), idBytes));\n       if (docid < 0) continue;\n       Document luceneDocument = searcher.doc(docid);\n       SolrDocument doc = toSolrDoc(luceneDocument,  req.getSchema());\n       if( transformer != null ) {\n         transformer.transform(doc, docid);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n\n   // if the client specified a single id=foo, then use \"doc\":{\n   // otherwise use a standard doclist\n\n   if (ids ==  null && allIds.length <= 1) {\n     // if the doc was not found, then use a value of null.\n     rsp.add(\"doc\", docList.size() > 0 ? docList.get(0) : null);\n   } else {\n     docList.setNumFound(docList.size());\n     rsp.add(\"response\", docList);\n   }\n\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    String id[] = params.getParams(\"id\");\n    String ids[] = params.getParams(\"ids\");\n\n    if (id == null && ids == null) {\n      return;\n    }\n\n    String[] allIds = id==null ? new String[0] : id;\n\n    if (ids != null) {\n      List<String> lst = new ArrayList<String>();\n      for (String s : allIds) {\n        lst.add(s);\n      }\n      for (String idList : ids) {\n        lst.addAll( StrUtils.splitSmart(idList, \",\", true) );\n      }\n      allIds = lst.toArray(new String[lst.size()]);\n    }\n\n    SchemaField idField = req.getSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = req.getCore().getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n\n    DocTransformer transformer = rsp.getReturnFields().getTransformer();\n    if (transformer != null) {\n      TransformContext context = new TransformContext();\n      context.req = req;\n      transformer.setContext(context);\n    }\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRef idBytes = new BytesRef();\n     for (String idStr : allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes);\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0);\n           switch (oper) {\n             case UpdateLog.ADD:\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), req.getSchema());\n               if(transformer!=null) {\n                 transformer.transform(doc, -1); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder =  req.getCore().getNewestSearcher(false);\n         searcher = searcherHolder.get();\n       }\n\n       // SolrCore.verbose(\"RealTimeGet using searcher \", searcher);\n\n       int docid = searcher.getFirstMatch(new Term(idField.getName(), idBytes));\n       if (docid < 0) continue;\n       Document luceneDocument = searcher.doc(docid);\n       SolrDocument doc = toSolrDoc(luceneDocument,  req.getSchema());\n       if( transformer != null ) {\n         transformer.transform(doc, docid);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n\n   // if the client specified a single id=foo, then use \"doc\":{\n   // otherwise use a standard doclist\n\n   if (ids ==  null && allIds.length <= 1) {\n     // if the doc was not found, then use a value of null.\n     rsp.add(\"doc\", docList.size() > 0 ? docList.get(0) : null);\n   } else {\n     docList.setNumFound(docList.size());\n     rsp.add(\"response\", docList);\n   }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0d22ac6a4146774c1bc8400160fc0b6150294e92","date":1327528604,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    String val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      processGetUpdates(rb);\n      return;\n    }\n\n    String id[] = params.getParams(\"id\");\n    String ids[] = params.getParams(\"ids\");\n\n    if (id == null && ids == null) {\n      return;\n    }\n\n    String[] allIds = id==null ? new String[0] : id;\n\n    if (ids != null) {\n      List<String> lst = new ArrayList<String>();\n      for (String s : allIds) {\n        lst.add(s);\n      }\n      for (String idList : ids) {\n        lst.addAll( StrUtils.splitSmart(idList, \",\", true) );\n      }\n      allIds = lst.toArray(new String[lst.size()]);\n    }\n\n    SchemaField idField = req.getSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = req.getCore().getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n\n    DocTransformer transformer = rsp.getReturnFields().getTransformer();\n    if (transformer != null) {\n      TransformContext context = new TransformContext();\n      context.req = req;\n      transformer.setContext(context);\n    }\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRef idBytes = new BytesRef();\n     for (String idStr : allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes);\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0);\n           switch (oper) {\n             case UpdateLog.ADD:\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), req.getSchema());\n               if(transformer!=null) {\n                 transformer.transform(doc, -1); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = req.getCore().getRealtimeSearcher();\n         searcher = searcherHolder.get();\n       }\n\n       // SolrCore.verbose(\"RealTimeGet using searcher \", searcher);\n\n       int docid = searcher.getFirstMatch(new Term(idField.getName(), idBytes));\n       if (docid < 0) continue;\n       Document luceneDocument = searcher.doc(docid);\n       SolrDocument doc = toSolrDoc(luceneDocument,  req.getSchema());\n       if( transformer != null ) {\n         transformer.transform(doc, docid);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n\n   // if the client specified a single id=foo, then use \"doc\":{\n   // otherwise use a standard doclist\n\n   if (ids ==  null && allIds.length <= 1) {\n     // if the doc was not found, then use a value of null.\n     rsp.add(\"doc\", docList.size() > 0 ? docList.get(0) : null);\n   } else {\n     docList.setNumFound(docList.size());\n     rsp.add(\"response\", docList);\n   }\n\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    String id[] = params.getParams(\"id\");\n    String ids[] = params.getParams(\"ids\");\n\n    if (id == null && ids == null) {\n      return;\n    }\n\n    String[] allIds = id==null ? new String[0] : id;\n\n    if (ids != null) {\n      List<String> lst = new ArrayList<String>();\n      for (String s : allIds) {\n        lst.add(s);\n      }\n      for (String idList : ids) {\n        lst.addAll( StrUtils.splitSmart(idList, \",\", true) );\n      }\n      allIds = lst.toArray(new String[lst.size()]);\n    }\n\n    SchemaField idField = req.getSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = req.getCore().getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n\n    DocTransformer transformer = rsp.getReturnFields().getTransformer();\n    if (transformer != null) {\n      TransformContext context = new TransformContext();\n      context.req = req;\n      transformer.setContext(context);\n    }\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRef idBytes = new BytesRef();\n     for (String idStr : allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes);\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0);\n           switch (oper) {\n             case UpdateLog.ADD:\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), req.getSchema());\n               if(transformer!=null) {\n                 transformer.transform(doc, -1); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder =  req.getCore().getNewestSearcher(false);\n         searcher = searcherHolder.get();\n       }\n\n       // SolrCore.verbose(\"RealTimeGet using searcher \", searcher);\n\n       int docid = searcher.getFirstMatch(new Term(idField.getName(), idBytes));\n       if (docid < 0) continue;\n       Document luceneDocument = searcher.doc(docid);\n       SolrDocument doc = toSolrDoc(luceneDocument,  req.getSchema());\n       if( transformer != null ) {\n         transformer.transform(doc, docid);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n\n   // if the client specified a single id=foo, then use \"doc\":{\n   // otherwise use a standard doclist\n\n   if (ids ==  null && allIds.length <= 1) {\n     // if the doc was not found, then use a value of null.\n     rsp.add(\"doc\", docList.size() > 0 ? docList.get(0) : null);\n   } else {\n     docList.setNumFound(docList.size());\n     rsp.add(\"response\", docList);\n   }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e99829242bceda4cf974ec0eb5d82d713615b3da","date":1337646971,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    String val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      processGetUpdates(rb);\n      return;\n    }\n\n    String id[] = params.getParams(\"id\");\n    String ids[] = params.getParams(\"ids\");\n\n    if (id == null && ids == null) {\n      return;\n    }\n\n    String[] allIds = id==null ? new String[0] : id;\n\n    if (ids != null) {\n      List<String> lst = new ArrayList<String>();\n      for (String s : allIds) {\n        lst.add(s);\n      }\n      for (String idList : ids) {\n        lst.addAll( StrUtils.splitSmart(idList, \",\", true) );\n      }\n      allIds = lst.toArray(new String[lst.size()]);\n    }\n\n    SchemaField idField = req.getSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = req.getCore().getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n\n    DocTransformer transformer = rsp.getReturnFields().getTransformer();\n    if (transformer != null) {\n      TransformContext context = new TransformContext();\n      context.req = req;\n      transformer.setContext(context);\n    }\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRef idBytes = new BytesRef();\n     for (String idStr : allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes);\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.ADD:\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), req.getSchema());\n               if(transformer!=null) {\n                 transformer.transform(doc, -1); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = req.getCore().getRealtimeSearcher();\n         searcher = searcherHolder.get();\n       }\n\n       // SolrCore.verbose(\"RealTimeGet using searcher \", searcher);\n\n       int docid = searcher.getFirstMatch(new Term(idField.getName(), idBytes));\n       if (docid < 0) continue;\n       Document luceneDocument = searcher.doc(docid);\n       SolrDocument doc = toSolrDoc(luceneDocument,  req.getSchema());\n       if( transformer != null ) {\n         transformer.transform(doc, docid);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n\n   // if the client specified a single id=foo, then use \"doc\":{\n   // otherwise use a standard doclist\n\n   if (ids ==  null && allIds.length <= 1) {\n     // if the doc was not found, then use a value of null.\n     rsp.add(\"doc\", docList.size() > 0 ? docList.get(0) : null);\n   } else {\n     docList.setNumFound(docList.size());\n     rsp.add(\"response\", docList);\n   }\n\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    String val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      processGetUpdates(rb);\n      return;\n    }\n\n    String id[] = params.getParams(\"id\");\n    String ids[] = params.getParams(\"ids\");\n\n    if (id == null && ids == null) {\n      return;\n    }\n\n    String[] allIds = id==null ? new String[0] : id;\n\n    if (ids != null) {\n      List<String> lst = new ArrayList<String>();\n      for (String s : allIds) {\n        lst.add(s);\n      }\n      for (String idList : ids) {\n        lst.addAll( StrUtils.splitSmart(idList, \",\", true) );\n      }\n      allIds = lst.toArray(new String[lst.size()]);\n    }\n\n    SchemaField idField = req.getSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = req.getCore().getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n\n    DocTransformer transformer = rsp.getReturnFields().getTransformer();\n    if (transformer != null) {\n      TransformContext context = new TransformContext();\n      context.req = req;\n      transformer.setContext(context);\n    }\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRef idBytes = new BytesRef();\n     for (String idStr : allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes);\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0);\n           switch (oper) {\n             case UpdateLog.ADD:\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), req.getSchema());\n               if(transformer!=null) {\n                 transformer.transform(doc, -1); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = req.getCore().getRealtimeSearcher();\n         searcher = searcherHolder.get();\n       }\n\n       // SolrCore.verbose(\"RealTimeGet using searcher \", searcher);\n\n       int docid = searcher.getFirstMatch(new Term(idField.getName(), idBytes));\n       if (docid < 0) continue;\n       Document luceneDocument = searcher.doc(docid);\n       SolrDocument doc = toSolrDoc(luceneDocument,  req.getSchema());\n       if( transformer != null ) {\n         transformer.transform(doc, docid);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n\n   // if the client specified a single id=foo, then use \"doc\":{\n   // otherwise use a standard doclist\n\n   if (ids ==  null && allIds.length <= 1) {\n     // if the doc was not found, then use a value of null.\n     rsp.add(\"doc\", docList.size() > 0 ? docList.get(0) : null);\n   } else {\n     docList.setNumFound(docList.size());\n     rsp.add(\"response\", docList);\n   }\n\n  }\n\n","bugFix":["bd0ef6574805f3cb9880e0983b7548a6aa933508"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3599646b4d4c346cf74d334813488b8b337b5bf5","date":1337790261,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    String val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      processGetUpdates(rb);\n      return;\n    }\n\n    String id[] = params.getParams(\"id\");\n    String ids[] = params.getParams(\"ids\");\n\n    if (id == null && ids == null) {\n      return;\n    }\n\n    String[] allIds = id==null ? new String[0] : id;\n\n    if (ids != null) {\n      List<String> lst = new ArrayList<String>();\n      for (String s : allIds) {\n        lst.add(s);\n      }\n      for (String idList : ids) {\n        lst.addAll( StrUtils.splitSmart(idList, \",\", true) );\n      }\n      allIds = lst.toArray(new String[lst.size()]);\n    }\n\n    SchemaField idField = req.getSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = req.getCore().getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n\n    DocTransformer transformer = rsp.getReturnFields().getTransformer();\n    if (transformer != null) {\n      TransformContext context = new TransformContext();\n      context.req = req;\n      transformer.setContext(context);\n    }\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRef idBytes = new BytesRef();\n     for (String idStr : allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes);\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.ADD:\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), req.getSchema());\n               if(transformer!=null) {\n                 transformer.transform(doc, -1); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = req.getCore().getRealtimeSearcher();\n         searcher = searcherHolder.get();\n       }\n\n       // SolrCore.verbose(\"RealTimeGet using searcher \", searcher);\n\n       int docid = searcher.getFirstMatch(new Term(idField.getName(), idBytes));\n       if (docid < 0) continue;\n       Document luceneDocument = searcher.doc(docid);\n       SolrDocument doc = toSolrDoc(luceneDocument,  req.getSchema());\n       if( transformer != null ) {\n         transformer.transform(doc, docid);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n\n   // if the client specified a single id=foo, then use \"doc\":{\n   // otherwise use a standard doclist\n\n   if (ids ==  null && allIds.length <= 1) {\n     // if the doc was not found, then use a value of null.\n     rsp.add(\"doc\", docList.size() > 0 ? docList.get(0) : null);\n   } else {\n     docList.setNumFound(docList.size());\n     rsp.add(\"response\", docList);\n   }\n\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    String val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      processGetUpdates(rb);\n      return;\n    }\n\n    String id[] = params.getParams(\"id\");\n    String ids[] = params.getParams(\"ids\");\n\n    if (id == null && ids == null) {\n      return;\n    }\n\n    String[] allIds = id==null ? new String[0] : id;\n\n    if (ids != null) {\n      List<String> lst = new ArrayList<String>();\n      for (String s : allIds) {\n        lst.add(s);\n      }\n      for (String idList : ids) {\n        lst.addAll( StrUtils.splitSmart(idList, \",\", true) );\n      }\n      allIds = lst.toArray(new String[lst.size()]);\n    }\n\n    SchemaField idField = req.getSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = req.getCore().getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n\n    DocTransformer transformer = rsp.getReturnFields().getTransformer();\n    if (transformer != null) {\n      TransformContext context = new TransformContext();\n      context.req = req;\n      transformer.setContext(context);\n    }\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRef idBytes = new BytesRef();\n     for (String idStr : allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes);\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0);\n           switch (oper) {\n             case UpdateLog.ADD:\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), req.getSchema());\n               if(transformer!=null) {\n                 transformer.transform(doc, -1); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = req.getCore().getRealtimeSearcher();\n         searcher = searcherHolder.get();\n       }\n\n       // SolrCore.verbose(\"RealTimeGet using searcher \", searcher);\n\n       int docid = searcher.getFirstMatch(new Term(idField.getName(), idBytes));\n       if (docid < 0) continue;\n       Document luceneDocument = searcher.doc(docid);\n       SolrDocument doc = toSolrDoc(luceneDocument,  req.getSchema());\n       if( transformer != null ) {\n         transformer.transform(doc, docid);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n\n   // if the client specified a single id=foo, then use \"doc\":{\n   // otherwise use a standard doclist\n\n   if (ids ==  null && allIds.length <= 1) {\n     // if the doc was not found, then use a value of null.\n     rsp.add(\"doc\", docList.size() > 0 ? docList.get(0) : null);\n   } else {\n     docList.setNumFound(docList.size());\n     rsp.add(\"response\", docList);\n   }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a7e4907084808af8fdb14b9809e6dceaccf6867b","date":1343473006,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    String val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      processGetUpdates(rb);\n      return;\n    }\n\n    String id[] = params.getParams(\"id\");\n    String ids[] = params.getParams(\"ids\");\n\n    if (id == null && ids == null) {\n      return;\n    }\n\n    String[] allIds = id==null ? new String[0] : id;\n\n    if (ids != null) {\n      List<String> lst = new ArrayList<String>();\n      for (String s : allIds) {\n        lst.add(s);\n      }\n      for (String idList : ids) {\n        lst.addAll( StrUtils.splitSmart(idList, \",\", true) );\n      }\n      allIds = lst.toArray(new String[lst.size()]);\n    }\n\n    SchemaField idField = req.getSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = req.getCore().getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n\n    DocTransformer transformer = rsp.getReturnFields().getTransformer();\n    if (transformer != null) {\n      TransformContext context = new TransformContext();\n      context.req = req;\n      transformer.setContext(context);\n    }\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRef idBytes = new BytesRef();\n     for (String idStr : allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes);\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.ADD:\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), req.getSchema());\n               if(transformer!=null) {\n                 transformer.transform(doc, -1); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = req.getCore().getRealtimeSearcher();\n         searcher = searcherHolder.get();\n       }\n\n       // SolrCore.verbose(\"RealTimeGet using searcher \", searcher);\n\n       int docid = searcher.getFirstMatch(new Term(idField.getName(), idBytes));\n       if (docid < 0) continue;\n       StoredDocument luceneDocument = searcher.doc(docid);\n       SolrDocument doc = toSolrDoc(luceneDocument,  req.getSchema());\n       if( transformer != null ) {\n         transformer.transform(doc, docid);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n\n   // if the client specified a single id=foo, then use \"doc\":{\n   // otherwise use a standard doclist\n\n   if (ids ==  null && allIds.length <= 1) {\n     // if the doc was not found, then use a value of null.\n     rsp.add(\"doc\", docList.size() > 0 ? docList.get(0) : null);\n   } else {\n     docList.setNumFound(docList.size());\n     rsp.add(\"response\", docList);\n   }\n\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    String val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      processGetUpdates(rb);\n      return;\n    }\n\n    String id[] = params.getParams(\"id\");\n    String ids[] = params.getParams(\"ids\");\n\n    if (id == null && ids == null) {\n      return;\n    }\n\n    String[] allIds = id==null ? new String[0] : id;\n\n    if (ids != null) {\n      List<String> lst = new ArrayList<String>();\n      for (String s : allIds) {\n        lst.add(s);\n      }\n      for (String idList : ids) {\n        lst.addAll( StrUtils.splitSmart(idList, \",\", true) );\n      }\n      allIds = lst.toArray(new String[lst.size()]);\n    }\n\n    SchemaField idField = req.getSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = req.getCore().getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n\n    DocTransformer transformer = rsp.getReturnFields().getTransformer();\n    if (transformer != null) {\n      TransformContext context = new TransformContext();\n      context.req = req;\n      transformer.setContext(context);\n    }\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRef idBytes = new BytesRef();\n     for (String idStr : allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes);\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.ADD:\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), req.getSchema());\n               if(transformer!=null) {\n                 transformer.transform(doc, -1); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = req.getCore().getRealtimeSearcher();\n         searcher = searcherHolder.get();\n       }\n\n       // SolrCore.verbose(\"RealTimeGet using searcher \", searcher);\n\n       int docid = searcher.getFirstMatch(new Term(idField.getName(), idBytes));\n       if (docid < 0) continue;\n       Document luceneDocument = searcher.doc(docid);\n       SolrDocument doc = toSolrDoc(luceneDocument,  req.getSchema());\n       if( transformer != null ) {\n         transformer.transform(doc, docid);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n\n   // if the client specified a single id=foo, then use \"doc\":{\n   // otherwise use a standard doclist\n\n   if (ids ==  null && allIds.length <= 1) {\n     // if the doc was not found, then use a value of null.\n     rsp.add(\"doc\", docList.size() > 0 ? docList.get(0) : null);\n   } else {\n     docList.setNumFound(docList.size());\n     rsp.add(\"response\", docList);\n   }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1d028314cced5858683a1bb4741423d0f934257b","date":1346596535,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    String val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      processGetUpdates(rb);\n      return;\n    }\n\n    String id[] = params.getParams(\"id\");\n    String ids[] = params.getParams(\"ids\");\n\n    if (id == null && ids == null) {\n      return;\n    }\n\n    String[] allIds = id==null ? new String[0] : id;\n\n    if (ids != null) {\n      List<String> lst = new ArrayList<String>();\n      for (String s : allIds) {\n        lst.add(s);\n      }\n      for (String idList : ids) {\n        lst.addAll( StrUtils.splitSmart(idList, \",\", true) );\n      }\n      allIds = lst.toArray(new String[lst.size()]);\n    }\n\n    SchemaField idField = req.getSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = req.getCore().getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n\n    DocTransformer transformer = rsp.getReturnFields().getTransformer();\n    if (transformer != null) {\n      TransformContext context = new TransformContext();\n      context.req = req;\n      transformer.setContext(context);\n    }\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRef idBytes = new BytesRef();\n     for (String idStr : allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes);\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.ADD:\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), req.getSchema());\n               if(transformer!=null) {\n                 transformer.transform(doc, -1); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = req.getCore().getRealtimeSearcher();\n         searcher = searcherHolder.get();\n       }\n\n       // SolrCore.verbose(\"RealTimeGet using searcher \", searcher);\n\n       int docid = searcher.getFirstMatch(new Term(idField.getName(), idBytes));\n       if (docid < 0) continue;\n       StoredDocument luceneDocument = searcher.doc(docid);\n       SolrDocument doc = toSolrDoc(luceneDocument,  req.getSchema());\n       if( transformer != null ) {\n         transformer.transform(doc, docid);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n\n   // if the client specified a single id=foo, then use \"doc\":{\n   // otherwise use a standard doclist\n\n   if (ids ==  null && allIds.length <= 1) {\n     // if the doc was not found, then use a value of null.\n     rsp.add(\"doc\", docList.size() > 0 ? docList.get(0) : null);\n   } else {\n     docList.setNumFound(docList.size());\n     rsp.add(\"response\", docList);\n   }\n\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    String val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      processGetUpdates(rb);\n      return;\n    }\n\n    String id[] = params.getParams(\"id\");\n    String ids[] = params.getParams(\"ids\");\n\n    if (id == null && ids == null) {\n      return;\n    }\n\n    String[] allIds = id==null ? new String[0] : id;\n\n    if (ids != null) {\n      List<String> lst = new ArrayList<String>();\n      for (String s : allIds) {\n        lst.add(s);\n      }\n      for (String idList : ids) {\n        lst.addAll( StrUtils.splitSmart(idList, \",\", true) );\n      }\n      allIds = lst.toArray(new String[lst.size()]);\n    }\n\n    SchemaField idField = req.getSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = req.getCore().getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n\n    DocTransformer transformer = rsp.getReturnFields().getTransformer();\n    if (transformer != null) {\n      TransformContext context = new TransformContext();\n      context.req = req;\n      transformer.setContext(context);\n    }\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRef idBytes = new BytesRef();\n     for (String idStr : allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes);\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.ADD:\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), req.getSchema());\n               if(transformer!=null) {\n                 transformer.transform(doc, -1); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = req.getCore().getRealtimeSearcher();\n         searcher = searcherHolder.get();\n       }\n\n       // SolrCore.verbose(\"RealTimeGet using searcher \", searcher);\n\n       int docid = searcher.getFirstMatch(new Term(idField.getName(), idBytes));\n       if (docid < 0) continue;\n       Document luceneDocument = searcher.doc(docid);\n       SolrDocument doc = toSolrDoc(luceneDocument,  req.getSchema());\n       if( transformer != null ) {\n         transformer.transform(doc, docid);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n\n   // if the client specified a single id=foo, then use \"doc\":{\n   // otherwise use a standard doclist\n\n   if (ids ==  null && allIds.length <= 1) {\n     // if the doc was not found, then use a value of null.\n     rsp.add(\"doc\", docList.size() > 0 ? docList.get(0) : null);\n   } else {\n     docList.setNumFound(docList.size());\n     rsp.add(\"response\", docList);\n   }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"08970e5b8411182a29412c177eff67ec1110095b","date":1366640815,"type":3,"author":"Steven Rowe","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    String val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      processGetUpdates(rb);\n      return;\n    }\n\n    String id[] = params.getParams(\"id\");\n    String ids[] = params.getParams(\"ids\");\n\n    if (id == null && ids == null) {\n      return;\n    }\n\n    String[] allIds = id==null ? new String[0] : id;\n\n    if (ids != null) {\n      List<String> lst = new ArrayList<String>();\n      for (String s : allIds) {\n        lst.add(s);\n      }\n      for (String idList : ids) {\n        lst.addAll( StrUtils.splitSmart(idList, \",\", true) );\n      }\n      allIds = lst.toArray(new String[lst.size()]);\n    }\n\n    SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n\n    DocTransformer transformer = rsp.getReturnFields().getTransformer();\n    if (transformer != null) {\n      TransformContext context = new TransformContext();\n      context.req = req;\n      transformer.setContext(context);\n    }\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRef idBytes = new BytesRef();\n     for (String idStr : allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes);\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.ADD:\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               if(transformer!=null) {\n                 transformer.transform(doc, -1); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = core.getRealtimeSearcher();\n         searcher = searcherHolder.get();\n       }\n\n       // SolrCore.verbose(\"RealTimeGet using searcher \", searcher);\n\n       int docid = searcher.getFirstMatch(new Term(idField.getName(), idBytes));\n       if (docid < 0) continue;\n       StoredDocument luceneDocument = searcher.doc(docid);\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       if( transformer != null ) {\n         transformer.transform(doc, docid);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n\n   // if the client specified a single id=foo, then use \"doc\":{\n   // otherwise use a standard doclist\n\n   if (ids ==  null && allIds.length <= 1) {\n     // if the doc was not found, then use a value of null.\n     rsp.add(\"doc\", docList.size() > 0 ? docList.get(0) : null);\n   } else {\n     docList.setNumFound(docList.size());\n     rsp.add(\"response\", docList);\n   }\n\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    String val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      processGetUpdates(rb);\n      return;\n    }\n\n    String id[] = params.getParams(\"id\");\n    String ids[] = params.getParams(\"ids\");\n\n    if (id == null && ids == null) {\n      return;\n    }\n\n    String[] allIds = id==null ? new String[0] : id;\n\n    if (ids != null) {\n      List<String> lst = new ArrayList<String>();\n      for (String s : allIds) {\n        lst.add(s);\n      }\n      for (String idList : ids) {\n        lst.addAll( StrUtils.splitSmart(idList, \",\", true) );\n      }\n      allIds = lst.toArray(new String[lst.size()]);\n    }\n\n    SchemaField idField = req.getSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = req.getCore().getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n\n    DocTransformer transformer = rsp.getReturnFields().getTransformer();\n    if (transformer != null) {\n      TransformContext context = new TransformContext();\n      context.req = req;\n      transformer.setContext(context);\n    }\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRef idBytes = new BytesRef();\n     for (String idStr : allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes);\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.ADD:\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), req.getSchema());\n               if(transformer!=null) {\n                 transformer.transform(doc, -1); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = req.getCore().getRealtimeSearcher();\n         searcher = searcherHolder.get();\n       }\n\n       // SolrCore.verbose(\"RealTimeGet using searcher \", searcher);\n\n       int docid = searcher.getFirstMatch(new Term(idField.getName(), idBytes));\n       if (docid < 0) continue;\n       StoredDocument luceneDocument = searcher.doc(docid);\n       SolrDocument doc = toSolrDoc(luceneDocument,  req.getSchema());\n       if( transformer != null ) {\n         transformer.transform(doc, docid);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n\n   // if the client specified a single id=foo, then use \"doc\":{\n   // otherwise use a standard doclist\n\n   if (ids ==  null && allIds.length <= 1) {\n     // if the doc was not found, then use a value of null.\n     rsp.add(\"doc\", docList.size() > 0 ? docList.get(0) : null);\n   } else {\n     docList.setNumFound(docList.size());\n     rsp.add(\"response\", docList);\n   }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    String val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      processGetUpdates(rb);\n      return;\n    }\n\n    String id[] = params.getParams(\"id\");\n    String ids[] = params.getParams(\"ids\");\n\n    if (id == null && ids == null) {\n      return;\n    }\n\n    String[] allIds = id==null ? new String[0] : id;\n\n    if (ids != null) {\n      List<String> lst = new ArrayList<>();\n      for (String s : allIds) {\n        lst.add(s);\n      }\n      for (String idList : ids) {\n        lst.addAll( StrUtils.splitSmart(idList, \",\", true) );\n      }\n      allIds = lst.toArray(new String[lst.size()]);\n    }\n\n    SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n\n    DocTransformer transformer = rsp.getReturnFields().getTransformer();\n    if (transformer != null) {\n      TransformContext context = new TransformContext();\n      context.req = req;\n      transformer.setContext(context);\n    }\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRef idBytes = new BytesRef();\n     for (String idStr : allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes);\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.ADD:\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               if(transformer!=null) {\n                 transformer.transform(doc, -1); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = core.getRealtimeSearcher();\n         searcher = searcherHolder.get();\n       }\n\n       // SolrCore.verbose(\"RealTimeGet using searcher \", searcher);\n\n       int docid = searcher.getFirstMatch(new Term(idField.getName(), idBytes));\n       if (docid < 0) continue;\n       StoredDocument luceneDocument = searcher.doc(docid);\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       if( transformer != null ) {\n         transformer.transform(doc, docid);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n\n   // if the client specified a single id=foo, then use \"doc\":{\n   // otherwise use a standard doclist\n\n   if (ids ==  null && allIds.length <= 1) {\n     // if the doc was not found, then use a value of null.\n     rsp.add(\"doc\", docList.size() > 0 ? docList.get(0) : null);\n   } else {\n     docList.setNumFound(docList.size());\n     rsp.add(\"response\", docList);\n   }\n\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    String val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      processGetUpdates(rb);\n      return;\n    }\n\n    String id[] = params.getParams(\"id\");\n    String ids[] = params.getParams(\"ids\");\n\n    if (id == null && ids == null) {\n      return;\n    }\n\n    String[] allIds = id==null ? new String[0] : id;\n\n    if (ids != null) {\n      List<String> lst = new ArrayList<String>();\n      for (String s : allIds) {\n        lst.add(s);\n      }\n      for (String idList : ids) {\n        lst.addAll( StrUtils.splitSmart(idList, \",\", true) );\n      }\n      allIds = lst.toArray(new String[lst.size()]);\n    }\n\n    SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n\n    DocTransformer transformer = rsp.getReturnFields().getTransformer();\n    if (transformer != null) {\n      TransformContext context = new TransformContext();\n      context.req = req;\n      transformer.setContext(context);\n    }\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRef idBytes = new BytesRef();\n     for (String idStr : allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes);\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.ADD:\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               if(transformer!=null) {\n                 transformer.transform(doc, -1); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = core.getRealtimeSearcher();\n         searcher = searcherHolder.get();\n       }\n\n       // SolrCore.verbose(\"RealTimeGet using searcher \", searcher);\n\n       int docid = searcher.getFirstMatch(new Term(idField.getName(), idBytes));\n       if (docid < 0) continue;\n       StoredDocument luceneDocument = searcher.doc(docid);\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       if( transformer != null ) {\n         transformer.transform(doc, docid);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n\n   // if the client specified a single id=foo, then use \"doc\":{\n   // otherwise use a standard doclist\n\n   if (ids ==  null && allIds.length <= 1) {\n     // if the doc was not found, then use a value of null.\n     rsp.add(\"doc\", docList.size() > 0 ? docList.get(0) : null);\n   } else {\n     docList.setNumFound(docList.size());\n     rsp.add(\"response\", docList);\n   }\n\n  }\n\n","bugFix":null,"bugIntro":["4c58bab35e821e15dc6b8669d2f15c2e3cc6d9ce"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50","date":1407854805,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    String val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      processGetUpdates(rb);\n      return;\n    }\n\n    String id[] = params.getParams(\"id\");\n    String ids[] = params.getParams(\"ids\");\n\n    if (id == null && ids == null) {\n      return;\n    }\n\n    String[] allIds = id==null ? new String[0] : id;\n\n    if (ids != null) {\n      List<String> lst = new ArrayList<>();\n      for (String s : allIds) {\n        lst.add(s);\n      }\n      for (String idList : ids) {\n        lst.addAll( StrUtils.splitSmart(idList, \",\", true) );\n      }\n      allIds = lst.toArray(new String[lst.size()]);\n    }\n\n    SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n\n    DocTransformer transformer = rsp.getReturnFields().getTransformer();\n    if (transformer != null) {\n      TransformContext context = new TransformContext();\n      context.req = req;\n      transformer.setContext(context);\n    }\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.ADD:\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               if(transformer!=null) {\n                 transformer.transform(doc, -1); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = core.getRealtimeSearcher();\n         searcher = searcherHolder.get();\n       }\n\n       // SolrCore.verbose(\"RealTimeGet using searcher \", searcher);\n\n       int docid = searcher.getFirstMatch(new Term(idField.getName(), idBytes.get()));\n       if (docid < 0) continue;\n       StoredDocument luceneDocument = searcher.doc(docid);\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       if( transformer != null ) {\n         transformer.transform(doc, docid);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n\n   // if the client specified a single id=foo, then use \"doc\":{\n   // otherwise use a standard doclist\n\n   if (ids ==  null && allIds.length <= 1) {\n     // if the doc was not found, then use a value of null.\n     rsp.add(\"doc\", docList.size() > 0 ? docList.get(0) : null);\n   } else {\n     docList.setNumFound(docList.size());\n     rsp.add(\"response\", docList);\n   }\n\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    String val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      processGetUpdates(rb);\n      return;\n    }\n\n    String id[] = params.getParams(\"id\");\n    String ids[] = params.getParams(\"ids\");\n\n    if (id == null && ids == null) {\n      return;\n    }\n\n    String[] allIds = id==null ? new String[0] : id;\n\n    if (ids != null) {\n      List<String> lst = new ArrayList<>();\n      for (String s : allIds) {\n        lst.add(s);\n      }\n      for (String idList : ids) {\n        lst.addAll( StrUtils.splitSmart(idList, \",\", true) );\n      }\n      allIds = lst.toArray(new String[lst.size()]);\n    }\n\n    SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n\n    DocTransformer transformer = rsp.getReturnFields().getTransformer();\n    if (transformer != null) {\n      TransformContext context = new TransformContext();\n      context.req = req;\n      transformer.setContext(context);\n    }\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRef idBytes = new BytesRef();\n     for (String idStr : allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes);\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.ADD:\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               if(transformer!=null) {\n                 transformer.transform(doc, -1); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = core.getRealtimeSearcher();\n         searcher = searcherHolder.get();\n       }\n\n       // SolrCore.verbose(\"RealTimeGet using searcher \", searcher);\n\n       int docid = searcher.getFirstMatch(new Term(idField.getName(), idBytes));\n       if (docid < 0) continue;\n       StoredDocument luceneDocument = searcher.doc(docid);\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       if( transformer != null ) {\n         transformer.transform(doc, docid);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n\n   // if the client specified a single id=foo, then use \"doc\":{\n   // otherwise use a standard doclist\n\n   if (ids ==  null && allIds.length <= 1) {\n     // if the doc was not found, then use a value of null.\n     rsp.add(\"doc\", docList.size() > 0 ? docList.get(0) : null);\n   } else {\n     docList.setNumFound(docList.size());\n     rsp.add(\"response\", docList);\n   }\n\n  }\n\n","bugFix":["bd0ef6574805f3cb9880e0983b7548a6aa933508"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"659d7ea4e085dbd15c54c80811439e4bb21a74fb","date":1422516918,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    String val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      processGetUpdates(rb);\n      return;\n    }\n\n    String id[] = params.getParams(\"id\");\n    String ids[] = params.getParams(\"ids\");\n\n    if (id == null && ids == null) {\n      return;\n    }\n\n    String[] allIds = id==null ? new String[0] : id;\n\n    if (ids != null) {\n      List<String> lst = new ArrayList<>();\n      for (String s : allIds) {\n        lst.add(s);\n      }\n      for (String idList : ids) {\n        lst.addAll( StrUtils.splitSmart(idList, \",\", true) );\n      }\n      allIds = lst.toArray(new String[lst.size()]);\n    }\n\n    SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n\n    DocTransformer transformer = rsp.getReturnFields().getTransformer();\n    if (transformer != null) {\n      TransformContext context = new TransformContext();\n      context.req = req;\n      transformer.setContext(context);\n    }\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.ADD:\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               if(transformer!=null) {\n                 transformer.transform(doc, -1); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = core.getRealtimeSearcher();\n         searcher = searcherHolder.get();\n       }\n\n       // SolrCore.verbose(\"RealTimeGet using searcher \", searcher);\n\n       int docid = searcher.getFirstMatch(new Term(idField.getName(), idBytes.get()));\n       if (docid < 0) continue;\n       StoredDocument luceneDocument = searcher.doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       if( transformer != null ) {\n         transformer.transform(doc, docid);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n\n   // if the client specified a single id=foo, then use \"doc\":{\n   // otherwise use a standard doclist\n\n   if (ids ==  null && allIds.length <= 1) {\n     // if the doc was not found, then use a value of null.\n     rsp.add(\"doc\", docList.size() > 0 ? docList.get(0) : null);\n   } else {\n     docList.setNumFound(docList.size());\n     rsp.add(\"response\", docList);\n   }\n\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    String val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      processGetUpdates(rb);\n      return;\n    }\n\n    String id[] = params.getParams(\"id\");\n    String ids[] = params.getParams(\"ids\");\n\n    if (id == null && ids == null) {\n      return;\n    }\n\n    String[] allIds = id==null ? new String[0] : id;\n\n    if (ids != null) {\n      List<String> lst = new ArrayList<>();\n      for (String s : allIds) {\n        lst.add(s);\n      }\n      for (String idList : ids) {\n        lst.addAll( StrUtils.splitSmart(idList, \",\", true) );\n      }\n      allIds = lst.toArray(new String[lst.size()]);\n    }\n\n    SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n\n    DocTransformer transformer = rsp.getReturnFields().getTransformer();\n    if (transformer != null) {\n      TransformContext context = new TransformContext();\n      context.req = req;\n      transformer.setContext(context);\n    }\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.ADD:\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               if(transformer!=null) {\n                 transformer.transform(doc, -1); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = core.getRealtimeSearcher();\n         searcher = searcherHolder.get();\n       }\n\n       // SolrCore.verbose(\"RealTimeGet using searcher \", searcher);\n\n       int docid = searcher.getFirstMatch(new Term(idField.getName(), idBytes.get()));\n       if (docid < 0) continue;\n       StoredDocument luceneDocument = searcher.doc(docid);\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       if( transformer != null ) {\n         transformer.transform(doc, docid);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n\n   // if the client specified a single id=foo, then use \"doc\":{\n   // otherwise use a standard doclist\n\n   if (ids ==  null && allIds.length <= 1) {\n     // if the doc was not found, then use a value of null.\n     rsp.add(\"doc\", docList.size() > 0 ? docList.get(0) : null);\n   } else {\n     docList.setNumFound(docList.size());\n     rsp.add(\"response\", docList);\n   }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6c94d2661bc1c14426980ec7882e951fdcff08d0","date":1427167177,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    String val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore().getCoreDescriptor()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n\n    String id[] = params.getParams(\"id\");\n    String ids[] = params.getParams(\"ids\");\n\n    if (id == null && ids == null) {\n      return;\n    }\n\n    String[] allIds = id==null ? new String[0] : id;\n\n    if (ids != null) {\n      List<String> lst = new ArrayList<>();\n      for (String s : allIds) {\n        lst.add(s);\n      }\n      for (String idList : ids) {\n        lst.addAll( StrUtils.splitSmart(idList, \",\", true) );\n      }\n      allIds = lst.toArray(new String[lst.size()]);\n    }\n\n    SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n\n    DocTransformer transformer = rsp.getReturnFields().getTransformer();\n    if (transformer != null) {\n      TransformContext context = new TransformContext();\n      context.req = req;\n      transformer.setContext(context);\n    }\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.ADD:\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               if(transformer!=null) {\n                 transformer.transform(doc, -1); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = core.getRealtimeSearcher();\n         searcher = searcherHolder.get();\n       }\n\n       // SolrCore.verbose(\"RealTimeGet using searcher \", searcher);\n\n       int docid = searcher.getFirstMatch(new Term(idField.getName(), idBytes.get()));\n       if (docid < 0) continue;\n       StoredDocument luceneDocument = searcher.doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       if( transformer != null ) {\n         transformer.transform(doc, docid);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n\n   // if the client specified a single id=foo, then use \"doc\":{\n   // otherwise use a standard doclist\n\n   if (ids ==  null && allIds.length <= 1) {\n     // if the doc was not found, then use a value of null.\n     rsp.add(\"doc\", docList.size() > 0 ? docList.get(0) : null);\n   } else {\n     docList.setNumFound(docList.size());\n     rsp.add(\"response\", docList);\n   }\n\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    String val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      processGetUpdates(rb);\n      return;\n    }\n\n    String id[] = params.getParams(\"id\");\n    String ids[] = params.getParams(\"ids\");\n\n    if (id == null && ids == null) {\n      return;\n    }\n\n    String[] allIds = id==null ? new String[0] : id;\n\n    if (ids != null) {\n      List<String> lst = new ArrayList<>();\n      for (String s : allIds) {\n        lst.add(s);\n      }\n      for (String idList : ids) {\n        lst.addAll( StrUtils.splitSmart(idList, \",\", true) );\n      }\n      allIds = lst.toArray(new String[lst.size()]);\n    }\n\n    SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n\n    DocTransformer transformer = rsp.getReturnFields().getTransformer();\n    if (transformer != null) {\n      TransformContext context = new TransformContext();\n      context.req = req;\n      transformer.setContext(context);\n    }\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.ADD:\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               if(transformer!=null) {\n                 transformer.transform(doc, -1); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = core.getRealtimeSearcher();\n         searcher = searcherHolder.get();\n       }\n\n       // SolrCore.verbose(\"RealTimeGet using searcher \", searcher);\n\n       int docid = searcher.getFirstMatch(new Term(idField.getName(), idBytes.get()));\n       if (docid < 0) continue;\n       StoredDocument luceneDocument = searcher.doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       if( transformer != null ) {\n         transformer.transform(doc, docid);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n\n   // if the client specified a single id=foo, then use \"doc\":{\n   // otherwise use a standard doclist\n\n   if (ids ==  null && allIds.length <= 1) {\n     // if the doc was not found, then use a value of null.\n     rsp.add(\"doc\", docList.size() > 0 ? docList.get(0) : null);\n   } else {\n     docList.setNumFound(docList.size());\n     rsp.add(\"response\", docList);\n   }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":3,"author":"Ryan Ernst","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    String val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore().getCoreDescriptor()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n\n    String id[] = params.getParams(\"id\");\n    String ids[] = params.getParams(\"ids\");\n\n    if (id == null && ids == null) {\n      return;\n    }\n\n    String[] allIds = id==null ? new String[0] : id;\n\n    if (ids != null) {\n      List<String> lst = new ArrayList<>();\n      for (String s : allIds) {\n        lst.add(s);\n      }\n      for (String idList : ids) {\n        lst.addAll( StrUtils.splitSmart(idList, \",\", true) );\n      }\n      allIds = lst.toArray(new String[lst.size()]);\n    }\n\n    SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n\n    DocTransformer transformer = rsp.getReturnFields().getTransformer();\n    if (transformer != null) {\n      TransformContext context = new TransformContext();\n      context.req = req;\n      transformer.setContext(context);\n    }\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.ADD:\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               if(transformer!=null) {\n                 transformer.transform(doc, -1); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = core.getRealtimeSearcher();\n         searcher = searcherHolder.get();\n       }\n\n       // SolrCore.verbose(\"RealTimeGet using searcher \", searcher);\n\n       int docid = searcher.getFirstMatch(new Term(idField.getName(), idBytes.get()));\n       if (docid < 0) continue;\n       StoredDocument luceneDocument = searcher.doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       if( transformer != null ) {\n         transformer.transform(doc, docid);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n\n   // if the client specified a single id=foo, then use \"doc\":{\n   // otherwise use a standard doclist\n\n   if (ids ==  null && allIds.length <= 1) {\n     // if the doc was not found, then use a value of null.\n     rsp.add(\"doc\", docList.size() > 0 ? docList.get(0) : null);\n   } else {\n     docList.setNumFound(docList.size());\n     rsp.add(\"response\", docList);\n   }\n\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    String val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      processGetUpdates(rb);\n      return;\n    }\n\n    String id[] = params.getParams(\"id\");\n    String ids[] = params.getParams(\"ids\");\n\n    if (id == null && ids == null) {\n      return;\n    }\n\n    String[] allIds = id==null ? new String[0] : id;\n\n    if (ids != null) {\n      List<String> lst = new ArrayList<>();\n      for (String s : allIds) {\n        lst.add(s);\n      }\n      for (String idList : ids) {\n        lst.addAll( StrUtils.splitSmart(idList, \",\", true) );\n      }\n      allIds = lst.toArray(new String[lst.size()]);\n    }\n\n    SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n\n    DocTransformer transformer = rsp.getReturnFields().getTransformer();\n    if (transformer != null) {\n      TransformContext context = new TransformContext();\n      context.req = req;\n      transformer.setContext(context);\n    }\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.ADD:\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               if(transformer!=null) {\n                 transformer.transform(doc, -1); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = core.getRealtimeSearcher();\n         searcher = searcherHolder.get();\n       }\n\n       // SolrCore.verbose(\"RealTimeGet using searcher \", searcher);\n\n       int docid = searcher.getFirstMatch(new Term(idField.getName(), idBytes.get()));\n       if (docid < 0) continue;\n       StoredDocument luceneDocument = searcher.doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       if( transformer != null ) {\n         transformer.transform(doc, docid);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n\n   // if the client specified a single id=foo, then use \"doc\":{\n   // otherwise use a standard doclist\n\n   if (ids ==  null && allIds.length <= 1) {\n     // if the doc was not found, then use a value of null.\n     rsp.add(\"doc\", docList.size() > 0 ? docList.get(0) : null);\n   } else {\n     docList.setNumFound(docList.size());\n     rsp.add(\"response\", docList);\n   }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7b8f0dc1dfedc7fda86aefc0cdabde0efae2d1dc","date":1440797084,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    String val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore().getCoreDescriptor()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n\n    String id[] = params.getParams(\"id\");\n    String ids[] = params.getParams(\"ids\");\n\n    if (id == null && ids == null) {\n      return;\n    }\n\n    String[] allIds = id==null ? new String[0] : id;\n\n    if (ids != null) {\n      List<String> lst = new ArrayList<>();\n      for (String s : allIds) {\n        lst.add(s);\n      }\n      for (String idList : ids) {\n        lst.addAll( StrUtils.splitSmart(idList, \",\", true) );\n      }\n      allIds = lst.toArray(new String[lst.size()]);\n    }\n\n    SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n\n    DocTransformer transformer = rsp.getReturnFields().getTransformer();\n    if (transformer != null) {\n      ResultContext context = new BasicResultContext(null, rsp.getReturnFields(), null, null, req);\n      transformer.setContext(context);\n    }\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.ADD:\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               if(transformer!=null) {\n                 transformer.transform(doc, -1, 0); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = core.getRealtimeSearcher();\n         searcher = searcherHolder.get();\n       }\n\n       // SolrCore.verbose(\"RealTimeGet using searcher \", searcher);\n\n       int docid = searcher.getFirstMatch(new Term(idField.getName(), idBytes.get()));\n       if (docid < 0) continue;\n       StoredDocument luceneDocument = searcher.doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       if( transformer != null ) {\n         transformer.transform(doc, docid, 0);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n\n   // if the client specified a single id=foo, then use \"doc\":{\n   // otherwise use a standard doclist\n\n   if (ids ==  null && allIds.length <= 1) {\n     // if the doc was not found, then use a value of null.\n     rsp.add(\"doc\", docList.size() > 0 ? docList.get(0) : null);\n   } else {\n     docList.setNumFound(docList.size());\n     rsp.add(\"response\", docList);\n   }\n\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    String val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore().getCoreDescriptor()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n\n    String id[] = params.getParams(\"id\");\n    String ids[] = params.getParams(\"ids\");\n\n    if (id == null && ids == null) {\n      return;\n    }\n\n    String[] allIds = id==null ? new String[0] : id;\n\n    if (ids != null) {\n      List<String> lst = new ArrayList<>();\n      for (String s : allIds) {\n        lst.add(s);\n      }\n      for (String idList : ids) {\n        lst.addAll( StrUtils.splitSmart(idList, \",\", true) );\n      }\n      allIds = lst.toArray(new String[lst.size()]);\n    }\n\n    SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n\n    DocTransformer transformer = rsp.getReturnFields().getTransformer();\n    if (transformer != null) {\n      TransformContext context = new TransformContext();\n      context.req = req;\n      transformer.setContext(context);\n    }\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.ADD:\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               if(transformer!=null) {\n                 transformer.transform(doc, -1); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = core.getRealtimeSearcher();\n         searcher = searcherHolder.get();\n       }\n\n       // SolrCore.verbose(\"RealTimeGet using searcher \", searcher);\n\n       int docid = searcher.getFirstMatch(new Term(idField.getName(), idBytes.get()));\n       if (docid < 0) continue;\n       StoredDocument luceneDocument = searcher.doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       if( transformer != null ) {\n         transformer.transform(doc, docid);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n\n   // if the client specified a single id=foo, then use \"doc\":{\n   // otherwise use a standard doclist\n\n   if (ids ==  null && allIds.length <= 1) {\n     // if the doc was not found, then use a value of null.\n     rsp.add(\"doc\", docList.size() > 0 ? docList.get(0) : null);\n   } else {\n     docList.setNumFound(docList.size());\n     rsp.add(\"response\", docList);\n   }\n\n  }\n\n","bugFix":null,"bugIntro":["136796946c32863f11b97ebec6b4091cdfe3a20b"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ecd75942508378ccc92c3a26f71db6cba9f25784","date":1450708761,"type":3,"author":"Christine Poerschke","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    String val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore().getCoreDescriptor()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n\n    String id[] = params.getParams(\"id\");\n    String ids[] = params.getParams(\"ids\");\n\n    if (id == null && ids == null) {\n      return;\n    }\n\n    String[] allIds = id==null ? new String[0] : id;\n\n    if (ids != null) {\n      List<String> lst = new ArrayList<>();\n      for (String s : allIds) {\n        lst.add(s);\n      }\n      for (String idList : ids) {\n        lst.addAll( StrUtils.splitSmart(idList, \",\", true) );\n      }\n      allIds = lst.toArray(new String[lst.size()]);\n    }\n\n    SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n\n    DocTransformer transformer = rsp.getReturnFields().getTransformer();\n    if (transformer != null) {\n      ResultContext context = new BasicResultContext(null, rsp.getReturnFields(), null, null, req);\n      transformer.setContext(context);\n    }\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.ADD:\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               if(transformer!=null) {\n                 transformer.transform(doc, -1, 0); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = core.getRealtimeSearcher();\n         searcher = searcherHolder.get();\n       }\n\n       // SolrCore.verbose(\"RealTimeGet using searcher \", searcher);\n\n       int docid = searcher.getFirstMatch(new Term(idField.getName(), idBytes.get()));\n       if (docid < 0) continue;\n       StoredDocument luceneDocument = searcher.doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       if( transformer != null ) {\n         transformer.transform(doc, docid, 0);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n\n   // if the client specified a single id=foo, then use \"doc\":{\n   // otherwise use a standard doclist\n\n   if (ids ==  null && allIds.length <= 1) {\n     // if the doc was not found, then use a value of null.\n     rsp.add(\"doc\", docList.size() > 0 ? docList.get(0) : null);\n   } else {\n     docList.setNumFound(docList.size());\n     rsp.addResponse(docList);\n   }\n\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    String val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore().getCoreDescriptor()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n\n    String id[] = params.getParams(\"id\");\n    String ids[] = params.getParams(\"ids\");\n\n    if (id == null && ids == null) {\n      return;\n    }\n\n    String[] allIds = id==null ? new String[0] : id;\n\n    if (ids != null) {\n      List<String> lst = new ArrayList<>();\n      for (String s : allIds) {\n        lst.add(s);\n      }\n      for (String idList : ids) {\n        lst.addAll( StrUtils.splitSmart(idList, \",\", true) );\n      }\n      allIds = lst.toArray(new String[lst.size()]);\n    }\n\n    SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n\n    DocTransformer transformer = rsp.getReturnFields().getTransformer();\n    if (transformer != null) {\n      ResultContext context = new BasicResultContext(null, rsp.getReturnFields(), null, null, req);\n      transformer.setContext(context);\n    }\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.ADD:\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               if(transformer!=null) {\n                 transformer.transform(doc, -1, 0); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = core.getRealtimeSearcher();\n         searcher = searcherHolder.get();\n       }\n\n       // SolrCore.verbose(\"RealTimeGet using searcher \", searcher);\n\n       int docid = searcher.getFirstMatch(new Term(idField.getName(), idBytes.get()));\n       if (docid < 0) continue;\n       StoredDocument luceneDocument = searcher.doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       if( transformer != null ) {\n         transformer.transform(doc, docid, 0);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n\n   // if the client specified a single id=foo, then use \"doc\":{\n   // otherwise use a standard doclist\n\n   if (ids ==  null && allIds.length <= 1) {\n     // if the doc was not found, then use a value of null.\n     rsp.add(\"doc\", docList.size() > 0 ? docList.get(0) : null);\n   } else {\n     docList.setNumFound(docList.size());\n     rsp.add(\"response\", docList);\n   }\n\n  }\n\n","bugFix":null,"bugIntro":["4c58bab35e821e15dc6b8669d2f15c2e3cc6d9ce"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2b0085a9ec29ebc27be992a3712f4bd5d65d2106","date":1450912573,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    String val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore().getCoreDescriptor()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n\n    String id[] = params.getParams(\"id\");\n    String ids[] = params.getParams(\"ids\");\n\n    if (id == null && ids == null) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, null, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n\n    String[] allIds = id==null ? new String[0] : id;\n\n    if (ids != null) {\n      List<String> lst = new ArrayList<>();\n      for (String s : allIds) {\n        lst.add(s);\n      }\n      for (String idList : ids) {\n        lst.addAll( StrUtils.splitSmart(idList, \",\", true) );\n      }\n      allIds = lst.toArray(new String[lst.size()]);\n    }\n\n    SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n\n    DocTransformer transformer = rsp.getReturnFields().getTransformer();\n    if (transformer != null) {\n      ResultContext context = new BasicResultContext(null, rsp.getReturnFields(), null, null, req);\n      transformer.setContext(context);\n    }\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.ADD:\n\n               if (rb.getFilters() != null) {\n                 // we have filters, so we need to check those against the indexed form of the doc\n                 if (searcherHolder != null) {\n                   // close handles to current searchers\n                   searcher = null;\n                   searcherHolder.decref();\n                   searcherHolder = null;\n                 }\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               if(transformer!=null) {\n                 transformer.transform(doc, -1, 0); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = core.getRealtimeSearcher();\n         searcher = searcherHolder.get();\n       }\n\n       int docid = -1;\n       long segAndId = searcher.lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcher.getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query q : rb.getFilters()) {\n             Scorer scorer = searcher.createWeight(q, false).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n\n       if (docid < 0) continue;\n       StoredDocument luceneDocument = searcher.doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       if( transformer != null ) {\n         transformer.transform(doc, docid, 0);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n\n   // if the client specified a single id=foo, then use \"doc\":{\n   // otherwise use a standard doclist\n\n   if (ids ==  null && allIds.length <= 1) {\n     // if the doc was not found, then use a value of null.\n     rsp.add(\"doc\", docList.size() > 0 ? docList.get(0) : null);\n   } else {\n     docList.setNumFound(docList.size());\n     rsp.addResponse(docList);\n   }\n\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    String val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore().getCoreDescriptor()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n\n    String id[] = params.getParams(\"id\");\n    String ids[] = params.getParams(\"ids\");\n\n    if (id == null && ids == null) {\n      return;\n    }\n\n    String[] allIds = id==null ? new String[0] : id;\n\n    if (ids != null) {\n      List<String> lst = new ArrayList<>();\n      for (String s : allIds) {\n        lst.add(s);\n      }\n      for (String idList : ids) {\n        lst.addAll( StrUtils.splitSmart(idList, \",\", true) );\n      }\n      allIds = lst.toArray(new String[lst.size()]);\n    }\n\n    SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n\n    DocTransformer transformer = rsp.getReturnFields().getTransformer();\n    if (transformer != null) {\n      ResultContext context = new BasicResultContext(null, rsp.getReturnFields(), null, null, req);\n      transformer.setContext(context);\n    }\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.ADD:\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               if(transformer!=null) {\n                 transformer.transform(doc, -1, 0); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = core.getRealtimeSearcher();\n         searcher = searcherHolder.get();\n       }\n\n       // SolrCore.verbose(\"RealTimeGet using searcher \", searcher);\n\n       int docid = searcher.getFirstMatch(new Term(idField.getName(), idBytes.get()));\n       if (docid < 0) continue;\n       StoredDocument luceneDocument = searcher.doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       if( transformer != null ) {\n         transformer.transform(doc, docid, 0);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n\n   // if the client specified a single id=foo, then use \"doc\":{\n   // otherwise use a standard doclist\n\n   if (ids ==  null && allIds.length <= 1) {\n     // if the doc was not found, then use a value of null.\n     rsp.add(\"doc\", docList.size() > 0 ? docList.get(0) : null);\n   } else {\n     docList.setNumFound(docList.size());\n     rsp.addResponse(docList);\n   }\n\n  }\n\n","bugFix":null,"bugIntro":["136796946c32863f11b97ebec6b4091cdfe3a20b","4c58bab35e821e15dc6b8669d2f15c2e3cc6d9ce","76b65cf789129cacd84e977b8f1538aec29e0281"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c","date":1453060490,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    String val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore().getCoreDescriptor()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n\n    String id[] = params.getParams(\"id\");\n    String ids[] = params.getParams(\"ids\");\n\n    if (id == null && ids == null) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, null, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n\n    String[] allIds = id==null ? new String[0] : id;\n\n    if (ids != null) {\n      List<String> lst = new ArrayList<>();\n      for (String s : allIds) {\n        lst.add(s);\n      }\n      for (String idList : ids) {\n        lst.addAll( StrUtils.splitSmart(idList, \",\", true) );\n      }\n      allIds = lst.toArray(new String[lst.size()]);\n    }\n\n    SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n\n    DocTransformer transformer = rsp.getReturnFields().getTransformer();\n    if (transformer != null) {\n      ResultContext context = new BasicResultContext(null, rsp.getReturnFields(), null, null, req);\n      transformer.setContext(context);\n    }\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.ADD:\n\n               if (rb.getFilters() != null) {\n                 // we have filters, so we need to check those against the indexed form of the doc\n                 if (searcherHolder != null) {\n                   // close handles to current searchers\n                   searcher = null;\n                   searcherHolder.decref();\n                   searcherHolder = null;\n                 }\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               if(transformer!=null) {\n                 transformer.transform(doc, -1, 0); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = core.getRealtimeSearcher();\n         searcher = searcherHolder.get();\n       }\n\n       int docid = -1;\n       long segAndId = searcher.lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcher.getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query q : rb.getFilters()) {\n             Scorer scorer = searcher.createWeight(q, false).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n\n       if (docid < 0) continue;\n       Document luceneDocument = searcher.doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       if( transformer != null ) {\n         transformer.transform(doc, docid, 0);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n\n   // if the client specified a single id=foo, then use \"doc\":{\n   // otherwise use a standard doclist\n\n   if (ids ==  null && allIds.length <= 1) {\n     // if the doc was not found, then use a value of null.\n     rsp.add(\"doc\", docList.size() > 0 ? docList.get(0) : null);\n   } else {\n     docList.setNumFound(docList.size());\n     rsp.addResponse(docList);\n   }\n\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    String val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore().getCoreDescriptor()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n\n    String id[] = params.getParams(\"id\");\n    String ids[] = params.getParams(\"ids\");\n\n    if (id == null && ids == null) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, null, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n\n    String[] allIds = id==null ? new String[0] : id;\n\n    if (ids != null) {\n      List<String> lst = new ArrayList<>();\n      for (String s : allIds) {\n        lst.add(s);\n      }\n      for (String idList : ids) {\n        lst.addAll( StrUtils.splitSmart(idList, \",\", true) );\n      }\n      allIds = lst.toArray(new String[lst.size()]);\n    }\n\n    SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n\n    DocTransformer transformer = rsp.getReturnFields().getTransformer();\n    if (transformer != null) {\n      ResultContext context = new BasicResultContext(null, rsp.getReturnFields(), null, null, req);\n      transformer.setContext(context);\n    }\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.ADD:\n\n               if (rb.getFilters() != null) {\n                 // we have filters, so we need to check those against the indexed form of the doc\n                 if (searcherHolder != null) {\n                   // close handles to current searchers\n                   searcher = null;\n                   searcherHolder.decref();\n                   searcherHolder = null;\n                 }\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               if(transformer!=null) {\n                 transformer.transform(doc, -1, 0); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = core.getRealtimeSearcher();\n         searcher = searcherHolder.get();\n       }\n\n       int docid = -1;\n       long segAndId = searcher.lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcher.getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query q : rb.getFilters()) {\n             Scorer scorer = searcher.createWeight(q, false).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n\n       if (docid < 0) continue;\n       StoredDocument luceneDocument = searcher.doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       if( transformer != null ) {\n         transformer.transform(doc, docid, 0);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n\n   // if the client specified a single id=foo, then use \"doc\":{\n   // otherwise use a standard doclist\n\n   if (ids ==  null && allIds.length <= 1) {\n     // if the doc was not found, then use a value of null.\n     rsp.add(\"doc\", docList.size() > 0 ? docList.get(0) : null);\n   } else {\n     docList.setNumFound(docList.size());\n     rsp.addResponse(docList);\n   }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4346940138bc1085f62b4535467e6724d604bc50","date":1458915511,"type":3,"author":"yonik","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    String val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore().getCoreDescriptor()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n\n    String id[] = params.getParams(\"id\");\n    String ids[] = params.getParams(\"ids\");\n\n    if (id == null && ids == null) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, null, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n\n    String[] allIds = id==null ? new String[0] : id;\n\n    if (ids != null) {\n      List<String> lst = new ArrayList<>();\n      for (String s : allIds) {\n        lst.add(s);\n      }\n      for (String idList : ids) {\n        lst.addAll( StrUtils.splitSmart(idList, \",\", true) );\n      }\n      allIds = lst.toArray(new String[lst.size()]);\n    }\n\n    SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n\n    DocTransformer transformer = rsp.getReturnFields().getTransformer();\n    if (transformer != null) {\n      ResultContext context = new BasicResultContext(null, rsp.getReturnFields(), null, null, req);\n      transformer.setContext(context);\n    }\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.ADD:\n\n               if (rb.getFilters() != null) {\n                 // we have filters, so we need to check those against the indexed form of the doc\n                 if (searcherHolder != null) {\n                   // close handles to current searchers\n                   searcher = null;\n                   searcherHolder.decref();\n                   searcherHolder = null;\n                 }\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               if(transformer!=null) {\n                 transformer.transform(doc, -1, 0); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = core.getRealtimeSearcher();\n         searcher = searcherHolder.get();\n       }\n\n       int docid = -1;\n       long segAndId = searcher.lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcher.getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query q : rb.getFilters()) {\n             Scorer scorer = searcher.createWeight(q, false).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n\n       if (docid < 0) continue;\n       Document luceneDocument = searcher.doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       searcher.decorateDocValueFields(doc, docid, searcher.getNonStoredDVs(true));\n       if( transformer != null ) {\n         transformer.transform(doc, docid, 0);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n\n   // if the client specified a single id=foo, then use \"doc\":{\n   // otherwise use a standard doclist\n\n   if (ids ==  null && allIds.length <= 1) {\n     // if the doc was not found, then use a value of null.\n     rsp.add(\"doc\", docList.size() > 0 ? docList.get(0) : null);\n   } else {\n     docList.setNumFound(docList.size());\n     rsp.addResponse(docList);\n   }\n\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    String val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore().getCoreDescriptor()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n\n    String id[] = params.getParams(\"id\");\n    String ids[] = params.getParams(\"ids\");\n\n    if (id == null && ids == null) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, null, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n\n    String[] allIds = id==null ? new String[0] : id;\n\n    if (ids != null) {\n      List<String> lst = new ArrayList<>();\n      for (String s : allIds) {\n        lst.add(s);\n      }\n      for (String idList : ids) {\n        lst.addAll( StrUtils.splitSmart(idList, \",\", true) );\n      }\n      allIds = lst.toArray(new String[lst.size()]);\n    }\n\n    SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n\n    DocTransformer transformer = rsp.getReturnFields().getTransformer();\n    if (transformer != null) {\n      ResultContext context = new BasicResultContext(null, rsp.getReturnFields(), null, null, req);\n      transformer.setContext(context);\n    }\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.ADD:\n\n               if (rb.getFilters() != null) {\n                 // we have filters, so we need to check those against the indexed form of the doc\n                 if (searcherHolder != null) {\n                   // close handles to current searchers\n                   searcher = null;\n                   searcherHolder.decref();\n                   searcherHolder = null;\n                 }\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               if(transformer!=null) {\n                 transformer.transform(doc, -1, 0); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = core.getRealtimeSearcher();\n         searcher = searcherHolder.get();\n       }\n\n       int docid = -1;\n       long segAndId = searcher.lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcher.getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query q : rb.getFilters()) {\n             Scorer scorer = searcher.createWeight(q, false).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n\n       if (docid < 0) continue;\n       Document luceneDocument = searcher.doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       if( transformer != null ) {\n         transformer.transform(doc, docid, 0);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n\n   // if the client specified a single id=foo, then use \"doc\":{\n   // otherwise use a standard doclist\n\n   if (ids ==  null && allIds.length <= 1) {\n     // if the doc was not found, then use a value of null.\n     rsp.add(\"doc\", docList.size() > 0 ? docList.get(0) : null);\n   } else {\n     docList.setNumFound(docList.size());\n     rsp.addResponse(docList);\n   }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e511b092029d56e0d4e30204fba8509c1c2647b6","date":1467838965,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    \n    // This seems rather kludgey, may there is better way to indicate\n    // that replica can support handling version ranges\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore().getCoreDescriptor()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n\n    String id[] = params.getParams(\"id\");\n    String ids[] = params.getParams(\"ids\");\n\n    if (id == null && ids == null) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, null, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n\n    String[] allIds = id==null ? new String[0] : id;\n\n    if (ids != null) {\n      List<String> lst = new ArrayList<>();\n      for (String s : allIds) {\n        lst.add(s);\n      }\n      for (String idList : ids) {\n        lst.addAll( StrUtils.splitSmart(idList, \",\", true) );\n      }\n      allIds = lst.toArray(new String[lst.size()]);\n    }\n\n    SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n\n    DocTransformer transformer = rsp.getReturnFields().getTransformer();\n    if (transformer != null) {\n      ResultContext context = new BasicResultContext(null, rsp.getReturnFields(), null, null, req);\n      transformer.setContext(context);\n    }\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.ADD:\n\n               if (rb.getFilters() != null) {\n                 // we have filters, so we need to check those against the indexed form of the doc\n                 if (searcherHolder != null) {\n                   // close handles to current searchers\n                   searcher = null;\n                   searcherHolder.decref();\n                   searcherHolder = null;\n                 }\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               if(transformer!=null) {\n                 transformer.transform(doc, -1, 0); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = core.getRealtimeSearcher();\n         searcher = searcherHolder.get();\n       }\n\n       int docid = -1;\n       long segAndId = searcher.lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcher.getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query q : rb.getFilters()) {\n             Scorer scorer = searcher.createWeight(q, false).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n\n       if (docid < 0) continue;\n       Document luceneDocument = searcher.doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       searcher.decorateDocValueFields(doc, docid, searcher.getNonStoredDVs(true));\n       if( transformer != null ) {\n         transformer.transform(doc, docid, 0);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n\n   // if the client specified a single id=foo, then use \"doc\":{\n   // otherwise use a standard doclist\n\n   if (ids ==  null && allIds.length <= 1) {\n     // if the doc was not found, then use a value of null.\n     rsp.add(\"doc\", docList.size() > 0 ? docList.get(0) : null);\n   } else {\n     docList.setNumFound(docList.size());\n     rsp.addResponse(docList);\n   }\n\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    String val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore().getCoreDescriptor()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n\n    String id[] = params.getParams(\"id\");\n    String ids[] = params.getParams(\"ids\");\n\n    if (id == null && ids == null) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, null, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n\n    String[] allIds = id==null ? new String[0] : id;\n\n    if (ids != null) {\n      List<String> lst = new ArrayList<>();\n      for (String s : allIds) {\n        lst.add(s);\n      }\n      for (String idList : ids) {\n        lst.addAll( StrUtils.splitSmart(idList, \",\", true) );\n      }\n      allIds = lst.toArray(new String[lst.size()]);\n    }\n\n    SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n\n    DocTransformer transformer = rsp.getReturnFields().getTransformer();\n    if (transformer != null) {\n      ResultContext context = new BasicResultContext(null, rsp.getReturnFields(), null, null, req);\n      transformer.setContext(context);\n    }\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.ADD:\n\n               if (rb.getFilters() != null) {\n                 // we have filters, so we need to check those against the indexed form of the doc\n                 if (searcherHolder != null) {\n                   // close handles to current searchers\n                   searcher = null;\n                   searcherHolder.decref();\n                   searcherHolder = null;\n                 }\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               if(transformer!=null) {\n                 transformer.transform(doc, -1, 0); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = core.getRealtimeSearcher();\n         searcher = searcherHolder.get();\n       }\n\n       int docid = -1;\n       long segAndId = searcher.lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcher.getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query q : rb.getFilters()) {\n             Scorer scorer = searcher.createWeight(q, false).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n\n       if (docid < 0) continue;\n       Document luceneDocument = searcher.doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       searcher.decorateDocValueFields(doc, docid, searcher.getNonStoredDVs(true));\n       if( transformer != null ) {\n         transformer.transform(doc, docid, 0);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n\n   // if the client specified a single id=foo, then use \"doc\":{\n   // otherwise use a standard doclist\n\n   if (ids ==  null && allIds.length <= 1) {\n     // if the doc was not found, then use a value of null.\n     rsp.add(\"doc\", docList.size() > 0 ? docList.get(0) : null);\n   } else {\n     docList.setNumFound(docList.size());\n     rsp.addResponse(docList);\n   }\n\n  }\n\n","bugFix":["2c007e7c4cf8c55bc2a5884e315123afaaeec87f","bd0ef6574805f3cb9880e0983b7548a6aa933508"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8381eb1cd44d2e0defb52130de3295a576ac1e7b","date":1467840340,"type":3,"author":"Chris Hostetter","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    \n    // This seems rather kludgey, may there is better way to indicate\n    // that replica can support handling version ranges\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore().getCoreDescriptor()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n\n    String id[] = params.getParams(\"id\");\n    String ids[] = params.getParams(\"ids\");\n\n    if (id == null && ids == null) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, null, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n\n    String[] allIds = id==null ? new String[0] : id;\n\n    if (ids != null) {\n      List<String> lst = new ArrayList<>();\n      for (String s : allIds) {\n        lst.add(s);\n      }\n      for (String idList : ids) {\n        lst.addAll( StrUtils.splitSmart(idList, \",\", true) );\n      }\n      allIds = lst.toArray(new String[lst.size()]);\n    }\n\n    SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n\n    DocTransformer transformer = rsp.getReturnFields().getTransformer();\n    if (transformer != null) {\n      ResultContext context = new BasicResultContext(null, rsp.getReturnFields(), null, null, req);\n      transformer.setContext(context);\n    }\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.ADD:\n\n               if (rb.getFilters() != null) {\n                 // we have filters, so we need to check those against the indexed form of the doc\n                 if (searcherHolder != null) {\n                   // close handles to current searchers\n                   searcher = null;\n                   searcherHolder.decref();\n                   searcherHolder = null;\n                 }\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               if(transformer!=null) {\n                 transformer.transform(doc, -1, 0); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = core.getRealtimeSearcher();\n         searcher = searcherHolder.get();\n       }\n\n       int docid = -1;\n       long segAndId = searcher.lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcher.getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query q : rb.getFilters()) {\n             Scorer scorer = searcher.createWeight(q, false).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n\n       if (docid < 0) continue;\n       Document luceneDocument = searcher.doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       searcher.decorateDocValueFields(doc, docid, searcher.getNonStoredDVs(true));\n       if( transformer != null ) {\n         transformer.transform(doc, docid, 0);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n\n   // if the client specified a single id=foo, then use \"doc\":{\n   // otherwise use a standard doclist\n\n   if (ids ==  null && allIds.length <= 1) {\n     // if the doc was not found, then use a value of null.\n     rsp.add(\"doc\", docList.size() > 0 ? docList.get(0) : null);\n   } else {\n     docList.setNumFound(docList.size());\n     rsp.addResponse(docList);\n   }\n\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    String val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore().getCoreDescriptor()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n\n    String id[] = params.getParams(\"id\");\n    String ids[] = params.getParams(\"ids\");\n\n    if (id == null && ids == null) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, null, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n\n    String[] allIds = id==null ? new String[0] : id;\n\n    if (ids != null) {\n      List<String> lst = new ArrayList<>();\n      for (String s : allIds) {\n        lst.add(s);\n      }\n      for (String idList : ids) {\n        lst.addAll( StrUtils.splitSmart(idList, \",\", true) );\n      }\n      allIds = lst.toArray(new String[lst.size()]);\n    }\n\n    SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n\n    DocTransformer transformer = rsp.getReturnFields().getTransformer();\n    if (transformer != null) {\n      ResultContext context = new BasicResultContext(null, rsp.getReturnFields(), null, null, req);\n      transformer.setContext(context);\n    }\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.ADD:\n\n               if (rb.getFilters() != null) {\n                 // we have filters, so we need to check those against the indexed form of the doc\n                 if (searcherHolder != null) {\n                   // close handles to current searchers\n                   searcher = null;\n                   searcherHolder.decref();\n                   searcherHolder = null;\n                 }\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               if(transformer!=null) {\n                 transformer.transform(doc, -1, 0); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = core.getRealtimeSearcher();\n         searcher = searcherHolder.get();\n       }\n\n       int docid = -1;\n       long segAndId = searcher.lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcher.getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query q : rb.getFilters()) {\n             Scorer scorer = searcher.createWeight(q, false).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n\n       if (docid < 0) continue;\n       Document luceneDocument = searcher.doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       searcher.decorateDocValueFields(doc, docid, searcher.getNonStoredDVs(true));\n       if( transformer != null ) {\n         transformer.transform(doc, docid, 0);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n\n   // if the client specified a single id=foo, then use \"doc\":{\n   // otherwise use a standard doclist\n\n   if (ids ==  null && allIds.length <= 1) {\n     // if the doc was not found, then use a value of null.\n     rsp.add(\"doc\", docList.size() > 0 ? docList.get(0) : null);\n   } else {\n     docList.setNumFound(docList.size());\n     rsp.addResponse(docList);\n   }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"02e175abd2c4c1611c5a9647486ae8ba249a94c1","date":1468327116,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    \n    // This seems rather kludgey, may there is better way to indicate\n    // that replica can support handling version ranges\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore().getCoreDescriptor()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n\n    String id[] = params.getParams(\"id\");\n    String ids[] = params.getParams(\"ids\");\n\n    if (id == null && ids == null) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, null, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n\n    String[] allIds = id==null ? new String[0] : id;\n\n    if (ids != null) {\n      List<String> lst = new ArrayList<>();\n      for (String s : allIds) {\n        lst.add(s);\n      }\n      for (String idList : ids) {\n        lst.addAll( StrUtils.splitSmart(idList, \",\", true) );\n      }\n      allIds = lst.toArray(new String[lst.size()]);\n    }\n\n    SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n\n    DocTransformer transformer = rsp.getReturnFields().getTransformer();\n    if (transformer != null) {\n      ResultContext context = new BasicResultContext(null, rsp.getReturnFields(), null, null, req);\n      transformer.setContext(context);\n    }\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.ADD:\n\n               if (rb.getFilters() != null) {\n                 // we have filters, so we need to check those against the indexed form of the doc\n                 if (searcherHolder != null) {\n                   // close handles to current searchers\n                   searcher = null;\n                   searcherHolder.decref();\n                   searcherHolder = null;\n                 }\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               if(transformer!=null) {\n                 transformer.transform(doc, -1, 0); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = core.getRealtimeSearcher();\n         searcher = searcherHolder.get();\n       }\n\n       int docid = -1;\n       long segAndId = searcher.lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcher.getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query q : rb.getFilters()) {\n             Scorer scorer = searcher.createWeight(q, false, 1f).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n\n       if (docid < 0) continue;\n       Document luceneDocument = searcher.doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       searcher.decorateDocValueFields(doc, docid, searcher.getNonStoredDVs(true));\n       if( transformer != null ) {\n         transformer.transform(doc, docid, 0);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n\n   // if the client specified a single id=foo, then use \"doc\":{\n   // otherwise use a standard doclist\n\n   if (ids ==  null && allIds.length <= 1) {\n     // if the doc was not found, then use a value of null.\n     rsp.add(\"doc\", docList.size() > 0 ? docList.get(0) : null);\n   } else {\n     docList.setNumFound(docList.size());\n     rsp.addResponse(docList);\n   }\n\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    \n    // This seems rather kludgey, may there is better way to indicate\n    // that replica can support handling version ranges\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore().getCoreDescriptor()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n\n    String id[] = params.getParams(\"id\");\n    String ids[] = params.getParams(\"ids\");\n\n    if (id == null && ids == null) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, null, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n\n    String[] allIds = id==null ? new String[0] : id;\n\n    if (ids != null) {\n      List<String> lst = new ArrayList<>();\n      for (String s : allIds) {\n        lst.add(s);\n      }\n      for (String idList : ids) {\n        lst.addAll( StrUtils.splitSmart(idList, \",\", true) );\n      }\n      allIds = lst.toArray(new String[lst.size()]);\n    }\n\n    SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n\n    DocTransformer transformer = rsp.getReturnFields().getTransformer();\n    if (transformer != null) {\n      ResultContext context = new BasicResultContext(null, rsp.getReturnFields(), null, null, req);\n      transformer.setContext(context);\n    }\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.ADD:\n\n               if (rb.getFilters() != null) {\n                 // we have filters, so we need to check those against the indexed form of the doc\n                 if (searcherHolder != null) {\n                   // close handles to current searchers\n                   searcher = null;\n                   searcherHolder.decref();\n                   searcherHolder = null;\n                 }\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               if(transformer!=null) {\n                 transformer.transform(doc, -1, 0); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = core.getRealtimeSearcher();\n         searcher = searcherHolder.get();\n       }\n\n       int docid = -1;\n       long segAndId = searcher.lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcher.getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query q : rb.getFilters()) {\n             Scorer scorer = searcher.createWeight(q, false).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n\n       if (docid < 0) continue;\n       Document luceneDocument = searcher.doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       searcher.decorateDocValueFields(doc, docid, searcher.getNonStoredDVs(true));\n       if( transformer != null ) {\n         transformer.transform(doc, docid, 0);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n\n   // if the client specified a single id=foo, then use \"doc\":{\n   // otherwise use a standard doclist\n\n   if (ids ==  null && allIds.length <= 1) {\n     // if the doc was not found, then use a value of null.\n     rsp.add(\"doc\", docList.size() > 0 ? docList.get(0) : null);\n   } else {\n     docList.setNumFound(docList.size());\n     rsp.addResponse(docList);\n   }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"136796946c32863f11b97ebec6b4091cdfe3a20b","date":1468862468,"type":3,"author":"Chris Hostetter","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    \n    // This seems rather kludgey, may there is better way to indicate\n    // that replica can support handling version ranges\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore().getCoreDescriptor()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n\n    String id[] = params.getParams(\"id\");\n    String ids[] = params.getParams(\"ids\");\n\n    if (id == null && ids == null) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, null, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n\n    String[] allIds = id==null ? new String[0] : id;\n\n    if (ids != null) {\n      List<String> lst = new ArrayList<>();\n      for (String s : allIds) {\n        lst.add(s);\n      }\n      for (String idList : ids) {\n        lst.addAll( StrUtils.splitSmart(idList, \",\", true) );\n      }\n      allIds = lst.toArray(new String[lst.size()]);\n    }\n\n    SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n    \n    // this is initialized & set on the context *after* any searcher (re-)opening\n    ResultContext resultContext = null;\n    final DocTransformer transformer = rsp.getReturnFields().getTransformer();\n\n    // true in any situation where we have to use a realtime searcher rather then returning docs\n    // directly from the UpdateLog\n    final boolean mustUseRealtimeSearcher =\n      // if we have filters, we need to check those against the indexed form of the doc\n      (rb.getFilters() != null)\n      || ((null != transformer) && transformer.needsSolrIndexSearcher());\n\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.ADD:\n\n               if (mustUseRealtimeSearcher) {\n                 if (searcherHolder != null) {\n                   // close handles to current searchers & result context\n                   searcher = null;\n                   searcherHolder.decref();\n                   searcherHolder = null;\n                   resultContext = null;\n                 }\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               if (transformer!=null) {\n                 transformer.transform(doc, -1, 0); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = core.getRealtimeSearcher();\n         searcher = searcherHolder.get();\n         // don't bother with ResultContext yet, we won't need it if doc doesn't match filters\n       }\n\n       int docid = -1;\n       long segAndId = searcher.lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcher.getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query q : rb.getFilters()) {\n             Scorer scorer = searcher.createWeight(q, false, 1f).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n       if (docid < 0) continue;\n       \n       Document luceneDocument = searcher.doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       searcher.decorateDocValueFields(doc, docid, searcher.getNonStoredDVs(true));\n       if ( null != transformer) {\n         if (null == resultContext) {\n           // either first pass, or we've re-opened searcher - either way now we setContext\n           resultContext = new RTGResultContext(rsp.getReturnFields(), searcher, req);\n           transformer.setContext(resultContext);\n         }\n         transformer.transform(doc, docid, 0);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n\n   // if the client specified a single id=foo, then use \"doc\":{\n   // otherwise use a standard doclist\n\n   if (ids ==  null && allIds.length <= 1) {\n     // if the doc was not found, then use a value of null.\n     rsp.add(\"doc\", docList.size() > 0 ? docList.get(0) : null);\n   } else {\n     docList.setNumFound(docList.size());\n     rsp.addResponse(docList);\n   }\n\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    \n    // This seems rather kludgey, may there is better way to indicate\n    // that replica can support handling version ranges\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore().getCoreDescriptor()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n\n    String id[] = params.getParams(\"id\");\n    String ids[] = params.getParams(\"ids\");\n\n    if (id == null && ids == null) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, null, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n\n    String[] allIds = id==null ? new String[0] : id;\n\n    if (ids != null) {\n      List<String> lst = new ArrayList<>();\n      for (String s : allIds) {\n        lst.add(s);\n      }\n      for (String idList : ids) {\n        lst.addAll( StrUtils.splitSmart(idList, \",\", true) );\n      }\n      allIds = lst.toArray(new String[lst.size()]);\n    }\n\n    SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n\n    DocTransformer transformer = rsp.getReturnFields().getTransformer();\n    if (transformer != null) {\n      ResultContext context = new BasicResultContext(null, rsp.getReturnFields(), null, null, req);\n      transformer.setContext(context);\n    }\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.ADD:\n\n               if (rb.getFilters() != null) {\n                 // we have filters, so we need to check those against the indexed form of the doc\n                 if (searcherHolder != null) {\n                   // close handles to current searchers\n                   searcher = null;\n                   searcherHolder.decref();\n                   searcherHolder = null;\n                 }\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               if(transformer!=null) {\n                 transformer.transform(doc, -1, 0); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = core.getRealtimeSearcher();\n         searcher = searcherHolder.get();\n       }\n\n       int docid = -1;\n       long segAndId = searcher.lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcher.getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query q : rb.getFilters()) {\n             Scorer scorer = searcher.createWeight(q, false, 1f).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n\n       if (docid < 0) continue;\n       Document luceneDocument = searcher.doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       searcher.decorateDocValueFields(doc, docid, searcher.getNonStoredDVs(true));\n       if( transformer != null ) {\n         transformer.transform(doc, docid, 0);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n\n   // if the client specified a single id=foo, then use \"doc\":{\n   // otherwise use a standard doclist\n\n   if (ids ==  null && allIds.length <= 1) {\n     // if the doc was not found, then use a value of null.\n     rsp.add(\"doc\", docList.size() > 0 ? docList.get(0) : null);\n   } else {\n     docList.setNumFound(docList.size());\n     rsp.addResponse(docList);\n   }\n\n  }\n\n","bugFix":["7b8f0dc1dfedc7fda86aefc0cdabde0efae2d1dc","29918ccc4b27ebd261d8446761e5e02666abe893","b68df8b95f3ea758a8dc21cb20a50a01db973e8e","2b0085a9ec29ebc27be992a3712f4bd5d65d2106"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4c58bab35e821e15dc6b8669d2f15c2e3cc6d9ce","date":1468951909,"type":3,"author":"Chris Hostetter","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    \n    // This seems rather kludgey, may there is better way to indicate\n    // that replica can support handling version ranges\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore().getCoreDescriptor()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n\n    final IdsRequsted reqIds = IdsRequsted.parseParams(req);\n    \n    if (reqIds.allIds.isEmpty()) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, null, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n    SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n    \n    // this is initialized & set on the context *after* any searcher (re-)opening\n    ResultContext resultContext = null;\n    final DocTransformer transformer = rsp.getReturnFields().getTransformer();\n\n    // true in any situation where we have to use a realtime searcher rather then returning docs\n    // directly from the UpdateLog\n    final boolean mustUseRealtimeSearcher =\n      // if we have filters, we need to check those against the indexed form of the doc\n      (rb.getFilters() != null)\n      || ((null != transformer) && transformer.needsSolrIndexSearcher());\n\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : reqIds.allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.ADD:\n\n               if (mustUseRealtimeSearcher) {\n                 if (searcherHolder != null) {\n                   // close handles to current searchers & result context\n                   searcher = null;\n                   searcherHolder.decref();\n                   searcherHolder = null;\n                   resultContext = null;\n                 }\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               if (transformer!=null) {\n                 transformer.transform(doc, -1, 0); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = core.getRealtimeSearcher();\n         searcher = searcherHolder.get();\n         // don't bother with ResultContext yet, we won't need it if doc doesn't match filters\n       }\n\n       int docid = -1;\n       long segAndId = searcher.lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcher.getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query q : rb.getFilters()) {\n             Scorer scorer = searcher.createWeight(q, false, 1f).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n       if (docid < 0) continue;\n       \n       Document luceneDocument = searcher.doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       searcher.decorateDocValueFields(doc, docid, searcher.getNonStoredDVs(true));\n       if ( null != transformer) {\n         if (null == resultContext) {\n           // either first pass, or we've re-opened searcher - either way now we setContext\n           resultContext = new RTGResultContext(rsp.getReturnFields(), searcher, req);\n           transformer.setContext(resultContext);\n         }\n         transformer.transform(doc, docid, 0);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n   addDocListToResponse(rb, docList);\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    \n    // This seems rather kludgey, may there is better way to indicate\n    // that replica can support handling version ranges\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore().getCoreDescriptor()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n\n    String id[] = params.getParams(\"id\");\n    String ids[] = params.getParams(\"ids\");\n\n    if (id == null && ids == null) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, null, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n\n    String[] allIds = id==null ? new String[0] : id;\n\n    if (ids != null) {\n      List<String> lst = new ArrayList<>();\n      for (String s : allIds) {\n        lst.add(s);\n      }\n      for (String idList : ids) {\n        lst.addAll( StrUtils.splitSmart(idList, \",\", true) );\n      }\n      allIds = lst.toArray(new String[lst.size()]);\n    }\n\n    SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n    \n    // this is initialized & set on the context *after* any searcher (re-)opening\n    ResultContext resultContext = null;\n    final DocTransformer transformer = rsp.getReturnFields().getTransformer();\n\n    // true in any situation where we have to use a realtime searcher rather then returning docs\n    // directly from the UpdateLog\n    final boolean mustUseRealtimeSearcher =\n      // if we have filters, we need to check those against the indexed form of the doc\n      (rb.getFilters() != null)\n      || ((null != transformer) && transformer.needsSolrIndexSearcher());\n\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.ADD:\n\n               if (mustUseRealtimeSearcher) {\n                 if (searcherHolder != null) {\n                   // close handles to current searchers & result context\n                   searcher = null;\n                   searcherHolder.decref();\n                   searcherHolder = null;\n                   resultContext = null;\n                 }\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               if (transformer!=null) {\n                 transformer.transform(doc, -1, 0); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = core.getRealtimeSearcher();\n         searcher = searcherHolder.get();\n         // don't bother with ResultContext yet, we won't need it if doc doesn't match filters\n       }\n\n       int docid = -1;\n       long segAndId = searcher.lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcher.getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query q : rb.getFilters()) {\n             Scorer scorer = searcher.createWeight(q, false, 1f).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n       if (docid < 0) continue;\n       \n       Document luceneDocument = searcher.doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       searcher.decorateDocValueFields(doc, docid, searcher.getNonStoredDVs(true));\n       if ( null != transformer) {\n         if (null == resultContext) {\n           // either first pass, or we've re-opened searcher - either way now we setContext\n           resultContext = new RTGResultContext(rsp.getReturnFields(), searcher, req);\n           transformer.setContext(resultContext);\n         }\n         transformer.transform(doc, docid, 0);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n\n   // if the client specified a single id=foo, then use \"doc\":{\n   // otherwise use a standard doclist\n\n   if (ids ==  null && allIds.length <= 1) {\n     // if the doc was not found, then use a value of null.\n     rsp.add(\"doc\", docList.size() > 0 ? docList.get(0) : null);\n   } else {\n     docList.setNumFound(docList.size());\n     rsp.addResponse(docList);\n   }\n\n  }\n\n","bugFix":["634f330c54fd3f9f491d52036dc3f40b4f4d8934","2b0085a9ec29ebc27be992a3712f4bd5d65d2106","bd0ef6574805f3cb9880e0983b7548a6aa933508","ecd75942508378ccc92c3a26f71db6cba9f25784"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"76b65cf789129cacd84e977b8f1538aec29e0281","date":1470165799,"type":3,"author":"Chris Hostetter","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    \n    // This seems rather kludgey, may there is better way to indicate\n    // that replica can support handling version ranges\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore().getCoreDescriptor()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n\n    final IdsRequsted reqIds = IdsRequsted.parseParams(req);\n    \n    if (reqIds.allIds.isEmpty()) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, null, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n    SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n    \n    // this is initialized & set on the context *after* any searcher (re-)opening\n    ResultContext resultContext = null;\n    final DocTransformer transformer = rsp.getReturnFields().getTransformer();\n\n    // true in any situation where we have to use a realtime searcher rather then returning docs\n    // directly from the UpdateLog\n    final boolean mustUseRealtimeSearcher =\n      // if we have filters, we need to check those against the indexed form of the doc\n      (rb.getFilters() != null)\n      || ((null != transformer) && transformer.needsSolrIndexSearcher());\n\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : reqIds.allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.ADD:\n\n               if (mustUseRealtimeSearcher) {\n                 if (searcherHolder != null) {\n                   // close handles to current searchers & result context\n                   searcher = null;\n                   searcherHolder.decref();\n                   searcherHolder = null;\n                   resultContext = null;\n                 }\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               if (transformer!=null) {\n                 transformer.transform(doc, -1, 0); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = core.getRealtimeSearcher();\n         searcher = searcherHolder.get();\n         // don't bother with ResultContext yet, we won't need it if doc doesn't match filters\n       }\n\n       int docid = -1;\n       long segAndId = searcher.lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcher.getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query raw : rb.getFilters()) {\n             Query q = raw.rewrite(searcher.getIndexReader());\n             Scorer scorer = searcher.createWeight(q, false, 1f).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n       if (docid < 0) continue;\n       \n       Document luceneDocument = searcher.doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       searcher.decorateDocValueFields(doc, docid, searcher.getNonStoredDVs(true));\n       if ( null != transformer) {\n         if (null == resultContext) {\n           // either first pass, or we've re-opened searcher - either way now we setContext\n           resultContext = new RTGResultContext(rsp.getReturnFields(), searcher, req);\n           transformer.setContext(resultContext);\n         }\n         transformer.transform(doc, docid, 0);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n   addDocListToResponse(rb, docList);\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    \n    // This seems rather kludgey, may there is better way to indicate\n    // that replica can support handling version ranges\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore().getCoreDescriptor()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n\n    final IdsRequsted reqIds = IdsRequsted.parseParams(req);\n    \n    if (reqIds.allIds.isEmpty()) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, null, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n    SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n    \n    // this is initialized & set on the context *after* any searcher (re-)opening\n    ResultContext resultContext = null;\n    final DocTransformer transformer = rsp.getReturnFields().getTransformer();\n\n    // true in any situation where we have to use a realtime searcher rather then returning docs\n    // directly from the UpdateLog\n    final boolean mustUseRealtimeSearcher =\n      // if we have filters, we need to check those against the indexed form of the doc\n      (rb.getFilters() != null)\n      || ((null != transformer) && transformer.needsSolrIndexSearcher());\n\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : reqIds.allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.ADD:\n\n               if (mustUseRealtimeSearcher) {\n                 if (searcherHolder != null) {\n                   // close handles to current searchers & result context\n                   searcher = null;\n                   searcherHolder.decref();\n                   searcherHolder = null;\n                   resultContext = null;\n                 }\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               if (transformer!=null) {\n                 transformer.transform(doc, -1, 0); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = core.getRealtimeSearcher();\n         searcher = searcherHolder.get();\n         // don't bother with ResultContext yet, we won't need it if doc doesn't match filters\n       }\n\n       int docid = -1;\n       long segAndId = searcher.lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcher.getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query q : rb.getFilters()) {\n             Scorer scorer = searcher.createWeight(q, false, 1f).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n       if (docid < 0) continue;\n       \n       Document luceneDocument = searcher.doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       searcher.decorateDocValueFields(doc, docid, searcher.getNonStoredDVs(true));\n       if ( null != transformer) {\n         if (null == resultContext) {\n           // either first pass, or we've re-opened searcher - either way now we setContext\n           resultContext = new RTGResultContext(rsp.getReturnFields(), searcher, req);\n           transformer.setContext(resultContext);\n         }\n         transformer.transform(doc, docid, 0);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n   addDocListToResponse(rb, docList);\n  }\n\n","bugFix":["2b0085a9ec29ebc27be992a3712f4bd5d65d2106"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cc5ee54a993d26579e3fe1f8f2a696b46b61c48f","date":1470751445,"type":3,"author":"Christine Poerschke","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    \n    // This seems rather kludgey, may there is better way to indicate\n    // that replica can support handling version ranges\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore().getCoreDescriptor()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n\n    final IdsRequsted reqIds = IdsRequsted.parseParams(req);\n    \n    if (reqIds.allIds.isEmpty()) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n    SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n    \n    // this is initialized & set on the context *after* any searcher (re-)opening\n    ResultContext resultContext = null;\n    final DocTransformer transformer = rsp.getReturnFields().getTransformer();\n\n    // true in any situation where we have to use a realtime searcher rather then returning docs\n    // directly from the UpdateLog\n    final boolean mustUseRealtimeSearcher =\n      // if we have filters, we need to check those against the indexed form of the doc\n      (rb.getFilters() != null)\n      || ((null != transformer) && transformer.needsSolrIndexSearcher());\n\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : reqIds.allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.ADD:\n\n               if (mustUseRealtimeSearcher) {\n                 if (searcherHolder != null) {\n                   // close handles to current searchers & result context\n                   searcher = null;\n                   searcherHolder.decref();\n                   searcherHolder = null;\n                   resultContext = null;\n                 }\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               if (transformer!=null) {\n                 transformer.transform(doc, -1, 0); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = core.getRealtimeSearcher();\n         searcher = searcherHolder.get();\n         // don't bother with ResultContext yet, we won't need it if doc doesn't match filters\n       }\n\n       int docid = -1;\n       long segAndId = searcher.lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcher.getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query raw : rb.getFilters()) {\n             Query q = raw.rewrite(searcher.getIndexReader());\n             Scorer scorer = searcher.createWeight(q, false, 1f).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n       if (docid < 0) continue;\n       \n       Document luceneDocument = searcher.doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       searcher.decorateDocValueFields(doc, docid, searcher.getNonStoredDVs(true));\n       if ( null != transformer) {\n         if (null == resultContext) {\n           // either first pass, or we've re-opened searcher - either way now we setContext\n           resultContext = new RTGResultContext(rsp.getReturnFields(), searcher, req);\n           transformer.setContext(resultContext);\n         }\n         transformer.transform(doc, docid, 0);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n   addDocListToResponse(rb, docList);\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    \n    // This seems rather kludgey, may there is better way to indicate\n    // that replica can support handling version ranges\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore().getCoreDescriptor()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n\n    final IdsRequsted reqIds = IdsRequsted.parseParams(req);\n    \n    if (reqIds.allIds.isEmpty()) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, null, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n    SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n    \n    // this is initialized & set on the context *after* any searcher (re-)opening\n    ResultContext resultContext = null;\n    final DocTransformer transformer = rsp.getReturnFields().getTransformer();\n\n    // true in any situation where we have to use a realtime searcher rather then returning docs\n    // directly from the UpdateLog\n    final boolean mustUseRealtimeSearcher =\n      // if we have filters, we need to check those against the indexed form of the doc\n      (rb.getFilters() != null)\n      || ((null != transformer) && transformer.needsSolrIndexSearcher());\n\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : reqIds.allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.ADD:\n\n               if (mustUseRealtimeSearcher) {\n                 if (searcherHolder != null) {\n                   // close handles to current searchers & result context\n                   searcher = null;\n                   searcherHolder.decref();\n                   searcherHolder = null;\n                   resultContext = null;\n                 }\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               if (transformer!=null) {\n                 transformer.transform(doc, -1, 0); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = core.getRealtimeSearcher();\n         searcher = searcherHolder.get();\n         // don't bother with ResultContext yet, we won't need it if doc doesn't match filters\n       }\n\n       int docid = -1;\n       long segAndId = searcher.lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcher.getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query raw : rb.getFilters()) {\n             Query q = raw.rewrite(searcher.getIndexReader());\n             Scorer scorer = searcher.createWeight(q, false, 1f).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n       if (docid < 0) continue;\n       \n       Document luceneDocument = searcher.doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       searcher.decorateDocValueFields(doc, docid, searcher.getNonStoredDVs(true));\n       if ( null != transformer) {\n         if (null == resultContext) {\n           // either first pass, or we've re-opened searcher - either way now we setContext\n           resultContext = new RTGResultContext(rsp.getReturnFields(), searcher, req);\n           transformer.setContext(resultContext);\n         }\n         transformer.transform(doc, docid, 0);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n   addDocListToResponse(rb, docList);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8bca25eefa1f2205e2b0ef713701dc3a0fecd702","date":1470810578,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    \n    // This seems rather kludgey, may there is better way to indicate\n    // that replica can support handling version ranges\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore().getCoreDescriptor()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n\n    final IdsRequsted reqIds = IdsRequsted.parseParams(req);\n    \n    if (reqIds.allIds.isEmpty()) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n    SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n    \n    // this is initialized & set on the context *after* any searcher (re-)opening\n    ResultContext resultContext = null;\n    final DocTransformer transformer = rsp.getReturnFields().getTransformer();\n\n    // true in any situation where we have to use a realtime searcher rather then returning docs\n    // directly from the UpdateLog\n    final boolean mustUseRealtimeSearcher =\n      // if we have filters, we need to check those against the indexed form of the doc\n      (rb.getFilters() != null)\n      || ((null != transformer) && transformer.needsSolrIndexSearcher());\n\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : reqIds.allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.ADD:\n\n               if (mustUseRealtimeSearcher) {\n                 if (searcherHolder != null) {\n                   // close handles to current searchers & result context\n                   searcher = null;\n                   searcherHolder.decref();\n                   searcherHolder = null;\n                   resultContext = null;\n                 }\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               if (transformer!=null) {\n                 transformer.transform(doc, -1, 0); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = core.getRealtimeSearcher();\n         searcher = searcherHolder.get();\n         // don't bother with ResultContext yet, we won't need it if doc doesn't match filters\n       }\n\n       int docid = -1;\n       long segAndId = searcher.lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcher.getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query raw : rb.getFilters()) {\n             Query q = raw.rewrite(searcher.getIndexReader());\n             Scorer scorer = searcher.createWeight(q, false, 1f).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n       if (docid < 0) continue;\n       \n       Document luceneDocument = searcher.doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       searcher.decorateDocValueFields(doc, docid, searcher.getNonStoredDVs(true));\n       if ( null != transformer) {\n         if (null == resultContext) {\n           // either first pass, or we've re-opened searcher - either way now we setContext\n           resultContext = new RTGResultContext(rsp.getReturnFields(), searcher, req);\n           transformer.setContext(resultContext);\n         }\n         transformer.transform(doc, docid, 0);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n   addDocListToResponse(rb, docList);\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    \n    // This seems rather kludgey, may there is better way to indicate\n    // that replica can support handling version ranges\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore().getCoreDescriptor()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n\n    final IdsRequsted reqIds = IdsRequsted.parseParams(req);\n    \n    if (reqIds.allIds.isEmpty()) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, null, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n    SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n    \n    // this is initialized & set on the context *after* any searcher (re-)opening\n    ResultContext resultContext = null;\n    final DocTransformer transformer = rsp.getReturnFields().getTransformer();\n\n    // true in any situation where we have to use a realtime searcher rather then returning docs\n    // directly from the UpdateLog\n    final boolean mustUseRealtimeSearcher =\n      // if we have filters, we need to check those against the indexed form of the doc\n      (rb.getFilters() != null)\n      || ((null != transformer) && transformer.needsSolrIndexSearcher());\n\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : reqIds.allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.ADD:\n\n               if (mustUseRealtimeSearcher) {\n                 if (searcherHolder != null) {\n                   // close handles to current searchers & result context\n                   searcher = null;\n                   searcherHolder.decref();\n                   searcherHolder = null;\n                   resultContext = null;\n                 }\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               if (transformer!=null) {\n                 transformer.transform(doc, -1, 0); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = core.getRealtimeSearcher();\n         searcher = searcherHolder.get();\n         // don't bother with ResultContext yet, we won't need it if doc doesn't match filters\n       }\n\n       int docid = -1;\n       long segAndId = searcher.lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcher.getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query raw : rb.getFilters()) {\n             Query q = raw.rewrite(searcher.getIndexReader());\n             Scorer scorer = searcher.createWeight(q, false, 1f).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n       if (docid < 0) continue;\n       \n       Document luceneDocument = searcher.doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       searcher.decorateDocValueFields(doc, docid, searcher.getNonStoredDVs(true));\n       if ( null != transformer) {\n         if (null == resultContext) {\n           // either first pass, or we've re-opened searcher - either way now we setContext\n           resultContext = new RTGResultContext(rsp.getReturnFields(), searcher, req);\n           transformer.setContext(resultContext);\n         }\n         transformer.transform(doc, docid, 0);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n   addDocListToResponse(rb, docList);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3b013574eedcdbac35dc7e35b0ee616ffc38895d","date":1470897818,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    \n    // This seems rather kludgey, may there is better way to indicate\n    // that replica can support handling version ranges\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore().getCoreDescriptor()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n\n    final IdsRequsted reqIds = IdsRequsted.parseParams(req);\n    \n    if (reqIds.allIds.isEmpty()) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n    SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n    \n    // this is initialized & set on the context *after* any searcher (re-)opening\n    ResultContext resultContext = null;\n    final DocTransformer transformer = rsp.getReturnFields().getTransformer();\n\n    // true in any situation where we have to use a realtime searcher rather then returning docs\n    // directly from the UpdateLog\n    final boolean mustUseRealtimeSearcher =\n      // if we have filters, we need to check those against the indexed form of the doc\n      (rb.getFilters() != null)\n      || ((null != transformer) && transformer.needsSolrIndexSearcher());\n\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : reqIds.allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.ADD:\n\n               if (mustUseRealtimeSearcher) {\n                 if (searcherHolder != null) {\n                   // close handles to current searchers & result context\n                   searcher = null;\n                   searcherHolder.decref();\n                   searcherHolder = null;\n                   resultContext = null;\n                 }\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               if (transformer!=null) {\n                 transformer.transform(doc, -1, 0); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = core.getRealtimeSearcher();\n         searcher = searcherHolder.get();\n         // don't bother with ResultContext yet, we won't need it if doc doesn't match filters\n       }\n\n       int docid = -1;\n       long segAndId = searcher.lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcher.getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query raw : rb.getFilters()) {\n             Query q = raw.rewrite(searcher.getIndexReader());\n             Scorer scorer = searcher.createWeight(q, false, 1f).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n       if (docid < 0) continue;\n       \n       Document luceneDocument = searcher.doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       searcher.decorateDocValueFields(doc, docid, searcher.getNonStoredDVs(true));\n       if ( null != transformer) {\n         if (null == resultContext) {\n           // either first pass, or we've re-opened searcher - either way now we setContext\n           resultContext = new RTGResultContext(rsp.getReturnFields(), searcher, req);\n           transformer.setContext(resultContext);\n         }\n         transformer.transform(doc, docid, 0);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n   addDocListToResponse(rb, docList);\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    \n    // This seems rather kludgey, may there is better way to indicate\n    // that replica can support handling version ranges\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore().getCoreDescriptor()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n\n    final IdsRequsted reqIds = IdsRequsted.parseParams(req);\n    \n    if (reqIds.allIds.isEmpty()) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, null, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n    SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n    \n    // this is initialized & set on the context *after* any searcher (re-)opening\n    ResultContext resultContext = null;\n    final DocTransformer transformer = rsp.getReturnFields().getTransformer();\n\n    // true in any situation where we have to use a realtime searcher rather then returning docs\n    // directly from the UpdateLog\n    final boolean mustUseRealtimeSearcher =\n      // if we have filters, we need to check those against the indexed form of the doc\n      (rb.getFilters() != null)\n      || ((null != transformer) && transformer.needsSolrIndexSearcher());\n\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : reqIds.allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.ADD:\n\n               if (mustUseRealtimeSearcher) {\n                 if (searcherHolder != null) {\n                   // close handles to current searchers & result context\n                   searcher = null;\n                   searcherHolder.decref();\n                   searcherHolder = null;\n                   resultContext = null;\n                 }\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               if (transformer!=null) {\n                 transformer.transform(doc, -1, 0); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = core.getRealtimeSearcher();\n         searcher = searcherHolder.get();\n         // don't bother with ResultContext yet, we won't need it if doc doesn't match filters\n       }\n\n       int docid = -1;\n       long segAndId = searcher.lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcher.getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query q : rb.getFilters()) {\n             Scorer scorer = searcher.createWeight(q, false, 1f).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n       if (docid < 0) continue;\n       \n       Document luceneDocument = searcher.doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       searcher.decorateDocValueFields(doc, docid, searcher.getNonStoredDVs(true));\n       if ( null != transformer) {\n         if (null == resultContext) {\n           // either first pass, or we've re-opened searcher - either way now we setContext\n           resultContext = new RTGResultContext(rsp.getReturnFields(), searcher, req);\n           transformer.setContext(resultContext);\n         }\n         transformer.transform(doc, docid, 0);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n   addDocListToResponse(rb, docList);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fcc7eba0b32cbc7cc5b8fd388032bb833fa07786","date":1474482359,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    \n    // This seems rather kludgey, may there is better way to indicate\n    // that replica can support handling version ranges\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n    \n    val = params.get(\"getFingerprint\");\n    if(val != null) {\n      processGetFingeprint(rb);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore().getCoreDescriptor()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n\n    final IdsRequsted reqIds = IdsRequsted.parseParams(req);\n    \n    if (reqIds.allIds.isEmpty()) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n    SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n    \n    // this is initialized & set on the context *after* any searcher (re-)opening\n    ResultContext resultContext = null;\n    final DocTransformer transformer = rsp.getReturnFields().getTransformer();\n\n    // true in any situation where we have to use a realtime searcher rather then returning docs\n    // directly from the UpdateLog\n    final boolean mustUseRealtimeSearcher =\n      // if we have filters, we need to check those against the indexed form of the doc\n      (rb.getFilters() != null)\n      || ((null != transformer) && transformer.needsSolrIndexSearcher());\n\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : reqIds.allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.ADD:\n\n               if (mustUseRealtimeSearcher) {\n                 if (searcherHolder != null) {\n                   // close handles to current searchers & result context\n                   searcher = null;\n                   searcherHolder.decref();\n                   searcherHolder = null;\n                   resultContext = null;\n                 }\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               if (transformer!=null) {\n                 transformer.transform(doc, -1, 0); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = core.getRealtimeSearcher();\n         searcher = searcherHolder.get();\n         // don't bother with ResultContext yet, we won't need it if doc doesn't match filters\n       }\n\n       int docid = -1;\n       long segAndId = searcher.lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcher.getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query raw : rb.getFilters()) {\n             Query q = raw.rewrite(searcher.getIndexReader());\n             Scorer scorer = searcher.createWeight(q, false, 1f).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n       if (docid < 0) continue;\n       \n       Document luceneDocument = searcher.doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       searcher.decorateDocValueFields(doc, docid, searcher.getNonStoredDVs(true));\n       if ( null != transformer) {\n         if (null == resultContext) {\n           // either first pass, or we've re-opened searcher - either way now we setContext\n           resultContext = new RTGResultContext(rsp.getReturnFields(), searcher, req);\n           transformer.setContext(resultContext);\n         }\n         transformer.transform(doc, docid, 0);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n   addDocListToResponse(rb, docList);\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    \n    // This seems rather kludgey, may there is better way to indicate\n    // that replica can support handling version ranges\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore().getCoreDescriptor()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n\n    final IdsRequsted reqIds = IdsRequsted.parseParams(req);\n    \n    if (reqIds.allIds.isEmpty()) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n    SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n    \n    // this is initialized & set on the context *after* any searcher (re-)opening\n    ResultContext resultContext = null;\n    final DocTransformer transformer = rsp.getReturnFields().getTransformer();\n\n    // true in any situation where we have to use a realtime searcher rather then returning docs\n    // directly from the UpdateLog\n    final boolean mustUseRealtimeSearcher =\n      // if we have filters, we need to check those against the indexed form of the doc\n      (rb.getFilters() != null)\n      || ((null != transformer) && transformer.needsSolrIndexSearcher());\n\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : reqIds.allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.ADD:\n\n               if (mustUseRealtimeSearcher) {\n                 if (searcherHolder != null) {\n                   // close handles to current searchers & result context\n                   searcher = null;\n                   searcherHolder.decref();\n                   searcherHolder = null;\n                   resultContext = null;\n                 }\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               if (transformer!=null) {\n                 transformer.transform(doc, -1, 0); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = core.getRealtimeSearcher();\n         searcher = searcherHolder.get();\n         // don't bother with ResultContext yet, we won't need it if doc doesn't match filters\n       }\n\n       int docid = -1;\n       long segAndId = searcher.lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcher.getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query raw : rb.getFilters()) {\n             Query q = raw.rewrite(searcher.getIndexReader());\n             Scorer scorer = searcher.createWeight(q, false, 1f).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n       if (docid < 0) continue;\n       \n       Document luceneDocument = searcher.doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       searcher.decorateDocValueFields(doc, docid, searcher.getNonStoredDVs(true));\n       if ( null != transformer) {\n         if (null == resultContext) {\n           // either first pass, or we've re-opened searcher - either way now we setContext\n           resultContext = new RTGResultContext(rsp.getReturnFields(), searcher, req);\n           transformer.setContext(resultContext);\n         }\n         transformer.transform(doc, docid, 0);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n   addDocListToResponse(rb, docList);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"17e5da53e4e5bd659e22add9bba1cfa222e7e30d","date":1475435902,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    \n    // This seems rather kludgey, may there is better way to indicate\n    // that replica can support handling version ranges\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n    \n    val = params.get(\"getFingerprint\");\n    if(val != null) {\n      processGetFingeprint(rb);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore().getCoreDescriptor()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n\n    final IdsRequsted reqIds = IdsRequsted.parseParams(req);\n    \n    if (reqIds.allIds.isEmpty()) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n    SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n    \n    // this is initialized & set on the context *after* any searcher (re-)opening\n    ResultContext resultContext = null;\n    final DocTransformer transformer = rsp.getReturnFields().getTransformer();\n\n    // true in any situation where we have to use a realtime searcher rather then returning docs\n    // directly from the UpdateLog\n    final boolean mustUseRealtimeSearcher =\n      // if we have filters, we need to check those against the indexed form of the doc\n      (rb.getFilters() != null)\n      || ((null != transformer) && transformer.needsSolrIndexSearcher());\n\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : reqIds.allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.ADD:\n\n               if (mustUseRealtimeSearcher) {\n                 if (searcherHolder != null) {\n                   // close handles to current searchers & result context\n                   searcher = null;\n                   searcherHolder.decref();\n                   searcherHolder = null;\n                   resultContext = null;\n                 }\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               if (transformer!=null) {\n                 transformer.transform(doc, -1, 0); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = core.getRealtimeSearcher();\n         searcher = searcherHolder.get();\n         // don't bother with ResultContext yet, we won't need it if doc doesn't match filters\n       }\n\n       int docid = -1;\n       long segAndId = searcher.lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcher.getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query raw : rb.getFilters()) {\n             Query q = raw.rewrite(searcher.getIndexReader());\n             Scorer scorer = searcher.createWeight(q, false, 1f).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n       if (docid < 0) continue;\n       \n       Document luceneDocument = searcher.doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       searcher.decorateDocValueFields(doc, docid, searcher.getNonStoredDVs(true));\n       if ( null != transformer) {\n         if (null == resultContext) {\n           // either first pass, or we've re-opened searcher - either way now we setContext\n           resultContext = new RTGResultContext(rsp.getReturnFields(), searcher, req);\n           transformer.setContext(resultContext);\n         }\n         transformer.transform(doc, docid, 0);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n   addDocListToResponse(rb, docList);\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    \n    // This seems rather kludgey, may there is better way to indicate\n    // that replica can support handling version ranges\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore().getCoreDescriptor()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n\n    final IdsRequsted reqIds = IdsRequsted.parseParams(req);\n    \n    if (reqIds.allIds.isEmpty()) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n    SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n    \n    // this is initialized & set on the context *after* any searcher (re-)opening\n    ResultContext resultContext = null;\n    final DocTransformer transformer = rsp.getReturnFields().getTransformer();\n\n    // true in any situation where we have to use a realtime searcher rather then returning docs\n    // directly from the UpdateLog\n    final boolean mustUseRealtimeSearcher =\n      // if we have filters, we need to check those against the indexed form of the doc\n      (rb.getFilters() != null)\n      || ((null != transformer) && transformer.needsSolrIndexSearcher());\n\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : reqIds.allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.ADD:\n\n               if (mustUseRealtimeSearcher) {\n                 if (searcherHolder != null) {\n                   // close handles to current searchers & result context\n                   searcher = null;\n                   searcherHolder.decref();\n                   searcherHolder = null;\n                   resultContext = null;\n                 }\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               if (transformer!=null) {\n                 transformer.transform(doc, -1, 0); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = core.getRealtimeSearcher();\n         searcher = searcherHolder.get();\n         // don't bother with ResultContext yet, we won't need it if doc doesn't match filters\n       }\n\n       int docid = -1;\n       long segAndId = searcher.lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcher.getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query raw : rb.getFilters()) {\n             Query q = raw.rewrite(searcher.getIndexReader());\n             Scorer scorer = searcher.createWeight(q, false, 1f).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n       if (docid < 0) continue;\n       \n       Document luceneDocument = searcher.doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       searcher.decorateDocValueFields(doc, docid, searcher.getNonStoredDVs(true));\n       if ( null != transformer) {\n         if (null == resultContext) {\n           // either first pass, or we've re-opened searcher - either way now we setContext\n           resultContext = new RTGResultContext(rsp.getReturnFields(), searcher, req);\n           transformer.setContext(resultContext);\n         }\n         transformer.transform(doc, docid, 0);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n   addDocListToResponse(rb, docList);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    \n    // This seems rather kludgey, may there is better way to indicate\n    // that replica can support handling version ranges\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n    \n    val = params.get(\"getFingerprint\");\n    if(val != null) {\n      processGetFingeprint(rb);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore().getCoreDescriptor()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n\n    final IdsRequsted reqIds = IdsRequsted.parseParams(req);\n    \n    if (reqIds.allIds.isEmpty()) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n    SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n    \n    // this is initialized & set on the context *after* any searcher (re-)opening\n    ResultContext resultContext = null;\n    final DocTransformer transformer = rsp.getReturnFields().getTransformer();\n\n    // true in any situation where we have to use a realtime searcher rather then returning docs\n    // directly from the UpdateLog\n    final boolean mustUseRealtimeSearcher =\n      // if we have filters, we need to check those against the indexed form of the doc\n      (rb.getFilters() != null)\n      || ((null != transformer) && transformer.needsSolrIndexSearcher());\n\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : reqIds.allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.ADD:\n\n               if (mustUseRealtimeSearcher) {\n                 if (searcherHolder != null) {\n                   // close handles to current searchers & result context\n                   searcher = null;\n                   searcherHolder.decref();\n                   searcherHolder = null;\n                   resultContext = null;\n                 }\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               if (transformer!=null) {\n                 transformer.transform(doc, -1, 0); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = core.getRealtimeSearcher();\n         searcher = searcherHolder.get();\n         // don't bother with ResultContext yet, we won't need it if doc doesn't match filters\n       }\n\n       int docid = -1;\n       long segAndId = searcher.lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcher.getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query raw : rb.getFilters()) {\n             Query q = raw.rewrite(searcher.getIndexReader());\n             Scorer scorer = searcher.createWeight(q, false, 1f).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n       if (docid < 0) continue;\n       \n       Document luceneDocument = searcher.doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       searcher.decorateDocValueFields(doc, docid, searcher.getNonStoredDVs(true));\n       if ( null != transformer) {\n         if (null == resultContext) {\n           // either first pass, or we've re-opened searcher - either way now we setContext\n           resultContext = new RTGResultContext(rsp.getReturnFields(), searcher, req);\n           transformer.setContext(resultContext);\n         }\n         transformer.transform(doc, docid, 0);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n   addDocListToResponse(rb, docList);\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    String val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore().getCoreDescriptor()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n\n    String id[] = params.getParams(\"id\");\n    String ids[] = params.getParams(\"ids\");\n\n    if (id == null && ids == null) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, null, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n\n    String[] allIds = id==null ? new String[0] : id;\n\n    if (ids != null) {\n      List<String> lst = new ArrayList<>();\n      for (String s : allIds) {\n        lst.add(s);\n      }\n      for (String idList : ids) {\n        lst.addAll( StrUtils.splitSmart(idList, \",\", true) );\n      }\n      allIds = lst.toArray(new String[lst.size()]);\n    }\n\n    SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n\n    DocTransformer transformer = rsp.getReturnFields().getTransformer();\n    if (transformer != null) {\n      ResultContext context = new BasicResultContext(null, rsp.getReturnFields(), null, null, req);\n      transformer.setContext(context);\n    }\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.ADD:\n\n               if (rb.getFilters() != null) {\n                 // we have filters, so we need to check those against the indexed form of the doc\n                 if (searcherHolder != null) {\n                   // close handles to current searchers\n                   searcher = null;\n                   searcherHolder.decref();\n                   searcherHolder = null;\n                 }\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               if(transformer!=null) {\n                 transformer.transform(doc, -1, 0); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = core.getRealtimeSearcher();\n         searcher = searcherHolder.get();\n       }\n\n       int docid = -1;\n       long segAndId = searcher.lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcher.getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query q : rb.getFilters()) {\n             Scorer scorer = searcher.createWeight(q, false).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n\n       if (docid < 0) continue;\n       Document luceneDocument = searcher.doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       searcher.decorateDocValueFields(doc, docid, searcher.getNonStoredDVs(true));\n       if( transformer != null ) {\n         transformer.transform(doc, docid, 0);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n\n   // if the client specified a single id=foo, then use \"doc\":{\n   // otherwise use a standard doclist\n\n   if (ids ==  null && allIds.length <= 1) {\n     // if the doc was not found, then use a value of null.\n     rsp.add(\"doc\", docList.size() > 0 ? docList.get(0) : null);\n   } else {\n     docList.setNumFound(docList.size());\n     rsp.addResponse(docList);\n   }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"415bbbe7da8065dd3c477bdc3c703c6425622998","date":1485393793,"type":3,"author":"Ishan Chattopadhyaya","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    \n    // This seems rather kludgey, may there is better way to indicate\n    // that replica can support handling version ranges\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n    \n    val = params.get(\"getFingerprint\");\n    if(val != null) {\n      processGetFingeprint(rb);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore().getCoreDescriptor()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n    \n    val = params.get(\"getInputDocument\");\n    if (val != null) {\n      processGetInputDocument(rb);\n      return;\n    }\n\n    final IdsRequsted reqIds = IdsRequsted.parseParams(req);\n    \n    if (reqIds.allIds.isEmpty()) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n    final SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    SearcherInfo searcherInfo =  new SearcherInfo(core);\n    \n    // this is initialized & set on the context *after* any searcher (re-)opening\n    ResultContext resultContext = null;\n    final DocTransformer transformer = rsp.getReturnFields().getTransformer();\n\n    // true in any situation where we have to use a realtime searcher rather then returning docs\n    // directly from the UpdateLog\n    final boolean mustUseRealtimeSearcher =\n      // if we have filters, we need to check those against the indexed form of the doc\n      (rb.getFilters() != null)\n      || ((null != transformer) && transformer.needsSolrIndexSearcher());\n\n   try {\n\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : reqIds.allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(UpdateLog.FLAGS_IDX) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.UPDATE_INPLACE: // fall through to ADD\n             case UpdateLog.ADD:\n\n               if (mustUseRealtimeSearcher) {\n                 // close handles to current searchers & result context\n                 searcherInfo.clear();\n                 resultContext = null;\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc;\n               if (oper == UpdateLog.ADD) {\n                 doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               } else if (oper == UpdateLog.UPDATE_INPLACE) {\n                 assert entry.size() == 5;\n                 // For in-place update case, we have obtained the partial document till now. We need to\n                 // resolve it to a full document to be returned to the user.\n                 doc = resolveFullDocument(core, idBytes.get(), rsp.getReturnFields(), (SolrInputDocument)entry.get(entry.size()-1), entry, null);\n                 if (doc == null) {\n                   break; // document has been deleted as the resolve was going on\n                 }\n               } else {\n                 throw new SolrException(ErrorCode.INVALID_STATE, \"Expected ADD or UPDATE_INPLACE. Got: \" + oper);\n               }\n               if (transformer!=null) {\n                 transformer.transform(doc, -1, 0); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       searcherInfo.init();\n       // don't bother with ResultContext yet, we won't need it if doc doesn't match filters\n\n       int docid = -1;\n       long segAndId = searcherInfo.getSearcher().lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcherInfo.getSearcher().getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query raw : rb.getFilters()) {\n             Query q = raw.rewrite(searcherInfo.getSearcher().getIndexReader());\n             Scorer scorer = searcherInfo.getSearcher().createWeight(q, false, 1f).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n       if (docid < 0) continue;\n       \n       Document luceneDocument = searcherInfo.getSearcher().doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       searcherInfo.getSearcher().decorateDocValueFields(doc, docid, searcherInfo.getSearcher().getNonStoredDVs(true));\n       if ( null != transformer) {\n         if (null == resultContext) {\n           // either first pass, or we've re-opened searcher - either way now we setContext\n           resultContext = new RTGResultContext(rsp.getReturnFields(), searcherInfo.getSearcher(), req);\n           transformer.setContext(resultContext);\n         }\n         transformer.transform(doc, docid, 0);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     searcherInfo.clear();\n   }\n\n   addDocListToResponse(rb, docList);\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    \n    // This seems rather kludgey, may there is better way to indicate\n    // that replica can support handling version ranges\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n    \n    val = params.get(\"getFingerprint\");\n    if(val != null) {\n      processGetFingeprint(rb);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore().getCoreDescriptor()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n\n    final IdsRequsted reqIds = IdsRequsted.parseParams(req);\n    \n    if (reqIds.allIds.isEmpty()) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n    SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n    \n    // this is initialized & set on the context *after* any searcher (re-)opening\n    ResultContext resultContext = null;\n    final DocTransformer transformer = rsp.getReturnFields().getTransformer();\n\n    // true in any situation where we have to use a realtime searcher rather then returning docs\n    // directly from the UpdateLog\n    final boolean mustUseRealtimeSearcher =\n      // if we have filters, we need to check those against the indexed form of the doc\n      (rb.getFilters() != null)\n      || ((null != transformer) && transformer.needsSolrIndexSearcher());\n\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : reqIds.allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.ADD:\n\n               if (mustUseRealtimeSearcher) {\n                 if (searcherHolder != null) {\n                   // close handles to current searchers & result context\n                   searcher = null;\n                   searcherHolder.decref();\n                   searcherHolder = null;\n                   resultContext = null;\n                 }\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               if (transformer!=null) {\n                 transformer.transform(doc, -1, 0); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = core.getRealtimeSearcher();\n         searcher = searcherHolder.get();\n         // don't bother with ResultContext yet, we won't need it if doc doesn't match filters\n       }\n\n       int docid = -1;\n       long segAndId = searcher.lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcher.getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query raw : rb.getFilters()) {\n             Query q = raw.rewrite(searcher.getIndexReader());\n             Scorer scorer = searcher.createWeight(q, false, 1f).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n       if (docid < 0) continue;\n       \n       Document luceneDocument = searcher.doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       searcher.decorateDocValueFields(doc, docid, searcher.getNonStoredDVs(true));\n       if ( null != transformer) {\n         if (null == resultContext) {\n           // either first pass, or we've re-opened searcher - either way now we setContext\n           resultContext = new RTGResultContext(rsp.getReturnFields(), searcher, req);\n           transformer.setContext(resultContext);\n         }\n         transformer.transform(doc, docid, 0);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n   addDocListToResponse(rb, docList);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"598b5d23aa7c9732bf473c21a9cd309c44599394","date":1485530378,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    \n    // This seems rather kludgey, may there is better way to indicate\n    // that replica can support handling version ranges\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n    \n    val = params.get(\"getFingerprint\");\n    if(val != null) {\n      processGetFingeprint(rb);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore().getCoreDescriptor()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n    \n    val = params.get(\"getInputDocument\");\n    if (val != null) {\n      processGetInputDocument(rb);\n      return;\n    }\n\n    final IdsRequsted reqIds = IdsRequsted.parseParams(req);\n    \n    if (reqIds.allIds.isEmpty()) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n    final SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    SearcherInfo searcherInfo =  new SearcherInfo(core);\n    \n    // this is initialized & set on the context *after* any searcher (re-)opening\n    ResultContext resultContext = null;\n    final DocTransformer transformer = rsp.getReturnFields().getTransformer();\n\n    // true in any situation where we have to use a realtime searcher rather then returning docs\n    // directly from the UpdateLog\n    final boolean mustUseRealtimeSearcher =\n      // if we have filters, we need to check those against the indexed form of the doc\n      (rb.getFilters() != null)\n      || ((null != transformer) && transformer.needsSolrIndexSearcher());\n\n   try {\n\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : reqIds.allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(UpdateLog.FLAGS_IDX) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.UPDATE_INPLACE: // fall through to ADD\n             case UpdateLog.ADD:\n\n               if (mustUseRealtimeSearcher) {\n                 // close handles to current searchers & result context\n                 searcherInfo.clear();\n                 resultContext = null;\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc;\n               if (oper == UpdateLog.ADD) {\n                 doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               } else if (oper == UpdateLog.UPDATE_INPLACE) {\n                 assert entry.size() == 5;\n                 // For in-place update case, we have obtained the partial document till now. We need to\n                 // resolve it to a full document to be returned to the user.\n                 doc = resolveFullDocument(core, idBytes.get(), rsp.getReturnFields(), (SolrInputDocument)entry.get(entry.size()-1), entry, null);\n                 if (doc == null) {\n                   break; // document has been deleted as the resolve was going on\n                 }\n               } else {\n                 throw new SolrException(ErrorCode.INVALID_STATE, \"Expected ADD or UPDATE_INPLACE. Got: \" + oper);\n               }\n               if (transformer!=null) {\n                 transformer.transform(doc, -1, 0); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       searcherInfo.init();\n       // don't bother with ResultContext yet, we won't need it if doc doesn't match filters\n\n       int docid = -1;\n       long segAndId = searcherInfo.getSearcher().lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcherInfo.getSearcher().getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query raw : rb.getFilters()) {\n             Query q = raw.rewrite(searcherInfo.getSearcher().getIndexReader());\n             Scorer scorer = searcherInfo.getSearcher().createWeight(q, false, 1f).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n       if (docid < 0) continue;\n       \n       Document luceneDocument = searcherInfo.getSearcher().doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       searcherInfo.getSearcher().decorateDocValueFields(doc, docid, searcherInfo.getSearcher().getNonStoredDVs(true));\n       if ( null != transformer) {\n         if (null == resultContext) {\n           // either first pass, or we've re-opened searcher - either way now we setContext\n           resultContext = new RTGResultContext(rsp.getReturnFields(), searcherInfo.getSearcher(), req);\n           transformer.setContext(resultContext);\n         }\n         transformer.transform(doc, docid, 0);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     searcherInfo.clear();\n   }\n\n   addDocListToResponse(rb, docList);\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    \n    // This seems rather kludgey, may there is better way to indicate\n    // that replica can support handling version ranges\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n    \n    val = params.get(\"getFingerprint\");\n    if(val != null) {\n      processGetFingeprint(rb);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore().getCoreDescriptor()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n\n    final IdsRequsted reqIds = IdsRequsted.parseParams(req);\n    \n    if (reqIds.allIds.isEmpty()) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n    SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    RefCounted<SolrIndexSearcher> searcherHolder = null;\n    \n    // this is initialized & set on the context *after* any searcher (re-)opening\n    ResultContext resultContext = null;\n    final DocTransformer transformer = rsp.getReturnFields().getTransformer();\n\n    // true in any situation where we have to use a realtime searcher rather then returning docs\n    // directly from the UpdateLog\n    final boolean mustUseRealtimeSearcher =\n      // if we have filters, we need to check those against the indexed form of the doc\n      (rb.getFilters() != null)\n      || ((null != transformer) && transformer.needsSolrIndexSearcher());\n\n   try {\n     SolrIndexSearcher searcher = null;\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : reqIds.allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.ADD:\n\n               if (mustUseRealtimeSearcher) {\n                 if (searcherHolder != null) {\n                   // close handles to current searchers & result context\n                   searcher = null;\n                   searcherHolder.decref();\n                   searcherHolder = null;\n                   resultContext = null;\n                 }\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               if (transformer!=null) {\n                 transformer.transform(doc, -1, 0); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       if (searcher == null) {\n         searcherHolder = core.getRealtimeSearcher();\n         searcher = searcherHolder.get();\n         // don't bother with ResultContext yet, we won't need it if doc doesn't match filters\n       }\n\n       int docid = -1;\n       long segAndId = searcher.lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcher.getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query raw : rb.getFilters()) {\n             Query q = raw.rewrite(searcher.getIndexReader());\n             Scorer scorer = searcher.createWeight(q, false, 1f).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n       if (docid < 0) continue;\n       \n       Document luceneDocument = searcher.doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       searcher.decorateDocValueFields(doc, docid, searcher.getNonStoredDVs(true));\n       if ( null != transformer) {\n         if (null == resultContext) {\n           // either first pass, or we've re-opened searcher - either way now we setContext\n           resultContext = new RTGResultContext(rsp.getReturnFields(), searcher, req);\n           transformer.setContext(resultContext);\n         }\n         transformer.transform(doc, docid, 0);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     if (searcherHolder != null) {\n       searcherHolder.decref();\n     }\n   }\n\n   addDocListToResponse(rb, docList);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"63a9344cff6a72bc4c1ef080c69e10ad0635b811","date":1490410892,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    \n    // This seems rather kludgey, may there is better way to indicate\n    // that replica can support handling version ranges\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n    \n    val = params.get(\"getFingerprint\");\n    if(val != null) {\n      processGetFingeprint(rb);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore().getCoreDescriptor()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n    \n    val = params.get(\"getInputDocument\");\n    if (val != null) {\n      processGetInputDocument(rb);\n      return;\n    }\n\n    final IdsRequsted reqIds = IdsRequsted.parseParams(req);\n    \n    if (reqIds.allIds.isEmpty()) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n    final SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    SearcherInfo searcherInfo =  new SearcherInfo(core);\n    \n    // this is initialized & set on the context *after* any searcher (re-)opening\n    ResultContext resultContext = null;\n    final DocTransformer transformer = rsp.getReturnFields().getTransformer();\n\n    // true in any situation where we have to use a realtime searcher rather then returning docs\n    // directly from the UpdateLog\n    final boolean mustUseRealtimeSearcher =\n      // if we have filters, we need to check those against the indexed form of the doc\n      (rb.getFilters() != null)\n      || ((null != transformer) && transformer.needsSolrIndexSearcher());\n\n   try {\n\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : reqIds.allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(UpdateLog.FLAGS_IDX) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.UPDATE_INPLACE: // fall through to ADD\n             case UpdateLog.ADD:\n\n               if (mustUseRealtimeSearcher) {\n                 // close handles to current searchers & result context\n                 searcherInfo.clear();\n                 resultContext = null;\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc;\n               if (oper == UpdateLog.ADD) {\n                 doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               } else if (oper == UpdateLog.UPDATE_INPLACE) {\n                 assert entry.size() == 5;\n                 // For in-place update case, we have obtained the partial document till now. We need to\n                 // resolve it to a full document to be returned to the user.\n                 doc = resolveFullDocument(core, idBytes.get(), rsp.getReturnFields(), (SolrInputDocument)entry.get(entry.size()-1), entry, null);\n                 if (doc == null) {\n                   break; // document has been deleted as the resolve was going on\n                 }\n               } else {\n                 throw new SolrException(ErrorCode.INVALID_STATE, \"Expected ADD or UPDATE_INPLACE. Got: \" + oper);\n               }\n               if (transformer!=null) {\n                 transformer.transform(doc, -1, 0); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       searcherInfo.init();\n       // don't bother with ResultContext yet, we won't need it if doc doesn't match filters\n\n       int docid = -1;\n       long segAndId = searcherInfo.getSearcher().lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcherInfo.getSearcher().getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query raw : rb.getFilters()) {\n             Query q = raw.rewrite(searcherInfo.getSearcher().getIndexReader());\n             Scorer scorer = searcherInfo.getSearcher().createWeight(q, false, 1f).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n       if (docid < 0) continue;\n       \n       Document luceneDocument = searcherInfo.getSearcher().doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       SolrDocumentFetcher docFetcher = searcherInfo.getSearcher().getDocFetcher();\n       docFetcher.decorateDocValueFields(doc, docid, docFetcher.getNonStoredDVs(true));\n       if ( null != transformer) {\n         if (null == resultContext) {\n           // either first pass, or we've re-opened searcher - either way now we setContext\n           resultContext = new RTGResultContext(rsp.getReturnFields(), searcherInfo.getSearcher(), req);\n           transformer.setContext(resultContext);\n         }\n         transformer.transform(doc, docid, 0);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     searcherInfo.clear();\n   }\n\n   addDocListToResponse(rb, docList);\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    \n    // This seems rather kludgey, may there is better way to indicate\n    // that replica can support handling version ranges\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n    \n    val = params.get(\"getFingerprint\");\n    if(val != null) {\n      processGetFingeprint(rb);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore().getCoreDescriptor()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n    \n    val = params.get(\"getInputDocument\");\n    if (val != null) {\n      processGetInputDocument(rb);\n      return;\n    }\n\n    final IdsRequsted reqIds = IdsRequsted.parseParams(req);\n    \n    if (reqIds.allIds.isEmpty()) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n    final SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    SearcherInfo searcherInfo =  new SearcherInfo(core);\n    \n    // this is initialized & set on the context *after* any searcher (re-)opening\n    ResultContext resultContext = null;\n    final DocTransformer transformer = rsp.getReturnFields().getTransformer();\n\n    // true in any situation where we have to use a realtime searcher rather then returning docs\n    // directly from the UpdateLog\n    final boolean mustUseRealtimeSearcher =\n      // if we have filters, we need to check those against the indexed form of the doc\n      (rb.getFilters() != null)\n      || ((null != transformer) && transformer.needsSolrIndexSearcher());\n\n   try {\n\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : reqIds.allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(UpdateLog.FLAGS_IDX) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.UPDATE_INPLACE: // fall through to ADD\n             case UpdateLog.ADD:\n\n               if (mustUseRealtimeSearcher) {\n                 // close handles to current searchers & result context\n                 searcherInfo.clear();\n                 resultContext = null;\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc;\n               if (oper == UpdateLog.ADD) {\n                 doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               } else if (oper == UpdateLog.UPDATE_INPLACE) {\n                 assert entry.size() == 5;\n                 // For in-place update case, we have obtained the partial document till now. We need to\n                 // resolve it to a full document to be returned to the user.\n                 doc = resolveFullDocument(core, idBytes.get(), rsp.getReturnFields(), (SolrInputDocument)entry.get(entry.size()-1), entry, null);\n                 if (doc == null) {\n                   break; // document has been deleted as the resolve was going on\n                 }\n               } else {\n                 throw new SolrException(ErrorCode.INVALID_STATE, \"Expected ADD or UPDATE_INPLACE. Got: \" + oper);\n               }\n               if (transformer!=null) {\n                 transformer.transform(doc, -1, 0); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       searcherInfo.init();\n       // don't bother with ResultContext yet, we won't need it if doc doesn't match filters\n\n       int docid = -1;\n       long segAndId = searcherInfo.getSearcher().lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcherInfo.getSearcher().getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query raw : rb.getFilters()) {\n             Query q = raw.rewrite(searcherInfo.getSearcher().getIndexReader());\n             Scorer scorer = searcherInfo.getSearcher().createWeight(q, false, 1f).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n       if (docid < 0) continue;\n       \n       Document luceneDocument = searcherInfo.getSearcher().doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       searcherInfo.getSearcher().decorateDocValueFields(doc, docid, searcherInfo.getSearcher().getNonStoredDVs(true));\n       if ( null != transformer) {\n         if (null == resultContext) {\n           // either first pass, or we've re-opened searcher - either way now we setContext\n           resultContext = new RTGResultContext(rsp.getReturnFields(), searcherInfo.getSearcher(), req);\n           transformer.setContext(resultContext);\n         }\n         transformer.transform(doc, docid, 0);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     searcherInfo.clear();\n   }\n\n   addDocListToResponse(rb, docList);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"de548de3ce5405595899f548152d4b93ac9eb9cc","date":1490594650,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    \n    // This seems rather kludgey, may there is better way to indicate\n    // that replica can support handling version ranges\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n    \n    val = params.get(\"getFingerprint\");\n    if(val != null) {\n      processGetFingeprint(rb);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore().getCoreDescriptor()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n    \n    val = params.get(\"getInputDocument\");\n    if (val != null) {\n      processGetInputDocument(rb);\n      return;\n    }\n\n    final IdsRequsted reqIds = IdsRequsted.parseParams(req);\n    \n    if (reqIds.allIds.isEmpty()) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n    final SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    SearcherInfo searcherInfo =  new SearcherInfo(core);\n    \n    // this is initialized & set on the context *after* any searcher (re-)opening\n    ResultContext resultContext = null;\n    final DocTransformer transformer = rsp.getReturnFields().getTransformer();\n\n    // true in any situation where we have to use a realtime searcher rather then returning docs\n    // directly from the UpdateLog\n    final boolean mustUseRealtimeSearcher =\n      // if we have filters, we need to check those against the indexed form of the doc\n      (rb.getFilters() != null)\n      || ((null != transformer) && transformer.needsSolrIndexSearcher());\n\n   try {\n\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : reqIds.allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(UpdateLog.FLAGS_IDX) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.UPDATE_INPLACE: // fall through to ADD\n             case UpdateLog.ADD:\n\n               if (mustUseRealtimeSearcher) {\n                 // close handles to current searchers & result context\n                 searcherInfo.clear();\n                 resultContext = null;\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc;\n               if (oper == UpdateLog.ADD) {\n                 doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               } else if (oper == UpdateLog.UPDATE_INPLACE) {\n                 assert entry.size() == 5;\n                 // For in-place update case, we have obtained the partial document till now. We need to\n                 // resolve it to a full document to be returned to the user.\n                 doc = resolveFullDocument(core, idBytes.get(), rsp.getReturnFields(), (SolrInputDocument)entry.get(entry.size()-1), entry, null);\n                 if (doc == null) {\n                   break; // document has been deleted as the resolve was going on\n                 }\n               } else {\n                 throw new SolrException(ErrorCode.INVALID_STATE, \"Expected ADD or UPDATE_INPLACE. Got: \" + oper);\n               }\n               if (transformer!=null) {\n                 transformer.transform(doc, -1, 0); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       searcherInfo.init();\n       // don't bother with ResultContext yet, we won't need it if doc doesn't match filters\n\n       int docid = -1;\n       long segAndId = searcherInfo.getSearcher().lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcherInfo.getSearcher().getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query raw : rb.getFilters()) {\n             Query q = raw.rewrite(searcherInfo.getSearcher().getIndexReader());\n             Scorer scorer = searcherInfo.getSearcher().createWeight(q, false, 1f).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n       if (docid < 0) continue;\n       \n       Document luceneDocument = searcherInfo.getSearcher().doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       SolrDocumentFetcher docFetcher = searcherInfo.getSearcher().getDocFetcher();\n       docFetcher.decorateDocValueFields(doc, docid, docFetcher.getNonStoredDVs(true));\n       if ( null != transformer) {\n         if (null == resultContext) {\n           // either first pass, or we've re-opened searcher - either way now we setContext\n           resultContext = new RTGResultContext(rsp.getReturnFields(), searcherInfo.getSearcher(), req);\n           transformer.setContext(resultContext);\n         }\n         transformer.transform(doc, docid, 0);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     searcherInfo.clear();\n   }\n\n   addDocListToResponse(rb, docList);\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    \n    // This seems rather kludgey, may there is better way to indicate\n    // that replica can support handling version ranges\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n    \n    val = params.get(\"getFingerprint\");\n    if(val != null) {\n      processGetFingeprint(rb);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore().getCoreDescriptor()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n    \n    val = params.get(\"getInputDocument\");\n    if (val != null) {\n      processGetInputDocument(rb);\n      return;\n    }\n\n    final IdsRequsted reqIds = IdsRequsted.parseParams(req);\n    \n    if (reqIds.allIds.isEmpty()) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n    final SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    SearcherInfo searcherInfo =  new SearcherInfo(core);\n    \n    // this is initialized & set on the context *after* any searcher (re-)opening\n    ResultContext resultContext = null;\n    final DocTransformer transformer = rsp.getReturnFields().getTransformer();\n\n    // true in any situation where we have to use a realtime searcher rather then returning docs\n    // directly from the UpdateLog\n    final boolean mustUseRealtimeSearcher =\n      // if we have filters, we need to check those against the indexed form of the doc\n      (rb.getFilters() != null)\n      || ((null != transformer) && transformer.needsSolrIndexSearcher());\n\n   try {\n\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : reqIds.allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(UpdateLog.FLAGS_IDX) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.UPDATE_INPLACE: // fall through to ADD\n             case UpdateLog.ADD:\n\n               if (mustUseRealtimeSearcher) {\n                 // close handles to current searchers & result context\n                 searcherInfo.clear();\n                 resultContext = null;\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc;\n               if (oper == UpdateLog.ADD) {\n                 doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               } else if (oper == UpdateLog.UPDATE_INPLACE) {\n                 assert entry.size() == 5;\n                 // For in-place update case, we have obtained the partial document till now. We need to\n                 // resolve it to a full document to be returned to the user.\n                 doc = resolveFullDocument(core, idBytes.get(), rsp.getReturnFields(), (SolrInputDocument)entry.get(entry.size()-1), entry, null);\n                 if (doc == null) {\n                   break; // document has been deleted as the resolve was going on\n                 }\n               } else {\n                 throw new SolrException(ErrorCode.INVALID_STATE, \"Expected ADD or UPDATE_INPLACE. Got: \" + oper);\n               }\n               if (transformer!=null) {\n                 transformer.transform(doc, -1, 0); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       searcherInfo.init();\n       // don't bother with ResultContext yet, we won't need it if doc doesn't match filters\n\n       int docid = -1;\n       long segAndId = searcherInfo.getSearcher().lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcherInfo.getSearcher().getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query raw : rb.getFilters()) {\n             Query q = raw.rewrite(searcherInfo.getSearcher().getIndexReader());\n             Scorer scorer = searcherInfo.getSearcher().createWeight(q, false, 1f).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n       if (docid < 0) continue;\n       \n       Document luceneDocument = searcherInfo.getSearcher().doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       searcherInfo.getSearcher().decorateDocValueFields(doc, docid, searcherInfo.getSearcher().getNonStoredDVs(true));\n       if ( null != transformer) {\n         if (null == resultContext) {\n           // either first pass, or we've re-opened searcher - either way now we setContext\n           resultContext = new RTGResultContext(rsp.getReturnFields(), searcherInfo.getSearcher(), req);\n           transformer.setContext(resultContext);\n         }\n         transformer.transform(doc, docid, 0);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     searcherInfo.clear();\n   }\n\n   addDocListToResponse(rb, docList);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"729cb470f975115d4c60517b2cb7c42e37a7a2e1","date":1492041760,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    \n    // This seems rather kludgey, may there is better way to indicate\n    // that replica can support handling version ranges\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n    \n    val = params.get(\"getFingerprint\");\n    if(val != null) {\n      processGetFingeprint(rb);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n    \n    val = params.get(\"getInputDocument\");\n    if (val != null) {\n      processGetInputDocument(rb);\n      return;\n    }\n\n    final IdsRequsted reqIds = IdsRequsted.parseParams(req);\n    \n    if (reqIds.allIds.isEmpty()) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n    final SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    SearcherInfo searcherInfo =  new SearcherInfo(core);\n    \n    // this is initialized & set on the context *after* any searcher (re-)opening\n    ResultContext resultContext = null;\n    final DocTransformer transformer = rsp.getReturnFields().getTransformer();\n\n    // true in any situation where we have to use a realtime searcher rather then returning docs\n    // directly from the UpdateLog\n    final boolean mustUseRealtimeSearcher =\n      // if we have filters, we need to check those against the indexed form of the doc\n      (rb.getFilters() != null)\n      || ((null != transformer) && transformer.needsSolrIndexSearcher());\n\n   try {\n\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : reqIds.allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(UpdateLog.FLAGS_IDX) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.UPDATE_INPLACE: // fall through to ADD\n             case UpdateLog.ADD:\n\n               if (mustUseRealtimeSearcher) {\n                 // close handles to current searchers & result context\n                 searcherInfo.clear();\n                 resultContext = null;\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc;\n               if (oper == UpdateLog.ADD) {\n                 doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               } else if (oper == UpdateLog.UPDATE_INPLACE) {\n                 assert entry.size() == 5;\n                 // For in-place update case, we have obtained the partial document till now. We need to\n                 // resolve it to a full document to be returned to the user.\n                 doc = resolveFullDocument(core, idBytes.get(), rsp.getReturnFields(), (SolrInputDocument)entry.get(entry.size()-1), entry, null);\n                 if (doc == null) {\n                   break; // document has been deleted as the resolve was going on\n                 }\n               } else {\n                 throw new SolrException(ErrorCode.INVALID_STATE, \"Expected ADD or UPDATE_INPLACE. Got: \" + oper);\n               }\n               if (transformer!=null) {\n                 transformer.transform(doc, -1, 0); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       searcherInfo.init();\n       // don't bother with ResultContext yet, we won't need it if doc doesn't match filters\n\n       int docid = -1;\n       long segAndId = searcherInfo.getSearcher().lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcherInfo.getSearcher().getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query raw : rb.getFilters()) {\n             Query q = raw.rewrite(searcherInfo.getSearcher().getIndexReader());\n             Scorer scorer = searcherInfo.getSearcher().createWeight(q, false, 1f).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n       if (docid < 0) continue;\n       \n       Document luceneDocument = searcherInfo.getSearcher().doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       SolrDocumentFetcher docFetcher = searcherInfo.getSearcher().getDocFetcher();\n       docFetcher.decorateDocValueFields(doc, docid, docFetcher.getNonStoredDVs(true));\n       if ( null != transformer) {\n         if (null == resultContext) {\n           // either first pass, or we've re-opened searcher - either way now we setContext\n           resultContext = new RTGResultContext(rsp.getReturnFields(), searcherInfo.getSearcher(), req);\n           transformer.setContext(resultContext);\n         }\n         transformer.transform(doc, docid, 0);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     searcherInfo.clear();\n   }\n\n   addDocListToResponse(rb, docList);\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    \n    // This seems rather kludgey, may there is better way to indicate\n    // that replica can support handling version ranges\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n    \n    val = params.get(\"getFingerprint\");\n    if(val != null) {\n      processGetFingeprint(rb);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore().getCoreDescriptor()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n    \n    val = params.get(\"getInputDocument\");\n    if (val != null) {\n      processGetInputDocument(rb);\n      return;\n    }\n\n    final IdsRequsted reqIds = IdsRequsted.parseParams(req);\n    \n    if (reqIds.allIds.isEmpty()) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n    final SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    SearcherInfo searcherInfo =  new SearcherInfo(core);\n    \n    // this is initialized & set on the context *after* any searcher (re-)opening\n    ResultContext resultContext = null;\n    final DocTransformer transformer = rsp.getReturnFields().getTransformer();\n\n    // true in any situation where we have to use a realtime searcher rather then returning docs\n    // directly from the UpdateLog\n    final boolean mustUseRealtimeSearcher =\n      // if we have filters, we need to check those against the indexed form of the doc\n      (rb.getFilters() != null)\n      || ((null != transformer) && transformer.needsSolrIndexSearcher());\n\n   try {\n\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : reqIds.allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(UpdateLog.FLAGS_IDX) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.UPDATE_INPLACE: // fall through to ADD\n             case UpdateLog.ADD:\n\n               if (mustUseRealtimeSearcher) {\n                 // close handles to current searchers & result context\n                 searcherInfo.clear();\n                 resultContext = null;\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc;\n               if (oper == UpdateLog.ADD) {\n                 doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               } else if (oper == UpdateLog.UPDATE_INPLACE) {\n                 assert entry.size() == 5;\n                 // For in-place update case, we have obtained the partial document till now. We need to\n                 // resolve it to a full document to be returned to the user.\n                 doc = resolveFullDocument(core, idBytes.get(), rsp.getReturnFields(), (SolrInputDocument)entry.get(entry.size()-1), entry, null);\n                 if (doc == null) {\n                   break; // document has been deleted as the resolve was going on\n                 }\n               } else {\n                 throw new SolrException(ErrorCode.INVALID_STATE, \"Expected ADD or UPDATE_INPLACE. Got: \" + oper);\n               }\n               if (transformer!=null) {\n                 transformer.transform(doc, -1, 0); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       searcherInfo.init();\n       // don't bother with ResultContext yet, we won't need it if doc doesn't match filters\n\n       int docid = -1;\n       long segAndId = searcherInfo.getSearcher().lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcherInfo.getSearcher().getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query raw : rb.getFilters()) {\n             Query q = raw.rewrite(searcherInfo.getSearcher().getIndexReader());\n             Scorer scorer = searcherInfo.getSearcher().createWeight(q, false, 1f).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n       if (docid < 0) continue;\n       \n       Document luceneDocument = searcherInfo.getSearcher().doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       SolrDocumentFetcher docFetcher = searcherInfo.getSearcher().getDocFetcher();\n       docFetcher.decorateDocValueFields(doc, docid, docFetcher.getNonStoredDVs(true));\n       if ( null != transformer) {\n         if (null == resultContext) {\n           // either first pass, or we've re-opened searcher - either way now we setContext\n           resultContext = new RTGResultContext(rsp.getReturnFields(), searcherInfo.getSearcher(), req);\n           transformer.setContext(resultContext);\n         }\n         transformer.transform(doc, docid, 0);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     searcherInfo.clear();\n   }\n\n   addDocListToResponse(rb, docList);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54ca69905c5d9d1529286f06ab1d12c68f6c13cb","date":1492683554,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    \n    // This seems rather kludgey, may there is better way to indicate\n    // that replica can support handling version ranges\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n    \n    val = params.get(\"getFingerprint\");\n    if(val != null) {\n      processGetFingeprint(rb);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n    \n    val = params.get(\"getInputDocument\");\n    if (val != null) {\n      processGetInputDocument(rb);\n      return;\n    }\n\n    final IdsRequsted reqIds = IdsRequsted.parseParams(req);\n    \n    if (reqIds.allIds.isEmpty()) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n    final SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    SearcherInfo searcherInfo =  new SearcherInfo(core);\n    \n    // this is initialized & set on the context *after* any searcher (re-)opening\n    ResultContext resultContext = null;\n    final DocTransformer transformer = rsp.getReturnFields().getTransformer();\n\n    // true in any situation where we have to use a realtime searcher rather then returning docs\n    // directly from the UpdateLog\n    final boolean mustUseRealtimeSearcher =\n      // if we have filters, we need to check those against the indexed form of the doc\n      (rb.getFilters() != null)\n      || ((null != transformer) && transformer.needsSolrIndexSearcher());\n\n   try {\n\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : reqIds.allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(UpdateLog.FLAGS_IDX) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.UPDATE_INPLACE: // fall through to ADD\n             case UpdateLog.ADD:\n\n               if (mustUseRealtimeSearcher) {\n                 // close handles to current searchers & result context\n                 searcherInfo.clear();\n                 resultContext = null;\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc;\n               if (oper == UpdateLog.ADD) {\n                 doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               } else if (oper == UpdateLog.UPDATE_INPLACE) {\n                 assert entry.size() == 5;\n                 // For in-place update case, we have obtained the partial document till now. We need to\n                 // resolve it to a full document to be returned to the user.\n                 doc = resolveFullDocument(core, idBytes.get(), rsp.getReturnFields(), (SolrInputDocument)entry.get(entry.size()-1), entry, null);\n                 if (doc == null) {\n                   break; // document has been deleted as the resolve was going on\n                 }\n               } else {\n                 throw new SolrException(ErrorCode.INVALID_STATE, \"Expected ADD or UPDATE_INPLACE. Got: \" + oper);\n               }\n               if (transformer!=null) {\n                 transformer.transform(doc, -1, 0); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       searcherInfo.init();\n       // don't bother with ResultContext yet, we won't need it if doc doesn't match filters\n\n       int docid = -1;\n       long segAndId = searcherInfo.getSearcher().lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcherInfo.getSearcher().getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query raw : rb.getFilters()) {\n             Query q = raw.rewrite(searcherInfo.getSearcher().getIndexReader());\n             Scorer scorer = searcherInfo.getSearcher().createWeight(q, false, 1f).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n       if (docid < 0) continue;\n       \n       Document luceneDocument = searcherInfo.getSearcher().doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       SolrDocumentFetcher docFetcher = searcherInfo.getSearcher().getDocFetcher();\n       docFetcher.decorateDocValueFields(doc, docid, docFetcher.getNonStoredDVs(true));\n       if ( null != transformer) {\n         if (null == resultContext) {\n           // either first pass, or we've re-opened searcher - either way now we setContext\n           resultContext = new RTGResultContext(rsp.getReturnFields(), searcherInfo.getSearcher(), req);\n           transformer.setContext(resultContext);\n         }\n         transformer.transform(doc, docid, 0);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     searcherInfo.clear();\n   }\n\n   addDocListToResponse(rb, docList);\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    \n    // This seems rather kludgey, may there is better way to indicate\n    // that replica can support handling version ranges\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n    \n    val = params.get(\"getFingerprint\");\n    if(val != null) {\n      processGetFingeprint(rb);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore().getCoreDescriptor()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n    \n    val = params.get(\"getInputDocument\");\n    if (val != null) {\n      processGetInputDocument(rb);\n      return;\n    }\n\n    final IdsRequsted reqIds = IdsRequsted.parseParams(req);\n    \n    if (reqIds.allIds.isEmpty()) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n    final SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    SearcherInfo searcherInfo =  new SearcherInfo(core);\n    \n    // this is initialized & set on the context *after* any searcher (re-)opening\n    ResultContext resultContext = null;\n    final DocTransformer transformer = rsp.getReturnFields().getTransformer();\n\n    // true in any situation where we have to use a realtime searcher rather then returning docs\n    // directly from the UpdateLog\n    final boolean mustUseRealtimeSearcher =\n      // if we have filters, we need to check those against the indexed form of the doc\n      (rb.getFilters() != null)\n      || ((null != transformer) && transformer.needsSolrIndexSearcher());\n\n   try {\n\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : reqIds.allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(UpdateLog.FLAGS_IDX) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.UPDATE_INPLACE: // fall through to ADD\n             case UpdateLog.ADD:\n\n               if (mustUseRealtimeSearcher) {\n                 // close handles to current searchers & result context\n                 searcherInfo.clear();\n                 resultContext = null;\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc;\n               if (oper == UpdateLog.ADD) {\n                 doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               } else if (oper == UpdateLog.UPDATE_INPLACE) {\n                 assert entry.size() == 5;\n                 // For in-place update case, we have obtained the partial document till now. We need to\n                 // resolve it to a full document to be returned to the user.\n                 doc = resolveFullDocument(core, idBytes.get(), rsp.getReturnFields(), (SolrInputDocument)entry.get(entry.size()-1), entry, null);\n                 if (doc == null) {\n                   break; // document has been deleted as the resolve was going on\n                 }\n               } else {\n                 throw new SolrException(ErrorCode.INVALID_STATE, \"Expected ADD or UPDATE_INPLACE. Got: \" + oper);\n               }\n               if (transformer!=null) {\n                 transformer.transform(doc, -1, 0); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       searcherInfo.init();\n       // don't bother with ResultContext yet, we won't need it if doc doesn't match filters\n\n       int docid = -1;\n       long segAndId = searcherInfo.getSearcher().lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcherInfo.getSearcher().getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query raw : rb.getFilters()) {\n             Query q = raw.rewrite(searcherInfo.getSearcher().getIndexReader());\n             Scorer scorer = searcherInfo.getSearcher().createWeight(q, false, 1f).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n       if (docid < 0) continue;\n       \n       Document luceneDocument = searcherInfo.getSearcher().doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       SolrDocumentFetcher docFetcher = searcherInfo.getSearcher().getDocFetcher();\n       docFetcher.decorateDocValueFields(doc, docid, docFetcher.getNonStoredDVs(true));\n       if ( null != transformer) {\n         if (null == resultContext) {\n           // either first pass, or we've re-opened searcher - either way now we setContext\n           resultContext = new RTGResultContext(rsp.getReturnFields(), searcherInfo.getSearcher(), req);\n           transformer.setContext(resultContext);\n         }\n         transformer.transform(doc, docid, 0);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     searcherInfo.clear();\n   }\n\n   addDocListToResponse(rb, docList);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"61c45e99cf6676da48f19d7511c73712ad39402b","date":1495508331,"type":3,"author":"Tomas Fernandez Lobbe","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    CloudDescriptor cloudDesc = req.getCore().getCoreDescriptor().getCloudDescriptor();\n\n    if (cloudDesc != null) {\n      Replica.Type replicaType = cloudDesc.getReplicaType();\n      if (replicaType != null) {\n        if (replicaType == Replica.Type.PULL) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \n              String.format(Locale.ROOT, \"%s can't handle realtime get requests. Replicas of type %s do not support these type of requests\", \n                  cloudDesc.getCoreNodeName(),\n                  Replica.Type.PULL));\n        } \n        // non-leader TLOG replicas should not respond to distrib /get requests, but internal requests are OK\n      }\n    }\n    \n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    \n    // This seems rather kludgey, may there is better way to indicate\n    // that replica can support handling version ranges\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n    \n    val = params.get(\"getFingerprint\");\n    if(val != null) {\n      processGetFingeprint(rb);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n    \n    val = params.get(\"getInputDocument\");\n    if (val != null) {\n      processGetInputDocument(rb);\n      return;\n    }\n\n    final IdsRequsted reqIds = IdsRequsted.parseParams(req);\n    \n    if (reqIds.allIds.isEmpty()) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n    final SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    SearcherInfo searcherInfo =  new SearcherInfo(core);\n    \n    // this is initialized & set on the context *after* any searcher (re-)opening\n    ResultContext resultContext = null;\n    final DocTransformer transformer = rsp.getReturnFields().getTransformer();\n\n    // true in any situation where we have to use a realtime searcher rather then returning docs\n    // directly from the UpdateLog\n    final boolean mustUseRealtimeSearcher =\n      // if we have filters, we need to check those against the indexed form of the doc\n      (rb.getFilters() != null)\n      || ((null != transformer) && transformer.needsSolrIndexSearcher());\n\n   try {\n\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : reqIds.allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(UpdateLog.FLAGS_IDX) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.UPDATE_INPLACE: // fall through to ADD\n             case UpdateLog.ADD:\n\n               if (mustUseRealtimeSearcher) {\n                 // close handles to current searchers & result context\n                 searcherInfo.clear();\n                 resultContext = null;\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc;\n               if (oper == UpdateLog.ADD) {\n                 doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               } else if (oper == UpdateLog.UPDATE_INPLACE) {\n                 assert entry.size() == 5;\n                 // For in-place update case, we have obtained the partial document till now. We need to\n                 // resolve it to a full document to be returned to the user.\n                 doc = resolveFullDocument(core, idBytes.get(), rsp.getReturnFields(), (SolrInputDocument)entry.get(entry.size()-1), entry, null);\n                 if (doc == null) {\n                   break; // document has been deleted as the resolve was going on\n                 }\n               } else {\n                 throw new SolrException(ErrorCode.INVALID_STATE, \"Expected ADD or UPDATE_INPLACE. Got: \" + oper);\n               }\n               if (transformer!=null) {\n                 transformer.transform(doc, -1, 0); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       searcherInfo.init();\n       // don't bother with ResultContext yet, we won't need it if doc doesn't match filters\n\n       int docid = -1;\n       long segAndId = searcherInfo.getSearcher().lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcherInfo.getSearcher().getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query raw : rb.getFilters()) {\n             Query q = raw.rewrite(searcherInfo.getSearcher().getIndexReader());\n             Scorer scorer = searcherInfo.getSearcher().createWeight(q, false, 1f).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n       if (docid < 0) continue;\n       \n       Document luceneDocument = searcherInfo.getSearcher().doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       SolrDocumentFetcher docFetcher = searcherInfo.getSearcher().getDocFetcher();\n       docFetcher.decorateDocValueFields(doc, docid, docFetcher.getNonStoredDVs(true));\n       if ( null != transformer) {\n         if (null == resultContext) {\n           // either first pass, or we've re-opened searcher - either way now we setContext\n           resultContext = new RTGResultContext(rsp.getReturnFields(), searcherInfo.getSearcher(), req);\n           transformer.setContext(resultContext);\n         }\n         transformer.transform(doc, docid, 0);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     searcherInfo.clear();\n   }\n\n   addDocListToResponse(rb, docList);\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    \n    // This seems rather kludgey, may there is better way to indicate\n    // that replica can support handling version ranges\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n    \n    val = params.get(\"getFingerprint\");\n    if(val != null) {\n      processGetFingeprint(rb);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n    \n    val = params.get(\"getInputDocument\");\n    if (val != null) {\n      processGetInputDocument(rb);\n      return;\n    }\n\n    final IdsRequsted reqIds = IdsRequsted.parseParams(req);\n    \n    if (reqIds.allIds.isEmpty()) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n    final SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    SearcherInfo searcherInfo =  new SearcherInfo(core);\n    \n    // this is initialized & set on the context *after* any searcher (re-)opening\n    ResultContext resultContext = null;\n    final DocTransformer transformer = rsp.getReturnFields().getTransformer();\n\n    // true in any situation where we have to use a realtime searcher rather then returning docs\n    // directly from the UpdateLog\n    final boolean mustUseRealtimeSearcher =\n      // if we have filters, we need to check those against the indexed form of the doc\n      (rb.getFilters() != null)\n      || ((null != transformer) && transformer.needsSolrIndexSearcher());\n\n   try {\n\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : reqIds.allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(UpdateLog.FLAGS_IDX) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.UPDATE_INPLACE: // fall through to ADD\n             case UpdateLog.ADD:\n\n               if (mustUseRealtimeSearcher) {\n                 // close handles to current searchers & result context\n                 searcherInfo.clear();\n                 resultContext = null;\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc;\n               if (oper == UpdateLog.ADD) {\n                 doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               } else if (oper == UpdateLog.UPDATE_INPLACE) {\n                 assert entry.size() == 5;\n                 // For in-place update case, we have obtained the partial document till now. We need to\n                 // resolve it to a full document to be returned to the user.\n                 doc = resolveFullDocument(core, idBytes.get(), rsp.getReturnFields(), (SolrInputDocument)entry.get(entry.size()-1), entry, null);\n                 if (doc == null) {\n                   break; // document has been deleted as the resolve was going on\n                 }\n               } else {\n                 throw new SolrException(ErrorCode.INVALID_STATE, \"Expected ADD or UPDATE_INPLACE. Got: \" + oper);\n               }\n               if (transformer!=null) {\n                 transformer.transform(doc, -1, 0); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       searcherInfo.init();\n       // don't bother with ResultContext yet, we won't need it if doc doesn't match filters\n\n       int docid = -1;\n       long segAndId = searcherInfo.getSearcher().lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcherInfo.getSearcher().getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query raw : rb.getFilters()) {\n             Query q = raw.rewrite(searcherInfo.getSearcher().getIndexReader());\n             Scorer scorer = searcherInfo.getSearcher().createWeight(q, false, 1f).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n       if (docid < 0) continue;\n       \n       Document luceneDocument = searcherInfo.getSearcher().doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       SolrDocumentFetcher docFetcher = searcherInfo.getSearcher().getDocFetcher();\n       docFetcher.decorateDocValueFields(doc, docid, docFetcher.getNonStoredDVs(true));\n       if ( null != transformer) {\n         if (null == resultContext) {\n           // either first pass, or we've re-opened searcher - either way now we setContext\n           resultContext = new RTGResultContext(rsp.getReturnFields(), searcherInfo.getSearcher(), req);\n           transformer.setContext(resultContext);\n         }\n         transformer.transform(doc, docid, 0);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     searcherInfo.clear();\n   }\n\n   addDocListToResponse(rb, docList);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e9017cf144952056066919f1ebc7897ff9bd71b1","date":1496757600,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    CloudDescriptor cloudDesc = req.getCore().getCoreDescriptor().getCloudDescriptor();\n\n    if (cloudDesc != null) {\n      Replica.Type replicaType = cloudDesc.getReplicaType();\n      if (replicaType != null) {\n        if (replicaType == Replica.Type.PULL) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \n              String.format(Locale.ROOT, \"%s can't handle realtime get requests. Replicas of type %s do not support these type of requests\", \n                  cloudDesc.getCoreNodeName(),\n                  Replica.Type.PULL));\n        } \n        // non-leader TLOG replicas should not respond to distrib /get requests, but internal requests are OK\n      }\n    }\n    \n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    \n    // This seems rather kludgey, may there is better way to indicate\n    // that replica can support handling version ranges\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n    \n    val = params.get(\"getFingerprint\");\n    if(val != null) {\n      processGetFingeprint(rb);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n    \n    val = params.get(\"getInputDocument\");\n    if (val != null) {\n      processGetInputDocument(rb);\n      return;\n    }\n\n    final IdsRequsted reqIds = IdsRequsted.parseParams(req);\n    \n    if (reqIds.allIds.isEmpty()) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n    final SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    SearcherInfo searcherInfo =  new SearcherInfo(core);\n    \n    // this is initialized & set on the context *after* any searcher (re-)opening\n    ResultContext resultContext = null;\n    final DocTransformer transformer = rsp.getReturnFields().getTransformer();\n\n    // true in any situation where we have to use a realtime searcher rather then returning docs\n    // directly from the UpdateLog\n    final boolean mustUseRealtimeSearcher =\n      // if we have filters, we need to check those against the indexed form of the doc\n      (rb.getFilters() != null)\n      || ((null != transformer) && transformer.needsSolrIndexSearcher());\n\n   try {\n\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : reqIds.allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(UpdateLog.FLAGS_IDX) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.UPDATE_INPLACE: // fall through to ADD\n             case UpdateLog.ADD:\n\n               if (mustUseRealtimeSearcher) {\n                 // close handles to current searchers & result context\n                 searcherInfo.clear();\n                 resultContext = null;\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc;\n               if (oper == UpdateLog.ADD) {\n                 doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               } else if (oper == UpdateLog.UPDATE_INPLACE) {\n                 assert entry.size() == 5;\n                 // For in-place update case, we have obtained the partial document till now. We need to\n                 // resolve it to a full document to be returned to the user.\n                 doc = resolveFullDocument(core, idBytes.get(), rsp.getReturnFields(), (SolrInputDocument)entry.get(entry.size()-1), entry, null);\n                 if (doc == null) {\n                   break; // document has been deleted as the resolve was going on\n                 }\n               } else {\n                 throw new SolrException(ErrorCode.INVALID_STATE, \"Expected ADD or UPDATE_INPLACE. Got: \" + oper);\n               }\n               if (transformer!=null) {\n                 transformer.transform(doc, -1, 0); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       searcherInfo.init();\n       // don't bother with ResultContext yet, we won't need it if doc doesn't match filters\n\n       int docid = -1;\n       long segAndId = searcherInfo.getSearcher().lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcherInfo.getSearcher().getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query raw : rb.getFilters()) {\n             Query q = raw.rewrite(searcherInfo.getSearcher().getIndexReader());\n             Scorer scorer = searcherInfo.getSearcher().createWeight(q, false, 1f).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n       if (docid < 0) continue;\n       \n       Document luceneDocument = searcherInfo.getSearcher().doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       SolrDocumentFetcher docFetcher = searcherInfo.getSearcher().getDocFetcher();\n       docFetcher.decorateDocValueFields(doc, docid, docFetcher.getNonStoredDVs(true));\n       if ( null != transformer) {\n         if (null == resultContext) {\n           // either first pass, or we've re-opened searcher - either way now we setContext\n           resultContext = new RTGResultContext(rsp.getReturnFields(), searcherInfo.getSearcher(), req);\n           transformer.setContext(resultContext);\n         }\n         transformer.transform(doc, docid, 0);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     searcherInfo.clear();\n   }\n\n   addDocListToResponse(rb, docList);\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    \n    // This seems rather kludgey, may there is better way to indicate\n    // that replica can support handling version ranges\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n    \n    val = params.get(\"getFingerprint\");\n    if(val != null) {\n      processGetFingeprint(rb);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n    \n    val = params.get(\"getInputDocument\");\n    if (val != null) {\n      processGetInputDocument(rb);\n      return;\n    }\n\n    final IdsRequsted reqIds = IdsRequsted.parseParams(req);\n    \n    if (reqIds.allIds.isEmpty()) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n    final SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    SearcherInfo searcherInfo =  new SearcherInfo(core);\n    \n    // this is initialized & set on the context *after* any searcher (re-)opening\n    ResultContext resultContext = null;\n    final DocTransformer transformer = rsp.getReturnFields().getTransformer();\n\n    // true in any situation where we have to use a realtime searcher rather then returning docs\n    // directly from the UpdateLog\n    final boolean mustUseRealtimeSearcher =\n      // if we have filters, we need to check those against the indexed form of the doc\n      (rb.getFilters() != null)\n      || ((null != transformer) && transformer.needsSolrIndexSearcher());\n\n   try {\n\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : reqIds.allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(UpdateLog.FLAGS_IDX) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.UPDATE_INPLACE: // fall through to ADD\n             case UpdateLog.ADD:\n\n               if (mustUseRealtimeSearcher) {\n                 // close handles to current searchers & result context\n                 searcherInfo.clear();\n                 resultContext = null;\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc;\n               if (oper == UpdateLog.ADD) {\n                 doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               } else if (oper == UpdateLog.UPDATE_INPLACE) {\n                 assert entry.size() == 5;\n                 // For in-place update case, we have obtained the partial document till now. We need to\n                 // resolve it to a full document to be returned to the user.\n                 doc = resolveFullDocument(core, idBytes.get(), rsp.getReturnFields(), (SolrInputDocument)entry.get(entry.size()-1), entry, null);\n                 if (doc == null) {\n                   break; // document has been deleted as the resolve was going on\n                 }\n               } else {\n                 throw new SolrException(ErrorCode.INVALID_STATE, \"Expected ADD or UPDATE_INPLACE. Got: \" + oper);\n               }\n               if (transformer!=null) {\n                 transformer.transform(doc, -1, 0); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       searcherInfo.init();\n       // don't bother with ResultContext yet, we won't need it if doc doesn't match filters\n\n       int docid = -1;\n       long segAndId = searcherInfo.getSearcher().lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcherInfo.getSearcher().getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query raw : rb.getFilters()) {\n             Query q = raw.rewrite(searcherInfo.getSearcher().getIndexReader());\n             Scorer scorer = searcherInfo.getSearcher().createWeight(q, false, 1f).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n       if (docid < 0) continue;\n       \n       Document luceneDocument = searcherInfo.getSearcher().doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       SolrDocumentFetcher docFetcher = searcherInfo.getSearcher().getDocFetcher();\n       docFetcher.decorateDocValueFields(doc, docid, docFetcher.getNonStoredDVs(true));\n       if ( null != transformer) {\n         if (null == resultContext) {\n           // either first pass, or we've re-opened searcher - either way now we setContext\n           resultContext = new RTGResultContext(rsp.getReturnFields(), searcherInfo.getSearcher(), req);\n           transformer.setContext(resultContext);\n         }\n         transformer.transform(doc, docid, 0);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     searcherInfo.clear();\n   }\n\n   addDocListToResponse(rb, docList);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"320eec6599df6f97f2461a5d1ad49cd93b324a14","date":1503502574,"type":3,"author":"Christine Poerschke","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    CloudDescriptor cloudDesc = req.getCore().getCoreDescriptor().getCloudDescriptor();\n\n    if (cloudDesc != null) {\n      Replica.Type replicaType = cloudDesc.getReplicaType();\n      if (replicaType != null) {\n        if (replicaType == Replica.Type.PULL) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \n              String.format(Locale.ROOT, \"%s can't handle realtime get requests. Replicas of type %s do not support these type of requests\", \n                  cloudDesc.getCoreNodeName(),\n                  Replica.Type.PULL));\n        } \n        // non-leader TLOG replicas should not respond to distrib /get requests, but internal requests are OK\n      }\n    }\n    \n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    \n    // This seems rather kludgey, may there is better way to indicate\n    // that replica can support handling version ranges\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n    \n    val = params.get(\"getFingerprint\");\n    if(val != null) {\n      processGetFingeprint(rb);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n    \n    val = params.get(\"getInputDocument\");\n    if (val != null) {\n      processGetInputDocument(rb);\n      return;\n    }\n\n    final IdsRequsted reqIds = IdsRequsted.parseParams(req);\n    \n    if (reqIds.allIds.isEmpty()) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n    final SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    SearcherInfo searcherInfo =  new SearcherInfo(core);\n    \n    // this is initialized & set on the context *after* any searcher (re-)opening\n    ResultContext resultContext = null;\n    final DocTransformer transformer = rsp.getReturnFields().getTransformer();\n\n    // true in any situation where we have to use a realtime searcher rather then returning docs\n    // directly from the UpdateLog\n    final boolean mustUseRealtimeSearcher =\n      // if we have filters, we need to check those against the indexed form of the doc\n      (rb.getFilters() != null)\n      || ((null != transformer) && transformer.needsSolrIndexSearcher());\n\n   try {\n\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : reqIds.allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(UpdateLog.FLAGS_IDX) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.UPDATE_INPLACE: // fall through to ADD\n             case UpdateLog.ADD:\n\n               if (mustUseRealtimeSearcher) {\n                 // close handles to current searchers & result context\n                 searcherInfo.clear();\n                 resultContext = null;\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc;\n               if (oper == UpdateLog.ADD) {\n                 doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               } else if (oper == UpdateLog.UPDATE_INPLACE) {\n                 assert entry.size() == 5;\n                 // For in-place update case, we have obtained the partial document till now. We need to\n                 // resolve it to a full document to be returned to the user.\n                 doc = resolveFullDocument(core, idBytes.get(), rsp.getReturnFields(), (SolrInputDocument)entry.get(entry.size()-1), entry, null);\n                 if (doc == null) {\n                   break; // document has been deleted as the resolve was going on\n                 }\n               } else {\n                 throw new SolrException(ErrorCode.INVALID_STATE, \"Expected ADD or UPDATE_INPLACE. Got: \" + oper);\n               }\n               if (transformer!=null) {\n                 transformer.transform(doc, -1); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       searcherInfo.init();\n       // don't bother with ResultContext yet, we won't need it if doc doesn't match filters\n\n       int docid = -1;\n       long segAndId = searcherInfo.getSearcher().lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcherInfo.getSearcher().getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query raw : rb.getFilters()) {\n             Query q = raw.rewrite(searcherInfo.getSearcher().getIndexReader());\n             Scorer scorer = searcherInfo.getSearcher().createWeight(q, false, 1f).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n       if (docid < 0) continue;\n       \n       Document luceneDocument = searcherInfo.getSearcher().doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       SolrDocumentFetcher docFetcher = searcherInfo.getSearcher().getDocFetcher();\n       docFetcher.decorateDocValueFields(doc, docid, docFetcher.getNonStoredDVs(true));\n       if ( null != transformer) {\n         if (null == resultContext) {\n           // either first pass, or we've re-opened searcher - either way now we setContext\n           resultContext = new RTGResultContext(rsp.getReturnFields(), searcherInfo.getSearcher(), req);\n           transformer.setContext(resultContext);\n         }\n         transformer.transform(doc, docid);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     searcherInfo.clear();\n   }\n\n   addDocListToResponse(rb, docList);\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    CloudDescriptor cloudDesc = req.getCore().getCoreDescriptor().getCloudDescriptor();\n\n    if (cloudDesc != null) {\n      Replica.Type replicaType = cloudDesc.getReplicaType();\n      if (replicaType != null) {\n        if (replicaType == Replica.Type.PULL) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \n              String.format(Locale.ROOT, \"%s can't handle realtime get requests. Replicas of type %s do not support these type of requests\", \n                  cloudDesc.getCoreNodeName(),\n                  Replica.Type.PULL));\n        } \n        // non-leader TLOG replicas should not respond to distrib /get requests, but internal requests are OK\n      }\n    }\n    \n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    \n    // This seems rather kludgey, may there is better way to indicate\n    // that replica can support handling version ranges\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n    \n    val = params.get(\"getFingerprint\");\n    if(val != null) {\n      processGetFingeprint(rb);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n    \n    val = params.get(\"getInputDocument\");\n    if (val != null) {\n      processGetInputDocument(rb);\n      return;\n    }\n\n    final IdsRequsted reqIds = IdsRequsted.parseParams(req);\n    \n    if (reqIds.allIds.isEmpty()) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n    final SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    SearcherInfo searcherInfo =  new SearcherInfo(core);\n    \n    // this is initialized & set on the context *after* any searcher (re-)opening\n    ResultContext resultContext = null;\n    final DocTransformer transformer = rsp.getReturnFields().getTransformer();\n\n    // true in any situation where we have to use a realtime searcher rather then returning docs\n    // directly from the UpdateLog\n    final boolean mustUseRealtimeSearcher =\n      // if we have filters, we need to check those against the indexed form of the doc\n      (rb.getFilters() != null)\n      || ((null != transformer) && transformer.needsSolrIndexSearcher());\n\n   try {\n\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : reqIds.allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(UpdateLog.FLAGS_IDX) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.UPDATE_INPLACE: // fall through to ADD\n             case UpdateLog.ADD:\n\n               if (mustUseRealtimeSearcher) {\n                 // close handles to current searchers & result context\n                 searcherInfo.clear();\n                 resultContext = null;\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc;\n               if (oper == UpdateLog.ADD) {\n                 doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               } else if (oper == UpdateLog.UPDATE_INPLACE) {\n                 assert entry.size() == 5;\n                 // For in-place update case, we have obtained the partial document till now. We need to\n                 // resolve it to a full document to be returned to the user.\n                 doc = resolveFullDocument(core, idBytes.get(), rsp.getReturnFields(), (SolrInputDocument)entry.get(entry.size()-1), entry, null);\n                 if (doc == null) {\n                   break; // document has been deleted as the resolve was going on\n                 }\n               } else {\n                 throw new SolrException(ErrorCode.INVALID_STATE, \"Expected ADD or UPDATE_INPLACE. Got: \" + oper);\n               }\n               if (transformer!=null) {\n                 transformer.transform(doc, -1, 0); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       searcherInfo.init();\n       // don't bother with ResultContext yet, we won't need it if doc doesn't match filters\n\n       int docid = -1;\n       long segAndId = searcherInfo.getSearcher().lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcherInfo.getSearcher().getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query raw : rb.getFilters()) {\n             Query q = raw.rewrite(searcherInfo.getSearcher().getIndexReader());\n             Scorer scorer = searcherInfo.getSearcher().createWeight(q, false, 1f).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n       if (docid < 0) continue;\n       \n       Document luceneDocument = searcherInfo.getSearcher().doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       SolrDocumentFetcher docFetcher = searcherInfo.getSearcher().getDocFetcher();\n       docFetcher.decorateDocValueFields(doc, docid, docFetcher.getNonStoredDVs(true));\n       if ( null != transformer) {\n         if (null == resultContext) {\n           // either first pass, or we've re-opened searcher - either way now we setContext\n           resultContext = new RTGResultContext(rsp.getReturnFields(), searcherInfo.getSearcher(), req);\n           transformer.setContext(resultContext);\n         }\n         transformer.transform(doc, docid, 0);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     searcherInfo.clear();\n   }\n\n   addDocListToResponse(rb, docList);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"182384b20c064aa16998ddebe9f36e649279c5a6","date":1503596494,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    CloudDescriptor cloudDesc = req.getCore().getCoreDescriptor().getCloudDescriptor();\n\n    if (cloudDesc != null) {\n      Replica.Type replicaType = cloudDesc.getReplicaType();\n      if (replicaType != null) {\n        if (replicaType == Replica.Type.PULL) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \n              String.format(Locale.ROOT, \"%s can't handle realtime get requests. Replicas of type %s do not support these type of requests\", \n                  cloudDesc.getCoreNodeName(),\n                  Replica.Type.PULL));\n        } \n        // non-leader TLOG replicas should not respond to distrib /get requests, but internal requests are OK\n      }\n    }\n    \n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    \n    // This seems rather kludgey, may there is better way to indicate\n    // that replica can support handling version ranges\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n    \n    val = params.get(\"getFingerprint\");\n    if(val != null) {\n      processGetFingeprint(rb);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n    \n    val = params.get(\"getInputDocument\");\n    if (val != null) {\n      processGetInputDocument(rb);\n      return;\n    }\n\n    final IdsRequsted reqIds = IdsRequsted.parseParams(req);\n    \n    if (reqIds.allIds.isEmpty()) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n    final SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    SearcherInfo searcherInfo =  new SearcherInfo(core);\n    \n    // this is initialized & set on the context *after* any searcher (re-)opening\n    ResultContext resultContext = null;\n    final DocTransformer transformer = rsp.getReturnFields().getTransformer();\n\n    // true in any situation where we have to use a realtime searcher rather then returning docs\n    // directly from the UpdateLog\n    final boolean mustUseRealtimeSearcher =\n      // if we have filters, we need to check those against the indexed form of the doc\n      (rb.getFilters() != null)\n      || ((null != transformer) && transformer.needsSolrIndexSearcher());\n\n   try {\n\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : reqIds.allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(UpdateLog.FLAGS_IDX) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.UPDATE_INPLACE: // fall through to ADD\n             case UpdateLog.ADD:\n\n               if (mustUseRealtimeSearcher) {\n                 // close handles to current searchers & result context\n                 searcherInfo.clear();\n                 resultContext = null;\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc;\n               if (oper == UpdateLog.ADD) {\n                 doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               } else if (oper == UpdateLog.UPDATE_INPLACE) {\n                 assert entry.size() == 5;\n                 // For in-place update case, we have obtained the partial document till now. We need to\n                 // resolve it to a full document to be returned to the user.\n                 doc = resolveFullDocument(core, idBytes.get(), rsp.getReturnFields(), (SolrInputDocument)entry.get(entry.size()-1), entry, null);\n                 if (doc == null) {\n                   break; // document has been deleted as the resolve was going on\n                 }\n               } else {\n                 throw new SolrException(ErrorCode.INVALID_STATE, \"Expected ADD or UPDATE_INPLACE. Got: \" + oper);\n               }\n               if (transformer!=null) {\n                 transformer.transform(doc, -1); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       searcherInfo.init();\n       // don't bother with ResultContext yet, we won't need it if doc doesn't match filters\n\n       int docid = -1;\n       long segAndId = searcherInfo.getSearcher().lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcherInfo.getSearcher().getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query raw : rb.getFilters()) {\n             Query q = raw.rewrite(searcherInfo.getSearcher().getIndexReader());\n             Scorer scorer = searcherInfo.getSearcher().createWeight(q, false, 1f).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n       if (docid < 0) continue;\n       \n       Document luceneDocument = searcherInfo.getSearcher().doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       SolrDocumentFetcher docFetcher = searcherInfo.getSearcher().getDocFetcher();\n       docFetcher.decorateDocValueFields(doc, docid, docFetcher.getNonStoredDVs(true));\n       if ( null != transformer) {\n         if (null == resultContext) {\n           // either first pass, or we've re-opened searcher - either way now we setContext\n           resultContext = new RTGResultContext(rsp.getReturnFields(), searcherInfo.getSearcher(), req);\n           transformer.setContext(resultContext);\n         }\n         transformer.transform(doc, docid);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     searcherInfo.clear();\n   }\n\n   addDocListToResponse(rb, docList);\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    CloudDescriptor cloudDesc = req.getCore().getCoreDescriptor().getCloudDescriptor();\n\n    if (cloudDesc != null) {\n      Replica.Type replicaType = cloudDesc.getReplicaType();\n      if (replicaType != null) {\n        if (replicaType == Replica.Type.PULL) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \n              String.format(Locale.ROOT, \"%s can't handle realtime get requests. Replicas of type %s do not support these type of requests\", \n                  cloudDesc.getCoreNodeName(),\n                  Replica.Type.PULL));\n        } \n        // non-leader TLOG replicas should not respond to distrib /get requests, but internal requests are OK\n      }\n    }\n    \n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    \n    // This seems rather kludgey, may there is better way to indicate\n    // that replica can support handling version ranges\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n    \n    val = params.get(\"getFingerprint\");\n    if(val != null) {\n      processGetFingeprint(rb);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n    \n    val = params.get(\"getInputDocument\");\n    if (val != null) {\n      processGetInputDocument(rb);\n      return;\n    }\n\n    final IdsRequsted reqIds = IdsRequsted.parseParams(req);\n    \n    if (reqIds.allIds.isEmpty()) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n    final SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    SearcherInfo searcherInfo =  new SearcherInfo(core);\n    \n    // this is initialized & set on the context *after* any searcher (re-)opening\n    ResultContext resultContext = null;\n    final DocTransformer transformer = rsp.getReturnFields().getTransformer();\n\n    // true in any situation where we have to use a realtime searcher rather then returning docs\n    // directly from the UpdateLog\n    final boolean mustUseRealtimeSearcher =\n      // if we have filters, we need to check those against the indexed form of the doc\n      (rb.getFilters() != null)\n      || ((null != transformer) && transformer.needsSolrIndexSearcher());\n\n   try {\n\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : reqIds.allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(UpdateLog.FLAGS_IDX) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.UPDATE_INPLACE: // fall through to ADD\n             case UpdateLog.ADD:\n\n               if (mustUseRealtimeSearcher) {\n                 // close handles to current searchers & result context\n                 searcherInfo.clear();\n                 resultContext = null;\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc;\n               if (oper == UpdateLog.ADD) {\n                 doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               } else if (oper == UpdateLog.UPDATE_INPLACE) {\n                 assert entry.size() == 5;\n                 // For in-place update case, we have obtained the partial document till now. We need to\n                 // resolve it to a full document to be returned to the user.\n                 doc = resolveFullDocument(core, idBytes.get(), rsp.getReturnFields(), (SolrInputDocument)entry.get(entry.size()-1), entry, null);\n                 if (doc == null) {\n                   break; // document has been deleted as the resolve was going on\n                 }\n               } else {\n                 throw new SolrException(ErrorCode.INVALID_STATE, \"Expected ADD or UPDATE_INPLACE. Got: \" + oper);\n               }\n               if (transformer!=null) {\n                 transformer.transform(doc, -1, 0); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       searcherInfo.init();\n       // don't bother with ResultContext yet, we won't need it if doc doesn't match filters\n\n       int docid = -1;\n       long segAndId = searcherInfo.getSearcher().lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcherInfo.getSearcher().getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query raw : rb.getFilters()) {\n             Query q = raw.rewrite(searcherInfo.getSearcher().getIndexReader());\n             Scorer scorer = searcherInfo.getSearcher().createWeight(q, false, 1f).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n       if (docid < 0) continue;\n       \n       Document luceneDocument = searcherInfo.getSearcher().doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       SolrDocumentFetcher docFetcher = searcherInfo.getSearcher().getDocFetcher();\n       docFetcher.decorateDocValueFields(doc, docid, docFetcher.getNonStoredDVs(true));\n       if ( null != transformer) {\n         if (null == resultContext) {\n           // either first pass, or we've re-opened searcher - either way now we setContext\n           resultContext = new RTGResultContext(rsp.getReturnFields(), searcherInfo.getSearcher(), req);\n           transformer.setContext(resultContext);\n         }\n         transformer.transform(doc, docid, 0);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     searcherInfo.clear();\n   }\n\n   addDocListToResponse(rb, docList);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a7809d1d753b67f48b1a706e17034bf8b624ea3","date":1504366927,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    CloudDescriptor cloudDesc = req.getCore().getCoreDescriptor().getCloudDescriptor();\n\n    if (cloudDesc != null) {\n      Replica.Type replicaType = cloudDesc.getReplicaType();\n      if (replicaType != null) {\n        if (replicaType == Replica.Type.PULL) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \n              String.format(Locale.ROOT, \"%s can't handle realtime get requests. Replicas of type %s do not support these type of requests\", \n                  cloudDesc.getCoreNodeName(),\n                  Replica.Type.PULL));\n        } \n        // non-leader TLOG replicas should not respond to distrib /get requests, but internal requests are OK\n      }\n    }\n    \n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    \n    // This seems rather kludgey, may there is better way to indicate\n    // that replica can support handling version ranges\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n    \n    val = params.get(\"getFingerprint\");\n    if(val != null) {\n      processGetFingeprint(rb);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n    \n    val = params.get(\"getInputDocument\");\n    if (val != null) {\n      processGetInputDocument(rb);\n      return;\n    }\n\n    final IdsRequsted reqIds = IdsRequsted.parseParams(req);\n    \n    if (reqIds.allIds.isEmpty()) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n    final SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    SearcherInfo searcherInfo =  new SearcherInfo(core);\n    \n    // this is initialized & set on the context *after* any searcher (re-)opening\n    ResultContext resultContext = null;\n    final DocTransformer transformer = rsp.getReturnFields().getTransformer();\n\n    // true in any situation where we have to use a realtime searcher rather then returning docs\n    // directly from the UpdateLog\n    final boolean mustUseRealtimeSearcher =\n      // if we have filters, we need to check those against the indexed form of the doc\n      (rb.getFilters() != null)\n      || ((null != transformer) && transformer.needsSolrIndexSearcher());\n\n   try {\n\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : reqIds.allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(UpdateLog.FLAGS_IDX) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.UPDATE_INPLACE: // fall through to ADD\n             case UpdateLog.ADD:\n\n               if (mustUseRealtimeSearcher) {\n                 // close handles to current searchers & result context\n                 searcherInfo.clear();\n                 resultContext = null;\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc;\n               if (oper == UpdateLog.ADD) {\n                 doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               } else if (oper == UpdateLog.UPDATE_INPLACE) {\n                 assert entry.size() == 5;\n                 // For in-place update case, we have obtained the partial document till now. We need to\n                 // resolve it to a full document to be returned to the user.\n                 doc = resolveFullDocument(core, idBytes.get(), rsp.getReturnFields(), (SolrInputDocument)entry.get(entry.size()-1), entry, null);\n                 if (doc == null) {\n                   break; // document has been deleted as the resolve was going on\n                 }\n               } else {\n                 throw new SolrException(ErrorCode.INVALID_STATE, \"Expected ADD or UPDATE_INPLACE. Got: \" + oper);\n               }\n               if (transformer!=null) {\n                 transformer.transform(doc, -1); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       searcherInfo.init();\n       // don't bother with ResultContext yet, we won't need it if doc doesn't match filters\n\n       int docid = -1;\n       long segAndId = searcherInfo.getSearcher().lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcherInfo.getSearcher().getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query raw : rb.getFilters()) {\n             Query q = raw.rewrite(searcherInfo.getSearcher().getIndexReader());\n             Scorer scorer = searcherInfo.getSearcher().createWeight(q, false, 1f).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n       if (docid < 0) continue;\n       \n       Document luceneDocument = searcherInfo.getSearcher().doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       SolrDocumentFetcher docFetcher = searcherInfo.getSearcher().getDocFetcher();\n       docFetcher.decorateDocValueFields(doc, docid, docFetcher.getNonStoredDVs(true));\n       if ( null != transformer) {\n         if (null == resultContext) {\n           // either first pass, or we've re-opened searcher - either way now we setContext\n           resultContext = new RTGResultContext(rsp.getReturnFields(), searcherInfo.getSearcher(), req);\n           transformer.setContext(resultContext);\n         }\n         transformer.transform(doc, docid);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     searcherInfo.clear();\n   }\n\n   addDocListToResponse(rb, docList);\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    CloudDescriptor cloudDesc = req.getCore().getCoreDescriptor().getCloudDescriptor();\n\n    if (cloudDesc != null) {\n      Replica.Type replicaType = cloudDesc.getReplicaType();\n      if (replicaType != null) {\n        if (replicaType == Replica.Type.PULL) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \n              String.format(Locale.ROOT, \"%s can't handle realtime get requests. Replicas of type %s do not support these type of requests\", \n                  cloudDesc.getCoreNodeName(),\n                  Replica.Type.PULL));\n        } \n        // non-leader TLOG replicas should not respond to distrib /get requests, but internal requests are OK\n      }\n    }\n    \n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    \n    // This seems rather kludgey, may there is better way to indicate\n    // that replica can support handling version ranges\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n    \n    val = params.get(\"getFingerprint\");\n    if(val != null) {\n      processGetFingeprint(rb);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n    \n    val = params.get(\"getInputDocument\");\n    if (val != null) {\n      processGetInputDocument(rb);\n      return;\n    }\n\n    final IdsRequsted reqIds = IdsRequsted.parseParams(req);\n    \n    if (reqIds.allIds.isEmpty()) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n    final SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    SearcherInfo searcherInfo =  new SearcherInfo(core);\n    \n    // this is initialized & set on the context *after* any searcher (re-)opening\n    ResultContext resultContext = null;\n    final DocTransformer transformer = rsp.getReturnFields().getTransformer();\n\n    // true in any situation where we have to use a realtime searcher rather then returning docs\n    // directly from the UpdateLog\n    final boolean mustUseRealtimeSearcher =\n      // if we have filters, we need to check those against the indexed form of the doc\n      (rb.getFilters() != null)\n      || ((null != transformer) && transformer.needsSolrIndexSearcher());\n\n   try {\n\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : reqIds.allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(UpdateLog.FLAGS_IDX) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.UPDATE_INPLACE: // fall through to ADD\n             case UpdateLog.ADD:\n\n               if (mustUseRealtimeSearcher) {\n                 // close handles to current searchers & result context\n                 searcherInfo.clear();\n                 resultContext = null;\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc;\n               if (oper == UpdateLog.ADD) {\n                 doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               } else if (oper == UpdateLog.UPDATE_INPLACE) {\n                 assert entry.size() == 5;\n                 // For in-place update case, we have obtained the partial document till now. We need to\n                 // resolve it to a full document to be returned to the user.\n                 doc = resolveFullDocument(core, idBytes.get(), rsp.getReturnFields(), (SolrInputDocument)entry.get(entry.size()-1), entry, null);\n                 if (doc == null) {\n                   break; // document has been deleted as the resolve was going on\n                 }\n               } else {\n                 throw new SolrException(ErrorCode.INVALID_STATE, \"Expected ADD or UPDATE_INPLACE. Got: \" + oper);\n               }\n               if (transformer!=null) {\n                 transformer.transform(doc, -1, 0); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       searcherInfo.init();\n       // don't bother with ResultContext yet, we won't need it if doc doesn't match filters\n\n       int docid = -1;\n       long segAndId = searcherInfo.getSearcher().lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcherInfo.getSearcher().getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query raw : rb.getFilters()) {\n             Query q = raw.rewrite(searcherInfo.getSearcher().getIndexReader());\n             Scorer scorer = searcherInfo.getSearcher().createWeight(q, false, 1f).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n       if (docid < 0) continue;\n       \n       Document luceneDocument = searcherInfo.getSearcher().doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       SolrDocumentFetcher docFetcher = searcherInfo.getSearcher().getDocFetcher();\n       docFetcher.decorateDocValueFields(doc, docid, docFetcher.getNonStoredDVs(true));\n       if ( null != transformer) {\n         if (null == resultContext) {\n           // either first pass, or we've re-opened searcher - either way now we setContext\n           resultContext = new RTGResultContext(rsp.getReturnFields(), searcherInfo.getSearcher(), req);\n           transformer.setContext(resultContext);\n         }\n         transformer.transform(doc, docid, 0);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     searcherInfo.clear();\n   }\n\n   addDocListToResponse(rb, docList);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9fc47cb7b4346802411bb432f501ed0673d7119e","date":1512640179,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    CloudDescriptor cloudDesc = req.getCore().getCoreDescriptor().getCloudDescriptor();\n\n    if (cloudDesc != null) {\n      Replica.Type replicaType = cloudDesc.getReplicaType();\n      if (replicaType != null) {\n        if (replicaType == Replica.Type.PULL) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \n              String.format(Locale.ROOT, \"%s can't handle realtime get requests. Replicas of type %s do not support these type of requests\", \n                  cloudDesc.getCoreNodeName(),\n                  Replica.Type.PULL));\n        } \n        // non-leader TLOG replicas should not respond to distrib /get requests, but internal requests are OK\n      }\n    }\n    \n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    \n    // This seems rather kludgey, may there is better way to indicate\n    // that replica can support handling version ranges\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n    \n    val = params.get(\"getFingerprint\");\n    if(val != null) {\n      processGetFingeprint(rb);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n    \n    val = params.get(\"getInputDocument\");\n    if (val != null) {\n      processGetInputDocument(rb);\n      return;\n    }\n\n    final IdsRequsted reqIds = IdsRequsted.parseParams(req);\n    \n    if (reqIds.allIds.isEmpty()) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n    final SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    SearcherInfo searcherInfo =  new SearcherInfo(core);\n    \n    // this is initialized & set on the context *after* any searcher (re-)opening\n    ResultContext resultContext = null;\n    final DocTransformer transformer = rsp.getReturnFields().getTransformer();\n\n    // true in any situation where we have to use a realtime searcher rather then returning docs\n    // directly from the UpdateLog\n    final boolean mustUseRealtimeSearcher =\n      // if we have filters, we need to check those against the indexed form of the doc\n      (rb.getFilters() != null)\n      || ((null != transformer) && transformer.needsSolrIndexSearcher());\n\n   try {\n\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : reqIds.allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(UpdateLog.FLAGS_IDX) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.UPDATE_INPLACE: // fall through to ADD\n             case UpdateLog.ADD:\n\n               if (mustUseRealtimeSearcher) {\n                 // close handles to current searchers & result context\n                 searcherInfo.clear();\n                 resultContext = null;\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc;\n               if (oper == UpdateLog.ADD) {\n                 doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               } else if (oper == UpdateLog.UPDATE_INPLACE) {\n                 assert entry.size() == 5;\n                 // For in-place update case, we have obtained the partial document till now. We need to\n                 // resolve it to a full document to be returned to the user.\n                 doc = resolveFullDocument(core, idBytes.get(), rsp.getReturnFields(), (SolrInputDocument)entry.get(entry.size()-1), entry, null);\n                 if (doc == null) {\n                   break; // document has been deleted as the resolve was going on\n                 }\n               } else {\n                 throw new SolrException(ErrorCode.INVALID_STATE, \"Expected ADD or UPDATE_INPLACE. Got: \" + oper);\n               }\n               if (transformer!=null) {\n                 transformer.transform(doc, -1); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       searcherInfo.init();\n       // don't bother with ResultContext yet, we won't need it if doc doesn't match filters\n\n       int docid = -1;\n       long segAndId = searcherInfo.getSearcher().lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcherInfo.getSearcher().getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query raw : rb.getFilters()) {\n             Query q = raw.rewrite(searcherInfo.getSearcher().getIndexReader());\n             Scorer scorer = searcherInfo.getSearcher().createWeight(q, ScoreMode.COMPLETE_NO_SCORES, 1f).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n       if (docid < 0) continue;\n       \n       Document luceneDocument = searcherInfo.getSearcher().doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       SolrDocumentFetcher docFetcher = searcherInfo.getSearcher().getDocFetcher();\n       docFetcher.decorateDocValueFields(doc, docid, docFetcher.getNonStoredDVs(true));\n       if ( null != transformer) {\n         if (null == resultContext) {\n           // either first pass, or we've re-opened searcher - either way now we setContext\n           resultContext = new RTGResultContext(rsp.getReturnFields(), searcherInfo.getSearcher(), req);\n           transformer.setContext(resultContext);\n         }\n         transformer.transform(doc, docid);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     searcherInfo.clear();\n   }\n\n   addDocListToResponse(rb, docList);\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    CloudDescriptor cloudDesc = req.getCore().getCoreDescriptor().getCloudDescriptor();\n\n    if (cloudDesc != null) {\n      Replica.Type replicaType = cloudDesc.getReplicaType();\n      if (replicaType != null) {\n        if (replicaType == Replica.Type.PULL) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \n              String.format(Locale.ROOT, \"%s can't handle realtime get requests. Replicas of type %s do not support these type of requests\", \n                  cloudDesc.getCoreNodeName(),\n                  Replica.Type.PULL));\n        } \n        // non-leader TLOG replicas should not respond to distrib /get requests, but internal requests are OK\n      }\n    }\n    \n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    \n    // This seems rather kludgey, may there is better way to indicate\n    // that replica can support handling version ranges\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n    \n    val = params.get(\"getFingerprint\");\n    if(val != null) {\n      processGetFingeprint(rb);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n    \n    val = params.get(\"getInputDocument\");\n    if (val != null) {\n      processGetInputDocument(rb);\n      return;\n    }\n\n    final IdsRequsted reqIds = IdsRequsted.parseParams(req);\n    \n    if (reqIds.allIds.isEmpty()) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n    final SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    SearcherInfo searcherInfo =  new SearcherInfo(core);\n    \n    // this is initialized & set on the context *after* any searcher (re-)opening\n    ResultContext resultContext = null;\n    final DocTransformer transformer = rsp.getReturnFields().getTransformer();\n\n    // true in any situation where we have to use a realtime searcher rather then returning docs\n    // directly from the UpdateLog\n    final boolean mustUseRealtimeSearcher =\n      // if we have filters, we need to check those against the indexed form of the doc\n      (rb.getFilters() != null)\n      || ((null != transformer) && transformer.needsSolrIndexSearcher());\n\n   try {\n\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : reqIds.allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(UpdateLog.FLAGS_IDX) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.UPDATE_INPLACE: // fall through to ADD\n             case UpdateLog.ADD:\n\n               if (mustUseRealtimeSearcher) {\n                 // close handles to current searchers & result context\n                 searcherInfo.clear();\n                 resultContext = null;\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc;\n               if (oper == UpdateLog.ADD) {\n                 doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               } else if (oper == UpdateLog.UPDATE_INPLACE) {\n                 assert entry.size() == 5;\n                 // For in-place update case, we have obtained the partial document till now. We need to\n                 // resolve it to a full document to be returned to the user.\n                 doc = resolveFullDocument(core, idBytes.get(), rsp.getReturnFields(), (SolrInputDocument)entry.get(entry.size()-1), entry, null);\n                 if (doc == null) {\n                   break; // document has been deleted as the resolve was going on\n                 }\n               } else {\n                 throw new SolrException(ErrorCode.INVALID_STATE, \"Expected ADD or UPDATE_INPLACE. Got: \" + oper);\n               }\n               if (transformer!=null) {\n                 transformer.transform(doc, -1); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       searcherInfo.init();\n       // don't bother with ResultContext yet, we won't need it if doc doesn't match filters\n\n       int docid = -1;\n       long segAndId = searcherInfo.getSearcher().lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcherInfo.getSearcher().getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query raw : rb.getFilters()) {\n             Query q = raw.rewrite(searcherInfo.getSearcher().getIndexReader());\n             Scorer scorer = searcherInfo.getSearcher().createWeight(q, false, 1f).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n       if (docid < 0) continue;\n       \n       Document luceneDocument = searcherInfo.getSearcher().doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       SolrDocumentFetcher docFetcher = searcherInfo.getSearcher().getDocFetcher();\n       docFetcher.decorateDocValueFields(doc, docid, docFetcher.getNonStoredDVs(true));\n       if ( null != transformer) {\n         if (null == resultContext) {\n           // either first pass, or we've re-opened searcher - either way now we setContext\n           resultContext = new RTGResultContext(rsp.getReturnFields(), searcherInfo.getSearcher(), req);\n           transformer.setContext(resultContext);\n         }\n         transformer.transform(doc, docid);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     searcherInfo.clear();\n   }\n\n   addDocListToResponse(rb, docList);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"417142ff08fda9cf0b72d5133e63097a166c6458","date":1512729693,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    CloudDescriptor cloudDesc = req.getCore().getCoreDescriptor().getCloudDescriptor();\n\n    if (cloudDesc != null) {\n      Replica.Type replicaType = cloudDesc.getReplicaType();\n      if (replicaType != null) {\n        if (replicaType == Replica.Type.PULL) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \n              String.format(Locale.ROOT, \"%s can't handle realtime get requests. Replicas of type %s do not support these type of requests\", \n                  cloudDesc.getCoreNodeName(),\n                  Replica.Type.PULL));\n        } \n        // non-leader TLOG replicas should not respond to distrib /get requests, but internal requests are OK\n      }\n    }\n    \n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    \n    // This seems rather kludgey, may there is better way to indicate\n    // that replica can support handling version ranges\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n    \n    val = params.get(\"getFingerprint\");\n    if(val != null) {\n      processGetFingeprint(rb);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n    \n    val = params.get(\"getInputDocument\");\n    if (val != null) {\n      processGetInputDocument(rb);\n      return;\n    }\n\n    final IdsRequsted reqIds = IdsRequsted.parseParams(req);\n    \n    if (reqIds.allIds.isEmpty()) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n    final SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    SearcherInfo searcherInfo =  new SearcherInfo(core);\n    \n    // this is initialized & set on the context *after* any searcher (re-)opening\n    ResultContext resultContext = null;\n    final DocTransformer transformer = rsp.getReturnFields().getTransformer();\n\n    // true in any situation where we have to use a realtime searcher rather then returning docs\n    // directly from the UpdateLog\n    final boolean mustUseRealtimeSearcher =\n      // if we have filters, we need to check those against the indexed form of the doc\n      (rb.getFilters() != null)\n      || ((null != transformer) && transformer.needsSolrIndexSearcher());\n\n   try {\n\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : reqIds.allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(UpdateLog.FLAGS_IDX) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.UPDATE_INPLACE: // fall through to ADD\n             case UpdateLog.ADD:\n\n               if (mustUseRealtimeSearcher) {\n                 // close handles to current searchers & result context\n                 searcherInfo.clear();\n                 resultContext = null;\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc;\n               if (oper == UpdateLog.ADD) {\n                 doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               } else if (oper == UpdateLog.UPDATE_INPLACE) {\n                 assert entry.size() == 5;\n                 // For in-place update case, we have obtained the partial document till now. We need to\n                 // resolve it to a full document to be returned to the user.\n                 doc = resolveFullDocument(core, idBytes.get(), rsp.getReturnFields(), (SolrInputDocument)entry.get(entry.size()-1), entry, null);\n                 if (doc == null) {\n                   break; // document has been deleted as the resolve was going on\n                 }\n               } else {\n                 throw new SolrException(ErrorCode.INVALID_STATE, \"Expected ADD or UPDATE_INPLACE. Got: \" + oper);\n               }\n               if (transformer!=null) {\n                 transformer.transform(doc, -1); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       searcherInfo.init();\n       // don't bother with ResultContext yet, we won't need it if doc doesn't match filters\n\n       int docid = -1;\n       long segAndId = searcherInfo.getSearcher().lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcherInfo.getSearcher().getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query raw : rb.getFilters()) {\n             Query q = raw.rewrite(searcherInfo.getSearcher().getIndexReader());\n             Scorer scorer = searcherInfo.getSearcher().createWeight(q, ScoreMode.COMPLETE_NO_SCORES, 1f).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n       if (docid < 0) continue;\n       \n       Document luceneDocument = searcherInfo.getSearcher().doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       SolrDocumentFetcher docFetcher = searcherInfo.getSearcher().getDocFetcher();\n       docFetcher.decorateDocValueFields(doc, docid, docFetcher.getNonStoredDVs(true));\n       if ( null != transformer) {\n         if (null == resultContext) {\n           // either first pass, or we've re-opened searcher - either way now we setContext\n           resultContext = new RTGResultContext(rsp.getReturnFields(), searcherInfo.getSearcher(), req);\n           transformer.setContext(resultContext);\n         }\n         transformer.transform(doc, docid);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     searcherInfo.clear();\n   }\n\n   addDocListToResponse(rb, docList);\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    CloudDescriptor cloudDesc = req.getCore().getCoreDescriptor().getCloudDescriptor();\n\n    if (cloudDesc != null) {\n      Replica.Type replicaType = cloudDesc.getReplicaType();\n      if (replicaType != null) {\n        if (replicaType == Replica.Type.PULL) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \n              String.format(Locale.ROOT, \"%s can't handle realtime get requests. Replicas of type %s do not support these type of requests\", \n                  cloudDesc.getCoreNodeName(),\n                  Replica.Type.PULL));\n        } \n        // non-leader TLOG replicas should not respond to distrib /get requests, but internal requests are OK\n      }\n    }\n    \n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    \n    // This seems rather kludgey, may there is better way to indicate\n    // that replica can support handling version ranges\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n    \n    val = params.get(\"getFingerprint\");\n    if(val != null) {\n      processGetFingeprint(rb);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n    \n    val = params.get(\"getInputDocument\");\n    if (val != null) {\n      processGetInputDocument(rb);\n      return;\n    }\n\n    final IdsRequsted reqIds = IdsRequsted.parseParams(req);\n    \n    if (reqIds.allIds.isEmpty()) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n    final SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    SearcherInfo searcherInfo =  new SearcherInfo(core);\n    \n    // this is initialized & set on the context *after* any searcher (re-)opening\n    ResultContext resultContext = null;\n    final DocTransformer transformer = rsp.getReturnFields().getTransformer();\n\n    // true in any situation where we have to use a realtime searcher rather then returning docs\n    // directly from the UpdateLog\n    final boolean mustUseRealtimeSearcher =\n      // if we have filters, we need to check those against the indexed form of the doc\n      (rb.getFilters() != null)\n      || ((null != transformer) && transformer.needsSolrIndexSearcher());\n\n   try {\n\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : reqIds.allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(UpdateLog.FLAGS_IDX) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.UPDATE_INPLACE: // fall through to ADD\n             case UpdateLog.ADD:\n\n               if (mustUseRealtimeSearcher) {\n                 // close handles to current searchers & result context\n                 searcherInfo.clear();\n                 resultContext = null;\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc;\n               if (oper == UpdateLog.ADD) {\n                 doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               } else if (oper == UpdateLog.UPDATE_INPLACE) {\n                 assert entry.size() == 5;\n                 // For in-place update case, we have obtained the partial document till now. We need to\n                 // resolve it to a full document to be returned to the user.\n                 doc = resolveFullDocument(core, idBytes.get(), rsp.getReturnFields(), (SolrInputDocument)entry.get(entry.size()-1), entry, null);\n                 if (doc == null) {\n                   break; // document has been deleted as the resolve was going on\n                 }\n               } else {\n                 throw new SolrException(ErrorCode.INVALID_STATE, \"Expected ADD or UPDATE_INPLACE. Got: \" + oper);\n               }\n               if (transformer!=null) {\n                 transformer.transform(doc, -1); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       searcherInfo.init();\n       // don't bother with ResultContext yet, we won't need it if doc doesn't match filters\n\n       int docid = -1;\n       long segAndId = searcherInfo.getSearcher().lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcherInfo.getSearcher().getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query raw : rb.getFilters()) {\n             Query q = raw.rewrite(searcherInfo.getSearcher().getIndexReader());\n             Scorer scorer = searcherInfo.getSearcher().createWeight(q, false, 1f).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n       if (docid < 0) continue;\n       \n       Document luceneDocument = searcherInfo.getSearcher().doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       SolrDocumentFetcher docFetcher = searcherInfo.getSearcher().getDocFetcher();\n       docFetcher.decorateDocValueFields(doc, docid, docFetcher.getNonStoredDVs(true));\n       if ( null != transformer) {\n         if (null == resultContext) {\n           // either first pass, or we've re-opened searcher - either way now we setContext\n           resultContext = new RTGResultContext(rsp.getReturnFields(), searcherInfo.getSearcher(), req);\n           transformer.setContext(resultContext);\n         }\n         transformer.transform(doc, docid);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     searcherInfo.clear();\n   }\n\n   addDocListToResponse(rb, docList);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"17e1bfbfa5a260860e3f12522fca45ec1240752f","date":1521057510,"type":3,"author":"Varun Thacker","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    CloudDescriptor cloudDesc = req.getCore().getCoreDescriptor().getCloudDescriptor();\n\n    if (cloudDesc != null) {\n      Replica.Type replicaType = cloudDesc.getReplicaType();\n      if (replicaType != null) {\n        if (replicaType == Replica.Type.PULL) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \n              String.format(Locale.ROOT, \"%s can't handle realtime get requests. Replicas of type %s do not support these type of requests\", \n                  cloudDesc.getCoreNodeName(),\n                  Replica.Type.PULL));\n        } \n        // non-leader TLOG replicas should not respond to distrib /get requests, but internal requests are OK\n      }\n    }\n    \n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    \n    // This seems rather kludgey, may there is better way to indicate\n    // that replica can support handling version ranges\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n    \n    val = params.get(\"getFingerprint\");\n    if(val != null) {\n      processGetFingeprint(rb);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n    \n    val = params.get(\"getInputDocument\");\n    if (val != null) {\n      processGetInputDocument(rb);\n      return;\n    }\n\n    final IdsRequsted reqIds = IdsRequsted.parseParams(req);\n    \n    if (reqIds.allIds.isEmpty()) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n    final SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    SearcherInfo searcherInfo =  new SearcherInfo(core);\n    \n    // this is initialized & set on the context *after* any searcher (re-)opening\n    ResultContext resultContext = null;\n    final DocTransformer transformer = rsp.getReturnFields().getTransformer();\n\n    // true in any situation where we have to use a realtime searcher rather then returning docs\n    // directly from the UpdateLog\n    final boolean mustUseRealtimeSearcher =\n      // if we have filters, we need to check those against the indexed form of the doc\n      (rb.getFilters() != null)\n      || ((null != transformer) && transformer.needsSolrIndexSearcher());\n\n   try {\n\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : reqIds.allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(UpdateLog.FLAGS_IDX) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.UPDATE_INPLACE: // fall through to ADD\n             case UpdateLog.ADD:\n\n               if (mustUseRealtimeSearcher) {\n                 // close handles to current searchers & result context\n                 searcherInfo.clear();\n                 resultContext = null;\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc;\n               if (oper == UpdateLog.ADD) {\n                 doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               } else if (oper == UpdateLog.UPDATE_INPLACE) {\n                 if (ulog instanceof CdcrUpdateLog) {\n                   assert entry.size() == 6;\n                 } else {\n                   assert entry.size() == 5;\n                 }\n                 // For in-place update case, we have obtained the partial document till now. We need to\n                 // resolve it to a full document to be returned to the user.\n                 doc = resolveFullDocument(core, idBytes.get(), rsp.getReturnFields(), (SolrInputDocument)entry.get(entry.size()-1), entry, null);\n                 if (doc == null) {\n                   break; // document has been deleted as the resolve was going on\n                 }\n               } else {\n                 throw new SolrException(ErrorCode.INVALID_STATE, \"Expected ADD or UPDATE_INPLACE. Got: \" + oper);\n               }\n               if (transformer!=null) {\n                 transformer.transform(doc, -1); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       searcherInfo.init();\n       // don't bother with ResultContext yet, we won't need it if doc doesn't match filters\n\n       int docid = -1;\n       long segAndId = searcherInfo.getSearcher().lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcherInfo.getSearcher().getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query raw : rb.getFilters()) {\n             Query q = raw.rewrite(searcherInfo.getSearcher().getIndexReader());\n             Scorer scorer = searcherInfo.getSearcher().createWeight(q, ScoreMode.COMPLETE_NO_SCORES, 1f).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n       if (docid < 0) continue;\n       \n       Document luceneDocument = searcherInfo.getSearcher().doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       SolrDocumentFetcher docFetcher = searcherInfo.getSearcher().getDocFetcher();\n       docFetcher.decorateDocValueFields(doc, docid, docFetcher.getNonStoredDVs(true));\n       if ( null != transformer) {\n         if (null == resultContext) {\n           // either first pass, or we've re-opened searcher - either way now we setContext\n           resultContext = new RTGResultContext(rsp.getReturnFields(), searcherInfo.getSearcher(), req);\n           transformer.setContext(resultContext);\n         }\n         transformer.transform(doc, docid);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     searcherInfo.clear();\n   }\n\n   addDocListToResponse(rb, docList);\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    CloudDescriptor cloudDesc = req.getCore().getCoreDescriptor().getCloudDescriptor();\n\n    if (cloudDesc != null) {\n      Replica.Type replicaType = cloudDesc.getReplicaType();\n      if (replicaType != null) {\n        if (replicaType == Replica.Type.PULL) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \n              String.format(Locale.ROOT, \"%s can't handle realtime get requests. Replicas of type %s do not support these type of requests\", \n                  cloudDesc.getCoreNodeName(),\n                  Replica.Type.PULL));\n        } \n        // non-leader TLOG replicas should not respond to distrib /get requests, but internal requests are OK\n      }\n    }\n    \n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    \n    // This seems rather kludgey, may there is better way to indicate\n    // that replica can support handling version ranges\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n    \n    val = params.get(\"getFingerprint\");\n    if(val != null) {\n      processGetFingeprint(rb);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n    \n    val = params.get(\"getInputDocument\");\n    if (val != null) {\n      processGetInputDocument(rb);\n      return;\n    }\n\n    final IdsRequsted reqIds = IdsRequsted.parseParams(req);\n    \n    if (reqIds.allIds.isEmpty()) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n    final SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    SearcherInfo searcherInfo =  new SearcherInfo(core);\n    \n    // this is initialized & set on the context *after* any searcher (re-)opening\n    ResultContext resultContext = null;\n    final DocTransformer transformer = rsp.getReturnFields().getTransformer();\n\n    // true in any situation where we have to use a realtime searcher rather then returning docs\n    // directly from the UpdateLog\n    final boolean mustUseRealtimeSearcher =\n      // if we have filters, we need to check those against the indexed form of the doc\n      (rb.getFilters() != null)\n      || ((null != transformer) && transformer.needsSolrIndexSearcher());\n\n   try {\n\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : reqIds.allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(UpdateLog.FLAGS_IDX) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.UPDATE_INPLACE: // fall through to ADD\n             case UpdateLog.ADD:\n\n               if (mustUseRealtimeSearcher) {\n                 // close handles to current searchers & result context\n                 searcherInfo.clear();\n                 resultContext = null;\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc;\n               if (oper == UpdateLog.ADD) {\n                 doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               } else if (oper == UpdateLog.UPDATE_INPLACE) {\n                 assert entry.size() == 5;\n                 // For in-place update case, we have obtained the partial document till now. We need to\n                 // resolve it to a full document to be returned to the user.\n                 doc = resolveFullDocument(core, idBytes.get(), rsp.getReturnFields(), (SolrInputDocument)entry.get(entry.size()-1), entry, null);\n                 if (doc == null) {\n                   break; // document has been deleted as the resolve was going on\n                 }\n               } else {\n                 throw new SolrException(ErrorCode.INVALID_STATE, \"Expected ADD or UPDATE_INPLACE. Got: \" + oper);\n               }\n               if (transformer!=null) {\n                 transformer.transform(doc, -1); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       searcherInfo.init();\n       // don't bother with ResultContext yet, we won't need it if doc doesn't match filters\n\n       int docid = -1;\n       long segAndId = searcherInfo.getSearcher().lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcherInfo.getSearcher().getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query raw : rb.getFilters()) {\n             Query q = raw.rewrite(searcherInfo.getSearcher().getIndexReader());\n             Scorer scorer = searcherInfo.getSearcher().createWeight(q, ScoreMode.COMPLETE_NO_SCORES, 1f).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n       if (docid < 0) continue;\n       \n       Document luceneDocument = searcherInfo.getSearcher().doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       SolrDocumentFetcher docFetcher = searcherInfo.getSearcher().getDocFetcher();\n       docFetcher.decorateDocValueFields(doc, docid, docFetcher.getNonStoredDVs(true));\n       if ( null != transformer) {\n         if (null == resultContext) {\n           // either first pass, or we've re-opened searcher - either way now we setContext\n           resultContext = new RTGResultContext(rsp.getReturnFields(), searcherInfo.getSearcher(), req);\n           transformer.setContext(resultContext);\n         }\n         transformer.transform(doc, docid);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     searcherInfo.clear();\n   }\n\n   addDocListToResponse(rb, docList);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"83788ad129a5154d5c6562c4e8ce3db48793aada","date":1532961485,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    CloudDescriptor cloudDesc = req.getCore().getCoreDescriptor().getCloudDescriptor();\n\n    if (cloudDesc != null) {\n      Replica.Type replicaType = cloudDesc.getReplicaType();\n      if (replicaType != null) {\n        if (replicaType == Replica.Type.PULL) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \n              String.format(Locale.ROOT, \"%s can't handle realtime get requests. Replicas of type %s do not support these type of requests\", \n                  cloudDesc.getCoreNodeName(),\n                  Replica.Type.PULL));\n        } \n        // non-leader TLOG replicas should not respond to distrib /get requests, but internal requests are OK\n      }\n    }\n    \n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    \n    // This seems rather kludgey, may there is better way to indicate\n    // that replica can support handling version ranges\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n    \n    val = params.get(\"getFingerprint\");\n    if(val != null) {\n      processGetFingeprint(rb);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.count(new MatchAllDocsQuery()));\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n    \n    val = params.get(\"getInputDocument\");\n    if (val != null) {\n      processGetInputDocument(rb);\n      return;\n    }\n\n    final IdsRequsted reqIds = IdsRequsted.parseParams(req);\n    \n    if (reqIds.allIds.isEmpty()) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n    final SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    SearcherInfo searcherInfo =  new SearcherInfo(core);\n    \n    // this is initialized & set on the context *after* any searcher (re-)opening\n    ResultContext resultContext = null;\n    final DocTransformer transformer = rsp.getReturnFields().getTransformer();\n\n    // true in any situation where we have to use a realtime searcher rather then returning docs\n    // directly from the UpdateLog\n    final boolean mustUseRealtimeSearcher =\n      // if we have filters, we need to check those against the indexed form of the doc\n      (rb.getFilters() != null)\n      || ((null != transformer) && transformer.needsSolrIndexSearcher());\n\n   try {\n\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : reqIds.allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(UpdateLog.FLAGS_IDX) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.UPDATE_INPLACE: // fall through to ADD\n             case UpdateLog.ADD:\n\n               if (mustUseRealtimeSearcher) {\n                 // close handles to current searchers & result context\n                 searcherInfo.clear();\n                 resultContext = null;\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc;\n               if (oper == UpdateLog.ADD) {\n                 doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               } else if (oper == UpdateLog.UPDATE_INPLACE) {\n                 if (ulog instanceof CdcrUpdateLog) {\n                   assert entry.size() == 6;\n                 } else {\n                   assert entry.size() == 5;\n                 }\n                 // For in-place update case, we have obtained the partial document till now. We need to\n                 // resolve it to a full document to be returned to the user.\n                 doc = resolveFullDocument(core, idBytes.get(), rsp.getReturnFields(), (SolrInputDocument)entry.get(entry.size()-1), entry, null);\n                 if (doc == null) {\n                   break; // document has been deleted as the resolve was going on\n                 }\n               } else {\n                 throw new SolrException(ErrorCode.INVALID_STATE, \"Expected ADD or UPDATE_INPLACE. Got: \" + oper);\n               }\n               if (transformer!=null) {\n                 transformer.transform(doc, -1); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       searcherInfo.init();\n       // don't bother with ResultContext yet, we won't need it if doc doesn't match filters\n\n       int docid = -1;\n       long segAndId = searcherInfo.getSearcher().lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcherInfo.getSearcher().getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query raw : rb.getFilters()) {\n             Query q = raw.rewrite(searcherInfo.getSearcher().getIndexReader());\n             Scorer scorer = searcherInfo.getSearcher().createWeight(q, ScoreMode.COMPLETE_NO_SCORES, 1f).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n       if (docid < 0) continue;\n       \n       Document luceneDocument = searcherInfo.getSearcher().doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       SolrDocumentFetcher docFetcher = searcherInfo.getSearcher().getDocFetcher();\n       docFetcher.decorateDocValueFields(doc, docid, docFetcher.getNonStoredDVs(true));\n       if ( null != transformer) {\n         if (null == resultContext) {\n           // either first pass, or we've re-opened searcher - either way now we setContext\n           resultContext = new RTGResultContext(rsp.getReturnFields(), searcherInfo.getSearcher(), req);\n           transformer.setContext(resultContext);\n         }\n         transformer.transform(doc, docid);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     searcherInfo.clear();\n   }\n\n   addDocListToResponse(rb, docList);\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    CloudDescriptor cloudDesc = req.getCore().getCoreDescriptor().getCloudDescriptor();\n\n    if (cloudDesc != null) {\n      Replica.Type replicaType = cloudDesc.getReplicaType();\n      if (replicaType != null) {\n        if (replicaType == Replica.Type.PULL) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \n              String.format(Locale.ROOT, \"%s can't handle realtime get requests. Replicas of type %s do not support these type of requests\", \n                  cloudDesc.getCoreNodeName(),\n                  Replica.Type.PULL));\n        } \n        // non-leader TLOG replicas should not respond to distrib /get requests, but internal requests are OK\n      }\n    }\n    \n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    \n    // This seems rather kludgey, may there is better way to indicate\n    // that replica can support handling version ranges\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n    \n    val = params.get(\"getFingerprint\");\n    if(val != null) {\n      processGetFingeprint(rb);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.search(new MatchAllDocsQuery(), 1).totalHits);\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n    \n    val = params.get(\"getInputDocument\");\n    if (val != null) {\n      processGetInputDocument(rb);\n      return;\n    }\n\n    final IdsRequsted reqIds = IdsRequsted.parseParams(req);\n    \n    if (reqIds.allIds.isEmpty()) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n    final SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    SearcherInfo searcherInfo =  new SearcherInfo(core);\n    \n    // this is initialized & set on the context *after* any searcher (re-)opening\n    ResultContext resultContext = null;\n    final DocTransformer transformer = rsp.getReturnFields().getTransformer();\n\n    // true in any situation where we have to use a realtime searcher rather then returning docs\n    // directly from the UpdateLog\n    final boolean mustUseRealtimeSearcher =\n      // if we have filters, we need to check those against the indexed form of the doc\n      (rb.getFilters() != null)\n      || ((null != transformer) && transformer.needsSolrIndexSearcher());\n\n   try {\n\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : reqIds.allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(UpdateLog.FLAGS_IDX) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.UPDATE_INPLACE: // fall through to ADD\n             case UpdateLog.ADD:\n\n               if (mustUseRealtimeSearcher) {\n                 // close handles to current searchers & result context\n                 searcherInfo.clear();\n                 resultContext = null;\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc;\n               if (oper == UpdateLog.ADD) {\n                 doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               } else if (oper == UpdateLog.UPDATE_INPLACE) {\n                 if (ulog instanceof CdcrUpdateLog) {\n                   assert entry.size() == 6;\n                 } else {\n                   assert entry.size() == 5;\n                 }\n                 // For in-place update case, we have obtained the partial document till now. We need to\n                 // resolve it to a full document to be returned to the user.\n                 doc = resolveFullDocument(core, idBytes.get(), rsp.getReturnFields(), (SolrInputDocument)entry.get(entry.size()-1), entry, null);\n                 if (doc == null) {\n                   break; // document has been deleted as the resolve was going on\n                 }\n               } else {\n                 throw new SolrException(ErrorCode.INVALID_STATE, \"Expected ADD or UPDATE_INPLACE. Got: \" + oper);\n               }\n               if (transformer!=null) {\n                 transformer.transform(doc, -1); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       searcherInfo.init();\n       // don't bother with ResultContext yet, we won't need it if doc doesn't match filters\n\n       int docid = -1;\n       long segAndId = searcherInfo.getSearcher().lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcherInfo.getSearcher().getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query raw : rb.getFilters()) {\n             Query q = raw.rewrite(searcherInfo.getSearcher().getIndexReader());\n             Scorer scorer = searcherInfo.getSearcher().createWeight(q, ScoreMode.COMPLETE_NO_SCORES, 1f).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n       if (docid < 0) continue;\n       \n       Document luceneDocument = searcherInfo.getSearcher().doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       SolrDocumentFetcher docFetcher = searcherInfo.getSearcher().getDocFetcher();\n       docFetcher.decorateDocValueFields(doc, docid, docFetcher.getNonStoredDVs(true));\n       if ( null != transformer) {\n         if (null == resultContext) {\n           // either first pass, or we've re-opened searcher - either way now we setContext\n           resultContext = new RTGResultContext(rsp.getReturnFields(), searcherInfo.getSearcher(), req);\n           transformer.setContext(resultContext);\n         }\n         transformer.transform(doc, docid);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     searcherInfo.clear();\n   }\n\n   addDocListToResponse(rb, docList);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"575e66bd4b2349209027f6801184da7fc3cba13f","date":1587609169,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    CloudDescriptor cloudDesc = req.getCore().getCoreDescriptor().getCloudDescriptor();\n\n    if (cloudDesc != null) {\n      Replica.Type replicaType = cloudDesc.getReplicaType();\n      if (replicaType != null) {\n        if (replicaType == Replica.Type.PULL) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \n              String.format(Locale.ROOT, \"%s can't handle realtime get requests. Replicas of type %s do not support these type of requests\", \n                  cloudDesc.getCoreNodeName(),\n                  Replica.Type.PULL));\n        } \n        // non-leader TLOG replicas should not respond to distrib /get requests, but internal requests are OK\n      }\n    }\n    \n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    \n    // This seems rather kludgey, may there is better way to indicate\n    // that replica can support handling version ranges\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n    \n    val = params.get(\"getFingerprint\");\n    if(val != null) {\n      processGetFingeprint(rb);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            if (log.isDebugEnabled()) {\n              log.debug(\"{} min count to sync to (from most recent searcher view) {}\"\n                  , req.getCore().getCoreContainer().getZkController().getNodeName()\n                  , searcher.count(new MatchAllDocsQuery()));\n            }\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n    \n    val = params.get(\"getInputDocument\");\n    if (val != null) {\n      processGetInputDocument(rb);\n      return;\n    }\n\n    final IdsRequsted reqIds = IdsRequsted.parseParams(req);\n    \n    if (reqIds.allIds.isEmpty()) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n    final SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    SearcherInfo searcherInfo =  new SearcherInfo(core);\n    \n    // this is initialized & set on the context *after* any searcher (re-)opening\n    ResultContext resultContext = null;\n    final DocTransformer transformer = rsp.getReturnFields().getTransformer();\n\n    // true in any situation where we have to use a realtime searcher rather then returning docs\n    // directly from the UpdateLog\n    final boolean mustUseRealtimeSearcher =\n      // if we have filters, we need to check those against the indexed form of the doc\n      (rb.getFilters() != null)\n      || ((null != transformer) && transformer.needsSolrIndexSearcher());\n\n   try {\n\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : reqIds.allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(UpdateLog.FLAGS_IDX) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.UPDATE_INPLACE: // fall through to ADD\n             case UpdateLog.ADD:\n\n               if (mustUseRealtimeSearcher) {\n                 // close handles to current searchers & result context\n                 searcherInfo.clear();\n                 resultContext = null;\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc;\n               if (oper == UpdateLog.ADD) {\n                 doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               } else if (oper == UpdateLog.UPDATE_INPLACE) {\n                 if (ulog instanceof CdcrUpdateLog) {\n                   assert entry.size() == 6;\n                 } else {\n                   assert entry.size() == 5;\n                 }\n                 // For in-place update case, we have obtained the partial document till now. We need to\n                 // resolve it to a full document to be returned to the user.\n                 doc = resolveFullDocument(core, idBytes.get(), rsp.getReturnFields(), (SolrInputDocument)entry.get(entry.size()-1), entry, null);\n                 if (doc == null) {\n                   break; // document has been deleted as the resolve was going on\n                 }\n               } else {\n                 throw new SolrException(ErrorCode.INVALID_STATE, \"Expected ADD or UPDATE_INPLACE. Got: \" + oper);\n               }\n               if (transformer!=null) {\n                 transformer.transform(doc, -1); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       searcherInfo.init();\n       // don't bother with ResultContext yet, we won't need it if doc doesn't match filters\n\n       int docid = -1;\n       long segAndId = searcherInfo.getSearcher().lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcherInfo.getSearcher().getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query raw : rb.getFilters()) {\n             Query q = raw.rewrite(searcherInfo.getSearcher().getIndexReader());\n             Scorer scorer = searcherInfo.getSearcher().createWeight(q, ScoreMode.COMPLETE_NO_SCORES, 1f).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n       if (docid < 0) continue;\n       \n       Document luceneDocument = searcherInfo.getSearcher().doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       SolrDocumentFetcher docFetcher = searcherInfo.getSearcher().getDocFetcher();\n       docFetcher.decorateDocValueFields(doc, docid, docFetcher.getNonStoredDVs(true));\n       if ( null != transformer) {\n         if (null == resultContext) {\n           // either first pass, or we've re-opened searcher - either way now we setContext\n           resultContext = new RTGResultContext(rsp.getReturnFields(), searcherInfo.getSearcher(), req);\n           transformer.setContext(resultContext);\n         }\n         transformer.transform(doc, docid);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     searcherInfo.clear();\n   }\n\n   addDocListToResponse(rb, docList);\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    CloudDescriptor cloudDesc = req.getCore().getCoreDescriptor().getCloudDescriptor();\n\n    if (cloudDesc != null) {\n      Replica.Type replicaType = cloudDesc.getReplicaType();\n      if (replicaType != null) {\n        if (replicaType == Replica.Type.PULL) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \n              String.format(Locale.ROOT, \"%s can't handle realtime get requests. Replicas of type %s do not support these type of requests\", \n                  cloudDesc.getCoreNodeName(),\n                  Replica.Type.PULL));\n        } \n        // non-leader TLOG replicas should not respond to distrib /get requests, but internal requests are OK\n      }\n    }\n    \n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    \n    // This seems rather kludgey, may there is better way to indicate\n    // that replica can support handling version ranges\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n    \n    val = params.get(\"getFingerprint\");\n    if(val != null) {\n      processGetFingeprint(rb);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            log.debug(req.getCore()\n                .getCoreContainer().getZkController().getNodeName()\n                + \" min count to sync to (from most recent searcher view) \"\n                + searcher.count(new MatchAllDocsQuery()));\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n    \n    val = params.get(\"getInputDocument\");\n    if (val != null) {\n      processGetInputDocument(rb);\n      return;\n    }\n\n    final IdsRequsted reqIds = IdsRequsted.parseParams(req);\n    \n    if (reqIds.allIds.isEmpty()) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n    final SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    SearcherInfo searcherInfo =  new SearcherInfo(core);\n    \n    // this is initialized & set on the context *after* any searcher (re-)opening\n    ResultContext resultContext = null;\n    final DocTransformer transformer = rsp.getReturnFields().getTransformer();\n\n    // true in any situation where we have to use a realtime searcher rather then returning docs\n    // directly from the UpdateLog\n    final boolean mustUseRealtimeSearcher =\n      // if we have filters, we need to check those against the indexed form of the doc\n      (rb.getFilters() != null)\n      || ((null != transformer) && transformer.needsSolrIndexSearcher());\n\n   try {\n\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : reqIds.allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(UpdateLog.FLAGS_IDX) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.UPDATE_INPLACE: // fall through to ADD\n             case UpdateLog.ADD:\n\n               if (mustUseRealtimeSearcher) {\n                 // close handles to current searchers & result context\n                 searcherInfo.clear();\n                 resultContext = null;\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc;\n               if (oper == UpdateLog.ADD) {\n                 doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               } else if (oper == UpdateLog.UPDATE_INPLACE) {\n                 if (ulog instanceof CdcrUpdateLog) {\n                   assert entry.size() == 6;\n                 } else {\n                   assert entry.size() == 5;\n                 }\n                 // For in-place update case, we have obtained the partial document till now. We need to\n                 // resolve it to a full document to be returned to the user.\n                 doc = resolveFullDocument(core, idBytes.get(), rsp.getReturnFields(), (SolrInputDocument)entry.get(entry.size()-1), entry, null);\n                 if (doc == null) {\n                   break; // document has been deleted as the resolve was going on\n                 }\n               } else {\n                 throw new SolrException(ErrorCode.INVALID_STATE, \"Expected ADD or UPDATE_INPLACE. Got: \" + oper);\n               }\n               if (transformer!=null) {\n                 transformer.transform(doc, -1); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       searcherInfo.init();\n       // don't bother with ResultContext yet, we won't need it if doc doesn't match filters\n\n       int docid = -1;\n       long segAndId = searcherInfo.getSearcher().lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcherInfo.getSearcher().getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query raw : rb.getFilters()) {\n             Query q = raw.rewrite(searcherInfo.getSearcher().getIndexReader());\n             Scorer scorer = searcherInfo.getSearcher().createWeight(q, ScoreMode.COMPLETE_NO_SCORES, 1f).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n       if (docid < 0) continue;\n       \n       Document luceneDocument = searcherInfo.getSearcher().doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       SolrDocumentFetcher docFetcher = searcherInfo.getSearcher().getDocFetcher();\n       docFetcher.decorateDocValueFields(doc, docid, docFetcher.getNonStoredDVs(true));\n       if ( null != transformer) {\n         if (null == resultContext) {\n           // either first pass, or we've re-opened searcher - either way now we setContext\n           resultContext = new RTGResultContext(rsp.getReturnFields(), searcherInfo.getSearcher(), req);\n           transformer.setContext(resultContext);\n         }\n         transformer.transform(doc, docid);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     searcherInfo.clear();\n   }\n\n   addDocListToResponse(rb, docList);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8582f07e9350eaeb33bf6c4617b8c9895d99c839","date":1591307386,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    CloudDescriptor cloudDesc = req.getCore().getCoreDescriptor().getCloudDescriptor();\n\n    if (cloudDesc != null) {\n      Replica.Type replicaType = cloudDesc.getReplicaType();\n      if (replicaType != null) {\n        if (replicaType == Replica.Type.PULL) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \n              String.format(Locale.ROOT, \"%s can't handle realtime get requests. Replicas of type %s do not support these type of requests\", \n                  cloudDesc.getCoreNodeName(),\n                  Replica.Type.PULL));\n        } \n        // non-leader TLOG replicas should not respond to distrib /get requests, but internal requests are OK\n      }\n    }\n    \n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    \n    // This seems rather kludgey, may there is better way to indicate\n    // that replica can support handling version ranges\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n    \n    val = params.get(\"getFingerprint\");\n    if(val != null) {\n      processGetFingeprint(rb);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            if (log.isDebugEnabled()) {\n              log.debug(\"{} min count to sync to (from most recent searcher view) {}\"\n                  , req.getCore().getCoreContainer().getZkController().getNodeName()\n                  , searcher.count(new MatchAllDocsQuery()));\n            }\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n    \n    val = params.get(\"getInputDocument\");\n    if (val != null) {\n      processGetInputDocument(rb);\n      return;\n    }\n\n    final IdsRequsted reqIds = IdsRequsted.parseParams(req);\n    \n    if (reqIds.allIds.isEmpty()) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n    final SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    SearcherInfo searcherInfo =  new SearcherInfo(core);\n    \n    // this is initialized & set on the context *after* any searcher (re-)opening\n    ResultContext resultContext = null;\n    final DocTransformer transformer = rsp.getReturnFields().getTransformer();\n\n    // true in any situation where we have to use a realtime searcher rather then returning docs\n    // directly from the UpdateLog\n    final boolean mustUseRealtimeSearcher =\n      // if we have filters, we need to check those against the indexed form of the doc\n      (rb.getFilters() != null)\n      || ((null != transformer) && transformer.needsSolrIndexSearcher());\n\n   try {\n\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : reqIds.allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           @SuppressWarnings({\"rawtypes\"})\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(UpdateLog.FLAGS_IDX) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.UPDATE_INPLACE: // fall through to ADD\n             case UpdateLog.ADD:\n\n               if (mustUseRealtimeSearcher) {\n                 // close handles to current searchers & result context\n                 searcherInfo.clear();\n                 resultContext = null;\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc;\n               if (oper == UpdateLog.ADD) {\n                 doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               } else if (oper == UpdateLog.UPDATE_INPLACE) {\n                 if (ulog instanceof CdcrUpdateLog) {\n                   assert entry.size() == 6;\n                 } else {\n                   assert entry.size() == 5;\n                 }\n                 // For in-place update case, we have obtained the partial document till now. We need to\n                 // resolve it to a full document to be returned to the user.\n                 doc = resolveFullDocument(core, idBytes.get(), rsp.getReturnFields(), (SolrInputDocument)entry.get(entry.size()-1), entry, null);\n                 if (doc == null) {\n                   break; // document has been deleted as the resolve was going on\n                 }\n               } else {\n                 throw new SolrException(ErrorCode.INVALID_STATE, \"Expected ADD or UPDATE_INPLACE. Got: \" + oper);\n               }\n               if (transformer!=null) {\n                 transformer.transform(doc, -1); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       searcherInfo.init();\n       // don't bother with ResultContext yet, we won't need it if doc doesn't match filters\n\n       int docid = -1;\n       long segAndId = searcherInfo.getSearcher().lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcherInfo.getSearcher().getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query raw : rb.getFilters()) {\n             Query q = raw.rewrite(searcherInfo.getSearcher().getIndexReader());\n             Scorer scorer = searcherInfo.getSearcher().createWeight(q, ScoreMode.COMPLETE_NO_SCORES, 1f).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n       if (docid < 0) continue;\n       \n       Document luceneDocument = searcherInfo.getSearcher().doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       SolrDocumentFetcher docFetcher = searcherInfo.getSearcher().getDocFetcher();\n       docFetcher.decorateDocValueFields(doc, docid, docFetcher.getNonStoredDVs(true));\n       if ( null != transformer) {\n         if (null == resultContext) {\n           // either first pass, or we've re-opened searcher - either way now we setContext\n           resultContext = new RTGResultContext(rsp.getReturnFields(), searcherInfo.getSearcher(), req);\n           transformer.setContext(resultContext);\n         }\n         transformer.transform(doc, docid);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     searcherInfo.clear();\n   }\n\n   addDocListToResponse(rb, docList);\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    CloudDescriptor cloudDesc = req.getCore().getCoreDescriptor().getCloudDescriptor();\n\n    if (cloudDesc != null) {\n      Replica.Type replicaType = cloudDesc.getReplicaType();\n      if (replicaType != null) {\n        if (replicaType == Replica.Type.PULL) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \n              String.format(Locale.ROOT, \"%s can't handle realtime get requests. Replicas of type %s do not support these type of requests\", \n                  cloudDesc.getCoreNodeName(),\n                  Replica.Type.PULL));\n        } \n        // non-leader TLOG replicas should not respond to distrib /get requests, but internal requests are OK\n      }\n    }\n    \n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    \n    // This seems rather kludgey, may there is better way to indicate\n    // that replica can support handling version ranges\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n    \n    val = params.get(\"getFingerprint\");\n    if(val != null) {\n      processGetFingeprint(rb);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            if (log.isDebugEnabled()) {\n              log.debug(\"{} min count to sync to (from most recent searcher view) {}\"\n                  , req.getCore().getCoreContainer().getZkController().getNodeName()\n                  , searcher.count(new MatchAllDocsQuery()));\n            }\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n    \n    val = params.get(\"getInputDocument\");\n    if (val != null) {\n      processGetInputDocument(rb);\n      return;\n    }\n\n    final IdsRequsted reqIds = IdsRequsted.parseParams(req);\n    \n    if (reqIds.allIds.isEmpty()) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n    final SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    SearcherInfo searcherInfo =  new SearcherInfo(core);\n    \n    // this is initialized & set on the context *after* any searcher (re-)opening\n    ResultContext resultContext = null;\n    final DocTransformer transformer = rsp.getReturnFields().getTransformer();\n\n    // true in any situation where we have to use a realtime searcher rather then returning docs\n    // directly from the UpdateLog\n    final boolean mustUseRealtimeSearcher =\n      // if we have filters, we need to check those against the indexed form of the doc\n      (rb.getFilters() != null)\n      || ((null != transformer) && transformer.needsSolrIndexSearcher());\n\n   try {\n\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : reqIds.allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(UpdateLog.FLAGS_IDX) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.UPDATE_INPLACE: // fall through to ADD\n             case UpdateLog.ADD:\n\n               if (mustUseRealtimeSearcher) {\n                 // close handles to current searchers & result context\n                 searcherInfo.clear();\n                 resultContext = null;\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc;\n               if (oper == UpdateLog.ADD) {\n                 doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               } else if (oper == UpdateLog.UPDATE_INPLACE) {\n                 if (ulog instanceof CdcrUpdateLog) {\n                   assert entry.size() == 6;\n                 } else {\n                   assert entry.size() == 5;\n                 }\n                 // For in-place update case, we have obtained the partial document till now. We need to\n                 // resolve it to a full document to be returned to the user.\n                 doc = resolveFullDocument(core, idBytes.get(), rsp.getReturnFields(), (SolrInputDocument)entry.get(entry.size()-1), entry, null);\n                 if (doc == null) {\n                   break; // document has been deleted as the resolve was going on\n                 }\n               } else {\n                 throw new SolrException(ErrorCode.INVALID_STATE, \"Expected ADD or UPDATE_INPLACE. Got: \" + oper);\n               }\n               if (transformer!=null) {\n                 transformer.transform(doc, -1); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       searcherInfo.init();\n       // don't bother with ResultContext yet, we won't need it if doc doesn't match filters\n\n       int docid = -1;\n       long segAndId = searcherInfo.getSearcher().lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcherInfo.getSearcher().getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query raw : rb.getFilters()) {\n             Query q = raw.rewrite(searcherInfo.getSearcher().getIndexReader());\n             Scorer scorer = searcherInfo.getSearcher().createWeight(q, ScoreMode.COMPLETE_NO_SCORES, 1f).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n       if (docid < 0) continue;\n       \n       Document luceneDocument = searcherInfo.getSearcher().doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       SolrDocumentFetcher docFetcher = searcherInfo.getSearcher().getDocFetcher();\n       docFetcher.decorateDocValueFields(doc, docid, docFetcher.getNonStoredDVs(true));\n       if ( null != transformer) {\n         if (null == resultContext) {\n           // either first pass, or we've re-opened searcher - either way now we setContext\n           resultContext = new RTGResultContext(rsp.getReturnFields(), searcherInfo.getSearcher(), req);\n           transformer.setContext(resultContext);\n         }\n         transformer.transform(doc, docid);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     searcherInfo.clear();\n   }\n\n   addDocListToResponse(rb, docList);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c38d3299f414132db022cec9d60b2dafc244a7c3","date":1597046674,"type":3,"author":"Cao Manh Dat","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    CloudDescriptor cloudDesc = req.getCore().getCoreDescriptor().getCloudDescriptor();\n\n    if (cloudDesc != null) {\n      Replica.Type replicaType = cloudDesc.getReplicaType();\n      if (replicaType != null) {\n        if (replicaType == Replica.Type.PULL) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \n              String.format(Locale.ROOT, \"%s can't handle realtime get requests. Replicas of type %s do not support these type of requests\", \n                  cloudDesc.getCoreNodeName(),\n                  Replica.Type.PULL));\n        } \n        // non-leader TLOG replicas should not respond to distrib /get requests, but internal requests are OK\n      }\n    }\n    \n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    //TODO remove this at Solr 10\n    //After SOLR-14641 other nodes won't call RTG with this param.\n    //Just keeping here for backward-compatibility, if we remove this, nodes with older versions will\n    //assume that this node can't handle version ranges.\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n\n    val = params.get(\"getFingerprint\");\n    if(val != null) {\n      processGetFingeprint(rb);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            if (log.isDebugEnabled()) {\n              log.debug(\"{} min count to sync to (from most recent searcher view) {}\"\n                  , req.getCore().getCoreContainer().getZkController().getNodeName()\n                  , searcher.count(new MatchAllDocsQuery()));\n            }\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n    \n    val = params.get(\"getInputDocument\");\n    if (val != null) {\n      processGetInputDocument(rb);\n      return;\n    }\n\n    final IdsRequsted reqIds = IdsRequsted.parseParams(req);\n    \n    if (reqIds.allIds.isEmpty()) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n    final SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    SearcherInfo searcherInfo =  new SearcherInfo(core);\n    \n    // this is initialized & set on the context *after* any searcher (re-)opening\n    ResultContext resultContext = null;\n    final DocTransformer transformer = rsp.getReturnFields().getTransformer();\n\n    // true in any situation where we have to use a realtime searcher rather then returning docs\n    // directly from the UpdateLog\n    final boolean mustUseRealtimeSearcher =\n      // if we have filters, we need to check those against the indexed form of the doc\n      (rb.getFilters() != null)\n      || ((null != transformer) && transformer.needsSolrIndexSearcher());\n\n   try {\n\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : reqIds.allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           @SuppressWarnings({\"rawtypes\"})\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(UpdateLog.FLAGS_IDX) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.UPDATE_INPLACE: // fall through to ADD\n             case UpdateLog.ADD:\n\n               if (mustUseRealtimeSearcher) {\n                 // close handles to current searchers & result context\n                 searcherInfo.clear();\n                 resultContext = null;\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc;\n               if (oper == UpdateLog.ADD) {\n                 doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               } else if (oper == UpdateLog.UPDATE_INPLACE) {\n                 if (ulog instanceof CdcrUpdateLog) {\n                   assert entry.size() == 6;\n                 } else {\n                   assert entry.size() == 5;\n                 }\n                 // For in-place update case, we have obtained the partial document till now. We need to\n                 // resolve it to a full document to be returned to the user.\n                 doc = resolveFullDocument(core, idBytes.get(), rsp.getReturnFields(), (SolrInputDocument)entry.get(entry.size()-1), entry, null);\n                 if (doc == null) {\n                   break; // document has been deleted as the resolve was going on\n                 }\n               } else {\n                 throw new SolrException(ErrorCode.INVALID_STATE, \"Expected ADD or UPDATE_INPLACE. Got: \" + oper);\n               }\n               if (transformer!=null) {\n                 transformer.transform(doc, -1); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       searcherInfo.init();\n       // don't bother with ResultContext yet, we won't need it if doc doesn't match filters\n\n       int docid = -1;\n       long segAndId = searcherInfo.getSearcher().lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcherInfo.getSearcher().getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query raw : rb.getFilters()) {\n             Query q = raw.rewrite(searcherInfo.getSearcher().getIndexReader());\n             Scorer scorer = searcherInfo.getSearcher().createWeight(q, ScoreMode.COMPLETE_NO_SCORES, 1f).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n       if (docid < 0) continue;\n       \n       Document luceneDocument = searcherInfo.getSearcher().doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       SolrDocumentFetcher docFetcher = searcherInfo.getSearcher().getDocFetcher();\n       docFetcher.decorateDocValueFields(doc, docid, docFetcher.getNonStoredDVs(true));\n       if ( null != transformer) {\n         if (null == resultContext) {\n           // either first pass, or we've re-opened searcher - either way now we setContext\n           resultContext = new RTGResultContext(rsp.getReturnFields(), searcherInfo.getSearcher(), req);\n           transformer.setContext(resultContext);\n         }\n         transformer.transform(doc, docid);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     searcherInfo.clear();\n   }\n\n   addDocListToResponse(rb, docList);\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    CloudDescriptor cloudDesc = req.getCore().getCoreDescriptor().getCloudDescriptor();\n\n    if (cloudDesc != null) {\n      Replica.Type replicaType = cloudDesc.getReplicaType();\n      if (replicaType != null) {\n        if (replicaType == Replica.Type.PULL) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \n              String.format(Locale.ROOT, \"%s can't handle realtime get requests. Replicas of type %s do not support these type of requests\", \n                  cloudDesc.getCoreNodeName(),\n                  Replica.Type.PULL));\n        } \n        // non-leader TLOG replicas should not respond to distrib /get requests, but internal requests are OK\n      }\n    }\n    \n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    \n    // This seems rather kludgey, may there is better way to indicate\n    // that replica can support handling version ranges\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n    \n    val = params.get(\"getFingerprint\");\n    if(val != null) {\n      processGetFingeprint(rb);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            if (log.isDebugEnabled()) {\n              log.debug(\"{} min count to sync to (from most recent searcher view) {}\"\n                  , req.getCore().getCoreContainer().getZkController().getNodeName()\n                  , searcher.count(new MatchAllDocsQuery()));\n            }\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n    \n    val = params.get(\"getInputDocument\");\n    if (val != null) {\n      processGetInputDocument(rb);\n      return;\n    }\n\n    final IdsRequsted reqIds = IdsRequsted.parseParams(req);\n    \n    if (reqIds.allIds.isEmpty()) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n    final SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    SearcherInfo searcherInfo =  new SearcherInfo(core);\n    \n    // this is initialized & set on the context *after* any searcher (re-)opening\n    ResultContext resultContext = null;\n    final DocTransformer transformer = rsp.getReturnFields().getTransformer();\n\n    // true in any situation where we have to use a realtime searcher rather then returning docs\n    // directly from the UpdateLog\n    final boolean mustUseRealtimeSearcher =\n      // if we have filters, we need to check those against the indexed form of the doc\n      (rb.getFilters() != null)\n      || ((null != transformer) && transformer.needsSolrIndexSearcher());\n\n   try {\n\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : reqIds.allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           @SuppressWarnings({\"rawtypes\"})\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(UpdateLog.FLAGS_IDX) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.UPDATE_INPLACE: // fall through to ADD\n             case UpdateLog.ADD:\n\n               if (mustUseRealtimeSearcher) {\n                 // close handles to current searchers & result context\n                 searcherInfo.clear();\n                 resultContext = null;\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc;\n               if (oper == UpdateLog.ADD) {\n                 doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               } else if (oper == UpdateLog.UPDATE_INPLACE) {\n                 if (ulog instanceof CdcrUpdateLog) {\n                   assert entry.size() == 6;\n                 } else {\n                   assert entry.size() == 5;\n                 }\n                 // For in-place update case, we have obtained the partial document till now. We need to\n                 // resolve it to a full document to be returned to the user.\n                 doc = resolveFullDocument(core, idBytes.get(), rsp.getReturnFields(), (SolrInputDocument)entry.get(entry.size()-1), entry, null);\n                 if (doc == null) {\n                   break; // document has been deleted as the resolve was going on\n                 }\n               } else {\n                 throw new SolrException(ErrorCode.INVALID_STATE, \"Expected ADD or UPDATE_INPLACE. Got: \" + oper);\n               }\n               if (transformer!=null) {\n                 transformer.transform(doc, -1); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       searcherInfo.init();\n       // don't bother with ResultContext yet, we won't need it if doc doesn't match filters\n\n       int docid = -1;\n       long segAndId = searcherInfo.getSearcher().lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcherInfo.getSearcher().getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query raw : rb.getFilters()) {\n             Query q = raw.rewrite(searcherInfo.getSearcher().getIndexReader());\n             Scorer scorer = searcherInfo.getSearcher().createWeight(q, ScoreMode.COMPLETE_NO_SCORES, 1f).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n       if (docid < 0) continue;\n       \n       Document luceneDocument = searcherInfo.getSearcher().doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       SolrDocumentFetcher docFetcher = searcherInfo.getSearcher().getDocFetcher();\n       docFetcher.decorateDocValueFields(doc, docid, docFetcher.getNonStoredDVs(true));\n       if ( null != transformer) {\n         if (null == resultContext) {\n           // either first pass, or we've re-opened searcher - either way now we setContext\n           resultContext = new RTGResultContext(rsp.getReturnFields(), searcherInfo.getSearcher(), req);\n           transformer.setContext(resultContext);\n         }\n         transformer.transform(doc, docid);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     searcherInfo.clear();\n   }\n\n   addDocListToResponse(rb, docList);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"23ec6d2969d61cadbfd0a5452e9be1f9999e8aa1","date":1598647393,"type":3,"author":"Ishan Chattopadhyaya","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/RealTimeGetComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    CloudDescriptor cloudDesc = req.getCore().getCoreDescriptor().getCloudDescriptor();\n\n    if (cloudDesc != null) {\n      Replica.Type replicaType = cloudDesc.getReplicaType();\n      if (replicaType != null) {\n        if (replicaType == Replica.Type.PULL) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \n              String.format(Locale.ROOT, \"%s can't handle realtime get requests. Replicas of type %s do not support these type of requests\", \n                  cloudDesc.getCoreNodeName(),\n                  Replica.Type.PULL));\n        } \n        // non-leader TLOG replicas should not respond to distrib /get requests, but internal requests are OK\n      }\n    }\n    \n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    //TODO remove this at Solr 10\n    //After SOLR-14641 other nodes won't call RTG with this param.\n    //Just keeping here for backward-compatibility, if we remove this, nodes with older versions will\n    //assume that this node can't handle version ranges.\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n\n    val = params.get(\"getFingerprint\");\n    if(val != null) {\n      processGetFingeprint(rb);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            if (log.isDebugEnabled()) {\n              log.debug(\"{} min count to sync to (from most recent searcher view) {}\"\n                  , req.getCore().getCoreContainer().getZkController().getNodeName()\n                  , searcher.count(new MatchAllDocsQuery()));\n            }\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n    \n    val = params.get(\"getInputDocument\");\n    if (val != null) {\n      processGetInputDocument(rb);\n      return;\n    }\n\n    final IdsRequsted reqIds = IdsRequsted.parseParams(req);\n    \n    if (reqIds.allIds.isEmpty()) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n    final SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    SearcherInfo searcherInfo =  new SearcherInfo(core);\n    \n    // this is initialized & set on the context *after* any searcher (re-)opening\n    ResultContext resultContext = null;\n    final DocTransformer transformer = rsp.getReturnFields().getTransformer();\n\n    // true in any situation where we have to use a realtime searcher rather then returning docs\n    // directly from the UpdateLog\n    final boolean mustUseRealtimeSearcher =\n      // if we have filters, we need to check those against the indexed form of the doc\n      (rb.getFilters() != null)\n      || ((null != transformer) && transformer.needsSolrIndexSearcher());\n\n   try {\n\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : reqIds.allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           @SuppressWarnings({\"rawtypes\"})\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(UpdateLog.FLAGS_IDX) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.UPDATE_INPLACE: // fall through to ADD\n             case UpdateLog.ADD:\n\n               if (mustUseRealtimeSearcher) {\n                 // close handles to current searchers & result context\n                 searcherInfo.clear();\n                 resultContext = null;\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc;\n               if (oper == UpdateLog.ADD) {\n                 doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               } else if (oper == UpdateLog.UPDATE_INPLACE) {\n                 assert entry.size() == 5;\n                 // For in-place update case, we have obtained the partial document till now. We need to\n                 // resolve it to a full document to be returned to the user.\n                 doc = resolveFullDocument(core, idBytes.get(), rsp.getReturnFields(), (SolrInputDocument)entry.get(entry.size()-1), entry, null);\n                 if (doc == null) {\n                   break; // document has been deleted as the resolve was going on\n                 }\n               } else {\n                 throw new SolrException(ErrorCode.INVALID_STATE, \"Expected ADD or UPDATE_INPLACE. Got: \" + oper);\n               }\n               if (transformer!=null) {\n                 transformer.transform(doc, -1); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       searcherInfo.init();\n       // don't bother with ResultContext yet, we won't need it if doc doesn't match filters\n\n       int docid = -1;\n       long segAndId = searcherInfo.getSearcher().lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcherInfo.getSearcher().getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query raw : rb.getFilters()) {\n             Query q = raw.rewrite(searcherInfo.getSearcher().getIndexReader());\n             Scorer scorer = searcherInfo.getSearcher().createWeight(q, ScoreMode.COMPLETE_NO_SCORES, 1f).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n       if (docid < 0) continue;\n       \n       Document luceneDocument = searcherInfo.getSearcher().doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       SolrDocumentFetcher docFetcher = searcherInfo.getSearcher().getDocFetcher();\n       docFetcher.decorateDocValueFields(doc, docid, docFetcher.getNonStoredDVs(true));\n       if ( null != transformer) {\n         if (null == resultContext) {\n           // either first pass, or we've re-opened searcher - either way now we setContext\n           resultContext = new RTGResultContext(rsp.getReturnFields(), searcherInfo.getSearcher(), req);\n           transformer.setContext(resultContext);\n         }\n         transformer.transform(doc, docid);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     searcherInfo.clear();\n   }\n\n   addDocListToResponse(rb, docList);\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    CloudDescriptor cloudDesc = req.getCore().getCoreDescriptor().getCloudDescriptor();\n\n    if (cloudDesc != null) {\n      Replica.Type replicaType = cloudDesc.getReplicaType();\n      if (replicaType != null) {\n        if (replicaType == Replica.Type.PULL) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \n              String.format(Locale.ROOT, \"%s can't handle realtime get requests. Replicas of type %s do not support these type of requests\", \n                  cloudDesc.getCoreNodeName(),\n                  Replica.Type.PULL));\n        } \n        // non-leader TLOG replicas should not respond to distrib /get requests, but internal requests are OK\n      }\n    }\n    \n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n\n    //TODO remove this at Solr 10\n    //After SOLR-14641 other nodes won't call RTG with this param.\n    //Just keeping here for backward-compatibility, if we remove this, nodes with older versions will\n    //assume that this node can't handle version ranges.\n    String val = params.get(\"checkCanHandleVersionRanges\");\n    if(val != null) {\n      rb.rsp.add(\"canHandleVersionRanges\", true);\n      return;\n    }\n\n    val = params.get(\"getFingerprint\");\n    if(val != null) {\n      processGetFingeprint(rb);\n      return;\n    }\n    \n    val = params.get(\"getVersions\");\n    if (val != null) {\n      processGetVersions(rb);\n      return;\n    }\n\n    val = params.get(\"getUpdates\");\n    if (val != null) {\n      // solrcloud_debug\n      if (log.isDebugEnabled()) {\n        try {\n          RefCounted<SolrIndexSearcher> searchHolder = req.getCore()\n              .getNewestSearcher(false);\n          SolrIndexSearcher searcher = searchHolder.get();\n          try {\n            if (log.isDebugEnabled()) {\n              log.debug(\"{} min count to sync to (from most recent searcher view) {}\"\n                  , req.getCore().getCoreContainer().getZkController().getNodeName()\n                  , searcher.count(new MatchAllDocsQuery()));\n            }\n          } finally {\n            searchHolder.decref();\n          }\n        } catch (Exception e) {\n          log.debug(\"Error in solrcloud_debug block\", e);\n        }\n      }\n      \n      processGetUpdates(rb);\n      return;\n    }\n    \n    val = params.get(\"getInputDocument\");\n    if (val != null) {\n      processGetInputDocument(rb);\n      return;\n    }\n\n    final IdsRequsted reqIds = IdsRequsted.parseParams(req);\n    \n    if (reqIds.allIds.isEmpty()) {\n      return;\n    }\n\n    // parse any existing filters\n    try {\n      String[] fqs = req.getParams().getParams(CommonParams.FQ);\n      if (fqs!=null && fqs.length!=0) {\n        List<Query> filters = rb.getFilters();\n        // if filters already exists, make a copy instead of modifying the original\n        filters = filters == null ? new ArrayList<Query>(fqs.length) : new ArrayList<>(filters);\n        for (String fq : fqs) {\n          if (fq != null && fq.trim().length()!=0) {\n            QParser fqp = QParser.getParser(fq, req);\n            filters.add(fqp.getQuery());\n          }\n        }\n        if (!filters.isEmpty()) {\n          rb.setFilters( filters );\n        }\n      }\n    } catch (SyntaxError e) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n    }\n\n    final SolrCore core = req.getCore();\n    SchemaField idField = core.getLatestSchema().getUniqueKeyField();\n    FieldType fieldType = idField.getType();\n\n    SolrDocumentList docList = new SolrDocumentList();\n    UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n\n    SearcherInfo searcherInfo =  new SearcherInfo(core);\n    \n    // this is initialized & set on the context *after* any searcher (re-)opening\n    ResultContext resultContext = null;\n    final DocTransformer transformer = rsp.getReturnFields().getTransformer();\n\n    // true in any situation where we have to use a realtime searcher rather then returning docs\n    // directly from the UpdateLog\n    final boolean mustUseRealtimeSearcher =\n      // if we have filters, we need to check those against the indexed form of the doc\n      (rb.getFilters() != null)\n      || ((null != transformer) && transformer.needsSolrIndexSearcher());\n\n   try {\n\n\n     BytesRefBuilder idBytes = new BytesRefBuilder();\n     for (String idStr : reqIds.allIds) {\n       fieldType.readableToIndexed(idStr, idBytes);\n       if (ulog != null) {\n         Object o = ulog.lookup(idBytes.get());\n         if (o != null) {\n           // should currently be a List<Oper,Ver,Doc/Id>\n           @SuppressWarnings({\"rawtypes\"})\n           List entry = (List)o;\n           assert entry.size() >= 3;\n           int oper = (Integer)entry.get(UpdateLog.FLAGS_IDX) & UpdateLog.OPERATION_MASK;\n           switch (oper) {\n             case UpdateLog.UPDATE_INPLACE: // fall through to ADD\n             case UpdateLog.ADD:\n\n               if (mustUseRealtimeSearcher) {\n                 // close handles to current searchers & result context\n                 searcherInfo.clear();\n                 resultContext = null;\n                 ulog.openRealtimeSearcher();  // force open a new realtime searcher\n                 o = null;  // pretend we never found this record and fall through to use the searcher\n                 break;\n               }\n\n               SolrDocument doc;\n               if (oper == UpdateLog.ADD) {\n                 doc = toSolrDoc((SolrInputDocument)entry.get(entry.size()-1), core.getLatestSchema());\n               } else if (oper == UpdateLog.UPDATE_INPLACE) {\n                 if (ulog instanceof CdcrUpdateLog) {\n                   assert entry.size() == 6;\n                 } else {\n                   assert entry.size() == 5;\n                 }\n                 // For in-place update case, we have obtained the partial document till now. We need to\n                 // resolve it to a full document to be returned to the user.\n                 doc = resolveFullDocument(core, idBytes.get(), rsp.getReturnFields(), (SolrInputDocument)entry.get(entry.size()-1), entry, null);\n                 if (doc == null) {\n                   break; // document has been deleted as the resolve was going on\n                 }\n               } else {\n                 throw new SolrException(ErrorCode.INVALID_STATE, \"Expected ADD or UPDATE_INPLACE. Got: \" + oper);\n               }\n               if (transformer!=null) {\n                 transformer.transform(doc, -1); // unknown docID\n               }\n              docList.add(doc);\n              break;\n             case UpdateLog.DELETE:\n              break;\n             default:\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n           }\n           if (o != null) continue;\n         }\n       }\n\n       // didn't find it in the update log, so it should be in the newest searcher opened\n       searcherInfo.init();\n       // don't bother with ResultContext yet, we won't need it if doc doesn't match filters\n\n       int docid = -1;\n       long segAndId = searcherInfo.getSearcher().lookupId(idBytes.get());\n       if (segAndId >= 0) {\n         int segid = (int) segAndId;\n         LeafReaderContext ctx = searcherInfo.getSearcher().getTopReaderContext().leaves().get((int) (segAndId >> 32));\n         docid = segid + ctx.docBase;\n\n         if (rb.getFilters() != null) {\n           for (Query raw : rb.getFilters()) {\n             Query q = raw.rewrite(searcherInfo.getSearcher().getIndexReader());\n             Scorer scorer = searcherInfo.getSearcher().createWeight(q, ScoreMode.COMPLETE_NO_SCORES, 1f).scorer(ctx);\n             if (scorer == null || segid != scorer.iterator().advance(segid)) {\n               // filter doesn't match.\n               docid = -1;\n               break;\n             }\n           }\n         }\n       }\n\n       if (docid < 0) continue;\n       \n       Document luceneDocument = searcherInfo.getSearcher().doc(docid, rsp.getReturnFields().getLuceneFieldNames());\n       SolrDocument doc = toSolrDoc(luceneDocument,  core.getLatestSchema());\n       SolrDocumentFetcher docFetcher = searcherInfo.getSearcher().getDocFetcher();\n       docFetcher.decorateDocValueFields(doc, docid, docFetcher.getNonStoredDVs(true));\n       if ( null != transformer) {\n         if (null == resultContext) {\n           // either first pass, or we've re-opened searcher - either way now we setContext\n           resultContext = new RTGResultContext(rsp.getReturnFields(), searcherInfo.getSearcher(), req);\n           transformer.setContext(resultContext);\n         }\n         transformer.transform(doc, docid);\n       }\n       docList.add(doc);\n     }\n\n   } finally {\n     searcherInfo.clear();\n   }\n\n   addDocListToResponse(rb, docList);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"29918ccc4b27ebd261d8446761e5e02666abe893":["bd0ef6574805f3cb9880e0983b7548a6aa933508"],"6c94d2661bc1c14426980ec7882e951fdcff08d0":["659d7ea4e085dbd15c54c80811439e4bb21a74fb"],"4346940138bc1085f62b4535467e6724d604bc50":["6654c5f3ec2e4a84ef867c82d4eec872c2372c8c"],"7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"7a3554ff15950ad0e3bcbb4e4e2ddb45b0b0f27e":["29918ccc4b27ebd261d8446761e5e02666abe893"],"e9017cf144952056066919f1ebc7897ff9bd71b1":["54ca69905c5d9d1529286f06ab1d12c68f6c13cb","61c45e99cf6676da48f19d7511c73712ad39402b"],"3a7809d1d753b67f48b1a706e17034bf8b624ea3":["e9017cf144952056066919f1ebc7897ff9bd71b1","182384b20c064aa16998ddebe9f36e649279c5a6"],"9fc47cb7b4346802411bb432f501ed0673d7119e":["182384b20c064aa16998ddebe9f36e649279c5a6"],"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c":["2b0085a9ec29ebc27be992a3712f4bd5d65d2106"],"415bbbe7da8065dd3c477bdc3c703c6425622998":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"8381eb1cd44d2e0defb52130de3295a576ac1e7b":["4346940138bc1085f62b4535467e6724d604bc50","e511b092029d56e0d4e30204fba8509c1c2647b6"],"a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d":["b68df8b95f3ea758a8dc21cb20a50a01db973e8e","2c007e7c4cf8c55bc2a5884e315123afaaeec87f"],"575e66bd4b2349209027f6801184da7fc3cba13f":["83788ad129a5154d5c6562c4e8ce3db48793aada"],"729cb470f975115d4c60517b2cb7c42e37a7a2e1":["63a9344cff6a72bc4c1ef080c69e10ad0635b811"],"8582f07e9350eaeb33bf6c4617b8c9895d99c839":["575e66bd4b2349209027f6801184da7fc3cba13f"],"b68df8b95f3ea758a8dc21cb20a50a01db973e8e":["7a3554ff15950ad0e3bcbb4e4e2ddb45b0b0f27e"],"17e1bfbfa5a260860e3f12522fca45ec1240752f":["417142ff08fda9cf0b72d5133e63097a166c6458"],"bd0ef6574805f3cb9880e0983b7548a6aa933508":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"54ca69905c5d9d1529286f06ab1d12c68f6c13cb":["de548de3ce5405595899f548152d4b93ac9eb9cc"],"598b5d23aa7c9732bf473c21a9cd309c44599394":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","415bbbe7da8065dd3c477bdc3c703c6425622998"],"63a9344cff6a72bc4c1ef080c69e10ad0635b811":["415bbbe7da8065dd3c477bdc3c703c6425622998"],"fcc7eba0b32cbc7cc5b8fd388032bb833fa07786":["8bca25eefa1f2205e2b0ef713701dc3a0fecd702"],"7b8f0dc1dfedc7fda86aefc0cdabde0efae2d1dc":["6c94d2661bc1c14426980ec7882e951fdcff08d0"],"08970e5b8411182a29412c177eff67ec1110095b":["1d028314cced5858683a1bb4741423d0f934257b"],"8bca25eefa1f2205e2b0ef713701dc3a0fecd702":["76b65cf789129cacd84e977b8f1538aec29e0281","cc5ee54a993d26579e3fe1f8f2a696b46b61c48f"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["659d7ea4e085dbd15c54c80811439e4bb21a74fb","6c94d2661bc1c14426980ec7882e951fdcff08d0"],"1d028314cced5858683a1bb4741423d0f934257b":["e99829242bceda4cf974ec0eb5d82d713615b3da","a7e4907084808af8fdb14b9809e6dceaccf6867b"],"e511b092029d56e0d4e30204fba8509c1c2647b6":["4346940138bc1085f62b4535467e6724d604bc50"],"0d22ac6a4146774c1bc8400160fc0b6150294e92":["b68df8b95f3ea758a8dc21cb20a50a01db973e8e","2c007e7c4cf8c55bc2a5884e315123afaaeec87f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"17e5da53e4e5bd659e22add9bba1cfa222e7e30d":["8bca25eefa1f2205e2b0ef713701dc3a0fecd702","fcc7eba0b32cbc7cc5b8fd388032bb833fa07786"],"3599646b4d4c346cf74d334813488b8b337b5bf5":["2c007e7c4cf8c55bc2a5884e315123afaaeec87f","e99829242bceda4cf974ec0eb5d82d713615b3da"],"83788ad129a5154d5c6562c4e8ce3db48793aada":["17e1bfbfa5a260860e3f12522fca45ec1240752f"],"e99829242bceda4cf974ec0eb5d82d713615b3da":["2c007e7c4cf8c55bc2a5884e315123afaaeec87f"],"a7e4907084808af8fdb14b9809e6dceaccf6867b":["e99829242bceda4cf974ec0eb5d82d713615b3da"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["08970e5b8411182a29412c177eff67ec1110095b"],"c38d3299f414132db022cec9d60b2dafc244a7c3":["8582f07e9350eaeb33bf6c4617b8c9895d99c839"],"61c45e99cf6676da48f19d7511c73712ad39402b":["729cb470f975115d4c60517b2cb7c42e37a7a2e1"],"de548de3ce5405595899f548152d4b93ac9eb9cc":["415bbbe7da8065dd3c477bdc3c703c6425622998"],"320eec6599df6f97f2461a5d1ad49cd93b324a14":["61c45e99cf6676da48f19d7511c73712ad39402b"],"cc5ee54a993d26579e3fe1f8f2a696b46b61c48f":["76b65cf789129cacd84e977b8f1538aec29e0281"],"2b0085a9ec29ebc27be992a3712f4bd5d65d2106":["ecd75942508378ccc92c3a26f71db6cba9f25784"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["4346940138bc1085f62b4535467e6724d604bc50","17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"417142ff08fda9cf0b72d5133e63097a166c6458":["182384b20c064aa16998ddebe9f36e649279c5a6","9fc47cb7b4346802411bb432f501ed0673d7119e"],"659d7ea4e085dbd15c54c80811439e4bb21a74fb":["7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50"],"182384b20c064aa16998ddebe9f36e649279c5a6":["61c45e99cf6676da48f19d7511c73712ad39402b","320eec6599df6f97f2461a5d1ad49cd93b324a14"],"136796946c32863f11b97ebec6b4091cdfe3a20b":["02e175abd2c4c1611c5a9647486ae8ba249a94c1"],"02e175abd2c4c1611c5a9647486ae8ba249a94c1":["8381eb1cd44d2e0defb52130de3295a576ac1e7b"],"2c007e7c4cf8c55bc2a5884e315123afaaeec87f":["b68df8b95f3ea758a8dc21cb20a50a01db973e8e"],"ecd75942508378ccc92c3a26f71db6cba9f25784":["7b8f0dc1dfedc7fda86aefc0cdabde0efae2d1dc"],"23ec6d2969d61cadbfd0a5452e9be1f9999e8aa1":["c38d3299f414132db022cec9d60b2dafc244a7c3"],"4c58bab35e821e15dc6b8669d2f15c2e3cc6d9ce":["136796946c32863f11b97ebec6b4091cdfe3a20b"],"3b013574eedcdbac35dc7e35b0ee616ffc38895d":["4c58bab35e821e15dc6b8669d2f15c2e3cc6d9ce","8bca25eefa1f2205e2b0ef713701dc3a0fecd702"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["23ec6d2969d61cadbfd0a5452e9be1f9999e8aa1"],"76b65cf789129cacd84e977b8f1538aec29e0281":["4c58bab35e821e15dc6b8669d2f15c2e3cc6d9ce"]},"commit2Childs":{"29918ccc4b27ebd261d8446761e5e02666abe893":["7a3554ff15950ad0e3bcbb4e4e2ddb45b0b0f27e"],"6c94d2661bc1c14426980ec7882e951fdcff08d0":["7b8f0dc1dfedc7fda86aefc0cdabde0efae2d1dc","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae"],"4346940138bc1085f62b4535467e6724d604bc50":["8381eb1cd44d2e0defb52130de3295a576ac1e7b","e511b092029d56e0d4e30204fba8509c1c2647b6","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50":["659d7ea4e085dbd15c54c80811439e4bb21a74fb"],"7a3554ff15950ad0e3bcbb4e4e2ddb45b0b0f27e":["b68df8b95f3ea758a8dc21cb20a50a01db973e8e"],"e9017cf144952056066919f1ebc7897ff9bd71b1":["3a7809d1d753b67f48b1a706e17034bf8b624ea3"],"3a7809d1d753b67f48b1a706e17034bf8b624ea3":[],"9fc47cb7b4346802411bb432f501ed0673d7119e":["417142ff08fda9cf0b72d5133e63097a166c6458"],"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c":["4346940138bc1085f62b4535467e6724d604bc50"],"415bbbe7da8065dd3c477bdc3c703c6425622998":["598b5d23aa7c9732bf473c21a9cd309c44599394","63a9344cff6a72bc4c1ef080c69e10ad0635b811","de548de3ce5405595899f548152d4b93ac9eb9cc"],"8381eb1cd44d2e0defb52130de3295a576ac1e7b":["02e175abd2c4c1611c5a9647486ae8ba249a94c1"],"a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d":[],"575e66bd4b2349209027f6801184da7fc3cba13f":["8582f07e9350eaeb33bf6c4617b8c9895d99c839"],"729cb470f975115d4c60517b2cb7c42e37a7a2e1":["61c45e99cf6676da48f19d7511c73712ad39402b"],"8582f07e9350eaeb33bf6c4617b8c9895d99c839":["c38d3299f414132db022cec9d60b2dafc244a7c3"],"b68df8b95f3ea758a8dc21cb20a50a01db973e8e":["a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d","0d22ac6a4146774c1bc8400160fc0b6150294e92","2c007e7c4cf8c55bc2a5884e315123afaaeec87f"],"17e1bfbfa5a260860e3f12522fca45ec1240752f":["83788ad129a5154d5c6562c4e8ce3db48793aada"],"bd0ef6574805f3cb9880e0983b7548a6aa933508":["29918ccc4b27ebd261d8446761e5e02666abe893"],"54ca69905c5d9d1529286f06ab1d12c68f6c13cb":["e9017cf144952056066919f1ebc7897ff9bd71b1"],"598b5d23aa7c9732bf473c21a9cd309c44599394":[],"63a9344cff6a72bc4c1ef080c69e10ad0635b811":["729cb470f975115d4c60517b2cb7c42e37a7a2e1"],"fcc7eba0b32cbc7cc5b8fd388032bb833fa07786":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"7b8f0dc1dfedc7fda86aefc0cdabde0efae2d1dc":["ecd75942508378ccc92c3a26f71db6cba9f25784"],"08970e5b8411182a29412c177eff67ec1110095b":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"8bca25eefa1f2205e2b0ef713701dc3a0fecd702":["fcc7eba0b32cbc7cc5b8fd388032bb833fa07786","17e5da53e4e5bd659e22add9bba1cfa222e7e30d","3b013574eedcdbac35dc7e35b0ee616ffc38895d"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":[],"e511b092029d56e0d4e30204fba8509c1c2647b6":["8381eb1cd44d2e0defb52130de3295a576ac1e7b"],"1d028314cced5858683a1bb4741423d0f934257b":["08970e5b8411182a29412c177eff67ec1110095b"],"0d22ac6a4146774c1bc8400160fc0b6150294e92":[],"17e5da53e4e5bd659e22add9bba1cfa222e7e30d":["415bbbe7da8065dd3c477bdc3c703c6425622998","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["bd0ef6574805f3cb9880e0983b7548a6aa933508"],"3599646b4d4c346cf74d334813488b8b337b5bf5":[],"83788ad129a5154d5c6562c4e8ce3db48793aada":["575e66bd4b2349209027f6801184da7fc3cba13f"],"e99829242bceda4cf974ec0eb5d82d713615b3da":["1d028314cced5858683a1bb4741423d0f934257b","3599646b4d4c346cf74d334813488b8b337b5bf5","a7e4907084808af8fdb14b9809e6dceaccf6867b"],"a7e4907084808af8fdb14b9809e6dceaccf6867b":["1d028314cced5858683a1bb4741423d0f934257b"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50"],"c38d3299f414132db022cec9d60b2dafc244a7c3":["23ec6d2969d61cadbfd0a5452e9be1f9999e8aa1"],"61c45e99cf6676da48f19d7511c73712ad39402b":["e9017cf144952056066919f1ebc7897ff9bd71b1","320eec6599df6f97f2461a5d1ad49cd93b324a14","182384b20c064aa16998ddebe9f36e649279c5a6"],"de548de3ce5405595899f548152d4b93ac9eb9cc":["54ca69905c5d9d1529286f06ab1d12c68f6c13cb"],"320eec6599df6f97f2461a5d1ad49cd93b324a14":["182384b20c064aa16998ddebe9f36e649279c5a6"],"cc5ee54a993d26579e3fe1f8f2a696b46b61c48f":["8bca25eefa1f2205e2b0ef713701dc3a0fecd702"],"2b0085a9ec29ebc27be992a3712f4bd5d65d2106":["6654c5f3ec2e4a84ef867c82d4eec872c2372c8c"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["598b5d23aa7c9732bf473c21a9cd309c44599394"],"417142ff08fda9cf0b72d5133e63097a166c6458":["17e1bfbfa5a260860e3f12522fca45ec1240752f"],"659d7ea4e085dbd15c54c80811439e4bb21a74fb":["6c94d2661bc1c14426980ec7882e951fdcff08d0","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae"],"182384b20c064aa16998ddebe9f36e649279c5a6":["3a7809d1d753b67f48b1a706e17034bf8b624ea3","9fc47cb7b4346802411bb432f501ed0673d7119e","417142ff08fda9cf0b72d5133e63097a166c6458"],"136796946c32863f11b97ebec6b4091cdfe3a20b":["4c58bab35e821e15dc6b8669d2f15c2e3cc6d9ce"],"2c007e7c4cf8c55bc2a5884e315123afaaeec87f":["a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d","0d22ac6a4146774c1bc8400160fc0b6150294e92","3599646b4d4c346cf74d334813488b8b337b5bf5","e99829242bceda4cf974ec0eb5d82d713615b3da"],"02e175abd2c4c1611c5a9647486ae8ba249a94c1":["136796946c32863f11b97ebec6b4091cdfe3a20b"],"ecd75942508378ccc92c3a26f71db6cba9f25784":["2b0085a9ec29ebc27be992a3712f4bd5d65d2106"],"23ec6d2969d61cadbfd0a5452e9be1f9999e8aa1":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"4c58bab35e821e15dc6b8669d2f15c2e3cc6d9ce":["3b013574eedcdbac35dc7e35b0ee616ffc38895d","76b65cf789129cacd84e977b8f1538aec29e0281"],"3b013574eedcdbac35dc7e35b0ee616ffc38895d":[],"76b65cf789129cacd84e977b8f1538aec29e0281":["8bca25eefa1f2205e2b0ef713701dc3a0fecd702","cc5ee54a993d26579e3fe1f8f2a696b46b61c48f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["3a7809d1d753b67f48b1a706e17034bf8b624ea3","a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d","598b5d23aa7c9732bf473c21a9cd309c44599394","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","0d22ac6a4146774c1bc8400160fc0b6150294e92","3599646b4d4c346cf74d334813488b8b337b5bf5","3b013574eedcdbac35dc7e35b0ee616ffc38895d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}