{"path":"solr/core/src/test/org/apache/solr/store/blockcache/BlockCacheTest#testBlockCache().mjava","commits":[{"id":"849494cf2f3a96af5c8c84995108ddd8456fcd04","date":1372277913,"type":0,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/store/blockcache/BlockCacheTest#testBlockCache().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testBlockCache() {\n    int blocksInTest = 2000000;\n    int blockSize = 1024;\n    \n    int slabSize = blockSize * 4096;\n    long totalMemory = 2 * slabSize;\n    \n    BlockCache blockCache = new BlockCache(new Metrics(new Configuration()), true,totalMemory,slabSize,blockSize);\n    byte[] buffer = new byte[1024];\n    Random random = random();\n    byte[] newData = new byte[blockSize];\n    AtomicLong hitsInCache = new AtomicLong();\n    AtomicLong missesInCache = new AtomicLong();\n    long storeTime = 0;\n    long fetchTime = 0;\n    int passes = 10000;\n\n    BlockCacheKey blockCacheKey = new BlockCacheKey();\n\n    for (int j = 0; j < passes; j++) {\n      long block = random.nextInt(blocksInTest);\n      int file = 0;\n      blockCacheKey.setBlock(block);\n      blockCacheKey.setFile(file);\n\n      if (blockCache.fetch(blockCacheKey, buffer)) {\n        hitsInCache.incrementAndGet();\n      } else {\n        missesInCache.incrementAndGet();\n      }\n\n      byte[] testData = testData(random, blockSize, newData);\n      long t1 = System.nanoTime();\n      blockCache.store(blockCacheKey, 0, testData, 0, blockSize);\n      storeTime += (System.nanoTime() - t1);\n\n      long t3 = System.nanoTime();\n      if (blockCache.fetch(blockCacheKey, buffer)) {\n        fetchTime += (System.nanoTime() - t3);\n        assertTrue(Arrays.equals(testData, buffer));\n      }\n    }\n    System.out.println(\"Cache Hits    = \" + hitsInCache.get());\n    System.out.println(\"Cache Misses  = \" + missesInCache.get());\n    System.out.println(\"Store         = \" + (storeTime / (double) passes) / 1000000.0);\n    System.out.println(\"Fetch         = \" + (fetchTime / (double) passes) / 1000000.0);\n    System.out.println(\"# of Elements = \" + blockCache.getSize());\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["26bd56bd7f06194390617d646d6b9a24a7a472dd"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"37a0f60745e53927c4c876cfe5b5a58170f0646c","date":1373994005,"type":0,"author":"Han Jiang","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/store/blockcache/BlockCacheTest#testBlockCache().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testBlockCache() {\n    int blocksInTest = 2000000;\n    int blockSize = 1024;\n    \n    int slabSize = blockSize * 4096;\n    long totalMemory = 2 * slabSize;\n    \n    BlockCache blockCache = new BlockCache(new Metrics(new Configuration()), true,totalMemory,slabSize,blockSize);\n    byte[] buffer = new byte[1024];\n    Random random = random();\n    byte[] newData = new byte[blockSize];\n    AtomicLong hitsInCache = new AtomicLong();\n    AtomicLong missesInCache = new AtomicLong();\n    long storeTime = 0;\n    long fetchTime = 0;\n    int passes = 10000;\n\n    BlockCacheKey blockCacheKey = new BlockCacheKey();\n\n    for (int j = 0; j < passes; j++) {\n      long block = random.nextInt(blocksInTest);\n      int file = 0;\n      blockCacheKey.setBlock(block);\n      blockCacheKey.setFile(file);\n\n      if (blockCache.fetch(blockCacheKey, buffer)) {\n        hitsInCache.incrementAndGet();\n      } else {\n        missesInCache.incrementAndGet();\n      }\n\n      byte[] testData = testData(random, blockSize, newData);\n      long t1 = System.nanoTime();\n      blockCache.store(blockCacheKey, 0, testData, 0, blockSize);\n      storeTime += (System.nanoTime() - t1);\n\n      long t3 = System.nanoTime();\n      if (blockCache.fetch(blockCacheKey, buffer)) {\n        fetchTime += (System.nanoTime() - t3);\n        assertTrue(Arrays.equals(testData, buffer));\n      }\n    }\n    System.out.println(\"Cache Hits    = \" + hitsInCache.get());\n    System.out.println(\"Cache Misses  = \" + missesInCache.get());\n    System.out.println(\"Store         = \" + (storeTime / (double) passes) / 1000000.0);\n    System.out.println(\"Fetch         = \" + (fetchTime / (double) passes) / 1000000.0);\n    System.out.println(\"# of Elements = \" + blockCache.getSize());\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"19389fe47925b510b2811e2b385a75f7ad19dcca","date":1393903127,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/store/blockcache/BlockCacheTest#testBlockCache().mjava","pathOld":"solr/core/src/test/org/apache/solr/store/blockcache/BlockCacheTest#testBlockCache().mjava","sourceNew":"  @Test\n  public void testBlockCache() {\n    int blocksInTest = 2000000;\n    int blockSize = 1024;\n    \n    int slabSize = blockSize * 4096;\n    long totalMemory = 2 * slabSize;\n    \n    BlockCache blockCache = new BlockCache(new Metrics(new Configuration()), true,totalMemory,slabSize,blockSize);\n    byte[] buffer = new byte[1024];\n    Random random = random();\n    byte[] newData = new byte[blockSize];\n    AtomicLong hitsInCache = new AtomicLong();\n    AtomicLong missesInCache = new AtomicLong();\n    long storeTime = 0;\n    long fetchTime = 0;\n    int passes = 10000;\n\n    BlockCacheKey blockCacheKey = new BlockCacheKey();\n\n    for (int j = 0; j < passes; j++) {\n      long block = random.nextInt(blocksInTest);\n      int file = 0;\n      blockCacheKey.setBlock(block);\n      blockCacheKey.setFile(file);\n      blockCacheKey.setPath(\"/\");\n\n      if (blockCache.fetch(blockCacheKey, buffer)) {\n        hitsInCache.incrementAndGet();\n      } else {\n        missesInCache.incrementAndGet();\n      }\n\n      byte[] testData = testData(random, blockSize, newData);\n      long t1 = System.nanoTime();\n      blockCache.store(blockCacheKey, 0, testData, 0, blockSize);\n      storeTime += (System.nanoTime() - t1);\n\n      long t3 = System.nanoTime();\n      if (blockCache.fetch(blockCacheKey, buffer)) {\n        fetchTime += (System.nanoTime() - t3);\n        assertTrue(Arrays.equals(testData, buffer));\n      }\n    }\n    System.out.println(\"Cache Hits    = \" + hitsInCache.get());\n    System.out.println(\"Cache Misses  = \" + missesInCache.get());\n    System.out.println(\"Store         = \" + (storeTime / (double) passes) / 1000000.0);\n    System.out.println(\"Fetch         = \" + (fetchTime / (double) passes) / 1000000.0);\n    System.out.println(\"# of Elements = \" + blockCache.getSize());\n  }\n\n","sourceOld":"  @Test\n  public void testBlockCache() {\n    int blocksInTest = 2000000;\n    int blockSize = 1024;\n    \n    int slabSize = blockSize * 4096;\n    long totalMemory = 2 * slabSize;\n    \n    BlockCache blockCache = new BlockCache(new Metrics(new Configuration()), true,totalMemory,slabSize,blockSize);\n    byte[] buffer = new byte[1024];\n    Random random = random();\n    byte[] newData = new byte[blockSize];\n    AtomicLong hitsInCache = new AtomicLong();\n    AtomicLong missesInCache = new AtomicLong();\n    long storeTime = 0;\n    long fetchTime = 0;\n    int passes = 10000;\n\n    BlockCacheKey blockCacheKey = new BlockCacheKey();\n\n    for (int j = 0; j < passes; j++) {\n      long block = random.nextInt(blocksInTest);\n      int file = 0;\n      blockCacheKey.setBlock(block);\n      blockCacheKey.setFile(file);\n\n      if (blockCache.fetch(blockCacheKey, buffer)) {\n        hitsInCache.incrementAndGet();\n      } else {\n        missesInCache.incrementAndGet();\n      }\n\n      byte[] testData = testData(random, blockSize, newData);\n      long t1 = System.nanoTime();\n      blockCache.store(blockCacheKey, 0, testData, 0, blockSize);\n      storeTime += (System.nanoTime() - t1);\n\n      long t3 = System.nanoTime();\n      if (blockCache.fetch(blockCacheKey, buffer)) {\n        fetchTime += (System.nanoTime() - t3);\n        assertTrue(Arrays.equals(testData, buffer));\n      }\n    }\n    System.out.println(\"Cache Hits    = \" + hitsInCache.get());\n    System.out.println(\"Cache Misses  = \" + missesInCache.get());\n    System.out.println(\"Store         = \" + (storeTime / (double) passes) / 1000000.0);\n    System.out.println(\"Fetch         = \" + (fetchTime / (double) passes) / 1000000.0);\n    System.out.println(\"# of Elements = \" + blockCache.getSize());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"96ea64d994d340044e0d57aeb6a5871539d10ca5","date":1394225445,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/store/blockcache/BlockCacheTest#testBlockCache().mjava","pathOld":"solr/core/src/test/org/apache/solr/store/blockcache/BlockCacheTest#testBlockCache().mjava","sourceNew":"  @Test\n  public void testBlockCache() {\n    int blocksInTest = 2000000;\n    int blockSize = 1024;\n    \n    int slabSize = blockSize * 4096;\n    long totalMemory = 2 * slabSize;\n    \n    BlockCache blockCache = new BlockCache(new Metrics(new Configuration()), true,totalMemory,slabSize,blockSize);\n    byte[] buffer = new byte[1024];\n    Random random = random();\n    byte[] newData = new byte[blockSize];\n    AtomicLong hitsInCache = new AtomicLong();\n    AtomicLong missesInCache = new AtomicLong();\n    long storeTime = 0;\n    long fetchTime = 0;\n    int passes = 10000;\n\n    BlockCacheKey blockCacheKey = new BlockCacheKey();\n\n    for (int j = 0; j < passes; j++) {\n      long block = random.nextInt(blocksInTest);\n      int file = 0;\n      blockCacheKey.setBlock(block);\n      blockCacheKey.setFile(file);\n      blockCacheKey.setPath(\"/\");\n\n      if (blockCache.fetch(blockCacheKey, buffer)) {\n        hitsInCache.incrementAndGet();\n      } else {\n        missesInCache.incrementAndGet();\n      }\n\n      byte[] testData = testData(random, blockSize, newData);\n      long t1 = System.nanoTime();\n      blockCache.store(blockCacheKey, 0, testData, 0, blockSize);\n      storeTime += (System.nanoTime() - t1);\n\n      long t3 = System.nanoTime();\n      if (blockCache.fetch(blockCacheKey, buffer)) {\n        fetchTime += (System.nanoTime() - t3);\n        assertTrue(Arrays.equals(testData, buffer));\n      }\n    }\n    System.out.println(\"Cache Hits    = \" + hitsInCache.get());\n    System.out.println(\"Cache Misses  = \" + missesInCache.get());\n    System.out.println(\"Store         = \" + (storeTime / (double) passes) / 1000000.0);\n    System.out.println(\"Fetch         = \" + (fetchTime / (double) passes) / 1000000.0);\n    System.out.println(\"# of Elements = \" + blockCache.getSize());\n  }\n\n","sourceOld":"  @Test\n  public void testBlockCache() {\n    int blocksInTest = 2000000;\n    int blockSize = 1024;\n    \n    int slabSize = blockSize * 4096;\n    long totalMemory = 2 * slabSize;\n    \n    BlockCache blockCache = new BlockCache(new Metrics(new Configuration()), true,totalMemory,slabSize,blockSize);\n    byte[] buffer = new byte[1024];\n    Random random = random();\n    byte[] newData = new byte[blockSize];\n    AtomicLong hitsInCache = new AtomicLong();\n    AtomicLong missesInCache = new AtomicLong();\n    long storeTime = 0;\n    long fetchTime = 0;\n    int passes = 10000;\n\n    BlockCacheKey blockCacheKey = new BlockCacheKey();\n\n    for (int j = 0; j < passes; j++) {\n      long block = random.nextInt(blocksInTest);\n      int file = 0;\n      blockCacheKey.setBlock(block);\n      blockCacheKey.setFile(file);\n\n      if (blockCache.fetch(blockCacheKey, buffer)) {\n        hitsInCache.incrementAndGet();\n      } else {\n        missesInCache.incrementAndGet();\n      }\n\n      byte[] testData = testData(random, blockSize, newData);\n      long t1 = System.nanoTime();\n      blockCache.store(blockCacheKey, 0, testData, 0, blockSize);\n      storeTime += (System.nanoTime() - t1);\n\n      long t3 = System.nanoTime();\n      if (blockCache.fetch(blockCacheKey, buffer)) {\n        fetchTime += (System.nanoTime() - t3);\n        assertTrue(Arrays.equals(testData, buffer));\n      }\n    }\n    System.out.println(\"Cache Hits    = \" + hitsInCache.get());\n    System.out.println(\"Cache Misses  = \" + missesInCache.get());\n    System.out.println(\"Store         = \" + (storeTime / (double) passes) / 1000000.0);\n    System.out.println(\"Fetch         = \" + (fetchTime / (double) passes) / 1000000.0);\n    System.out.println(\"# of Elements = \" + blockCache.getSize());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"26bd56bd7f06194390617d646d6b9a24a7a472dd","date":1420576157,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/store/blockcache/BlockCacheTest#testBlockCache().mjava","pathOld":"solr/core/src/test/org/apache/solr/store/blockcache/BlockCacheTest#testBlockCache().mjava","sourceNew":"  @Test\n  public void testBlockCache() {\n    int blocksInTest = 2000000;\n    int blockSize = 1024;\n    \n    int slabSize = blockSize * 4096;\n    long totalMemory = 2 * slabSize;\n    \n    BlockCache blockCache = new BlockCache(new Metrics(), true, totalMemory, slabSize, blockSize);\n    byte[] buffer = new byte[1024];\n    Random random = random();\n    byte[] newData = new byte[blockSize];\n    AtomicLong hitsInCache = new AtomicLong();\n    AtomicLong missesInCache = new AtomicLong();\n    long storeTime = 0;\n    long fetchTime = 0;\n    int passes = 10000;\n\n    BlockCacheKey blockCacheKey = new BlockCacheKey();\n\n    for (int j = 0; j < passes; j++) {\n      long block = random.nextInt(blocksInTest);\n      int file = 0;\n      blockCacheKey.setBlock(block);\n      blockCacheKey.setFile(file);\n      blockCacheKey.setPath(\"/\");\n\n      if (blockCache.fetch(blockCacheKey, buffer)) {\n        hitsInCache.incrementAndGet();\n      } else {\n        missesInCache.incrementAndGet();\n      }\n\n      byte[] testData = testData(random, blockSize, newData);\n      long t1 = System.nanoTime();\n      blockCache.store(blockCacheKey, 0, testData, 0, blockSize);\n      storeTime += (System.nanoTime() - t1);\n\n      long t3 = System.nanoTime();\n      if (blockCache.fetch(blockCacheKey, buffer)) {\n        fetchTime += (System.nanoTime() - t3);\n        assertTrue(Arrays.equals(testData, buffer));\n      }\n    }\n    System.out.println(\"Cache Hits    = \" + hitsInCache.get());\n    System.out.println(\"Cache Misses  = \" + missesInCache.get());\n    System.out.println(\"Store         = \" + (storeTime / (double) passes) / 1000000.0);\n    System.out.println(\"Fetch         = \" + (fetchTime / (double) passes) / 1000000.0);\n    System.out.println(\"# of Elements = \" + blockCache.getSize());\n  }\n\n","sourceOld":"  @Test\n  public void testBlockCache() {\n    int blocksInTest = 2000000;\n    int blockSize = 1024;\n    \n    int slabSize = blockSize * 4096;\n    long totalMemory = 2 * slabSize;\n    \n    BlockCache blockCache = new BlockCache(new Metrics(new Configuration()), true,totalMemory,slabSize,blockSize);\n    byte[] buffer = new byte[1024];\n    Random random = random();\n    byte[] newData = new byte[blockSize];\n    AtomicLong hitsInCache = new AtomicLong();\n    AtomicLong missesInCache = new AtomicLong();\n    long storeTime = 0;\n    long fetchTime = 0;\n    int passes = 10000;\n\n    BlockCacheKey blockCacheKey = new BlockCacheKey();\n\n    for (int j = 0; j < passes; j++) {\n      long block = random.nextInt(blocksInTest);\n      int file = 0;\n      blockCacheKey.setBlock(block);\n      blockCacheKey.setFile(file);\n      blockCacheKey.setPath(\"/\");\n\n      if (blockCache.fetch(blockCacheKey, buffer)) {\n        hitsInCache.incrementAndGet();\n      } else {\n        missesInCache.incrementAndGet();\n      }\n\n      byte[] testData = testData(random, blockSize, newData);\n      long t1 = System.nanoTime();\n      blockCache.store(blockCacheKey, 0, testData, 0, blockSize);\n      storeTime += (System.nanoTime() - t1);\n\n      long t3 = System.nanoTime();\n      if (blockCache.fetch(blockCacheKey, buffer)) {\n        fetchTime += (System.nanoTime() - t3);\n        assertTrue(Arrays.equals(testData, buffer));\n      }\n    }\n    System.out.println(\"Cache Hits    = \" + hitsInCache.get());\n    System.out.println(\"Cache Misses  = \" + missesInCache.get());\n    System.out.println(\"Store         = \" + (storeTime / (double) passes) / 1000000.0);\n    System.out.println(\"Fetch         = \" + (fetchTime / (double) passes) / 1000000.0);\n    System.out.println(\"# of Elements = \" + blockCache.getSize());\n  }\n\n","bugFix":["849494cf2f3a96af5c8c84995108ddd8456fcd04"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"46386805f467fa40cb9d5a3cab791713306548c2","date":1487170610,"type":3,"author":"yonik","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/store/blockcache/BlockCacheTest#testBlockCache().mjava","pathOld":"solr/core/src/test/org/apache/solr/store/blockcache/BlockCacheTest#testBlockCache().mjava","sourceNew":"  @Test\n  public void testBlockCache() {\n    int blocksInTest = 2000000;\n    int blockSize = 1024;\n    \n    int slabSize = blockSize * 4096;\n    long totalMemory = 2 * slabSize;\n    \n    BlockCache blockCache = new BlockCache(new Metrics(), true, totalMemory, slabSize, blockSize);\n    byte[] buffer = new byte[1024];\n    Random random = random();\n    byte[] newData = new byte[blockSize];\n    AtomicLong hitsInCache = new AtomicLong();\n    AtomicLong missesInCache = new AtomicLong();\n    long storeTime = 0;\n    long fetchTime = 0;\n    int passes = 10000;\n\n    BlockCacheKey blockCacheKey = new BlockCacheKey();\n\n    for (int j = 0; j < passes; j++) {\n      long block = random.nextInt(blocksInTest);\n      int file = 0;\n      blockCacheKey.setBlock(block);\n      blockCacheKey.setFile(file);\n      blockCacheKey.setPath(\"/\");\n\n      if (blockCache.fetch(blockCacheKey, buffer)) {\n        hitsInCache.incrementAndGet();\n      } else {\n        missesInCache.incrementAndGet();\n      }\n\n      byte[] testData = testData(random, blockSize, newData);\n      long t1 = System.nanoTime();\n      boolean success = blockCache.store(blockCacheKey, 0, testData, 0, blockSize);\n      storeTime += (System.nanoTime() - t1);\n      if (!success) continue;  // for now, updating existing blocks is not supported... see SOLR-10121\n\n      long t3 = System.nanoTime();\n      if (blockCache.fetch(blockCacheKey, buffer)) {\n        fetchTime += (System.nanoTime() - t3);\n        assertTrue(Arrays.equals(testData, buffer));\n      }\n    }\n    System.out.println(\"Cache Hits    = \" + hitsInCache.get());\n    System.out.println(\"Cache Misses  = \" + missesInCache.get());\n    System.out.println(\"Store         = \" + (storeTime / (double) passes) / 1000000.0);\n    System.out.println(\"Fetch         = \" + (fetchTime / (double) passes) / 1000000.0);\n    System.out.println(\"# of Elements = \" + blockCache.getSize());\n  }\n\n","sourceOld":"  @Test\n  public void testBlockCache() {\n    int blocksInTest = 2000000;\n    int blockSize = 1024;\n    \n    int slabSize = blockSize * 4096;\n    long totalMemory = 2 * slabSize;\n    \n    BlockCache blockCache = new BlockCache(new Metrics(), true, totalMemory, slabSize, blockSize);\n    byte[] buffer = new byte[1024];\n    Random random = random();\n    byte[] newData = new byte[blockSize];\n    AtomicLong hitsInCache = new AtomicLong();\n    AtomicLong missesInCache = new AtomicLong();\n    long storeTime = 0;\n    long fetchTime = 0;\n    int passes = 10000;\n\n    BlockCacheKey blockCacheKey = new BlockCacheKey();\n\n    for (int j = 0; j < passes; j++) {\n      long block = random.nextInt(blocksInTest);\n      int file = 0;\n      blockCacheKey.setBlock(block);\n      blockCacheKey.setFile(file);\n      blockCacheKey.setPath(\"/\");\n\n      if (blockCache.fetch(blockCacheKey, buffer)) {\n        hitsInCache.incrementAndGet();\n      } else {\n        missesInCache.incrementAndGet();\n      }\n\n      byte[] testData = testData(random, blockSize, newData);\n      long t1 = System.nanoTime();\n      blockCache.store(blockCacheKey, 0, testData, 0, blockSize);\n      storeTime += (System.nanoTime() - t1);\n\n      long t3 = System.nanoTime();\n      if (blockCache.fetch(blockCacheKey, buffer)) {\n        fetchTime += (System.nanoTime() - t3);\n        assertTrue(Arrays.equals(testData, buffer));\n      }\n    }\n    System.out.println(\"Cache Hits    = \" + hitsInCache.get());\n    System.out.println(\"Cache Misses  = \" + missesInCache.get());\n    System.out.println(\"Store         = \" + (storeTime / (double) passes) / 1000000.0);\n    System.out.println(\"Fetch         = \" + (fetchTime / (double) passes) / 1000000.0);\n    System.out.println(\"# of Elements = \" + blockCache.getSize());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"87f0484c38f986062889ed50f3bf3bd462848c26","date":1570108628,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/store/blockcache/BlockCacheTest#testBlockCache().mjava","pathOld":"solr/core/src/test/org/apache/solr/store/blockcache/BlockCacheTest#testBlockCache().mjava","sourceNew":"  @Test\n  public void testBlockCache() {\n    int blocksInTest = 2000000;\n    int blockSize = 1024;\n\n    int slabSize = blockSize * 4096;\n    long totalMemory = 2 * slabSize;\n\n    BlockCache blockCache = new BlockCache(new Metrics(), true, totalMemory, slabSize, blockSize);\n    byte[] buffer = new byte[1024];\n    Random random = random();\n    byte[] newData = new byte[blockSize];\n    AtomicLong hitsInCache = new AtomicLong();\n    AtomicLong missesInCache = new AtomicLong();\n    long storeTime = 0;\n    long fetchTime = 0;\n    int passes = 10000;\n\n    BlockCacheKey blockCacheKey = new BlockCacheKey();\n\n    for (int j = 0; j < passes; j++) {\n      long block = random.nextInt(blocksInTest);\n      int file = 0;\n      blockCacheKey.setBlock(block);\n      blockCacheKey.setFile(file);\n      blockCacheKey.setPath(\"/\");\n\n      if (blockCache.fetch(blockCacheKey, buffer)) {\n        hitsInCache.incrementAndGet();\n      } else {\n        missesInCache.incrementAndGet();\n      }\n\n      byte[] testData = testData(random, blockSize, newData);\n      long t1 = System.nanoTime();\n      boolean success = blockCache.store(blockCacheKey, 0, testData, 0, blockSize);\n      storeTime += (System.nanoTime() - t1);\n      if (!success) continue;  // for now, updating existing blocks is not supported... see SOLR-10121\n\n      long t3 = System.nanoTime();\n      if (blockCache.fetch(blockCacheKey, buffer)) {\n        fetchTime += (System.nanoTime() - t3);\n        assertTrue(\"buffer content differs\", Arrays.equals(testData, buffer));\n      }\n    }\n    System.out.println(\"Cache Hits    = \" + hitsInCache.get());\n    System.out.println(\"Cache Misses  = \" + missesInCache.get());\n    System.out.println(\"Store         = \" + (storeTime / (double) passes) / 1000000.0);\n    System.out.println(\"Fetch         = \" + (fetchTime / (double) passes) / 1000000.0);\n    System.out.println(\"# of Elements = \" + blockCache.getSize());\n  }\n\n","sourceOld":"  @Test\n  public void testBlockCache() {\n    int blocksInTest = 2000000;\n    int blockSize = 1024;\n    \n    int slabSize = blockSize * 4096;\n    long totalMemory = 2 * slabSize;\n    \n    BlockCache blockCache = new BlockCache(new Metrics(), true, totalMemory, slabSize, blockSize);\n    byte[] buffer = new byte[1024];\n    Random random = random();\n    byte[] newData = new byte[blockSize];\n    AtomicLong hitsInCache = new AtomicLong();\n    AtomicLong missesInCache = new AtomicLong();\n    long storeTime = 0;\n    long fetchTime = 0;\n    int passes = 10000;\n\n    BlockCacheKey blockCacheKey = new BlockCacheKey();\n\n    for (int j = 0; j < passes; j++) {\n      long block = random.nextInt(blocksInTest);\n      int file = 0;\n      blockCacheKey.setBlock(block);\n      blockCacheKey.setFile(file);\n      blockCacheKey.setPath(\"/\");\n\n      if (blockCache.fetch(blockCacheKey, buffer)) {\n        hitsInCache.incrementAndGet();\n      } else {\n        missesInCache.incrementAndGet();\n      }\n\n      byte[] testData = testData(random, blockSize, newData);\n      long t1 = System.nanoTime();\n      boolean success = blockCache.store(blockCacheKey, 0, testData, 0, blockSize);\n      storeTime += (System.nanoTime() - t1);\n      if (!success) continue;  // for now, updating existing blocks is not supported... see SOLR-10121\n\n      long t3 = System.nanoTime();\n      if (blockCache.fetch(blockCacheKey, buffer)) {\n        fetchTime += (System.nanoTime() - t3);\n        assertTrue(Arrays.equals(testData, buffer));\n      }\n    }\n    System.out.println(\"Cache Hits    = \" + hitsInCache.get());\n    System.out.println(\"Cache Misses  = \" + missesInCache.get());\n    System.out.println(\"Store         = \" + (storeTime / (double) passes) / 1000000.0);\n    System.out.println(\"Fetch         = \" + (fetchTime / (double) passes) / 1000000.0);\n    System.out.println(\"# of Elements = \" + blockCache.getSize());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b0b597c65628ca9e73913a07e81691f8229bae35","date":1571224353,"type":3,"author":"jimczi","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/store/blockcache/BlockCacheTest#testBlockCache().mjava","pathOld":"solr/core/src/test/org/apache/solr/store/blockcache/BlockCacheTest#testBlockCache().mjava","sourceNew":"  @Test\n  public void testBlockCache() {\n    int blocksInTest = 2000000;\n    int blockSize = 1024;\n\n    int slabSize = blockSize * 4096;\n    long totalMemory = 2 * slabSize;\n\n    BlockCache blockCache = new BlockCache(new Metrics(), true, totalMemory, slabSize, blockSize);\n    byte[] buffer = new byte[1024];\n    Random random = random();\n    byte[] newData = new byte[blockSize];\n    AtomicLong hitsInCache = new AtomicLong();\n    AtomicLong missesInCache = new AtomicLong();\n    long storeTime = 0;\n    long fetchTime = 0;\n    int passes = 10000;\n\n    BlockCacheKey blockCacheKey = new BlockCacheKey();\n\n    for (int j = 0; j < passes; j++) {\n      long block = random.nextInt(blocksInTest);\n      int file = 0;\n      blockCacheKey.setBlock(block);\n      blockCacheKey.setFile(file);\n      blockCacheKey.setPath(\"/\");\n\n      if (blockCache.fetch(blockCacheKey, buffer)) {\n        hitsInCache.incrementAndGet();\n      } else {\n        missesInCache.incrementAndGet();\n      }\n\n      byte[] testData = testData(random, blockSize, newData);\n      long t1 = System.nanoTime();\n      boolean success = blockCache.store(blockCacheKey, 0, testData, 0, blockSize);\n      storeTime += (System.nanoTime() - t1);\n      if (!success) continue;  // for now, updating existing blocks is not supported... see SOLR-10121\n\n      long t3 = System.nanoTime();\n      if (blockCache.fetch(blockCacheKey, buffer)) {\n        fetchTime += (System.nanoTime() - t3);\n        assertTrue(\"buffer content differs\", Arrays.equals(testData, buffer));\n      }\n    }\n    System.out.println(\"Cache Hits    = \" + hitsInCache.get());\n    System.out.println(\"Cache Misses  = \" + missesInCache.get());\n    System.out.println(\"Store         = \" + (storeTime / (double) passes) / 1000000.0);\n    System.out.println(\"Fetch         = \" + (fetchTime / (double) passes) / 1000000.0);\n    System.out.println(\"# of Elements = \" + blockCache.getSize());\n  }\n\n","sourceOld":"  @Test\n  public void testBlockCache() {\n    int blocksInTest = 2000000;\n    int blockSize = 1024;\n    \n    int slabSize = blockSize * 4096;\n    long totalMemory = 2 * slabSize;\n    \n    BlockCache blockCache = new BlockCache(new Metrics(), true, totalMemory, slabSize, blockSize);\n    byte[] buffer = new byte[1024];\n    Random random = random();\n    byte[] newData = new byte[blockSize];\n    AtomicLong hitsInCache = new AtomicLong();\n    AtomicLong missesInCache = new AtomicLong();\n    long storeTime = 0;\n    long fetchTime = 0;\n    int passes = 10000;\n\n    BlockCacheKey blockCacheKey = new BlockCacheKey();\n\n    for (int j = 0; j < passes; j++) {\n      long block = random.nextInt(blocksInTest);\n      int file = 0;\n      blockCacheKey.setBlock(block);\n      blockCacheKey.setFile(file);\n      blockCacheKey.setPath(\"/\");\n\n      if (blockCache.fetch(blockCacheKey, buffer)) {\n        hitsInCache.incrementAndGet();\n      } else {\n        missesInCache.incrementAndGet();\n      }\n\n      byte[] testData = testData(random, blockSize, newData);\n      long t1 = System.nanoTime();\n      boolean success = blockCache.store(blockCacheKey, 0, testData, 0, blockSize);\n      storeTime += (System.nanoTime() - t1);\n      if (!success) continue;  // for now, updating existing blocks is not supported... see SOLR-10121\n\n      long t3 = System.nanoTime();\n      if (blockCache.fetch(blockCacheKey, buffer)) {\n        fetchTime += (System.nanoTime() - t3);\n        assertTrue(Arrays.equals(testData, buffer));\n      }\n    }\n    System.out.println(\"Cache Hits    = \" + hitsInCache.get());\n    System.out.println(\"Cache Misses  = \" + missesInCache.get());\n    System.out.println(\"Store         = \" + (storeTime / (double) passes) / 1000000.0);\n    System.out.println(\"Fetch         = \" + (fetchTime / (double) passes) / 1000000.0);\n    System.out.println(\"# of Elements = \" + blockCache.getSize());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"19389fe47925b510b2811e2b385a75f7ad19dcca":["849494cf2f3a96af5c8c84995108ddd8456fcd04"],"849494cf2f3a96af5c8c84995108ddd8456fcd04":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"96ea64d994d340044e0d57aeb6a5871539d10ca5":["849494cf2f3a96af5c8c84995108ddd8456fcd04","19389fe47925b510b2811e2b385a75f7ad19dcca"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","849494cf2f3a96af5c8c84995108ddd8456fcd04"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"87f0484c38f986062889ed50f3bf3bd462848c26":["46386805f467fa40cb9d5a3cab791713306548c2"],"46386805f467fa40cb9d5a3cab791713306548c2":["26bd56bd7f06194390617d646d6b9a24a7a472dd"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["87f0484c38f986062889ed50f3bf3bd462848c26"],"26bd56bd7f06194390617d646d6b9a24a7a472dd":["19389fe47925b510b2811e2b385a75f7ad19dcca"],"b0b597c65628ca9e73913a07e81691f8229bae35":["46386805f467fa40cb9d5a3cab791713306548c2","87f0484c38f986062889ed50f3bf3bd462848c26"]},"commit2Childs":{"19389fe47925b510b2811e2b385a75f7ad19dcca":["96ea64d994d340044e0d57aeb6a5871539d10ca5","26bd56bd7f06194390617d646d6b9a24a7a472dd"],"849494cf2f3a96af5c8c84995108ddd8456fcd04":["19389fe47925b510b2811e2b385a75f7ad19dcca","96ea64d994d340044e0d57aeb6a5871539d10ca5","37a0f60745e53927c4c876cfe5b5a58170f0646c"],"96ea64d994d340044e0d57aeb6a5871539d10ca5":[],"37a0f60745e53927c4c876cfe5b5a58170f0646c":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["849494cf2f3a96af5c8c84995108ddd8456fcd04","37a0f60745e53927c4c876cfe5b5a58170f0646c"],"87f0484c38f986062889ed50f3bf3bd462848c26":["cd5edd1f2b162a5cfa08efd17851a07373a96817","b0b597c65628ca9e73913a07e81691f8229bae35"],"46386805f467fa40cb9d5a3cab791713306548c2":["87f0484c38f986062889ed50f3bf3bd462848c26","b0b597c65628ca9e73913a07e81691f8229bae35"],"26bd56bd7f06194390617d646d6b9a24a7a472dd":["46386805f467fa40cb9d5a3cab791713306548c2"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"b0b597c65628ca9e73913a07e81691f8229bae35":[]},"heads":["96ea64d994d340044e0d57aeb6a5871539d10ca5","37a0f60745e53927c4c876cfe5b5a58170f0646c","cd5edd1f2b162a5cfa08efd17851a07373a96817","b0b597c65628ca9e73913a07e81691f8229bae35"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}