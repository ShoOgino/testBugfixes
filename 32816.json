{"path":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestLargeCluster#testBasic().mjava","commits":[{"id":"1d4bf9d5308dfef350829c28f2b3b2648df1e9b1","date":1513252583,"type":0,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestLargeCluster#testBasic().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testBasic() throws Exception {\n    SolrClient solrClient = cluster.simGetSolrClient();\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [\" +\n        \"{'name':'compute','class':'\" + ComputePlanAction.class.getName() + \"'},\" +\n        \"{'name':'execute','class':'\" + ExecutePlanAction.class.getName() + \"'},\" +\n        \"{'name':'test','class':'\" + TestTriggerAction.class.getName() + \"'}\" +\n        \"]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'foo',\" +\n        \"'trigger' : 'node_lost_trigger',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED', 'FAILED'],\" +\n        \"'beforeAction' : ['compute', 'execute'],\" +\n        \"'afterAction' : ['compute', 'execute'],\" +\n        \"'class' : '\" + TestTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    cluster.getTimeSource().sleep(5000);\n\n    // pick a few random nodes\n    List<String> nodes = new ArrayList<>();\n    int limit = 75;\n    for (String node : cluster.getClusterStateProvider().getLiveNodes()) {\n      nodes.add(node);\n      if (nodes.size() > limit) {\n        break;\n      }\n    }\n    Collections.shuffle(nodes, random());\n    // create collection on these nodes\n    String collectionName = \"testBasic\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 5, 5, 5, 5);\n    create.setMaxShardsPerNode(1);\n    create.setCreateNodeSet(String.join(\",\", nodes));\n    create.process(solrClient);\n\n    log.info(\"Ready after \" + waitForState(collectionName, 30 * nodes.size(), TimeUnit.SECONDS, clusterShape(5, 15)) + \"ms\");\n\n    int KILL_NODES = 8;\n    // kill off a number of nodes\n    for (int i = 0; i < KILL_NODES; i++) {\n      cluster.simRemoveNode(nodes.get(i), false);\n    }\n    // should fully recover\n    log.info(\"Ready after \" + waitForState(collectionName, 90 * KILL_NODES, TimeUnit.SECONDS, clusterShape(5, 15)) + \"ms\");\n\n    log.info(\"OP COUNTS: \" + cluster.simGetOpCounts());\n    long moveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n\n    // simulate a number of flaky nodes\n    int FLAKY_NODES = 10;\n    int flakyReplicas = 0;\n    for (int cnt = 0; cnt < 10; cnt++) {\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        flakyReplicas += cluster.getSimClusterStateProvider().simGetReplicaInfos(nodes.get(i))\n            .stream().filter(r -> r.getState().equals(Replica.State.ACTIVE)).count();\n        cluster.simRemoveNode(nodes.get(i), false);\n      }\n      cluster.getTimeSource().sleep(TimeUnit.SECONDS.toMillis(waitForSeconds) * 2);\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        final String nodeId = nodes.get(i);\n        cluster.submit(() -> cluster.getSimClusterStateProvider().simRestoreNode(nodeId));\n      }\n    }\n\n    log.info(\"Ready after \" + waitForState(collectionName, 30 * nodes.size(), TimeUnit.SECONDS, clusterShape(5, 15)) + \"ms\");\n    log.info(\"OP COUNTS: \" + cluster.simGetOpCounts());\n    long newMoveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n    log.info(\"==== Flaky replicas: {}. Additional MOVEREPLICA count: {}\", flakyReplicas, (newMoveReplicaOps - moveReplicaOps));\n    // flaky nodes lead to a number of MOVEREPLICA that is non-zero but lower than the number of flaky replicas\n    assertTrue(\"there should be new MOVERPLICA ops\", newMoveReplicaOps - moveReplicaOps > 0);\n    assertTrue(\"there should be less than flakyReplicas=\" + flakyReplicas + \" MOVEREPLICA ops\",\n        newMoveReplicaOps - moveReplicaOps < flakyReplicas);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a4422b331d00607258b0ed3e43934306e67764aa","date":1513943901,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestLargeCluster#testBasic().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestLargeCluster#testBasic().mjava","sourceNew":"  @Test\n  public void testBasic() throws Exception {\n    SolrClient solrClient = cluster.simGetSolrClient();\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [\" +\n        \"{'name':'compute','class':'\" + ComputePlanAction.class.getName() + \"'},\" +\n        \"{'name':'execute','class':'\" + ExecutePlanAction.class.getName() + \"'},\" +\n        \"{'name':'test','class':'\" + TestTriggerAction.class.getName() + \"'}\" +\n        \"]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'foo',\" +\n        \"'trigger' : 'node_lost_trigger',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED', 'FAILED'],\" +\n        \"'beforeAction' : ['compute', 'execute'],\" +\n        \"'afterAction' : ['compute', 'execute'],\" +\n        \"'class' : '\" + TestTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    cluster.getTimeSource().sleep(5000);\n\n    // pick a few random nodes\n    List<String> nodes = new ArrayList<>();\n    int limit = 75;\n    for (String node : cluster.getClusterStateProvider().getLiveNodes()) {\n      nodes.add(node);\n      if (nodes.size() > limit) {\n        break;\n      }\n    }\n    Collections.shuffle(nodes, random());\n    // create collection on these nodes\n    String collectionName = \"testBasic\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 5, 5, 5, 5);\n    create.setMaxShardsPerNode(1);\n    create.setAutoAddReplicas(false);\n    create.setCreateNodeSet(String.join(\",\", nodes));\n    create.process(solrClient);\n\n    log.info(\"Ready after \" + waitForState(collectionName, 30 * nodes.size(), TimeUnit.SECONDS, clusterShape(5, 15)) + \"ms\");\n\n    int KILL_NODES = 8;\n    // kill off a number of nodes\n    for (int i = 0; i < KILL_NODES; i++) {\n      cluster.simRemoveNode(nodes.get(i), false);\n    }\n    // should fully recover\n    log.info(\"Ready after \" + waitForState(collectionName, 90 * KILL_NODES, TimeUnit.SECONDS, clusterShape(5, 15)) + \"ms\");\n\n    log.info(\"OP COUNTS: \" + cluster.simGetOpCounts());\n    long moveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n\n    // simulate a number of flaky nodes\n    int FLAKY_NODES = 10;\n    int flakyReplicas = 0;\n    for (int cnt = 0; cnt < 10; cnt++) {\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        flakyReplicas += cluster.getSimClusterStateProvider().simGetReplicaInfos(nodes.get(i))\n            .stream().filter(r -> r.getState().equals(Replica.State.ACTIVE)).count();\n        cluster.simRemoveNode(nodes.get(i), false);\n      }\n      cluster.getTimeSource().sleep(TimeUnit.SECONDS.toMillis(waitForSeconds) * 2);\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        final String nodeId = nodes.get(i);\n        cluster.submit(() -> cluster.getSimClusterStateProvider().simRestoreNode(nodeId));\n      }\n    }\n\n    log.info(\"Ready after \" + waitForState(collectionName, 30 * nodes.size(), TimeUnit.SECONDS, clusterShape(5, 15)) + \"ms\");\n    long newMoveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n    log.info(\"==== Flaky replicas: {}. Additional MOVEREPLICA count: {}\", flakyReplicas, (newMoveReplicaOps - moveReplicaOps));\n    // flaky nodes lead to a number of MOVEREPLICA that is non-zero but lower than the number of flaky replicas\n    assertTrue(\"there should be new MOVERPLICA ops\", newMoveReplicaOps - moveReplicaOps > 0);\n    assertTrue(\"there should be less than flakyReplicas=\" + flakyReplicas + \" MOVEREPLICA ops\",\n        newMoveReplicaOps - moveReplicaOps < flakyReplicas);\n  }\n\n","sourceOld":"  @Test\n  public void testBasic() throws Exception {\n    SolrClient solrClient = cluster.simGetSolrClient();\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [\" +\n        \"{'name':'compute','class':'\" + ComputePlanAction.class.getName() + \"'},\" +\n        \"{'name':'execute','class':'\" + ExecutePlanAction.class.getName() + \"'},\" +\n        \"{'name':'test','class':'\" + TestTriggerAction.class.getName() + \"'}\" +\n        \"]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'foo',\" +\n        \"'trigger' : 'node_lost_trigger',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED', 'FAILED'],\" +\n        \"'beforeAction' : ['compute', 'execute'],\" +\n        \"'afterAction' : ['compute', 'execute'],\" +\n        \"'class' : '\" + TestTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    cluster.getTimeSource().sleep(5000);\n\n    // pick a few random nodes\n    List<String> nodes = new ArrayList<>();\n    int limit = 75;\n    for (String node : cluster.getClusterStateProvider().getLiveNodes()) {\n      nodes.add(node);\n      if (nodes.size() > limit) {\n        break;\n      }\n    }\n    Collections.shuffle(nodes, random());\n    // create collection on these nodes\n    String collectionName = \"testBasic\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 5, 5, 5, 5);\n    create.setMaxShardsPerNode(1);\n    create.setCreateNodeSet(String.join(\",\", nodes));\n    create.process(solrClient);\n\n    log.info(\"Ready after \" + waitForState(collectionName, 30 * nodes.size(), TimeUnit.SECONDS, clusterShape(5, 15)) + \"ms\");\n\n    int KILL_NODES = 8;\n    // kill off a number of nodes\n    for (int i = 0; i < KILL_NODES; i++) {\n      cluster.simRemoveNode(nodes.get(i), false);\n    }\n    // should fully recover\n    log.info(\"Ready after \" + waitForState(collectionName, 90 * KILL_NODES, TimeUnit.SECONDS, clusterShape(5, 15)) + \"ms\");\n\n    log.info(\"OP COUNTS: \" + cluster.simGetOpCounts());\n    long moveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n\n    // simulate a number of flaky nodes\n    int FLAKY_NODES = 10;\n    int flakyReplicas = 0;\n    for (int cnt = 0; cnt < 10; cnt++) {\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        flakyReplicas += cluster.getSimClusterStateProvider().simGetReplicaInfos(nodes.get(i))\n            .stream().filter(r -> r.getState().equals(Replica.State.ACTIVE)).count();\n        cluster.simRemoveNode(nodes.get(i), false);\n      }\n      cluster.getTimeSource().sleep(TimeUnit.SECONDS.toMillis(waitForSeconds) * 2);\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        final String nodeId = nodes.get(i);\n        cluster.submit(() -> cluster.getSimClusterStateProvider().simRestoreNode(nodeId));\n      }\n    }\n\n    log.info(\"Ready after \" + waitForState(collectionName, 30 * nodes.size(), TimeUnit.SECONDS, clusterShape(5, 15)) + \"ms\");\n    log.info(\"OP COUNTS: \" + cluster.simGetOpCounts());\n    long newMoveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n    log.info(\"==== Flaky replicas: {}. Additional MOVEREPLICA count: {}\", flakyReplicas, (newMoveReplicaOps - moveReplicaOps));\n    // flaky nodes lead to a number of MOVEREPLICA that is non-zero but lower than the number of flaky replicas\n    assertTrue(\"there should be new MOVERPLICA ops\", newMoveReplicaOps - moveReplicaOps > 0);\n    assertTrue(\"there should be less than flakyReplicas=\" + flakyReplicas + \" MOVEREPLICA ops\",\n        newMoveReplicaOps - moveReplicaOps < flakyReplicas);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9c6c0dad4932399aec99b4818086cb1772773916","date":1520515900,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestLargeCluster#testBasic().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestLargeCluster#testBasic().mjava","sourceNew":"  @Test\n  public void testBasic() throws Exception {\n    SolrClient solrClient = cluster.simGetSolrClient();\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [\" +\n        \"{'name':'compute','class':'\" + ComputePlanAction.class.getName() + \"'},\" +\n        \"{'name':'execute','class':'\" + ExecutePlanAction.class.getName() + \"'},\" +\n        \"{'name':'test','class':'\" + TestTriggerAction.class.getName() + \"'}\" +\n        \"]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'foo',\" +\n        \"'trigger' : 'node_lost_trigger',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED', 'FAILED'],\" +\n        \"'beforeAction' : ['compute', 'execute'],\" +\n        \"'afterAction' : ['compute', 'execute'],\" +\n        \"'class' : '\" + TestTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    cluster.getTimeSource().sleep(5000);\n\n    // pick a few random nodes\n    List<String> nodes = new ArrayList<>();\n    int limit = 75;\n    for (String node : cluster.getClusterStateProvider().getLiveNodes()) {\n      nodes.add(node);\n      if (nodes.size() > limit) {\n        break;\n      }\n    }\n    Collections.shuffle(nodes, random());\n    // create collection on these nodes\n    String collectionName = \"testBasic\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 5, 5, 5, 5);\n    create.setMaxShardsPerNode(1);\n    create.setAutoAddReplicas(false);\n    create.setCreateNodeSet(String.join(\",\", nodes));\n    create.process(solrClient);\n\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15)) + \"ms\");\n\n    int KILL_NODES = 8;\n    // kill off a number of nodes\n    for (int i = 0; i < KILL_NODES; i++) {\n      cluster.simRemoveNode(nodes.get(i), false);\n    }\n    // should fully recover\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 90 * KILL_NODES, TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15)) + \"ms\");\n\n    log.info(\"OP COUNTS: \" + cluster.simGetOpCounts());\n    long moveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n\n    // simulate a number of flaky nodes\n    int FLAKY_NODES = 10;\n    int flakyReplicas = 0;\n    for (int cnt = 0; cnt < 10; cnt++) {\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        flakyReplicas += cluster.getSimClusterStateProvider().simGetReplicaInfos(nodes.get(i))\n            .stream().filter(r -> r.getState().equals(Replica.State.ACTIVE)).count();\n        cluster.simRemoveNode(nodes.get(i), false);\n      }\n      cluster.getTimeSource().sleep(TimeUnit.SECONDS.toMillis(waitForSeconds) * 2);\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        final String nodeId = nodes.get(i);\n        cluster.submit(() -> cluster.getSimClusterStateProvider().simRestoreNode(nodeId));\n      }\n    }\n\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15)) + \"ms\");\n    long newMoveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n    log.info(\"==== Flaky replicas: {}. Additional MOVEREPLICA count: {}\", flakyReplicas, (newMoveReplicaOps - moveReplicaOps));\n    // flaky nodes lead to a number of MOVEREPLICA that is non-zero but lower than the number of flaky replicas\n    assertTrue(\"there should be new MOVERPLICA ops\", newMoveReplicaOps - moveReplicaOps > 0);\n    assertTrue(\"there should be less than flakyReplicas=\" + flakyReplicas + \" MOVEREPLICA ops\",\n        newMoveReplicaOps - moveReplicaOps < flakyReplicas);\n  }\n\n","sourceOld":"  @Test\n  public void testBasic() throws Exception {\n    SolrClient solrClient = cluster.simGetSolrClient();\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [\" +\n        \"{'name':'compute','class':'\" + ComputePlanAction.class.getName() + \"'},\" +\n        \"{'name':'execute','class':'\" + ExecutePlanAction.class.getName() + \"'},\" +\n        \"{'name':'test','class':'\" + TestTriggerAction.class.getName() + \"'}\" +\n        \"]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'foo',\" +\n        \"'trigger' : 'node_lost_trigger',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED', 'FAILED'],\" +\n        \"'beforeAction' : ['compute', 'execute'],\" +\n        \"'afterAction' : ['compute', 'execute'],\" +\n        \"'class' : '\" + TestTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    cluster.getTimeSource().sleep(5000);\n\n    // pick a few random nodes\n    List<String> nodes = new ArrayList<>();\n    int limit = 75;\n    for (String node : cluster.getClusterStateProvider().getLiveNodes()) {\n      nodes.add(node);\n      if (nodes.size() > limit) {\n        break;\n      }\n    }\n    Collections.shuffle(nodes, random());\n    // create collection on these nodes\n    String collectionName = \"testBasic\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 5, 5, 5, 5);\n    create.setMaxShardsPerNode(1);\n    create.setAutoAddReplicas(false);\n    create.setCreateNodeSet(String.join(\",\", nodes));\n    create.process(solrClient);\n\n    log.info(\"Ready after \" + waitForState(collectionName, 30 * nodes.size(), TimeUnit.SECONDS, clusterShape(5, 15)) + \"ms\");\n\n    int KILL_NODES = 8;\n    // kill off a number of nodes\n    for (int i = 0; i < KILL_NODES; i++) {\n      cluster.simRemoveNode(nodes.get(i), false);\n    }\n    // should fully recover\n    log.info(\"Ready after \" + waitForState(collectionName, 90 * KILL_NODES, TimeUnit.SECONDS, clusterShape(5, 15)) + \"ms\");\n\n    log.info(\"OP COUNTS: \" + cluster.simGetOpCounts());\n    long moveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n\n    // simulate a number of flaky nodes\n    int FLAKY_NODES = 10;\n    int flakyReplicas = 0;\n    for (int cnt = 0; cnt < 10; cnt++) {\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        flakyReplicas += cluster.getSimClusterStateProvider().simGetReplicaInfos(nodes.get(i))\n            .stream().filter(r -> r.getState().equals(Replica.State.ACTIVE)).count();\n        cluster.simRemoveNode(nodes.get(i), false);\n      }\n      cluster.getTimeSource().sleep(TimeUnit.SECONDS.toMillis(waitForSeconds) * 2);\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        final String nodeId = nodes.get(i);\n        cluster.submit(() -> cluster.getSimClusterStateProvider().simRestoreNode(nodeId));\n      }\n    }\n\n    log.info(\"Ready after \" + waitForState(collectionName, 30 * nodes.size(), TimeUnit.SECONDS, clusterShape(5, 15)) + \"ms\");\n    long newMoveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n    log.info(\"==== Flaky replicas: {}. Additional MOVEREPLICA count: {}\", flakyReplicas, (newMoveReplicaOps - moveReplicaOps));\n    // flaky nodes lead to a number of MOVEREPLICA that is non-zero but lower than the number of flaky replicas\n    assertTrue(\"there should be new MOVERPLICA ops\", newMoveReplicaOps - moveReplicaOps > 0);\n    assertTrue(\"there should be less than flakyReplicas=\" + flakyReplicas + \" MOVEREPLICA ops\",\n        newMoveReplicaOps - moveReplicaOps < flakyReplicas);\n  }\n\n","bugFix":null,"bugIntro":["042b92cf48996255bedb0c3c4bf772d7e06e4dea"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1294fc81133ad1c53ea75edf471f5bea39621e68","date":1528194755,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestLargeCluster#testBasic().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestLargeCluster#testBasic().mjava","sourceNew":"  @Test\n  public void testBasic() throws Exception {\n    SolrClient solrClient = cluster.simGetSolrClient();\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger1',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [\" +\n        \"{'name':'start','class':'\" + StartTriggerAction.class.getName() + \"'},\" +\n        \"{'name':'compute','class':'\" + ComputePlanAction.class.getName() + \"'},\" +\n        \"{'name':'execute','class':'\" + ExecutePlanAction.class.getName() + \"'},\" +\n        \"{'name':'test','class':'\" + FinishTriggerAction.class.getName() + \"'}\" +\n        \"]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'foo',\" +\n        \"'trigger' : 'node_lost_trigger1',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED', 'FAILED'],\" +\n        \"'beforeAction' : ['compute', 'execute'],\" +\n        \"'afterAction' : ['compute', 'execute'],\" +\n        \"'class' : '\" + TestTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    cluster.getTimeSource().sleep(5000);\n\n    // pick a few random nodes\n    List<String> nodes = new ArrayList<>();\n    int limit = 75;\n    for (String node : cluster.getClusterStateProvider().getLiveNodes()) {\n      nodes.add(node);\n      if (nodes.size() > limit) {\n        break;\n      }\n    }\n    Collections.shuffle(nodes, random());\n    // create collection on these nodes\n    String collectionName = \"testBasic\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 5, 5, 5, 5);\n    create.setMaxShardsPerNode(1);\n    create.setAutoAddReplicas(false);\n    create.setCreateNodeSet(String.join(\",\", nodes));\n    create.process(solrClient);\n\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15)) + \"ms\");\n\n    int KILL_NODES = 8;\n    // kill off a number of nodes\n    for (int i = 0; i < KILL_NODES; i++) {\n      cluster.simRemoveNode(nodes.get(i), false);\n    }\n    // should fully recover\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 90 * KILL_NODES, TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15)) + \"ms\");\n\n    log.info(\"OP COUNTS: \" + cluster.simGetOpCounts());\n    long moveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n\n    // simulate a number of flaky nodes\n    int FLAKY_NODES = 10;\n    int flakyReplicas = 0;\n    for (int cnt = 0; cnt < 10; cnt++) {\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        flakyReplicas += cluster.getSimClusterStateProvider().simGetReplicaInfos(nodes.get(i))\n            .stream().filter(r -> r.getState().equals(Replica.State.ACTIVE)).count();\n        cluster.simRemoveNode(nodes.get(i), false);\n      }\n      cluster.getTimeSource().sleep(TimeUnit.SECONDS.toMillis(waitForSeconds) * 2);\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        final String nodeId = nodes.get(i);\n        cluster.submit(() -> cluster.getSimClusterStateProvider().simRestoreNode(nodeId));\n      }\n    }\n\n    // wait until started == finished\n    TimeOut timeOut = new TimeOut(20 * waitForSeconds * NUM_NODES, TimeUnit.SECONDS, cluster.getTimeSource());\n    while (!timeOut.hasTimedOut()) {\n      if (triggerStartedCount.get() == triggerFinishedCount.get()) {\n        break;\n      }\n      timeOut.sleep(1000);\n    }\n    if (timeOut.hasTimedOut()) {\n      fail(\"did not finish processing all events in time: started=\" + triggerStartedCount.get() + \", finished=\" + triggerFinishedCount.get());\n    }\n\n\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15)) + \"ms\");\n    long newMoveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n    log.info(\"==== Flaky replicas: {}. Additional MOVEREPLICA count: {}\", flakyReplicas, (newMoveReplicaOps - moveReplicaOps));\n    // flaky nodes lead to a number of MOVEREPLICA that is non-zero but lower than the number of flaky replicas\n    assertTrue(\"there should be new MOVERPLICA ops\", newMoveReplicaOps - moveReplicaOps > 0);\n    assertTrue(\"there should be less than flakyReplicas=\" + flakyReplicas + \" MOVEREPLICA ops\",\n        newMoveReplicaOps - moveReplicaOps < flakyReplicas);\n  }\n\n","sourceOld":"  @Test\n  public void testBasic() throws Exception {\n    SolrClient solrClient = cluster.simGetSolrClient();\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [\" +\n        \"{'name':'compute','class':'\" + ComputePlanAction.class.getName() + \"'},\" +\n        \"{'name':'execute','class':'\" + ExecutePlanAction.class.getName() + \"'},\" +\n        \"{'name':'test','class':'\" + TestTriggerAction.class.getName() + \"'}\" +\n        \"]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'foo',\" +\n        \"'trigger' : 'node_lost_trigger',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED', 'FAILED'],\" +\n        \"'beforeAction' : ['compute', 'execute'],\" +\n        \"'afterAction' : ['compute', 'execute'],\" +\n        \"'class' : '\" + TestTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    cluster.getTimeSource().sleep(5000);\n\n    // pick a few random nodes\n    List<String> nodes = new ArrayList<>();\n    int limit = 75;\n    for (String node : cluster.getClusterStateProvider().getLiveNodes()) {\n      nodes.add(node);\n      if (nodes.size() > limit) {\n        break;\n      }\n    }\n    Collections.shuffle(nodes, random());\n    // create collection on these nodes\n    String collectionName = \"testBasic\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 5, 5, 5, 5);\n    create.setMaxShardsPerNode(1);\n    create.setAutoAddReplicas(false);\n    create.setCreateNodeSet(String.join(\",\", nodes));\n    create.process(solrClient);\n\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15)) + \"ms\");\n\n    int KILL_NODES = 8;\n    // kill off a number of nodes\n    for (int i = 0; i < KILL_NODES; i++) {\n      cluster.simRemoveNode(nodes.get(i), false);\n    }\n    // should fully recover\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 90 * KILL_NODES, TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15)) + \"ms\");\n\n    log.info(\"OP COUNTS: \" + cluster.simGetOpCounts());\n    long moveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n\n    // simulate a number of flaky nodes\n    int FLAKY_NODES = 10;\n    int flakyReplicas = 0;\n    for (int cnt = 0; cnt < 10; cnt++) {\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        flakyReplicas += cluster.getSimClusterStateProvider().simGetReplicaInfos(nodes.get(i))\n            .stream().filter(r -> r.getState().equals(Replica.State.ACTIVE)).count();\n        cluster.simRemoveNode(nodes.get(i), false);\n      }\n      cluster.getTimeSource().sleep(TimeUnit.SECONDS.toMillis(waitForSeconds) * 2);\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        final String nodeId = nodes.get(i);\n        cluster.submit(() -> cluster.getSimClusterStateProvider().simRestoreNode(nodeId));\n      }\n    }\n\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15)) + \"ms\");\n    long newMoveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n    log.info(\"==== Flaky replicas: {}. Additional MOVEREPLICA count: {}\", flakyReplicas, (newMoveReplicaOps - moveReplicaOps));\n    // flaky nodes lead to a number of MOVEREPLICA that is non-zero but lower than the number of flaky replicas\n    assertTrue(\"there should be new MOVERPLICA ops\", newMoveReplicaOps - moveReplicaOps > 0);\n    assertTrue(\"there should be less than flakyReplicas=\" + flakyReplicas + \" MOVEREPLICA ops\",\n        newMoveReplicaOps - moveReplicaOps < flakyReplicas);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f592209545c71895260367152601e9200399776d","date":1528238935,"type":3,"author":"Michael Braun","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestLargeCluster#testBasic().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestLargeCluster#testBasic().mjava","sourceNew":"  @Test\n  public void testBasic() throws Exception {\n    SolrClient solrClient = cluster.simGetSolrClient();\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger1',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [\" +\n        \"{'name':'start','class':'\" + StartTriggerAction.class.getName() + \"'},\" +\n        \"{'name':'compute','class':'\" + ComputePlanAction.class.getName() + \"'},\" +\n        \"{'name':'execute','class':'\" + ExecutePlanAction.class.getName() + \"'},\" +\n        \"{'name':'test','class':'\" + FinishTriggerAction.class.getName() + \"'}\" +\n        \"]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'foo',\" +\n        \"'trigger' : 'node_lost_trigger1',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED', 'FAILED'],\" +\n        \"'beforeAction' : ['compute', 'execute'],\" +\n        \"'afterAction' : ['compute', 'execute'],\" +\n        \"'class' : '\" + TestTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    cluster.getTimeSource().sleep(5000);\n\n    // pick a few random nodes\n    List<String> nodes = new ArrayList<>();\n    int limit = 75;\n    for (String node : cluster.getClusterStateProvider().getLiveNodes()) {\n      nodes.add(node);\n      if (nodes.size() > limit) {\n        break;\n      }\n    }\n    Collections.shuffle(nodes, random());\n    // create collection on these nodes\n    String collectionName = \"testBasic\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 5, 5, 5, 5);\n    create.setMaxShardsPerNode(1);\n    create.setAutoAddReplicas(false);\n    create.setCreateNodeSet(String.join(\",\", nodes));\n    create.process(solrClient);\n\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15)) + \"ms\");\n\n    int KILL_NODES = 8;\n    // kill off a number of nodes\n    for (int i = 0; i < KILL_NODES; i++) {\n      cluster.simRemoveNode(nodes.get(i), false);\n    }\n    // should fully recover\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 90 * KILL_NODES, TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15)) + \"ms\");\n\n    log.info(\"OP COUNTS: \" + cluster.simGetOpCounts());\n    long moveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n\n    // simulate a number of flaky nodes\n    int FLAKY_NODES = 10;\n    int flakyReplicas = 0;\n    for (int cnt = 0; cnt < 10; cnt++) {\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        flakyReplicas += cluster.getSimClusterStateProvider().simGetReplicaInfos(nodes.get(i))\n            .stream().filter(r -> r.getState().equals(Replica.State.ACTIVE)).count();\n        cluster.simRemoveNode(nodes.get(i), false);\n      }\n      cluster.getTimeSource().sleep(TimeUnit.SECONDS.toMillis(waitForSeconds) * 2);\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        final String nodeId = nodes.get(i);\n        cluster.submit(() -> cluster.getSimClusterStateProvider().simRestoreNode(nodeId));\n      }\n    }\n\n    // wait until started == finished\n    TimeOut timeOut = new TimeOut(20 * waitForSeconds * NUM_NODES, TimeUnit.SECONDS, cluster.getTimeSource());\n    while (!timeOut.hasTimedOut()) {\n      if (triggerStartedCount.get() == triggerFinishedCount.get()) {\n        break;\n      }\n      timeOut.sleep(1000);\n    }\n    if (timeOut.hasTimedOut()) {\n      fail(\"did not finish processing all events in time: started=\" + triggerStartedCount.get() + \", finished=\" + triggerFinishedCount.get());\n    }\n\n\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15)) + \"ms\");\n    long newMoveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n    log.info(\"==== Flaky replicas: {}. Additional MOVEREPLICA count: {}\", flakyReplicas, (newMoveReplicaOps - moveReplicaOps));\n    // flaky nodes lead to a number of MOVEREPLICA that is non-zero but lower than the number of flaky replicas\n    assertTrue(\"there should be new MOVERPLICA ops\", newMoveReplicaOps - moveReplicaOps > 0);\n    assertTrue(\"there should be less than flakyReplicas=\" + flakyReplicas + \" MOVEREPLICA ops\",\n        newMoveReplicaOps - moveReplicaOps < flakyReplicas);\n  }\n\n","sourceOld":"  @Test\n  public void testBasic() throws Exception {\n    SolrClient solrClient = cluster.simGetSolrClient();\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [\" +\n        \"{'name':'compute','class':'\" + ComputePlanAction.class.getName() + \"'},\" +\n        \"{'name':'execute','class':'\" + ExecutePlanAction.class.getName() + \"'},\" +\n        \"{'name':'test','class':'\" + TestTriggerAction.class.getName() + \"'}\" +\n        \"]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'foo',\" +\n        \"'trigger' : 'node_lost_trigger',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED', 'FAILED'],\" +\n        \"'beforeAction' : ['compute', 'execute'],\" +\n        \"'afterAction' : ['compute', 'execute'],\" +\n        \"'class' : '\" + TestTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    cluster.getTimeSource().sleep(5000);\n\n    // pick a few random nodes\n    List<String> nodes = new ArrayList<>();\n    int limit = 75;\n    for (String node : cluster.getClusterStateProvider().getLiveNodes()) {\n      nodes.add(node);\n      if (nodes.size() > limit) {\n        break;\n      }\n    }\n    Collections.shuffle(nodes, random());\n    // create collection on these nodes\n    String collectionName = \"testBasic\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 5, 5, 5, 5);\n    create.setMaxShardsPerNode(1);\n    create.setAutoAddReplicas(false);\n    create.setCreateNodeSet(String.join(\",\", nodes));\n    create.process(solrClient);\n\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15)) + \"ms\");\n\n    int KILL_NODES = 8;\n    // kill off a number of nodes\n    for (int i = 0; i < KILL_NODES; i++) {\n      cluster.simRemoveNode(nodes.get(i), false);\n    }\n    // should fully recover\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 90 * KILL_NODES, TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15)) + \"ms\");\n\n    log.info(\"OP COUNTS: \" + cluster.simGetOpCounts());\n    long moveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n\n    // simulate a number of flaky nodes\n    int FLAKY_NODES = 10;\n    int flakyReplicas = 0;\n    for (int cnt = 0; cnt < 10; cnt++) {\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        flakyReplicas += cluster.getSimClusterStateProvider().simGetReplicaInfos(nodes.get(i))\n            .stream().filter(r -> r.getState().equals(Replica.State.ACTIVE)).count();\n        cluster.simRemoveNode(nodes.get(i), false);\n      }\n      cluster.getTimeSource().sleep(TimeUnit.SECONDS.toMillis(waitForSeconds) * 2);\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        final String nodeId = nodes.get(i);\n        cluster.submit(() -> cluster.getSimClusterStateProvider().simRestoreNode(nodeId));\n      }\n    }\n\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15)) + \"ms\");\n    long newMoveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n    log.info(\"==== Flaky replicas: {}. Additional MOVEREPLICA count: {}\", flakyReplicas, (newMoveReplicaOps - moveReplicaOps));\n    // flaky nodes lead to a number of MOVEREPLICA that is non-zero but lower than the number of flaky replicas\n    assertTrue(\"there should be new MOVERPLICA ops\", newMoveReplicaOps - moveReplicaOps > 0);\n    assertTrue(\"there should be less than flakyReplicas=\" + flakyReplicas + \" MOVEREPLICA ops\",\n        newMoveReplicaOps - moveReplicaOps < flakyReplicas);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b70042a8a492f7054d480ccdd2be9796510d4327","date":1528386658,"type":3,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestLargeCluster#testBasic().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestLargeCluster#testBasic().mjava","sourceNew":"  @Test\n  public void testBasic() throws Exception {\n    SolrClient solrClient = cluster.simGetSolrClient();\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger1',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [\" +\n        \"{'name':'start','class':'\" + StartTriggerAction.class.getName() + \"'},\" +\n        \"{'name':'compute','class':'\" + ComputePlanAction.class.getName() + \"'},\" +\n        \"{'name':'execute','class':'\" + ExecutePlanAction.class.getName() + \"'},\" +\n        \"{'name':'test','class':'\" + FinishTriggerAction.class.getName() + \"'}\" +\n        \"]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'foo',\" +\n        \"'trigger' : 'node_lost_trigger1',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED', 'FAILED'],\" +\n        \"'beforeAction' : ['compute', 'execute'],\" +\n        \"'afterAction' : ['compute', 'execute'],\" +\n        \"'class' : '\" + TestTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    cluster.getTimeSource().sleep(5000);\n\n    // pick a few random nodes\n    List<String> nodes = new ArrayList<>();\n    int limit = 75;\n    for (String node : cluster.getClusterStateProvider().getLiveNodes()) {\n      nodes.add(node);\n      if (nodes.size() > limit) {\n        break;\n      }\n    }\n    Collections.shuffle(nodes, random());\n    // create collection on these nodes\n    String collectionName = \"testBasic\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 5, 5, 5, 5);\n    create.setMaxShardsPerNode(1);\n    create.setAutoAddReplicas(false);\n    create.setCreateNodeSet(String.join(\",\", nodes));\n    create.process(solrClient);\n\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15)) + \"ms\");\n\n    int KILL_NODES = 8;\n    // kill off a number of nodes\n    for (int i = 0; i < KILL_NODES; i++) {\n      cluster.simRemoveNode(nodes.get(i), false);\n    }\n    // should fully recover\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 90 * KILL_NODES, TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15)) + \"ms\");\n\n    log.info(\"OP COUNTS: \" + cluster.simGetOpCounts());\n    long moveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n\n    // simulate a number of flaky nodes\n    int FLAKY_NODES = 10;\n    int flakyReplicas = 0;\n    for (int cnt = 0; cnt < 10; cnt++) {\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        flakyReplicas += cluster.getSimClusterStateProvider().simGetReplicaInfos(nodes.get(i))\n            .stream().filter(r -> r.getState().equals(Replica.State.ACTIVE)).count();\n        cluster.simRemoveNode(nodes.get(i), false);\n      }\n      cluster.getTimeSource().sleep(TimeUnit.SECONDS.toMillis(waitForSeconds) * 2);\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        final String nodeId = nodes.get(i);\n        cluster.submit(() -> cluster.getSimClusterStateProvider().simRestoreNode(nodeId));\n      }\n    }\n\n    // wait until started == finished\n    TimeOut timeOut = new TimeOut(20 * waitForSeconds * NUM_NODES, TimeUnit.SECONDS, cluster.getTimeSource());\n    while (!timeOut.hasTimedOut()) {\n      if (triggerStartedCount.get() == triggerFinishedCount.get()) {\n        break;\n      }\n      timeOut.sleep(1000);\n    }\n    if (timeOut.hasTimedOut()) {\n      fail(\"did not finish processing all events in time: started=\" + triggerStartedCount.get() + \", finished=\" + triggerFinishedCount.get());\n    }\n\n\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15)) + \"ms\");\n    long newMoveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n    log.info(\"==== Flaky replicas: {}. Additional MOVEREPLICA count: {}\", flakyReplicas, (newMoveReplicaOps - moveReplicaOps));\n    // flaky nodes lead to a number of MOVEREPLICA that is non-zero but lower than the number of flaky replicas\n    assertTrue(\"there should be new MOVERPLICA ops\", newMoveReplicaOps - moveReplicaOps > 0);\n    assertTrue(\"there should be less than flakyReplicas=\" + flakyReplicas + \" MOVEREPLICA ops\",\n        newMoveReplicaOps - moveReplicaOps < flakyReplicas);\n  }\n\n","sourceOld":"  @Test\n  public void testBasic() throws Exception {\n    SolrClient solrClient = cluster.simGetSolrClient();\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [\" +\n        \"{'name':'compute','class':'\" + ComputePlanAction.class.getName() + \"'},\" +\n        \"{'name':'execute','class':'\" + ExecutePlanAction.class.getName() + \"'},\" +\n        \"{'name':'test','class':'\" + TestTriggerAction.class.getName() + \"'}\" +\n        \"]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'foo',\" +\n        \"'trigger' : 'node_lost_trigger',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED', 'FAILED'],\" +\n        \"'beforeAction' : ['compute', 'execute'],\" +\n        \"'afterAction' : ['compute', 'execute'],\" +\n        \"'class' : '\" + TestTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    cluster.getTimeSource().sleep(5000);\n\n    // pick a few random nodes\n    List<String> nodes = new ArrayList<>();\n    int limit = 75;\n    for (String node : cluster.getClusterStateProvider().getLiveNodes()) {\n      nodes.add(node);\n      if (nodes.size() > limit) {\n        break;\n      }\n    }\n    Collections.shuffle(nodes, random());\n    // create collection on these nodes\n    String collectionName = \"testBasic\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 5, 5, 5, 5);\n    create.setMaxShardsPerNode(1);\n    create.setAutoAddReplicas(false);\n    create.setCreateNodeSet(String.join(\",\", nodes));\n    create.process(solrClient);\n\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15)) + \"ms\");\n\n    int KILL_NODES = 8;\n    // kill off a number of nodes\n    for (int i = 0; i < KILL_NODES; i++) {\n      cluster.simRemoveNode(nodes.get(i), false);\n    }\n    // should fully recover\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 90 * KILL_NODES, TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15)) + \"ms\");\n\n    log.info(\"OP COUNTS: \" + cluster.simGetOpCounts());\n    long moveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n\n    // simulate a number of flaky nodes\n    int FLAKY_NODES = 10;\n    int flakyReplicas = 0;\n    for (int cnt = 0; cnt < 10; cnt++) {\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        flakyReplicas += cluster.getSimClusterStateProvider().simGetReplicaInfos(nodes.get(i))\n            .stream().filter(r -> r.getState().equals(Replica.State.ACTIVE)).count();\n        cluster.simRemoveNode(nodes.get(i), false);\n      }\n      cluster.getTimeSource().sleep(TimeUnit.SECONDS.toMillis(waitForSeconds) * 2);\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        final String nodeId = nodes.get(i);\n        cluster.submit(() -> cluster.getSimClusterStateProvider().simRestoreNode(nodeId));\n      }\n    }\n\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15)) + \"ms\");\n    long newMoveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n    log.info(\"==== Flaky replicas: {}. Additional MOVEREPLICA count: {}\", flakyReplicas, (newMoveReplicaOps - moveReplicaOps));\n    // flaky nodes lead to a number of MOVEREPLICA that is non-zero but lower than the number of flaky replicas\n    assertTrue(\"there should be new MOVERPLICA ops\", newMoveReplicaOps - moveReplicaOps > 0);\n    assertTrue(\"there should be less than flakyReplicas=\" + flakyReplicas + \" MOVEREPLICA ops\",\n        newMoveReplicaOps - moveReplicaOps < flakyReplicas);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7a7544ad4b63d1b5f556c3da8f9c63d332aa034e","date":1529622176,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestLargeCluster#testBasic().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestLargeCluster#testBasic().mjava","sourceNew":"  @Test\n  @LuceneTestCase.BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 2018-06-18\n  public void testBasic() throws Exception {\n    SolrClient solrClient = cluster.simGetSolrClient();\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger1',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [\" +\n        \"{'name':'start','class':'\" + StartTriggerAction.class.getName() + \"'},\" +\n        \"{'name':'compute','class':'\" + ComputePlanAction.class.getName() + \"'},\" +\n        \"{'name':'execute','class':'\" + ExecutePlanAction.class.getName() + \"'},\" +\n        \"{'name':'test','class':'\" + FinishTriggerAction.class.getName() + \"'}\" +\n        \"]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'foo',\" +\n        \"'trigger' : 'node_lost_trigger1',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED', 'FAILED'],\" +\n        \"'beforeAction' : ['compute', 'execute'],\" +\n        \"'afterAction' : ['compute', 'execute'],\" +\n        \"'class' : '\" + TestTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    cluster.getTimeSource().sleep(5000);\n\n    // pick a few random nodes\n    List<String> nodes = new ArrayList<>();\n    int limit = 75;\n    for (String node : cluster.getClusterStateProvider().getLiveNodes()) {\n      nodes.add(node);\n      if (nodes.size() > limit) {\n        break;\n      }\n    }\n    Collections.shuffle(nodes, random());\n    // create collection on these nodes\n    String collectionName = \"testBasic\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 5, 5, 5, 5);\n    create.setMaxShardsPerNode(1);\n    create.setAutoAddReplicas(false);\n    create.setCreateNodeSet(String.join(\",\", nodes));\n    create.process(solrClient);\n\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15)) + \"ms\");\n\n    int KILL_NODES = 8;\n    // kill off a number of nodes\n    for (int i = 0; i < KILL_NODES; i++) {\n      cluster.simRemoveNode(nodes.get(i), false);\n    }\n    // should fully recover\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 90 * KILL_NODES, TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15)) + \"ms\");\n\n    log.info(\"OP COUNTS: \" + cluster.simGetOpCounts());\n    long moveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n\n    // simulate a number of flaky nodes\n    int FLAKY_NODES = 10;\n    int flakyReplicas = 0;\n    for (int cnt = 0; cnt < 10; cnt++) {\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        flakyReplicas += cluster.getSimClusterStateProvider().simGetReplicaInfos(nodes.get(i))\n            .stream().filter(r -> r.getState().equals(Replica.State.ACTIVE)).count();\n        cluster.simRemoveNode(nodes.get(i), false);\n      }\n      cluster.getTimeSource().sleep(TimeUnit.SECONDS.toMillis(waitForSeconds) * 2);\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        final String nodeId = nodes.get(i);\n        cluster.submit(() -> cluster.getSimClusterStateProvider().simRestoreNode(nodeId));\n      }\n    }\n\n    // wait until started == finished\n    TimeOut timeOut = new TimeOut(20 * waitForSeconds * NUM_NODES, TimeUnit.SECONDS, cluster.getTimeSource());\n    while (!timeOut.hasTimedOut()) {\n      if (triggerStartedCount.get() == triggerFinishedCount.get()) {\n        break;\n      }\n      timeOut.sleep(1000);\n    }\n    if (timeOut.hasTimedOut()) {\n      fail(\"did not finish processing all events in time: started=\" + triggerStartedCount.get() + \", finished=\" + triggerFinishedCount.get());\n    }\n\n\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15)) + \"ms\");\n    long newMoveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n    log.info(\"==== Flaky replicas: {}. Additional MOVEREPLICA count: {}\", flakyReplicas, (newMoveReplicaOps - moveReplicaOps));\n    // flaky nodes lead to a number of MOVEREPLICA that is non-zero but lower than the number of flaky replicas\n    assertTrue(\"there should be new MOVERPLICA ops\", newMoveReplicaOps - moveReplicaOps > 0);\n    assertTrue(\"there should be less than flakyReplicas=\" + flakyReplicas + \" MOVEREPLICA ops\",\n        newMoveReplicaOps - moveReplicaOps < flakyReplicas);\n  }\n\n","sourceOld":"  @Test\n  public void testBasic() throws Exception {\n    SolrClient solrClient = cluster.simGetSolrClient();\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger1',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [\" +\n        \"{'name':'start','class':'\" + StartTriggerAction.class.getName() + \"'},\" +\n        \"{'name':'compute','class':'\" + ComputePlanAction.class.getName() + \"'},\" +\n        \"{'name':'execute','class':'\" + ExecutePlanAction.class.getName() + \"'},\" +\n        \"{'name':'test','class':'\" + FinishTriggerAction.class.getName() + \"'}\" +\n        \"]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'foo',\" +\n        \"'trigger' : 'node_lost_trigger1',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED', 'FAILED'],\" +\n        \"'beforeAction' : ['compute', 'execute'],\" +\n        \"'afterAction' : ['compute', 'execute'],\" +\n        \"'class' : '\" + TestTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    cluster.getTimeSource().sleep(5000);\n\n    // pick a few random nodes\n    List<String> nodes = new ArrayList<>();\n    int limit = 75;\n    for (String node : cluster.getClusterStateProvider().getLiveNodes()) {\n      nodes.add(node);\n      if (nodes.size() > limit) {\n        break;\n      }\n    }\n    Collections.shuffle(nodes, random());\n    // create collection on these nodes\n    String collectionName = \"testBasic\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 5, 5, 5, 5);\n    create.setMaxShardsPerNode(1);\n    create.setAutoAddReplicas(false);\n    create.setCreateNodeSet(String.join(\",\", nodes));\n    create.process(solrClient);\n\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15)) + \"ms\");\n\n    int KILL_NODES = 8;\n    // kill off a number of nodes\n    for (int i = 0; i < KILL_NODES; i++) {\n      cluster.simRemoveNode(nodes.get(i), false);\n    }\n    // should fully recover\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 90 * KILL_NODES, TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15)) + \"ms\");\n\n    log.info(\"OP COUNTS: \" + cluster.simGetOpCounts());\n    long moveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n\n    // simulate a number of flaky nodes\n    int FLAKY_NODES = 10;\n    int flakyReplicas = 0;\n    for (int cnt = 0; cnt < 10; cnt++) {\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        flakyReplicas += cluster.getSimClusterStateProvider().simGetReplicaInfos(nodes.get(i))\n            .stream().filter(r -> r.getState().equals(Replica.State.ACTIVE)).count();\n        cluster.simRemoveNode(nodes.get(i), false);\n      }\n      cluster.getTimeSource().sleep(TimeUnit.SECONDS.toMillis(waitForSeconds) * 2);\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        final String nodeId = nodes.get(i);\n        cluster.submit(() -> cluster.getSimClusterStateProvider().simRestoreNode(nodeId));\n      }\n    }\n\n    // wait until started == finished\n    TimeOut timeOut = new TimeOut(20 * waitForSeconds * NUM_NODES, TimeUnit.SECONDS, cluster.getTimeSource());\n    while (!timeOut.hasTimedOut()) {\n      if (triggerStartedCount.get() == triggerFinishedCount.get()) {\n        break;\n      }\n      timeOut.sleep(1000);\n    }\n    if (timeOut.hasTimedOut()) {\n      fail(\"did not finish processing all events in time: started=\" + triggerStartedCount.get() + \", finished=\" + triggerFinishedCount.get());\n    }\n\n\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15)) + \"ms\");\n    long newMoveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n    log.info(\"==== Flaky replicas: {}. Additional MOVEREPLICA count: {}\", flakyReplicas, (newMoveReplicaOps - moveReplicaOps));\n    // flaky nodes lead to a number of MOVEREPLICA that is non-zero but lower than the number of flaky replicas\n    assertTrue(\"there should be new MOVERPLICA ops\", newMoveReplicaOps - moveReplicaOps > 0);\n    assertTrue(\"there should be less than flakyReplicas=\" + flakyReplicas + \" MOVEREPLICA ops\",\n        newMoveReplicaOps - moveReplicaOps < flakyReplicas);\n  }\n\n","bugFix":null,"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26","date":1531589977,"type":3,"author":"Michael Braun","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestLargeCluster#testBasic().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestLargeCluster#testBasic().mjava","sourceNew":"  @Test\n  @LuceneTestCase.BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 2018-06-18\n  public void testBasic() throws Exception {\n    SolrClient solrClient = cluster.simGetSolrClient();\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger1',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [\" +\n        \"{'name':'start','class':'\" + StartTriggerAction.class.getName() + \"'},\" +\n        \"{'name':'compute','class':'\" + ComputePlanAction.class.getName() + \"'},\" +\n        \"{'name':'execute','class':'\" + ExecutePlanAction.class.getName() + \"'},\" +\n        \"{'name':'test','class':'\" + FinishTriggerAction.class.getName() + \"'}\" +\n        \"]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'foo',\" +\n        \"'trigger' : 'node_lost_trigger1',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED', 'FAILED'],\" +\n        \"'beforeAction' : ['compute', 'execute'],\" +\n        \"'afterAction' : ['compute', 'execute'],\" +\n        \"'class' : '\" + TestTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    cluster.getTimeSource().sleep(5000);\n\n    // pick a few random nodes\n    List<String> nodes = new ArrayList<>();\n    int limit = 75;\n    for (String node : cluster.getClusterStateProvider().getLiveNodes()) {\n      nodes.add(node);\n      if (nodes.size() > limit) {\n        break;\n      }\n    }\n    Collections.shuffle(nodes, random());\n    // create collection on these nodes\n    String collectionName = \"testBasic\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 5, 5, 5, 5);\n    create.setMaxShardsPerNode(1);\n    create.setAutoAddReplicas(false);\n    create.setCreateNodeSet(String.join(\",\", nodes));\n    create.process(solrClient);\n\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15)) + \"ms\");\n\n    int KILL_NODES = 8;\n    // kill off a number of nodes\n    for (int i = 0; i < KILL_NODES; i++) {\n      cluster.simRemoveNode(nodes.get(i), false);\n    }\n    // should fully recover\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 90 * KILL_NODES, TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15)) + \"ms\");\n\n    log.info(\"OP COUNTS: \" + cluster.simGetOpCounts());\n    long moveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n\n    // simulate a number of flaky nodes\n    int FLAKY_NODES = 10;\n    int flakyReplicas = 0;\n    for (int cnt = 0; cnt < 10; cnt++) {\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        flakyReplicas += cluster.getSimClusterStateProvider().simGetReplicaInfos(nodes.get(i))\n            .stream().filter(r -> r.getState().equals(Replica.State.ACTIVE)).count();\n        cluster.simRemoveNode(nodes.get(i), false);\n      }\n      cluster.getTimeSource().sleep(TimeUnit.SECONDS.toMillis(waitForSeconds) * 2);\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        final String nodeId = nodes.get(i);\n        cluster.submit(() -> cluster.getSimClusterStateProvider().simRestoreNode(nodeId));\n      }\n    }\n\n    // wait until started == finished\n    TimeOut timeOut = new TimeOut(20 * waitForSeconds * NUM_NODES, TimeUnit.SECONDS, cluster.getTimeSource());\n    while (!timeOut.hasTimedOut()) {\n      if (triggerStartedCount.get() == triggerFinishedCount.get()) {\n        break;\n      }\n      timeOut.sleep(1000);\n    }\n    if (timeOut.hasTimedOut()) {\n      fail(\"did not finish processing all events in time: started=\" + triggerStartedCount.get() + \", finished=\" + triggerFinishedCount.get());\n    }\n\n\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15)) + \"ms\");\n    long newMoveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n    log.info(\"==== Flaky replicas: {}. Additional MOVEREPLICA count: {}\", flakyReplicas, (newMoveReplicaOps - moveReplicaOps));\n    // flaky nodes lead to a number of MOVEREPLICA that is non-zero but lower than the number of flaky replicas\n    assertTrue(\"there should be new MOVERPLICA ops\", newMoveReplicaOps - moveReplicaOps > 0);\n    assertTrue(\"there should be less than flakyReplicas=\" + flakyReplicas + \" MOVEREPLICA ops\",\n        newMoveReplicaOps - moveReplicaOps < flakyReplicas);\n  }\n\n","sourceOld":"  @Test\n  public void testBasic() throws Exception {\n    SolrClient solrClient = cluster.simGetSolrClient();\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger1',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [\" +\n        \"{'name':'start','class':'\" + StartTriggerAction.class.getName() + \"'},\" +\n        \"{'name':'compute','class':'\" + ComputePlanAction.class.getName() + \"'},\" +\n        \"{'name':'execute','class':'\" + ExecutePlanAction.class.getName() + \"'},\" +\n        \"{'name':'test','class':'\" + FinishTriggerAction.class.getName() + \"'}\" +\n        \"]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'foo',\" +\n        \"'trigger' : 'node_lost_trigger1',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED', 'FAILED'],\" +\n        \"'beforeAction' : ['compute', 'execute'],\" +\n        \"'afterAction' : ['compute', 'execute'],\" +\n        \"'class' : '\" + TestTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    cluster.getTimeSource().sleep(5000);\n\n    // pick a few random nodes\n    List<String> nodes = new ArrayList<>();\n    int limit = 75;\n    for (String node : cluster.getClusterStateProvider().getLiveNodes()) {\n      nodes.add(node);\n      if (nodes.size() > limit) {\n        break;\n      }\n    }\n    Collections.shuffle(nodes, random());\n    // create collection on these nodes\n    String collectionName = \"testBasic\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 5, 5, 5, 5);\n    create.setMaxShardsPerNode(1);\n    create.setAutoAddReplicas(false);\n    create.setCreateNodeSet(String.join(\",\", nodes));\n    create.process(solrClient);\n\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15)) + \"ms\");\n\n    int KILL_NODES = 8;\n    // kill off a number of nodes\n    for (int i = 0; i < KILL_NODES; i++) {\n      cluster.simRemoveNode(nodes.get(i), false);\n    }\n    // should fully recover\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 90 * KILL_NODES, TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15)) + \"ms\");\n\n    log.info(\"OP COUNTS: \" + cluster.simGetOpCounts());\n    long moveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n\n    // simulate a number of flaky nodes\n    int FLAKY_NODES = 10;\n    int flakyReplicas = 0;\n    for (int cnt = 0; cnt < 10; cnt++) {\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        flakyReplicas += cluster.getSimClusterStateProvider().simGetReplicaInfos(nodes.get(i))\n            .stream().filter(r -> r.getState().equals(Replica.State.ACTIVE)).count();\n        cluster.simRemoveNode(nodes.get(i), false);\n      }\n      cluster.getTimeSource().sleep(TimeUnit.SECONDS.toMillis(waitForSeconds) * 2);\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        final String nodeId = nodes.get(i);\n        cluster.submit(() -> cluster.getSimClusterStateProvider().simRestoreNode(nodeId));\n      }\n    }\n\n    // wait until started == finished\n    TimeOut timeOut = new TimeOut(20 * waitForSeconds * NUM_NODES, TimeUnit.SECONDS, cluster.getTimeSource());\n    while (!timeOut.hasTimedOut()) {\n      if (triggerStartedCount.get() == triggerFinishedCount.get()) {\n        break;\n      }\n      timeOut.sleep(1000);\n    }\n    if (timeOut.hasTimedOut()) {\n      fail(\"did not finish processing all events in time: started=\" + triggerStartedCount.get() + \", finished=\" + triggerFinishedCount.get());\n    }\n\n\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15)) + \"ms\");\n    long newMoveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n    log.info(\"==== Flaky replicas: {}. Additional MOVEREPLICA count: {}\", flakyReplicas, (newMoveReplicaOps - moveReplicaOps));\n    // flaky nodes lead to a number of MOVEREPLICA that is non-zero but lower than the number of flaky replicas\n    assertTrue(\"there should be new MOVERPLICA ops\", newMoveReplicaOps - moveReplicaOps > 0);\n    assertTrue(\"there should be less than flakyReplicas=\" + flakyReplicas + \" MOVEREPLICA ops\",\n        newMoveReplicaOps - moveReplicaOps < flakyReplicas);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","date":1531905561,"type":3,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestLargeCluster#testBasic().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestLargeCluster#testBasic().mjava","sourceNew":"  @Test\n  @LuceneTestCase.BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 2018-06-18\n  public void testBasic() throws Exception {\n    SolrClient solrClient = cluster.simGetSolrClient();\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger1',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [\" +\n        \"{'name':'start','class':'\" + StartTriggerAction.class.getName() + \"'},\" +\n        \"{'name':'compute','class':'\" + ComputePlanAction.class.getName() + \"'},\" +\n        \"{'name':'execute','class':'\" + ExecutePlanAction.class.getName() + \"'},\" +\n        \"{'name':'test','class':'\" + FinishTriggerAction.class.getName() + \"'}\" +\n        \"]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'foo',\" +\n        \"'trigger' : 'node_lost_trigger1',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED', 'FAILED'],\" +\n        \"'beforeAction' : ['compute', 'execute'],\" +\n        \"'afterAction' : ['compute', 'execute'],\" +\n        \"'class' : '\" + TestTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    cluster.getTimeSource().sleep(5000);\n\n    // pick a few random nodes\n    List<String> nodes = new ArrayList<>();\n    int limit = 75;\n    for (String node : cluster.getClusterStateProvider().getLiveNodes()) {\n      nodes.add(node);\n      if (nodes.size() > limit) {\n        break;\n      }\n    }\n    Collections.shuffle(nodes, random());\n    // create collection on these nodes\n    String collectionName = \"testBasic\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 5, 5, 5, 5);\n    create.setMaxShardsPerNode(1);\n    create.setAutoAddReplicas(false);\n    create.setCreateNodeSet(String.join(\",\", nodes));\n    create.process(solrClient);\n\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15)) + \"ms\");\n\n    int KILL_NODES = 8;\n    // kill off a number of nodes\n    for (int i = 0; i < KILL_NODES; i++) {\n      cluster.simRemoveNode(nodes.get(i), false);\n    }\n    // should fully recover\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 90 * KILL_NODES, TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15)) + \"ms\");\n\n    log.info(\"OP COUNTS: \" + cluster.simGetOpCounts());\n    long moveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n\n    // simulate a number of flaky nodes\n    int FLAKY_NODES = 10;\n    int flakyReplicas = 0;\n    for (int cnt = 0; cnt < 10; cnt++) {\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        flakyReplicas += cluster.getSimClusterStateProvider().simGetReplicaInfos(nodes.get(i))\n            .stream().filter(r -> r.getState().equals(Replica.State.ACTIVE)).count();\n        cluster.simRemoveNode(nodes.get(i), false);\n      }\n      cluster.getTimeSource().sleep(TimeUnit.SECONDS.toMillis(waitForSeconds) * 2);\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        final String nodeId = nodes.get(i);\n        cluster.submit(() -> cluster.getSimClusterStateProvider().simRestoreNode(nodeId));\n      }\n    }\n\n    // wait until started == finished\n    TimeOut timeOut = new TimeOut(20 * waitForSeconds * NUM_NODES, TimeUnit.SECONDS, cluster.getTimeSource());\n    while (!timeOut.hasTimedOut()) {\n      if (triggerStartedCount.get() == triggerFinishedCount.get()) {\n        break;\n      }\n      timeOut.sleep(1000);\n    }\n    if (timeOut.hasTimedOut()) {\n      fail(\"did not finish processing all events in time: started=\" + triggerStartedCount.get() + \", finished=\" + triggerFinishedCount.get());\n    }\n\n\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15)) + \"ms\");\n    long newMoveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n    log.info(\"==== Flaky replicas: {}. Additional MOVEREPLICA count: {}\", flakyReplicas, (newMoveReplicaOps - moveReplicaOps));\n    // flaky nodes lead to a number of MOVEREPLICA that is non-zero but lower than the number of flaky replicas\n    assertTrue(\"there should be new MOVERPLICA ops\", newMoveReplicaOps - moveReplicaOps > 0);\n    assertTrue(\"there should be less than flakyReplicas=\" + flakyReplicas + \" MOVEREPLICA ops\",\n        newMoveReplicaOps - moveReplicaOps < flakyReplicas);\n  }\n\n","sourceOld":"  @Test\n  public void testBasic() throws Exception {\n    SolrClient solrClient = cluster.simGetSolrClient();\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger1',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [\" +\n        \"{'name':'start','class':'\" + StartTriggerAction.class.getName() + \"'},\" +\n        \"{'name':'compute','class':'\" + ComputePlanAction.class.getName() + \"'},\" +\n        \"{'name':'execute','class':'\" + ExecutePlanAction.class.getName() + \"'},\" +\n        \"{'name':'test','class':'\" + FinishTriggerAction.class.getName() + \"'}\" +\n        \"]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'foo',\" +\n        \"'trigger' : 'node_lost_trigger1',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED', 'FAILED'],\" +\n        \"'beforeAction' : ['compute', 'execute'],\" +\n        \"'afterAction' : ['compute', 'execute'],\" +\n        \"'class' : '\" + TestTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    cluster.getTimeSource().sleep(5000);\n\n    // pick a few random nodes\n    List<String> nodes = new ArrayList<>();\n    int limit = 75;\n    for (String node : cluster.getClusterStateProvider().getLiveNodes()) {\n      nodes.add(node);\n      if (nodes.size() > limit) {\n        break;\n      }\n    }\n    Collections.shuffle(nodes, random());\n    // create collection on these nodes\n    String collectionName = \"testBasic\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 5, 5, 5, 5);\n    create.setMaxShardsPerNode(1);\n    create.setAutoAddReplicas(false);\n    create.setCreateNodeSet(String.join(\",\", nodes));\n    create.process(solrClient);\n\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15)) + \"ms\");\n\n    int KILL_NODES = 8;\n    // kill off a number of nodes\n    for (int i = 0; i < KILL_NODES; i++) {\n      cluster.simRemoveNode(nodes.get(i), false);\n    }\n    // should fully recover\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 90 * KILL_NODES, TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15)) + \"ms\");\n\n    log.info(\"OP COUNTS: \" + cluster.simGetOpCounts());\n    long moveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n\n    // simulate a number of flaky nodes\n    int FLAKY_NODES = 10;\n    int flakyReplicas = 0;\n    for (int cnt = 0; cnt < 10; cnt++) {\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        flakyReplicas += cluster.getSimClusterStateProvider().simGetReplicaInfos(nodes.get(i))\n            .stream().filter(r -> r.getState().equals(Replica.State.ACTIVE)).count();\n        cluster.simRemoveNode(nodes.get(i), false);\n      }\n      cluster.getTimeSource().sleep(TimeUnit.SECONDS.toMillis(waitForSeconds) * 2);\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        final String nodeId = nodes.get(i);\n        cluster.submit(() -> cluster.getSimClusterStateProvider().simRestoreNode(nodeId));\n      }\n    }\n\n    // wait until started == finished\n    TimeOut timeOut = new TimeOut(20 * waitForSeconds * NUM_NODES, TimeUnit.SECONDS, cluster.getTimeSource());\n    while (!timeOut.hasTimedOut()) {\n      if (triggerStartedCount.get() == triggerFinishedCount.get()) {\n        break;\n      }\n      timeOut.sleep(1000);\n    }\n    if (timeOut.hasTimedOut()) {\n      fail(\"did not finish processing all events in time: started=\" + triggerStartedCount.get() + \", finished=\" + triggerFinishedCount.get());\n    }\n\n\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15)) + \"ms\");\n    long newMoveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n    log.info(\"==== Flaky replicas: {}. Additional MOVEREPLICA count: {}\", flakyReplicas, (newMoveReplicaOps - moveReplicaOps));\n    // flaky nodes lead to a number of MOVEREPLICA that is non-zero but lower than the number of flaky replicas\n    assertTrue(\"there should be new MOVERPLICA ops\", newMoveReplicaOps - moveReplicaOps > 0);\n    assertTrue(\"there should be less than flakyReplicas=\" + flakyReplicas + \" MOVEREPLICA ops\",\n        newMoveReplicaOps - moveReplicaOps < flakyReplicas);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"042b92cf48996255bedb0c3c4bf772d7e06e4dea","date":1534272102,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestLargeCluster#testBasic().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestLargeCluster#testBasic().mjava","sourceNew":"  @Test\n  @LuceneTestCase.BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 2018-06-18\n  public void testBasic() throws Exception {\n    SolrClient solrClient = cluster.simGetSolrClient();\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger1',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [\" +\n        \"{'name':'start','class':'\" + StartTriggerAction.class.getName() + \"'},\" +\n        \"{'name':'compute','class':'\" + ComputePlanAction.class.getName() + \"'},\" +\n        \"{'name':'execute','class':'\" + ExecutePlanAction.class.getName() + \"'},\" +\n        \"{'name':'test','class':'\" + FinishTriggerAction.class.getName() + \"'}\" +\n        \"]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'foo',\" +\n        \"'trigger' : 'node_lost_trigger1',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED', 'FAILED'],\" +\n        \"'beforeAction' : ['compute', 'execute'],\" +\n        \"'afterAction' : ['compute', 'execute'],\" +\n        \"'class' : '\" + TestTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    cluster.getTimeSource().sleep(5000);\n\n    // pick a few random nodes\n    List<String> nodes = new ArrayList<>();\n    int limit = 75;\n    for (String node : cluster.getClusterStateProvider().getLiveNodes()) {\n      nodes.add(node);\n      if (nodes.size() > limit) {\n        break;\n      }\n    }\n    Collections.shuffle(nodes, random());\n    // create collection on these nodes\n    String collectionName = \"testBasic\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 5, 5, 5, 5);\n    create.setMaxShardsPerNode(1);\n    create.setAutoAddReplicas(false);\n    create.setCreateNodeSet(String.join(\",\", nodes));\n    create.process(solrClient);\n\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15, false, true)) + \"ms\");\n\n    int KILL_NODES = 8;\n    // kill off a number of nodes\n    for (int i = 0; i < KILL_NODES; i++) {\n      cluster.simRemoveNode(nodes.get(i), false);\n    }\n    // should fully recover\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 90 * KILL_NODES, TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15, false, true)) + \"ms\");\n\n    log.info(\"OP COUNTS: \" + cluster.simGetOpCounts());\n    long moveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n\n    // simulate a number of flaky nodes\n    int FLAKY_NODES = 10;\n    int flakyReplicas = 0;\n    for (int cnt = 0; cnt < 10; cnt++) {\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        flakyReplicas += cluster.getSimClusterStateProvider().simGetReplicaInfos(nodes.get(i))\n            .stream().filter(r -> r.getState().equals(Replica.State.ACTIVE)).count();\n        cluster.simRemoveNode(nodes.get(i), false);\n      }\n      cluster.getTimeSource().sleep(TimeUnit.SECONDS.toMillis(waitForSeconds) * 2);\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        final String nodeId = nodes.get(i);\n        cluster.submit(() -> cluster.getSimClusterStateProvider().simRestoreNode(nodeId));\n      }\n    }\n\n    // wait until started == finished\n    TimeOut timeOut = new TimeOut(20 * waitForSeconds * NUM_NODES, TimeUnit.SECONDS, cluster.getTimeSource());\n    while (!timeOut.hasTimedOut()) {\n      if (triggerStartedCount.get() == triggerFinishedCount.get()) {\n        break;\n      }\n      timeOut.sleep(1000);\n    }\n    if (timeOut.hasTimedOut()) {\n      fail(\"did not finish processing all events in time: started=\" + triggerStartedCount.get() + \", finished=\" + triggerFinishedCount.get());\n    }\n\n\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15, false, true)) + \"ms\");\n    long newMoveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n    log.info(\"==== Flaky replicas: {}. Additional MOVEREPLICA count: {}\", flakyReplicas, (newMoveReplicaOps - moveReplicaOps));\n    // flaky nodes lead to a number of MOVEREPLICA that is non-zero but lower than the number of flaky replicas\n    assertTrue(\"there should be new MOVERPLICA ops\", newMoveReplicaOps - moveReplicaOps > 0);\n    assertTrue(\"there should be less than flakyReplicas=\" + flakyReplicas + \" MOVEREPLICA ops\",\n        newMoveReplicaOps - moveReplicaOps < flakyReplicas);\n  }\n\n","sourceOld":"  @Test\n  @LuceneTestCase.BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 2018-06-18\n  public void testBasic() throws Exception {\n    SolrClient solrClient = cluster.simGetSolrClient();\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger1',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [\" +\n        \"{'name':'start','class':'\" + StartTriggerAction.class.getName() + \"'},\" +\n        \"{'name':'compute','class':'\" + ComputePlanAction.class.getName() + \"'},\" +\n        \"{'name':'execute','class':'\" + ExecutePlanAction.class.getName() + \"'},\" +\n        \"{'name':'test','class':'\" + FinishTriggerAction.class.getName() + \"'}\" +\n        \"]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'foo',\" +\n        \"'trigger' : 'node_lost_trigger1',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED', 'FAILED'],\" +\n        \"'beforeAction' : ['compute', 'execute'],\" +\n        \"'afterAction' : ['compute', 'execute'],\" +\n        \"'class' : '\" + TestTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    cluster.getTimeSource().sleep(5000);\n\n    // pick a few random nodes\n    List<String> nodes = new ArrayList<>();\n    int limit = 75;\n    for (String node : cluster.getClusterStateProvider().getLiveNodes()) {\n      nodes.add(node);\n      if (nodes.size() > limit) {\n        break;\n      }\n    }\n    Collections.shuffle(nodes, random());\n    // create collection on these nodes\n    String collectionName = \"testBasic\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 5, 5, 5, 5);\n    create.setMaxShardsPerNode(1);\n    create.setAutoAddReplicas(false);\n    create.setCreateNodeSet(String.join(\",\", nodes));\n    create.process(solrClient);\n\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15)) + \"ms\");\n\n    int KILL_NODES = 8;\n    // kill off a number of nodes\n    for (int i = 0; i < KILL_NODES; i++) {\n      cluster.simRemoveNode(nodes.get(i), false);\n    }\n    // should fully recover\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 90 * KILL_NODES, TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15)) + \"ms\");\n\n    log.info(\"OP COUNTS: \" + cluster.simGetOpCounts());\n    long moveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n\n    // simulate a number of flaky nodes\n    int FLAKY_NODES = 10;\n    int flakyReplicas = 0;\n    for (int cnt = 0; cnt < 10; cnt++) {\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        flakyReplicas += cluster.getSimClusterStateProvider().simGetReplicaInfos(nodes.get(i))\n            .stream().filter(r -> r.getState().equals(Replica.State.ACTIVE)).count();\n        cluster.simRemoveNode(nodes.get(i), false);\n      }\n      cluster.getTimeSource().sleep(TimeUnit.SECONDS.toMillis(waitForSeconds) * 2);\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        final String nodeId = nodes.get(i);\n        cluster.submit(() -> cluster.getSimClusterStateProvider().simRestoreNode(nodeId));\n      }\n    }\n\n    // wait until started == finished\n    TimeOut timeOut = new TimeOut(20 * waitForSeconds * NUM_NODES, TimeUnit.SECONDS, cluster.getTimeSource());\n    while (!timeOut.hasTimedOut()) {\n      if (triggerStartedCount.get() == triggerFinishedCount.get()) {\n        break;\n      }\n      timeOut.sleep(1000);\n    }\n    if (timeOut.hasTimedOut()) {\n      fail(\"did not finish processing all events in time: started=\" + triggerStartedCount.get() + \", finished=\" + triggerFinishedCount.get());\n    }\n\n\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15)) + \"ms\");\n    long newMoveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n    log.info(\"==== Flaky replicas: {}. Additional MOVEREPLICA count: {}\", flakyReplicas, (newMoveReplicaOps - moveReplicaOps));\n    // flaky nodes lead to a number of MOVEREPLICA that is non-zero but lower than the number of flaky replicas\n    assertTrue(\"there should be new MOVERPLICA ops\", newMoveReplicaOps - moveReplicaOps > 0);\n    assertTrue(\"there should be less than flakyReplicas=\" + flakyReplicas + \" MOVEREPLICA ops\",\n        newMoveReplicaOps - moveReplicaOps < flakyReplicas);\n  }\n\n","bugFix":["9c6c0dad4932399aec99b4818086cb1772773916"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a6a5c1c40529f15b445e6720dfde1967e139bff1","date":1535375643,"type":5,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimLargeCluster#testBasic().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestLargeCluster#testBasic().mjava","sourceNew":"  @Test\n  @LuceneTestCase.BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 2018-06-18\n  public void testBasic() throws Exception {\n    SolrClient solrClient = cluster.simGetSolrClient();\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger1',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [\" +\n        \"{'name':'start','class':'\" + StartTriggerAction.class.getName() + \"'},\" +\n        \"{'name':'compute','class':'\" + ComputePlanAction.class.getName() + \"'},\" +\n        \"{'name':'execute','class':'\" + ExecutePlanAction.class.getName() + \"'},\" +\n        \"{'name':'test','class':'\" + FinishTriggerAction.class.getName() + \"'}\" +\n        \"]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'foo',\" +\n        \"'trigger' : 'node_lost_trigger1',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED', 'FAILED'],\" +\n        \"'beforeAction' : ['compute', 'execute'],\" +\n        \"'afterAction' : ['compute', 'execute'],\" +\n        \"'class' : '\" + TestTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    cluster.getTimeSource().sleep(5000);\n\n    // pick a few random nodes\n    List<String> nodes = new ArrayList<>();\n    int limit = 75;\n    for (String node : cluster.getClusterStateProvider().getLiveNodes()) {\n      nodes.add(node);\n      if (nodes.size() > limit) {\n        break;\n      }\n    }\n    Collections.shuffle(nodes, random());\n    // create collection on these nodes\n    String collectionName = \"testBasic\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 5, 5, 5, 5);\n    create.setMaxShardsPerNode(1);\n    create.setAutoAddReplicas(false);\n    create.setCreateNodeSet(String.join(\",\", nodes));\n    create.process(solrClient);\n\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15, false, true)) + \"ms\");\n\n    int KILL_NODES = 8;\n    // kill off a number of nodes\n    for (int i = 0; i < KILL_NODES; i++) {\n      cluster.simRemoveNode(nodes.get(i), false);\n    }\n    // should fully recover\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 90 * KILL_NODES, TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15, false, true)) + \"ms\");\n\n    log.info(\"OP COUNTS: \" + cluster.simGetOpCounts());\n    long moveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n\n    // simulate a number of flaky nodes\n    int FLAKY_NODES = 10;\n    int flakyReplicas = 0;\n    for (int cnt = 0; cnt < 10; cnt++) {\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        flakyReplicas += cluster.getSimClusterStateProvider().simGetReplicaInfos(nodes.get(i))\n            .stream().filter(r -> r.getState().equals(Replica.State.ACTIVE)).count();\n        cluster.simRemoveNode(nodes.get(i), false);\n      }\n      cluster.getTimeSource().sleep(TimeUnit.SECONDS.toMillis(waitForSeconds) * 2);\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        final String nodeId = nodes.get(i);\n        cluster.submit(() -> cluster.getSimClusterStateProvider().simRestoreNode(nodeId));\n      }\n    }\n\n    // wait until started == finished\n    TimeOut timeOut = new TimeOut(20 * waitForSeconds * NUM_NODES, TimeUnit.SECONDS, cluster.getTimeSource());\n    while (!timeOut.hasTimedOut()) {\n      if (triggerStartedCount.get() == triggerFinishedCount.get()) {\n        break;\n      }\n      timeOut.sleep(1000);\n    }\n    if (timeOut.hasTimedOut()) {\n      fail(\"did not finish processing all events in time: started=\" + triggerStartedCount.get() + \", finished=\" + triggerFinishedCount.get());\n    }\n\n\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15, false, true)) + \"ms\");\n    long newMoveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n    log.info(\"==== Flaky replicas: {}. Additional MOVEREPLICA count: {}\", flakyReplicas, (newMoveReplicaOps - moveReplicaOps));\n    // flaky nodes lead to a number of MOVEREPLICA that is non-zero but lower than the number of flaky replicas\n    assertTrue(\"there should be new MOVERPLICA ops\", newMoveReplicaOps - moveReplicaOps > 0);\n    assertTrue(\"there should be less than flakyReplicas=\" + flakyReplicas + \" MOVEREPLICA ops\",\n        newMoveReplicaOps - moveReplicaOps < flakyReplicas);\n  }\n\n","sourceOld":"  @Test\n  @LuceneTestCase.BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 2018-06-18\n  public void testBasic() throws Exception {\n    SolrClient solrClient = cluster.simGetSolrClient();\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger1',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [\" +\n        \"{'name':'start','class':'\" + StartTriggerAction.class.getName() + \"'},\" +\n        \"{'name':'compute','class':'\" + ComputePlanAction.class.getName() + \"'},\" +\n        \"{'name':'execute','class':'\" + ExecutePlanAction.class.getName() + \"'},\" +\n        \"{'name':'test','class':'\" + FinishTriggerAction.class.getName() + \"'}\" +\n        \"]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'foo',\" +\n        \"'trigger' : 'node_lost_trigger1',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED', 'FAILED'],\" +\n        \"'beforeAction' : ['compute', 'execute'],\" +\n        \"'afterAction' : ['compute', 'execute'],\" +\n        \"'class' : '\" + TestTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    cluster.getTimeSource().sleep(5000);\n\n    // pick a few random nodes\n    List<String> nodes = new ArrayList<>();\n    int limit = 75;\n    for (String node : cluster.getClusterStateProvider().getLiveNodes()) {\n      nodes.add(node);\n      if (nodes.size() > limit) {\n        break;\n      }\n    }\n    Collections.shuffle(nodes, random());\n    // create collection on these nodes\n    String collectionName = \"testBasic\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 5, 5, 5, 5);\n    create.setMaxShardsPerNode(1);\n    create.setAutoAddReplicas(false);\n    create.setCreateNodeSet(String.join(\",\", nodes));\n    create.process(solrClient);\n\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15, false, true)) + \"ms\");\n\n    int KILL_NODES = 8;\n    // kill off a number of nodes\n    for (int i = 0; i < KILL_NODES; i++) {\n      cluster.simRemoveNode(nodes.get(i), false);\n    }\n    // should fully recover\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 90 * KILL_NODES, TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15, false, true)) + \"ms\");\n\n    log.info(\"OP COUNTS: \" + cluster.simGetOpCounts());\n    long moveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n\n    // simulate a number of flaky nodes\n    int FLAKY_NODES = 10;\n    int flakyReplicas = 0;\n    for (int cnt = 0; cnt < 10; cnt++) {\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        flakyReplicas += cluster.getSimClusterStateProvider().simGetReplicaInfos(nodes.get(i))\n            .stream().filter(r -> r.getState().equals(Replica.State.ACTIVE)).count();\n        cluster.simRemoveNode(nodes.get(i), false);\n      }\n      cluster.getTimeSource().sleep(TimeUnit.SECONDS.toMillis(waitForSeconds) * 2);\n      for (int i = KILL_NODES; i < KILL_NODES + FLAKY_NODES; i++) {\n        final String nodeId = nodes.get(i);\n        cluster.submit(() -> cluster.getSimClusterStateProvider().simRestoreNode(nodeId));\n      }\n    }\n\n    // wait until started == finished\n    TimeOut timeOut = new TimeOut(20 * waitForSeconds * NUM_NODES, TimeUnit.SECONDS, cluster.getTimeSource());\n    while (!timeOut.hasTimedOut()) {\n      if (triggerStartedCount.get() == triggerFinishedCount.get()) {\n        break;\n      }\n      timeOut.sleep(1000);\n    }\n    if (timeOut.hasTimedOut()) {\n      fail(\"did not finish processing all events in time: started=\" + triggerStartedCount.get() + \", finished=\" + triggerFinishedCount.get());\n    }\n\n\n    log.info(\"Ready after \" + CloudTestUtils.waitForState(cluster, collectionName, 30 * nodes.size(), TimeUnit.SECONDS,\n        CloudTestUtils.clusterShape(5, 15, false, true)) + \"ms\");\n    long newMoveReplicaOps = cluster.simGetOpCount(CollectionParams.CollectionAction.MOVEREPLICA.name());\n    log.info(\"==== Flaky replicas: {}. Additional MOVEREPLICA count: {}\", flakyReplicas, (newMoveReplicaOps - moveReplicaOps));\n    // flaky nodes lead to a number of MOVEREPLICA that is non-zero but lower than the number of flaky replicas\n    assertTrue(\"there should be new MOVERPLICA ops\", newMoveReplicaOps - moveReplicaOps > 0);\n    assertTrue(\"there should be less than flakyReplicas=\" + flakyReplicas + \" MOVEREPLICA ops\",\n        newMoveReplicaOps - moveReplicaOps < flakyReplicas);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"a6a5c1c40529f15b445e6720dfde1967e139bff1":["042b92cf48996255bedb0c3c4bf772d7e06e4dea"],"1294fc81133ad1c53ea75edf471f5bea39621e68":["9c6c0dad4932399aec99b4818086cb1772773916"],"042b92cf48996255bedb0c3c4bf772d7e06e4dea":["7a7544ad4b63d1b5f556c3da8f9c63d332aa034e"],"9c6c0dad4932399aec99b4818086cb1772773916":["a4422b331d00607258b0ed3e43934306e67764aa"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":["b70042a8a492f7054d480ccdd2be9796510d4327","7a7544ad4b63d1b5f556c3da8f9c63d332aa034e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b70042a8a492f7054d480ccdd2be9796510d4327":["9c6c0dad4932399aec99b4818086cb1772773916","1294fc81133ad1c53ea75edf471f5bea39621e68"],"a4422b331d00607258b0ed3e43934306e67764aa":["1d4bf9d5308dfef350829c28f2b3b2648df1e9b1"],"7a7544ad4b63d1b5f556c3da8f9c63d332aa034e":["1294fc81133ad1c53ea75edf471f5bea39621e68"],"1d4bf9d5308dfef350829c28f2b3b2648df1e9b1":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"f592209545c71895260367152601e9200399776d":["9c6c0dad4932399aec99b4818086cb1772773916","1294fc81133ad1c53ea75edf471f5bea39621e68"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a6a5c1c40529f15b445e6720dfde1967e139bff1"],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":["f592209545c71895260367152601e9200399776d","7a7544ad4b63d1b5f556c3da8f9c63d332aa034e"]},"commit2Childs":{"a6a5c1c40529f15b445e6720dfde1967e139bff1":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"1294fc81133ad1c53ea75edf471f5bea39621e68":["b70042a8a492f7054d480ccdd2be9796510d4327","7a7544ad4b63d1b5f556c3da8f9c63d332aa034e","f592209545c71895260367152601e9200399776d"],"042b92cf48996255bedb0c3c4bf772d7e06e4dea":["a6a5c1c40529f15b445e6720dfde1967e139bff1"],"9c6c0dad4932399aec99b4818086cb1772773916":["1294fc81133ad1c53ea75edf471f5bea39621e68","b70042a8a492f7054d480ccdd2be9796510d4327","f592209545c71895260367152601e9200399776d"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":[],"b70042a8a492f7054d480ccdd2be9796510d4327":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["1d4bf9d5308dfef350829c28f2b3b2648df1e9b1"],"a4422b331d00607258b0ed3e43934306e67764aa":["9c6c0dad4932399aec99b4818086cb1772773916"],"7a7544ad4b63d1b5f556c3da8f9c63d332aa034e":["042b92cf48996255bedb0c3c4bf772d7e06e4dea","0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"1d4bf9d5308dfef350829c28f2b3b2648df1e9b1":["a4422b331d00607258b0ed3e43934306e67764aa"],"f592209545c71895260367152601e9200399776d":["7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":[]},"heads":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","cd5edd1f2b162a5cfa08efd17851a07373a96817","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}