{"path":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamDecoratorTest#testParallelReducerStream().mjava","commits":[{"id":"8ff654a6d1fb7a79aedaa65c23cc052fdc770aaf","date":1522951207,"type":1,"author":"Joel Bernstein","isMerge":false,"pathNew":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamDecoratorTest#testParallelReducerStream().mjava","pathOld":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelReducerStream().mjava","sourceNew":"  @Test\n  public void testParallelReducerStream() throws Exception {\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"1\")\n        .add(id, \"2\", \"a_s\", \"hello0\", \"a_i\", \"2\", \"a_f\", \"2\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\")\n        .add(id, \"1\", \"a_s\", \"hello0\", \"a_i\", \"1\", \"a_f\", \"5\")\n        .add(id, \"5\", \"a_s\", \"hello3\", \"a_i\", \"10\", \"a_f\", \"6\")\n        .add(id, \"6\", \"a_s\", \"hello4\", \"a_i\", \"11\", \"a_f\", \"7\")\n        .add(id, \"7\", \"a_s\", \"hello3\", \"a_i\", \"12\", \"a_f\", \"8\")\n        .add(id, \"8\", \"a_s\", \"hello3\", \"a_i\", \"13\", \"a_f\", \"9\")\n        .add(id, \"9\", \"a_s\", \"hello0\", \"a_i\", \"14\", \"a_f\", \"10\")\n        .commit(cluster.getSolrClient(), COLLECTIONORALIAS);\n\n    StreamContext streamContext = new StreamContext();\n    SolrClientCache solrClientCache = new SolrClientCache();\n    streamContext.setSolrClientCache(solrClientCache);\n\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory streamFactory = new StreamFactory().withCollectionZkHost(COLLECTIONORALIAS, zkHost)\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"group\", GroupOperation.class)\n        .withFunctionName(\"reduce\", ReducerStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class);\n\n\n    try {\n      ParallelStream pstream = (ParallelStream) streamFactory.constructStream(\"parallel(\" + COLLECTIONORALIAS + \", \" +\n          \"reduce(\" +\n          \"search(\" + COLLECTIONORALIAS + \", q=\\\"*:*\\\", fl=\\\"id,a_s,a_i,a_f\\\", sort=\\\"a_s asc,a_f asc\\\", partitionKeys=\\\"a_s\\\"), \" +\n          \"by=\\\"a_s\\\",\" +\n          \"group(sort=\\\"a_i asc\\\", n=\\\"5\\\")), \" +\n          \"workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"a_s asc\\\")\");\n\n      pstream.setStreamContext(streamContext);\n\n      List<Tuple> tuples = getTuples(pstream);\n\n      assert (tuples.size() == 3);\n\n      Tuple t0 = tuples.get(0);\n      List<Map> maps0 = t0.getMaps(\"group\");\n      assertMaps(maps0, 0, 1, 2, 9);\n\n      Tuple t1 = tuples.get(1);\n      List<Map> maps1 = t1.getMaps(\"group\");\n      assertMaps(maps1, 3, 5, 7, 8);\n\n      Tuple t2 = tuples.get(2);\n      List<Map> maps2 = t2.getMaps(\"group\");\n      assertMaps(maps2, 4, 6);\n\n\n      pstream = (ParallelStream) streamFactory.constructStream(\"parallel(\" + COLLECTIONORALIAS + \", \" +\n          \"reduce(\" +\n          \"search(\" + COLLECTIONORALIAS + \", q=\\\"*:*\\\", fl=\\\"id,a_s,a_i,a_f\\\", sort=\\\"a_s desc,a_f asc\\\", partitionKeys=\\\"a_s\\\"), \" +\n          \"by=\\\"a_s\\\", \" +\n          \"group(sort=\\\"a_i desc\\\", n=\\\"5\\\")),\" +\n          \"workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"a_s desc\\\")\");\n\n      pstream.setStreamContext(streamContext);\n      tuples = getTuples(pstream);\n\n      assert (tuples.size() == 3);\n\n      t0 = tuples.get(0);\n      maps0 = t0.getMaps(\"group\");\n      assertMaps(maps0, 6, 4);\n\n\n      t1 = tuples.get(1);\n      maps1 = t1.getMaps(\"group\");\n      assertMaps(maps1, 8, 7, 5, 3);\n\n\n      t2 = tuples.get(2);\n      maps2 = t2.getMaps(\"group\");\n      assertMaps(maps2, 9, 2, 1, 0);\n    } finally {\n      solrClientCache.close();\n    }\n\n  }\n\n","sourceOld":"  @Test\n  public void testParallelReducerStream() throws Exception {\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"1\")\n        .add(id, \"2\", \"a_s\", \"hello0\", \"a_i\", \"2\", \"a_f\", \"2\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\")\n        .add(id, \"1\", \"a_s\", \"hello0\", \"a_i\", \"1\", \"a_f\", \"5\")\n        .add(id, \"5\", \"a_s\", \"hello3\", \"a_i\", \"10\", \"a_f\", \"6\")\n        .add(id, \"6\", \"a_s\", \"hello4\", \"a_i\", \"11\", \"a_f\", \"7\")\n        .add(id, \"7\", \"a_s\", \"hello3\", \"a_i\", \"12\", \"a_f\", \"8\")\n        .add(id, \"8\", \"a_s\", \"hello3\", \"a_i\", \"13\", \"a_f\", \"9\")\n        .add(id, \"9\", \"a_s\", \"hello0\", \"a_i\", \"14\", \"a_f\", \"10\")\n        .commit(cluster.getSolrClient(), COLLECTIONORALIAS);\n\n    StreamContext streamContext = new StreamContext();\n    SolrClientCache solrClientCache = new SolrClientCache();\n    streamContext.setSolrClientCache(solrClientCache);\n\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory streamFactory = new StreamFactory().withCollectionZkHost(COLLECTIONORALIAS, zkHost)\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"group\", GroupOperation.class)\n        .withFunctionName(\"reduce\", ReducerStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class);\n\n\n    try {\n      ParallelStream pstream = (ParallelStream) streamFactory.constructStream(\"parallel(\" + COLLECTIONORALIAS + \", \" +\n          \"reduce(\" +\n          \"search(\" + COLLECTIONORALIAS + \", q=\\\"*:*\\\", fl=\\\"id,a_s,a_i,a_f\\\", sort=\\\"a_s asc,a_f asc\\\", partitionKeys=\\\"a_s\\\"), \" +\n          \"by=\\\"a_s\\\",\" +\n          \"group(sort=\\\"a_i asc\\\", n=\\\"5\\\")), \" +\n          \"workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"a_s asc\\\")\");\n\n      pstream.setStreamContext(streamContext);\n\n      List<Tuple> tuples = getTuples(pstream);\n\n      assert (tuples.size() == 3);\n\n      Tuple t0 = tuples.get(0);\n      List<Map> maps0 = t0.getMaps(\"group\");\n      assertMaps(maps0, 0, 1, 2, 9);\n\n      Tuple t1 = tuples.get(1);\n      List<Map> maps1 = t1.getMaps(\"group\");\n      assertMaps(maps1, 3, 5, 7, 8);\n\n      Tuple t2 = tuples.get(2);\n      List<Map> maps2 = t2.getMaps(\"group\");\n      assertMaps(maps2, 4, 6);\n\n\n      pstream = (ParallelStream) streamFactory.constructStream(\"parallel(\" + COLLECTIONORALIAS + \", \" +\n          \"reduce(\" +\n          \"search(\" + COLLECTIONORALIAS + \", q=\\\"*:*\\\", fl=\\\"id,a_s,a_i,a_f\\\", sort=\\\"a_s desc,a_f asc\\\", partitionKeys=\\\"a_s\\\"), \" +\n          \"by=\\\"a_s\\\", \" +\n          \"group(sort=\\\"a_i desc\\\", n=\\\"5\\\")),\" +\n          \"workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"a_s desc\\\")\");\n\n      pstream.setStreamContext(streamContext);\n      tuples = getTuples(pstream);\n\n      assert (tuples.size() == 3);\n\n      t0 = tuples.get(0);\n      maps0 = t0.getMaps(\"group\");\n      assertMaps(maps0, 6, 4);\n\n\n      t1 = tuples.get(1);\n      maps1 = t1.getMaps(\"group\");\n      assertMaps(maps1, 8, 7, 5, 3);\n\n\n      t2 = tuples.get(2);\n      maps2 = t2.getMaps(\"group\");\n      assertMaps(maps2, 9, 2, 1, 0);\n    } finally {\n      solrClientCache.close();\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"05a3c9b5f1dfb39879069eb1dac3ca104d3e4108","date":1533256859,"type":3,"author":"Erick","isMerge":false,"pathNew":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamDecoratorTest#testParallelReducerStream().mjava","pathOld":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamDecoratorTest#testParallelReducerStream().mjava","sourceNew":"  @Test\n  @LuceneTestCase.BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 2-Aug-2018\n  public void testParallelReducerStream() throws Exception {\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"1\")\n        .add(id, \"2\", \"a_s\", \"hello0\", \"a_i\", \"2\", \"a_f\", \"2\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\")\n        .add(id, \"1\", \"a_s\", \"hello0\", \"a_i\", \"1\", \"a_f\", \"5\")\n        .add(id, \"5\", \"a_s\", \"hello3\", \"a_i\", \"10\", \"a_f\", \"6\")\n        .add(id, \"6\", \"a_s\", \"hello4\", \"a_i\", \"11\", \"a_f\", \"7\")\n        .add(id, \"7\", \"a_s\", \"hello3\", \"a_i\", \"12\", \"a_f\", \"8\")\n        .add(id, \"8\", \"a_s\", \"hello3\", \"a_i\", \"13\", \"a_f\", \"9\")\n        .add(id, \"9\", \"a_s\", \"hello0\", \"a_i\", \"14\", \"a_f\", \"10\")\n        .commit(cluster.getSolrClient(), COLLECTIONORALIAS);\n\n    StreamContext streamContext = new StreamContext();\n    SolrClientCache solrClientCache = new SolrClientCache();\n    streamContext.setSolrClientCache(solrClientCache);\n\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory streamFactory = new StreamFactory().withCollectionZkHost(COLLECTIONORALIAS, zkHost)\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"group\", GroupOperation.class)\n        .withFunctionName(\"reduce\", ReducerStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class);\n\n\n    try {\n      ParallelStream pstream = (ParallelStream) streamFactory.constructStream(\"parallel(\" + COLLECTIONORALIAS + \", \" +\n          \"reduce(\" +\n          \"search(\" + COLLECTIONORALIAS + \", q=\\\"*:*\\\", fl=\\\"id,a_s,a_i,a_f\\\", sort=\\\"a_s asc,a_f asc\\\", partitionKeys=\\\"a_s\\\"), \" +\n          \"by=\\\"a_s\\\",\" +\n          \"group(sort=\\\"a_i asc\\\", n=\\\"5\\\")), \" +\n          \"workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"a_s asc\\\")\");\n\n      pstream.setStreamContext(streamContext);\n\n      List<Tuple> tuples = getTuples(pstream);\n\n      assert (tuples.size() == 3);\n\n      Tuple t0 = tuples.get(0);\n      List<Map> maps0 = t0.getMaps(\"group\");\n      assertMaps(maps0, 0, 1, 2, 9);\n\n      Tuple t1 = tuples.get(1);\n      List<Map> maps1 = t1.getMaps(\"group\");\n      assertMaps(maps1, 3, 5, 7, 8);\n\n      Tuple t2 = tuples.get(2);\n      List<Map> maps2 = t2.getMaps(\"group\");\n      assertMaps(maps2, 4, 6);\n\n\n      pstream = (ParallelStream) streamFactory.constructStream(\"parallel(\" + COLLECTIONORALIAS + \", \" +\n          \"reduce(\" +\n          \"search(\" + COLLECTIONORALIAS + \", q=\\\"*:*\\\", fl=\\\"id,a_s,a_i,a_f\\\", sort=\\\"a_s desc,a_f asc\\\", partitionKeys=\\\"a_s\\\"), \" +\n          \"by=\\\"a_s\\\", \" +\n          \"group(sort=\\\"a_i desc\\\", n=\\\"5\\\")),\" +\n          \"workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"a_s desc\\\")\");\n\n      pstream.setStreamContext(streamContext);\n      tuples = getTuples(pstream);\n\n      assert (tuples.size() == 3);\n\n      t0 = tuples.get(0);\n      maps0 = t0.getMaps(\"group\");\n      assertMaps(maps0, 6, 4);\n\n\n      t1 = tuples.get(1);\n      maps1 = t1.getMaps(\"group\");\n      assertMaps(maps1, 8, 7, 5, 3);\n\n\n      t2 = tuples.get(2);\n      maps2 = t2.getMaps(\"group\");\n      assertMaps(maps2, 9, 2, 1, 0);\n    } finally {\n      solrClientCache.close();\n    }\n\n  }\n\n","sourceOld":"  @Test\n  public void testParallelReducerStream() throws Exception {\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"1\")\n        .add(id, \"2\", \"a_s\", \"hello0\", \"a_i\", \"2\", \"a_f\", \"2\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\")\n        .add(id, \"1\", \"a_s\", \"hello0\", \"a_i\", \"1\", \"a_f\", \"5\")\n        .add(id, \"5\", \"a_s\", \"hello3\", \"a_i\", \"10\", \"a_f\", \"6\")\n        .add(id, \"6\", \"a_s\", \"hello4\", \"a_i\", \"11\", \"a_f\", \"7\")\n        .add(id, \"7\", \"a_s\", \"hello3\", \"a_i\", \"12\", \"a_f\", \"8\")\n        .add(id, \"8\", \"a_s\", \"hello3\", \"a_i\", \"13\", \"a_f\", \"9\")\n        .add(id, \"9\", \"a_s\", \"hello0\", \"a_i\", \"14\", \"a_f\", \"10\")\n        .commit(cluster.getSolrClient(), COLLECTIONORALIAS);\n\n    StreamContext streamContext = new StreamContext();\n    SolrClientCache solrClientCache = new SolrClientCache();\n    streamContext.setSolrClientCache(solrClientCache);\n\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory streamFactory = new StreamFactory().withCollectionZkHost(COLLECTIONORALIAS, zkHost)\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"group\", GroupOperation.class)\n        .withFunctionName(\"reduce\", ReducerStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class);\n\n\n    try {\n      ParallelStream pstream = (ParallelStream) streamFactory.constructStream(\"parallel(\" + COLLECTIONORALIAS + \", \" +\n          \"reduce(\" +\n          \"search(\" + COLLECTIONORALIAS + \", q=\\\"*:*\\\", fl=\\\"id,a_s,a_i,a_f\\\", sort=\\\"a_s asc,a_f asc\\\", partitionKeys=\\\"a_s\\\"), \" +\n          \"by=\\\"a_s\\\",\" +\n          \"group(sort=\\\"a_i asc\\\", n=\\\"5\\\")), \" +\n          \"workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"a_s asc\\\")\");\n\n      pstream.setStreamContext(streamContext);\n\n      List<Tuple> tuples = getTuples(pstream);\n\n      assert (tuples.size() == 3);\n\n      Tuple t0 = tuples.get(0);\n      List<Map> maps0 = t0.getMaps(\"group\");\n      assertMaps(maps0, 0, 1, 2, 9);\n\n      Tuple t1 = tuples.get(1);\n      List<Map> maps1 = t1.getMaps(\"group\");\n      assertMaps(maps1, 3, 5, 7, 8);\n\n      Tuple t2 = tuples.get(2);\n      List<Map> maps2 = t2.getMaps(\"group\");\n      assertMaps(maps2, 4, 6);\n\n\n      pstream = (ParallelStream) streamFactory.constructStream(\"parallel(\" + COLLECTIONORALIAS + \", \" +\n          \"reduce(\" +\n          \"search(\" + COLLECTIONORALIAS + \", q=\\\"*:*\\\", fl=\\\"id,a_s,a_i,a_f\\\", sort=\\\"a_s desc,a_f asc\\\", partitionKeys=\\\"a_s\\\"), \" +\n          \"by=\\\"a_s\\\", \" +\n          \"group(sort=\\\"a_i desc\\\", n=\\\"5\\\")),\" +\n          \"workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"a_s desc\\\")\");\n\n      pstream.setStreamContext(streamContext);\n      tuples = getTuples(pstream);\n\n      assert (tuples.size() == 3);\n\n      t0 = tuples.get(0);\n      maps0 = t0.getMaps(\"group\");\n      assertMaps(maps0, 6, 4);\n\n\n      t1 = tuples.get(1);\n      maps1 = t1.getMaps(\"group\");\n      assertMaps(maps1, 8, 7, 5, 3);\n\n\n      t2 = tuples.get(2);\n      maps2 = t2.getMaps(\"group\");\n      assertMaps(maps2, 9, 2, 1, 0);\n    } finally {\n      solrClientCache.close();\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b73cc5cc718a5ccdc940b7e3ecbf17e6c145d233","date":1543335722,"type":3,"author":"Joel Bernstein","isMerge":false,"pathNew":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamDecoratorTest#testParallelReducerStream().mjava","pathOld":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamDecoratorTest#testParallelReducerStream().mjava","sourceNew":"  @Test\n  @LuceneTestCase.BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 2-Aug-2018\n  public void testParallelReducerStream() throws Exception {\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"1\")\n        .add(id, \"2\", \"a_s\", \"hello0\", \"a_i\", \"2\", \"a_f\", \"2\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\")\n        .add(id, \"1\", \"a_s\", \"hello0\", \"a_i\", \"1\", \"a_f\", \"5\")\n        .add(id, \"5\", \"a_s\", \"hello3\", \"a_i\", \"10\", \"a_f\", \"6\")\n        .add(id, \"6\", \"a_s\", \"hello4\", \"a_i\", \"11\", \"a_f\", \"7\")\n        .add(id, \"7\", \"a_s\", \"hello3\", \"a_i\", \"12\", \"a_f\", \"8\")\n        .add(id, \"8\", \"a_s\", \"hello3\", \"a_i\", \"13\", \"a_f\", \"9\")\n        .add(id, \"9\", \"a_s\", \"hello0\", \"a_i\", \"14\", \"a_f\", \"10\")\n        .commit(cluster.getSolrClient(), COLLECTIONORALIAS);\n\n    StreamContext streamContext = new StreamContext();\n    SolrClientCache solrClientCache = new SolrClientCache();\n    streamContext.setSolrClientCache(solrClientCache);\n\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory streamFactory = new StreamFactory().withCollectionZkHost(COLLECTIONORALIAS, zkHost)\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"group\", GroupOperation.class)\n        .withFunctionName(\"reduce\", ReducerStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class);\n\n\n    try {\n      ParallelStream pstream = (ParallelStream) streamFactory.constructStream(\"parallel(\" + COLLECTIONORALIAS + \", \" +\n          \"reduce(\" +\n          \"search(\" + COLLECTIONORALIAS + \", q=\\\"*:*\\\", fl=\\\"id,a_s,a_i,a_f\\\", sort=\\\"a_s asc,a_f asc\\\", partitionKeys=\\\"a_s\\\", qt=\\\"/export\\\"), \" +\n          \"by=\\\"a_s\\\",\" +\n          \"group(sort=\\\"a_i asc\\\", n=\\\"5\\\")), \" +\n          \"workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"a_s asc\\\")\");\n\n      pstream.setStreamContext(streamContext);\n\n      List<Tuple> tuples = getTuples(pstream);\n\n      assert (tuples.size() == 3);\n\n      Tuple t0 = tuples.get(0);\n      List<Map> maps0 = t0.getMaps(\"group\");\n      assertMaps(maps0, 0, 1, 2, 9);\n\n      Tuple t1 = tuples.get(1);\n      List<Map> maps1 = t1.getMaps(\"group\");\n      assertMaps(maps1, 3, 5, 7, 8);\n\n      Tuple t2 = tuples.get(2);\n      List<Map> maps2 = t2.getMaps(\"group\");\n      assertMaps(maps2, 4, 6);\n\n\n      pstream = (ParallelStream) streamFactory.constructStream(\"parallel(\" + COLLECTIONORALIAS + \", \" +\n          \"reduce(\" +\n          \"search(\" + COLLECTIONORALIAS + \", q=\\\"*:*\\\", fl=\\\"id,a_s,a_i,a_f\\\", sort=\\\"a_s desc,a_f asc\\\", partitionKeys=\\\"a_s\\\", qt=\\\"/export\\\"), \" +\n          \"by=\\\"a_s\\\", \" +\n          \"group(sort=\\\"a_i desc\\\", n=\\\"5\\\")),\" +\n          \"workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"a_s desc\\\")\");\n\n      pstream.setStreamContext(streamContext);\n      tuples = getTuples(pstream);\n\n      assert (tuples.size() == 3);\n\n      t0 = tuples.get(0);\n      maps0 = t0.getMaps(\"group\");\n      assertMaps(maps0, 6, 4);\n\n\n      t1 = tuples.get(1);\n      maps1 = t1.getMaps(\"group\");\n      assertMaps(maps1, 8, 7, 5, 3);\n\n\n      t2 = tuples.get(2);\n      maps2 = t2.getMaps(\"group\");\n      assertMaps(maps2, 9, 2, 1, 0);\n    } finally {\n      solrClientCache.close();\n    }\n\n  }\n\n","sourceOld":"  @Test\n  @LuceneTestCase.BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 2-Aug-2018\n  public void testParallelReducerStream() throws Exception {\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"1\")\n        .add(id, \"2\", \"a_s\", \"hello0\", \"a_i\", \"2\", \"a_f\", \"2\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\")\n        .add(id, \"1\", \"a_s\", \"hello0\", \"a_i\", \"1\", \"a_f\", \"5\")\n        .add(id, \"5\", \"a_s\", \"hello3\", \"a_i\", \"10\", \"a_f\", \"6\")\n        .add(id, \"6\", \"a_s\", \"hello4\", \"a_i\", \"11\", \"a_f\", \"7\")\n        .add(id, \"7\", \"a_s\", \"hello3\", \"a_i\", \"12\", \"a_f\", \"8\")\n        .add(id, \"8\", \"a_s\", \"hello3\", \"a_i\", \"13\", \"a_f\", \"9\")\n        .add(id, \"9\", \"a_s\", \"hello0\", \"a_i\", \"14\", \"a_f\", \"10\")\n        .commit(cluster.getSolrClient(), COLLECTIONORALIAS);\n\n    StreamContext streamContext = new StreamContext();\n    SolrClientCache solrClientCache = new SolrClientCache();\n    streamContext.setSolrClientCache(solrClientCache);\n\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory streamFactory = new StreamFactory().withCollectionZkHost(COLLECTIONORALIAS, zkHost)\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"group\", GroupOperation.class)\n        .withFunctionName(\"reduce\", ReducerStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class);\n\n\n    try {\n      ParallelStream pstream = (ParallelStream) streamFactory.constructStream(\"parallel(\" + COLLECTIONORALIAS + \", \" +\n          \"reduce(\" +\n          \"search(\" + COLLECTIONORALIAS + \", q=\\\"*:*\\\", fl=\\\"id,a_s,a_i,a_f\\\", sort=\\\"a_s asc,a_f asc\\\", partitionKeys=\\\"a_s\\\"), \" +\n          \"by=\\\"a_s\\\",\" +\n          \"group(sort=\\\"a_i asc\\\", n=\\\"5\\\")), \" +\n          \"workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"a_s asc\\\")\");\n\n      pstream.setStreamContext(streamContext);\n\n      List<Tuple> tuples = getTuples(pstream);\n\n      assert (tuples.size() == 3);\n\n      Tuple t0 = tuples.get(0);\n      List<Map> maps0 = t0.getMaps(\"group\");\n      assertMaps(maps0, 0, 1, 2, 9);\n\n      Tuple t1 = tuples.get(1);\n      List<Map> maps1 = t1.getMaps(\"group\");\n      assertMaps(maps1, 3, 5, 7, 8);\n\n      Tuple t2 = tuples.get(2);\n      List<Map> maps2 = t2.getMaps(\"group\");\n      assertMaps(maps2, 4, 6);\n\n\n      pstream = (ParallelStream) streamFactory.constructStream(\"parallel(\" + COLLECTIONORALIAS + \", \" +\n          \"reduce(\" +\n          \"search(\" + COLLECTIONORALIAS + \", q=\\\"*:*\\\", fl=\\\"id,a_s,a_i,a_f\\\", sort=\\\"a_s desc,a_f asc\\\", partitionKeys=\\\"a_s\\\"), \" +\n          \"by=\\\"a_s\\\", \" +\n          \"group(sort=\\\"a_i desc\\\", n=\\\"5\\\")),\" +\n          \"workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"a_s desc\\\")\");\n\n      pstream.setStreamContext(streamContext);\n      tuples = getTuples(pstream);\n\n      assert (tuples.size() == 3);\n\n      t0 = tuples.get(0);\n      maps0 = t0.getMaps(\"group\");\n      assertMaps(maps0, 6, 4);\n\n\n      t1 = tuples.get(1);\n      maps1 = t1.getMaps(\"group\");\n      assertMaps(maps1, 8, 7, 5, 3);\n\n\n      t2 = tuples.get(2);\n      maps2 = t2.getMaps(\"group\");\n      assertMaps(maps2, 9, 2, 1, 0);\n    } finally {\n      solrClientCache.close();\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8d35c84fdef07284c122012ca4000d3b7285a66e","date":1545962630,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamDecoratorTest#testParallelReducerStream().mjava","pathOld":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamDecoratorTest#testParallelReducerStream().mjava","sourceNew":"  @Test\n  // commented out on: 24-Dec-2018   @LuceneTestCase.BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 2-Aug-2018\n  public void testParallelReducerStream() throws Exception {\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"1\")\n        .add(id, \"2\", \"a_s\", \"hello0\", \"a_i\", \"2\", \"a_f\", \"2\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\")\n        .add(id, \"1\", \"a_s\", \"hello0\", \"a_i\", \"1\", \"a_f\", \"5\")\n        .add(id, \"5\", \"a_s\", \"hello3\", \"a_i\", \"10\", \"a_f\", \"6\")\n        .add(id, \"6\", \"a_s\", \"hello4\", \"a_i\", \"11\", \"a_f\", \"7\")\n        .add(id, \"7\", \"a_s\", \"hello3\", \"a_i\", \"12\", \"a_f\", \"8\")\n        .add(id, \"8\", \"a_s\", \"hello3\", \"a_i\", \"13\", \"a_f\", \"9\")\n        .add(id, \"9\", \"a_s\", \"hello0\", \"a_i\", \"14\", \"a_f\", \"10\")\n        .commit(cluster.getSolrClient(), COLLECTIONORALIAS);\n\n    StreamContext streamContext = new StreamContext();\n    SolrClientCache solrClientCache = new SolrClientCache();\n    streamContext.setSolrClientCache(solrClientCache);\n\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory streamFactory = new StreamFactory().withCollectionZkHost(COLLECTIONORALIAS, zkHost)\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"group\", GroupOperation.class)\n        .withFunctionName(\"reduce\", ReducerStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class);\n\n\n    try {\n      ParallelStream pstream = (ParallelStream) streamFactory.constructStream(\"parallel(\" + COLLECTIONORALIAS + \", \" +\n          \"reduce(\" +\n          \"search(\" + COLLECTIONORALIAS + \", q=\\\"*:*\\\", fl=\\\"id,a_s,a_i,a_f\\\", sort=\\\"a_s asc,a_f asc\\\", partitionKeys=\\\"a_s\\\", qt=\\\"/export\\\"), \" +\n          \"by=\\\"a_s\\\",\" +\n          \"group(sort=\\\"a_i asc\\\", n=\\\"5\\\")), \" +\n          \"workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"a_s asc\\\")\");\n\n      pstream.setStreamContext(streamContext);\n\n      List<Tuple> tuples = getTuples(pstream);\n\n      assert (tuples.size() == 3);\n\n      Tuple t0 = tuples.get(0);\n      List<Map> maps0 = t0.getMaps(\"group\");\n      assertMaps(maps0, 0, 1, 2, 9);\n\n      Tuple t1 = tuples.get(1);\n      List<Map> maps1 = t1.getMaps(\"group\");\n      assertMaps(maps1, 3, 5, 7, 8);\n\n      Tuple t2 = tuples.get(2);\n      List<Map> maps2 = t2.getMaps(\"group\");\n      assertMaps(maps2, 4, 6);\n\n\n      pstream = (ParallelStream) streamFactory.constructStream(\"parallel(\" + COLLECTIONORALIAS + \", \" +\n          \"reduce(\" +\n          \"search(\" + COLLECTIONORALIAS + \", q=\\\"*:*\\\", fl=\\\"id,a_s,a_i,a_f\\\", sort=\\\"a_s desc,a_f asc\\\", partitionKeys=\\\"a_s\\\", qt=\\\"/export\\\"), \" +\n          \"by=\\\"a_s\\\", \" +\n          \"group(sort=\\\"a_i desc\\\", n=\\\"5\\\")),\" +\n          \"workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"a_s desc\\\")\");\n\n      pstream.setStreamContext(streamContext);\n      tuples = getTuples(pstream);\n\n      assert (tuples.size() == 3);\n\n      t0 = tuples.get(0);\n      maps0 = t0.getMaps(\"group\");\n      assertMaps(maps0, 6, 4);\n\n\n      t1 = tuples.get(1);\n      maps1 = t1.getMaps(\"group\");\n      assertMaps(maps1, 8, 7, 5, 3);\n\n\n      t2 = tuples.get(2);\n      maps2 = t2.getMaps(\"group\");\n      assertMaps(maps2, 9, 2, 1, 0);\n    } finally {\n      solrClientCache.close();\n    }\n\n  }\n\n","sourceOld":"  @Test\n  @LuceneTestCase.BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 2-Aug-2018\n  public void testParallelReducerStream() throws Exception {\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"1\")\n        .add(id, \"2\", \"a_s\", \"hello0\", \"a_i\", \"2\", \"a_f\", \"2\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\")\n        .add(id, \"1\", \"a_s\", \"hello0\", \"a_i\", \"1\", \"a_f\", \"5\")\n        .add(id, \"5\", \"a_s\", \"hello3\", \"a_i\", \"10\", \"a_f\", \"6\")\n        .add(id, \"6\", \"a_s\", \"hello4\", \"a_i\", \"11\", \"a_f\", \"7\")\n        .add(id, \"7\", \"a_s\", \"hello3\", \"a_i\", \"12\", \"a_f\", \"8\")\n        .add(id, \"8\", \"a_s\", \"hello3\", \"a_i\", \"13\", \"a_f\", \"9\")\n        .add(id, \"9\", \"a_s\", \"hello0\", \"a_i\", \"14\", \"a_f\", \"10\")\n        .commit(cluster.getSolrClient(), COLLECTIONORALIAS);\n\n    StreamContext streamContext = new StreamContext();\n    SolrClientCache solrClientCache = new SolrClientCache();\n    streamContext.setSolrClientCache(solrClientCache);\n\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory streamFactory = new StreamFactory().withCollectionZkHost(COLLECTIONORALIAS, zkHost)\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"group\", GroupOperation.class)\n        .withFunctionName(\"reduce\", ReducerStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class);\n\n\n    try {\n      ParallelStream pstream = (ParallelStream) streamFactory.constructStream(\"parallel(\" + COLLECTIONORALIAS + \", \" +\n          \"reduce(\" +\n          \"search(\" + COLLECTIONORALIAS + \", q=\\\"*:*\\\", fl=\\\"id,a_s,a_i,a_f\\\", sort=\\\"a_s asc,a_f asc\\\", partitionKeys=\\\"a_s\\\", qt=\\\"/export\\\"), \" +\n          \"by=\\\"a_s\\\",\" +\n          \"group(sort=\\\"a_i asc\\\", n=\\\"5\\\")), \" +\n          \"workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"a_s asc\\\")\");\n\n      pstream.setStreamContext(streamContext);\n\n      List<Tuple> tuples = getTuples(pstream);\n\n      assert (tuples.size() == 3);\n\n      Tuple t0 = tuples.get(0);\n      List<Map> maps0 = t0.getMaps(\"group\");\n      assertMaps(maps0, 0, 1, 2, 9);\n\n      Tuple t1 = tuples.get(1);\n      List<Map> maps1 = t1.getMaps(\"group\");\n      assertMaps(maps1, 3, 5, 7, 8);\n\n      Tuple t2 = tuples.get(2);\n      List<Map> maps2 = t2.getMaps(\"group\");\n      assertMaps(maps2, 4, 6);\n\n\n      pstream = (ParallelStream) streamFactory.constructStream(\"parallel(\" + COLLECTIONORALIAS + \", \" +\n          \"reduce(\" +\n          \"search(\" + COLLECTIONORALIAS + \", q=\\\"*:*\\\", fl=\\\"id,a_s,a_i,a_f\\\", sort=\\\"a_s desc,a_f asc\\\", partitionKeys=\\\"a_s\\\", qt=\\\"/export\\\"), \" +\n          \"by=\\\"a_s\\\", \" +\n          \"group(sort=\\\"a_i desc\\\", n=\\\"5\\\")),\" +\n          \"workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"a_s desc\\\")\");\n\n      pstream.setStreamContext(streamContext);\n      tuples = getTuples(pstream);\n\n      assert (tuples.size() == 3);\n\n      t0 = tuples.get(0);\n      maps0 = t0.getMaps(\"group\");\n      assertMaps(maps0, 6, 4);\n\n\n      t1 = tuples.get(1);\n      maps1 = t1.getMaps(\"group\");\n      assertMaps(maps1, 8, 7, 5, 3);\n\n\n      t2 = tuples.get(2);\n      maps2 = t2.getMaps(\"group\");\n      assertMaps(maps2, 9, 2, 1, 0);\n    } finally {\n      solrClientCache.close();\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8a1cae9aea470e88146567017129e8280d21ca76","date":1563504024,"type":3,"author":"Chris Hostetter","isMerge":false,"pathNew":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamDecoratorTest#testParallelReducerStream().mjava","pathOld":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamDecoratorTest#testParallelReducerStream().mjava","sourceNew":"  @Test\n  public void testParallelReducerStream() throws Exception {\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"1\")\n        .add(id, \"2\", \"a_s\", \"hello0\", \"a_i\", \"2\", \"a_f\", \"2\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\")\n        .add(id, \"1\", \"a_s\", \"hello0\", \"a_i\", \"1\", \"a_f\", \"5\")\n        .add(id, \"5\", \"a_s\", \"hello3\", \"a_i\", \"10\", \"a_f\", \"6\")\n        .add(id, \"6\", \"a_s\", \"hello4\", \"a_i\", \"11\", \"a_f\", \"7\")\n        .add(id, \"7\", \"a_s\", \"hello3\", \"a_i\", \"12\", \"a_f\", \"8\")\n        .add(id, \"8\", \"a_s\", \"hello3\", \"a_i\", \"13\", \"a_f\", \"9\")\n        .add(id, \"9\", \"a_s\", \"hello0\", \"a_i\", \"14\", \"a_f\", \"10\")\n        .commit(cluster.getSolrClient(), COLLECTIONORALIAS);\n\n    StreamContext streamContext = new StreamContext();\n    SolrClientCache solrClientCache = new SolrClientCache();\n    streamContext.setSolrClientCache(solrClientCache);\n\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory streamFactory = new StreamFactory().withCollectionZkHost(COLLECTIONORALIAS, zkHost)\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"group\", GroupOperation.class)\n        .withFunctionName(\"reduce\", ReducerStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class);\n\n\n    try {\n      ParallelStream pstream = (ParallelStream) streamFactory.constructStream(\"parallel(\" + COLLECTIONORALIAS + \", \" +\n          \"reduce(\" +\n          \"search(\" + COLLECTIONORALIAS + \", q=\\\"*:*\\\", fl=\\\"id,a_s,a_i,a_f\\\", sort=\\\"a_s asc,a_f asc\\\", partitionKeys=\\\"a_s\\\", qt=\\\"/export\\\"), \" +\n          \"by=\\\"a_s\\\",\" +\n          \"group(sort=\\\"a_i asc\\\", n=\\\"5\\\")), \" +\n          \"workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"a_s asc\\\")\");\n\n      pstream.setStreamContext(streamContext);\n\n      List<Tuple> tuples = getTuples(pstream);\n\n      assert (tuples.size() == 3);\n\n      Tuple t0 = tuples.get(0);\n      List<Map> maps0 = t0.getMaps(\"group\");\n      assertMaps(maps0, 0, 1, 2, 9);\n\n      Tuple t1 = tuples.get(1);\n      List<Map> maps1 = t1.getMaps(\"group\");\n      assertMaps(maps1, 3, 5, 7, 8);\n\n      Tuple t2 = tuples.get(2);\n      List<Map> maps2 = t2.getMaps(\"group\");\n      assertMaps(maps2, 4, 6);\n\n\n      pstream = (ParallelStream) streamFactory.constructStream(\"parallel(\" + COLLECTIONORALIAS + \", \" +\n          \"reduce(\" +\n          \"search(\" + COLLECTIONORALIAS + \", q=\\\"*:*\\\", fl=\\\"id,a_s,a_i,a_f\\\", sort=\\\"a_s desc,a_f asc\\\", partitionKeys=\\\"a_s\\\", qt=\\\"/export\\\"), \" +\n          \"by=\\\"a_s\\\", \" +\n          \"group(sort=\\\"a_i desc\\\", n=\\\"5\\\")),\" +\n          \"workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"a_s desc\\\")\");\n\n      pstream.setStreamContext(streamContext);\n      tuples = getTuples(pstream);\n\n      assert (tuples.size() == 3);\n\n      t0 = tuples.get(0);\n      maps0 = t0.getMaps(\"group\");\n      assertMaps(maps0, 6, 4);\n\n\n      t1 = tuples.get(1);\n      maps1 = t1.getMaps(\"group\");\n      assertMaps(maps1, 8, 7, 5, 3);\n\n\n      t2 = tuples.get(2);\n      maps2 = t2.getMaps(\"group\");\n      assertMaps(maps2, 9, 2, 1, 0);\n    } finally {\n      solrClientCache.close();\n    }\n\n  }\n\n","sourceOld":"  @Test\n  // commented out on: 24-Dec-2018   @LuceneTestCase.BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 2-Aug-2018\n  public void testParallelReducerStream() throws Exception {\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"1\")\n        .add(id, \"2\", \"a_s\", \"hello0\", \"a_i\", \"2\", \"a_f\", \"2\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\")\n        .add(id, \"1\", \"a_s\", \"hello0\", \"a_i\", \"1\", \"a_f\", \"5\")\n        .add(id, \"5\", \"a_s\", \"hello3\", \"a_i\", \"10\", \"a_f\", \"6\")\n        .add(id, \"6\", \"a_s\", \"hello4\", \"a_i\", \"11\", \"a_f\", \"7\")\n        .add(id, \"7\", \"a_s\", \"hello3\", \"a_i\", \"12\", \"a_f\", \"8\")\n        .add(id, \"8\", \"a_s\", \"hello3\", \"a_i\", \"13\", \"a_f\", \"9\")\n        .add(id, \"9\", \"a_s\", \"hello0\", \"a_i\", \"14\", \"a_f\", \"10\")\n        .commit(cluster.getSolrClient(), COLLECTIONORALIAS);\n\n    StreamContext streamContext = new StreamContext();\n    SolrClientCache solrClientCache = new SolrClientCache();\n    streamContext.setSolrClientCache(solrClientCache);\n\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory streamFactory = new StreamFactory().withCollectionZkHost(COLLECTIONORALIAS, zkHost)\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"group\", GroupOperation.class)\n        .withFunctionName(\"reduce\", ReducerStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class);\n\n\n    try {\n      ParallelStream pstream = (ParallelStream) streamFactory.constructStream(\"parallel(\" + COLLECTIONORALIAS + \", \" +\n          \"reduce(\" +\n          \"search(\" + COLLECTIONORALIAS + \", q=\\\"*:*\\\", fl=\\\"id,a_s,a_i,a_f\\\", sort=\\\"a_s asc,a_f asc\\\", partitionKeys=\\\"a_s\\\", qt=\\\"/export\\\"), \" +\n          \"by=\\\"a_s\\\",\" +\n          \"group(sort=\\\"a_i asc\\\", n=\\\"5\\\")), \" +\n          \"workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"a_s asc\\\")\");\n\n      pstream.setStreamContext(streamContext);\n\n      List<Tuple> tuples = getTuples(pstream);\n\n      assert (tuples.size() == 3);\n\n      Tuple t0 = tuples.get(0);\n      List<Map> maps0 = t0.getMaps(\"group\");\n      assertMaps(maps0, 0, 1, 2, 9);\n\n      Tuple t1 = tuples.get(1);\n      List<Map> maps1 = t1.getMaps(\"group\");\n      assertMaps(maps1, 3, 5, 7, 8);\n\n      Tuple t2 = tuples.get(2);\n      List<Map> maps2 = t2.getMaps(\"group\");\n      assertMaps(maps2, 4, 6);\n\n\n      pstream = (ParallelStream) streamFactory.constructStream(\"parallel(\" + COLLECTIONORALIAS + \", \" +\n          \"reduce(\" +\n          \"search(\" + COLLECTIONORALIAS + \", q=\\\"*:*\\\", fl=\\\"id,a_s,a_i,a_f\\\", sort=\\\"a_s desc,a_f asc\\\", partitionKeys=\\\"a_s\\\", qt=\\\"/export\\\"), \" +\n          \"by=\\\"a_s\\\", \" +\n          \"group(sort=\\\"a_i desc\\\", n=\\\"5\\\")),\" +\n          \"workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"a_s desc\\\")\");\n\n      pstream.setStreamContext(streamContext);\n      tuples = getTuples(pstream);\n\n      assert (tuples.size() == 3);\n\n      t0 = tuples.get(0);\n      maps0 = t0.getMaps(\"group\");\n      assertMaps(maps0, 6, 4);\n\n\n      t1 = tuples.get(1);\n      maps1 = t1.getMaps(\"group\");\n      assertMaps(maps1, 8, 7, 5, 3);\n\n\n      t2 = tuples.get(2);\n      maps2 = t2.getMaps(\"group\");\n      assertMaps(maps2, 9, 2, 1, 0);\n    } finally {\n      solrClientCache.close();\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9ba1b632c041956c93c41aa1143d16a567014891","date":1592328473,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamDecoratorTest#testParallelReducerStream().mjava","pathOld":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamDecoratorTest#testParallelReducerStream().mjava","sourceNew":"  @Test\n  public void testParallelReducerStream() throws Exception {\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"1\")\n        .add(id, \"2\", \"a_s\", \"hello0\", \"a_i\", \"2\", \"a_f\", \"2\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\")\n        .add(id, \"1\", \"a_s\", \"hello0\", \"a_i\", \"1\", \"a_f\", \"5\")\n        .add(id, \"5\", \"a_s\", \"hello3\", \"a_i\", \"10\", \"a_f\", \"6\")\n        .add(id, \"6\", \"a_s\", \"hello4\", \"a_i\", \"11\", \"a_f\", \"7\")\n        .add(id, \"7\", \"a_s\", \"hello3\", \"a_i\", \"12\", \"a_f\", \"8\")\n        .add(id, \"8\", \"a_s\", \"hello3\", \"a_i\", \"13\", \"a_f\", \"9\")\n        .add(id, \"9\", \"a_s\", \"hello0\", \"a_i\", \"14\", \"a_f\", \"10\")\n        .commit(cluster.getSolrClient(), COLLECTIONORALIAS);\n\n    StreamContext streamContext = new StreamContext();\n    SolrClientCache solrClientCache = new SolrClientCache();\n    streamContext.setSolrClientCache(solrClientCache);\n\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory streamFactory = new StreamFactory().withCollectionZkHost(COLLECTIONORALIAS, zkHost)\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"group\", GroupOperation.class)\n        .withFunctionName(\"reduce\", ReducerStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class);\n\n\n    try {\n      ParallelStream pstream = (ParallelStream) streamFactory.constructStream(\"parallel(\" + COLLECTIONORALIAS + \", \" +\n          \"reduce(\" +\n          \"search(\" + COLLECTIONORALIAS + \", q=\\\"*:*\\\", fl=\\\"id,a_s,a_i,a_f\\\", sort=\\\"a_s asc,a_f asc\\\", partitionKeys=\\\"a_s\\\", qt=\\\"/export\\\"), \" +\n          \"by=\\\"a_s\\\",\" +\n          \"group(sort=\\\"a_i asc\\\", n=\\\"5\\\")), \" +\n          \"workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"a_s asc\\\")\");\n\n      pstream.setStreamContext(streamContext);\n\n      List<Tuple> tuples = getTuples(pstream);\n\n      assert (tuples.size() == 3);\n\n      Tuple t0 = tuples.get(0);\n      @SuppressWarnings({\"rawtypes\"})\n      List<Map> maps0 = t0.getMaps(\"group\");\n      assertMaps(maps0, 0, 1, 2, 9);\n\n      Tuple t1 = tuples.get(1);\n      @SuppressWarnings({\"rawtypes\"})\n      List<Map> maps1 = t1.getMaps(\"group\");\n      assertMaps(maps1, 3, 5, 7, 8);\n\n      Tuple t2 = tuples.get(2);\n      @SuppressWarnings({\"rawtypes\"})\n      List<Map> maps2 = t2.getMaps(\"group\");\n      assertMaps(maps2, 4, 6);\n\n\n      pstream = (ParallelStream) streamFactory.constructStream(\"parallel(\" + COLLECTIONORALIAS + \", \" +\n          \"reduce(\" +\n          \"search(\" + COLLECTIONORALIAS + \", q=\\\"*:*\\\", fl=\\\"id,a_s,a_i,a_f\\\", sort=\\\"a_s desc,a_f asc\\\", partitionKeys=\\\"a_s\\\", qt=\\\"/export\\\"), \" +\n          \"by=\\\"a_s\\\", \" +\n          \"group(sort=\\\"a_i desc\\\", n=\\\"5\\\")),\" +\n          \"workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"a_s desc\\\")\");\n\n      pstream.setStreamContext(streamContext);\n      tuples = getTuples(pstream);\n\n      assert (tuples.size() == 3);\n\n      t0 = tuples.get(0);\n      maps0 = t0.getMaps(\"group\");\n      assertMaps(maps0, 6, 4);\n\n\n      t1 = tuples.get(1);\n      maps1 = t1.getMaps(\"group\");\n      assertMaps(maps1, 8, 7, 5, 3);\n\n\n      t2 = tuples.get(2);\n      maps2 = t2.getMaps(\"group\");\n      assertMaps(maps2, 9, 2, 1, 0);\n    } finally {\n      solrClientCache.close();\n    }\n\n  }\n\n","sourceOld":"  @Test\n  public void testParallelReducerStream() throws Exception {\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"1\")\n        .add(id, \"2\", \"a_s\", \"hello0\", \"a_i\", \"2\", \"a_f\", \"2\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\")\n        .add(id, \"1\", \"a_s\", \"hello0\", \"a_i\", \"1\", \"a_f\", \"5\")\n        .add(id, \"5\", \"a_s\", \"hello3\", \"a_i\", \"10\", \"a_f\", \"6\")\n        .add(id, \"6\", \"a_s\", \"hello4\", \"a_i\", \"11\", \"a_f\", \"7\")\n        .add(id, \"7\", \"a_s\", \"hello3\", \"a_i\", \"12\", \"a_f\", \"8\")\n        .add(id, \"8\", \"a_s\", \"hello3\", \"a_i\", \"13\", \"a_f\", \"9\")\n        .add(id, \"9\", \"a_s\", \"hello0\", \"a_i\", \"14\", \"a_f\", \"10\")\n        .commit(cluster.getSolrClient(), COLLECTIONORALIAS);\n\n    StreamContext streamContext = new StreamContext();\n    SolrClientCache solrClientCache = new SolrClientCache();\n    streamContext.setSolrClientCache(solrClientCache);\n\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory streamFactory = new StreamFactory().withCollectionZkHost(COLLECTIONORALIAS, zkHost)\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"group\", GroupOperation.class)\n        .withFunctionName(\"reduce\", ReducerStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class);\n\n\n    try {\n      ParallelStream pstream = (ParallelStream) streamFactory.constructStream(\"parallel(\" + COLLECTIONORALIAS + \", \" +\n          \"reduce(\" +\n          \"search(\" + COLLECTIONORALIAS + \", q=\\\"*:*\\\", fl=\\\"id,a_s,a_i,a_f\\\", sort=\\\"a_s asc,a_f asc\\\", partitionKeys=\\\"a_s\\\", qt=\\\"/export\\\"), \" +\n          \"by=\\\"a_s\\\",\" +\n          \"group(sort=\\\"a_i asc\\\", n=\\\"5\\\")), \" +\n          \"workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"a_s asc\\\")\");\n\n      pstream.setStreamContext(streamContext);\n\n      List<Tuple> tuples = getTuples(pstream);\n\n      assert (tuples.size() == 3);\n\n      Tuple t0 = tuples.get(0);\n      List<Map> maps0 = t0.getMaps(\"group\");\n      assertMaps(maps0, 0, 1, 2, 9);\n\n      Tuple t1 = tuples.get(1);\n      List<Map> maps1 = t1.getMaps(\"group\");\n      assertMaps(maps1, 3, 5, 7, 8);\n\n      Tuple t2 = tuples.get(2);\n      List<Map> maps2 = t2.getMaps(\"group\");\n      assertMaps(maps2, 4, 6);\n\n\n      pstream = (ParallelStream) streamFactory.constructStream(\"parallel(\" + COLLECTIONORALIAS + \", \" +\n          \"reduce(\" +\n          \"search(\" + COLLECTIONORALIAS + \", q=\\\"*:*\\\", fl=\\\"id,a_s,a_i,a_f\\\", sort=\\\"a_s desc,a_f asc\\\", partitionKeys=\\\"a_s\\\", qt=\\\"/export\\\"), \" +\n          \"by=\\\"a_s\\\", \" +\n          \"group(sort=\\\"a_i desc\\\", n=\\\"5\\\")),\" +\n          \"workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"a_s desc\\\")\");\n\n      pstream.setStreamContext(streamContext);\n      tuples = getTuples(pstream);\n\n      assert (tuples.size() == 3);\n\n      t0 = tuples.get(0);\n      maps0 = t0.getMaps(\"group\");\n      assertMaps(maps0, 6, 4);\n\n\n      t1 = tuples.get(1);\n      maps1 = t1.getMaps(\"group\");\n      assertMaps(maps1, 8, 7, 5, 3);\n\n\n      t2 = tuples.get(2);\n      maps2 = t2.getMaps(\"group\");\n      assertMaps(maps2, 9, 2, 1, 0);\n    } finally {\n      solrClientCache.close();\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"9ba1b632c041956c93c41aa1143d16a567014891":["8a1cae9aea470e88146567017129e8280d21ca76"],"05a3c9b5f1dfb39879069eb1dac3ca104d3e4108":["8ff654a6d1fb7a79aedaa65c23cc052fdc770aaf"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"8a1cae9aea470e88146567017129e8280d21ca76":["8d35c84fdef07284c122012ca4000d3b7285a66e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9ba1b632c041956c93c41aa1143d16a567014891"],"8d35c84fdef07284c122012ca4000d3b7285a66e":["b73cc5cc718a5ccdc940b7e3ecbf17e6c145d233"],"b73cc5cc718a5ccdc940b7e3ecbf17e6c145d233":["05a3c9b5f1dfb39879069eb1dac3ca104d3e4108"],"8ff654a6d1fb7a79aedaa65c23cc052fdc770aaf":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"9ba1b632c041956c93c41aa1143d16a567014891":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"05a3c9b5f1dfb39879069eb1dac3ca104d3e4108":["b73cc5cc718a5ccdc940b7e3ecbf17e6c145d233"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["8ff654a6d1fb7a79aedaa65c23cc052fdc770aaf"],"8a1cae9aea470e88146567017129e8280d21ca76":["9ba1b632c041956c93c41aa1143d16a567014891"],"8ff654a6d1fb7a79aedaa65c23cc052fdc770aaf":["05a3c9b5f1dfb39879069eb1dac3ca104d3e4108"],"8d35c84fdef07284c122012ca4000d3b7285a66e":["8a1cae9aea470e88146567017129e8280d21ca76"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"b73cc5cc718a5ccdc940b7e3ecbf17e6c145d233":["8d35c84fdef07284c122012ca4000d3b7285a66e"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}