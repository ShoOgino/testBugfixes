{"path":"src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,SegmentReader[],int[],Map,boolean,boolean,int).mjava","commits":[{"id":"961159f13aece73fbb30aea720e77a2237e8bafd","date":1247258916,"type":1,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,SegmentReader[],int[],Map,boolean,boolean,int).mjava","pathOld":"src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,SegmentReader[],int[],Map,boolean,boolean).mjava","sourceNew":"  /** This contructor is only used for {@link #reopen()} */\n  DirectoryReader(Directory directory, SegmentInfos infos, SegmentReader[] oldReaders, int[] oldStarts,\n                  Map oldNormsCache, boolean readOnly, boolean doClone, int termInfosIndexDivisor) throws IOException {\n    this.directory = directory;\n    this.readOnly = readOnly;\n    this.segmentInfos = infos;\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    if (!readOnly) {\n      // We assume that this segments_N was previously\n      // properly sync'd:\n      synced.addAll(infos.files(directory, true));\n    }\n\n    // we put the old SegmentReaders in a map, that allows us\n    // to lookup a reader using its segment name\n    Map segmentReaders = new HashMap();\n\n    if (oldReaders != null) {\n      // create a Map SegmentName->SegmentReader\n      for (int i = 0; i < oldReaders.length; i++) {\n        segmentReaders.put(oldReaders[i].getSegmentName(), new Integer(i));\n      }\n    }\n    \n    SegmentReader[] newReaders = new SegmentReader[infos.size()];\n    \n    // remember which readers are shared between the old and the re-opened\n    // DirectoryReader - we have to incRef those readers\n    boolean[] readerShared = new boolean[infos.size()];\n    \n    for (int i = infos.size() - 1; i>=0; i--) {\n      // find SegmentReader for this segment\n      Integer oldReaderIndex = (Integer) segmentReaders.get(infos.info(i).name);\n      if (oldReaderIndex == null) {\n        // this is a new segment, no old SegmentReader can be reused\n        newReaders[i] = null;\n      } else {\n        // there is an old reader for this segment - we'll try to reopen it\n        newReaders[i] = oldReaders[oldReaderIndex.intValue()];\n      }\n\n      boolean success = false;\n      try {\n        SegmentReader newReader;\n        if (newReaders[i] == null || infos.info(i).getUseCompoundFile() != newReaders[i].getSegmentInfo().getUseCompoundFile()) {\n\n          // We should never see a totally new segment during cloning\n          assert !doClone;\n\n          // this is a new reader; in case we hit an exception we can close it safely\n          newReader = SegmentReader.get(readOnly, infos.info(i), termInfosIndexDivisor);\n        } else {\n          newReader = newReaders[i].reopenSegment(infos.info(i), doClone, readOnly);\n        }\n        if (newReader == newReaders[i]) {\n          // this reader will be shared between the old and the new one,\n          // so we must incRef it\n          readerShared[i] = true;\n          newReader.incRef();\n        } else {\n          readerShared[i] = false;\n          newReaders[i] = newReader;\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          for (i++; i < infos.size(); i++) {\n            if (newReaders[i] != null) {\n              try {\n                if (!readerShared[i]) {\n                  // this is a new subReader that is not used by the old one,\n                  // we can close it\n                  newReaders[i].close();\n                } else {\n                  // this subReader is also used by the old reader, so instead\n                  // closing we must decRef it\n                  newReaders[i].decRef();\n                }\n              } catch (IOException ignore) {\n                // keep going - we want to clean up as much as possible\n              }\n            }\n          }\n        }\n      }\n    }    \n    \n    // initialize the readers to calculate maxDoc before we try to reuse the old normsCache\n    initialize(newReaders);\n    \n    // try to copy unchanged norms from the old normsCache to the new one\n    if (oldNormsCache != null) {\n      Iterator it = oldNormsCache.entrySet().iterator();\n      while (it.hasNext()) {\n        Map.Entry entry = (Map.Entry) it.next();\n        String field = (String) entry.getKey();\n        if (!hasNorms(field)) {\n          continue;\n        }\n\n        byte[] oldBytes = (byte[]) entry.getValue();\n\n        byte[] bytes = new byte[maxDoc()];\n\n        for (int i = 0; i < subReaders.length; i++) {\n          Integer oldReaderIndex = ((Integer) segmentReaders.get(subReaders[i].getSegmentName()));\n\n          // this SegmentReader was not re-opened, we can copy all of its norms \n          if (oldReaderIndex != null &&\n               (oldReaders[oldReaderIndex.intValue()] == subReaders[i] \n                 || oldReaders[oldReaderIndex.intValue()].norms.get(field) == subReaders[i].norms.get(field))) {\n            // we don't have to synchronize here: either this constructor is called from a SegmentReader,\n            // in which case no old norms cache is present, or it is called from MultiReader.reopen(),\n            // which is synchronized\n            System.arraycopy(oldBytes, oldStarts[oldReaderIndex.intValue()], bytes, starts[i], starts[i+1] - starts[i]);\n          } else {\n            subReaders[i].norms(field, bytes, starts[i]);\n          }\n        }\n\n        normsCache.put(field, bytes);      // update cache\n      }\n    }\n  }\n\n","sourceOld":"  /** This contructor is only used for {@link #reopen()} */\n  DirectoryReader(Directory directory, SegmentInfos infos, SegmentReader[] oldReaders, int[] oldStarts,\n                     Map oldNormsCache, boolean readOnly, boolean doClone) throws IOException {\n    this.directory = directory;\n    this.readOnly = readOnly;\n    this.segmentInfos = infos;\n    if (!readOnly) {\n      // We assume that this segments_N was previously\n      // properly sync'd:\n      synced.addAll(infos.files(directory, true));\n    }\n\n    // we put the old SegmentReaders in a map, that allows us\n    // to lookup a reader using its segment name\n    Map segmentReaders = new HashMap();\n\n    if (oldReaders != null) {\n      // create a Map SegmentName->SegmentReader\n      for (int i = 0; i < oldReaders.length; i++) {\n        segmentReaders.put(oldReaders[i].getSegmentName(), new Integer(i));\n      }\n    }\n    \n    SegmentReader[] newReaders = new SegmentReader[infos.size()];\n    \n    // remember which readers are shared between the old and the re-opened\n    // DirectoryReader - we have to incRef those readers\n    boolean[] readerShared = new boolean[infos.size()];\n    \n    for (int i = infos.size() - 1; i>=0; i--) {\n      // find SegmentReader for this segment\n      Integer oldReaderIndex = (Integer) segmentReaders.get(infos.info(i).name);\n      if (oldReaderIndex == null) {\n        // this is a new segment, no old SegmentReader can be reused\n        newReaders[i] = null;\n      } else {\n        // there is an old reader for this segment - we'll try to reopen it\n        newReaders[i] = oldReaders[oldReaderIndex.intValue()];\n      }\n\n      boolean success = false;\n      try {\n        SegmentReader newReader;\n        if (newReaders[i] == null || infos.info(i).getUseCompoundFile() != newReaders[i].getSegmentInfo().getUseCompoundFile()) {\n\n          // We should never see a totally new segment during cloning\n          assert !doClone;\n\n          // this is a new reader; in case we hit an exception we can close it safely\n          newReader = SegmentReader.get(readOnly, infos.info(i));\n        } else {\n          newReader = newReaders[i].reopenSegment(infos.info(i), doClone, readOnly);\n        }\n        if (newReader == newReaders[i]) {\n          // this reader will be shared between the old and the new one,\n          // so we must incRef it\n          readerShared[i] = true;\n          newReader.incRef();\n        } else {\n          readerShared[i] = false;\n          newReaders[i] = newReader;\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          for (i++; i < infos.size(); i++) {\n            if (newReaders[i] != null) {\n              try {\n                if (!readerShared[i]) {\n                  // this is a new subReader that is not used by the old one,\n                  // we can close it\n                  newReaders[i].close();\n                } else {\n                  // this subReader is also used by the old reader, so instead\n                  // closing we must decRef it\n                  newReaders[i].decRef();\n                }\n              } catch (IOException ignore) {\n                // keep going - we want to clean up as much as possible\n              }\n            }\n          }\n        }\n      }\n    }    \n    \n    // initialize the readers to calculate maxDoc before we try to reuse the old normsCache\n    initialize(newReaders);\n    \n    // try to copy unchanged norms from the old normsCache to the new one\n    if (oldNormsCache != null) {\n      Iterator it = oldNormsCache.entrySet().iterator();\n      while (it.hasNext()) {\n        Map.Entry entry = (Map.Entry) it.next();\n        String field = (String) entry.getKey();\n        if (!hasNorms(field)) {\n          continue;\n        }\n\n        byte[] oldBytes = (byte[]) entry.getValue();\n\n        byte[] bytes = new byte[maxDoc()];\n\n        for (int i = 0; i < subReaders.length; i++) {\n          Integer oldReaderIndex = ((Integer) segmentReaders.get(subReaders[i].getSegmentName()));\n\n          // this SegmentReader was not re-opened, we can copy all of its norms \n          if (oldReaderIndex != null &&\n               (oldReaders[oldReaderIndex.intValue()] == subReaders[i] \n                 || oldReaders[oldReaderIndex.intValue()].norms.get(field) == subReaders[i].norms.get(field))) {\n            // we don't have to synchronize here: either this constructor is called from a SegmentReader,\n            // in which case no old norms cache is present, or it is called from MultiReader.reopen(),\n            // which is synchronized\n            System.arraycopy(oldBytes, oldStarts[oldReaderIndex.intValue()], bytes, starts[i], starts[i+1] - starts[i]);\n          } else {\n            subReaders[i].norms(field, bytes, starts[i]);\n          }\n        }\n\n        normsCache.put(field, bytes);      // update cache\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"add7d922e63099fbce8f0a1b31216df7ef5067f1","date":1252002701,"type":3,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,SegmentReader[],int[],Map,boolean,boolean,int).mjava","pathOld":"src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,SegmentReader[],int[],Map,boolean,boolean,int).mjava","sourceNew":"  /** This constructor is only used for {@link #reopen()} */\n  DirectoryReader(Directory directory, SegmentInfos infos, SegmentReader[] oldReaders, int[] oldStarts,\n                  Map oldNormsCache, boolean readOnly, boolean doClone, int termInfosIndexDivisor) throws IOException {\n    this.directory = directory;\n    this.readOnly = readOnly;\n    this.segmentInfos = infos;\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    if (!readOnly) {\n      // We assume that this segments_N was previously\n      // properly sync'd:\n      synced.addAll(infos.files(directory, true));\n    }\n\n    // we put the old SegmentReaders in a map, that allows us\n    // to lookup a reader using its segment name\n    Map segmentReaders = new HashMap();\n\n    if (oldReaders != null) {\n      // create a Map SegmentName->SegmentReader\n      for (int i = 0; i < oldReaders.length; i++) {\n        segmentReaders.put(oldReaders[i].getSegmentName(), new Integer(i));\n      }\n    }\n    \n    SegmentReader[] newReaders = new SegmentReader[infos.size()];\n    \n    // remember which readers are shared between the old and the re-opened\n    // DirectoryReader - we have to incRef those readers\n    boolean[] readerShared = new boolean[infos.size()];\n    \n    for (int i = infos.size() - 1; i>=0; i--) {\n      // find SegmentReader for this segment\n      Integer oldReaderIndex = (Integer) segmentReaders.get(infos.info(i).name);\n      if (oldReaderIndex == null) {\n        // this is a new segment, no old SegmentReader can be reused\n        newReaders[i] = null;\n      } else {\n        // there is an old reader for this segment - we'll try to reopen it\n        newReaders[i] = oldReaders[oldReaderIndex.intValue()];\n      }\n\n      boolean success = false;\n      try {\n        SegmentReader newReader;\n        if (newReaders[i] == null || infos.info(i).getUseCompoundFile() != newReaders[i].getSegmentInfo().getUseCompoundFile()) {\n\n          // We should never see a totally new segment during cloning\n          assert !doClone;\n\n          // this is a new reader; in case we hit an exception we can close it safely\n          newReader = SegmentReader.get(readOnly, infos.info(i), termInfosIndexDivisor);\n        } else {\n          newReader = newReaders[i].reopenSegment(infos.info(i), doClone, readOnly);\n        }\n        if (newReader == newReaders[i]) {\n          // this reader will be shared between the old and the new one,\n          // so we must incRef it\n          readerShared[i] = true;\n          newReader.incRef();\n        } else {\n          readerShared[i] = false;\n          newReaders[i] = newReader;\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          for (i++; i < infos.size(); i++) {\n            if (newReaders[i] != null) {\n              try {\n                if (!readerShared[i]) {\n                  // this is a new subReader that is not used by the old one,\n                  // we can close it\n                  newReaders[i].close();\n                } else {\n                  // this subReader is also used by the old reader, so instead\n                  // closing we must decRef it\n                  newReaders[i].decRef();\n                }\n              } catch (IOException ignore) {\n                // keep going - we want to clean up as much as possible\n              }\n            }\n          }\n        }\n      }\n    }    \n    \n    // initialize the readers to calculate maxDoc before we try to reuse the old normsCache\n    initialize(newReaders);\n    \n    // try to copy unchanged norms from the old normsCache to the new one\n    if (oldNormsCache != null) {\n      Iterator it = oldNormsCache.entrySet().iterator();\n      while (it.hasNext()) {\n        Map.Entry entry = (Map.Entry) it.next();\n        String field = (String) entry.getKey();\n        if (!hasNorms(field)) {\n          continue;\n        }\n\n        byte[] oldBytes = (byte[]) entry.getValue();\n\n        byte[] bytes = new byte[maxDoc()];\n\n        for (int i = 0; i < subReaders.length; i++) {\n          Integer oldReaderIndex = ((Integer) segmentReaders.get(subReaders[i].getSegmentName()));\n\n          // this SegmentReader was not re-opened, we can copy all of its norms \n          if (oldReaderIndex != null &&\n               (oldReaders[oldReaderIndex.intValue()] == subReaders[i] \n                 || oldReaders[oldReaderIndex.intValue()].norms.get(field) == subReaders[i].norms.get(field))) {\n            // we don't have to synchronize here: either this constructor is called from a SegmentReader,\n            // in which case no old norms cache is present, or it is called from MultiReader.reopen(),\n            // which is synchronized\n            System.arraycopy(oldBytes, oldStarts[oldReaderIndex.intValue()], bytes, starts[i], starts[i+1] - starts[i]);\n          } else {\n            subReaders[i].norms(field, bytes, starts[i]);\n          }\n        }\n\n        normsCache.put(field, bytes);      // update cache\n      }\n    }\n  }\n\n","sourceOld":"  /** This contructor is only used for {@link #reopen()} */\n  DirectoryReader(Directory directory, SegmentInfos infos, SegmentReader[] oldReaders, int[] oldStarts,\n                  Map oldNormsCache, boolean readOnly, boolean doClone, int termInfosIndexDivisor) throws IOException {\n    this.directory = directory;\n    this.readOnly = readOnly;\n    this.segmentInfos = infos;\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    if (!readOnly) {\n      // We assume that this segments_N was previously\n      // properly sync'd:\n      synced.addAll(infos.files(directory, true));\n    }\n\n    // we put the old SegmentReaders in a map, that allows us\n    // to lookup a reader using its segment name\n    Map segmentReaders = new HashMap();\n\n    if (oldReaders != null) {\n      // create a Map SegmentName->SegmentReader\n      for (int i = 0; i < oldReaders.length; i++) {\n        segmentReaders.put(oldReaders[i].getSegmentName(), new Integer(i));\n      }\n    }\n    \n    SegmentReader[] newReaders = new SegmentReader[infos.size()];\n    \n    // remember which readers are shared between the old and the re-opened\n    // DirectoryReader - we have to incRef those readers\n    boolean[] readerShared = new boolean[infos.size()];\n    \n    for (int i = infos.size() - 1; i>=0; i--) {\n      // find SegmentReader for this segment\n      Integer oldReaderIndex = (Integer) segmentReaders.get(infos.info(i).name);\n      if (oldReaderIndex == null) {\n        // this is a new segment, no old SegmentReader can be reused\n        newReaders[i] = null;\n      } else {\n        // there is an old reader for this segment - we'll try to reopen it\n        newReaders[i] = oldReaders[oldReaderIndex.intValue()];\n      }\n\n      boolean success = false;\n      try {\n        SegmentReader newReader;\n        if (newReaders[i] == null || infos.info(i).getUseCompoundFile() != newReaders[i].getSegmentInfo().getUseCompoundFile()) {\n\n          // We should never see a totally new segment during cloning\n          assert !doClone;\n\n          // this is a new reader; in case we hit an exception we can close it safely\n          newReader = SegmentReader.get(readOnly, infos.info(i), termInfosIndexDivisor);\n        } else {\n          newReader = newReaders[i].reopenSegment(infos.info(i), doClone, readOnly);\n        }\n        if (newReader == newReaders[i]) {\n          // this reader will be shared between the old and the new one,\n          // so we must incRef it\n          readerShared[i] = true;\n          newReader.incRef();\n        } else {\n          readerShared[i] = false;\n          newReaders[i] = newReader;\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          for (i++; i < infos.size(); i++) {\n            if (newReaders[i] != null) {\n              try {\n                if (!readerShared[i]) {\n                  // this is a new subReader that is not used by the old one,\n                  // we can close it\n                  newReaders[i].close();\n                } else {\n                  // this subReader is also used by the old reader, so instead\n                  // closing we must decRef it\n                  newReaders[i].decRef();\n                }\n              } catch (IOException ignore) {\n                // keep going - we want to clean up as much as possible\n              }\n            }\n          }\n        }\n      }\n    }    \n    \n    // initialize the readers to calculate maxDoc before we try to reuse the old normsCache\n    initialize(newReaders);\n    \n    // try to copy unchanged norms from the old normsCache to the new one\n    if (oldNormsCache != null) {\n      Iterator it = oldNormsCache.entrySet().iterator();\n      while (it.hasNext()) {\n        Map.Entry entry = (Map.Entry) it.next();\n        String field = (String) entry.getKey();\n        if (!hasNorms(field)) {\n          continue;\n        }\n\n        byte[] oldBytes = (byte[]) entry.getValue();\n\n        byte[] bytes = new byte[maxDoc()];\n\n        for (int i = 0; i < subReaders.length; i++) {\n          Integer oldReaderIndex = ((Integer) segmentReaders.get(subReaders[i].getSegmentName()));\n\n          // this SegmentReader was not re-opened, we can copy all of its norms \n          if (oldReaderIndex != null &&\n               (oldReaders[oldReaderIndex.intValue()] == subReaders[i] \n                 || oldReaders[oldReaderIndex.intValue()].norms.get(field) == subReaders[i].norms.get(field))) {\n            // we don't have to synchronize here: either this constructor is called from a SegmentReader,\n            // in which case no old norms cache is present, or it is called from MultiReader.reopen(),\n            // which is synchronized\n            System.arraycopy(oldBytes, oldStarts[oldReaderIndex.intValue()], bytes, starts[i], starts[i+1] - starts[i]);\n          } else {\n            subReaders[i].norms(field, bytes, starts[i]);\n          }\n        }\n\n        normsCache.put(field, bytes);      // update cache\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6bcde5e3f23911110baa101ed062b544162825b5","date":1254521804,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,SegmentReader[],int[],Map,boolean,boolean,int).mjava","pathOld":"src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,SegmentReader[],int[],Map,boolean,boolean,int).mjava","sourceNew":"  /** This constructor is only used for {@link #reopen()} */\n  DirectoryReader(Directory directory, SegmentInfos infos, SegmentReader[] oldReaders, int[] oldStarts,\n                  Map oldNormsCache, boolean readOnly, boolean doClone, int termInfosIndexDivisor) throws IOException {\n    this.directory = directory;\n    this.readOnly = readOnly;\n    this.segmentInfos = infos;\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    if (!readOnly) {\n      // We assume that this segments_N was previously\n      // properly sync'd:\n      synced.addAll(infos.files(directory, true));\n    }\n\n    // we put the old SegmentReaders in a map, that allows us\n    // to lookup a reader using its segment name\n    Map segmentReaders = new HashMap();\n\n    if (oldReaders != null) {\n      // create a Map SegmentName->SegmentReader\n      for (int i = 0; i < oldReaders.length; i++) {\n        segmentReaders.put(oldReaders[i].getSegmentName(), Integer.valueOf(i));\n      }\n    }\n    \n    SegmentReader[] newReaders = new SegmentReader[infos.size()];\n    \n    // remember which readers are shared between the old and the re-opened\n    // DirectoryReader - we have to incRef those readers\n    boolean[] readerShared = new boolean[infos.size()];\n    \n    for (int i = infos.size() - 1; i>=0; i--) {\n      // find SegmentReader for this segment\n      Integer oldReaderIndex = (Integer) segmentReaders.get(infos.info(i).name);\n      if (oldReaderIndex == null) {\n        // this is a new segment, no old SegmentReader can be reused\n        newReaders[i] = null;\n      } else {\n        // there is an old reader for this segment - we'll try to reopen it\n        newReaders[i] = oldReaders[oldReaderIndex.intValue()];\n      }\n\n      boolean success = false;\n      try {\n        SegmentReader newReader;\n        if (newReaders[i] == null || infos.info(i).getUseCompoundFile() != newReaders[i].getSegmentInfo().getUseCompoundFile()) {\n\n          // We should never see a totally new segment during cloning\n          assert !doClone;\n\n          // this is a new reader; in case we hit an exception we can close it safely\n          newReader = SegmentReader.get(readOnly, infos.info(i), termInfosIndexDivisor);\n        } else {\n          newReader = newReaders[i].reopenSegment(infos.info(i), doClone, readOnly);\n        }\n        if (newReader == newReaders[i]) {\n          // this reader will be shared between the old and the new one,\n          // so we must incRef it\n          readerShared[i] = true;\n          newReader.incRef();\n        } else {\n          readerShared[i] = false;\n          newReaders[i] = newReader;\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          for (i++; i < infos.size(); i++) {\n            if (newReaders[i] != null) {\n              try {\n                if (!readerShared[i]) {\n                  // this is a new subReader that is not used by the old one,\n                  // we can close it\n                  newReaders[i].close();\n                } else {\n                  // this subReader is also used by the old reader, so instead\n                  // closing we must decRef it\n                  newReaders[i].decRef();\n                }\n              } catch (IOException ignore) {\n                // keep going - we want to clean up as much as possible\n              }\n            }\n          }\n        }\n      }\n    }    \n    \n    // initialize the readers to calculate maxDoc before we try to reuse the old normsCache\n    initialize(newReaders);\n    \n    // try to copy unchanged norms from the old normsCache to the new one\n    if (oldNormsCache != null) {\n      Iterator it = oldNormsCache.entrySet().iterator();\n      while (it.hasNext()) {\n        Map.Entry entry = (Map.Entry) it.next();\n        String field = (String) entry.getKey();\n        if (!hasNorms(field)) {\n          continue;\n        }\n\n        byte[] oldBytes = (byte[]) entry.getValue();\n\n        byte[] bytes = new byte[maxDoc()];\n\n        for (int i = 0; i < subReaders.length; i++) {\n          Integer oldReaderIndex = ((Integer) segmentReaders.get(subReaders[i].getSegmentName()));\n\n          // this SegmentReader was not re-opened, we can copy all of its norms \n          if (oldReaderIndex != null &&\n               (oldReaders[oldReaderIndex.intValue()] == subReaders[i] \n                 || oldReaders[oldReaderIndex.intValue()].norms.get(field) == subReaders[i].norms.get(field))) {\n            // we don't have to synchronize here: either this constructor is called from a SegmentReader,\n            // in which case no old norms cache is present, or it is called from MultiReader.reopen(),\n            // which is synchronized\n            System.arraycopy(oldBytes, oldStarts[oldReaderIndex.intValue()], bytes, starts[i], starts[i+1] - starts[i]);\n          } else {\n            subReaders[i].norms(field, bytes, starts[i]);\n          }\n        }\n\n        normsCache.put(field, bytes);      // update cache\n      }\n    }\n  }\n\n","sourceOld":"  /** This constructor is only used for {@link #reopen()} */\n  DirectoryReader(Directory directory, SegmentInfos infos, SegmentReader[] oldReaders, int[] oldStarts,\n                  Map oldNormsCache, boolean readOnly, boolean doClone, int termInfosIndexDivisor) throws IOException {\n    this.directory = directory;\n    this.readOnly = readOnly;\n    this.segmentInfos = infos;\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    if (!readOnly) {\n      // We assume that this segments_N was previously\n      // properly sync'd:\n      synced.addAll(infos.files(directory, true));\n    }\n\n    // we put the old SegmentReaders in a map, that allows us\n    // to lookup a reader using its segment name\n    Map segmentReaders = new HashMap();\n\n    if (oldReaders != null) {\n      // create a Map SegmentName->SegmentReader\n      for (int i = 0; i < oldReaders.length; i++) {\n        segmentReaders.put(oldReaders[i].getSegmentName(), new Integer(i));\n      }\n    }\n    \n    SegmentReader[] newReaders = new SegmentReader[infos.size()];\n    \n    // remember which readers are shared between the old and the re-opened\n    // DirectoryReader - we have to incRef those readers\n    boolean[] readerShared = new boolean[infos.size()];\n    \n    for (int i = infos.size() - 1; i>=0; i--) {\n      // find SegmentReader for this segment\n      Integer oldReaderIndex = (Integer) segmentReaders.get(infos.info(i).name);\n      if (oldReaderIndex == null) {\n        // this is a new segment, no old SegmentReader can be reused\n        newReaders[i] = null;\n      } else {\n        // there is an old reader for this segment - we'll try to reopen it\n        newReaders[i] = oldReaders[oldReaderIndex.intValue()];\n      }\n\n      boolean success = false;\n      try {\n        SegmentReader newReader;\n        if (newReaders[i] == null || infos.info(i).getUseCompoundFile() != newReaders[i].getSegmentInfo().getUseCompoundFile()) {\n\n          // We should never see a totally new segment during cloning\n          assert !doClone;\n\n          // this is a new reader; in case we hit an exception we can close it safely\n          newReader = SegmentReader.get(readOnly, infos.info(i), termInfosIndexDivisor);\n        } else {\n          newReader = newReaders[i].reopenSegment(infos.info(i), doClone, readOnly);\n        }\n        if (newReader == newReaders[i]) {\n          // this reader will be shared between the old and the new one,\n          // so we must incRef it\n          readerShared[i] = true;\n          newReader.incRef();\n        } else {\n          readerShared[i] = false;\n          newReaders[i] = newReader;\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          for (i++; i < infos.size(); i++) {\n            if (newReaders[i] != null) {\n              try {\n                if (!readerShared[i]) {\n                  // this is a new subReader that is not used by the old one,\n                  // we can close it\n                  newReaders[i].close();\n                } else {\n                  // this subReader is also used by the old reader, so instead\n                  // closing we must decRef it\n                  newReaders[i].decRef();\n                }\n              } catch (IOException ignore) {\n                // keep going - we want to clean up as much as possible\n              }\n            }\n          }\n        }\n      }\n    }    \n    \n    // initialize the readers to calculate maxDoc before we try to reuse the old normsCache\n    initialize(newReaders);\n    \n    // try to copy unchanged norms from the old normsCache to the new one\n    if (oldNormsCache != null) {\n      Iterator it = oldNormsCache.entrySet().iterator();\n      while (it.hasNext()) {\n        Map.Entry entry = (Map.Entry) it.next();\n        String field = (String) entry.getKey();\n        if (!hasNorms(field)) {\n          continue;\n        }\n\n        byte[] oldBytes = (byte[]) entry.getValue();\n\n        byte[] bytes = new byte[maxDoc()];\n\n        for (int i = 0; i < subReaders.length; i++) {\n          Integer oldReaderIndex = ((Integer) segmentReaders.get(subReaders[i].getSegmentName()));\n\n          // this SegmentReader was not re-opened, we can copy all of its norms \n          if (oldReaderIndex != null &&\n               (oldReaders[oldReaderIndex.intValue()] == subReaders[i] \n                 || oldReaders[oldReaderIndex.intValue()].norms.get(field) == subReaders[i].norms.get(field))) {\n            // we don't have to synchronize here: either this constructor is called from a SegmentReader,\n            // in which case no old norms cache is present, or it is called from MultiReader.reopen(),\n            // which is synchronized\n            System.arraycopy(oldBytes, oldStarts[oldReaderIndex.intValue()], bytes, starts[i], starts[i+1] - starts[i]);\n          } else {\n            subReaders[i].norms(field, bytes, starts[i]);\n          }\n        }\n\n        normsCache.put(field, bytes);      // update cache\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f011f01db72fa6f556a9a0843944ecee2de4aaa8","date":1255806907,"type":5,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,SegmentReader[],int[],Map[String,byte[]],boolean,boolean,int).mjava","pathOld":"src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,SegmentReader[],int[],Map,boolean,boolean,int).mjava","sourceNew":"  /** This constructor is only used for {@link #reopen()} */\n  DirectoryReader(Directory directory, SegmentInfos infos, SegmentReader[] oldReaders, int[] oldStarts,\n                  Map<String,byte[]> oldNormsCache, boolean readOnly, boolean doClone, int termInfosIndexDivisor) throws IOException {\n    this.directory = directory;\n    this.readOnly = readOnly;\n    this.segmentInfos = infos;\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    if (!readOnly) {\n      // We assume that this segments_N was previously\n      // properly sync'd:\n      synced.addAll(infos.files(directory, true));\n    }\n\n    // we put the old SegmentReaders in a map, that allows us\n    // to lookup a reader using its segment name\n    Map<String,Integer> segmentReaders = new HashMap<String,Integer>();\n\n    if (oldReaders != null) {\n      // create a Map SegmentName->SegmentReader\n      for (int i = 0; i < oldReaders.length; i++) {\n        segmentReaders.put(oldReaders[i].getSegmentName(), Integer.valueOf(i));\n      }\n    }\n    \n    SegmentReader[] newReaders = new SegmentReader[infos.size()];\n    \n    // remember which readers are shared between the old and the re-opened\n    // DirectoryReader - we have to incRef those readers\n    boolean[] readerShared = new boolean[infos.size()];\n    \n    for (int i = infos.size() - 1; i>=0; i--) {\n      // find SegmentReader for this segment\n      Integer oldReaderIndex = (Integer) segmentReaders.get(infos.info(i).name);\n      if (oldReaderIndex == null) {\n        // this is a new segment, no old SegmentReader can be reused\n        newReaders[i] = null;\n      } else {\n        // there is an old reader for this segment - we'll try to reopen it\n        newReaders[i] = oldReaders[oldReaderIndex.intValue()];\n      }\n\n      boolean success = false;\n      try {\n        SegmentReader newReader;\n        if (newReaders[i] == null || infos.info(i).getUseCompoundFile() != newReaders[i].getSegmentInfo().getUseCompoundFile()) {\n\n          // We should never see a totally new segment during cloning\n          assert !doClone;\n\n          // this is a new reader; in case we hit an exception we can close it safely\n          newReader = SegmentReader.get(readOnly, infos.info(i), termInfosIndexDivisor);\n        } else {\n          newReader = newReaders[i].reopenSegment(infos.info(i), doClone, readOnly);\n        }\n        if (newReader == newReaders[i]) {\n          // this reader will be shared between the old and the new one,\n          // so we must incRef it\n          readerShared[i] = true;\n          newReader.incRef();\n        } else {\n          readerShared[i] = false;\n          newReaders[i] = newReader;\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          for (i++; i < infos.size(); i++) {\n            if (newReaders[i] != null) {\n              try {\n                if (!readerShared[i]) {\n                  // this is a new subReader that is not used by the old one,\n                  // we can close it\n                  newReaders[i].close();\n                } else {\n                  // this subReader is also used by the old reader, so instead\n                  // closing we must decRef it\n                  newReaders[i].decRef();\n                }\n              } catch (IOException ignore) {\n                // keep going - we want to clean up as much as possible\n              }\n            }\n          }\n        }\n      }\n    }    \n    \n    // initialize the readers to calculate maxDoc before we try to reuse the old normsCache\n    initialize(newReaders);\n    \n    // try to copy unchanged norms from the old normsCache to the new one\n    if (oldNormsCache != null) {\n      for (Map.Entry<String,byte[]> entry: oldNormsCache.entrySet()) {\n        String field = (String) entry.getKey();\n        if (!hasNorms(field)) {\n          continue;\n        }\n\n        byte[] oldBytes = (byte[]) entry.getValue();\n\n        byte[] bytes = new byte[maxDoc()];\n\n        for (int i = 0; i < subReaders.length; i++) {\n          Integer oldReaderIndex = ((Integer) segmentReaders.get(subReaders[i].getSegmentName()));\n\n          // this SegmentReader was not re-opened, we can copy all of its norms \n          if (oldReaderIndex != null &&\n               (oldReaders[oldReaderIndex.intValue()] == subReaders[i] \n                 || oldReaders[oldReaderIndex.intValue()].norms.get(field) == subReaders[i].norms.get(field))) {\n            // we don't have to synchronize here: either this constructor is called from a SegmentReader,\n            // in which case no old norms cache is present, or it is called from MultiReader.reopen(),\n            // which is synchronized\n            System.arraycopy(oldBytes, oldStarts[oldReaderIndex.intValue()], bytes, starts[i], starts[i+1] - starts[i]);\n          } else {\n            subReaders[i].norms(field, bytes, starts[i]);\n          }\n        }\n\n        normsCache.put(field, bytes);      // update cache\n      }\n    }\n  }\n\n","sourceOld":"  /** This constructor is only used for {@link #reopen()} */\n  DirectoryReader(Directory directory, SegmentInfos infos, SegmentReader[] oldReaders, int[] oldStarts,\n                  Map oldNormsCache, boolean readOnly, boolean doClone, int termInfosIndexDivisor) throws IOException {\n    this.directory = directory;\n    this.readOnly = readOnly;\n    this.segmentInfos = infos;\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    if (!readOnly) {\n      // We assume that this segments_N was previously\n      // properly sync'd:\n      synced.addAll(infos.files(directory, true));\n    }\n\n    // we put the old SegmentReaders in a map, that allows us\n    // to lookup a reader using its segment name\n    Map segmentReaders = new HashMap();\n\n    if (oldReaders != null) {\n      // create a Map SegmentName->SegmentReader\n      for (int i = 0; i < oldReaders.length; i++) {\n        segmentReaders.put(oldReaders[i].getSegmentName(), Integer.valueOf(i));\n      }\n    }\n    \n    SegmentReader[] newReaders = new SegmentReader[infos.size()];\n    \n    // remember which readers are shared between the old and the re-opened\n    // DirectoryReader - we have to incRef those readers\n    boolean[] readerShared = new boolean[infos.size()];\n    \n    for (int i = infos.size() - 1; i>=0; i--) {\n      // find SegmentReader for this segment\n      Integer oldReaderIndex = (Integer) segmentReaders.get(infos.info(i).name);\n      if (oldReaderIndex == null) {\n        // this is a new segment, no old SegmentReader can be reused\n        newReaders[i] = null;\n      } else {\n        // there is an old reader for this segment - we'll try to reopen it\n        newReaders[i] = oldReaders[oldReaderIndex.intValue()];\n      }\n\n      boolean success = false;\n      try {\n        SegmentReader newReader;\n        if (newReaders[i] == null || infos.info(i).getUseCompoundFile() != newReaders[i].getSegmentInfo().getUseCompoundFile()) {\n\n          // We should never see a totally new segment during cloning\n          assert !doClone;\n\n          // this is a new reader; in case we hit an exception we can close it safely\n          newReader = SegmentReader.get(readOnly, infos.info(i), termInfosIndexDivisor);\n        } else {\n          newReader = newReaders[i].reopenSegment(infos.info(i), doClone, readOnly);\n        }\n        if (newReader == newReaders[i]) {\n          // this reader will be shared between the old and the new one,\n          // so we must incRef it\n          readerShared[i] = true;\n          newReader.incRef();\n        } else {\n          readerShared[i] = false;\n          newReaders[i] = newReader;\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          for (i++; i < infos.size(); i++) {\n            if (newReaders[i] != null) {\n              try {\n                if (!readerShared[i]) {\n                  // this is a new subReader that is not used by the old one,\n                  // we can close it\n                  newReaders[i].close();\n                } else {\n                  // this subReader is also used by the old reader, so instead\n                  // closing we must decRef it\n                  newReaders[i].decRef();\n                }\n              } catch (IOException ignore) {\n                // keep going - we want to clean up as much as possible\n              }\n            }\n          }\n        }\n      }\n    }    \n    \n    // initialize the readers to calculate maxDoc before we try to reuse the old normsCache\n    initialize(newReaders);\n    \n    // try to copy unchanged norms from the old normsCache to the new one\n    if (oldNormsCache != null) {\n      Iterator it = oldNormsCache.entrySet().iterator();\n      while (it.hasNext()) {\n        Map.Entry entry = (Map.Entry) it.next();\n        String field = (String) entry.getKey();\n        if (!hasNorms(field)) {\n          continue;\n        }\n\n        byte[] oldBytes = (byte[]) entry.getValue();\n\n        byte[] bytes = new byte[maxDoc()];\n\n        for (int i = 0; i < subReaders.length; i++) {\n          Integer oldReaderIndex = ((Integer) segmentReaders.get(subReaders[i].getSegmentName()));\n\n          // this SegmentReader was not re-opened, we can copy all of its norms \n          if (oldReaderIndex != null &&\n               (oldReaders[oldReaderIndex.intValue()] == subReaders[i] \n                 || oldReaders[oldReaderIndex.intValue()].norms.get(field) == subReaders[i].norms.get(field))) {\n            // we don't have to synchronize here: either this constructor is called from a SegmentReader,\n            // in which case no old norms cache is present, or it is called from MultiReader.reopen(),\n            // which is synchronized\n            System.arraycopy(oldBytes, oldStarts[oldReaderIndex.intValue()], bytes, starts[i], starts[i+1] - starts[i]);\n          } else {\n            subReaders[i].norms(field, bytes, starts[i]);\n          }\n        }\n\n        normsCache.put(field, bytes);      // update cache\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"6bcde5e3f23911110baa101ed062b544162825b5":["add7d922e63099fbce8f0a1b31216df7ef5067f1"],"961159f13aece73fbb30aea720e77a2237e8bafd":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"add7d922e63099fbce8f0a1b31216df7ef5067f1":["961159f13aece73fbb30aea720e77a2237e8bafd"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"f011f01db72fa6f556a9a0843944ecee2de4aaa8":["6bcde5e3f23911110baa101ed062b544162825b5"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["f011f01db72fa6f556a9a0843944ecee2de4aaa8"]},"commit2Childs":{"6bcde5e3f23911110baa101ed062b544162825b5":["f011f01db72fa6f556a9a0843944ecee2de4aaa8"],"961159f13aece73fbb30aea720e77a2237e8bafd":["add7d922e63099fbce8f0a1b31216df7ef5067f1"],"add7d922e63099fbce8f0a1b31216df7ef5067f1":["6bcde5e3f23911110baa101ed062b544162825b5"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["961159f13aece73fbb30aea720e77a2237e8bafd"],"f011f01db72fa6f556a9a0843944ecee2de4aaa8":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}