{"path":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#BKDWriter(int,Directory,String,int,int,int,double,long).mjava","commits":[{"id":"9a5a0f27d9486cd33de88627ed3d2ff8dc5074ca","date":1457777566,"type":1,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#BKDWriter(int,Directory,String,int,int,int,double,long).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#BKDWriter(int,Directory,String,int,int,int,double).mjava","sourceNew":"  public BKDWriter(int maxDoc, Directory tempDir, String tempFileNamePrefix, int numDims, int bytesPerDim, int maxPointsInLeafNode, double maxMBSortInHeap, long totalPointCount) throws IOException {\n    verifyParams(numDims, maxPointsInLeafNode, maxMBSortInHeap, totalPointCount);\n    // We use tracking dir to deal with removing files on exception, so each place that\n    // creates temp files doesn't need crazy try/finally/sucess logic:\n    this.tempDir = new TrackingDirectoryWrapper(tempDir);\n    this.tempFileNamePrefix = tempFileNamePrefix;\n    this.maxPointsInLeafNode = maxPointsInLeafNode;\n    this.numDims = numDims;\n    this.bytesPerDim = bytesPerDim;\n    this.totalPointCount = totalPointCount;\n    docsSeen = new FixedBitSet(maxDoc);\n    packedBytesLength = numDims * bytesPerDim;\n\n    scratchDiff = new byte[bytesPerDim];\n    scratchPackedValue = new byte[packedBytesLength];\n    scratch1 = new byte[packedBytesLength];\n    scratch2 = new byte[packedBytesLength];\n    commonPrefixLengths = new int[numDims];\n\n    minPackedValue = new byte[packedBytesLength];\n    maxPackedValue = new byte[packedBytesLength];\n\n    // If we may have more than 1+Integer.MAX_VALUE values, then we must encode ords with long (8 bytes), else we can use int (4 bytes).\n    longOrds = totalPointCount > Integer.MAX_VALUE;\n\n    // dimensional values (numDims * bytesPerDim) + ord (int or long) + docID (int)\n    if (longOrds) {\n      bytesPerDoc = packedBytesLength + Long.BYTES + Integer.BYTES;\n    } else {\n      bytesPerDoc = packedBytesLength + Integer.BYTES + Integer.BYTES;\n    }\n\n    // As we recurse, we compute temporary partitions of the data, halving the\n    // number of points at each recursion.  Once there are few enough points,\n    // we can switch to sorting in heap instead of offline (on disk).  At any\n    // time in the recursion, we hold the number of points at that level, plus\n    // all recursive halves (i.e. 16 + 8 + 4 + 2) so the memory usage is 2X\n    // what that level would consume, so we multiply by 0.5 to convert from\n    // bytes to points here.  Each dimension has its own sorted partition, so\n    // we must divide by numDims as wel.\n\n    maxPointsSortInHeap = (int) (0.5 * (maxMBSortInHeap * 1024 * 1024) / (bytesPerDoc * numDims));\n\n    // Finally, we must be able to hold at least the leaf node in heap during build:\n    if (maxPointsSortInHeap < maxPointsInLeafNode) {\n      throw new IllegalArgumentException(\"maxMBSortInHeap=\" + maxMBSortInHeap + \" only allows for maxPointsSortInHeap=\" + maxPointsSortInHeap + \", but this is less than maxPointsInLeafNode=\" + maxPointsInLeafNode + \"; either increase maxMBSortInHeap or decrease maxPointsInLeafNode\");\n    }\n\n    // We write first maxPointsSortInHeap in heap, then cutover to offline for additional points:\n    heapPointWriter = new HeapPointWriter(16, maxPointsSortInHeap, packedBytesLength, longOrds);\n\n    this.maxMBSortInHeap = maxMBSortInHeap;\n  }\n\n","sourceOld":"  public BKDWriter(int maxDoc, Directory tempDir, String tempFileNamePrefix, int numDims, int bytesPerDim, int maxPointsInLeafNode, double maxMBSortInHeap) throws IOException {\n    verifyParams(numDims, maxPointsInLeafNode, maxMBSortInHeap);\n    // We use tracking dir to deal with removing files on exception, so each place that\n    // creates temp files doesn't need crazy try/finally/sucess logic:\n    this.tempDir = new TrackingDirectoryWrapper(tempDir);\n    this.tempFileNamePrefix = tempFileNamePrefix;\n    this.maxPointsInLeafNode = maxPointsInLeafNode;\n    this.numDims = numDims;\n    this.bytesPerDim = bytesPerDim;\n    docsSeen = new FixedBitSet(maxDoc);\n    packedBytesLength = numDims * bytesPerDim;\n\n    scratchDiff = new byte[bytesPerDim];\n    scratchPackedValue = new byte[packedBytesLength];\n    scratch1 = new byte[packedBytesLength];\n    scratch2 = new byte[packedBytesLength];\n    commonPrefixLengths = new int[numDims];\n\n    minPackedValue = new byte[packedBytesLength];\n    maxPackedValue = new byte[packedBytesLength];\n\n    // dimensional values (numDims * bytesPerDim) + ord (long) + docID (int)\n    bytesPerDoc = packedBytesLength + Long.BYTES + Integer.BYTES;\n\n    // As we recurse, we compute temporary partitions of the data, halving the\n    // number of points at each recursion.  Once there are few enough points,\n    // we can switch to sorting in heap instead of offline (on disk).  At any\n    // time in the recursion, we hold the number of points at that level, plus\n    // all recursive halves (i.e. 16 + 8 + 4 + 2) so the memory usage is 2X\n    // what that level would consume, so we multiply by 0.5 to convert from\n    // bytes to points here.  Each dimension has its own sorted partition, so\n    // we must divide by numDims as wel.\n\n    maxPointsSortInHeap = (int) (0.5 * (maxMBSortInHeap * 1024 * 1024) / (bytesPerDoc * numDims));\n\n    // Finally, we must be able to hold at least the leaf node in heap during build:\n    if (maxPointsSortInHeap < maxPointsInLeafNode) {\n      throw new IllegalArgumentException(\"maxMBSortInHeap=\" + maxMBSortInHeap + \" only allows for maxPointsSortInHeap=\" + maxPointsSortInHeap + \", but this is less than maxPointsInLeafNode=\" + maxPointsInLeafNode + \"; either increase maxMBSortInHeap or decrease maxPointsInLeafNode\");\n    }\n\n    // We write first maxPointsSortInHeap in heap, then cutover to offline for additional points:\n    heapPointWriter = new HeapPointWriter(16, maxPointsSortInHeap, packedBytesLength);\n\n    this.maxMBSortInHeap = maxMBSortInHeap;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"16ffb58ba57f805651a528311c104f104d9f4573","date":1457861471,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#BKDWriter(int,Directory,String,int,int,int,double,long).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#BKDWriter(int,Directory,String,int,int,int,double,long).mjava","sourceNew":"  public BKDWriter(int maxDoc, Directory tempDir, String tempFileNamePrefix, int numDims, int bytesPerDim, int maxPointsInLeafNode, double maxMBSortInHeap, long totalPointCount) throws IOException {\n    verifyParams(numDims, maxPointsInLeafNode, maxMBSortInHeap, totalPointCount);\n    // We use tracking dir to deal with removing files on exception, so each place that\n    // creates temp files doesn't need crazy try/finally/sucess logic:\n    this.tempDir = new TrackingDirectoryWrapper(tempDir);\n    this.tempFileNamePrefix = tempFileNamePrefix;\n    this.maxPointsInLeafNode = maxPointsInLeafNode;\n    this.numDims = numDims;\n    this.bytesPerDim = bytesPerDim;\n    this.totalPointCount = totalPointCount;\n    docsSeen = new FixedBitSet(maxDoc);\n    packedBytesLength = numDims * bytesPerDim;\n\n    scratchDiff = new byte[bytesPerDim];\n    scratchBytesRef.length = packedBytesLength;\n    scratch1 = new byte[packedBytesLength];\n    scratch2 = new byte[packedBytesLength];\n    commonPrefixLengths = new int[numDims];\n\n    minPackedValue = new byte[packedBytesLength];\n    maxPackedValue = new byte[packedBytesLength];\n\n    // If we may have more than 1+Integer.MAX_VALUE values, then we must encode ords with long (8 bytes), else we can use int (4 bytes).\n    longOrds = totalPointCount > Integer.MAX_VALUE;\n\n    // dimensional values (numDims * bytesPerDim) + ord (int or long) + docID (int)\n    if (longOrds) {\n      bytesPerDoc = packedBytesLength + Long.BYTES + Integer.BYTES;\n    } else {\n      bytesPerDoc = packedBytesLength + Integer.BYTES + Integer.BYTES;\n    }\n\n    // As we recurse, we compute temporary partitions of the data, halving the\n    // number of points at each recursion.  Once there are few enough points,\n    // we can switch to sorting in heap instead of offline (on disk).  At any\n    // time in the recursion, we hold the number of points at that level, plus\n    // all recursive halves (i.e. 16 + 8 + 4 + 2) so the memory usage is 2X\n    // what that level would consume, so we multiply by 0.5 to convert from\n    // bytes to points here.  Each dimension has its own sorted partition, so\n    // we must divide by numDims as wel.\n\n    maxPointsSortInHeap = (int) (0.5 * (maxMBSortInHeap * 1024 * 1024) / (bytesPerDoc * numDims));\n\n    // Finally, we must be able to hold at least the leaf node in heap during build:\n    if (maxPointsSortInHeap < maxPointsInLeafNode) {\n      throw new IllegalArgumentException(\"maxMBSortInHeap=\" + maxMBSortInHeap + \" only allows for maxPointsSortInHeap=\" + maxPointsSortInHeap + \", but this is less than maxPointsInLeafNode=\" + maxPointsInLeafNode + \"; either increase maxMBSortInHeap or decrease maxPointsInLeafNode\");\n    }\n\n    // We write first maxPointsSortInHeap in heap, then cutover to offline for additional points:\n    heapPointWriter = new HeapPointWriter(16, maxPointsSortInHeap, packedBytesLength, longOrds);\n\n    this.maxMBSortInHeap = maxMBSortInHeap;\n  }\n\n","sourceOld":"  public BKDWriter(int maxDoc, Directory tempDir, String tempFileNamePrefix, int numDims, int bytesPerDim, int maxPointsInLeafNode, double maxMBSortInHeap, long totalPointCount) throws IOException {\n    verifyParams(numDims, maxPointsInLeafNode, maxMBSortInHeap, totalPointCount);\n    // We use tracking dir to deal with removing files on exception, so each place that\n    // creates temp files doesn't need crazy try/finally/sucess logic:\n    this.tempDir = new TrackingDirectoryWrapper(tempDir);\n    this.tempFileNamePrefix = tempFileNamePrefix;\n    this.maxPointsInLeafNode = maxPointsInLeafNode;\n    this.numDims = numDims;\n    this.bytesPerDim = bytesPerDim;\n    this.totalPointCount = totalPointCount;\n    docsSeen = new FixedBitSet(maxDoc);\n    packedBytesLength = numDims * bytesPerDim;\n\n    scratchDiff = new byte[bytesPerDim];\n    scratchPackedValue = new byte[packedBytesLength];\n    scratch1 = new byte[packedBytesLength];\n    scratch2 = new byte[packedBytesLength];\n    commonPrefixLengths = new int[numDims];\n\n    minPackedValue = new byte[packedBytesLength];\n    maxPackedValue = new byte[packedBytesLength];\n\n    // If we may have more than 1+Integer.MAX_VALUE values, then we must encode ords with long (8 bytes), else we can use int (4 bytes).\n    longOrds = totalPointCount > Integer.MAX_VALUE;\n\n    // dimensional values (numDims * bytesPerDim) + ord (int or long) + docID (int)\n    if (longOrds) {\n      bytesPerDoc = packedBytesLength + Long.BYTES + Integer.BYTES;\n    } else {\n      bytesPerDoc = packedBytesLength + Integer.BYTES + Integer.BYTES;\n    }\n\n    // As we recurse, we compute temporary partitions of the data, halving the\n    // number of points at each recursion.  Once there are few enough points,\n    // we can switch to sorting in heap instead of offline (on disk).  At any\n    // time in the recursion, we hold the number of points at that level, plus\n    // all recursive halves (i.e. 16 + 8 + 4 + 2) so the memory usage is 2X\n    // what that level would consume, so we multiply by 0.5 to convert from\n    // bytes to points here.  Each dimension has its own sorted partition, so\n    // we must divide by numDims as wel.\n\n    maxPointsSortInHeap = (int) (0.5 * (maxMBSortInHeap * 1024 * 1024) / (bytesPerDoc * numDims));\n\n    // Finally, we must be able to hold at least the leaf node in heap during build:\n    if (maxPointsSortInHeap < maxPointsInLeafNode) {\n      throw new IllegalArgumentException(\"maxMBSortInHeap=\" + maxMBSortInHeap + \" only allows for maxPointsSortInHeap=\" + maxPointsSortInHeap + \", but this is less than maxPointsInLeafNode=\" + maxPointsInLeafNode + \"; either increase maxMBSortInHeap or decrease maxPointsInLeafNode\");\n    }\n\n    // We write first maxPointsSortInHeap in heap, then cutover to offline for additional points:\n    heapPointWriter = new HeapPointWriter(16, maxPointsSortInHeap, packedBytesLength, longOrds);\n\n    this.maxMBSortInHeap = maxMBSortInHeap;\n  }\n\n","bugFix":null,"bugIntro":["1e52a98a3809d9d747b7694f15f80b7018403ef5"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b9028cf27fe30db95667505bb92ecaee8fa3aef7","date":1457861734,"type":3,"author":"Mike McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#BKDWriter(int,Directory,String,int,int,int,double,long).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#BKDWriter(int,Directory,String,int,int,int,double,long).mjava","sourceNew":"  public BKDWriter(int maxDoc, Directory tempDir, String tempFileNamePrefix, int numDims, int bytesPerDim, int maxPointsInLeafNode, double maxMBSortInHeap, long totalPointCount) throws IOException {\n    verifyParams(numDims, maxPointsInLeafNode, maxMBSortInHeap, totalPointCount);\n    // We use tracking dir to deal with removing files on exception, so each place that\n    // creates temp files doesn't need crazy try/finally/sucess logic:\n    this.tempDir = new TrackingDirectoryWrapper(tempDir);\n    this.tempFileNamePrefix = tempFileNamePrefix;\n    this.maxPointsInLeafNode = maxPointsInLeafNode;\n    this.numDims = numDims;\n    this.bytesPerDim = bytesPerDim;\n    this.totalPointCount = totalPointCount;\n    docsSeen = new FixedBitSet(maxDoc);\n    packedBytesLength = numDims * bytesPerDim;\n\n    scratchDiff = new byte[bytesPerDim];\n    scratchBytesRef.length = packedBytesLength;\n    scratch1 = new byte[packedBytesLength];\n    scratch2 = new byte[packedBytesLength];\n    commonPrefixLengths = new int[numDims];\n\n    minPackedValue = new byte[packedBytesLength];\n    maxPackedValue = new byte[packedBytesLength];\n\n    // If we may have more than 1+Integer.MAX_VALUE values, then we must encode ords with long (8 bytes), else we can use int (4 bytes).\n    longOrds = totalPointCount > Integer.MAX_VALUE;\n\n    // dimensional values (numDims * bytesPerDim) + ord (int or long) + docID (int)\n    if (longOrds) {\n      bytesPerDoc = packedBytesLength + Long.BYTES + Integer.BYTES;\n    } else {\n      bytesPerDoc = packedBytesLength + Integer.BYTES + Integer.BYTES;\n    }\n\n    // As we recurse, we compute temporary partitions of the data, halving the\n    // number of points at each recursion.  Once there are few enough points,\n    // we can switch to sorting in heap instead of offline (on disk).  At any\n    // time in the recursion, we hold the number of points at that level, plus\n    // all recursive halves (i.e. 16 + 8 + 4 + 2) so the memory usage is 2X\n    // what that level would consume, so we multiply by 0.5 to convert from\n    // bytes to points here.  Each dimension has its own sorted partition, so\n    // we must divide by numDims as wel.\n\n    maxPointsSortInHeap = (int) (0.5 * (maxMBSortInHeap * 1024 * 1024) / (bytesPerDoc * numDims));\n\n    // Finally, we must be able to hold at least the leaf node in heap during build:\n    if (maxPointsSortInHeap < maxPointsInLeafNode) {\n      throw new IllegalArgumentException(\"maxMBSortInHeap=\" + maxMBSortInHeap + \" only allows for maxPointsSortInHeap=\" + maxPointsSortInHeap + \", but this is less than maxPointsInLeafNode=\" + maxPointsInLeafNode + \"; either increase maxMBSortInHeap or decrease maxPointsInLeafNode\");\n    }\n\n    // We write first maxPointsSortInHeap in heap, then cutover to offline for additional points:\n    heapPointWriter = new HeapPointWriter(16, maxPointsSortInHeap, packedBytesLength, longOrds);\n\n    this.maxMBSortInHeap = maxMBSortInHeap;\n  }\n\n","sourceOld":"  public BKDWriter(int maxDoc, Directory tempDir, String tempFileNamePrefix, int numDims, int bytesPerDim, int maxPointsInLeafNode, double maxMBSortInHeap, long totalPointCount) throws IOException {\n    verifyParams(numDims, maxPointsInLeafNode, maxMBSortInHeap, totalPointCount);\n    // We use tracking dir to deal with removing files on exception, so each place that\n    // creates temp files doesn't need crazy try/finally/sucess logic:\n    this.tempDir = new TrackingDirectoryWrapper(tempDir);\n    this.tempFileNamePrefix = tempFileNamePrefix;\n    this.maxPointsInLeafNode = maxPointsInLeafNode;\n    this.numDims = numDims;\n    this.bytesPerDim = bytesPerDim;\n    this.totalPointCount = totalPointCount;\n    docsSeen = new FixedBitSet(maxDoc);\n    packedBytesLength = numDims * bytesPerDim;\n\n    scratchDiff = new byte[bytesPerDim];\n    scratchPackedValue = new byte[packedBytesLength];\n    scratch1 = new byte[packedBytesLength];\n    scratch2 = new byte[packedBytesLength];\n    commonPrefixLengths = new int[numDims];\n\n    minPackedValue = new byte[packedBytesLength];\n    maxPackedValue = new byte[packedBytesLength];\n\n    // If we may have more than 1+Integer.MAX_VALUE values, then we must encode ords with long (8 bytes), else we can use int (4 bytes).\n    longOrds = totalPointCount > Integer.MAX_VALUE;\n\n    // dimensional values (numDims * bytesPerDim) + ord (int or long) + docID (int)\n    if (longOrds) {\n      bytesPerDoc = packedBytesLength + Long.BYTES + Integer.BYTES;\n    } else {\n      bytesPerDoc = packedBytesLength + Integer.BYTES + Integer.BYTES;\n    }\n\n    // As we recurse, we compute temporary partitions of the data, halving the\n    // number of points at each recursion.  Once there are few enough points,\n    // we can switch to sorting in heap instead of offline (on disk).  At any\n    // time in the recursion, we hold the number of points at that level, plus\n    // all recursive halves (i.e. 16 + 8 + 4 + 2) so the memory usage is 2X\n    // what that level would consume, so we multiply by 0.5 to convert from\n    // bytes to points here.  Each dimension has its own sorted partition, so\n    // we must divide by numDims as wel.\n\n    maxPointsSortInHeap = (int) (0.5 * (maxMBSortInHeap * 1024 * 1024) / (bytesPerDoc * numDims));\n\n    // Finally, we must be able to hold at least the leaf node in heap during build:\n    if (maxPointsSortInHeap < maxPointsInLeafNode) {\n      throw new IllegalArgumentException(\"maxMBSortInHeap=\" + maxMBSortInHeap + \" only allows for maxPointsSortInHeap=\" + maxPointsSortInHeap + \", but this is less than maxPointsInLeafNode=\" + maxPointsInLeafNode + \"; either increase maxMBSortInHeap or decrease maxPointsInLeafNode\");\n    }\n\n    // We write first maxPointsSortInHeap in heap, then cutover to offline for additional points:\n    heapPointWriter = new HeapPointWriter(16, maxPointsSortInHeap, packedBytesLength, longOrds);\n\n    this.maxMBSortInHeap = maxMBSortInHeap;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"416f9e28900210be57b69bc12e2954fb98ed7ebe","date":1458479803,"type":5,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#BKDWriter(int,Directory,String,int,int,int,double,long,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#BKDWriter(int,Directory,String,int,int,int,double,long).mjava","sourceNew":"  public BKDWriter(int maxDoc, Directory tempDir, String tempFileNamePrefix, int numDims, int bytesPerDim, int maxPointsInLeafNode, double maxMBSortInHeap, long totalPointCount, boolean singleValuePerDoc) throws IOException {\n    verifyParams(numDims, maxPointsInLeafNode, maxMBSortInHeap, totalPointCount);\n    // We use tracking dir to deal with removing files on exception, so each place that\n    // creates temp files doesn't need crazy try/finally/sucess logic:\n    this.tempDir = new TrackingDirectoryWrapper(tempDir);\n    this.tempFileNamePrefix = tempFileNamePrefix;\n    this.maxPointsInLeafNode = maxPointsInLeafNode;\n    this.numDims = numDims;\n    this.bytesPerDim = bytesPerDim;\n    this.totalPointCount = totalPointCount;\n    this.maxDoc = maxDoc;\n    docsSeen = new FixedBitSet(maxDoc);\n    packedBytesLength = numDims * bytesPerDim;\n\n    scratchDiff = new byte[bytesPerDim];\n    scratchBytesRef.length = packedBytesLength;\n    scratch1 = new byte[packedBytesLength];\n    scratch2 = new byte[packedBytesLength];\n    commonPrefixLengths = new int[numDims];\n\n    minPackedValue = new byte[packedBytesLength];\n    maxPackedValue = new byte[packedBytesLength];\n\n    // If we may have more than 1+Integer.MAX_VALUE values, then we must encode ords with long (8 bytes), else we can use int (4 bytes).\n    longOrds = totalPointCount > Integer.MAX_VALUE;\n    this.singleValuePerDoc = singleValuePerDoc;\n\n    // dimensional values (numDims * bytesPerDim) + ord (int or long) + docID (int)\n    if (singleValuePerDoc) {\n      // Lucene only supports up to 2.1 docs, so we better not need longOrds in this case:\n      assert longOrds == false;\n      bytesPerDoc = packedBytesLength + Integer.BYTES;\n    } else if (longOrds) {\n      bytesPerDoc = packedBytesLength + Long.BYTES + Integer.BYTES;\n    } else {\n      bytesPerDoc = packedBytesLength + Integer.BYTES + Integer.BYTES;\n    }\n\n    // As we recurse, we compute temporary partitions of the data, halving the\n    // number of points at each recursion.  Once there are few enough points,\n    // we can switch to sorting in heap instead of offline (on disk).  At any\n    // time in the recursion, we hold the number of points at that level, plus\n    // all recursive halves (i.e. 16 + 8 + 4 + 2) so the memory usage is 2X\n    // what that level would consume, so we multiply by 0.5 to convert from\n    // bytes to points here.  Each dimension has its own sorted partition, so\n    // we must divide by numDims as wel.\n\n    maxPointsSortInHeap = (int) (0.5 * (maxMBSortInHeap * 1024 * 1024) / (bytesPerDoc * numDims));\n\n    // Finally, we must be able to hold at least the leaf node in heap during build:\n    if (maxPointsSortInHeap < maxPointsInLeafNode) {\n      throw new IllegalArgumentException(\"maxMBSortInHeap=\" + maxMBSortInHeap + \" only allows for maxPointsSortInHeap=\" + maxPointsSortInHeap + \", but this is less than maxPointsInLeafNode=\" + maxPointsInLeafNode + \"; either increase maxMBSortInHeap or decrease maxPointsInLeafNode\");\n    }\n\n    // We write first maxPointsSortInHeap in heap, then cutover to offline for additional points:\n    heapPointWriter = new HeapPointWriter(16, maxPointsSortInHeap, packedBytesLength, longOrds, singleValuePerDoc);\n\n    this.maxMBSortInHeap = maxMBSortInHeap;\n  }\n\n","sourceOld":"  public BKDWriter(int maxDoc, Directory tempDir, String tempFileNamePrefix, int numDims, int bytesPerDim, int maxPointsInLeafNode, double maxMBSortInHeap, long totalPointCount) throws IOException {\n    verifyParams(numDims, maxPointsInLeafNode, maxMBSortInHeap, totalPointCount);\n    // We use tracking dir to deal with removing files on exception, so each place that\n    // creates temp files doesn't need crazy try/finally/sucess logic:\n    this.tempDir = new TrackingDirectoryWrapper(tempDir);\n    this.tempFileNamePrefix = tempFileNamePrefix;\n    this.maxPointsInLeafNode = maxPointsInLeafNode;\n    this.numDims = numDims;\n    this.bytesPerDim = bytesPerDim;\n    this.totalPointCount = totalPointCount;\n    docsSeen = new FixedBitSet(maxDoc);\n    packedBytesLength = numDims * bytesPerDim;\n\n    scratchDiff = new byte[bytesPerDim];\n    scratchBytesRef.length = packedBytesLength;\n    scratch1 = new byte[packedBytesLength];\n    scratch2 = new byte[packedBytesLength];\n    commonPrefixLengths = new int[numDims];\n\n    minPackedValue = new byte[packedBytesLength];\n    maxPackedValue = new byte[packedBytesLength];\n\n    // If we may have more than 1+Integer.MAX_VALUE values, then we must encode ords with long (8 bytes), else we can use int (4 bytes).\n    longOrds = totalPointCount > Integer.MAX_VALUE;\n\n    // dimensional values (numDims * bytesPerDim) + ord (int or long) + docID (int)\n    if (longOrds) {\n      bytesPerDoc = packedBytesLength + Long.BYTES + Integer.BYTES;\n    } else {\n      bytesPerDoc = packedBytesLength + Integer.BYTES + Integer.BYTES;\n    }\n\n    // As we recurse, we compute temporary partitions of the data, halving the\n    // number of points at each recursion.  Once there are few enough points,\n    // we can switch to sorting in heap instead of offline (on disk).  At any\n    // time in the recursion, we hold the number of points at that level, plus\n    // all recursive halves (i.e. 16 + 8 + 4 + 2) so the memory usage is 2X\n    // what that level would consume, so we multiply by 0.5 to convert from\n    // bytes to points here.  Each dimension has its own sorted partition, so\n    // we must divide by numDims as wel.\n\n    maxPointsSortInHeap = (int) (0.5 * (maxMBSortInHeap * 1024 * 1024) / (bytesPerDoc * numDims));\n\n    // Finally, we must be able to hold at least the leaf node in heap during build:\n    if (maxPointsSortInHeap < maxPointsInLeafNode) {\n      throw new IllegalArgumentException(\"maxMBSortInHeap=\" + maxMBSortInHeap + \" only allows for maxPointsSortInHeap=\" + maxPointsSortInHeap + \", but this is less than maxPointsInLeafNode=\" + maxPointsInLeafNode + \"; either increase maxMBSortInHeap or decrease maxPointsInLeafNode\");\n    }\n\n    // We write first maxPointsSortInHeap in heap, then cutover to offline for additional points:\n    heapPointWriter = new HeapPointWriter(16, maxPointsSortInHeap, packedBytesLength, longOrds);\n\n    this.maxMBSortInHeap = maxMBSortInHeap;\n  }\n\n","bugFix":null,"bugIntro":["1e52a98a3809d9d747b7694f15f80b7018403ef5"],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"16ffb58ba57f805651a528311c104f104d9f4573":["9a5a0f27d9486cd33de88627ed3d2ff8dc5074ca"],"b9028cf27fe30db95667505bb92ecaee8fa3aef7":["9a5a0f27d9486cd33de88627ed3d2ff8dc5074ca","16ffb58ba57f805651a528311c104f104d9f4573"],"9a5a0f27d9486cd33de88627ed3d2ff8dc5074ca":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"416f9e28900210be57b69bc12e2954fb98ed7ebe":["b9028cf27fe30db95667505bb92ecaee8fa3aef7"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["416f9e28900210be57b69bc12e2954fb98ed7ebe"]},"commit2Childs":{"16ffb58ba57f805651a528311c104f104d9f4573":["b9028cf27fe30db95667505bb92ecaee8fa3aef7"],"b9028cf27fe30db95667505bb92ecaee8fa3aef7":["416f9e28900210be57b69bc12e2954fb98ed7ebe"],"9a5a0f27d9486cd33de88627ed3d2ff8dc5074ca":["16ffb58ba57f805651a528311c104f104d9f4573","b9028cf27fe30db95667505bb92ecaee8fa3aef7"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9a5a0f27d9486cd33de88627ed3d2ff8dc5074ca"],"416f9e28900210be57b69bc12e2954fb98ed7ebe":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}