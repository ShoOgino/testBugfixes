{"path":"lucene/core/src/test/org/apache/lucene/search/TestSloppyPhraseQuery#checkPhraseQuery(Document,PhraseQuery,int,int).mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestSloppyPhraseQuery#checkPhraseQuery(Document,PhraseQuery,int,int).mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestSloppyPhraseQuery#checkPhraseQuery(Document,PhraseQuery,int,int).mjava","sourceNew":"  private float  checkPhraseQuery(Document doc, PhraseQuery query, int slop, int expectedNumResults) throws Exception {\n    query.setSlop(slop);\n\n    Directory ramDir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, ramDir, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false));\n    writer.addDocument(doc);\n\n    IndexReader reader = writer.getReader();\n\n    IndexSearcher searcher = newSearcher(reader);\n    MaxFreqCollector c = new MaxFreqCollector();\n    searcher.search(query, c);\n    assertEquals(\"slop: \"+slop+\"  query: \"+query+\"  doc: \"+doc+\"  Wrong number of hits\", expectedNumResults, c.totalHits);\n\n    //QueryUtils.check(query,searcher);\n    writer.close();\n    reader.close();\n    ramDir.close();\n\n    // returns the max Scorer.freq() found, because even though norms are omitted, many index stats are different\n    // with these different tokens/distributions/lengths.. otherwise this test is very fragile.\n    return c.max; \n  }\n\n","sourceOld":"  private float  checkPhraseQuery(Document doc, PhraseQuery query, int slop, int expectedNumResults) throws Exception {\n    query.setSlop(slop);\n\n    Directory ramDir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, ramDir, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false));\n    writer.addDocument(doc);\n\n    IndexReader reader = writer.getReader();\n\n    IndexSearcher searcher = newSearcher(reader);\n    MaxFreqCollector c = new MaxFreqCollector();\n    searcher.search(query, c);\n    assertEquals(\"slop: \"+slop+\"  query: \"+query+\"  doc: \"+doc+\"  Wrong number of hits\", expectedNumResults, c.totalHits);\n\n    //QueryUtils.check(query,searcher);\n    writer.close();\n    reader.close();\n    ramDir.close();\n\n    // returns the max Scorer.freq() found, because even though norms are omitted, many index stats are different\n    // with these different tokens/distributions/lengths.. otherwise this test is very fragile.\n    return c.max; \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestSloppyPhraseQuery#checkPhraseQuery(Document,PhraseQuery,int,int).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestSloppyPhraseQuery#checkPhraseQuery(Document,PhraseQuery,int,int).mjava","sourceNew":"  private float  checkPhraseQuery(Document doc, PhraseQuery query, int slop, int expectedNumResults) throws Exception {\n    query.setSlop(slop);\n\n    Directory ramDir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), ramDir, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false));\n    writer.addDocument(doc);\n\n    IndexReader reader = writer.getReader();\n\n    IndexSearcher searcher = newSearcher(reader);\n    MaxFreqCollector c = new MaxFreqCollector();\n    searcher.search(query, c);\n    assertEquals(\"slop: \"+slop+\"  query: \"+query+\"  doc: \"+doc+\"  Wrong number of hits\", expectedNumResults, c.totalHits);\n\n    //QueryUtils.check(query,searcher);\n    writer.close();\n    reader.close();\n    ramDir.close();\n\n    // returns the max Scorer.freq() found, because even though norms are omitted, many index stats are different\n    // with these different tokens/distributions/lengths.. otherwise this test is very fragile.\n    return c.max; \n  }\n\n","sourceOld":"  private float  checkPhraseQuery(Document doc, PhraseQuery query, int slop, int expectedNumResults) throws Exception {\n    query.setSlop(slop);\n\n    Directory ramDir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, ramDir, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false));\n    writer.addDocument(doc);\n\n    IndexReader reader = writer.getReader();\n\n    IndexSearcher searcher = newSearcher(reader);\n    MaxFreqCollector c = new MaxFreqCollector();\n    searcher.search(query, c);\n    assertEquals(\"slop: \"+slop+\"  query: \"+query+\"  doc: \"+doc+\"  Wrong number of hits\", expectedNumResults, c.totalHits);\n\n    //QueryUtils.check(query,searcher);\n    writer.close();\n    reader.close();\n    ramDir.close();\n\n    // returns the max Scorer.freq() found, because even though norms are omitted, many index stats are different\n    // with these different tokens/distributions/lengths.. otherwise this test is very fragile.\n    return c.max; \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"19275ba31e621f6da1b83bf13af75233876fd3d4","date":1374846698,"type":3,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestSloppyPhraseQuery#checkPhraseQuery(Document,PhraseQuery,int,int).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestSloppyPhraseQuery#checkPhraseQuery(Document,PhraseQuery,int,int).mjava","sourceNew":"  private float  checkPhraseQuery(Document doc, PhraseQuery query, int slop, int expectedNumResults) throws Exception {\n    query.setSlop(slop);\n\n    Directory ramDir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), ramDir, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false));\n    writer.addDocument(doc);\n\n    IndexReader reader = writer.getReader();\n\n    IndexSearcher searcher = newSearcher(reader);\n    MaxFreqCollector c = new MaxFreqCollector();\n    searcher.search(query, c);\n    assertEquals(\"slop: \"+slop+\"  query: \"+query+\"  doc: \"+doc+\"  Wrong number of hits\", expectedNumResults, c.totalHits);\n\n    //QueryUtils.check(query,searcher);\n    writer.close();\n    reader.close();\n    ramDir.close();\n\n    // returns the max Scorer.freq() found, because even though norms are omitted, many index stats are different\n    // with these different tokens/distributions/lengths.. otherwise this test is very fragile.\n    return c.max; \n  }\n\n","sourceOld":"  private float  checkPhraseQuery(Document doc, PhraseQuery query, int slop, int expectedNumResults) throws Exception {\n    query.setSlop(slop);\n\n    Directory ramDir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), ramDir, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false));\n    writer.addDocument(doc);\n\n    IndexReader reader = writer.getReader();\n\n    IndexSearcher searcher = newSearcher(reader);\n    MaxFreqCollector c = new MaxFreqCollector();\n    searcher.search(query, c);\n    assertEquals(\"slop: \"+slop+\"  query: \"+query+\"  doc: \"+doc+\"  Wrong number of hits\", expectedNumResults, c.totalHits);\n\n    //QueryUtils.check(query,searcher);\n    writer.close();\n    reader.close();\n    ramDir.close();\n\n    // returns the max Scorer.freq() found, because even though norms are omitted, many index stats are different\n    // with these different tokens/distributions/lengths.. otherwise this test is very fragile.\n    return c.max; \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","date":1376366778,"type":3,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestSloppyPhraseQuery#checkPhraseQuery(Document,PhraseQuery,int,int).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestSloppyPhraseQuery#checkPhraseQuery(Document,PhraseQuery,int,int).mjava","sourceNew":"  private float  checkPhraseQuery(Document doc, PhraseQuery query, int slop, int expectedNumResults) throws Exception {\n    query.setSlop(slop);\n\n    Directory ramDir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), ramDir, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false));\n    writer.addDocument(doc);\n\n    IndexReader reader = writer.getReader();\n\n    IndexSearcher searcher = newSearcher(reader);\n    MaxFreqCollector c = new MaxFreqCollector();\n    searcher.search(query, c);\n    assertEquals(\"slop: \"+slop+\"  query: \"+query+\"  doc: \"+doc+\"  Wrong number of hits\", expectedNumResults, c.totalHits);\n\n    //QueryUtils.check(query,searcher);\n    writer.close();\n    reader.close();\n    ramDir.close();\n\n    // returns the max Scorer.freq() found, because even though norms are omitted, many index stats are different\n    // with these different tokens/distributions/lengths.. otherwise this test is very fragile.\n    return c.max; \n  }\n\n","sourceOld":"  private float  checkPhraseQuery(Document doc, PhraseQuery query, int slop, int expectedNumResults) throws Exception {\n    query.setSlop(slop);\n\n    Directory ramDir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), ramDir, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false));\n    writer.addDocument(doc);\n\n    IndexReader reader = writer.getReader();\n\n    IndexSearcher searcher = newSearcher(reader);\n    MaxFreqCollector c = new MaxFreqCollector();\n    searcher.search(query, c);\n    assertEquals(\"slop: \"+slop+\"  query: \"+query+\"  doc: \"+doc+\"  Wrong number of hits\", expectedNumResults, c.totalHits);\n\n    //QueryUtils.check(query,searcher);\n    writer.close();\n    reader.close();\n    ramDir.close();\n\n    // returns the max Scorer.freq() found, because even though norms are omitted, many index stats are different\n    // with these different tokens/distributions/lengths.. otherwise this test is very fragile.\n    return c.max; \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestSloppyPhraseQuery#checkPhraseQuery(Document,PhraseQuery,int,int).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestSloppyPhraseQuery#checkPhraseQuery(Document,PhraseQuery,int,int).mjava","sourceNew":"  private float  checkPhraseQuery(Document doc, PhraseQuery query, int slop, int expectedNumResults) throws Exception {\n    query.setSlop(slop);\n\n    Directory ramDir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), ramDir, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false));\n    writer.addDocument(doc);\n\n    IndexReader reader = writer.getReader();\n\n    IndexSearcher searcher = newSearcher(reader);\n    MaxFreqCollector c = new MaxFreqCollector();\n    searcher.search(query, c);\n    assertEquals(\"slop: \"+slop+\"  query: \"+query+\"  doc: \"+doc+\"  Wrong number of hits\", expectedNumResults, c.totalHits);\n\n    //QueryUtils.check(query,searcher);\n    writer.shutdown();\n    reader.close();\n    ramDir.close();\n\n    // returns the max Scorer.freq() found, because even though norms are omitted, many index stats are different\n    // with these different tokens/distributions/lengths.. otherwise this test is very fragile.\n    return c.max; \n  }\n\n","sourceOld":"  private float  checkPhraseQuery(Document doc, PhraseQuery query, int slop, int expectedNumResults) throws Exception {\n    query.setSlop(slop);\n\n    Directory ramDir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), ramDir, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false));\n    writer.addDocument(doc);\n\n    IndexReader reader = writer.getReader();\n\n    IndexSearcher searcher = newSearcher(reader);\n    MaxFreqCollector c = new MaxFreqCollector();\n    searcher.search(query, c);\n    assertEquals(\"slop: \"+slop+\"  query: \"+query+\"  doc: \"+doc+\"  Wrong number of hits\", expectedNumResults, c.totalHits);\n\n    //QueryUtils.check(query,searcher);\n    writer.close();\n    reader.close();\n    ramDir.close();\n\n    // returns the max Scorer.freq() found, because even though norms are omitted, many index stats are different\n    // with these different tokens/distributions/lengths.. otherwise this test is very fragile.\n    return c.max; \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestSloppyPhraseQuery#checkPhraseQuery(Document,PhraseQuery,int,int).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestSloppyPhraseQuery#checkPhraseQuery(Document,PhraseQuery,int,int).mjava","sourceNew":"  private float  checkPhraseQuery(Document doc, PhraseQuery query, int slop, int expectedNumResults) throws Exception {\n    query.setSlop(slop);\n\n    Directory ramDir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), ramDir, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false));\n    writer.addDocument(doc);\n\n    IndexReader reader = writer.getReader();\n\n    IndexSearcher searcher = newSearcher(reader);\n    MaxFreqCollector c = new MaxFreqCollector();\n    searcher.search(query, c);\n    assertEquals(\"slop: \"+slop+\"  query: \"+query+\"  doc: \"+doc+\"  Wrong number of hits\", expectedNumResults, c.totalHits);\n\n    //QueryUtils.check(query,searcher);\n    writer.close();\n    reader.close();\n    ramDir.close();\n\n    // returns the max Scorer.freq() found, because even though norms are omitted, many index stats are different\n    // with these different tokens/distributions/lengths.. otherwise this test is very fragile.\n    return c.max; \n  }\n\n","sourceOld":"  private float  checkPhraseQuery(Document doc, PhraseQuery query, int slop, int expectedNumResults) throws Exception {\n    query.setSlop(slop);\n\n    Directory ramDir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), ramDir, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false));\n    writer.addDocument(doc);\n\n    IndexReader reader = writer.getReader();\n\n    IndexSearcher searcher = newSearcher(reader);\n    MaxFreqCollector c = new MaxFreqCollector();\n    searcher.search(query, c);\n    assertEquals(\"slop: \"+slop+\"  query: \"+query+\"  doc: \"+doc+\"  Wrong number of hits\", expectedNumResults, c.totalHits);\n\n    //QueryUtils.check(query,searcher);\n    writer.shutdown();\n    reader.close();\n    ramDir.close();\n\n    // returns the max Scorer.freq() found, because even though norms are omitted, many index stats are different\n    // with these different tokens/distributions/lengths.. otherwise this test is very fragile.\n    return c.max; \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"431452b6326a9c17ba5bb1e1a6d89e23a8932e73","date":1417113370,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestSloppyPhraseQuery#checkPhraseQuery(Document,PhraseQuery,int,int).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestSloppyPhraseQuery#checkPhraseQuery(Document,PhraseQuery,int,int).mjava","sourceNew":"  private float  checkPhraseQuery(Document doc, PhraseQuery query, int slop, int expectedNumResults) throws Exception {\n    query.setSlop(slop);\n\n    MockDirectoryWrapper ramDir = new MockDirectoryWrapper(random(), new RAMDirectory());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), ramDir, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false));\n    writer.addDocument(doc);\n\n    IndexReader reader = writer.getReader();\n\n    IndexSearcher searcher = newSearcher(reader);\n    MaxFreqCollector c = new MaxFreqCollector();\n    searcher.search(query, c);\n    assertEquals(\"slop: \"+slop+\"  query: \"+query+\"  doc: \"+doc+\"  Wrong number of hits\", expectedNumResults, c.totalHits);\n\n    //QueryUtils.check(query,searcher);\n    writer.close();\n    reader.close();\n    ramDir.close();\n\n    // returns the max Scorer.freq() found, because even though norms are omitted, many index stats are different\n    // with these different tokens/distributions/lengths.. otherwise this test is very fragile.\n    return c.max; \n  }\n\n","sourceOld":"  private float  checkPhraseQuery(Document doc, PhraseQuery query, int slop, int expectedNumResults) throws Exception {\n    query.setSlop(slop);\n\n    Directory ramDir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), ramDir, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false));\n    writer.addDocument(doc);\n\n    IndexReader reader = writer.getReader();\n\n    IndexSearcher searcher = newSearcher(reader);\n    MaxFreqCollector c = new MaxFreqCollector();\n    searcher.search(query, c);\n    assertEquals(\"slop: \"+slop+\"  query: \"+query+\"  doc: \"+doc+\"  Wrong number of hits\", expectedNumResults, c.totalHits);\n\n    //QueryUtils.check(query,searcher);\n    writer.close();\n    reader.close();\n    ramDir.close();\n\n    // returns the max Scorer.freq() found, because even though norms are omitted, many index stats are different\n    // with these different tokens/distributions/lengths.. otherwise this test is very fragile.\n    return c.max; \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e9e1499c5d26c936238506df90a3c02c76707722","date":1434449920,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestSloppyPhraseQuery#checkPhraseQuery(Document,PhraseQuery,int,int).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestSloppyPhraseQuery#checkPhraseQuery(Document,PhraseQuery,int,int).mjava","sourceNew":"  private float  checkPhraseQuery(Document doc, PhraseQuery query, int slop, int expectedNumResults) throws Exception {\n    PhraseQuery.Builder builder = new PhraseQuery.Builder();\n    Term[] terms = query.getTerms();\n    int[] positions = query.getPositions();\n    for (int i = 0; i < terms.length; ++i) {\n      builder.add(terms[i], positions[i]);\n    }\n    builder.setSlop(slop);\n    query = builder.build();\n\n    MockDirectoryWrapper ramDir = new MockDirectoryWrapper(random(), new RAMDirectory());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), ramDir, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false));\n    writer.addDocument(doc);\n\n    IndexReader reader = writer.getReader();\n\n    IndexSearcher searcher = newSearcher(reader);\n    MaxFreqCollector c = new MaxFreqCollector();\n    searcher.search(query, c);\n    assertEquals(\"slop: \"+slop+\"  query: \"+query+\"  doc: \"+doc+\"  Wrong number of hits\", expectedNumResults, c.totalHits);\n\n    //QueryUtils.check(query,searcher);\n    writer.close();\n    reader.close();\n    ramDir.close();\n\n    // returns the max Scorer.freq() found, because even though norms are omitted, many index stats are different\n    // with these different tokens/distributions/lengths.. otherwise this test is very fragile.\n    return c.max; \n  }\n\n","sourceOld":"  private float  checkPhraseQuery(Document doc, PhraseQuery query, int slop, int expectedNumResults) throws Exception {\n    query.setSlop(slop);\n\n    MockDirectoryWrapper ramDir = new MockDirectoryWrapper(random(), new RAMDirectory());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), ramDir, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false));\n    writer.addDocument(doc);\n\n    IndexReader reader = writer.getReader();\n\n    IndexSearcher searcher = newSearcher(reader);\n    MaxFreqCollector c = new MaxFreqCollector();\n    searcher.search(query, c);\n    assertEquals(\"slop: \"+slop+\"  query: \"+query+\"  doc: \"+doc+\"  Wrong number of hits\", expectedNumResults, c.totalHits);\n\n    //QueryUtils.check(query,searcher);\n    writer.close();\n    reader.close();\n    ramDir.close();\n\n    // returns the max Scorer.freq() found, because even though norms are omitted, many index stats are different\n    // with these different tokens/distributions/lengths.. otherwise this test is very fragile.\n    return c.max; \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d77dafd89756a5161d244985903e3487ca109182","date":1548679743,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestSloppyPhraseQuery#checkPhraseQuery(Document,PhraseQuery,int,int).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestSloppyPhraseQuery#checkPhraseQuery(Document,PhraseQuery,int,int).mjava","sourceNew":"  private float  checkPhraseQuery(Document doc, PhraseQuery query, int slop, int expectedNumResults) throws Exception {\n    PhraseQuery.Builder builder = new PhraseQuery.Builder();\n    Term[] terms = query.getTerms();\n    int[] positions = query.getPositions();\n    for (int i = 0; i < terms.length; ++i) {\n      builder.add(terms[i], positions[i]);\n    }\n    builder.setSlop(slop);\n    query = builder.build();\n\n    MockDirectoryWrapper ramDir = new MockDirectoryWrapper(random(), new ByteBuffersDirectory());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), ramDir, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false));\n    writer.addDocument(doc);\n\n    IndexReader reader = writer.getReader();\n\n    IndexSearcher searcher = newSearcher(reader);\n    MaxFreqCollector c = new MaxFreqCollector();\n    searcher.search(query, c);\n    assertEquals(\"slop: \"+slop+\"  query: \"+query+\"  doc: \"+doc+\"  Wrong number of hits\", expectedNumResults, c.totalHits);\n\n    //QueryUtils.check(query,searcher);\n    writer.close();\n    reader.close();\n    ramDir.close();\n\n    // returns the max Scorer.freq() found, because even though norms are omitted, many index stats are different\n    // with these different tokens/distributions/lengths.. otherwise this test is very fragile.\n    return c.max; \n  }\n\n","sourceOld":"  private float  checkPhraseQuery(Document doc, PhraseQuery query, int slop, int expectedNumResults) throws Exception {\n    PhraseQuery.Builder builder = new PhraseQuery.Builder();\n    Term[] terms = query.getTerms();\n    int[] positions = query.getPositions();\n    for (int i = 0; i < terms.length; ++i) {\n      builder.add(terms[i], positions[i]);\n    }\n    builder.setSlop(slop);\n    query = builder.build();\n\n    MockDirectoryWrapper ramDir = new MockDirectoryWrapper(random(), new RAMDirectory());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), ramDir, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false));\n    writer.addDocument(doc);\n\n    IndexReader reader = writer.getReader();\n\n    IndexSearcher searcher = newSearcher(reader);\n    MaxFreqCollector c = new MaxFreqCollector();\n    searcher.search(query, c);\n    assertEquals(\"slop: \"+slop+\"  query: \"+query+\"  doc: \"+doc+\"  Wrong number of hits\", expectedNumResults, c.totalHits);\n\n    //QueryUtils.check(query,searcher);\n    writer.close();\n    reader.close();\n    ramDir.close();\n\n    // returns the max Scorer.freq() found, because even though norms are omitted, many index stats are different\n    // with these different tokens/distributions/lengths.. otherwise this test is very fragile.\n    return c.max; \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"e9e1499c5d26c936238506df90a3c02c76707722":["431452b6326a9c17ba5bb1e1a6d89e23a8932e73"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"d77dafd89756a5161d244985903e3487ca109182":["e9e1499c5d26c936238506df90a3c02c76707722"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["19275ba31e621f6da1b83bf13af75233876fd3d4"],"19275ba31e621f6da1b83bf13af75233876fd3d4":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"431452b6326a9c17ba5bb1e1a6d89e23a8932e73":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["d77dafd89756a5161d244985903e3487ca109182"]},"commit2Childs":{"e9e1499c5d26c936238506df90a3c02c76707722":["d77dafd89756a5161d244985903e3487ca109182"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["431452b6326a9c17ba5bb1e1a6d89e23a8932e73"],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":[],"d77dafd89756a5161d244985903e3487ca109182":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"19275ba31e621f6da1b83bf13af75233876fd3d4":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"431452b6326a9c17ba5bb1e1a6d89e23a8932e73":["e9e1499c5d26c936238506df90a3c02c76707722"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","19275ba31e621f6da1b83bf13af75233876fd3d4"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}