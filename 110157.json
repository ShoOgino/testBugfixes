{"path":"lucene/highlighter/src/test/org/apache/lucene/search/uhighlight/TestUnifiedHighlighterTermVec#testFetchTermVecsOncePerDoc().mjava","commits":[{"id":"1f5ce59aaf4a055cc9ec62c15a89c263a05ff4b2","date":1475611903,"type":0,"author":"David Smiley","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/uhighlight/TestUnifiedHighlighterTermVec#testFetchTermVecsOncePerDoc().mjava","pathOld":"/dev/null","sourceNew":"  public void testFetchTermVecsOncePerDoc() throws IOException {\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, indexAnalyzer);\n\n    // Declare some number of fields with random field type; but at least one will have term vectors.\n    final int numTvFields = 1 + random().nextInt(3);\n    List<String> fields = new ArrayList<>(numTvFields);\n    List<FieldType> fieldTypes = new ArrayList<>(numTvFields);\n    for (int i = 0; i < numTvFields; i++) {\n      fields.add(\"body\" + i);\n      fieldTypes.add(UHTestHelper.randomFieldType(random()));\n    }\n    //ensure at least one has TVs by setting one randomly to it:\n    fieldTypes.set(random().nextInt(fieldTypes.size()), UHTestHelper.tvType);\n\n    final int numDocs = 1 + random().nextInt(3);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      for (String field : fields) {\n        doc.add(new Field(field, \"some test text\", UHTestHelper.tvType));\n      }\n      iw.addDocument(doc);\n    }\n\n    // Wrap the reader to ensure we only fetch TVs once per doc\n    DirectoryReader originalReader = iw.getReader();\n    IndexReader ir = new AssertOnceTermVecDirectoryReader(originalReader);\n    iw.close();\n\n    IndexSearcher searcher = newSearcher(ir);\n    UnifiedHighlighter highlighter = new UnifiedHighlighter(searcher, indexAnalyzer);\n    BooleanQuery.Builder queryBuilder = new BooleanQuery.Builder();\n    for (String field : fields) {\n      queryBuilder.add(new TermQuery(new Term(field, \"test\")), BooleanClause.Occur.MUST);\n    }\n    BooleanQuery query = queryBuilder.build();\n    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);\n    assertEquals(numDocs, topDocs.totalHits);\n    Map<String, String[]> fieldToSnippets =\n        highlighter.highlightFields(fields.toArray(new String[numTvFields]), query, topDocs);\n    String[] expectedSnippetsByDoc = new String[numDocs];\n    Arrays.fill(expectedSnippetsByDoc, \"some <b>test</b> text\");\n    for (String field : fields) {\n      assertArrayEquals(expectedSnippetsByDoc, fieldToSnippets.get(field));\n    }\n\n    ir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":0,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/uhighlight/TestUnifiedHighlighterTermVec#testFetchTermVecsOncePerDoc().mjava","pathOld":"/dev/null","sourceNew":"  public void testFetchTermVecsOncePerDoc() throws IOException {\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, indexAnalyzer);\n\n    // Declare some number of fields with random field type; but at least one will have term vectors.\n    final int numTvFields = 1 + random().nextInt(3);\n    List<String> fields = new ArrayList<>(numTvFields);\n    List<FieldType> fieldTypes = new ArrayList<>(numTvFields);\n    for (int i = 0; i < numTvFields; i++) {\n      fields.add(\"body\" + i);\n      fieldTypes.add(UHTestHelper.randomFieldType(random()));\n    }\n    //ensure at least one has TVs by setting one randomly to it:\n    fieldTypes.set(random().nextInt(fieldTypes.size()), UHTestHelper.tvType);\n\n    final int numDocs = 1 + random().nextInt(3);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      for (String field : fields) {\n        doc.add(new Field(field, \"some test text\", UHTestHelper.tvType));\n      }\n      iw.addDocument(doc);\n    }\n\n    // Wrap the reader to ensure we only fetch TVs once per doc\n    DirectoryReader originalReader = iw.getReader();\n    IndexReader ir = new AssertOnceTermVecDirectoryReader(originalReader);\n    iw.close();\n\n    IndexSearcher searcher = newSearcher(ir);\n    UnifiedHighlighter highlighter = new UnifiedHighlighter(searcher, indexAnalyzer);\n    BooleanQuery.Builder queryBuilder = new BooleanQuery.Builder();\n    for (String field : fields) {\n      queryBuilder.add(new TermQuery(new Term(field, \"test\")), BooleanClause.Occur.MUST);\n    }\n    BooleanQuery query = queryBuilder.build();\n    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);\n    assertEquals(numDocs, topDocs.totalHits);\n    Map<String, String[]> fieldToSnippets =\n        highlighter.highlightFields(fields.toArray(new String[numTvFields]), query, topDocs);\n    String[] expectedSnippetsByDoc = new String[numDocs];\n    Arrays.fill(expectedSnippetsByDoc, \"some <b>test</b> text\");\n    for (String field : fields) {\n      assertArrayEquals(expectedSnippetsByDoc, fieldToSnippets.get(field));\n    }\n\n    ir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"83788ad129a5154d5c6562c4e8ce3db48793aada","date":1532961485,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/uhighlight/TestUnifiedHighlighterTermVec#testFetchTermVecsOncePerDoc().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/uhighlight/TestUnifiedHighlighterTermVec#testFetchTermVecsOncePerDoc().mjava","sourceNew":"  public void testFetchTermVecsOncePerDoc() throws IOException {\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, indexAnalyzer);\n\n    // Declare some number of fields with random field type; but at least one will have term vectors.\n    final int numTvFields = 1 + random().nextInt(3);\n    List<String> fields = new ArrayList<>(numTvFields);\n    List<FieldType> fieldTypes = new ArrayList<>(numTvFields);\n    for (int i = 0; i < numTvFields; i++) {\n      fields.add(\"body\" + i);\n      fieldTypes.add(UHTestHelper.randomFieldType(random()));\n    }\n    //ensure at least one has TVs by setting one randomly to it:\n    fieldTypes.set(random().nextInt(fieldTypes.size()), UHTestHelper.tvType);\n\n    final int numDocs = 1 + random().nextInt(3);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      for (String field : fields) {\n        doc.add(new Field(field, \"some test text\", UHTestHelper.tvType));\n      }\n      iw.addDocument(doc);\n    }\n\n    // Wrap the reader to ensure we only fetch TVs once per doc\n    DirectoryReader originalReader = iw.getReader();\n    IndexReader ir = new AssertOnceTermVecDirectoryReader(originalReader);\n    iw.close();\n\n    IndexSearcher searcher = newSearcher(ir);\n    UnifiedHighlighter highlighter = new UnifiedHighlighter(searcher, indexAnalyzer);\n    BooleanQuery.Builder queryBuilder = new BooleanQuery.Builder();\n    for (String field : fields) {\n      queryBuilder.add(new TermQuery(new Term(field, \"test\")), BooleanClause.Occur.MUST);\n    }\n    BooleanQuery query = queryBuilder.build();\n    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);\n    assertEquals(numDocs, topDocs.totalHits.value);\n    Map<String, String[]> fieldToSnippets =\n        highlighter.highlightFields(fields.toArray(new String[numTvFields]), query, topDocs);\n    String[] expectedSnippetsByDoc = new String[numDocs];\n    Arrays.fill(expectedSnippetsByDoc, \"some <b>test</b> text\");\n    for (String field : fields) {\n      assertArrayEquals(expectedSnippetsByDoc, fieldToSnippets.get(field));\n    }\n\n    ir.close();\n  }\n\n","sourceOld":"  public void testFetchTermVecsOncePerDoc() throws IOException {\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, indexAnalyzer);\n\n    // Declare some number of fields with random field type; but at least one will have term vectors.\n    final int numTvFields = 1 + random().nextInt(3);\n    List<String> fields = new ArrayList<>(numTvFields);\n    List<FieldType> fieldTypes = new ArrayList<>(numTvFields);\n    for (int i = 0; i < numTvFields; i++) {\n      fields.add(\"body\" + i);\n      fieldTypes.add(UHTestHelper.randomFieldType(random()));\n    }\n    //ensure at least one has TVs by setting one randomly to it:\n    fieldTypes.set(random().nextInt(fieldTypes.size()), UHTestHelper.tvType);\n\n    final int numDocs = 1 + random().nextInt(3);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      for (String field : fields) {\n        doc.add(new Field(field, \"some test text\", UHTestHelper.tvType));\n      }\n      iw.addDocument(doc);\n    }\n\n    // Wrap the reader to ensure we only fetch TVs once per doc\n    DirectoryReader originalReader = iw.getReader();\n    IndexReader ir = new AssertOnceTermVecDirectoryReader(originalReader);\n    iw.close();\n\n    IndexSearcher searcher = newSearcher(ir);\n    UnifiedHighlighter highlighter = new UnifiedHighlighter(searcher, indexAnalyzer);\n    BooleanQuery.Builder queryBuilder = new BooleanQuery.Builder();\n    for (String field : fields) {\n      queryBuilder.add(new TermQuery(new Term(field, \"test\")), BooleanClause.Occur.MUST);\n    }\n    BooleanQuery query = queryBuilder.build();\n    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);\n    assertEquals(numDocs, topDocs.totalHits);\n    Map<String, String[]> fieldToSnippets =\n        highlighter.highlightFields(fields.toArray(new String[numTvFields]), query, topDocs);\n    String[] expectedSnippetsByDoc = new String[numDocs];\n    Arrays.fill(expectedSnippetsByDoc, \"some <b>test</b> text\");\n    for (String field : fields) {\n      assertArrayEquals(expectedSnippetsByDoc, fieldToSnippets.get(field));\n    }\n\n    ir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ac7dc8447caedf847d70ac1910dc1efaa36f0f68","date":1596059784,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/uhighlight/TestUnifiedHighlighterTermVec#testFetchTermVecsOncePerDoc().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/uhighlight/TestUnifiedHighlighterTermVec#testFetchTermVecsOncePerDoc().mjava","sourceNew":"  public void testFetchTermVecsOncePerDoc() throws IOException {\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, indexAnalyzer);\n\n    // Declare some number of fields with random field type; but at least one will have term vectors.\n    final int numTvFields = 1 + random().nextInt(3);\n    List<String> fields = new ArrayList<>(numTvFields);\n    List<FieldType> fieldTypes = new ArrayList<>(numTvFields);\n    for (int i = 0; i < numTvFields; i++) {\n      fields.add(\"body\" + i);\n      fieldTypes.add(UHTestHelper.randomFieldType(random()));\n    }\n    //ensure at least one has TVs by setting one randomly to it:\n    fieldTypes.set(random().nextInt(fieldTypes.size()), UHTestHelper.tvType);\n\n    final int numDocs = 1 + random().nextInt(3);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      for (String field : fields) {\n        doc.add(new Field(field, \"some test text\", UHTestHelper.tvType));\n      }\n      iw.addDocument(doc);\n    }\n\n    // Wrap the reader to ensure we only fetch TVs once per doc\n    DirectoryReader originalReader = iw.getReader();\n    IndexReader ir = new AssertOnceTermVecDirectoryReader(originalReader);\n    iw.close();\n\n    IndexSearcher searcher = newSearcher(ir);\n    UnifiedHighlighter highlighter = new UnifiedHighlighter(searcher, indexAnalyzer);\n    BooleanQuery.Builder queryBuilder = new BooleanQuery.Builder();\n    for (String field : fields) {\n      queryBuilder.add(new TermQuery(new Term(field, \"test\")), BooleanClause.Occur.MUST);\n    }\n    BooleanQuery query = queryBuilder.build();\n    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);\n    assertEquals(numDocs, topDocs.totalHits.value);\n    Map<String, String[]> fieldToSnippets =\n        highlighter.highlightFields(fields.toArray(new String[numTvFields]), query, topDocs);\n    String[] expectedSnippetsByDoc = new String[numDocs];\n    Arrays.fill(expectedSnippetsByDoc, \"some <b>test</b> text\");\n    for (String field : fields) {\n      assertArrayEquals(expectedSnippetsByDoc, fieldToSnippets.get(field));\n    }\n\n    ir.document(0); // ensure this works because the ir hasn't been closed\n    ir.close();\n  }\n\n","sourceOld":"  public void testFetchTermVecsOncePerDoc() throws IOException {\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, indexAnalyzer);\n\n    // Declare some number of fields with random field type; but at least one will have term vectors.\n    final int numTvFields = 1 + random().nextInt(3);\n    List<String> fields = new ArrayList<>(numTvFields);\n    List<FieldType> fieldTypes = new ArrayList<>(numTvFields);\n    for (int i = 0; i < numTvFields; i++) {\n      fields.add(\"body\" + i);\n      fieldTypes.add(UHTestHelper.randomFieldType(random()));\n    }\n    //ensure at least one has TVs by setting one randomly to it:\n    fieldTypes.set(random().nextInt(fieldTypes.size()), UHTestHelper.tvType);\n\n    final int numDocs = 1 + random().nextInt(3);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      for (String field : fields) {\n        doc.add(new Field(field, \"some test text\", UHTestHelper.tvType));\n      }\n      iw.addDocument(doc);\n    }\n\n    // Wrap the reader to ensure we only fetch TVs once per doc\n    DirectoryReader originalReader = iw.getReader();\n    IndexReader ir = new AssertOnceTermVecDirectoryReader(originalReader);\n    iw.close();\n\n    IndexSearcher searcher = newSearcher(ir);\n    UnifiedHighlighter highlighter = new UnifiedHighlighter(searcher, indexAnalyzer);\n    BooleanQuery.Builder queryBuilder = new BooleanQuery.Builder();\n    for (String field : fields) {\n      queryBuilder.add(new TermQuery(new Term(field, \"test\")), BooleanClause.Occur.MUST);\n    }\n    BooleanQuery query = queryBuilder.build();\n    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);\n    assertEquals(numDocs, topDocs.totalHits.value);\n    Map<String, String[]> fieldToSnippets =\n        highlighter.highlightFields(fields.toArray(new String[numTvFields]), query, topDocs);\n    String[] expectedSnippetsByDoc = new String[numDocs];\n    Arrays.fill(expectedSnippetsByDoc, \"some <b>test</b> text\");\n    for (String field : fields) {\n      assertArrayEquals(expectedSnippetsByDoc, fieldToSnippets.get(field));\n    }\n\n    ir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"1f5ce59aaf4a055cc9ec62c15a89c263a05ff4b2":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"ac7dc8447caedf847d70ac1910dc1efaa36f0f68":["83788ad129a5154d5c6562c4e8ce3db48793aada"],"83788ad129a5154d5c6562c4e8ce3db48793aada":["1f5ce59aaf4a055cc9ec62c15a89c263a05ff4b2"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","1f5ce59aaf4a055cc9ec62c15a89c263a05ff4b2"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["ac7dc8447caedf847d70ac1910dc1efaa36f0f68"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["1f5ce59aaf4a055cc9ec62c15a89c263a05ff4b2","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"1f5ce59aaf4a055cc9ec62c15a89c263a05ff4b2":["83788ad129a5154d5c6562c4e8ce3db48793aada","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"ac7dc8447caedf847d70ac1910dc1efaa36f0f68":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"83788ad129a5154d5c6562c4e8ce3db48793aada":["ac7dc8447caedf847d70ac1910dc1efaa36f0f68"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}