{"path":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat#testTwoFieldsTwoFormats().mjava","commits":[{"id":"2ec08217282b5e9df023dcdff55c745ff68b1c7d","date":1359392781,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat#testTwoFieldsTwoFormats().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/TestDemoDocValue#testDemoTwoFieldsTwoFormats().mjava","sourceNew":"  // just a simple trivial test\n  // nocommit: if we are going to pass down suffixes to segmentread/writestate,\n  // then they should be respected by *all* codec apis!\n  public void testTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    final DocValuesFormat fast = DocValuesFormat.forName(\"Lucene42\");\n    final DocValuesFormat slow = DocValuesFormat.forName(\"SimpleText\");\n    iwc.setCodec(new Lucene42Codec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new NumericDocValuesField(\"dv1\", 5));\n    doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = new IndexSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    BytesRef scratch = new BytesRef();\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(5, dv.get(hits.scoreDocs[i].doc));\n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      dv2.get(hits.scoreDocs[i].doc, scratch);\n      assertEquals(new BytesRef(\"hello world\"), scratch);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","sourceOld":"  // nocommit: if we are going to pass down suffixes to segmentread/writestate,\n  // then they should be respected by *all* codec apis!\n  public void testDemoTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    final DocValuesFormat fast = DocValuesFormat.forName(\"Lucene42\");\n    final DocValuesFormat slow = DocValuesFormat.forName(\"SimpleText\");\n    iwc.setCodec(new Lucene42Codec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new NumericDocValuesField(\"dv1\", 5));\n    doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = new IndexSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    BytesRef scratch = new BytesRef();\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(5, dv.get(hits.scoreDocs[i].doc));\n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      dv2.get(hits.scoreDocs[i].doc, scratch);\n      assertEquals(new BytesRef(\"hello world\"), scratch);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e9eafdf27a0bda3d70664dd39f3a1683d8416dcf","date":1359644871,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat#testTwoFieldsTwoFormats().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat#testTwoFieldsTwoFormats().mjava","sourceNew":"  // just a simple trivial test\n  // TODO: we should come up with a test that somehow checks that segment suffix\n  // is respected by all codec apis (not just docvalues and postings)\n  public void testTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    final DocValuesFormat fast = DocValuesFormat.forName(\"Lucene42\");\n    final DocValuesFormat slow = DocValuesFormat.forName(\"SimpleText\");\n    iwc.setCodec(new Lucene42Codec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new NumericDocValuesField(\"dv1\", 5));\n    doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = new IndexSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    BytesRef scratch = new BytesRef();\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(5, dv.get(hits.scoreDocs[i].doc));\n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      dv2.get(hits.scoreDocs[i].doc, scratch);\n      assertEquals(new BytesRef(\"hello world\"), scratch);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","sourceOld":"  // just a simple trivial test\n  // nocommit: if we are going to pass down suffixes to segmentread/writestate,\n  // then they should be respected by *all* codec apis!\n  public void testTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    final DocValuesFormat fast = DocValuesFormat.forName(\"Lucene42\");\n    final DocValuesFormat slow = DocValuesFormat.forName(\"SimpleText\");\n    iwc.setCodec(new Lucene42Codec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new NumericDocValuesField(\"dv1\", 5));\n    doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = new IndexSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    BytesRef scratch = new BytesRef();\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(5, dv.get(hits.scoreDocs[i].doc));\n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      dv2.get(hits.scoreDocs[i].doc, scratch);\n      assertEquals(new BytesRef(\"hello world\"), scratch);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d4d69c535930b5cce125cff868d40f6373dc27d4","date":1360270101,"type":0,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat#testTwoFieldsTwoFormats().mjava","pathOld":"/dev/null","sourceNew":"  // just a simple trivial test\n  // TODO: we should come up with a test that somehow checks that segment suffix\n  // is respected by all codec apis (not just docvalues and postings)\n  public void testTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    final DocValuesFormat fast = DocValuesFormat.forName(\"Lucene42\");\n    final DocValuesFormat slow = DocValuesFormat.forName(\"SimpleText\");\n    iwc.setCodec(new Lucene42Codec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new NumericDocValuesField(\"dv1\", 5));\n    doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = new IndexSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    BytesRef scratch = new BytesRef();\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(5, dv.get(hits.scoreDocs[i].doc));\n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      dv2.get(hits.scoreDocs[i].doc, scratch);\n      assertEquals(new BytesRef(\"hello world\"), scratch);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3b0e8c39ca08b5a02de6edcd33d6f3b90b865173","date":1365631993,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat#testTwoFieldsTwoFormats().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat#testTwoFieldsTwoFormats().mjava","sourceNew":"  // just a simple trivial test\n  // TODO: we should come up with a test that somehow checks that segment suffix\n  // is respected by all codec apis (not just docvalues and postings)\n  public void testTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    final DocValuesFormat fast = DocValuesFormat.forName(\"Lucene42\");\n    final DocValuesFormat slow = DocValuesFormat.forName(\"SimpleText\");\n    iwc.setCodec(new Lucene42Codec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new NumericDocValuesField(\"dv1\", 5));\n    doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = newSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    BytesRef scratch = new BytesRef();\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(5, dv.get(hits.scoreDocs[i].doc));\n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      dv2.get(hits.scoreDocs[i].doc, scratch);\n      assertEquals(new BytesRef(\"hello world\"), scratch);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","sourceOld":"  // just a simple trivial test\n  // TODO: we should come up with a test that somehow checks that segment suffix\n  // is respected by all codec apis (not just docvalues and postings)\n  public void testTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    final DocValuesFormat fast = DocValuesFormat.forName(\"Lucene42\");\n    final DocValuesFormat slow = DocValuesFormat.forName(\"SimpleText\");\n    iwc.setCodec(new Lucene42Codec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new NumericDocValuesField(\"dv1\", 5));\n    doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = new IndexSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    BytesRef scratch = new BytesRef();\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(5, dv.get(hits.scoreDocs[i].doc));\n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      dv2.get(hits.scoreDocs[i].doc, scratch);\n      assertEquals(new BytesRef(\"hello world\"), scratch);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"11a746437bc5c0a0b3df0337ed249c387c812871","date":1376687959,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat#testTwoFieldsTwoFormats().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat#testTwoFieldsTwoFormats().mjava","sourceNew":"  // just a simple trivial test\n  // TODO: we should come up with a test that somehow checks that segment suffix\n  // is respected by all codec apis (not just docvalues and postings)\n  public void testTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    final DocValuesFormat fast = DocValuesFormat.forName(\"Lucene45\");\n    final DocValuesFormat slow = DocValuesFormat.forName(\"SimpleText\");\n    iwc.setCodec(new Lucene45Codec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new NumericDocValuesField(\"dv1\", 5));\n    doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = newSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    BytesRef scratch = new BytesRef();\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(5, dv.get(hits.scoreDocs[i].doc));\n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      dv2.get(hits.scoreDocs[i].doc, scratch);\n      assertEquals(new BytesRef(\"hello world\"), scratch);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","sourceOld":"  // just a simple trivial test\n  // TODO: we should come up with a test that somehow checks that segment suffix\n  // is respected by all codec apis (not just docvalues and postings)\n  public void testTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    final DocValuesFormat fast = DocValuesFormat.forName(\"Lucene42\");\n    final DocValuesFormat slow = DocValuesFormat.forName(\"SimpleText\");\n    iwc.setCodec(new Lucene42Codec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new NumericDocValuesField(\"dv1\", 5));\n    doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = newSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    BytesRef scratch = new BytesRef();\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(5, dv.get(hits.scoreDocs[i].doc));\n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      dv2.get(hits.scoreDocs[i].doc, scratch);\n      assertEquals(new BytesRef(\"hello world\"), scratch);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":["8106bc60c7452250f84c65cdb43ab6b1d8eb1534"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e70ec9cf78e14cbbf13fd0e1a9aefa8081c325ff","date":1377034255,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat#testTwoFieldsTwoFormats().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat#testTwoFieldsTwoFormats().mjava","sourceNew":"  // just a simple trivial test\n  // TODO: we should come up with a test that somehow checks that segment suffix\n  // is respected by all codec apis (not just docvalues and postings)\n  public void testTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    final DocValuesFormat fast = DocValuesFormat.forName(\"Lucene45\");\n    final DocValuesFormat slow = DocValuesFormat.forName(\"SimpleText\");\n    iwc.setCodec(new Lucene45Codec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new NumericDocValuesField(\"dv1\", 5));\n    doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = newSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    BytesRef scratch = new BytesRef();\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(5, dv.get(hits.scoreDocs[i].doc));\n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      dv2.get(hits.scoreDocs[i].doc, scratch);\n      assertEquals(new BytesRef(\"hello world\"), scratch);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","sourceOld":"  // just a simple trivial test\n  // TODO: we should come up with a test that somehow checks that segment suffix\n  // is respected by all codec apis (not just docvalues and postings)\n  public void testTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    final DocValuesFormat fast = DocValuesFormat.forName(\"Lucene42\");\n    final DocValuesFormat slow = DocValuesFormat.forName(\"SimpleText\");\n    iwc.setCodec(new Lucene42Codec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new NumericDocValuesField(\"dv1\", 5));\n    doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = newSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    BytesRef scratch = new BytesRef();\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(5, dv.get(hits.scoreDocs[i].doc));\n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      dv2.get(hits.scoreDocs[i].doc, scratch);\n      assertEquals(new BytesRef(\"hello world\"), scratch);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3dffec77fb8f7d0e9ca4869dddd6af94528b4576","date":1377875202,"type":3,"author":"Han Jiang","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat#testTwoFieldsTwoFormats().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat#testTwoFieldsTwoFormats().mjava","sourceNew":"  // just a simple trivial test\n  // TODO: we should come up with a test that somehow checks that segment suffix\n  // is respected by all codec apis (not just docvalues and postings)\n  public void testTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    final DocValuesFormat fast = DocValuesFormat.forName(\"Lucene45\");\n    final DocValuesFormat slow = DocValuesFormat.forName(\"SimpleText\");\n    iwc.setCodec(new Lucene45Codec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new NumericDocValuesField(\"dv1\", 5));\n    doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = newSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    BytesRef scratch = new BytesRef();\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(5, dv.get(hits.scoreDocs[i].doc));\n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      dv2.get(hits.scoreDocs[i].doc, scratch);\n      assertEquals(new BytesRef(\"hello world\"), scratch);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","sourceOld":"  // just a simple trivial test\n  // TODO: we should come up with a test that somehow checks that segment suffix\n  // is respected by all codec apis (not just docvalues and postings)\n  public void testTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    final DocValuesFormat fast = DocValuesFormat.forName(\"Lucene42\");\n    final DocValuesFormat slow = DocValuesFormat.forName(\"SimpleText\");\n    iwc.setCodec(new Lucene42Codec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new NumericDocValuesField(\"dv1\", 5));\n    doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = newSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    BytesRef scratch = new BytesRef();\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(5, dv.get(hits.scoreDocs[i].doc));\n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      dv2.get(hits.scoreDocs[i].doc, scratch);\n      assertEquals(new BytesRef(\"hello world\"), scratch);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8435160e9702b19398118ddf76b61c846612b6a4","date":1380349140,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat#testTwoFieldsTwoFormats().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat#testTwoFieldsTwoFormats().mjava","sourceNew":"  // just a simple trivial test\n  // TODO: we should come up with a test that somehow checks that segment suffix\n  // is respected by all codec apis (not just docvalues and postings)\n  public void testTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    final DocValuesFormat fast = DocValuesFormat.forName(\"Lucene45\");\n    final DocValuesFormat slow = DocValuesFormat.forName(\"SimpleText\");\n    iwc.setCodec(new Lucene46Codec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new NumericDocValuesField(\"dv1\", 5));\n    doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = newSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    BytesRef scratch = new BytesRef();\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(5, dv.get(hits.scoreDocs[i].doc));\n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      dv2.get(hits.scoreDocs[i].doc, scratch);\n      assertEquals(new BytesRef(\"hello world\"), scratch);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","sourceOld":"  // just a simple trivial test\n  // TODO: we should come up with a test that somehow checks that segment suffix\n  // is respected by all codec apis (not just docvalues and postings)\n  public void testTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    final DocValuesFormat fast = DocValuesFormat.forName(\"Lucene45\");\n    final DocValuesFormat slow = DocValuesFormat.forName(\"SimpleText\");\n    iwc.setCodec(new Lucene45Codec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new NumericDocValuesField(\"dv1\", 5));\n    doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = newSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    BytesRef scratch = new BytesRef();\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(5, dv.get(hits.scoreDocs[i].doc));\n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      dv2.get(hits.scoreDocs[i].doc, scratch);\n      assertEquals(new BytesRef(\"hello world\"), scratch);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":["8106bc60c7452250f84c65cdb43ab6b1d8eb1534"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat#testTwoFieldsTwoFormats().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat#testTwoFieldsTwoFormats().mjava","sourceNew":"  // just a simple trivial test\n  // TODO: we should come up with a test that somehow checks that segment suffix\n  // is respected by all codec apis (not just docvalues and postings)\n  public void testTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    final DocValuesFormat fast = DocValuesFormat.forName(\"Lucene45\");\n    final DocValuesFormat slow = DocValuesFormat.forName(\"SimpleText\");\n    iwc.setCodec(new Lucene46Codec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new NumericDocValuesField(\"dv1\", 5));\n    doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.shutdown();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = newSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    BytesRef scratch = new BytesRef();\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(5, dv.get(hits.scoreDocs[i].doc));\n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      dv2.get(hits.scoreDocs[i].doc, scratch);\n      assertEquals(new BytesRef(\"hello world\"), scratch);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","sourceOld":"  // just a simple trivial test\n  // TODO: we should come up with a test that somehow checks that segment suffix\n  // is respected by all codec apis (not just docvalues and postings)\n  public void testTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    final DocValuesFormat fast = DocValuesFormat.forName(\"Lucene45\");\n    final DocValuesFormat slow = DocValuesFormat.forName(\"SimpleText\");\n    iwc.setCodec(new Lucene46Codec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new NumericDocValuesField(\"dv1\", 5));\n    doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = newSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    BytesRef scratch = new BytesRef();\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(5, dv.get(hits.scoreDocs[i].doc));\n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      dv2.get(hits.scoreDocs[i].doc, scratch);\n      assertEquals(new BytesRef(\"hello world\"), scratch);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8106bc60c7452250f84c65cdb43ab6b1d8eb1534","date":1401906364,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat#testTwoFieldsTwoFormats().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat#testTwoFieldsTwoFormats().mjava","sourceNew":"  // just a simple trivial test\n  // TODO: we should come up with a test that somehow checks that segment suffix\n  // is respected by all codec apis (not just docvalues and postings)\n  public void testTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    final DocValuesFormat fast = DocValuesFormat.forName(\"Lucene49\");\n    final DocValuesFormat slow = DocValuesFormat.forName(\"SimpleText\");\n    iwc.setCodec(new Lucene49Codec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new NumericDocValuesField(\"dv1\", 5));\n    doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.shutdown();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = newSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    BytesRef scratch = new BytesRef();\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(5, dv.get(hits.scoreDocs[i].doc));\n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      dv2.get(hits.scoreDocs[i].doc, scratch);\n      assertEquals(new BytesRef(\"hello world\"), scratch);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","sourceOld":"  // just a simple trivial test\n  // TODO: we should come up with a test that somehow checks that segment suffix\n  // is respected by all codec apis (not just docvalues and postings)\n  public void testTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    final DocValuesFormat fast = DocValuesFormat.forName(\"Lucene45\");\n    final DocValuesFormat slow = DocValuesFormat.forName(\"SimpleText\");\n    iwc.setCodec(new Lucene46Codec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new NumericDocValuesField(\"dv1\", 5));\n    doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.shutdown();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = newSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    BytesRef scratch = new BytesRef();\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(5, dv.get(hits.scoreDocs[i].doc));\n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      dv2.get(hits.scoreDocs[i].doc, scratch);\n      assertEquals(new BytesRef(\"hello world\"), scratch);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","bugFix":["8435160e9702b19398118ddf76b61c846612b6a4","11a746437bc5c0a0b3df0337ed249c387c812871"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"53fc2f4c5ce4f2053be3d5f5d14d79129ebb4bbf","date":1401983689,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat#testTwoFieldsTwoFormats().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat#testTwoFieldsTwoFormats().mjava","sourceNew":"  // just a simple trivial test\n  // TODO: we should come up with a test that somehow checks that segment suffix\n  // is respected by all codec apis (not just docvalues and postings)\n  public void testTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    final DocValuesFormat fast = DocValuesFormat.forName(\"Lucene49\");\n    final DocValuesFormat slow = DocValuesFormat.forName(\"SimpleText\");\n    iwc.setCodec(new Lucene49Codec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new NumericDocValuesField(\"dv1\", 5));\n    doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.shutdown();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = newSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(5, dv.get(hits.scoreDocs[i].doc));\n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      final BytesRef term = dv2.get(hits.scoreDocs[i].doc);\n      assertEquals(new BytesRef(\"hello world\"), term);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","sourceOld":"  // just a simple trivial test\n  // TODO: we should come up with a test that somehow checks that segment suffix\n  // is respected by all codec apis (not just docvalues and postings)\n  public void testTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    final DocValuesFormat fast = DocValuesFormat.forName(\"Lucene49\");\n    final DocValuesFormat slow = DocValuesFormat.forName(\"SimpleText\");\n    iwc.setCodec(new Lucene49Codec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new NumericDocValuesField(\"dv1\", 5));\n    doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.shutdown();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = newSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    BytesRef scratch = new BytesRef();\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(5, dv.get(hits.scoreDocs[i].doc));\n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      dv2.get(hits.scoreDocs[i].doc, scratch);\n      assertEquals(new BytesRef(\"hello world\"), scratch);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat#testTwoFieldsTwoFormats().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat#testTwoFieldsTwoFormats().mjava","sourceNew":"  // just a simple trivial test\n  // TODO: we should come up with a test that somehow checks that segment suffix\n  // is respected by all codec apis (not just docvalues and postings)\n  public void testTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    final DocValuesFormat fast = DocValuesFormat.forName(\"Lucene49\");\n    final DocValuesFormat slow = DocValuesFormat.forName(\"SimpleText\");\n    iwc.setCodec(new Lucene49Codec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new NumericDocValuesField(\"dv1\", 5));\n    doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.shutdown();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = newSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(5, dv.get(hits.scoreDocs[i].doc));\n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      final BytesRef term = dv2.get(hits.scoreDocs[i].doc);\n      assertEquals(new BytesRef(\"hello world\"), term);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","sourceOld":"  // just a simple trivial test\n  // TODO: we should come up with a test that somehow checks that segment suffix\n  // is respected by all codec apis (not just docvalues and postings)\n  public void testTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    final DocValuesFormat fast = DocValuesFormat.forName(\"Lucene49\");\n    final DocValuesFormat slow = DocValuesFormat.forName(\"SimpleText\");\n    iwc.setCodec(new Lucene49Codec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new NumericDocValuesField(\"dv1\", 5));\n    doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.shutdown();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = newSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(5, dv.get(hits.scoreDocs[i].doc));\n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      final BytesRef term = dv2.get(hits.scoreDocs[i].doc);\n      assertEquals(new BytesRef(\"hello world\"), term);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat#testTwoFieldsTwoFormats().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat#testTwoFieldsTwoFormats().mjava","sourceNew":"  // just a simple trivial test\n  // TODO: we should come up with a test that somehow checks that segment suffix\n  // is respected by all codec apis (not just docvalues and postings)\n  public void testTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    final DocValuesFormat fast = DocValuesFormat.forName(\"Lucene49\");\n    final DocValuesFormat slow = DocValuesFormat.forName(\"SimpleText\");\n    iwc.setCodec(new Lucene49Codec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new NumericDocValuesField(\"dv1\", 5));\n    doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = newSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(5, dv.get(hits.scoreDocs[i].doc));\n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      final BytesRef term = dv2.get(hits.scoreDocs[i].doc);\n      assertEquals(new BytesRef(\"hello world\"), term);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","sourceOld":"  // just a simple trivial test\n  // TODO: we should come up with a test that somehow checks that segment suffix\n  // is respected by all codec apis (not just docvalues and postings)\n  public void testTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    final DocValuesFormat fast = DocValuesFormat.forName(\"Lucene49\");\n    final DocValuesFormat slow = DocValuesFormat.forName(\"SimpleText\");\n    iwc.setCodec(new Lucene49Codec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new NumericDocValuesField(\"dv1\", 5));\n    doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.shutdown();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = newSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(5, dv.get(hits.scoreDocs[i].doc));\n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      final BytesRef term = dv2.get(hits.scoreDocs[i].doc);\n      assertEquals(new BytesRef(\"hello world\"), term);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0ce5e7f280a7b3f0f96f2623d9f0ce70f742b793","date":1408030244,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat#testTwoFieldsTwoFormats().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat#testTwoFieldsTwoFormats().mjava","sourceNew":"  // just a simple trivial test\n  // TODO: we should come up with a test that somehow checks that segment suffix\n  // is respected by all codec apis (not just docvalues and postings)\n  public void testTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    final DocValuesFormat fast = DocValuesFormat.forName(\"Lucene410\");\n    final DocValuesFormat slow = DocValuesFormat.forName(\"SimpleText\");\n    iwc.setCodec(new Lucene410Codec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new NumericDocValuesField(\"dv1\", 5));\n    doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = newSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(5, dv.get(hits.scoreDocs[i].doc));\n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      final BytesRef term = dv2.get(hits.scoreDocs[i].doc);\n      assertEquals(new BytesRef(\"hello world\"), term);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","sourceOld":"  // just a simple trivial test\n  // TODO: we should come up with a test that somehow checks that segment suffix\n  // is respected by all codec apis (not just docvalues and postings)\n  public void testTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    final DocValuesFormat fast = DocValuesFormat.forName(\"Lucene49\");\n    final DocValuesFormat slow = DocValuesFormat.forName(\"SimpleText\");\n    iwc.setCodec(new Lucene49Codec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new NumericDocValuesField(\"dv1\", 5));\n    doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = newSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(5, dv.get(hits.scoreDocs[i].doc));\n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      final BytesRef term = dv2.get(hits.scoreDocs[i].doc);\n      assertEquals(new BytesRef(\"hello world\"), term);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e49088db00ea6cb232fbde9c8c646c721d4d049f","date":1411433559,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat#testTwoFieldsTwoFormats().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat#testTwoFieldsTwoFormats().mjava","sourceNew":"  // just a simple trivial test\n  // TODO: we should come up with a test that somehow checks that segment suffix\n  // is respected by all codec apis (not just docvalues and postings)\n  public void testTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    final DocValuesFormat fast = TestUtil.getDefaultDocValuesFormat();\n    final DocValuesFormat slow = DocValuesFormat.forName(\"SimpleText\");\n    iwc.setCodec(new AssertingCodec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new NumericDocValuesField(\"dv1\", 5));\n    doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = newSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(5, dv.get(hits.scoreDocs[i].doc));\n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      final BytesRef term = dv2.get(hits.scoreDocs[i].doc);\n      assertEquals(new BytesRef(\"hello world\"), term);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","sourceOld":"  // just a simple trivial test\n  // TODO: we should come up with a test that somehow checks that segment suffix\n  // is respected by all codec apis (not just docvalues and postings)\n  public void testTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    final DocValuesFormat fast = DocValuesFormat.forName(\"Lucene410\");\n    final DocValuesFormat slow = DocValuesFormat.forName(\"SimpleText\");\n    iwc.setCodec(new Lucene410Codec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new NumericDocValuesField(\"dv1\", 5));\n    doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = newSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(5, dv.get(hits.scoreDocs[i].doc));\n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      final BytesRef term = dv2.get(hits.scoreDocs[i].doc);\n      assertEquals(new BytesRef(\"hello world\"), term);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc","date":1424799790,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat#testTwoFieldsTwoFormats().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat#testTwoFieldsTwoFormats().mjava","sourceNew":"  // just a simple trivial test\n  // TODO: we should come up with a test that somehow checks that segment suffix\n  // is respected by all codec apis (not just docvalues and postings)\n  public void testTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    final DocValuesFormat fast = TestUtil.getDefaultDocValuesFormat();\n    final DocValuesFormat slow = DocValuesFormat.forName(\"SimpleText\");\n    iwc.setCodec(new AssertingCodec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new NumericDocValuesField(\"dv1\", 5));\n    doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = newSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(5, dv.get(hits.scoreDocs[i].doc));\n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      final BytesRef term = dv2.get(hits.scoreDocs[i].doc);\n      assertEquals(new BytesRef(\"hello world\"), term);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","sourceOld":"  // just a simple trivial test\n  // TODO: we should come up with a test that somehow checks that segment suffix\n  // is respected by all codec apis (not just docvalues and postings)\n  public void testTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    final DocValuesFormat fast = TestUtil.getDefaultDocValuesFormat();\n    final DocValuesFormat slow = DocValuesFormat.forName(\"SimpleText\");\n    iwc.setCodec(new AssertingCodec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new NumericDocValuesField(\"dv1\", 5));\n    doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = newSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(5, dv.get(hits.scoreDocs[i].doc));\n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      final BytesRef term = dv2.get(hits.scoreDocs[i].doc);\n      assertEquals(new BytesRef(\"hello world\"), term);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c","date":1453060490,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat#testTwoFieldsTwoFormats().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat#testTwoFieldsTwoFormats().mjava","sourceNew":"  // just a simple trivial test\n  // TODO: we should come up with a test that somehow checks that segment suffix\n  // is respected by all codec apis (not just docvalues and postings)\n  public void testTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    final DocValuesFormat fast = TestUtil.getDefaultDocValuesFormat();\n    final DocValuesFormat slow = DocValuesFormat.forName(\"SimpleText\");\n    iwc.setCodec(new AssertingCodec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new NumericDocValuesField(\"dv1\", 5));\n    doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = newSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(5, dv.get(hits.scoreDocs[i].doc));\n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      final BytesRef term = dv2.get(hits.scoreDocs[i].doc);\n      assertEquals(new BytesRef(\"hello world\"), term);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","sourceOld":"  // just a simple trivial test\n  // TODO: we should come up with a test that somehow checks that segment suffix\n  // is respected by all codec apis (not just docvalues and postings)\n  public void testTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    final DocValuesFormat fast = TestUtil.getDefaultDocValuesFormat();\n    final DocValuesFormat slow = DocValuesFormat.forName(\"SimpleText\");\n    iwc.setCodec(new AssertingCodec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new NumericDocValuesField(\"dv1\", 5));\n    doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = newSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(5, dv.get(hits.scoreDocs[i].doc));\n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      final BytesRef term = dv2.get(hits.scoreDocs[i].doc);\n      assertEquals(new BytesRef(\"hello world\"), term);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"71488d7f5786ae87541276121ecb69705a11a295","date":1465498138,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat#testTwoFieldsTwoFormats().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat#testTwoFieldsTwoFormats().mjava","sourceNew":"  // just a simple trivial test\n  // TODO: we should come up with a test that somehow checks that segment suffix\n  // is respected by all codec apis (not just docvalues and postings)\n  public void testTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    final DocValuesFormat fast = TestUtil.getDefaultDocValuesFormat();\n    final DocValuesFormat slow = DocValuesFormat.forName(\"Memory\");\n    iwc.setCodec(new AssertingCodec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new NumericDocValuesField(\"dv1\", 5));\n    doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = newSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(5, dv.get(hits.scoreDocs[i].doc));\n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      final BytesRef term = dv2.get(hits.scoreDocs[i].doc);\n      assertEquals(new BytesRef(\"hello world\"), term);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","sourceOld":"  // just a simple trivial test\n  // TODO: we should come up with a test that somehow checks that segment suffix\n  // is respected by all codec apis (not just docvalues and postings)\n  public void testTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    final DocValuesFormat fast = TestUtil.getDefaultDocValuesFormat();\n    final DocValuesFormat slow = DocValuesFormat.forName(\"SimpleText\");\n    iwc.setCodec(new AssertingCodec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new NumericDocValuesField(\"dv1\", 5));\n    doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = newSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(5, dv.get(hits.scoreDocs[i].doc));\n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      final BytesRef term = dv2.get(hits.scoreDocs[i].doc);\n      assertEquals(new BytesRef(\"hello world\"), term);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6652c74b2358a0b13223817a6a793bf1c9d0749d","date":1474465301,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat#testTwoFieldsTwoFormats().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat#testTwoFieldsTwoFormats().mjava","sourceNew":"  // just a simple trivial test\n  // TODO: we should come up with a test that somehow checks that segment suffix\n  // is respected by all codec apis (not just docvalues and postings)\n  public void testTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    final DocValuesFormat fast = TestUtil.getDefaultDocValuesFormat();\n    final DocValuesFormat slow = DocValuesFormat.forName(\"Memory\");\n    iwc.setCodec(new AssertingCodec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new NumericDocValuesField(\"dv1\", 5));\n    doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = newSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      int hitDocID = hits.scoreDocs[i].doc;\n      Document hitDoc = isearcher.doc(hitDocID);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(hitDocID, dv.advance(hitDocID));\n      assertEquals(5, dv.longValue());\n      \n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      assertEquals(hitDocID, dv2.advance(hitDocID));\n      final BytesRef term = dv2.binaryValue();\n      assertEquals(new BytesRef(\"hello world\"), term);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","sourceOld":"  // just a simple trivial test\n  // TODO: we should come up with a test that somehow checks that segment suffix\n  // is respected by all codec apis (not just docvalues and postings)\n  public void testTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    final DocValuesFormat fast = TestUtil.getDefaultDocValuesFormat();\n    final DocValuesFormat slow = DocValuesFormat.forName(\"Memory\");\n    iwc.setCodec(new AssertingCodec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new NumericDocValuesField(\"dv1\", 5));\n    doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = newSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(5, dv.get(hits.scoreDocs[i].doc));\n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      final BytesRef term = dv2.get(hits.scoreDocs[i].doc);\n      assertEquals(new BytesRef(\"hello world\"), term);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"17e5da53e4e5bd659e22add9bba1cfa222e7e30d","date":1475435902,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat#testTwoFieldsTwoFormats().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat#testTwoFieldsTwoFormats().mjava","sourceNew":"  // just a simple trivial test\n  // TODO: we should come up with a test that somehow checks that segment suffix\n  // is respected by all codec apis (not just docvalues and postings)\n  public void testTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    final DocValuesFormat fast = TestUtil.getDefaultDocValuesFormat();\n    final DocValuesFormat slow = DocValuesFormat.forName(\"Memory\");\n    iwc.setCodec(new AssertingCodec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new NumericDocValuesField(\"dv1\", 5));\n    doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = newSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      int hitDocID = hits.scoreDocs[i].doc;\n      Document hitDoc = isearcher.doc(hitDocID);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(hitDocID, dv.advance(hitDocID));\n      assertEquals(5, dv.longValue());\n      \n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      assertEquals(hitDocID, dv2.advance(hitDocID));\n      final BytesRef term = dv2.binaryValue();\n      assertEquals(new BytesRef(\"hello world\"), term);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","sourceOld":"  // just a simple trivial test\n  // TODO: we should come up with a test that somehow checks that segment suffix\n  // is respected by all codec apis (not just docvalues and postings)\n  public void testTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    final DocValuesFormat fast = TestUtil.getDefaultDocValuesFormat();\n    final DocValuesFormat slow = DocValuesFormat.forName(\"Memory\");\n    iwc.setCodec(new AssertingCodec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new NumericDocValuesField(\"dv1\", 5));\n    doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = newSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(5, dv.get(hits.scoreDocs[i].doc));\n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      final BytesRef term = dv2.get(hits.scoreDocs[i].doc);\n      assertEquals(new BytesRef(\"hello world\"), term);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat#testTwoFieldsTwoFormats().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat#testTwoFieldsTwoFormats().mjava","sourceNew":"  // just a simple trivial test\n  // TODO: we should come up with a test that somehow checks that segment suffix\n  // is respected by all codec apis (not just docvalues and postings)\n  public void testTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    final DocValuesFormat fast = TestUtil.getDefaultDocValuesFormat();\n    final DocValuesFormat slow = DocValuesFormat.forName(\"Memory\");\n    iwc.setCodec(new AssertingCodec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new NumericDocValuesField(\"dv1\", 5));\n    doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = newSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      int hitDocID = hits.scoreDocs[i].doc;\n      Document hitDoc = isearcher.doc(hitDocID);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(hitDocID, dv.advance(hitDocID));\n      assertEquals(5, dv.longValue());\n      \n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      assertEquals(hitDocID, dv2.advance(hitDocID));\n      final BytesRef term = dv2.binaryValue();\n      assertEquals(new BytesRef(\"hello world\"), term);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","sourceOld":"  // just a simple trivial test\n  // TODO: we should come up with a test that somehow checks that segment suffix\n  // is respected by all codec apis (not just docvalues and postings)\n  public void testTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    final DocValuesFormat fast = TestUtil.getDefaultDocValuesFormat();\n    final DocValuesFormat slow = DocValuesFormat.forName(\"SimpleText\");\n    iwc.setCodec(new AssertingCodec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new NumericDocValuesField(\"dv1\", 5));\n    doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = newSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(5, dv.get(hits.scoreDocs[i].doc));\n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      final BytesRef term = dv2.get(hits.scoreDocs[i].doc);\n      assertEquals(new BytesRef(\"hello world\"), term);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"24f89e8a6aac05753cde4c83d62a74356098200d","date":1525768331,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat#testTwoFieldsTwoFormats().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat#testTwoFieldsTwoFormats().mjava","sourceNew":"  // just a simple trivial test\n  // TODO: we should come up with a test that somehow checks that segment suffix\n  // is respected by all codec apis (not just docvalues and postings)\n  public void testTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    final DocValuesFormat fast = TestUtil.getDefaultDocValuesFormat();\n    final DocValuesFormat slow = DocValuesFormat.forName(\"Direct\");\n    iwc.setCodec(new AssertingCodec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new NumericDocValuesField(\"dv1\", 5));\n    doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = newSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      int hitDocID = hits.scoreDocs[i].doc;\n      Document hitDoc = isearcher.doc(hitDocID);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(hitDocID, dv.advance(hitDocID));\n      assertEquals(5, dv.longValue());\n      \n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      assertEquals(hitDocID, dv2.advance(hitDocID));\n      final BytesRef term = dv2.binaryValue();\n      assertEquals(new BytesRef(\"hello world\"), term);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","sourceOld":"  // just a simple trivial test\n  // TODO: we should come up with a test that somehow checks that segment suffix\n  // is respected by all codec apis (not just docvalues and postings)\n  public void testTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    final DocValuesFormat fast = TestUtil.getDefaultDocValuesFormat();\n    final DocValuesFormat slow = DocValuesFormat.forName(\"Memory\");\n    iwc.setCodec(new AssertingCodec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new NumericDocValuesField(\"dv1\", 5));\n    doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = newSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      int hitDocID = hits.scoreDocs[i].doc;\n      Document hitDoc = isearcher.doc(hitDocID);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(hitDocID, dv.advance(hitDocID));\n      assertEquals(5, dv.longValue());\n      \n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      assertEquals(hitDocID, dv2.advance(hitDocID));\n      final BytesRef term = dv2.binaryValue();\n      assertEquals(new BytesRef(\"hello world\"), term);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"470eaac3a77cf637b62126a5408b178d7be93eb1","date":1531830722,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat#testTwoFieldsTwoFormats().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat#testTwoFieldsTwoFormats().mjava","sourceNew":"  // just a simple trivial test\n  // TODO: we should come up with a test that somehow checks that segment suffix\n  // is respected by all codec apis (not just docvalues and postings)\n  public void testTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    final DocValuesFormat fast = TestUtil.getDefaultDocValuesFormat();\n    final DocValuesFormat slow = DocValuesFormat.forName(\"Direct\");\n    iwc.setCodec(new AssertingCodec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new NumericDocValuesField(\"dv1\", 5));\n    doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = newSearcher(ireader);\n\n    assertEquals(1, isearcher.count(new TermQuery(new Term(\"fieldname\", longTerm))));\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      int hitDocID = hits.scoreDocs[i].doc;\n      Document hitDoc = isearcher.doc(hitDocID);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(hitDocID, dv.advance(hitDocID));\n      assertEquals(5, dv.longValue());\n      \n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      assertEquals(hitDocID, dv2.advance(hitDocID));\n      final BytesRef term = dv2.binaryValue();\n      assertEquals(new BytesRef(\"hello world\"), term);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","sourceOld":"  // just a simple trivial test\n  // TODO: we should come up with a test that somehow checks that segment suffix\n  // is respected by all codec apis (not just docvalues and postings)\n  public void testTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    final DocValuesFormat fast = TestUtil.getDefaultDocValuesFormat();\n    final DocValuesFormat slow = DocValuesFormat.forName(\"Direct\");\n    iwc.setCodec(new AssertingCodec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new NumericDocValuesField(\"dv1\", 5));\n    doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = newSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      int hitDocID = hits.scoreDocs[i].doc;\n      Document hitDoc = isearcher.doc(hitDocID);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(hitDocID, dv.advance(hitDocID));\n      assertEquals(5, dv.longValue());\n      \n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      assertEquals(hitDocID, dv2.advance(hitDocID));\n      final BytesRef term = dv2.binaryValue();\n      assertEquals(new BytesRef(\"hello world\"), term);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","date":1531905561,"type":3,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat#testTwoFieldsTwoFormats().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat#testTwoFieldsTwoFormats().mjava","sourceNew":"  // just a simple trivial test\n  // TODO: we should come up with a test that somehow checks that segment suffix\n  // is respected by all codec apis (not just docvalues and postings)\n  public void testTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    final DocValuesFormat fast = TestUtil.getDefaultDocValuesFormat();\n    final DocValuesFormat slow = DocValuesFormat.forName(\"Direct\");\n    iwc.setCodec(new AssertingCodec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new NumericDocValuesField(\"dv1\", 5));\n    doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = newSearcher(ireader);\n\n    assertEquals(1, isearcher.count(new TermQuery(new Term(\"fieldname\", longTerm))));\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      int hitDocID = hits.scoreDocs[i].doc;\n      Document hitDoc = isearcher.doc(hitDocID);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(hitDocID, dv.advance(hitDocID));\n      assertEquals(5, dv.longValue());\n      \n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      assertEquals(hitDocID, dv2.advance(hitDocID));\n      final BytesRef term = dv2.binaryValue();\n      assertEquals(new BytesRef(\"hello world\"), term);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","sourceOld":"  // just a simple trivial test\n  // TODO: we should come up with a test that somehow checks that segment suffix\n  // is respected by all codec apis (not just docvalues and postings)\n  public void testTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    final DocValuesFormat fast = TestUtil.getDefaultDocValuesFormat();\n    final DocValuesFormat slow = DocValuesFormat.forName(\"Direct\");\n    iwc.setCodec(new AssertingCodec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new NumericDocValuesField(\"dv1\", 5));\n    doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = newSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      int hitDocID = hits.scoreDocs[i].doc;\n      Document hitDoc = isearcher.doc(hitDocID);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(hitDocID, dv.advance(hitDocID));\n      assertEquals(5, dv.longValue());\n      \n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      assertEquals(hitDocID, dv2.advance(hitDocID));\n      final BytesRef term = dv2.binaryValue();\n      assertEquals(new BytesRef(\"hello world\"), term);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"83788ad129a5154d5c6562c4e8ce3db48793aada","date":1532961485,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat#testTwoFieldsTwoFormats().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat#testTwoFieldsTwoFormats().mjava","sourceNew":"  // just a simple trivial test\n  // TODO: we should come up with a test that somehow checks that segment suffix\n  // is respected by all codec apis (not just docvalues and postings)\n  public void testTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    final DocValuesFormat fast = TestUtil.getDefaultDocValuesFormat();\n    final DocValuesFormat slow = DocValuesFormat.forName(\"Direct\");\n    iwc.setCodec(new AssertingCodec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new NumericDocValuesField(\"dv1\", 5));\n    doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = newSearcher(ireader);\n\n    assertEquals(1, isearcher.count(new TermQuery(new Term(\"fieldname\", longTerm))));\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, 1);\n    assertEquals(1, hits.totalHits.value);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      int hitDocID = hits.scoreDocs[i].doc;\n      Document hitDoc = isearcher.doc(hitDocID);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(hitDocID, dv.advance(hitDocID));\n      assertEquals(5, dv.longValue());\n      \n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      assertEquals(hitDocID, dv2.advance(hitDocID));\n      final BytesRef term = dv2.binaryValue();\n      assertEquals(new BytesRef(\"hello world\"), term);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","sourceOld":"  // just a simple trivial test\n  // TODO: we should come up with a test that somehow checks that segment suffix\n  // is respected by all codec apis (not just docvalues and postings)\n  public void testTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    final DocValuesFormat fast = TestUtil.getDefaultDocValuesFormat();\n    final DocValuesFormat slow = DocValuesFormat.forName(\"Direct\");\n    iwc.setCodec(new AssertingCodec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new NumericDocValuesField(\"dv1\", 5));\n    doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = newSearcher(ireader);\n\n    assertEquals(1, isearcher.count(new TermQuery(new Term(\"fieldname\", longTerm))));\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      int hitDocID = hits.scoreDocs[i].doc;\n      Document hitDoc = isearcher.doc(hitDocID);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(hitDocID, dv.advance(hitDocID));\n      assertEquals(5, dv.longValue());\n      \n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      assertEquals(hitDocID, dv2.advance(hitDocID));\n      final BytesRef term = dv2.binaryValue();\n      assertEquals(new BytesRef(\"hello world\"), term);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"49895fdba9e90c6af3763513a4a2865a4ba588bc","date":1567675638,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat#testTwoFieldsTwoFormats().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat#testTwoFieldsTwoFormats().mjava","sourceNew":"  // just a simple trivial test\n  // TODO: we should come up with a test that somehow checks that segment suffix\n  // is respected by all codec apis (not just docvalues and postings)\n  public void testTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    final DocValuesFormat fast = TestUtil.getDefaultDocValuesFormat();\n    final DocValuesFormat slow = DocValuesFormat.forName(\"Asserting\");\n    iwc.setCodec(new AssertingCodec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new NumericDocValuesField(\"dv1\", 5));\n    doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = newSearcher(ireader);\n\n    assertEquals(1, isearcher.count(new TermQuery(new Term(\"fieldname\", longTerm))));\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, 1);\n    assertEquals(1, hits.totalHits.value);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      int hitDocID = hits.scoreDocs[i].doc;\n      Document hitDoc = isearcher.doc(hitDocID);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(hitDocID, dv.advance(hitDocID));\n      assertEquals(5, dv.longValue());\n      \n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      assertEquals(hitDocID, dv2.advance(hitDocID));\n      final BytesRef term = dv2.binaryValue();\n      assertEquals(new BytesRef(\"hello world\"), term);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","sourceOld":"  // just a simple trivial test\n  // TODO: we should come up with a test that somehow checks that segment suffix\n  // is respected by all codec apis (not just docvalues and postings)\n  public void testTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    final DocValuesFormat fast = TestUtil.getDefaultDocValuesFormat();\n    final DocValuesFormat slow = DocValuesFormat.forName(\"Direct\");\n    iwc.setCodec(new AssertingCodec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new NumericDocValuesField(\"dv1\", 5));\n    doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = newSearcher(ireader);\n\n    assertEquals(1, isearcher.count(new TermQuery(new Term(\"fieldname\", longTerm))));\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, 1);\n    assertEquals(1, hits.totalHits.value);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      int hitDocID = hits.scoreDocs[i].doc;\n      Document hitDoc = isearcher.doc(hitDocID);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(hitDocID, dv.advance(hitDocID));\n      assertEquals(5, dv.longValue());\n      \n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      assertEquals(hitDocID, dv2.advance(hitDocID));\n      final BytesRef term = dv2.binaryValue();\n      assertEquals(new BytesRef(\"hello world\"), term);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"e49088db00ea6cb232fbde9c8c646c721d4d049f":["0ce5e7f280a7b3f0f96f2623d9f0ce70f742b793"],"3b0e8c39ca08b5a02de6edcd33d6f3b90b865173":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"11a746437bc5c0a0b3df0337ed249c387c812871":["3b0e8c39ca08b5a02de6edcd33d6f3b90b865173"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":["24f89e8a6aac05753cde4c83d62a74356098200d","470eaac3a77cf637b62126a5408b178d7be93eb1"],"24f89e8a6aac05753cde4c83d62a74356098200d":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"e9eafdf27a0bda3d70664dd39f3a1683d8416dcf":["2ec08217282b5e9df023dcdff55c745ff68b1c7d"],"f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc":["e49088db00ea6cb232fbde9c8c646c721d4d049f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"17e5da53e4e5bd659e22add9bba1cfa222e7e30d":["71488d7f5786ae87541276121ecb69705a11a295","6652c74b2358a0b13223817a6a793bf1c9d0749d"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["8435160e9702b19398118ddf76b61c846612b6a4"],"83788ad129a5154d5c6562c4e8ce3db48793aada":["470eaac3a77cf637b62126a5408b178d7be93eb1"],"0ce5e7f280a7b3f0f96f2623d9f0ce70f742b793":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c":["f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["53fc2f4c5ce4f2053be3d5f5d14d79129ebb4bbf"],"53fc2f4c5ce4f2053be3d5f5d14d79129ebb4bbf":["8106bc60c7452250f84c65cdb43ab6b1d8eb1534"],"3dffec77fb8f7d0e9ca4869dddd6af94528b4576":["3b0e8c39ca08b5a02de6edcd33d6f3b90b865173","e70ec9cf78e14cbbf13fd0e1a9aefa8081c325ff"],"8435160e9702b19398118ddf76b61c846612b6a4":["e70ec9cf78e14cbbf13fd0e1a9aefa8081c325ff"],"49895fdba9e90c6af3763513a4a2865a4ba588bc":["83788ad129a5154d5c6562c4e8ce3db48793aada"],"71488d7f5786ae87541276121ecb69705a11a295":["6654c5f3ec2e4a84ef867c82d4eec872c2372c8c"],"e70ec9cf78e14cbbf13fd0e1a9aefa8081c325ff":["3b0e8c39ca08b5a02de6edcd33d6f3b90b865173","11a746437bc5c0a0b3df0337ed249c387c812871"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["6654c5f3ec2e4a84ef867c82d4eec872c2372c8c","17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"d4d69c535930b5cce125cff868d40f6373dc27d4":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","e9eafdf27a0bda3d70664dd39f3a1683d8416dcf"],"6652c74b2358a0b13223817a6a793bf1c9d0749d":["71488d7f5786ae87541276121ecb69705a11a295"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"8106bc60c7452250f84c65cdb43ab6b1d8eb1534":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"470eaac3a77cf637b62126a5408b178d7be93eb1":["24f89e8a6aac05753cde4c83d62a74356098200d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["49895fdba9e90c6af3763513a4a2865a4ba588bc"],"2ec08217282b5e9df023dcdff55c745ff68b1c7d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"e49088db00ea6cb232fbde9c8c646c721d4d049f":["f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc"],"3b0e8c39ca08b5a02de6edcd33d6f3b90b865173":["11a746437bc5c0a0b3df0337ed249c387c812871","3dffec77fb8f7d0e9ca4869dddd6af94528b4576","e70ec9cf78e14cbbf13fd0e1a9aefa8081c325ff"],"11a746437bc5c0a0b3df0337ed249c387c812871":["e70ec9cf78e14cbbf13fd0e1a9aefa8081c325ff"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":[],"24f89e8a6aac05753cde4c83d62a74356098200d":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","470eaac3a77cf637b62126a5408b178d7be93eb1"],"e9eafdf27a0bda3d70664dd39f3a1683d8416dcf":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"17e5da53e4e5bd659e22add9bba1cfa222e7e30d":["24f89e8a6aac05753cde4c83d62a74356098200d","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc":["6654c5f3ec2e4a84ef867c82d4eec872c2372c8c"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["d4d69c535930b5cce125cff868d40f6373dc27d4","2ec08217282b5e9df023dcdff55c745ff68b1c7d"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["8106bc60c7452250f84c65cdb43ab6b1d8eb1534"],"83788ad129a5154d5c6562c4e8ce3db48793aada":["49895fdba9e90c6af3763513a4a2865a4ba588bc"],"0ce5e7f280a7b3f0f96f2623d9f0ce70f742b793":["e49088db00ea6cb232fbde9c8c646c721d4d049f"],"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c":["71488d7f5786ae87541276121ecb69705a11a295","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"53fc2f4c5ce4f2053be3d5f5d14d79129ebb4bbf":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"3dffec77fb8f7d0e9ca4869dddd6af94528b4576":[],"8435160e9702b19398118ddf76b61c846612b6a4":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"71488d7f5786ae87541276121ecb69705a11a295":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d","6652c74b2358a0b13223817a6a793bf1c9d0749d"],"49895fdba9e90c6af3763513a4a2865a4ba588bc":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"e70ec9cf78e14cbbf13fd0e1a9aefa8081c325ff":["3dffec77fb8f7d0e9ca4869dddd6af94528b4576","8435160e9702b19398118ddf76b61c846612b6a4"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"d4d69c535930b5cce125cff868d40f6373dc27d4":["3b0e8c39ca08b5a02de6edcd33d6f3b90b865173"],"6652c74b2358a0b13223817a6a793bf1c9d0749d":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["0ce5e7f280a7b3f0f96f2623d9f0ce70f742b793"],"8106bc60c7452250f84c65cdb43ab6b1d8eb1534":["53fc2f4c5ce4f2053be3d5f5d14d79129ebb4bbf"],"470eaac3a77cf637b62126a5408b178d7be93eb1":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","83788ad129a5154d5c6562c4e8ce3db48793aada"],"2ec08217282b5e9df023dcdff55c745ff68b1c7d":["e9eafdf27a0bda3d70664dd39f3a1683d8416dcf"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","3dffec77fb8f7d0e9ca4869dddd6af94528b4576","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}