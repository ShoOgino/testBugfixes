{"path":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsWriter#CompressingTermVectorsWriter(Directory,SegmentInfo,String,IOContext,String,CompressionMode,int).mjava","commits":[{"id":"eda61b1e90b490cc5837200e04c02639a0d272c7","date":1358795519,"type":0,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsWriter#CompressingTermVectorsWriter(Directory,SegmentInfo,String,IOContext,String,CompressionMode,int).mjava","pathOld":"/dev/null","sourceNew":"  /** Sole constructor. */\n  public CompressingTermVectorsWriter(Directory directory, SegmentInfo si, String segmentSuffix, IOContext context,\n      String formatName, CompressionMode compressionMode, int chunkSize) throws IOException {\n    assert directory != null;\n    this.directory = directory;\n    this.segment = si.name;\n    this.segmentSuffix = segmentSuffix;\n    this.compressionMode = compressionMode;\n    this.compressor = compressionMode.newCompressor();\n    this.chunkSize = chunkSize;\n\n    numDocs = 0;\n    pendingDocs = new ArrayDeque<DocData>();\n    termSuffixes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(chunkSize, 1));\n    payloadBytes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(1, 1));\n    lastTerm = new BytesRef(ArrayUtil.oversize(30, 1));\n\n    boolean success = false;\n    IndexOutput indexStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION), context);\n    try {\n      vectorsStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION), context);\n\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      CodecUtil.writeHeader(indexStream, codecNameIdx, VERSION_CURRENT);\n      CodecUtil.writeHeader(vectorsStream, codecNameDat, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameDat) == vectorsStream.getFilePointer();\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n\n      indexWriter = new CompressingStoredFieldsIndexWriter(indexStream);\n      indexStream = null;\n\n      vectorsStream.writeVInt(PackedInts.VERSION_CURRENT);\n      vectorsStream.writeVInt(chunkSize);\n      writer = new BlockPackedWriter(vectorsStream, BLOCK_SIZE);\n\n      positionsBuf = new int[1024];\n      startOffsetsBuf = new int[1024];\n      lengthsBuf = new int[1024];\n      payloadLengthsBuf = new int[1024];\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(indexStream);\n        abort();\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["b88448324d3a96c5842455dabea63450b697b58f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"07155cdd910937cdf6877e48884d5782845c8b8b","date":1358796205,"type":0,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsWriter#CompressingTermVectorsWriter(Directory,SegmentInfo,String,IOContext,String,CompressionMode,int).mjava","pathOld":"/dev/null","sourceNew":"  /** Sole constructor. */\n  public CompressingTermVectorsWriter(Directory directory, SegmentInfo si, String segmentSuffix, IOContext context,\n      String formatName, CompressionMode compressionMode, int chunkSize) throws IOException {\n    assert directory != null;\n    this.directory = directory;\n    this.segment = si.name;\n    this.segmentSuffix = segmentSuffix;\n    this.compressionMode = compressionMode;\n    this.compressor = compressionMode.newCompressor();\n    this.chunkSize = chunkSize;\n\n    numDocs = 0;\n    pendingDocs = new ArrayDeque<DocData>();\n    termSuffixes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(chunkSize, 1));\n    payloadBytes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(1, 1));\n    lastTerm = new BytesRef(ArrayUtil.oversize(30, 1));\n\n    boolean success = false;\n    IndexOutput indexStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION), context);\n    try {\n      vectorsStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION), context);\n\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      CodecUtil.writeHeader(indexStream, codecNameIdx, VERSION_CURRENT);\n      CodecUtil.writeHeader(vectorsStream, codecNameDat, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameDat) == vectorsStream.getFilePointer();\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n\n      indexWriter = new CompressingStoredFieldsIndexWriter(indexStream);\n      indexStream = null;\n\n      vectorsStream.writeVInt(PackedInts.VERSION_CURRENT);\n      vectorsStream.writeVInt(chunkSize);\n      writer = new BlockPackedWriter(vectorsStream, BLOCK_SIZE);\n\n      positionsBuf = new int[1024];\n      startOffsetsBuf = new int[1024];\n      lengthsBuf = new int[1024];\n      payloadLengthsBuf = new int[1024];\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(indexStream);\n        abort();\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsWriter#CompressingTermVectorsWriter(Directory,SegmentInfo,String,IOContext,String,CompressionMode,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsWriter#CompressingTermVectorsWriter(Directory,SegmentInfo,String,IOContext,String,CompressionMode,int).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingTermVectorsWriter(Directory directory, SegmentInfo si, String segmentSuffix, IOContext context,\n      String formatName, CompressionMode compressionMode, int chunkSize) throws IOException {\n    assert directory != null;\n    this.directory = directory;\n    this.segment = si.name;\n    this.segmentSuffix = segmentSuffix;\n    this.compressionMode = compressionMode;\n    this.compressor = compressionMode.newCompressor();\n    this.chunkSize = chunkSize;\n\n    numDocs = 0;\n    pendingDocs = new ArrayDeque<>();\n    termSuffixes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(chunkSize, 1));\n    payloadBytes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(1, 1));\n    lastTerm = new BytesRef(ArrayUtil.oversize(30, 1));\n\n    boolean success = false;\n    IndexOutput indexStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION), context);\n    try {\n      vectorsStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION), context);\n\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      CodecUtil.writeHeader(indexStream, codecNameIdx, VERSION_CURRENT);\n      CodecUtil.writeHeader(vectorsStream, codecNameDat, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameDat) == vectorsStream.getFilePointer();\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n\n      indexWriter = new CompressingStoredFieldsIndexWriter(indexStream);\n      indexStream = null;\n\n      vectorsStream.writeVInt(PackedInts.VERSION_CURRENT);\n      vectorsStream.writeVInt(chunkSize);\n      writer = new BlockPackedWriter(vectorsStream, BLOCK_SIZE);\n\n      positionsBuf = new int[1024];\n      startOffsetsBuf = new int[1024];\n      lengthsBuf = new int[1024];\n      payloadLengthsBuf = new int[1024];\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(indexStream);\n        abort();\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingTermVectorsWriter(Directory directory, SegmentInfo si, String segmentSuffix, IOContext context,\n      String formatName, CompressionMode compressionMode, int chunkSize) throws IOException {\n    assert directory != null;\n    this.directory = directory;\n    this.segment = si.name;\n    this.segmentSuffix = segmentSuffix;\n    this.compressionMode = compressionMode;\n    this.compressor = compressionMode.newCompressor();\n    this.chunkSize = chunkSize;\n\n    numDocs = 0;\n    pendingDocs = new ArrayDeque<DocData>();\n    termSuffixes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(chunkSize, 1));\n    payloadBytes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(1, 1));\n    lastTerm = new BytesRef(ArrayUtil.oversize(30, 1));\n\n    boolean success = false;\n    IndexOutput indexStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION), context);\n    try {\n      vectorsStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION), context);\n\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      CodecUtil.writeHeader(indexStream, codecNameIdx, VERSION_CURRENT);\n      CodecUtil.writeHeader(vectorsStream, codecNameDat, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameDat) == vectorsStream.getFilePointer();\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n\n      indexWriter = new CompressingStoredFieldsIndexWriter(indexStream);\n      indexStream = null;\n\n      vectorsStream.writeVInt(PackedInts.VERSION_CURRENT);\n      vectorsStream.writeVInt(chunkSize);\n      writer = new BlockPackedWriter(vectorsStream, BLOCK_SIZE);\n\n      positionsBuf = new int[1024];\n      startOffsetsBuf = new int[1024];\n      lengthsBuf = new int[1024];\n      payloadLengthsBuf = new int[1024];\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(indexStream);\n        abort();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1f3b037cd083286b2af89f96e768f85dcd8072d6","date":1396337805,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsWriter#CompressingTermVectorsWriter(Directory,SegmentInfo,String,IOContext,String,CompressionMode,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsWriter#CompressingTermVectorsWriter(Directory,SegmentInfo,String,IOContext,String,CompressionMode,int).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingTermVectorsWriter(Directory directory, SegmentInfo si, String segmentSuffix, IOContext context,\n      String formatName, CompressionMode compressionMode, int chunkSize) throws IOException {\n    assert directory != null;\n    this.directory = directory;\n    this.segment = si.name;\n    this.segmentSuffix = segmentSuffix;\n    this.compressionMode = compressionMode;\n    this.compressor = compressionMode.newCompressor();\n    this.chunkSize = chunkSize;\n\n    numDocs = 0;\n    pendingDocs = new ArrayDeque<>();\n    termSuffixes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(chunkSize, 1));\n    payloadBytes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(1, 1));\n    lastTerm = new BytesRef(ArrayUtil.oversize(30, 1));\n\n    boolean success = false;\n    IndexOutput indexStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION), \n                                                                     context);\n    try {\n      vectorsStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION),\n                                                     context);\n\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      CodecUtil.writeHeader(indexStream, codecNameIdx, VERSION_CURRENT);\n      CodecUtil.writeHeader(vectorsStream, codecNameDat, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameDat) == vectorsStream.getFilePointer();\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n\n      indexWriter = new CompressingStoredFieldsIndexWriter(indexStream);\n      indexStream = null;\n\n      vectorsStream.writeVInt(PackedInts.VERSION_CURRENT);\n      vectorsStream.writeVInt(chunkSize);\n      writer = new BlockPackedWriter(vectorsStream, BLOCK_SIZE);\n\n      positionsBuf = new int[1024];\n      startOffsetsBuf = new int[1024];\n      lengthsBuf = new int[1024];\n      payloadLengthsBuf = new int[1024];\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(indexStream);\n        abort();\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingTermVectorsWriter(Directory directory, SegmentInfo si, String segmentSuffix, IOContext context,\n      String formatName, CompressionMode compressionMode, int chunkSize) throws IOException {\n    assert directory != null;\n    this.directory = directory;\n    this.segment = si.name;\n    this.segmentSuffix = segmentSuffix;\n    this.compressionMode = compressionMode;\n    this.compressor = compressionMode.newCompressor();\n    this.chunkSize = chunkSize;\n\n    numDocs = 0;\n    pendingDocs = new ArrayDeque<>();\n    termSuffixes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(chunkSize, 1));\n    payloadBytes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(1, 1));\n    lastTerm = new BytesRef(ArrayUtil.oversize(30, 1));\n\n    boolean success = false;\n    IndexOutput indexStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION), context);\n    try {\n      vectorsStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION), context);\n\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      CodecUtil.writeHeader(indexStream, codecNameIdx, VERSION_CURRENT);\n      CodecUtil.writeHeader(vectorsStream, codecNameDat, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameDat) == vectorsStream.getFilePointer();\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n\n      indexWriter = new CompressingStoredFieldsIndexWriter(indexStream);\n      indexStream = null;\n\n      vectorsStream.writeVInt(PackedInts.VERSION_CURRENT);\n      vectorsStream.writeVInt(chunkSize);\n      writer = new BlockPackedWriter(vectorsStream, BLOCK_SIZE);\n\n      positionsBuf = new int[1024];\n      startOffsetsBuf = new int[1024];\n      lengthsBuf = new int[1024];\n      payloadLengthsBuf = new int[1024];\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(indexStream);\n        abort();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5eb2511ababf862ea11e10761c70ee560cd84510","date":1396607225,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsWriter#CompressingTermVectorsWriter(Directory,SegmentInfo,String,IOContext,String,CompressionMode,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsWriter#CompressingTermVectorsWriter(Directory,SegmentInfo,String,IOContext,String,CompressionMode,int).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingTermVectorsWriter(Directory directory, SegmentInfo si, String segmentSuffix, IOContext context,\n      String formatName, CompressionMode compressionMode, int chunkSize) throws IOException {\n    assert directory != null;\n    this.directory = directory;\n    this.segment = si.name;\n    this.segmentSuffix = segmentSuffix;\n    this.compressionMode = compressionMode;\n    this.compressor = compressionMode.newCompressor();\n    this.chunkSize = chunkSize;\n\n    numDocs = 0;\n    pendingDocs = new ArrayDeque<>();\n    termSuffixes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(chunkSize, 1));\n    payloadBytes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(1, 1));\n    lastTerm = new BytesRef(ArrayUtil.oversize(30, 1));\n\n    boolean success = false;\n    IndexOutput indexStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION), \n                                                                     context);\n    try {\n      vectorsStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION),\n                                                     context);\n\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      CodecUtil.writeHeader(indexStream, codecNameIdx, VERSION_CURRENT);\n      CodecUtil.writeHeader(vectorsStream, codecNameDat, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameDat) == vectorsStream.getFilePointer();\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n\n      indexWriter = new CompressingStoredFieldsIndexWriter(indexStream);\n      indexStream = null;\n\n      vectorsStream.writeVInt(PackedInts.VERSION_CURRENT);\n      vectorsStream.writeVInt(chunkSize);\n      writer = new BlockPackedWriter(vectorsStream, BLOCK_SIZE);\n\n      positionsBuf = new int[1024];\n      startOffsetsBuf = new int[1024];\n      lengthsBuf = new int[1024];\n      payloadLengthsBuf = new int[1024];\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(indexStream);\n        abort();\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingTermVectorsWriter(Directory directory, SegmentInfo si, String segmentSuffix, IOContext context,\n      String formatName, CompressionMode compressionMode, int chunkSize) throws IOException {\n    assert directory != null;\n    this.directory = directory;\n    this.segment = si.name;\n    this.segmentSuffix = segmentSuffix;\n    this.compressionMode = compressionMode;\n    this.compressor = compressionMode.newCompressor();\n    this.chunkSize = chunkSize;\n\n    numDocs = 0;\n    pendingDocs = new ArrayDeque<>();\n    termSuffixes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(chunkSize, 1));\n    payloadBytes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(1, 1));\n    lastTerm = new BytesRef(ArrayUtil.oversize(30, 1));\n\n    boolean success = false;\n    IndexOutput indexStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION), context);\n    try {\n      vectorsStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION), context);\n\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      CodecUtil.writeHeader(indexStream, codecNameIdx, VERSION_CURRENT);\n      CodecUtil.writeHeader(vectorsStream, codecNameDat, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameDat) == vectorsStream.getFilePointer();\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n\n      indexWriter = new CompressingStoredFieldsIndexWriter(indexStream);\n      indexStream = null;\n\n      vectorsStream.writeVInt(PackedInts.VERSION_CURRENT);\n      vectorsStream.writeVInt(chunkSize);\n      writer = new BlockPackedWriter(vectorsStream, BLOCK_SIZE);\n\n      positionsBuf = new int[1024];\n      startOffsetsBuf = new int[1024];\n      lengthsBuf = new int[1024];\n      payloadLengthsBuf = new int[1024];\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(indexStream);\n        abort();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d36ccb9a1c11aeb91962e89bda4a2e643c8629b3","date":1401710950,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsWriter#CompressingTermVectorsWriter(Directory,SegmentInfo,String,IOContext,String,CompressionMode,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsWriter#CompressingTermVectorsWriter(Directory,SegmentInfo,String,IOContext,String,CompressionMode,int).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingTermVectorsWriter(Directory directory, SegmentInfo si, String segmentSuffix, IOContext context,\n      String formatName, CompressionMode compressionMode, int chunkSize) throws IOException {\n    assert directory != null;\n    this.directory = directory;\n    this.segment = si.name;\n    this.segmentSuffix = segmentSuffix;\n    this.compressionMode = compressionMode;\n    this.compressor = compressionMode.newCompressor();\n    this.chunkSize = chunkSize;\n\n    numDocs = 0;\n    pendingDocs = new ArrayDeque<>();\n    termSuffixes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(chunkSize, 1));\n    payloadBytes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(1, 1));\n    lastTerm = new BytesRef(ArrayUtil.oversize(30, 1));\n\n    boolean success = false;\n    IndexOutput indexStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION), \n                                                                     context);\n    try {\n      vectorsStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION),\n                                                     context);\n\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      CodecUtil.writeHeader(indexStream, codecNameIdx, VERSION_CURRENT);\n      CodecUtil.writeHeader(vectorsStream, codecNameDat, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameDat) == vectorsStream.getFilePointer();\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n\n      indexWriter = new CompressingStoredFieldsIndexWriter(indexStream);\n      indexStream = null;\n\n      vectorsStream.writeVInt(PackedInts.VERSION_CURRENT);\n      vectorsStream.writeVInt(chunkSize);\n      writer = new BlockPackedWriter(vectorsStream, BLOCK_SIZE, PackedInts.COMPACT);\n\n      positionsBuf = new int[1024];\n      startOffsetsBuf = new int[1024];\n      lengthsBuf = new int[1024];\n      payloadLengthsBuf = new int[1024];\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(indexStream);\n        abort();\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingTermVectorsWriter(Directory directory, SegmentInfo si, String segmentSuffix, IOContext context,\n      String formatName, CompressionMode compressionMode, int chunkSize) throws IOException {\n    assert directory != null;\n    this.directory = directory;\n    this.segment = si.name;\n    this.segmentSuffix = segmentSuffix;\n    this.compressionMode = compressionMode;\n    this.compressor = compressionMode.newCompressor();\n    this.chunkSize = chunkSize;\n\n    numDocs = 0;\n    pendingDocs = new ArrayDeque<>();\n    termSuffixes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(chunkSize, 1));\n    payloadBytes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(1, 1));\n    lastTerm = new BytesRef(ArrayUtil.oversize(30, 1));\n\n    boolean success = false;\n    IndexOutput indexStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION), \n                                                                     context);\n    try {\n      vectorsStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION),\n                                                     context);\n\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      CodecUtil.writeHeader(indexStream, codecNameIdx, VERSION_CURRENT);\n      CodecUtil.writeHeader(vectorsStream, codecNameDat, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameDat) == vectorsStream.getFilePointer();\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n\n      indexWriter = new CompressingStoredFieldsIndexWriter(indexStream);\n      indexStream = null;\n\n      vectorsStream.writeVInt(PackedInts.VERSION_CURRENT);\n      vectorsStream.writeVInt(chunkSize);\n      writer = new BlockPackedWriter(vectorsStream, BLOCK_SIZE);\n\n      positionsBuf = new int[1024];\n      startOffsetsBuf = new int[1024];\n      lengthsBuf = new int[1024];\n      payloadLengthsBuf = new int[1024];\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(indexStream);\n        abort();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["8106bc60c7452250f84c65cdb43ab6b1d8eb1534"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8106bc60c7452250f84c65cdb43ab6b1d8eb1534","date":1401906364,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsWriter#CompressingTermVectorsWriter(Directory,SegmentInfo,String,IOContext,String,CompressionMode,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsWriter#CompressingTermVectorsWriter(Directory,SegmentInfo,String,IOContext,String,CompressionMode,int).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingTermVectorsWriter(Directory directory, SegmentInfo si, String segmentSuffix, IOContext context,\n      String formatName, CompressionMode compressionMode, int chunkSize) throws IOException {\n    assert directory != null;\n    this.directory = directory;\n    this.segment = si.name;\n    this.segmentSuffix = segmentSuffix;\n    this.compressionMode = compressionMode;\n    this.compressor = compressionMode.newCompressor();\n    this.chunkSize = chunkSize;\n\n    numDocs = 0;\n    pendingDocs = new ArrayDeque<>();\n    termSuffixes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(chunkSize, 1));\n    payloadBytes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(1, 1));\n    lastTerm = new BytesRef(ArrayUtil.oversize(30, 1));\n\n    boolean success = false;\n    IndexOutput indexStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION), \n                                                                     context);\n    try {\n      vectorsStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION),\n                                                     context);\n\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      CodecUtil.writeHeader(indexStream, codecNameIdx, VERSION_CURRENT);\n      CodecUtil.writeHeader(vectorsStream, codecNameDat, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameDat) == vectorsStream.getFilePointer();\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n\n      indexWriter = new CompressingStoredFieldsIndexWriter(indexStream);\n      indexStream = null;\n\n      vectorsStream.writeVInt(PackedInts.VERSION_CURRENT);\n      vectorsStream.writeVInt(chunkSize);\n      writer = new BlockPackedWriter(vectorsStream, BLOCK_SIZE);\n\n      positionsBuf = new int[1024];\n      startOffsetsBuf = new int[1024];\n      lengthsBuf = new int[1024];\n      payloadLengthsBuf = new int[1024];\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(indexStream);\n        abort();\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingTermVectorsWriter(Directory directory, SegmentInfo si, String segmentSuffix, IOContext context,\n      String formatName, CompressionMode compressionMode, int chunkSize) throws IOException {\n    assert directory != null;\n    this.directory = directory;\n    this.segment = si.name;\n    this.segmentSuffix = segmentSuffix;\n    this.compressionMode = compressionMode;\n    this.compressor = compressionMode.newCompressor();\n    this.chunkSize = chunkSize;\n\n    numDocs = 0;\n    pendingDocs = new ArrayDeque<>();\n    termSuffixes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(chunkSize, 1));\n    payloadBytes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(1, 1));\n    lastTerm = new BytesRef(ArrayUtil.oversize(30, 1));\n\n    boolean success = false;\n    IndexOutput indexStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION), \n                                                                     context);\n    try {\n      vectorsStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION),\n                                                     context);\n\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      CodecUtil.writeHeader(indexStream, codecNameIdx, VERSION_CURRENT);\n      CodecUtil.writeHeader(vectorsStream, codecNameDat, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameDat) == vectorsStream.getFilePointer();\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n\n      indexWriter = new CompressingStoredFieldsIndexWriter(indexStream);\n      indexStream = null;\n\n      vectorsStream.writeVInt(PackedInts.VERSION_CURRENT);\n      vectorsStream.writeVInt(chunkSize);\n      writer = new BlockPackedWriter(vectorsStream, BLOCK_SIZE, PackedInts.COMPACT);\n\n      positionsBuf = new int[1024];\n      startOffsetsBuf = new int[1024];\n      lengthsBuf = new int[1024];\n      payloadLengthsBuf = new int[1024];\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(indexStream);\n        abort();\n      }\n    }\n  }\n\n","bugFix":["d36ccb9a1c11aeb91962e89bda4a2e643c8629b3"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"389e8bca54f58e35576077f3ff46f123b3660018","date":1411859915,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsWriter#CompressingTermVectorsWriter(Directory,SegmentInfo,String,IOContext,String,CompressionMode,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsWriter#CompressingTermVectorsWriter(Directory,SegmentInfo,String,IOContext,String,CompressionMode,int).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingTermVectorsWriter(Directory directory, SegmentInfo si, String segmentSuffix, IOContext context,\n      String formatName, CompressionMode compressionMode, int chunkSize) throws IOException {\n    assert directory != null;\n    this.directory = directory;\n    this.segment = si.name;\n    this.segmentSuffix = segmentSuffix;\n    this.compressionMode = compressionMode;\n    this.compressor = compressionMode.newCompressor();\n    this.chunkSize = chunkSize;\n\n    numDocs = 0;\n    pendingDocs = new ArrayDeque<>();\n    termSuffixes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(chunkSize, 1));\n    payloadBytes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(1, 1));\n    lastTerm = new BytesRef(ArrayUtil.oversize(30, 1));\n\n    boolean success = false;\n    IndexOutput indexStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION), \n                                                                     context);\n    try {\n      vectorsStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION),\n                                                     context);\n\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      CodecUtil.writeSegmentHeader(indexStream, codecNameIdx, VERSION_CURRENT, si.getId());\n      CodecUtil.writeSegmentHeader(vectorsStream, codecNameDat, VERSION_CURRENT, si.getId());\n      assert CodecUtil.segmentHeaderLength(codecNameDat) == vectorsStream.getFilePointer();\n      assert CodecUtil.segmentHeaderLength(codecNameIdx) == indexStream.getFilePointer();\n\n      indexWriter = new CompressingStoredFieldsIndexWriter(indexStream);\n      indexStream = null;\n\n      vectorsStream.writeVInt(PackedInts.VERSION_CURRENT);\n      vectorsStream.writeVInt(chunkSize);\n      writer = new BlockPackedWriter(vectorsStream, BLOCK_SIZE);\n\n      positionsBuf = new int[1024];\n      startOffsetsBuf = new int[1024];\n      lengthsBuf = new int[1024];\n      payloadLengthsBuf = new int[1024];\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(indexStream);\n        abort();\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingTermVectorsWriter(Directory directory, SegmentInfo si, String segmentSuffix, IOContext context,\n      String formatName, CompressionMode compressionMode, int chunkSize) throws IOException {\n    assert directory != null;\n    this.directory = directory;\n    this.segment = si.name;\n    this.segmentSuffix = segmentSuffix;\n    this.compressionMode = compressionMode;\n    this.compressor = compressionMode.newCompressor();\n    this.chunkSize = chunkSize;\n\n    numDocs = 0;\n    pendingDocs = new ArrayDeque<>();\n    termSuffixes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(chunkSize, 1));\n    payloadBytes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(1, 1));\n    lastTerm = new BytesRef(ArrayUtil.oversize(30, 1));\n\n    boolean success = false;\n    IndexOutput indexStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION), \n                                                                     context);\n    try {\n      vectorsStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION),\n                                                     context);\n\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      CodecUtil.writeHeader(indexStream, codecNameIdx, VERSION_CURRENT);\n      CodecUtil.writeHeader(vectorsStream, codecNameDat, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameDat) == vectorsStream.getFilePointer();\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n\n      indexWriter = new CompressingStoredFieldsIndexWriter(indexStream);\n      indexStream = null;\n\n      vectorsStream.writeVInt(PackedInts.VERSION_CURRENT);\n      vectorsStream.writeVInt(chunkSize);\n      writer = new BlockPackedWriter(vectorsStream, BLOCK_SIZE);\n\n      positionsBuf = new int[1024];\n      startOffsetsBuf = new int[1024];\n      lengthsBuf = new int[1024];\n      payloadLengthsBuf = new int[1024];\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(indexStream);\n        abort();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a78b813d9350cc28625598f6dbbb49b586a40618","date":1412073147,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsWriter#CompressingTermVectorsWriter(Directory,SegmentInfo,String,IOContext,String,CompressionMode,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsWriter#CompressingTermVectorsWriter(Directory,SegmentInfo,String,IOContext,String,CompressionMode,int).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingTermVectorsWriter(Directory directory, SegmentInfo si, String segmentSuffix, IOContext context,\n      String formatName, CompressionMode compressionMode, int chunkSize) throws IOException {\n    assert directory != null;\n    this.directory = directory;\n    this.segment = si.name;\n    this.segmentSuffix = segmentSuffix;\n    this.compressionMode = compressionMode;\n    this.compressor = compressionMode.newCompressor();\n    this.chunkSize = chunkSize;\n\n    numDocs = 0;\n    pendingDocs = new ArrayDeque<>();\n    termSuffixes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(chunkSize, 1));\n    payloadBytes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(1, 1));\n    lastTerm = new BytesRef(ArrayUtil.oversize(30, 1));\n\n    boolean success = false;\n    IndexOutput indexStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION), \n                                                                     context);\n    try {\n      vectorsStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION),\n                                                     context);\n\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      CodecUtil.writeSegmentHeader(indexStream, codecNameIdx, VERSION_CURRENT, si.getId(), segmentSuffix);\n      CodecUtil.writeSegmentHeader(vectorsStream, codecNameDat, VERSION_CURRENT, si.getId(), segmentSuffix);\n      assert CodecUtil.segmentHeaderLength(codecNameDat, segmentSuffix) == vectorsStream.getFilePointer();\n      assert CodecUtil.segmentHeaderLength(codecNameIdx, segmentSuffix) == indexStream.getFilePointer();\n\n      indexWriter = new CompressingStoredFieldsIndexWriter(indexStream);\n      indexStream = null;\n\n      vectorsStream.writeVInt(PackedInts.VERSION_CURRENT);\n      vectorsStream.writeVInt(chunkSize);\n      writer = new BlockPackedWriter(vectorsStream, BLOCK_SIZE);\n\n      positionsBuf = new int[1024];\n      startOffsetsBuf = new int[1024];\n      lengthsBuf = new int[1024];\n      payloadLengthsBuf = new int[1024];\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(indexStream);\n        abort();\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingTermVectorsWriter(Directory directory, SegmentInfo si, String segmentSuffix, IOContext context,\n      String formatName, CompressionMode compressionMode, int chunkSize) throws IOException {\n    assert directory != null;\n    this.directory = directory;\n    this.segment = si.name;\n    this.segmentSuffix = segmentSuffix;\n    this.compressionMode = compressionMode;\n    this.compressor = compressionMode.newCompressor();\n    this.chunkSize = chunkSize;\n\n    numDocs = 0;\n    pendingDocs = new ArrayDeque<>();\n    termSuffixes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(chunkSize, 1));\n    payloadBytes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(1, 1));\n    lastTerm = new BytesRef(ArrayUtil.oversize(30, 1));\n\n    boolean success = false;\n    IndexOutput indexStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION), \n                                                                     context);\n    try {\n      vectorsStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION),\n                                                     context);\n\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      CodecUtil.writeSegmentHeader(indexStream, codecNameIdx, VERSION_CURRENT, si.getId());\n      CodecUtil.writeSegmentHeader(vectorsStream, codecNameDat, VERSION_CURRENT, si.getId());\n      assert CodecUtil.segmentHeaderLength(codecNameDat) == vectorsStream.getFilePointer();\n      assert CodecUtil.segmentHeaderLength(codecNameIdx) == indexStream.getFilePointer();\n\n      indexWriter = new CompressingStoredFieldsIndexWriter(indexStream);\n      indexStream = null;\n\n      vectorsStream.writeVInt(PackedInts.VERSION_CURRENT);\n      vectorsStream.writeVInt(chunkSize);\n      writer = new BlockPackedWriter(vectorsStream, BLOCK_SIZE);\n\n      positionsBuf = new int[1024];\n      startOffsetsBuf = new int[1024];\n      lengthsBuf = new int[1024];\n      payloadLengthsBuf = new int[1024];\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(indexStream);\n        abort();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9bb9a29a5e71a90295f175df8919802993142c9a","date":1412517673,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsWriter#CompressingTermVectorsWriter(Directory,SegmentInfo,String,IOContext,String,CompressionMode,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsWriter#CompressingTermVectorsWriter(Directory,SegmentInfo,String,IOContext,String,CompressionMode,int).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingTermVectorsWriter(Directory directory, SegmentInfo si, String segmentSuffix, IOContext context,\n      String formatName, CompressionMode compressionMode, int chunkSize) throws IOException {\n    assert directory != null;\n    this.directory = directory;\n    this.segment = si.name;\n    this.segmentSuffix = segmentSuffix;\n    this.compressionMode = compressionMode;\n    this.compressor = compressionMode.newCompressor();\n    this.chunkSize = chunkSize;\n\n    numDocs = 0;\n    pendingDocs = new ArrayDeque<>();\n    termSuffixes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(chunkSize, 1));\n    payloadBytes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(1, 1));\n    lastTerm = new BytesRef(ArrayUtil.oversize(30, 1));\n\n    boolean success = false;\n    IndexOutput indexStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION), \n                                                                     context);\n    try {\n      vectorsStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION),\n                                                     context);\n\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      CodecUtil.writeSegmentHeader(indexStream, codecNameIdx, VERSION_CURRENT, si.getId(), segmentSuffix);\n      CodecUtil.writeSegmentHeader(vectorsStream, codecNameDat, VERSION_CURRENT, si.getId(), segmentSuffix);\n      assert CodecUtil.segmentHeaderLength(codecNameDat, segmentSuffix) == vectorsStream.getFilePointer();\n      assert CodecUtil.segmentHeaderLength(codecNameIdx, segmentSuffix) == indexStream.getFilePointer();\n\n      indexWriter = new CompressingStoredFieldsIndexWriter(indexStream);\n      indexStream = null;\n\n      vectorsStream.writeVInt(PackedInts.VERSION_CURRENT);\n      vectorsStream.writeVInt(chunkSize);\n      writer = new BlockPackedWriter(vectorsStream, BLOCK_SIZE);\n\n      positionsBuf = new int[1024];\n      startOffsetsBuf = new int[1024];\n      lengthsBuf = new int[1024];\n      payloadLengthsBuf = new int[1024];\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(indexStream);\n        abort();\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingTermVectorsWriter(Directory directory, SegmentInfo si, String segmentSuffix, IOContext context,\n      String formatName, CompressionMode compressionMode, int chunkSize) throws IOException {\n    assert directory != null;\n    this.directory = directory;\n    this.segment = si.name;\n    this.segmentSuffix = segmentSuffix;\n    this.compressionMode = compressionMode;\n    this.compressor = compressionMode.newCompressor();\n    this.chunkSize = chunkSize;\n\n    numDocs = 0;\n    pendingDocs = new ArrayDeque<>();\n    termSuffixes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(chunkSize, 1));\n    payloadBytes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(1, 1));\n    lastTerm = new BytesRef(ArrayUtil.oversize(30, 1));\n\n    boolean success = false;\n    IndexOutput indexStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION), \n                                                                     context);\n    try {\n      vectorsStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION),\n                                                     context);\n\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      CodecUtil.writeHeader(indexStream, codecNameIdx, VERSION_CURRENT);\n      CodecUtil.writeHeader(vectorsStream, codecNameDat, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameDat) == vectorsStream.getFilePointer();\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n\n      indexWriter = new CompressingStoredFieldsIndexWriter(indexStream);\n      indexStream = null;\n\n      vectorsStream.writeVInt(PackedInts.VERSION_CURRENT);\n      vectorsStream.writeVInt(chunkSize);\n      writer = new BlockPackedWriter(vectorsStream, BLOCK_SIZE);\n\n      positionsBuf = new int[1024];\n      startOffsetsBuf = new int[1024];\n      lengthsBuf = new int[1024];\n      payloadLengthsBuf = new int[1024];\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(indexStream);\n        abort();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3384e6013a93e4d11b7d75388693f8d0388602bf","date":1413951663,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsWriter#CompressingTermVectorsWriter(Directory,SegmentInfo,String,IOContext,String,CompressionMode,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsWriter#CompressingTermVectorsWriter(Directory,SegmentInfo,String,IOContext,String,CompressionMode,int).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingTermVectorsWriter(Directory directory, SegmentInfo si, String segmentSuffix, IOContext context,\n      String formatName, CompressionMode compressionMode, int chunkSize) throws IOException {\n    assert directory != null;\n    this.directory = directory;\n    this.segment = si.name;\n    this.segmentSuffix = segmentSuffix;\n    this.compressionMode = compressionMode;\n    this.compressor = compressionMode.newCompressor();\n    this.chunkSize = chunkSize;\n\n    numDocs = 0;\n    pendingDocs = new ArrayDeque<>();\n    termSuffixes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(chunkSize, 1));\n    payloadBytes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(1, 1));\n    lastTerm = new BytesRef(ArrayUtil.oversize(30, 1));\n\n    boolean success = false;\n    IndexOutput indexStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION), \n                                                                     context);\n    try {\n      vectorsStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION),\n                                                     context);\n\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      CodecUtil.writeIndexHeader(indexStream, codecNameIdx, VERSION_CURRENT, si.getId(), segmentSuffix);\n      CodecUtil.writeIndexHeader(vectorsStream, codecNameDat, VERSION_CURRENT, si.getId(), segmentSuffix);\n      assert CodecUtil.indexHeaderLength(codecNameDat, segmentSuffix) == vectorsStream.getFilePointer();\n      assert CodecUtil.indexHeaderLength(codecNameIdx, segmentSuffix) == indexStream.getFilePointer();\n\n      indexWriter = new CompressingStoredFieldsIndexWriter(indexStream);\n      indexStream = null;\n\n      vectorsStream.writeVInt(PackedInts.VERSION_CURRENT);\n      vectorsStream.writeVInt(chunkSize);\n      writer = new BlockPackedWriter(vectorsStream, BLOCK_SIZE);\n\n      positionsBuf = new int[1024];\n      startOffsetsBuf = new int[1024];\n      lengthsBuf = new int[1024];\n      payloadLengthsBuf = new int[1024];\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(indexStream);\n        abort();\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingTermVectorsWriter(Directory directory, SegmentInfo si, String segmentSuffix, IOContext context,\n      String formatName, CompressionMode compressionMode, int chunkSize) throws IOException {\n    assert directory != null;\n    this.directory = directory;\n    this.segment = si.name;\n    this.segmentSuffix = segmentSuffix;\n    this.compressionMode = compressionMode;\n    this.compressor = compressionMode.newCompressor();\n    this.chunkSize = chunkSize;\n\n    numDocs = 0;\n    pendingDocs = new ArrayDeque<>();\n    termSuffixes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(chunkSize, 1));\n    payloadBytes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(1, 1));\n    lastTerm = new BytesRef(ArrayUtil.oversize(30, 1));\n\n    boolean success = false;\n    IndexOutput indexStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION), \n                                                                     context);\n    try {\n      vectorsStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION),\n                                                     context);\n\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      CodecUtil.writeSegmentHeader(indexStream, codecNameIdx, VERSION_CURRENT, si.getId(), segmentSuffix);\n      CodecUtil.writeSegmentHeader(vectorsStream, codecNameDat, VERSION_CURRENT, si.getId(), segmentSuffix);\n      assert CodecUtil.segmentHeaderLength(codecNameDat, segmentSuffix) == vectorsStream.getFilePointer();\n      assert CodecUtil.segmentHeaderLength(codecNameIdx, segmentSuffix) == indexStream.getFilePointer();\n\n      indexWriter = new CompressingStoredFieldsIndexWriter(indexStream);\n      indexStream = null;\n\n      vectorsStream.writeVInt(PackedInts.VERSION_CURRENT);\n      vectorsStream.writeVInt(chunkSize);\n      writer = new BlockPackedWriter(vectorsStream, BLOCK_SIZE);\n\n      positionsBuf = new int[1024];\n      startOffsetsBuf = new int[1024];\n      lengthsBuf = new int[1024];\n      payloadLengthsBuf = new int[1024];\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(indexStream);\n        abort();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"db68c63cbfaa8698b9c4475f75ed2b9c9696d238","date":1414118621,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsWriter#CompressingTermVectorsWriter(Directory,SegmentInfo,String,IOContext,String,CompressionMode,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsWriter#CompressingTermVectorsWriter(Directory,SegmentInfo,String,IOContext,String,CompressionMode,int).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingTermVectorsWriter(Directory directory, SegmentInfo si, String segmentSuffix, IOContext context,\n      String formatName, CompressionMode compressionMode, int chunkSize) throws IOException {\n    assert directory != null;\n    this.directory = directory;\n    this.segment = si.name;\n    this.segmentSuffix = segmentSuffix;\n    this.compressionMode = compressionMode;\n    this.compressor = compressionMode.newCompressor();\n    this.chunkSize = chunkSize;\n\n    numDocs = 0;\n    pendingDocs = new ArrayDeque<>();\n    termSuffixes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(chunkSize, 1));\n    payloadBytes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(1, 1));\n    lastTerm = new BytesRef(ArrayUtil.oversize(30, 1));\n\n    boolean success = false;\n    IndexOutput indexStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION), \n                                                                     context);\n    try {\n      vectorsStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION),\n                                                     context);\n\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      CodecUtil.writeIndexHeader(indexStream, codecNameIdx, VERSION_CURRENT, si.getId(), segmentSuffix);\n      CodecUtil.writeIndexHeader(vectorsStream, codecNameDat, VERSION_CURRENT, si.getId(), segmentSuffix);\n      assert CodecUtil.indexHeaderLength(codecNameDat, segmentSuffix) == vectorsStream.getFilePointer();\n      assert CodecUtil.indexHeaderLength(codecNameIdx, segmentSuffix) == indexStream.getFilePointer();\n\n      indexWriter = new CompressingStoredFieldsIndexWriter(indexStream);\n      indexStream = null;\n\n      vectorsStream.writeVInt(PackedInts.VERSION_CURRENT);\n      vectorsStream.writeVInt(chunkSize);\n      writer = new BlockPackedWriter(vectorsStream, BLOCK_SIZE);\n\n      positionsBuf = new int[1024];\n      startOffsetsBuf = new int[1024];\n      lengthsBuf = new int[1024];\n      payloadLengthsBuf = new int[1024];\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(indexStream);\n        abort();\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingTermVectorsWriter(Directory directory, SegmentInfo si, String segmentSuffix, IOContext context,\n      String formatName, CompressionMode compressionMode, int chunkSize) throws IOException {\n    assert directory != null;\n    this.directory = directory;\n    this.segment = si.name;\n    this.segmentSuffix = segmentSuffix;\n    this.compressionMode = compressionMode;\n    this.compressor = compressionMode.newCompressor();\n    this.chunkSize = chunkSize;\n\n    numDocs = 0;\n    pendingDocs = new ArrayDeque<>();\n    termSuffixes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(chunkSize, 1));\n    payloadBytes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(1, 1));\n    lastTerm = new BytesRef(ArrayUtil.oversize(30, 1));\n\n    boolean success = false;\n    IndexOutput indexStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION), \n                                                                     context);\n    try {\n      vectorsStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION),\n                                                     context);\n\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      CodecUtil.writeSegmentHeader(indexStream, codecNameIdx, VERSION_CURRENT, si.getId(), segmentSuffix);\n      CodecUtil.writeSegmentHeader(vectorsStream, codecNameDat, VERSION_CURRENT, si.getId(), segmentSuffix);\n      assert CodecUtil.segmentHeaderLength(codecNameDat, segmentSuffix) == vectorsStream.getFilePointer();\n      assert CodecUtil.segmentHeaderLength(codecNameIdx, segmentSuffix) == indexStream.getFilePointer();\n\n      indexWriter = new CompressingStoredFieldsIndexWriter(indexStream);\n      indexStream = null;\n\n      vectorsStream.writeVInt(PackedInts.VERSION_CURRENT);\n      vectorsStream.writeVInt(chunkSize);\n      writer = new BlockPackedWriter(vectorsStream, BLOCK_SIZE);\n\n      positionsBuf = new int[1024];\n      startOffsetsBuf = new int[1024];\n      lengthsBuf = new int[1024];\n      payloadLengthsBuf = new int[1024];\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(indexStream);\n        abort();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"474b77fc1ee62c3fc1c73ceb19cc975cb03667ac","date":1417363109,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsWriter#CompressingTermVectorsWriter(Directory,SegmentInfo,String,IOContext,String,CompressionMode,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsWriter#CompressingTermVectorsWriter(Directory,SegmentInfo,String,IOContext,String,CompressionMode,int).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingTermVectorsWriter(Directory directory, SegmentInfo si, String segmentSuffix, IOContext context,\n      String formatName, CompressionMode compressionMode, int chunkSize) throws IOException {\n    assert directory != null;\n    this.directory = directory;\n    this.segment = si.name;\n    this.segmentSuffix = segmentSuffix;\n    this.compressionMode = compressionMode;\n    this.compressor = compressionMode.newCompressor();\n    this.chunkSize = chunkSize;\n\n    numDocs = 0;\n    pendingDocs = new ArrayDeque<>();\n    termSuffixes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(chunkSize, 1));\n    payloadBytes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(1, 1));\n    lastTerm = new BytesRef(ArrayUtil.oversize(30, 1));\n\n    boolean success = false;\n    IndexOutput indexStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION), \n                                                                     context);\n    try {\n      vectorsStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION),\n                                                     context);\n\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      CodecUtil.writeIndexHeader(indexStream, codecNameIdx, VERSION_CURRENT, si.getId(), segmentSuffix);\n      CodecUtil.writeIndexHeader(vectorsStream, codecNameDat, VERSION_CURRENT, si.getId(), segmentSuffix);\n      assert CodecUtil.indexHeaderLength(codecNameDat, segmentSuffix) == vectorsStream.getFilePointer();\n      assert CodecUtil.indexHeaderLength(codecNameIdx, segmentSuffix) == indexStream.getFilePointer();\n\n      indexWriter = new CompressingStoredFieldsIndexWriter(indexStream);\n      indexStream = null;\n\n      vectorsStream.writeVInt(PackedInts.VERSION_CURRENT);\n      vectorsStream.writeVInt(chunkSize);\n      writer = new BlockPackedWriter(vectorsStream, BLOCK_SIZE);\n\n      positionsBuf = new int[1024];\n      startOffsetsBuf = new int[1024];\n      lengthsBuf = new int[1024];\n      payloadLengthsBuf = new int[1024];\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(vectorsStream, indexStream, indexWriter);\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingTermVectorsWriter(Directory directory, SegmentInfo si, String segmentSuffix, IOContext context,\n      String formatName, CompressionMode compressionMode, int chunkSize) throws IOException {\n    assert directory != null;\n    this.directory = directory;\n    this.segment = si.name;\n    this.segmentSuffix = segmentSuffix;\n    this.compressionMode = compressionMode;\n    this.compressor = compressionMode.newCompressor();\n    this.chunkSize = chunkSize;\n\n    numDocs = 0;\n    pendingDocs = new ArrayDeque<>();\n    termSuffixes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(chunkSize, 1));\n    payloadBytes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(1, 1));\n    lastTerm = new BytesRef(ArrayUtil.oversize(30, 1));\n\n    boolean success = false;\n    IndexOutput indexStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION), \n                                                                     context);\n    try {\n      vectorsStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION),\n                                                     context);\n\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      CodecUtil.writeIndexHeader(indexStream, codecNameIdx, VERSION_CURRENT, si.getId(), segmentSuffix);\n      CodecUtil.writeIndexHeader(vectorsStream, codecNameDat, VERSION_CURRENT, si.getId(), segmentSuffix);\n      assert CodecUtil.indexHeaderLength(codecNameDat, segmentSuffix) == vectorsStream.getFilePointer();\n      assert CodecUtil.indexHeaderLength(codecNameIdx, segmentSuffix) == indexStream.getFilePointer();\n\n      indexWriter = new CompressingStoredFieldsIndexWriter(indexStream);\n      indexStream = null;\n\n      vectorsStream.writeVInt(PackedInts.VERSION_CURRENT);\n      vectorsStream.writeVInt(chunkSize);\n      writer = new BlockPackedWriter(vectorsStream, BLOCK_SIZE);\n\n      positionsBuf = new int[1024];\n      startOffsetsBuf = new int[1024];\n      lengthsBuf = new int[1024];\n      payloadLengthsBuf = new int[1024];\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(indexStream);\n        abort();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"59d4661023aa9541b0a759e4d2e11dcf83b923a0","date":1420124226,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsWriter#CompressingTermVectorsWriter(Directory,SegmentInfo,String,IOContext,String,CompressionMode,int,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsWriter#CompressingTermVectorsWriter(Directory,SegmentInfo,String,IOContext,String,CompressionMode,int).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingTermVectorsWriter(Directory directory, SegmentInfo si, String segmentSuffix, IOContext context,\n      String formatName, CompressionMode compressionMode, int chunkSize, int blockSize) throws IOException {\n    assert directory != null;\n    this.directory = directory;\n    this.segment = si.name;\n    this.segmentSuffix = segmentSuffix;\n    this.compressionMode = compressionMode;\n    this.compressor = compressionMode.newCompressor();\n    this.chunkSize = chunkSize;\n\n    numDocs = 0;\n    pendingDocs = new ArrayDeque<>();\n    termSuffixes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(chunkSize, 1));\n    payloadBytes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(1, 1));\n    lastTerm = new BytesRef(ArrayUtil.oversize(30, 1));\n\n    boolean success = false;\n    IndexOutput indexStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION), \n                                                                     context);\n    try {\n      vectorsStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION),\n                                                     context);\n\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      CodecUtil.writeIndexHeader(indexStream, codecNameIdx, VERSION_CURRENT, si.getId(), segmentSuffix);\n      CodecUtil.writeIndexHeader(vectorsStream, codecNameDat, VERSION_CURRENT, si.getId(), segmentSuffix);\n      assert CodecUtil.indexHeaderLength(codecNameDat, segmentSuffix) == vectorsStream.getFilePointer();\n      assert CodecUtil.indexHeaderLength(codecNameIdx, segmentSuffix) == indexStream.getFilePointer();\n\n      indexWriter = new CompressingStoredFieldsIndexWriter(indexStream, blockSize);\n      indexStream = null;\n\n      vectorsStream.writeVInt(PackedInts.VERSION_CURRENT);\n      vectorsStream.writeVInt(chunkSize);\n      writer = new BlockPackedWriter(vectorsStream, PACKED_BLOCK_SIZE);\n\n      positionsBuf = new int[1024];\n      startOffsetsBuf = new int[1024];\n      lengthsBuf = new int[1024];\n      payloadLengthsBuf = new int[1024];\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(vectorsStream, indexStream, indexWriter);\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingTermVectorsWriter(Directory directory, SegmentInfo si, String segmentSuffix, IOContext context,\n      String formatName, CompressionMode compressionMode, int chunkSize) throws IOException {\n    assert directory != null;\n    this.directory = directory;\n    this.segment = si.name;\n    this.segmentSuffix = segmentSuffix;\n    this.compressionMode = compressionMode;\n    this.compressor = compressionMode.newCompressor();\n    this.chunkSize = chunkSize;\n\n    numDocs = 0;\n    pendingDocs = new ArrayDeque<>();\n    termSuffixes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(chunkSize, 1));\n    payloadBytes = new GrowableByteArrayDataOutput(ArrayUtil.oversize(1, 1));\n    lastTerm = new BytesRef(ArrayUtil.oversize(30, 1));\n\n    boolean success = false;\n    IndexOutput indexStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION), \n                                                                     context);\n    try {\n      vectorsStream = directory.createOutput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION),\n                                                     context);\n\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      CodecUtil.writeIndexHeader(indexStream, codecNameIdx, VERSION_CURRENT, si.getId(), segmentSuffix);\n      CodecUtil.writeIndexHeader(vectorsStream, codecNameDat, VERSION_CURRENT, si.getId(), segmentSuffix);\n      assert CodecUtil.indexHeaderLength(codecNameDat, segmentSuffix) == vectorsStream.getFilePointer();\n      assert CodecUtil.indexHeaderLength(codecNameIdx, segmentSuffix) == indexStream.getFilePointer();\n\n      indexWriter = new CompressingStoredFieldsIndexWriter(indexStream);\n      indexStream = null;\n\n      vectorsStream.writeVInt(PackedInts.VERSION_CURRENT);\n      vectorsStream.writeVInt(chunkSize);\n      writer = new BlockPackedWriter(vectorsStream, BLOCK_SIZE);\n\n      positionsBuf = new int[1024];\n      startOffsetsBuf = new int[1024];\n      lengthsBuf = new int[1024];\n      payloadLengthsBuf = new int[1024];\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(vectorsStream, indexStream, indexWriter);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"5eb2511ababf862ea11e10761c70ee560cd84510":["634f330c54fd3f9f491d52036dc3f40b4f4d8934","1f3b037cd083286b2af89f96e768f85dcd8072d6"],"1f3b037cd083286b2af89f96e768f85dcd8072d6":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["eda61b1e90b490cc5837200e04c02639a0d272c7"],"eda61b1e90b490cc5837200e04c02639a0d272c7":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"3384e6013a93e4d11b7d75388693f8d0388602bf":["a78b813d9350cc28625598f6dbbb49b586a40618"],"07155cdd910937cdf6877e48884d5782845c8b8b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","eda61b1e90b490cc5837200e04c02639a0d272c7"],"474b77fc1ee62c3fc1c73ceb19cc975cb03667ac":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238"],"a78b813d9350cc28625598f6dbbb49b586a40618":["389e8bca54f58e35576077f3ff46f123b3660018"],"d36ccb9a1c11aeb91962e89bda4a2e643c8629b3":["1f3b037cd083286b2af89f96e768f85dcd8072d6"],"9bb9a29a5e71a90295f175df8919802993142c9a":["8106bc60c7452250f84c65cdb43ab6b1d8eb1534","a78b813d9350cc28625598f6dbbb49b586a40618"],"59d4661023aa9541b0a759e4d2e11dcf83b923a0":["474b77fc1ee62c3fc1c73ceb19cc975cb03667ac"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"8106bc60c7452250f84c65cdb43ab6b1d8eb1534":["d36ccb9a1c11aeb91962e89bda4a2e643c8629b3"],"db68c63cbfaa8698b9c4475f75ed2b9c9696d238":["9bb9a29a5e71a90295f175df8919802993142c9a","3384e6013a93e4d11b7d75388693f8d0388602bf"],"389e8bca54f58e35576077f3ff46f123b3660018":["8106bc60c7452250f84c65cdb43ab6b1d8eb1534"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["59d4661023aa9541b0a759e4d2e11dcf83b923a0"]},"commit2Childs":{"5eb2511ababf862ea11e10761c70ee560cd84510":[],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["5eb2511ababf862ea11e10761c70ee560cd84510","1f3b037cd083286b2af89f96e768f85dcd8072d6"],"1f3b037cd083286b2af89f96e768f85dcd8072d6":["5eb2511ababf862ea11e10761c70ee560cd84510","d36ccb9a1c11aeb91962e89bda4a2e643c8629b3"],"eda61b1e90b490cc5837200e04c02639a0d272c7":["634f330c54fd3f9f491d52036dc3f40b4f4d8934","07155cdd910937cdf6877e48884d5782845c8b8b"],"3384e6013a93e4d11b7d75388693f8d0388602bf":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238"],"07155cdd910937cdf6877e48884d5782845c8b8b":[],"a78b813d9350cc28625598f6dbbb49b586a40618":["3384e6013a93e4d11b7d75388693f8d0388602bf","9bb9a29a5e71a90295f175df8919802993142c9a"],"474b77fc1ee62c3fc1c73ceb19cc975cb03667ac":["59d4661023aa9541b0a759e4d2e11dcf83b923a0"],"d36ccb9a1c11aeb91962e89bda4a2e643c8629b3":["8106bc60c7452250f84c65cdb43ab6b1d8eb1534"],"9bb9a29a5e71a90295f175df8919802993142c9a":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["eda61b1e90b490cc5837200e04c02639a0d272c7","07155cdd910937cdf6877e48884d5782845c8b8b"],"59d4661023aa9541b0a759e4d2e11dcf83b923a0":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"8106bc60c7452250f84c65cdb43ab6b1d8eb1534":["9bb9a29a5e71a90295f175df8919802993142c9a","389e8bca54f58e35576077f3ff46f123b3660018"],"db68c63cbfaa8698b9c4475f75ed2b9c9696d238":["474b77fc1ee62c3fc1c73ceb19cc975cb03667ac"],"389e8bca54f58e35576077f3ff46f123b3660018":["a78b813d9350cc28625598f6dbbb49b586a40618"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["5eb2511ababf862ea11e10761c70ee560cd84510","07155cdd910937cdf6877e48884d5782845c8b8b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}