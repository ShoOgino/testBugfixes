{"path":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/SolrRecordWriter#createEmbeddedSolrServer(Path,FileSystem,Path).mjava","commits":[{"id":"70f91c8322fbffe3a3a897ef20ea19119cac10cd","date":1386170124,"type":1,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/SolrRecordWriter#createEmbeddedSolrServer(Path,FileSystem,Path).mjava","pathOld":"solr/contrib/solr-mr/src/java/org/apache/solr/hadoop/SolrRecordWriter#createEmbeddedSolrServer(Path,FileSystem,Path).mjava","sourceNew":"  public static EmbeddedSolrServer createEmbeddedSolrServer(Path solrHomeDir, FileSystem fs, Path outputShardDir)\n      throws IOException {\n\n    if (solrHomeDir == null) {\n      throw new IOException(\"Unable to find solr home setting\");\n    }\n    LOG.info(\"Creating embedded Solr server with solrHomeDir: \" + solrHomeDir + \", fs: \" + fs + \", outputShardDir: \" + outputShardDir);\n\n    Properties props = new Properties();\n    // FIXME note this is odd (no scheme) given Solr doesn't currently\n    // support uris (just abs/relative path)\n    Path solrDataDir = new Path(outputShardDir, \"data\");\n    if (!fs.exists(solrDataDir) && !fs.mkdirs(solrDataDir)) {\n      throw new IOException(\"Unable to create \" + solrDataDir);\n    }\n\n    String dataDirStr = solrDataDir.toUri().toString();\n    props.setProperty(\"solr.data.dir\", dataDirStr);\n    props.setProperty(\"solr.home\", solrHomeDir.toString());\n\n    SolrResourceLoader loader = new SolrResourceLoader(solrHomeDir.toString(),\n        null, props);\n\n    LOG.info(String\n        .format(Locale.ENGLISH, \n            \"Constructed instance information solr.home %s (%s), instance dir %s, conf dir %s, writing index to solr.data.dir %s, with permdir %s\",\n            solrHomeDir, solrHomeDir.toUri(), loader.getInstanceDir(),\n            loader.getConfigDir(), dataDirStr, outputShardDir));\n\n    CoreContainer container = new CoreContainer(loader);\n    container.load();\n    CoreDescriptor descr = new CoreDescriptor(container, \"core1\",\n        \".\", props);\n    \n    SolrCore core = container.create(descr);\n    container.register(core, false);\n    \n    System.setProperty(\"solr.hdfs.nrtcachingdirectory\", \"false\");\n    System.setProperty(\"solr.hdfs.blockcache.enabled\", \"false\");\n    System.setProperty(\"solr.autoCommit.maxTime\", \"-1\");\n    System.setProperty(\"solr.autoSoftCommit.maxTime\", \"-1\");\n    EmbeddedSolrServer solr = new EmbeddedSolrServer(container, \"core1\");\n    return solr;\n  }\n\n","sourceOld":"  public static EmbeddedSolrServer createEmbeddedSolrServer(Path solrHomeDir, FileSystem fs, Path outputShardDir)\n      throws IOException {\n\n    if (solrHomeDir == null) {\n      throw new IOException(\"Unable to find solr home setting\");\n    }\n    LOG.info(\"Creating embedded Solr server with solrHomeDir: \" + solrHomeDir + \", fs: \" + fs + \", outputShardDir: \" + outputShardDir);\n\n    Properties props = new Properties();\n    // FIXME note this is odd (no scheme) given Solr doesn't currently\n    // support uris (just abs/relative path)\n    Path solrDataDir = new Path(outputShardDir, \"data\");\n    if (!fs.exists(solrDataDir) && !fs.mkdirs(solrDataDir)) {\n      throw new IOException(\"Unable to create \" + solrDataDir);\n    }\n\n    String dataDirStr = solrDataDir.toUri().toString();\n    props.setProperty(\"solr.data.dir\", dataDirStr);\n    props.setProperty(\"solr.home\", solrHomeDir.toString());\n\n    SolrResourceLoader loader = new SolrResourceLoader(solrHomeDir.toString(),\n        null, props);\n\n    LOG.info(String\n        .format(Locale.ENGLISH, \n            \"Constructed instance information solr.home %s (%s), instance dir %s, conf dir %s, writing index to solr.data.dir %s, with permdir %s\",\n            solrHomeDir, solrHomeDir.toUri(), loader.getInstanceDir(),\n            loader.getConfigDir(), dataDirStr, outputShardDir));\n\n    CoreContainer container = new CoreContainer(loader);\n    container.load();\n    CoreDescriptor descr = new CoreDescriptor(container, \"core1\",\n        \".\", props);\n    \n    SolrCore core = container.create(descr);\n    container.register(core, false);\n    \n    System.setProperty(\"solr.hdfs.nrtcachingdirectory\", \"false\");\n    System.setProperty(\"solr.hdfs.blockcache.enabled\", \"false\");\n    System.setProperty(\"solr.autoCommit.maxTime\", \"-1\");\n    System.setProperty(\"solr.autoSoftCommit.maxTime\", \"-1\");\n    EmbeddedSolrServer solr = new EmbeddedSolrServer(container, \"core1\");\n    return solr;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9b0d372d32bc2f431c90e9d5bd34cd074a70479e","date":1386349487,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/SolrRecordWriter#createEmbeddedSolrServer(Path,FileSystem,Path).mjava","pathOld":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/SolrRecordWriter#createEmbeddedSolrServer(Path,FileSystem,Path).mjava","sourceNew":"  public static EmbeddedSolrServer createEmbeddedSolrServer(Path solrHomeDir, FileSystem fs, Path outputShardDir)\n      throws IOException {\n\n    if (solrHomeDir == null) {\n      throw new IOException(\"Unable to find solr home setting\");\n    }\n    LOG.info(\"Creating embedded Solr server with solrHomeDir: \" + solrHomeDir + \", fs: \" + fs + \", outputShardDir: \" + outputShardDir);\n\n    Path solrDataDir = new Path(outputShardDir, \"data\");\n\n    String dataDirStr = solrDataDir.toUri().toString();\n\n    SolrResourceLoader loader = new SolrResourceLoader(solrHomeDir.toString(), null, null);\n\n    LOG.info(String\n        .format(Locale.ENGLISH, \n            \"Constructed instance information solr.home %s (%s), instance dir %s, conf dir %s, writing index to solr.data.dir %s, with permdir %s\",\n            solrHomeDir, solrHomeDir.toUri(), loader.getInstanceDir(),\n            loader.getConfigDir(), dataDirStr, outputShardDir));\n\n    // TODO: This is fragile and should be well documented\n    System.setProperty(\"solr.directoryFactory\", HdfsDirectoryFactory.class.getName()); \n    System.setProperty(\"solr.lock.type\", \"hdfs\"); \n    System.setProperty(\"solr.hdfs.nrtcachingdirectory\", \"false\");\n    System.setProperty(\"solr.hdfs.blockcache.enabled\", \"false\");\n    System.setProperty(\"solr.autoCommit.maxTime\", \"-1\");\n    System.setProperty(\"solr.autoSoftCommit.maxTime\", \"-1\");\n    \n    CoreContainer container = new CoreContainer(loader);\n    container.load();\n    \n    Properties props = new Properties();\n    props.setProperty(CoreDescriptor.CORE_DATADIR, dataDirStr);\n    \n    CoreDescriptor descr = new CoreDescriptor(container, \"core1\", solrHomeDir.toString(), props);\n    \n    SolrCore core = container.create(descr);\n    container.register(core, false);\n\n    EmbeddedSolrServer solr = new EmbeddedSolrServer(container, \"core1\");\n    return solr;\n  }\n\n","sourceOld":"  public static EmbeddedSolrServer createEmbeddedSolrServer(Path solrHomeDir, FileSystem fs, Path outputShardDir)\n      throws IOException {\n\n    if (solrHomeDir == null) {\n      throw new IOException(\"Unable to find solr home setting\");\n    }\n    LOG.info(\"Creating embedded Solr server with solrHomeDir: \" + solrHomeDir + \", fs: \" + fs + \", outputShardDir: \" + outputShardDir);\n\n    Properties props = new Properties();\n    // FIXME note this is odd (no scheme) given Solr doesn't currently\n    // support uris (just abs/relative path)\n    Path solrDataDir = new Path(outputShardDir, \"data\");\n    if (!fs.exists(solrDataDir) && !fs.mkdirs(solrDataDir)) {\n      throw new IOException(\"Unable to create \" + solrDataDir);\n    }\n\n    String dataDirStr = solrDataDir.toUri().toString();\n    props.setProperty(\"solr.data.dir\", dataDirStr);\n    props.setProperty(\"solr.home\", solrHomeDir.toString());\n\n    SolrResourceLoader loader = new SolrResourceLoader(solrHomeDir.toString(),\n        null, props);\n\n    LOG.info(String\n        .format(Locale.ENGLISH, \n            \"Constructed instance information solr.home %s (%s), instance dir %s, conf dir %s, writing index to solr.data.dir %s, with permdir %s\",\n            solrHomeDir, solrHomeDir.toUri(), loader.getInstanceDir(),\n            loader.getConfigDir(), dataDirStr, outputShardDir));\n\n    CoreContainer container = new CoreContainer(loader);\n    container.load();\n    CoreDescriptor descr = new CoreDescriptor(container, \"core1\",\n        \".\", props);\n    \n    SolrCore core = container.create(descr);\n    container.register(core, false);\n    \n    System.setProperty(\"solr.hdfs.nrtcachingdirectory\", \"false\");\n    System.setProperty(\"solr.hdfs.blockcache.enabled\", \"false\");\n    System.setProperty(\"solr.autoCommit.maxTime\", \"-1\");\n    System.setProperty(\"solr.autoSoftCommit.maxTime\", \"-1\");\n    EmbeddedSolrServer solr = new EmbeddedSolrServer(container, \"core1\");\n    return solr;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"74f45af4339b0daf7a95c820ab88c1aea74fbce0","date":1387475327,"type":0,"author":"Michael McCandless","isMerge":true,"pathNew":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/SolrRecordWriter#createEmbeddedSolrServer(Path,FileSystem,Path).mjava","pathOld":"/dev/null","sourceNew":"  public static EmbeddedSolrServer createEmbeddedSolrServer(Path solrHomeDir, FileSystem fs, Path outputShardDir)\n      throws IOException {\n\n    if (solrHomeDir == null) {\n      throw new IOException(\"Unable to find solr home setting\");\n    }\n    LOG.info(\"Creating embedded Solr server with solrHomeDir: \" + solrHomeDir + \", fs: \" + fs + \", outputShardDir: \" + outputShardDir);\n\n    Path solrDataDir = new Path(outputShardDir, \"data\");\n\n    String dataDirStr = solrDataDir.toUri().toString();\n\n    SolrResourceLoader loader = new SolrResourceLoader(solrHomeDir.toString(), null, null);\n\n    LOG.info(String\n        .format(Locale.ENGLISH, \n            \"Constructed instance information solr.home %s (%s), instance dir %s, conf dir %s, writing index to solr.data.dir %s, with permdir %s\",\n            solrHomeDir, solrHomeDir.toUri(), loader.getInstanceDir(),\n            loader.getConfigDir(), dataDirStr, outputShardDir));\n\n    // TODO: This is fragile and should be well documented\n    System.setProperty(\"solr.directoryFactory\", HdfsDirectoryFactory.class.getName()); \n    System.setProperty(\"solr.lock.type\", \"hdfs\"); \n    System.setProperty(\"solr.hdfs.nrtcachingdirectory\", \"false\");\n    System.setProperty(\"solr.hdfs.blockcache.enabled\", \"false\");\n    System.setProperty(\"solr.autoCommit.maxTime\", \"-1\");\n    System.setProperty(\"solr.autoSoftCommit.maxTime\", \"-1\");\n    \n    CoreContainer container = new CoreContainer(loader);\n    container.load();\n    \n    Properties props = new Properties();\n    props.setProperty(CoreDescriptor.CORE_DATADIR, dataDirStr);\n    \n    CoreDescriptor descr = new CoreDescriptor(container, \"core1\", solrHomeDir.toString(), props);\n    \n    SolrCore core = container.create(descr);\n    container.register(core, false);\n\n    EmbeddedSolrServer solr = new EmbeddedSolrServer(container, \"core1\");\n    return solr;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1c531908b0df71ea5e90eb461360834ef05dd417","date":1389837541,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/SolrRecordWriter#createEmbeddedSolrServer(Path,FileSystem,Path).mjava","pathOld":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/SolrRecordWriter#createEmbeddedSolrServer(Path,FileSystem,Path).mjava","sourceNew":"  public static EmbeddedSolrServer createEmbeddedSolrServer(Path solrHomeDir, FileSystem fs, Path outputShardDir)\n      throws IOException {\n\n    if (solrHomeDir == null) {\n      throw new IOException(\"Unable to find solr home setting\");\n    }\n    LOG.info(\"Creating embedded Solr server with solrHomeDir: \" + solrHomeDir + \", fs: \" + fs + \", outputShardDir: \" + outputShardDir);\n\n    Path solrDataDir = new Path(outputShardDir, \"data\");\n\n    String dataDirStr = solrDataDir.toUri().toString();\n\n    SolrResourceLoader loader = new SolrResourceLoader(solrHomeDir.toString(), null, null);\n\n    LOG.info(String\n        .format(Locale.ENGLISH, \n            \"Constructed instance information solr.home %s (%s), instance dir %s, conf dir %s, writing index to solr.data.dir %s, with permdir %s\",\n            solrHomeDir, solrHomeDir.toUri(), loader.getInstanceDir(),\n            loader.getConfigDir(), dataDirStr, outputShardDir));\n\n    // TODO: This is fragile and should be well documented\n    System.setProperty(\"solr.directoryFactory\", HdfsDirectoryFactory.class.getName()); \n    System.setProperty(\"solr.lock.type\", \"hdfs\"); \n    System.setProperty(\"solr.hdfs.nrtcachingdirectory\", \"false\");\n    System.setProperty(\"solr.hdfs.blockcache.enabled\", \"false\");\n    System.setProperty(\"solr.autoCommit.maxTime\", \"-1\");\n    System.setProperty(\"solr.autoSoftCommit.maxTime\", \"-1\");\n    \n    CoreContainer container = new CoreContainer(loader);\n    container.load();\n    \n    Properties props = new Properties();\n    props.setProperty(CoreDescriptor.CORE_DATADIR, dataDirStr);\n    \n    CoreDescriptor descr = new CoreDescriptor(container, \"core1\", solrHomeDir.toString(), props);\n    \n    SolrCore core = container.create(descr);\n    \n    if (!(core.getDirectoryFactory() instanceof HdfsDirectoryFactory)) {\n      throw new UnsupportedOperationException(\n          \"Invalid configuration. Currently, the only DirectoryFactory supported is \"\n              + HdfsDirectoryFactory.class.getSimpleName());\n    }\n\n    container.register(core, false);\n\n    EmbeddedSolrServer solr = new EmbeddedSolrServer(container, \"core1\");\n    return solr;\n  }\n\n","sourceOld":"  public static EmbeddedSolrServer createEmbeddedSolrServer(Path solrHomeDir, FileSystem fs, Path outputShardDir)\n      throws IOException {\n\n    if (solrHomeDir == null) {\n      throw new IOException(\"Unable to find solr home setting\");\n    }\n    LOG.info(\"Creating embedded Solr server with solrHomeDir: \" + solrHomeDir + \", fs: \" + fs + \", outputShardDir: \" + outputShardDir);\n\n    Path solrDataDir = new Path(outputShardDir, \"data\");\n\n    String dataDirStr = solrDataDir.toUri().toString();\n\n    SolrResourceLoader loader = new SolrResourceLoader(solrHomeDir.toString(), null, null);\n\n    LOG.info(String\n        .format(Locale.ENGLISH, \n            \"Constructed instance information solr.home %s (%s), instance dir %s, conf dir %s, writing index to solr.data.dir %s, with permdir %s\",\n            solrHomeDir, solrHomeDir.toUri(), loader.getInstanceDir(),\n            loader.getConfigDir(), dataDirStr, outputShardDir));\n\n    // TODO: This is fragile and should be well documented\n    System.setProperty(\"solr.directoryFactory\", HdfsDirectoryFactory.class.getName()); \n    System.setProperty(\"solr.lock.type\", \"hdfs\"); \n    System.setProperty(\"solr.hdfs.nrtcachingdirectory\", \"false\");\n    System.setProperty(\"solr.hdfs.blockcache.enabled\", \"false\");\n    System.setProperty(\"solr.autoCommit.maxTime\", \"-1\");\n    System.setProperty(\"solr.autoSoftCommit.maxTime\", \"-1\");\n    \n    CoreContainer container = new CoreContainer(loader);\n    container.load();\n    \n    Properties props = new Properties();\n    props.setProperty(CoreDescriptor.CORE_DATADIR, dataDirStr);\n    \n    CoreDescriptor descr = new CoreDescriptor(container, \"core1\", solrHomeDir.toString(), props);\n    \n    SolrCore core = container.create(descr);\n    container.register(core, false);\n\n    EmbeddedSolrServer solr = new EmbeddedSolrServer(container, \"core1\");\n    return solr;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c74a1d30fa4439a3687ae194fa516accc89d4f35","date":1395251530,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/SolrRecordWriter#createEmbeddedSolrServer(Path,FileSystem,Path).mjava","pathOld":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/SolrRecordWriter#createEmbeddedSolrServer(Path,FileSystem,Path).mjava","sourceNew":"  public static EmbeddedSolrServer createEmbeddedSolrServer(Path solrHomeDir, FileSystem fs, Path outputShardDir)\n      throws IOException {\n\n    if (solrHomeDir == null) {\n      throw new IOException(\"Unable to find solr home setting\");\n    }\n    LOG.info(\"Creating embedded Solr server with solrHomeDir: \" + solrHomeDir + \", fs: \" + fs + \", outputShardDir: \" + outputShardDir);\n\n    Path solrDataDir = new Path(outputShardDir, \"data\");\n\n    String dataDirStr = solrDataDir.toUri().toString();\n\n    SolrResourceLoader loader = new SolrResourceLoader(solrHomeDir.toString(), null, null);\n\n    LOG.info(String\n        .format(Locale.ENGLISH, \n            \"Constructed instance information solr.home %s (%s), instance dir %s, conf dir %s, writing index to solr.data.dir %s, with permdir %s\",\n            solrHomeDir, solrHomeDir.toUri(), loader.getInstanceDir(),\n            loader.getConfigDir(), dataDirStr, outputShardDir));\n\n    // TODO: This is fragile and should be well documented\n    System.setProperty(\"solr.directoryFactory\", HdfsDirectoryFactory.class.getName()); \n    System.setProperty(\"solr.lock.type\", \"hdfs\"); \n    System.setProperty(\"solr.hdfs.nrtcachingdirectory\", \"false\");\n    System.setProperty(\"solr.hdfs.blockcache.enabled\", \"false\");\n    System.setProperty(\"solr.autoCommit.maxTime\", \"600000\");\n    System.setProperty(\"solr.autoSoftCommit.maxTime\", \"-1\");\n    \n    CoreContainer container = new CoreContainer(loader);\n    container.load();\n    \n    Properties props = new Properties();\n    props.setProperty(CoreDescriptor.CORE_DATADIR, dataDirStr);\n    \n    CoreDescriptor descr = new CoreDescriptor(container, \"core1\", solrHomeDir.toString(), props);\n    \n    SolrCore core = container.create(descr);\n    \n    if (!(core.getDirectoryFactory() instanceof HdfsDirectoryFactory)) {\n      throw new UnsupportedOperationException(\n          \"Invalid configuration. Currently, the only DirectoryFactory supported is \"\n              + HdfsDirectoryFactory.class.getSimpleName());\n    }\n\n    container.register(core, false);\n\n    EmbeddedSolrServer solr = new EmbeddedSolrServer(container, \"core1\");\n    return solr;\n  }\n\n","sourceOld":"  public static EmbeddedSolrServer createEmbeddedSolrServer(Path solrHomeDir, FileSystem fs, Path outputShardDir)\n      throws IOException {\n\n    if (solrHomeDir == null) {\n      throw new IOException(\"Unable to find solr home setting\");\n    }\n    LOG.info(\"Creating embedded Solr server with solrHomeDir: \" + solrHomeDir + \", fs: \" + fs + \", outputShardDir: \" + outputShardDir);\n\n    Path solrDataDir = new Path(outputShardDir, \"data\");\n\n    String dataDirStr = solrDataDir.toUri().toString();\n\n    SolrResourceLoader loader = new SolrResourceLoader(solrHomeDir.toString(), null, null);\n\n    LOG.info(String\n        .format(Locale.ENGLISH, \n            \"Constructed instance information solr.home %s (%s), instance dir %s, conf dir %s, writing index to solr.data.dir %s, with permdir %s\",\n            solrHomeDir, solrHomeDir.toUri(), loader.getInstanceDir(),\n            loader.getConfigDir(), dataDirStr, outputShardDir));\n\n    // TODO: This is fragile and should be well documented\n    System.setProperty(\"solr.directoryFactory\", HdfsDirectoryFactory.class.getName()); \n    System.setProperty(\"solr.lock.type\", \"hdfs\"); \n    System.setProperty(\"solr.hdfs.nrtcachingdirectory\", \"false\");\n    System.setProperty(\"solr.hdfs.blockcache.enabled\", \"false\");\n    System.setProperty(\"solr.autoCommit.maxTime\", \"-1\");\n    System.setProperty(\"solr.autoSoftCommit.maxTime\", \"-1\");\n    \n    CoreContainer container = new CoreContainer(loader);\n    container.load();\n    \n    Properties props = new Properties();\n    props.setProperty(CoreDescriptor.CORE_DATADIR, dataDirStr);\n    \n    CoreDescriptor descr = new CoreDescriptor(container, \"core1\", solrHomeDir.toString(), props);\n    \n    SolrCore core = container.create(descr);\n    \n    if (!(core.getDirectoryFactory() instanceof HdfsDirectoryFactory)) {\n      throw new UnsupportedOperationException(\n          \"Invalid configuration. Currently, the only DirectoryFactory supported is \"\n              + HdfsDirectoryFactory.class.getSimpleName());\n    }\n\n    container.register(core, false);\n\n    EmbeddedSolrServer solr = new EmbeddedSolrServer(container, \"core1\");\n    return solr;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"85032ab568b3f50eabd577aaa994ba197db93758","date":1404157267,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/SolrRecordWriter#createEmbeddedSolrServer(Path,FileSystem,Path).mjava","pathOld":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/SolrRecordWriter#createEmbeddedSolrServer(Path,FileSystem,Path).mjava","sourceNew":"  public static EmbeddedSolrServer createEmbeddedSolrServer(Path solrHomeDir, FileSystem fs, Path outputShardDir)\n      throws IOException {\n\n    if (solrHomeDir == null) {\n      throw new IOException(\"Unable to find solr home setting\");\n    }\n    LOG.info(\"Creating embedded Solr server with solrHomeDir: \" + solrHomeDir + \", fs: \" + fs + \", outputShardDir: \" + outputShardDir);\n\n    Path solrDataDir = new Path(outputShardDir, \"data\");\n\n    String dataDirStr = solrDataDir.toUri().toString();\n\n    SolrResourceLoader loader = new SolrResourceLoader(solrHomeDir.toString(), null, null);\n\n    LOG.info(String\n        .format(Locale.ENGLISH, \n            \"Constructed instance information solr.home %s (%s), instance dir %s, conf dir %s, writing index to solr.data.dir %s, with permdir %s\",\n            solrHomeDir, solrHomeDir.toUri(), loader.getInstanceDir(),\n            loader.getConfigDir(), dataDirStr, outputShardDir));\n\n    // TODO: This is fragile and should be well documented\n    System.setProperty(\"solr.directoryFactory\", HdfsDirectoryFactory.class.getName()); \n    System.setProperty(\"solr.lock.type\", \"hdfs\"); \n    System.setProperty(\"solr.hdfs.nrtcachingdirectory\", \"false\");\n    System.setProperty(\"solr.hdfs.blockcache.enabled\", \"false\");\n    System.setProperty(\"solr.autoCommit.maxTime\", \"600000\");\n    System.setProperty(\"solr.autoSoftCommit.maxTime\", \"-1\");\n    \n    CoreContainer container = new CoreContainer(loader);\n    container.load();\n    \n    Properties props = new Properties();\n    props.setProperty(CoreDescriptor.CORE_DATADIR, dataDirStr);\n    \n    CoreDescriptor descr = new CoreDescriptor(container, \"core1\", solrHomeDir.toString(), props);\n    \n    SolrCore core = container.create(descr);\n    \n    if (!(core.getDirectoryFactory() instanceof HdfsDirectoryFactory)) {\n      throw new UnsupportedOperationException(\n          \"Invalid configuration. Currently, the only DirectoryFactory supported is \"\n              + HdfsDirectoryFactory.class.getSimpleName());\n    }\n\n    EmbeddedSolrServer solr = new EmbeddedSolrServer(container, \"core1\");\n    return solr;\n  }\n\n","sourceOld":"  public static EmbeddedSolrServer createEmbeddedSolrServer(Path solrHomeDir, FileSystem fs, Path outputShardDir)\n      throws IOException {\n\n    if (solrHomeDir == null) {\n      throw new IOException(\"Unable to find solr home setting\");\n    }\n    LOG.info(\"Creating embedded Solr server with solrHomeDir: \" + solrHomeDir + \", fs: \" + fs + \", outputShardDir: \" + outputShardDir);\n\n    Path solrDataDir = new Path(outputShardDir, \"data\");\n\n    String dataDirStr = solrDataDir.toUri().toString();\n\n    SolrResourceLoader loader = new SolrResourceLoader(solrHomeDir.toString(), null, null);\n\n    LOG.info(String\n        .format(Locale.ENGLISH, \n            \"Constructed instance information solr.home %s (%s), instance dir %s, conf dir %s, writing index to solr.data.dir %s, with permdir %s\",\n            solrHomeDir, solrHomeDir.toUri(), loader.getInstanceDir(),\n            loader.getConfigDir(), dataDirStr, outputShardDir));\n\n    // TODO: This is fragile and should be well documented\n    System.setProperty(\"solr.directoryFactory\", HdfsDirectoryFactory.class.getName()); \n    System.setProperty(\"solr.lock.type\", \"hdfs\"); \n    System.setProperty(\"solr.hdfs.nrtcachingdirectory\", \"false\");\n    System.setProperty(\"solr.hdfs.blockcache.enabled\", \"false\");\n    System.setProperty(\"solr.autoCommit.maxTime\", \"600000\");\n    System.setProperty(\"solr.autoSoftCommit.maxTime\", \"-1\");\n    \n    CoreContainer container = new CoreContainer(loader);\n    container.load();\n    \n    Properties props = new Properties();\n    props.setProperty(CoreDescriptor.CORE_DATADIR, dataDirStr);\n    \n    CoreDescriptor descr = new CoreDescriptor(container, \"core1\", solrHomeDir.toString(), props);\n    \n    SolrCore core = container.create(descr);\n    \n    if (!(core.getDirectoryFactory() instanceof HdfsDirectoryFactory)) {\n      throw new UnsupportedOperationException(\n          \"Invalid configuration. Currently, the only DirectoryFactory supported is \"\n              + HdfsDirectoryFactory.class.getSimpleName());\n    }\n\n    container.register(core, false);\n\n    EmbeddedSolrServer solr = new EmbeddedSolrServer(container, \"core1\");\n    return solr;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"efa0ddc8716305bc4a06f27f9ae99fe5e23fc87d","date":1433692150,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/SolrRecordWriter#createEmbeddedSolrServer(Path,FileSystem,Path).mjava","pathOld":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/SolrRecordWriter#createEmbeddedSolrServer(Path,FileSystem,Path).mjava","sourceNew":"  public static EmbeddedSolrServer createEmbeddedSolrServer(Path solrHomeDir, FileSystem fs, Path outputShardDir)\n      throws IOException {\n\n    LOG.info(\"Creating embedded Solr server with solrHomeDir: \" + solrHomeDir + \", fs: \" + fs + \", outputShardDir: \" + outputShardDir);\n\n    Path solrDataDir = new Path(outputShardDir, \"data\");\n\n    String dataDirStr = solrDataDir.toUri().toString();\n\n    SolrResourceLoader loader = new SolrResourceLoader(solrHomeDir.toString(), null, null);\n\n    LOG.info(String\n        .format(Locale.ENGLISH, \n            \"Constructed instance information solr.home %s (%s), instance dir %s, conf dir %s, writing index to solr.data.dir %s, with permdir %s\",\n            solrHomeDir, solrHomeDir.toUri(), loader.getInstanceDir(),\n            loader.getConfigDir(), dataDirStr, outputShardDir));\n\n    // TODO: This is fragile and should be well documented\n    System.setProperty(\"solr.directoryFactory\", HdfsDirectoryFactory.class.getName()); \n    System.setProperty(\"solr.lock.type\", \"hdfs\"); \n    System.setProperty(\"solr.hdfs.nrtcachingdirectory\", \"false\");\n    System.setProperty(\"solr.hdfs.blockcache.enabled\", \"false\");\n    System.setProperty(\"solr.autoCommit.maxTime\", \"600000\");\n    System.setProperty(\"solr.autoSoftCommit.maxTime\", \"-1\");\n    \n    CoreContainer container = new CoreContainer(loader);\n    container.load();\n    \n    Properties props = new Properties();\n    props.setProperty(CoreDescriptor.CORE_DATADIR, dataDirStr);\n    \n    CoreDescriptor descr = new CoreDescriptor(container, \"core1\", solrHomeDir.toString(), props);\n    \n    SolrCore core = container.create(descr);\n    \n    if (!(core.getDirectoryFactory() instanceof HdfsDirectoryFactory)) {\n      throw new UnsupportedOperationException(\n          \"Invalid configuration. Currently, the only DirectoryFactory supported is \"\n              + HdfsDirectoryFactory.class.getSimpleName());\n    }\n\n    EmbeddedSolrServer solr = new EmbeddedSolrServer(container, \"core1\");\n    return solr;\n  }\n\n","sourceOld":"  public static EmbeddedSolrServer createEmbeddedSolrServer(Path solrHomeDir, FileSystem fs, Path outputShardDir)\n      throws IOException {\n\n    if (solrHomeDir == null) {\n      throw new IOException(\"Unable to find solr home setting\");\n    }\n    LOG.info(\"Creating embedded Solr server with solrHomeDir: \" + solrHomeDir + \", fs: \" + fs + \", outputShardDir: \" + outputShardDir);\n\n    Path solrDataDir = new Path(outputShardDir, \"data\");\n\n    String dataDirStr = solrDataDir.toUri().toString();\n\n    SolrResourceLoader loader = new SolrResourceLoader(solrHomeDir.toString(), null, null);\n\n    LOG.info(String\n        .format(Locale.ENGLISH, \n            \"Constructed instance information solr.home %s (%s), instance dir %s, conf dir %s, writing index to solr.data.dir %s, with permdir %s\",\n            solrHomeDir, solrHomeDir.toUri(), loader.getInstanceDir(),\n            loader.getConfigDir(), dataDirStr, outputShardDir));\n\n    // TODO: This is fragile and should be well documented\n    System.setProperty(\"solr.directoryFactory\", HdfsDirectoryFactory.class.getName()); \n    System.setProperty(\"solr.lock.type\", \"hdfs\"); \n    System.setProperty(\"solr.hdfs.nrtcachingdirectory\", \"false\");\n    System.setProperty(\"solr.hdfs.blockcache.enabled\", \"false\");\n    System.setProperty(\"solr.autoCommit.maxTime\", \"600000\");\n    System.setProperty(\"solr.autoSoftCommit.maxTime\", \"-1\");\n    \n    CoreContainer container = new CoreContainer(loader);\n    container.load();\n    \n    Properties props = new Properties();\n    props.setProperty(CoreDescriptor.CORE_DATADIR, dataDirStr);\n    \n    CoreDescriptor descr = new CoreDescriptor(container, \"core1\", solrHomeDir.toString(), props);\n    \n    SolrCore core = container.create(descr);\n    \n    if (!(core.getDirectoryFactory() instanceof HdfsDirectoryFactory)) {\n      throw new UnsupportedOperationException(\n          \"Invalid configuration. Currently, the only DirectoryFactory supported is \"\n              + HdfsDirectoryFactory.class.getSimpleName());\n    }\n\n    EmbeddedSolrServer solr = new EmbeddedSolrServer(container, \"core1\");\n    return solr;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a626ec4d1c92e59fe390724d6220081047b03ce7","date":1448021525,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/SolrRecordWriter#createEmbeddedSolrServer(Path,FileSystem,Path).mjava","pathOld":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/SolrRecordWriter#createEmbeddedSolrServer(Path,FileSystem,Path).mjava","sourceNew":"  public static EmbeddedSolrServer createEmbeddedSolrServer(Path solrHomeDir, FileSystem fs, Path outputShardDir)\n      throws IOException {\n\n    LOG.info(\"Creating embedded Solr server with solrHomeDir: \" + solrHomeDir + \", fs: \" + fs + \", outputShardDir: \" + outputShardDir);\n\n    Path solrDataDir = new Path(outputShardDir, \"data\");\n\n    String dataDirStr = solrDataDir.toUri().toString();\n\n    SolrResourceLoader loader = new SolrResourceLoader(Paths.get(solrHomeDir.toString()), null, null);\n\n    LOG.info(String\n        .format(Locale.ENGLISH, \n            \"Constructed instance information solr.home %s (%s), instance dir %s, conf dir %s, writing index to solr.data.dir %s, with permdir %s\",\n            solrHomeDir, solrHomeDir.toUri(), loader.getInstancePath(),\n            loader.getConfigDir(), dataDirStr, outputShardDir));\n\n    // TODO: This is fragile and should be well documented\n    System.setProperty(\"solr.directoryFactory\", HdfsDirectoryFactory.class.getName()); \n    System.setProperty(\"solr.lock.type\", \"hdfs\"); \n    System.setProperty(\"solr.hdfs.nrtcachingdirectory\", \"false\");\n    System.setProperty(\"solr.hdfs.blockcache.enabled\", \"false\");\n    System.setProperty(\"solr.autoCommit.maxTime\", \"600000\");\n    System.setProperty(\"solr.autoSoftCommit.maxTime\", \"-1\");\n    \n    CoreContainer container = new CoreContainer(loader);\n    container.load();\n    \n    Properties props = new Properties();\n    props.setProperty(CoreDescriptor.CORE_DATADIR, dataDirStr);\n    \n    CoreDescriptor descr = new CoreDescriptor(container, \"core1\", solrHomeDir.toString(), props);\n    \n    SolrCore core = container.create(descr);\n    \n    if (!(core.getDirectoryFactory() instanceof HdfsDirectoryFactory)) {\n      throw new UnsupportedOperationException(\n          \"Invalid configuration. Currently, the only DirectoryFactory supported is \"\n              + HdfsDirectoryFactory.class.getSimpleName());\n    }\n\n    EmbeddedSolrServer solr = new EmbeddedSolrServer(container, \"core1\");\n    return solr;\n  }\n\n","sourceOld":"  public static EmbeddedSolrServer createEmbeddedSolrServer(Path solrHomeDir, FileSystem fs, Path outputShardDir)\n      throws IOException {\n\n    LOG.info(\"Creating embedded Solr server with solrHomeDir: \" + solrHomeDir + \", fs: \" + fs + \", outputShardDir: \" + outputShardDir);\n\n    Path solrDataDir = new Path(outputShardDir, \"data\");\n\n    String dataDirStr = solrDataDir.toUri().toString();\n\n    SolrResourceLoader loader = new SolrResourceLoader(solrHomeDir.toString(), null, null);\n\n    LOG.info(String\n        .format(Locale.ENGLISH, \n            \"Constructed instance information solr.home %s (%s), instance dir %s, conf dir %s, writing index to solr.data.dir %s, with permdir %s\",\n            solrHomeDir, solrHomeDir.toUri(), loader.getInstanceDir(),\n            loader.getConfigDir(), dataDirStr, outputShardDir));\n\n    // TODO: This is fragile and should be well documented\n    System.setProperty(\"solr.directoryFactory\", HdfsDirectoryFactory.class.getName()); \n    System.setProperty(\"solr.lock.type\", \"hdfs\"); \n    System.setProperty(\"solr.hdfs.nrtcachingdirectory\", \"false\");\n    System.setProperty(\"solr.hdfs.blockcache.enabled\", \"false\");\n    System.setProperty(\"solr.autoCommit.maxTime\", \"600000\");\n    System.setProperty(\"solr.autoSoftCommit.maxTime\", \"-1\");\n    \n    CoreContainer container = new CoreContainer(loader);\n    container.load();\n    \n    Properties props = new Properties();\n    props.setProperty(CoreDescriptor.CORE_DATADIR, dataDirStr);\n    \n    CoreDescriptor descr = new CoreDescriptor(container, \"core1\", solrHomeDir.toString(), props);\n    \n    SolrCore core = container.create(descr);\n    \n    if (!(core.getDirectoryFactory() instanceof HdfsDirectoryFactory)) {\n      throw new UnsupportedOperationException(\n          \"Invalid configuration. Currently, the only DirectoryFactory supported is \"\n              + HdfsDirectoryFactory.class.getSimpleName());\n    }\n\n    EmbeddedSolrServer solr = new EmbeddedSolrServer(container, \"core1\");\n    return solr;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"11d8a050b7d5f98040f790d32ec1cfd2fc3490e3","date":1448892165,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/SolrRecordWriter#createEmbeddedSolrServer(Path,FileSystem,Path).mjava","pathOld":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/SolrRecordWriter#createEmbeddedSolrServer(Path,FileSystem,Path).mjava","sourceNew":"  public static EmbeddedSolrServer createEmbeddedSolrServer(Path solrHomeDir, FileSystem fs, Path outputShardDir)\n      throws IOException {\n\n    LOG.info(\"Creating embedded Solr server with solrHomeDir: \" + solrHomeDir + \", fs: \" + fs + \", outputShardDir: \" + outputShardDir);\n\n    Path solrDataDir = new Path(outputShardDir, \"data\");\n\n    String dataDirStr = solrDataDir.toUri().toString();\n\n    SolrResourceLoader loader = new SolrResourceLoader(Paths.get(solrHomeDir.toString()), null, null);\n\n    LOG.info(String\n        .format(Locale.ENGLISH, \n            \"Constructed instance information solr.home %s (%s), instance dir %s, conf dir %s, writing index to solr.data.dir %s, with permdir %s\",\n            solrHomeDir, solrHomeDir.toUri(), loader.getInstancePath(),\n            loader.getConfigDir(), dataDirStr, outputShardDir));\n\n    // TODO: This is fragile and should be well documented\n    System.setProperty(\"solr.directoryFactory\", HdfsDirectoryFactory.class.getName()); \n    System.setProperty(\"solr.lock.type\", \"hdfs\"); \n    System.setProperty(\"solr.hdfs.nrtcachingdirectory\", \"false\");\n    System.setProperty(\"solr.hdfs.blockcache.enabled\", \"false\");\n    System.setProperty(\"solr.autoCommit.maxTime\", \"600000\");\n    System.setProperty(\"solr.autoSoftCommit.maxTime\", \"-1\");\n    \n    CoreContainer container = new CoreContainer(loader);\n    container.load();\n\n    SolrCore core = container.create(\"core1\", ImmutableMap.of(CoreDescriptor.CORE_DATADIR, dataDirStr));\n    \n    if (!(core.getDirectoryFactory() instanceof HdfsDirectoryFactory)) {\n      throw new UnsupportedOperationException(\n          \"Invalid configuration. Currently, the only DirectoryFactory supported is \"\n              + HdfsDirectoryFactory.class.getSimpleName());\n    }\n\n    EmbeddedSolrServer solr = new EmbeddedSolrServer(container, \"core1\");\n    return solr;\n  }\n\n","sourceOld":"  public static EmbeddedSolrServer createEmbeddedSolrServer(Path solrHomeDir, FileSystem fs, Path outputShardDir)\n      throws IOException {\n\n    LOG.info(\"Creating embedded Solr server with solrHomeDir: \" + solrHomeDir + \", fs: \" + fs + \", outputShardDir: \" + outputShardDir);\n\n    Path solrDataDir = new Path(outputShardDir, \"data\");\n\n    String dataDirStr = solrDataDir.toUri().toString();\n\n    SolrResourceLoader loader = new SolrResourceLoader(Paths.get(solrHomeDir.toString()), null, null);\n\n    LOG.info(String\n        .format(Locale.ENGLISH, \n            \"Constructed instance information solr.home %s (%s), instance dir %s, conf dir %s, writing index to solr.data.dir %s, with permdir %s\",\n            solrHomeDir, solrHomeDir.toUri(), loader.getInstancePath(),\n            loader.getConfigDir(), dataDirStr, outputShardDir));\n\n    // TODO: This is fragile and should be well documented\n    System.setProperty(\"solr.directoryFactory\", HdfsDirectoryFactory.class.getName()); \n    System.setProperty(\"solr.lock.type\", \"hdfs\"); \n    System.setProperty(\"solr.hdfs.nrtcachingdirectory\", \"false\");\n    System.setProperty(\"solr.hdfs.blockcache.enabled\", \"false\");\n    System.setProperty(\"solr.autoCommit.maxTime\", \"600000\");\n    System.setProperty(\"solr.autoSoftCommit.maxTime\", \"-1\");\n    \n    CoreContainer container = new CoreContainer(loader);\n    container.load();\n    \n    Properties props = new Properties();\n    props.setProperty(CoreDescriptor.CORE_DATADIR, dataDirStr);\n    \n    CoreDescriptor descr = new CoreDescriptor(container, \"core1\", solrHomeDir.toString(), props);\n    \n    SolrCore core = container.create(descr);\n    \n    if (!(core.getDirectoryFactory() instanceof HdfsDirectoryFactory)) {\n      throw new UnsupportedOperationException(\n          \"Invalid configuration. Currently, the only DirectoryFactory supported is \"\n              + HdfsDirectoryFactory.class.getSimpleName());\n    }\n\n    EmbeddedSolrServer solr = new EmbeddedSolrServer(container, \"core1\");\n    return solr;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e50357e583524185222c1c691f5c333b34f7cbb2","date":1452268776,"type":3,"author":"Christine Poerschke","isMerge":false,"pathNew":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/SolrRecordWriter#createEmbeddedSolrServer(Path,FileSystem,Path).mjava","pathOld":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/SolrRecordWriter#createEmbeddedSolrServer(Path,FileSystem,Path).mjava","sourceNew":"  public static EmbeddedSolrServer createEmbeddedSolrServer(Path solrHomeDir, FileSystem fs, Path outputShardDir)\n      throws IOException {\n\n    LOG.info(\"Creating embedded Solr server with solrHomeDir: \" + solrHomeDir + \", fs: \" + fs + \", outputShardDir: \" + outputShardDir);\n\n    Path solrDataDir = new Path(outputShardDir, \"data\");\n\n    String dataDirStr = solrDataDir.toUri().toString();\n\n    SolrResourceLoader loader = new SolrResourceLoader(Paths.get(solrHomeDir.toString()), null, null);\n\n    LOG.info(String\n        .format(Locale.ENGLISH, \n            \"Constructed instance information solr.home %s (%s), instance dir %s, conf dir %s, writing index to solr.data.dir %s, with permdir %s\",\n            solrHomeDir, solrHomeDir.toUri(), loader.getInstancePath(),\n            loader.getConfigDir(), dataDirStr, outputShardDir));\n\n    // TODO: This is fragile and should be well documented\n    System.setProperty(\"solr.directoryFactory\", HdfsDirectoryFactory.class.getName()); \n    System.setProperty(\"solr.lock.type\", DirectoryFactory.LOCK_TYPE_HDFS);\n    System.setProperty(\"solr.hdfs.nrtcachingdirectory\", \"false\");\n    System.setProperty(\"solr.hdfs.blockcache.enabled\", \"false\");\n    System.setProperty(\"solr.autoCommit.maxTime\", \"600000\");\n    System.setProperty(\"solr.autoSoftCommit.maxTime\", \"-1\");\n    \n    CoreContainer container = new CoreContainer(loader);\n    container.load();\n\n    SolrCore core = container.create(\"core1\", ImmutableMap.of(CoreDescriptor.CORE_DATADIR, dataDirStr));\n    \n    if (!(core.getDirectoryFactory() instanceof HdfsDirectoryFactory)) {\n      throw new UnsupportedOperationException(\n          \"Invalid configuration. Currently, the only DirectoryFactory supported is \"\n              + HdfsDirectoryFactory.class.getSimpleName());\n    }\n\n    EmbeddedSolrServer solr = new EmbeddedSolrServer(container, \"core1\");\n    return solr;\n  }\n\n","sourceOld":"  public static EmbeddedSolrServer createEmbeddedSolrServer(Path solrHomeDir, FileSystem fs, Path outputShardDir)\n      throws IOException {\n\n    LOG.info(\"Creating embedded Solr server with solrHomeDir: \" + solrHomeDir + \", fs: \" + fs + \", outputShardDir: \" + outputShardDir);\n\n    Path solrDataDir = new Path(outputShardDir, \"data\");\n\n    String dataDirStr = solrDataDir.toUri().toString();\n\n    SolrResourceLoader loader = new SolrResourceLoader(Paths.get(solrHomeDir.toString()), null, null);\n\n    LOG.info(String\n        .format(Locale.ENGLISH, \n            \"Constructed instance information solr.home %s (%s), instance dir %s, conf dir %s, writing index to solr.data.dir %s, with permdir %s\",\n            solrHomeDir, solrHomeDir.toUri(), loader.getInstancePath(),\n            loader.getConfigDir(), dataDirStr, outputShardDir));\n\n    // TODO: This is fragile and should be well documented\n    System.setProperty(\"solr.directoryFactory\", HdfsDirectoryFactory.class.getName()); \n    System.setProperty(\"solr.lock.type\", \"hdfs\"); \n    System.setProperty(\"solr.hdfs.nrtcachingdirectory\", \"false\");\n    System.setProperty(\"solr.hdfs.blockcache.enabled\", \"false\");\n    System.setProperty(\"solr.autoCommit.maxTime\", \"600000\");\n    System.setProperty(\"solr.autoSoftCommit.maxTime\", \"-1\");\n    \n    CoreContainer container = new CoreContainer(loader);\n    container.load();\n\n    SolrCore core = container.create(\"core1\", ImmutableMap.of(CoreDescriptor.CORE_DATADIR, dataDirStr));\n    \n    if (!(core.getDirectoryFactory() instanceof HdfsDirectoryFactory)) {\n      throw new UnsupportedOperationException(\n          \"Invalid configuration. Currently, the only DirectoryFactory supported is \"\n              + HdfsDirectoryFactory.class.getSimpleName());\n    }\n\n    EmbeddedSolrServer solr = new EmbeddedSolrServer(container, \"core1\");\n    return solr;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"61c6fb105d0ce095d846502a1d7a2a4bbf8fdecd","date":1466528770,"type":3,"author":"markrmiller","isMerge":false,"pathNew":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/SolrRecordWriter#createEmbeddedSolrServer(Path,FileSystem,Path).mjava","pathOld":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/SolrRecordWriter#createEmbeddedSolrServer(Path,FileSystem,Path).mjava","sourceNew":"  public static EmbeddedSolrServer createEmbeddedSolrServer(Path solrHomeDir, FileSystem fs, Path outputShardDir)\n      throws IOException {\n\n    LOG.info(\"Creating embedded Solr server with solrHomeDir: \" + solrHomeDir + \", fs: \" + fs + \", outputShardDir: \" + outputShardDir);\n\n    Path solrDataDir = new Path(outputShardDir, \"data\");\n\n    String dataDirStr = solrDataDir.toUri().toString();\n\n    SolrResourceLoader loader = new SolrResourceLoader(Paths.get(solrHomeDir.toString()), null, null);\n\n    LOG.info(String\n        .format(Locale.ENGLISH, \n            \"Constructed instance information solr.home %s (%s), instance dir %s, conf dir %s, writing index to solr.data.dir %s, with permdir %s\",\n            solrHomeDir, solrHomeDir.toUri(), loader.getInstancePath(),\n            loader.getConfigDir(), dataDirStr, outputShardDir));\n\n    // TODO: This is fragile and should be well documented\n    System.setProperty(\"solr.directoryFactory\", HdfsDirectoryFactory.class.getName()); \n    System.setProperty(\"solr.lock.type\", DirectoryFactory.LOCK_TYPE_HDFS);\n    System.setProperty(\"solr.hdfs.nrtcachingdirectory\", \"false\");\n    System.setProperty(\"solr.hdfs.blockcache.enabled\", \"false\");\n    System.setProperty(\"solr.autoCommit.maxTime\", \"600000\");\n    System.setProperty(\"solr.autoSoftCommit.maxTime\", \"-1\");\n    \n    CoreContainer container = new CoreContainer(loader);\n    container.load();\n    SolrCore core = container.create(\"\", ImmutableMap.of(CoreDescriptor.CORE_DATADIR, dataDirStr));\n    \n    if (!(core.getDirectoryFactory() instanceof HdfsDirectoryFactory)) {\n      throw new UnsupportedOperationException(\n          \"Invalid configuration. Currently, the only DirectoryFactory supported is \"\n              + HdfsDirectoryFactory.class.getSimpleName());\n    }\n\n    EmbeddedSolrServer solr = new EmbeddedSolrServer(container, \"\");\n    return solr;\n  }\n\n","sourceOld":"  public static EmbeddedSolrServer createEmbeddedSolrServer(Path solrHomeDir, FileSystem fs, Path outputShardDir)\n      throws IOException {\n\n    LOG.info(\"Creating embedded Solr server with solrHomeDir: \" + solrHomeDir + \", fs: \" + fs + \", outputShardDir: \" + outputShardDir);\n\n    Path solrDataDir = new Path(outputShardDir, \"data\");\n\n    String dataDirStr = solrDataDir.toUri().toString();\n\n    SolrResourceLoader loader = new SolrResourceLoader(Paths.get(solrHomeDir.toString()), null, null);\n\n    LOG.info(String\n        .format(Locale.ENGLISH, \n            \"Constructed instance information solr.home %s (%s), instance dir %s, conf dir %s, writing index to solr.data.dir %s, with permdir %s\",\n            solrHomeDir, solrHomeDir.toUri(), loader.getInstancePath(),\n            loader.getConfigDir(), dataDirStr, outputShardDir));\n\n    // TODO: This is fragile and should be well documented\n    System.setProperty(\"solr.directoryFactory\", HdfsDirectoryFactory.class.getName()); \n    System.setProperty(\"solr.lock.type\", DirectoryFactory.LOCK_TYPE_HDFS);\n    System.setProperty(\"solr.hdfs.nrtcachingdirectory\", \"false\");\n    System.setProperty(\"solr.hdfs.blockcache.enabled\", \"false\");\n    System.setProperty(\"solr.autoCommit.maxTime\", \"600000\");\n    System.setProperty(\"solr.autoSoftCommit.maxTime\", \"-1\");\n    \n    CoreContainer container = new CoreContainer(loader);\n    container.load();\n\n    SolrCore core = container.create(\"core1\", ImmutableMap.of(CoreDescriptor.CORE_DATADIR, dataDirStr));\n    \n    if (!(core.getDirectoryFactory() instanceof HdfsDirectoryFactory)) {\n      throw new UnsupportedOperationException(\n          \"Invalid configuration. Currently, the only DirectoryFactory supported is \"\n              + HdfsDirectoryFactory.class.getSimpleName());\n    }\n\n    EmbeddedSolrServer solr = new EmbeddedSolrServer(container, \"core1\");\n    return solr;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/SolrRecordWriter#createEmbeddedSolrServer(Path,FileSystem,Path).mjava","pathOld":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/SolrRecordWriter#createEmbeddedSolrServer(Path,FileSystem,Path).mjava","sourceNew":"  public static EmbeddedSolrServer createEmbeddedSolrServer(Path solrHomeDir, FileSystem fs, Path outputShardDir)\n      throws IOException {\n\n    LOG.info(\"Creating embedded Solr server with solrHomeDir: \" + solrHomeDir + \", fs: \" + fs + \", outputShardDir: \" + outputShardDir);\n\n    Path solrDataDir = new Path(outputShardDir, \"data\");\n\n    String dataDirStr = solrDataDir.toUri().toString();\n\n    SolrResourceLoader loader = new SolrResourceLoader(Paths.get(solrHomeDir.toString()), null, null);\n\n    LOG.info(String\n        .format(Locale.ENGLISH, \n            \"Constructed instance information solr.home %s (%s), instance dir %s, conf dir %s, writing index to solr.data.dir %s, with permdir %s\",\n            solrHomeDir, solrHomeDir.toUri(), loader.getInstancePath(),\n            loader.getConfigDir(), dataDirStr, outputShardDir));\n\n    // TODO: This is fragile and should be well documented\n    System.setProperty(\"solr.directoryFactory\", HdfsDirectoryFactory.class.getName()); \n    System.setProperty(\"solr.lock.type\", DirectoryFactory.LOCK_TYPE_HDFS);\n    System.setProperty(\"solr.hdfs.nrtcachingdirectory\", \"false\");\n    System.setProperty(\"solr.hdfs.blockcache.enabled\", \"false\");\n    System.setProperty(\"solr.autoCommit.maxTime\", \"600000\");\n    System.setProperty(\"solr.autoSoftCommit.maxTime\", \"-1\");\n    \n    CoreContainer container = new CoreContainer(loader);\n    container.load();\n    SolrCore core = container.create(\"\", ImmutableMap.of(CoreDescriptor.CORE_DATADIR, dataDirStr));\n    \n    if (!(core.getDirectoryFactory() instanceof HdfsDirectoryFactory)) {\n      throw new UnsupportedOperationException(\n          \"Invalid configuration. Currently, the only DirectoryFactory supported is \"\n              + HdfsDirectoryFactory.class.getSimpleName());\n    }\n\n    EmbeddedSolrServer solr = new EmbeddedSolrServer(container, \"\");\n    return solr;\n  }\n\n","sourceOld":"  public static EmbeddedSolrServer createEmbeddedSolrServer(Path solrHomeDir, FileSystem fs, Path outputShardDir)\n      throws IOException {\n\n    LOG.info(\"Creating embedded Solr server with solrHomeDir: \" + solrHomeDir + \", fs: \" + fs + \", outputShardDir: \" + outputShardDir);\n\n    Path solrDataDir = new Path(outputShardDir, \"data\");\n\n    String dataDirStr = solrDataDir.toUri().toString();\n\n    SolrResourceLoader loader = new SolrResourceLoader(Paths.get(solrHomeDir.toString()), null, null);\n\n    LOG.info(String\n        .format(Locale.ENGLISH, \n            \"Constructed instance information solr.home %s (%s), instance dir %s, conf dir %s, writing index to solr.data.dir %s, with permdir %s\",\n            solrHomeDir, solrHomeDir.toUri(), loader.getInstancePath(),\n            loader.getConfigDir(), dataDirStr, outputShardDir));\n\n    // TODO: This is fragile and should be well documented\n    System.setProperty(\"solr.directoryFactory\", HdfsDirectoryFactory.class.getName()); \n    System.setProperty(\"solr.lock.type\", DirectoryFactory.LOCK_TYPE_HDFS);\n    System.setProperty(\"solr.hdfs.nrtcachingdirectory\", \"false\");\n    System.setProperty(\"solr.hdfs.blockcache.enabled\", \"false\");\n    System.setProperty(\"solr.autoCommit.maxTime\", \"600000\");\n    System.setProperty(\"solr.autoSoftCommit.maxTime\", \"-1\");\n    \n    CoreContainer container = new CoreContainer(loader);\n    container.load();\n\n    SolrCore core = container.create(\"core1\", ImmutableMap.of(CoreDescriptor.CORE_DATADIR, dataDirStr));\n    \n    if (!(core.getDirectoryFactory() instanceof HdfsDirectoryFactory)) {\n      throw new UnsupportedOperationException(\n          \"Invalid configuration. Currently, the only DirectoryFactory supported is \"\n              + HdfsDirectoryFactory.class.getSimpleName());\n    }\n\n    EmbeddedSolrServer solr = new EmbeddedSolrServer(container, \"core1\");\n    return solr;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"12109b652e9210b8d58fca47f6c4a725d058a58e","date":1490373076,"type":4,"author":"Steve Rowe","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/SolrRecordWriter#createEmbeddedSolrServer(Path,FileSystem,Path).mjava","sourceNew":null,"sourceOld":"  public static EmbeddedSolrServer createEmbeddedSolrServer(Path solrHomeDir, FileSystem fs, Path outputShardDir)\n      throws IOException {\n\n    LOG.info(\"Creating embedded Solr server with solrHomeDir: \" + solrHomeDir + \", fs: \" + fs + \", outputShardDir: \" + outputShardDir);\n\n    Path solrDataDir = new Path(outputShardDir, \"data\");\n\n    String dataDirStr = solrDataDir.toUri().toString();\n\n    SolrResourceLoader loader = new SolrResourceLoader(Paths.get(solrHomeDir.toString()), null, null);\n\n    LOG.info(String\n        .format(Locale.ENGLISH, \n            \"Constructed instance information solr.home %s (%s), instance dir %s, conf dir %s, writing index to solr.data.dir %s, with permdir %s\",\n            solrHomeDir, solrHomeDir.toUri(), loader.getInstancePath(),\n            loader.getConfigDir(), dataDirStr, outputShardDir));\n\n    // TODO: This is fragile and should be well documented\n    System.setProperty(\"solr.directoryFactory\", HdfsDirectoryFactory.class.getName()); \n    System.setProperty(\"solr.lock.type\", DirectoryFactory.LOCK_TYPE_HDFS);\n    System.setProperty(\"solr.hdfs.nrtcachingdirectory\", \"false\");\n    System.setProperty(\"solr.hdfs.blockcache.enabled\", \"false\");\n    System.setProperty(\"solr.autoCommit.maxTime\", \"600000\");\n    System.setProperty(\"solr.autoSoftCommit.maxTime\", \"-1\");\n    \n    CoreContainer container = new CoreContainer(loader);\n    container.load();\n    SolrCore core = container.create(\"\", ImmutableMap.of(CoreDescriptor.CORE_DATADIR, dataDirStr));\n    \n    if (!(core.getDirectoryFactory() instanceof HdfsDirectoryFactory)) {\n      throw new UnsupportedOperationException(\n          \"Invalid configuration. Currently, the only DirectoryFactory supported is \"\n              + HdfsDirectoryFactory.class.getSimpleName());\n    }\n\n    EmbeddedSolrServer solr = new EmbeddedSolrServer(container, \"\");\n    return solr;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fe1c4aa9af769a38e878f608070f672efbeac27f","date":1490594650,"type":4,"author":"Steve Rowe","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/SolrRecordWriter#createEmbeddedSolrServer(Path,FileSystem,Path).mjava","sourceNew":null,"sourceOld":"  public static EmbeddedSolrServer createEmbeddedSolrServer(Path solrHomeDir, FileSystem fs, Path outputShardDir)\n      throws IOException {\n\n    LOG.info(\"Creating embedded Solr server with solrHomeDir: \" + solrHomeDir + \", fs: \" + fs + \", outputShardDir: \" + outputShardDir);\n\n    Path solrDataDir = new Path(outputShardDir, \"data\");\n\n    String dataDirStr = solrDataDir.toUri().toString();\n\n    SolrResourceLoader loader = new SolrResourceLoader(Paths.get(solrHomeDir.toString()), null, null);\n\n    LOG.info(String\n        .format(Locale.ENGLISH, \n            \"Constructed instance information solr.home %s (%s), instance dir %s, conf dir %s, writing index to solr.data.dir %s, with permdir %s\",\n            solrHomeDir, solrHomeDir.toUri(), loader.getInstancePath(),\n            loader.getConfigDir(), dataDirStr, outputShardDir));\n\n    // TODO: This is fragile and should be well documented\n    System.setProperty(\"solr.directoryFactory\", HdfsDirectoryFactory.class.getName()); \n    System.setProperty(\"solr.lock.type\", DirectoryFactory.LOCK_TYPE_HDFS);\n    System.setProperty(\"solr.hdfs.nrtcachingdirectory\", \"false\");\n    System.setProperty(\"solr.hdfs.blockcache.enabled\", \"false\");\n    System.setProperty(\"solr.autoCommit.maxTime\", \"600000\");\n    System.setProperty(\"solr.autoSoftCommit.maxTime\", \"-1\");\n    \n    CoreContainer container = new CoreContainer(loader);\n    container.load();\n    SolrCore core = container.create(\"\", ImmutableMap.of(CoreDescriptor.CORE_DATADIR, dataDirStr));\n    \n    if (!(core.getDirectoryFactory() instanceof HdfsDirectoryFactory)) {\n      throw new UnsupportedOperationException(\n          \"Invalid configuration. Currently, the only DirectoryFactory supported is \"\n              + HdfsDirectoryFactory.class.getSimpleName());\n    }\n\n    EmbeddedSolrServer solr = new EmbeddedSolrServer(container, \"\");\n    return solr;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"12109b652e9210b8d58fca47f6c4a725d058a58e":["61c6fb105d0ce095d846502a1d7a2a4bbf8fdecd"],"efa0ddc8716305bc4a06f27f9ae99fe5e23fc87d":["85032ab568b3f50eabd577aaa994ba197db93758"],"61c6fb105d0ce095d846502a1d7a2a4bbf8fdecd":["e50357e583524185222c1c691f5c333b34f7cbb2"],"fe1c4aa9af769a38e878f608070f672efbeac27f":["61c6fb105d0ce095d846502a1d7a2a4bbf8fdecd"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["e50357e583524185222c1c691f5c333b34f7cbb2","61c6fb105d0ce095d846502a1d7a2a4bbf8fdecd"],"9b0d372d32bc2f431c90e9d5bd34cd074a70479e":["70f91c8322fbffe3a3a897ef20ea19119cac10cd"],"70f91c8322fbffe3a3a897ef20ea19119cac10cd":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"11d8a050b7d5f98040f790d32ec1cfd2fc3490e3":["a626ec4d1c92e59fe390724d6220081047b03ce7"],"a626ec4d1c92e59fe390724d6220081047b03ce7":["efa0ddc8716305bc4a06f27f9ae99fe5e23fc87d"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"e50357e583524185222c1c691f5c333b34f7cbb2":["11d8a050b7d5f98040f790d32ec1cfd2fc3490e3"],"74f45af4339b0daf7a95c820ab88c1aea74fbce0":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","9b0d372d32bc2f431c90e9d5bd34cd074a70479e"],"c74a1d30fa4439a3687ae194fa516accc89d4f35":["1c531908b0df71ea5e90eb461360834ef05dd417"],"85032ab568b3f50eabd577aaa994ba197db93758":["c74a1d30fa4439a3687ae194fa516accc89d4f35"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["12109b652e9210b8d58fca47f6c4a725d058a58e"],"1c531908b0df71ea5e90eb461360834ef05dd417":["9b0d372d32bc2f431c90e9d5bd34cd074a70479e"]},"commit2Childs":{"12109b652e9210b8d58fca47f6c4a725d058a58e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"efa0ddc8716305bc4a06f27f9ae99fe5e23fc87d":["a626ec4d1c92e59fe390724d6220081047b03ce7"],"61c6fb105d0ce095d846502a1d7a2a4bbf8fdecd":["12109b652e9210b8d58fca47f6c4a725d058a58e","fe1c4aa9af769a38e878f608070f672efbeac27f","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"fe1c4aa9af769a38e878f608070f672efbeac27f":[],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"9b0d372d32bc2f431c90e9d5bd34cd074a70479e":["74f45af4339b0daf7a95c820ab88c1aea74fbce0","1c531908b0df71ea5e90eb461360834ef05dd417"],"70f91c8322fbffe3a3a897ef20ea19119cac10cd":["9b0d372d32bc2f431c90e9d5bd34cd074a70479e"],"11d8a050b7d5f98040f790d32ec1cfd2fc3490e3":["e50357e583524185222c1c691f5c333b34f7cbb2"],"a626ec4d1c92e59fe390724d6220081047b03ce7":["11d8a050b7d5f98040f790d32ec1cfd2fc3490e3"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["70f91c8322fbffe3a3a897ef20ea19119cac10cd","74f45af4339b0daf7a95c820ab88c1aea74fbce0"],"e50357e583524185222c1c691f5c333b34f7cbb2":["61c6fb105d0ce095d846502a1d7a2a4bbf8fdecd","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"74f45af4339b0daf7a95c820ab88c1aea74fbce0":[],"c74a1d30fa4439a3687ae194fa516accc89d4f35":["85032ab568b3f50eabd577aaa994ba197db93758"],"85032ab568b3f50eabd577aaa994ba197db93758":["efa0ddc8716305bc4a06f27f9ae99fe5e23fc87d"],"1c531908b0df71ea5e90eb461360834ef05dd417":["c74a1d30fa4439a3687ae194fa516accc89d4f35"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["fe1c4aa9af769a38e878f608070f672efbeac27f","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","74f45af4339b0daf7a95c820ab88c1aea74fbce0","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}