{"path":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/BatchWriter#close(TaskAttemptContext).mjava","commits":[{"id":"70f91c8322fbffe3a3a897ef20ea19119cac10cd","date":1386170124,"type":1,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/BatchWriter#close(TaskAttemptContext).mjava","pathOld":"solr/contrib/solr-mr/src/java/org/apache/solr/hadoop/BatchWriter#close(TaskAttemptContext).mjava","sourceNew":"  public synchronized void close(TaskAttemptContext context)\n      throws InterruptedException, SolrServerException, IOException {\n\n    if (batchPool != null) {\n      context.setStatus(\"Waiting for batches to complete\");\n      batchPool.shutdown();\n  \n      while (!batchPool.isTerminated()) {\n        LOG.info(String.format(Locale.ENGLISH, \n            \"Waiting for %d items and %d threads to finish executing\", batchPool\n                .getQueue().size(), batchPool.getActiveCount()));\n        batchPool.awaitTermination(5, TimeUnit.SECONDS);\n      }\n    }\n    //reporter.setStatus(\"Committing Solr\");\n    //solr.commit(true, false);\n    context.setStatus(\"Optimizing Solr\");\n    int maxSegments = context.getConfiguration().getInt(SolrOutputFormat.SOLR_RECORD_WRITER_MAX_SEGMENTS, 1);\n    LOG.info(\"Optimizing Solr: forcing merge down to {} segments\", maxSegments);\n    long start = System.currentTimeMillis();\n    solr.optimize(true, false, maxSegments);\n    context.getCounter(SolrCounters.class.getName(), SolrCounters.PHYSICAL_REDUCER_MERGE_TIME.toString()).increment(System.currentTimeMillis() - start);\n    float secs = (System.currentTimeMillis() - start) / 1000.0f;\n    LOG.info(\"Optimizing Solr: done forcing merge down to {} segments in {} secs\", maxSegments, secs);\n    context.setStatus(\"Shutting down Solr\");\n    // TODO is core close needed? - according to TestEmbeddedSolrServer it's not...\n    //core.close();\n    solr.shutdown();\n  }\n\n","sourceOld":"  public synchronized void close(TaskAttemptContext context)\n      throws InterruptedException, SolrServerException, IOException {\n\n    if (batchPool != null) {\n      context.setStatus(\"Waiting for batches to complete\");\n      batchPool.shutdown();\n  \n      while (!batchPool.isTerminated()) {\n        LOG.info(String.format(Locale.ENGLISH, \n            \"Waiting for %d items and %d threads to finish executing\", batchPool\n                .getQueue().size(), batchPool.getActiveCount()));\n        batchPool.awaitTermination(5, TimeUnit.SECONDS);\n      }\n    }\n    //reporter.setStatus(\"Committing Solr\");\n    //solr.commit(true, false);\n    context.setStatus(\"Optimizing Solr\");\n    int maxSegments = context.getConfiguration().getInt(SolrOutputFormat.SOLR_RECORD_WRITER_MAX_SEGMENTS, 1);\n    LOG.info(\"Optimizing Solr: forcing merge down to {} segments\", maxSegments);\n    long start = System.currentTimeMillis();\n    solr.optimize(true, false, maxSegments);\n    context.getCounter(SolrCounters.class.getName(), SolrCounters.PHYSICAL_REDUCER_MERGE_TIME.toString()).increment(System.currentTimeMillis() - start);\n    float secs = (System.currentTimeMillis() - start) / 1000.0f;\n    LOG.info(\"Optimizing Solr: done forcing merge down to {} segments in {} secs\", maxSegments, secs);\n    context.setStatus(\"Shutting down Solr\");\n    // TODO is core close needed? - according to TestEmbeddedSolrServer it's not...\n    //core.close();\n    solr.shutdown();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"42d384b06aa87eae925b668b65f3246154f0b0fa","date":1386181725,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/BatchWriter#close(TaskAttemptContext).mjava","pathOld":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/BatchWriter#close(TaskAttemptContext).mjava","sourceNew":"  public synchronized void close(TaskAttemptContext context)\n      throws InterruptedException, SolrServerException, IOException {\n\n    if (batchPool != null) {\n      context.setStatus(\"Waiting for batches to complete\");\n      batchPool.shutdown();\n  \n      while (!batchPool.isTerminated()) {\n        LOG.info(String.format(Locale.ENGLISH, \n            \"Waiting for %d items and %d threads to finish executing\", batchPool\n                .getQueue().size(), batchPool.getActiveCount()));\n        batchPool.awaitTermination(5, TimeUnit.SECONDS);\n      }\n    }\n    context.setStatus(\"Committing Solr Phase 1\");\n    solr.commit(true, false);\n    context.setStatus(\"Optimizing Solr\");\n    int maxSegments = context.getConfiguration().getInt(SolrOutputFormat.SOLR_RECORD_WRITER_MAX_SEGMENTS, 1);\n    LOG.info(\"Optimizing Solr: forcing merge down to {} segments\", maxSegments);\n    long start = System.currentTimeMillis();\n    solr.optimize(true, false, maxSegments);\n    context.getCounter(SolrCounters.class.getName(), SolrCounters.PHYSICAL_REDUCER_MERGE_TIME.toString()).increment(System.currentTimeMillis() - start);\n    float secs = (System.currentTimeMillis() - start) / 1000.0f;\n    LOG.info(\"Optimizing Solr: done forcing merge down to {} segments in {} secs\", maxSegments, secs);\n    context.setStatus(\"Committing Solr Phase 2\");\n    solr.commit(true, false);\n    context.setStatus(\"Shutting down Solr\");\n    solr.shutdown();\n  }\n\n","sourceOld":"  public synchronized void close(TaskAttemptContext context)\n      throws InterruptedException, SolrServerException, IOException {\n\n    if (batchPool != null) {\n      context.setStatus(\"Waiting for batches to complete\");\n      batchPool.shutdown();\n  \n      while (!batchPool.isTerminated()) {\n        LOG.info(String.format(Locale.ENGLISH, \n            \"Waiting for %d items and %d threads to finish executing\", batchPool\n                .getQueue().size(), batchPool.getActiveCount()));\n        batchPool.awaitTermination(5, TimeUnit.SECONDS);\n      }\n    }\n    //reporter.setStatus(\"Committing Solr\");\n    //solr.commit(true, false);\n    context.setStatus(\"Optimizing Solr\");\n    int maxSegments = context.getConfiguration().getInt(SolrOutputFormat.SOLR_RECORD_WRITER_MAX_SEGMENTS, 1);\n    LOG.info(\"Optimizing Solr: forcing merge down to {} segments\", maxSegments);\n    long start = System.currentTimeMillis();\n    solr.optimize(true, false, maxSegments);\n    context.getCounter(SolrCounters.class.getName(), SolrCounters.PHYSICAL_REDUCER_MERGE_TIME.toString()).increment(System.currentTimeMillis() - start);\n    float secs = (System.currentTimeMillis() - start) / 1000.0f;\n    LOG.info(\"Optimizing Solr: done forcing merge down to {} segments in {} secs\", maxSegments, secs);\n    context.setStatus(\"Shutting down Solr\");\n    // TODO is core close needed? - according to TestEmbeddedSolrServer it's not...\n    //core.close();\n    solr.shutdown();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"74f45af4339b0daf7a95c820ab88c1aea74fbce0","date":1387475327,"type":0,"author":"Michael McCandless","isMerge":true,"pathNew":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/BatchWriter#close(TaskAttemptContext).mjava","pathOld":"/dev/null","sourceNew":"  public synchronized void close(TaskAttemptContext context)\n      throws InterruptedException, SolrServerException, IOException {\n\n    if (batchPool != null) {\n      context.setStatus(\"Waiting for batches to complete\");\n      batchPool.shutdown();\n  \n      while (!batchPool.isTerminated()) {\n        LOG.info(String.format(Locale.ENGLISH, \n            \"Waiting for %d items and %d threads to finish executing\", batchPool\n                .getQueue().size(), batchPool.getActiveCount()));\n        batchPool.awaitTermination(5, TimeUnit.SECONDS);\n      }\n    }\n    context.setStatus(\"Committing Solr Phase 1\");\n    solr.commit(true, false);\n    context.setStatus(\"Optimizing Solr\");\n    int maxSegments = context.getConfiguration().getInt(SolrOutputFormat.SOLR_RECORD_WRITER_MAX_SEGMENTS, 1);\n    LOG.info(\"Optimizing Solr: forcing merge down to {} segments\", maxSegments);\n    long start = System.currentTimeMillis();\n    solr.optimize(true, false, maxSegments);\n    context.getCounter(SolrCounters.class.getName(), SolrCounters.PHYSICAL_REDUCER_MERGE_TIME.toString()).increment(System.currentTimeMillis() - start);\n    float secs = (System.currentTimeMillis() - start) / 1000.0f;\n    LOG.info(\"Optimizing Solr: done forcing merge down to {} segments in {} secs\", maxSegments, secs);\n    context.setStatus(\"Committing Solr Phase 2\");\n    solr.commit(true, false);\n    context.setStatus(\"Shutting down Solr\");\n    solr.shutdown();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fd5bc858b8426d40bbe90b94120ead37c77d7954","date":1393812525,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/BatchWriter#close(TaskAttemptContext).mjava","pathOld":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/BatchWriter#close(TaskAttemptContext).mjava","sourceNew":"  public synchronized void close(TaskAttemptContext context)\n      throws InterruptedException, SolrServerException, IOException {\n\n    if (batchPool != null) {\n      context.setStatus(\"Waiting for batches to complete\");\n      batchPool.shutdown();\n  \n      while (!batchPool.isTerminated()) {\n        LOG.info(String.format(Locale.ENGLISH, \n            \"Waiting for %d items and %d threads to finish executing\", batchPool\n                .getQueue().size(), batchPool.getActiveCount()));\n        batchPool.awaitTermination(5, TimeUnit.SECONDS);\n      }\n    }\n    context.setStatus(\"Committing Solr Phase 1\");\n    solr.commit(true, false);\n    context.setStatus(\"Optimizing Solr\");\n    int maxSegments = context.getConfiguration().getInt(SolrOutputFormat.SOLR_RECORD_WRITER_MAX_SEGMENTS, 1);\n    LOG.info(\"Optimizing Solr: forcing merge down to {} segments\", maxSegments);\n    long start = System.nanoTime();\n    solr.optimize(true, false, maxSegments);\n    context.getCounter(SolrCounters.class.getName(), SolrCounters.PHYSICAL_REDUCER_MERGE_TIME.toString()).increment(System.nanoTime() - start);\n    float secs = (System.nanoTime() - start) / (float)(10^9);\n    LOG.info(\"Optimizing Solr: done forcing merge down to {} segments in {} secs\", maxSegments, secs);\n    context.setStatus(\"Committing Solr Phase 2\");\n    solr.commit(true, false);\n    context.setStatus(\"Shutting down Solr\");\n    solr.shutdown();\n  }\n\n","sourceOld":"  public synchronized void close(TaskAttemptContext context)\n      throws InterruptedException, SolrServerException, IOException {\n\n    if (batchPool != null) {\n      context.setStatus(\"Waiting for batches to complete\");\n      batchPool.shutdown();\n  \n      while (!batchPool.isTerminated()) {\n        LOG.info(String.format(Locale.ENGLISH, \n            \"Waiting for %d items and %d threads to finish executing\", batchPool\n                .getQueue().size(), batchPool.getActiveCount()));\n        batchPool.awaitTermination(5, TimeUnit.SECONDS);\n      }\n    }\n    context.setStatus(\"Committing Solr Phase 1\");\n    solr.commit(true, false);\n    context.setStatus(\"Optimizing Solr\");\n    int maxSegments = context.getConfiguration().getInt(SolrOutputFormat.SOLR_RECORD_WRITER_MAX_SEGMENTS, 1);\n    LOG.info(\"Optimizing Solr: forcing merge down to {} segments\", maxSegments);\n    long start = System.currentTimeMillis();\n    solr.optimize(true, false, maxSegments);\n    context.getCounter(SolrCounters.class.getName(), SolrCounters.PHYSICAL_REDUCER_MERGE_TIME.toString()).increment(System.currentTimeMillis() - start);\n    float secs = (System.currentTimeMillis() - start) / 1000.0f;\n    LOG.info(\"Optimizing Solr: done forcing merge down to {} segments in {} secs\", maxSegments, secs);\n    context.setStatus(\"Committing Solr Phase 2\");\n    solr.commit(true, false);\n    context.setStatus(\"Shutting down Solr\");\n    solr.shutdown();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cc3b13b430571c2e169f98fe38e1e7666f88522d","date":1422446157,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/BatchWriter#close(TaskAttemptContext).mjava","pathOld":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/BatchWriter#close(TaskAttemptContext).mjava","sourceNew":"  public synchronized void close(TaskAttemptContext context)\n      throws InterruptedException, SolrServerException, IOException {\n\n    if (batchPool != null) {\n      context.setStatus(\"Waiting for batches to complete\");\n      batchPool.shutdown();\n  \n      while (!batchPool.isTerminated()) {\n        LOG.info(String.format(Locale.ENGLISH, \n            \"Waiting for %d items and %d threads to finish executing\", batchPool\n                .getQueue().size(), batchPool.getActiveCount()));\n        batchPool.awaitTermination(5, TimeUnit.SECONDS);\n      }\n    }\n    context.setStatus(\"Committing Solr Phase 1\");\n    solr.commit(true, false);\n    context.setStatus(\"Optimizing Solr\");\n    int maxSegments = context.getConfiguration().getInt(SolrOutputFormat.SOLR_RECORD_WRITER_MAX_SEGMENTS, 1);\n    LOG.info(\"Optimizing Solr: forcing merge down to {} segments\", maxSegments);\n    long start = System.nanoTime();\n    solr.optimize(true, false, maxSegments);\n    context.getCounter(SolrCounters.class.getName(), SolrCounters.PHYSICAL_REDUCER_MERGE_TIME.toString()).increment(System.nanoTime() - start);\n    float secs = (System.nanoTime() - start) / (float)(10^9);\n    LOG.info(\"Optimizing Solr: done forcing merge down to {} segments in {} secs\", maxSegments, secs);\n    context.setStatus(\"Committing Solr Phase 2\");\n    solr.commit(true, false);\n    context.setStatus(\"Shutting down Solr\");\n    solr.close();\n  }\n\n","sourceOld":"  public synchronized void close(TaskAttemptContext context)\n      throws InterruptedException, SolrServerException, IOException {\n\n    if (batchPool != null) {\n      context.setStatus(\"Waiting for batches to complete\");\n      batchPool.shutdown();\n  \n      while (!batchPool.isTerminated()) {\n        LOG.info(String.format(Locale.ENGLISH, \n            \"Waiting for %d items and %d threads to finish executing\", batchPool\n                .getQueue().size(), batchPool.getActiveCount()));\n        batchPool.awaitTermination(5, TimeUnit.SECONDS);\n      }\n    }\n    context.setStatus(\"Committing Solr Phase 1\");\n    solr.commit(true, false);\n    context.setStatus(\"Optimizing Solr\");\n    int maxSegments = context.getConfiguration().getInt(SolrOutputFormat.SOLR_RECORD_WRITER_MAX_SEGMENTS, 1);\n    LOG.info(\"Optimizing Solr: forcing merge down to {} segments\", maxSegments);\n    long start = System.nanoTime();\n    solr.optimize(true, false, maxSegments);\n    context.getCounter(SolrCounters.class.getName(), SolrCounters.PHYSICAL_REDUCER_MERGE_TIME.toString()).increment(System.nanoTime() - start);\n    float secs = (System.nanoTime() - start) / (float)(10^9);\n    LOG.info(\"Optimizing Solr: done forcing merge down to {} segments in {} secs\", maxSegments, secs);\n    context.setStatus(\"Committing Solr Phase 2\");\n    solr.commit(true, false);\n    context.setStatus(\"Shutting down Solr\");\n    solr.shutdown();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"12109b652e9210b8d58fca47f6c4a725d058a58e","date":1490373076,"type":4,"author":"Steve Rowe","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/BatchWriter#close(TaskAttemptContext).mjava","sourceNew":null,"sourceOld":"  public synchronized void close(TaskAttemptContext context)\n      throws InterruptedException, SolrServerException, IOException {\n\n    if (batchPool != null) {\n      context.setStatus(\"Waiting for batches to complete\");\n      batchPool.shutdown();\n  \n      while (!batchPool.isTerminated()) {\n        LOG.info(String.format(Locale.ENGLISH, \n            \"Waiting for %d items and %d threads to finish executing\", batchPool\n                .getQueue().size(), batchPool.getActiveCount()));\n        batchPool.awaitTermination(5, TimeUnit.SECONDS);\n      }\n    }\n    context.setStatus(\"Committing Solr Phase 1\");\n    solr.commit(true, false);\n    context.setStatus(\"Optimizing Solr\");\n    int maxSegments = context.getConfiguration().getInt(SolrOutputFormat.SOLR_RECORD_WRITER_MAX_SEGMENTS, 1);\n    LOG.info(\"Optimizing Solr: forcing merge down to {} segments\", maxSegments);\n    long start = System.nanoTime();\n    solr.optimize(true, false, maxSegments);\n    context.getCounter(SolrCounters.class.getName(), SolrCounters.PHYSICAL_REDUCER_MERGE_TIME.toString()).increment(System.nanoTime() - start);\n    float secs = (System.nanoTime() - start) / (float)(10^9);\n    LOG.info(\"Optimizing Solr: done forcing merge down to {} segments in {} secs\", maxSegments, secs);\n    context.setStatus(\"Committing Solr Phase 2\");\n    solr.commit(true, false);\n    context.setStatus(\"Shutting down Solr\");\n    solr.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fe1c4aa9af769a38e878f608070f672efbeac27f","date":1490594650,"type":4,"author":"Steve Rowe","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/BatchWriter#close(TaskAttemptContext).mjava","sourceNew":null,"sourceOld":"  public synchronized void close(TaskAttemptContext context)\n      throws InterruptedException, SolrServerException, IOException {\n\n    if (batchPool != null) {\n      context.setStatus(\"Waiting for batches to complete\");\n      batchPool.shutdown();\n  \n      while (!batchPool.isTerminated()) {\n        LOG.info(String.format(Locale.ENGLISH, \n            \"Waiting for %d items and %d threads to finish executing\", batchPool\n                .getQueue().size(), batchPool.getActiveCount()));\n        batchPool.awaitTermination(5, TimeUnit.SECONDS);\n      }\n    }\n    context.setStatus(\"Committing Solr Phase 1\");\n    solr.commit(true, false);\n    context.setStatus(\"Optimizing Solr\");\n    int maxSegments = context.getConfiguration().getInt(SolrOutputFormat.SOLR_RECORD_WRITER_MAX_SEGMENTS, 1);\n    LOG.info(\"Optimizing Solr: forcing merge down to {} segments\", maxSegments);\n    long start = System.nanoTime();\n    solr.optimize(true, false, maxSegments);\n    context.getCounter(SolrCounters.class.getName(), SolrCounters.PHYSICAL_REDUCER_MERGE_TIME.toString()).increment(System.nanoTime() - start);\n    float secs = (System.nanoTime() - start) / (float)(10^9);\n    LOG.info(\"Optimizing Solr: done forcing merge down to {} segments in {} secs\", maxSegments, secs);\n    context.setStatus(\"Committing Solr Phase 2\");\n    solr.commit(true, false);\n    context.setStatus(\"Shutting down Solr\");\n    solr.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"70f91c8322fbffe3a3a897ef20ea19119cac10cd":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"12109b652e9210b8d58fca47f6c4a725d058a58e":["cc3b13b430571c2e169f98fe38e1e7666f88522d"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"74f45af4339b0daf7a95c820ab88c1aea74fbce0":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","42d384b06aa87eae925b668b65f3246154f0b0fa"],"cc3b13b430571c2e169f98fe38e1e7666f88522d":["fd5bc858b8426d40bbe90b94120ead37c77d7954"],"fe1c4aa9af769a38e878f608070f672efbeac27f":["cc3b13b430571c2e169f98fe38e1e7666f88522d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["12109b652e9210b8d58fca47f6c4a725d058a58e"],"fd5bc858b8426d40bbe90b94120ead37c77d7954":["42d384b06aa87eae925b668b65f3246154f0b0fa"],"42d384b06aa87eae925b668b65f3246154f0b0fa":["70f91c8322fbffe3a3a897ef20ea19119cac10cd"]},"commit2Childs":{"70f91c8322fbffe3a3a897ef20ea19119cac10cd":["42d384b06aa87eae925b668b65f3246154f0b0fa"],"12109b652e9210b8d58fca47f6c4a725d058a58e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["70f91c8322fbffe3a3a897ef20ea19119cac10cd","74f45af4339b0daf7a95c820ab88c1aea74fbce0"],"74f45af4339b0daf7a95c820ab88c1aea74fbce0":[],"cc3b13b430571c2e169f98fe38e1e7666f88522d":["12109b652e9210b8d58fca47f6c4a725d058a58e","fe1c4aa9af769a38e878f608070f672efbeac27f"],"fe1c4aa9af769a38e878f608070f672efbeac27f":[],"42d384b06aa87eae925b668b65f3246154f0b0fa":["74f45af4339b0daf7a95c820ab88c1aea74fbce0","fd5bc858b8426d40bbe90b94120ead37c77d7954"],"fd5bc858b8426d40bbe90b94120ead37c77d7954":["cc3b13b430571c2e169f98fe38e1e7666f88522d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["74f45af4339b0daf7a95c820ab88c1aea74fbce0","fe1c4aa9af769a38e878f608070f672efbeac27f","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}