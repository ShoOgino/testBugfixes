{"path":"lucene/src/java/org/apache/lucene/index/DocumentsWriter#balanceRAM().mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/DocumentsWriter#balanceRAM().mjava","pathOld":"src/java/org/apache/lucene/index/DocumentsWriter#balanceRAM().mjava","sourceNew":"  /* We have four pools of RAM: Postings, byte blocks\n   * (holds freq/prox posting data), char blocks (holds\n   * characters in the term) and per-doc buffers (stored fields/term vectors).  \n   * Different docs require varying amount of storage from \n   * these four classes.\n   * \n   * For example, docs with many unique single-occurrence\n   * short terms will use up the Postings RAM and hardly any\n   * of the other two.  Whereas docs with very large terms\n   * will use alot of char blocks RAM and relatively less of\n   * the other two.  This method just frees allocations from\n   * the pools once we are over-budget, which balances the\n   * pools to match the current docs. */\n  void balanceRAM() {\n\n    // We flush when we've used our target usage\n    final long flushTrigger = ramBufferSize;\n\n    final long deletesRAMUsed = deletesInRAM.bytesUsed+deletesFlushed.bytesUsed;\n\n    if (numBytesAlloc+deletesRAMUsed > freeTrigger) {\n\n      if (infoStream != null)\n        message(\"  RAM: now balance allocations: usedMB=\" + toMB(numBytesUsed) +\n                \" vs trigger=\" + toMB(flushTrigger) +\n                \" allocMB=\" + toMB(numBytesAlloc) +\n                \" deletesMB=\" + toMB(deletesRAMUsed) +\n                \" vs trigger=\" + toMB(freeTrigger) +\n                \" byteBlockFree=\" + toMB(byteBlockAllocator.freeByteBlocks.size()*BYTE_BLOCK_SIZE) +\n                \" perDocFree=\" + toMB(perDocAllocator.freeByteBlocks.size()*PER_DOC_BLOCK_SIZE) +\n                \" charBlockFree=\" + toMB(freeCharBlocks.size()*CHAR_BLOCK_SIZE*CHAR_NUM_BYTE));\n\n      final long startBytesAlloc = numBytesAlloc + deletesRAMUsed;\n\n      int iter = 0;\n\n      // We free equally from each pool in 32 KB\n      // chunks until we are below our threshold\n      // (freeLevel)\n\n      boolean any = true;\n\n      while(numBytesAlloc+deletesRAMUsed > freeLevel) {\n      \n        synchronized(this) {\n          if (0 == perDocAllocator.freeByteBlocks.size() \n              && 0 == byteBlockAllocator.freeByteBlocks.size() \n              && 0 == freeCharBlocks.size() \n              && 0 == freeIntBlocks.size() \n              && !any) {\n            // Nothing else to free -- must flush now.\n            bufferIsFull = numBytesUsed+deletesRAMUsed > flushTrigger;\n            if (infoStream != null) {\n              if (numBytesUsed > flushTrigger)\n                message(\"    nothing to free; now set bufferIsFull\");\n              else\n                message(\"    nothing to free\");\n            }\n            assert numBytesUsed <= numBytesAlloc;\n            break;\n          }\n\n          if ((0 == iter % 5) && byteBlockAllocator.freeByteBlocks.size() > 0) {\n            byteBlockAllocator.freeByteBlocks.remove(byteBlockAllocator.freeByteBlocks.size()-1);\n            numBytesAlloc -= BYTE_BLOCK_SIZE;\n          }\n\n          if ((1 == iter % 5) && freeCharBlocks.size() > 0) {\n            freeCharBlocks.remove(freeCharBlocks.size()-1);\n            numBytesAlloc -= CHAR_BLOCK_SIZE * CHAR_NUM_BYTE;\n          }\n\n          if ((2 == iter % 5) && freeIntBlocks.size() > 0) {\n            freeIntBlocks.remove(freeIntBlocks.size()-1);\n            numBytesAlloc -= INT_BLOCK_SIZE * INT_NUM_BYTE;\n          }\n\n          if ((3 == iter % 5) && perDocAllocator.freeByteBlocks.size() > 0) {\n            // Remove upwards of 32 blocks (each block is 1K)\n            for (int i = 0; i < 32; ++i) {\n              perDocAllocator.freeByteBlocks.remove(perDocAllocator.freeByteBlocks.size() - 1);\n              numBytesAlloc -= PER_DOC_BLOCK_SIZE;\n              if (perDocAllocator.freeByteBlocks.size() == 0) {\n                break;\n              }\n            }\n          }\n        }\n\n        if ((4 == iter % 5) && any)\n          // Ask consumer to free any recycled state\n          any = consumer.freeRAM();\n\n        iter++;\n      }\n\n      if (infoStream != null)\n        message(\"    after free: freedMB=\" + nf.format((startBytesAlloc-numBytesAlloc-deletesRAMUsed)/1024./1024.) + \" usedMB=\" + nf.format((numBytesUsed+deletesRAMUsed)/1024./1024.) + \" allocMB=\" + nf.format(numBytesAlloc/1024./1024.));\n      \n    } else {\n      // If we have not crossed the 100% mark, but have\n      // crossed the 95% mark of RAM we are actually\n      // using, go ahead and flush.  This prevents\n      // over-allocating and then freeing, with every\n      // flush.\n      synchronized(this) {\n\n        if (numBytesUsed+deletesRAMUsed > flushTrigger) {\n          if (infoStream != null)\n            message(\"  RAM: now flush @ usedMB=\" + nf.format(numBytesUsed/1024./1024.) +\n                    \" allocMB=\" + nf.format(numBytesAlloc/1024./1024.) +\n                    \" deletesMB=\" + nf.format(deletesRAMUsed/1024./1024.) +\n                    \" triggerMB=\" + nf.format(flushTrigger/1024./1024.));\n\n          bufferIsFull = true;\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /* We have four pools of RAM: Postings, byte blocks\n   * (holds freq/prox posting data), char blocks (holds\n   * characters in the term) and per-doc buffers (stored fields/term vectors).  \n   * Different docs require varying amount of storage from \n   * these four classes.\n   * \n   * For example, docs with many unique single-occurrence\n   * short terms will use up the Postings RAM and hardly any\n   * of the other two.  Whereas docs with very large terms\n   * will use alot of char blocks RAM and relatively less of\n   * the other two.  This method just frees allocations from\n   * the pools once we are over-budget, which balances the\n   * pools to match the current docs. */\n  void balanceRAM() {\n\n    // We flush when we've used our target usage\n    final long flushTrigger = ramBufferSize;\n\n    final long deletesRAMUsed = deletesInRAM.bytesUsed+deletesFlushed.bytesUsed;\n\n    if (numBytesAlloc+deletesRAMUsed > freeTrigger) {\n\n      if (infoStream != null)\n        message(\"  RAM: now balance allocations: usedMB=\" + toMB(numBytesUsed) +\n                \" vs trigger=\" + toMB(flushTrigger) +\n                \" allocMB=\" + toMB(numBytesAlloc) +\n                \" deletesMB=\" + toMB(deletesRAMUsed) +\n                \" vs trigger=\" + toMB(freeTrigger) +\n                \" byteBlockFree=\" + toMB(byteBlockAllocator.freeByteBlocks.size()*BYTE_BLOCK_SIZE) +\n                \" perDocFree=\" + toMB(perDocAllocator.freeByteBlocks.size()*PER_DOC_BLOCK_SIZE) +\n                \" charBlockFree=\" + toMB(freeCharBlocks.size()*CHAR_BLOCK_SIZE*CHAR_NUM_BYTE));\n\n      final long startBytesAlloc = numBytesAlloc + deletesRAMUsed;\n\n      int iter = 0;\n\n      // We free equally from each pool in 32 KB\n      // chunks until we are below our threshold\n      // (freeLevel)\n\n      boolean any = true;\n\n      while(numBytesAlloc+deletesRAMUsed > freeLevel) {\n      \n        synchronized(this) {\n          if (0 == perDocAllocator.freeByteBlocks.size() \n              && 0 == byteBlockAllocator.freeByteBlocks.size() \n              && 0 == freeCharBlocks.size() \n              && 0 == freeIntBlocks.size() \n              && !any) {\n            // Nothing else to free -- must flush now.\n            bufferIsFull = numBytesUsed+deletesRAMUsed > flushTrigger;\n            if (infoStream != null) {\n              if (numBytesUsed > flushTrigger)\n                message(\"    nothing to free; now set bufferIsFull\");\n              else\n                message(\"    nothing to free\");\n            }\n            assert numBytesUsed <= numBytesAlloc;\n            break;\n          }\n\n          if ((0 == iter % 5) && byteBlockAllocator.freeByteBlocks.size() > 0) {\n            byteBlockAllocator.freeByteBlocks.remove(byteBlockAllocator.freeByteBlocks.size()-1);\n            numBytesAlloc -= BYTE_BLOCK_SIZE;\n          }\n\n          if ((1 == iter % 5) && freeCharBlocks.size() > 0) {\n            freeCharBlocks.remove(freeCharBlocks.size()-1);\n            numBytesAlloc -= CHAR_BLOCK_SIZE * CHAR_NUM_BYTE;\n          }\n\n          if ((2 == iter % 5) && freeIntBlocks.size() > 0) {\n            freeIntBlocks.remove(freeIntBlocks.size()-1);\n            numBytesAlloc -= INT_BLOCK_SIZE * INT_NUM_BYTE;\n          }\n\n          if ((3 == iter % 5) && perDocAllocator.freeByteBlocks.size() > 0) {\n            // Remove upwards of 32 blocks (each block is 1K)\n            for (int i = 0; i < 32; ++i) {\n              perDocAllocator.freeByteBlocks.remove(perDocAllocator.freeByteBlocks.size() - 1);\n              numBytesAlloc -= PER_DOC_BLOCK_SIZE;\n              if (perDocAllocator.freeByteBlocks.size() == 0) {\n                break;\n              }\n            }\n          }\n        }\n\n        if ((4 == iter % 5) && any)\n          // Ask consumer to free any recycled state\n          any = consumer.freeRAM();\n\n        iter++;\n      }\n\n      if (infoStream != null)\n        message(\"    after free: freedMB=\" + nf.format((startBytesAlloc-numBytesAlloc-deletesRAMUsed)/1024./1024.) + \" usedMB=\" + nf.format((numBytesUsed+deletesRAMUsed)/1024./1024.) + \" allocMB=\" + nf.format(numBytesAlloc/1024./1024.));\n      \n    } else {\n      // If we have not crossed the 100% mark, but have\n      // crossed the 95% mark of RAM we are actually\n      // using, go ahead and flush.  This prevents\n      // over-allocating and then freeing, with every\n      // flush.\n      synchronized(this) {\n\n        if (numBytesUsed+deletesRAMUsed > flushTrigger) {\n          if (infoStream != null)\n            message(\"  RAM: now flush @ usedMB=\" + nf.format(numBytesUsed/1024./1024.) +\n                    \" allocMB=\" + nf.format(numBytesAlloc/1024./1024.) +\n                    \" deletesMB=\" + nf.format(deletesRAMUsed/1024./1024.) +\n                    \" triggerMB=\" + nf.format(flushTrigger/1024./1024.));\n\n          bufferIsFull = true;\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"955c32f886db6f6356c9fcdea6b1f1cb4effda24","date":1270581567,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/DocumentsWriter#balanceRAM().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/DocumentsWriter#balanceRAM().mjava","sourceNew":"  /* We have three pools of RAM: Postings, byte blocks\n   * (holds freq/prox posting data) and per-doc buffers\n   * (stored fields/term vectors).  Different docs require\n   * varying amount of storage from these classes.  For\n   * example, docs with many unique single-occurrence short\n   * terms will use up the Postings RAM and hardly any of\n   * the other two.  Whereas docs with very large terms will\n   * use alot of byte blocks RAM.  This method just frees\n   * allocations from the pools once we are over-budget,\n   * which balances the pools to match the current docs. */\n  void balanceRAM() {\n\n    final long deletesRAMUsed = deletesInRAM.bytesUsed+deletesFlushed.bytesUsed;\n\n    if (numBytesUsed+deletesRAMUsed > ramBufferSize) {\n\n      if (infoStream != null)\n        message(\"  RAM: now balance allocations: usedMB=\" + toMB(numBytesUsed) +\n                \" vs trigger=\" + toMB(ramBufferSize) +\n                \" deletesMB=\" + toMB(deletesRAMUsed) +\n                \" byteBlockFree=\" + toMB(byteBlockAllocator.freeByteBlocks.size()*BYTE_BLOCK_SIZE) +\n                \" perDocFree=\" + toMB(perDocAllocator.freeByteBlocks.size()*PER_DOC_BLOCK_SIZE));\n\n      final long startBytesUsed = numBytesUsed + deletesRAMUsed;\n\n      int iter = 0;\n\n      // We free equally from each pool in 32 KB\n      // chunks until we are below our threshold\n      // (freeLevel)\n\n      boolean any = true;\n\n      while(numBytesUsed+deletesRAMUsed > freeLevel) {\n      \n        synchronized(this) {\n          if (0 == perDocAllocator.freeByteBlocks.size() &&\n              0 == byteBlockAllocator.freeByteBlocks.size() &&\n              0 == freeIntBlocks.size() && !any) {\n            // Nothing else to free -- must flush now.\n            bufferIsFull = numBytesUsed+deletesRAMUsed > ramBufferSize;\n            if (infoStream != null) {\n              if (numBytesUsed+deletesRAMUsed > ramBufferSize)\n                message(\"    nothing to free; now set bufferIsFull\");\n              else\n                message(\"    nothing to free\");\n            }\n            break;\n          }\n\n          if ((0 == iter % 4) && byteBlockAllocator.freeByteBlocks.size() > 0) {\n            byteBlockAllocator.freeByteBlocks.remove(byteBlockAllocator.freeByteBlocks.size()-1);\n            numBytesUsed -= BYTE_BLOCK_SIZE;\n          }\n\n          if ((1 == iter % 4) && freeIntBlocks.size() > 0) {\n            freeIntBlocks.remove(freeIntBlocks.size()-1);\n            numBytesUsed -= INT_BLOCK_SIZE * INT_NUM_BYTE;\n          }\n\n          if ((2 == iter % 4) && perDocAllocator.freeByteBlocks.size() > 0) {\n            // Remove upwards of 32 blocks (each block is 1K)\n            for (int i = 0; i < 32; ++i) {\n              perDocAllocator.freeByteBlocks.remove(perDocAllocator.freeByteBlocks.size() - 1);\n              numBytesUsed -= PER_DOC_BLOCK_SIZE;\n              if (perDocAllocator.freeByteBlocks.size() == 0) {\n                break;\n              }\n            }\n          }\n        }\n\n        if ((3 == iter % 4) && any)\n          // Ask consumer to free any recycled state\n          any = consumer.freeRAM();\n\n        iter++;\n      }\n\n      if (infoStream != null)\n        message(\"    after free: freedMB=\" + nf.format((startBytesUsed-numBytesUsed-deletesRAMUsed)/1024./1024.) + \" usedMB=\" + nf.format((numBytesUsed+deletesRAMUsed)/1024./1024.));\n    }\n  }\n\n","sourceOld":"  /* We have four pools of RAM: Postings, byte blocks\n   * (holds freq/prox posting data), char blocks (holds\n   * characters in the term) and per-doc buffers (stored fields/term vectors).  \n   * Different docs require varying amount of storage from \n   * these four classes.\n   * \n   * For example, docs with many unique single-occurrence\n   * short terms will use up the Postings RAM and hardly any\n   * of the other two.  Whereas docs with very large terms\n   * will use alot of char blocks RAM and relatively less of\n   * the other two.  This method just frees allocations from\n   * the pools once we are over-budget, which balances the\n   * pools to match the current docs. */\n  void balanceRAM() {\n\n    // We flush when we've used our target usage\n    final long flushTrigger = ramBufferSize;\n\n    final long deletesRAMUsed = deletesInRAM.bytesUsed+deletesFlushed.bytesUsed;\n\n    if (numBytesAlloc+deletesRAMUsed > freeTrigger) {\n\n      if (infoStream != null)\n        message(\"  RAM: now balance allocations: usedMB=\" + toMB(numBytesUsed) +\n                \" vs trigger=\" + toMB(flushTrigger) +\n                \" allocMB=\" + toMB(numBytesAlloc) +\n                \" deletesMB=\" + toMB(deletesRAMUsed) +\n                \" vs trigger=\" + toMB(freeTrigger) +\n                \" byteBlockFree=\" + toMB(byteBlockAllocator.freeByteBlocks.size()*BYTE_BLOCK_SIZE) +\n                \" perDocFree=\" + toMB(perDocAllocator.freeByteBlocks.size()*PER_DOC_BLOCK_SIZE) +\n                \" charBlockFree=\" + toMB(freeCharBlocks.size()*CHAR_BLOCK_SIZE*CHAR_NUM_BYTE));\n\n      final long startBytesAlloc = numBytesAlloc + deletesRAMUsed;\n\n      int iter = 0;\n\n      // We free equally from each pool in 32 KB\n      // chunks until we are below our threshold\n      // (freeLevel)\n\n      boolean any = true;\n\n      while(numBytesAlloc+deletesRAMUsed > freeLevel) {\n      \n        synchronized(this) {\n          if (0 == perDocAllocator.freeByteBlocks.size() \n              && 0 == byteBlockAllocator.freeByteBlocks.size() \n              && 0 == freeCharBlocks.size() \n              && 0 == freeIntBlocks.size() \n              && !any) {\n            // Nothing else to free -- must flush now.\n            bufferIsFull = numBytesUsed+deletesRAMUsed > flushTrigger;\n            if (infoStream != null) {\n              if (numBytesUsed > flushTrigger)\n                message(\"    nothing to free; now set bufferIsFull\");\n              else\n                message(\"    nothing to free\");\n            }\n            assert numBytesUsed <= numBytesAlloc;\n            break;\n          }\n\n          if ((0 == iter % 5) && byteBlockAllocator.freeByteBlocks.size() > 0) {\n            byteBlockAllocator.freeByteBlocks.remove(byteBlockAllocator.freeByteBlocks.size()-1);\n            numBytesAlloc -= BYTE_BLOCK_SIZE;\n          }\n\n          if ((1 == iter % 5) && freeCharBlocks.size() > 0) {\n            freeCharBlocks.remove(freeCharBlocks.size()-1);\n            numBytesAlloc -= CHAR_BLOCK_SIZE * CHAR_NUM_BYTE;\n          }\n\n          if ((2 == iter % 5) && freeIntBlocks.size() > 0) {\n            freeIntBlocks.remove(freeIntBlocks.size()-1);\n            numBytesAlloc -= INT_BLOCK_SIZE * INT_NUM_BYTE;\n          }\n\n          if ((3 == iter % 5) && perDocAllocator.freeByteBlocks.size() > 0) {\n            // Remove upwards of 32 blocks (each block is 1K)\n            for (int i = 0; i < 32; ++i) {\n              perDocAllocator.freeByteBlocks.remove(perDocAllocator.freeByteBlocks.size() - 1);\n              numBytesAlloc -= PER_DOC_BLOCK_SIZE;\n              if (perDocAllocator.freeByteBlocks.size() == 0) {\n                break;\n              }\n            }\n          }\n        }\n\n        if ((4 == iter % 5) && any)\n          // Ask consumer to free any recycled state\n          any = consumer.freeRAM();\n\n        iter++;\n      }\n\n      if (infoStream != null)\n        message(\"    after free: freedMB=\" + nf.format((startBytesAlloc-numBytesAlloc-deletesRAMUsed)/1024./1024.) + \" usedMB=\" + nf.format((numBytesUsed+deletesRAMUsed)/1024./1024.) + \" allocMB=\" + nf.format(numBytesAlloc/1024./1024.));\n      \n    } else {\n      // If we have not crossed the 100% mark, but have\n      // crossed the 95% mark of RAM we are actually\n      // using, go ahead and flush.  This prevents\n      // over-allocating and then freeing, with every\n      // flush.\n      synchronized(this) {\n\n        if (numBytesUsed+deletesRAMUsed > flushTrigger) {\n          if (infoStream != null)\n            message(\"  RAM: now flush @ usedMB=\" + nf.format(numBytesUsed/1024./1024.) +\n                    \" allocMB=\" + nf.format(numBytesAlloc/1024./1024.) +\n                    \" deletesMB=\" + nf.format(deletesRAMUsed/1024./1024.) +\n                    \" triggerMB=\" + nf.format(flushTrigger/1024./1024.));\n\n          bufferIsFull = true;\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f58dd714e47e4b20e7ddf69802a24d8278a50d3d","date":1270583819,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/DocumentsWriter#balanceRAM().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/DocumentsWriter#balanceRAM().mjava","sourceNew":"  /* We have three pools of RAM: Postings, byte blocks\n   * (holds freq/prox posting data) and per-doc buffers\n   * (stored fields/term vectors).  Different docs require\n   * varying amount of storage from these classes.  For\n   * example, docs with many unique single-occurrence short\n   * terms will use up the Postings RAM and hardly any of\n   * the other two.  Whereas docs with very large terms will\n   * use alot of byte blocks RAM.  This method just frees\n   * allocations from the pools once we are over-budget,\n   * which balances the pools to match the current docs. */\n  void balanceRAM() {\n\n    final boolean doBalance;\n    final long deletesRAMUsed;\n\n    synchronized(this) {\n      if (ramBufferSize == IndexWriterConfig.DISABLE_AUTO_FLUSH || bufferIsFull) {\n        return;\n      }\n    \n      deletesRAMUsed = deletesInRAM.bytesUsed+deletesFlushed.bytesUsed;\n      doBalance = numBytesUsed+deletesRAMUsed >= ramBufferSize;\n    }\n\n    if (doBalance) {\n\n      if (infoStream != null)\n        message(\"  RAM: now balance allocations: usedMB=\" + toMB(numBytesUsed) +\n                \" vs trigger=\" + toMB(ramBufferSize) +\n                \" deletesMB=\" + toMB(deletesRAMUsed) +\n                \" byteBlockFree=\" + toMB(byteBlockAllocator.freeByteBlocks.size()*BYTE_BLOCK_SIZE) +\n                \" perDocFree=\" + toMB(perDocAllocator.freeByteBlocks.size()*PER_DOC_BLOCK_SIZE));\n\n      final long startBytesUsed = numBytesUsed + deletesRAMUsed;\n\n      int iter = 0;\n\n      // We free equally from each pool in 32 KB\n      // chunks until we are below our threshold\n      // (freeLevel)\n\n      boolean any = true;\n\n      while(numBytesUsed+deletesRAMUsed > freeLevel) {\n      \n        synchronized(this) {\n          if (0 == perDocAllocator.freeByteBlocks.size() &&\n              0 == byteBlockAllocator.freeByteBlocks.size() &&\n              0 == freeIntBlocks.size() && !any) {\n            // Nothing else to free -- must flush now.\n            bufferIsFull = numBytesUsed+deletesRAMUsed > ramBufferSize;\n            if (infoStream != null) {\n              if (numBytesUsed+deletesRAMUsed > ramBufferSize)\n                message(\"    nothing to free; now set bufferIsFull\");\n              else\n                message(\"    nothing to free\");\n            }\n            break;\n          }\n\n          if ((0 == iter % 4) && byteBlockAllocator.freeByteBlocks.size() > 0) {\n            byteBlockAllocator.freeByteBlocks.remove(byteBlockAllocator.freeByteBlocks.size()-1);\n            numBytesUsed -= BYTE_BLOCK_SIZE;\n          }\n\n          if ((1 == iter % 4) && freeIntBlocks.size() > 0) {\n            freeIntBlocks.remove(freeIntBlocks.size()-1);\n            numBytesUsed -= INT_BLOCK_SIZE * INT_NUM_BYTE;\n          }\n\n          if ((2 == iter % 4) && perDocAllocator.freeByteBlocks.size() > 0) {\n            // Remove upwards of 32 blocks (each block is 1K)\n            for (int i = 0; i < 32; ++i) {\n              perDocAllocator.freeByteBlocks.remove(perDocAllocator.freeByteBlocks.size() - 1);\n              numBytesUsed -= PER_DOC_BLOCK_SIZE;\n              if (perDocAllocator.freeByteBlocks.size() == 0) {\n                break;\n              }\n            }\n          }\n        }\n\n        if ((3 == iter % 4) && any)\n          // Ask consumer to free any recycled state\n          any = consumer.freeRAM();\n\n        iter++;\n      }\n\n      if (infoStream != null)\n        message(\"    after free: freedMB=\" + nf.format((startBytesUsed-numBytesUsed-deletesRAMUsed)/1024./1024.) + \" usedMB=\" + nf.format((numBytesUsed+deletesRAMUsed)/1024./1024.));\n    }\n  }\n\n","sourceOld":"  /* We have three pools of RAM: Postings, byte blocks\n   * (holds freq/prox posting data) and per-doc buffers\n   * (stored fields/term vectors).  Different docs require\n   * varying amount of storage from these classes.  For\n   * example, docs with many unique single-occurrence short\n   * terms will use up the Postings RAM and hardly any of\n   * the other two.  Whereas docs with very large terms will\n   * use alot of byte blocks RAM.  This method just frees\n   * allocations from the pools once we are over-budget,\n   * which balances the pools to match the current docs. */\n  void balanceRAM() {\n\n    final long deletesRAMUsed = deletesInRAM.bytesUsed+deletesFlushed.bytesUsed;\n\n    if (numBytesUsed+deletesRAMUsed > ramBufferSize) {\n\n      if (infoStream != null)\n        message(\"  RAM: now balance allocations: usedMB=\" + toMB(numBytesUsed) +\n                \" vs trigger=\" + toMB(ramBufferSize) +\n                \" deletesMB=\" + toMB(deletesRAMUsed) +\n                \" byteBlockFree=\" + toMB(byteBlockAllocator.freeByteBlocks.size()*BYTE_BLOCK_SIZE) +\n                \" perDocFree=\" + toMB(perDocAllocator.freeByteBlocks.size()*PER_DOC_BLOCK_SIZE));\n\n      final long startBytesUsed = numBytesUsed + deletesRAMUsed;\n\n      int iter = 0;\n\n      // We free equally from each pool in 32 KB\n      // chunks until we are below our threshold\n      // (freeLevel)\n\n      boolean any = true;\n\n      while(numBytesUsed+deletesRAMUsed > freeLevel) {\n      \n        synchronized(this) {\n          if (0 == perDocAllocator.freeByteBlocks.size() &&\n              0 == byteBlockAllocator.freeByteBlocks.size() &&\n              0 == freeIntBlocks.size() && !any) {\n            // Nothing else to free -- must flush now.\n            bufferIsFull = numBytesUsed+deletesRAMUsed > ramBufferSize;\n            if (infoStream != null) {\n              if (numBytesUsed+deletesRAMUsed > ramBufferSize)\n                message(\"    nothing to free; now set bufferIsFull\");\n              else\n                message(\"    nothing to free\");\n            }\n            break;\n          }\n\n          if ((0 == iter % 4) && byteBlockAllocator.freeByteBlocks.size() > 0) {\n            byteBlockAllocator.freeByteBlocks.remove(byteBlockAllocator.freeByteBlocks.size()-1);\n            numBytesUsed -= BYTE_BLOCK_SIZE;\n          }\n\n          if ((1 == iter % 4) && freeIntBlocks.size() > 0) {\n            freeIntBlocks.remove(freeIntBlocks.size()-1);\n            numBytesUsed -= INT_BLOCK_SIZE * INT_NUM_BYTE;\n          }\n\n          if ((2 == iter % 4) && perDocAllocator.freeByteBlocks.size() > 0) {\n            // Remove upwards of 32 blocks (each block is 1K)\n            for (int i = 0; i < 32; ++i) {\n              perDocAllocator.freeByteBlocks.remove(perDocAllocator.freeByteBlocks.size() - 1);\n              numBytesUsed -= PER_DOC_BLOCK_SIZE;\n              if (perDocAllocator.freeByteBlocks.size() == 0) {\n                break;\n              }\n            }\n          }\n        }\n\n        if ((3 == iter % 4) && any)\n          // Ask consumer to free any recycled state\n          any = consumer.freeRAM();\n\n        iter++;\n      }\n\n      if (infoStream != null)\n        message(\"    after free: freedMB=\" + nf.format((startBytesUsed-numBytesUsed-deletesRAMUsed)/1024./1024.) + \" usedMB=\" + nf.format((numBytesUsed+deletesRAMUsed)/1024./1024.));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9b832cbed6eb3d54a8bb9339296bdda8eeb53014","date":1279708040,"type":4,"author":"Michael Busch","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/src/java/org/apache/lucene/index/DocumentsWriter#balanceRAM().mjava","sourceNew":null,"sourceOld":"  /* We have three pools of RAM: Postings, byte blocks\n   * (holds freq/prox posting data) and per-doc buffers\n   * (stored fields/term vectors).  Different docs require\n   * varying amount of storage from these classes.  For\n   * example, docs with many unique single-occurrence short\n   * terms will use up the Postings RAM and hardly any of\n   * the other two.  Whereas docs with very large terms will\n   * use alot of byte blocks RAM.  This method just frees\n   * allocations from the pools once we are over-budget,\n   * which balances the pools to match the current docs. */\n  void balanceRAM() {\n\n    final boolean doBalance;\n    final long deletesRAMUsed;\n\n    synchronized(this) {\n      if (ramBufferSize == IndexWriterConfig.DISABLE_AUTO_FLUSH || bufferIsFull) {\n        return;\n      }\n    \n      deletesRAMUsed = deletesInRAM.bytesUsed+deletesFlushed.bytesUsed;\n      doBalance = numBytesUsed+deletesRAMUsed >= ramBufferSize;\n    }\n\n    if (doBalance) {\n\n      if (infoStream != null)\n        message(\"  RAM: now balance allocations: usedMB=\" + toMB(numBytesUsed) +\n                \" vs trigger=\" + toMB(ramBufferSize) +\n                \" deletesMB=\" + toMB(deletesRAMUsed) +\n                \" byteBlockFree=\" + toMB(byteBlockAllocator.freeByteBlocks.size()*BYTE_BLOCK_SIZE) +\n                \" perDocFree=\" + toMB(perDocAllocator.freeByteBlocks.size()*PER_DOC_BLOCK_SIZE));\n\n      final long startBytesUsed = numBytesUsed + deletesRAMUsed;\n\n      int iter = 0;\n\n      // We free equally from each pool in 32 KB\n      // chunks until we are below our threshold\n      // (freeLevel)\n\n      boolean any = true;\n\n      while(numBytesUsed+deletesRAMUsed > freeLevel) {\n      \n        synchronized(this) {\n          if (0 == perDocAllocator.freeByteBlocks.size() &&\n              0 == byteBlockAllocator.freeByteBlocks.size() &&\n              0 == freeIntBlocks.size() && !any) {\n            // Nothing else to free -- must flush now.\n            bufferIsFull = numBytesUsed+deletesRAMUsed > ramBufferSize;\n            if (infoStream != null) {\n              if (numBytesUsed+deletesRAMUsed > ramBufferSize)\n                message(\"    nothing to free; now set bufferIsFull\");\n              else\n                message(\"    nothing to free\");\n            }\n            break;\n          }\n\n          if ((0 == iter % 4) && byteBlockAllocator.freeByteBlocks.size() > 0) {\n            byteBlockAllocator.freeByteBlocks.remove(byteBlockAllocator.freeByteBlocks.size()-1);\n            numBytesUsed -= BYTE_BLOCK_SIZE;\n          }\n\n          if ((1 == iter % 4) && freeIntBlocks.size() > 0) {\n            freeIntBlocks.remove(freeIntBlocks.size()-1);\n            numBytesUsed -= INT_BLOCK_SIZE * INT_NUM_BYTE;\n          }\n\n          if ((2 == iter % 4) && perDocAllocator.freeByteBlocks.size() > 0) {\n            // Remove upwards of 32 blocks (each block is 1K)\n            for (int i = 0; i < 32; ++i) {\n              perDocAllocator.freeByteBlocks.remove(perDocAllocator.freeByteBlocks.size() - 1);\n              numBytesUsed -= PER_DOC_BLOCK_SIZE;\n              if (perDocAllocator.freeByteBlocks.size() == 0) {\n                break;\n              }\n            }\n          }\n        }\n\n        if ((3 == iter % 4) && any)\n          // Ask consumer to free any recycled state\n          any = consumer.freeRAM();\n\n        iter++;\n      }\n\n      if (infoStream != null)\n        message(\"    after free: freedMB=\" + nf.format((startBytesUsed-numBytesUsed-deletesRAMUsed)/1024./1024.) + \" usedMB=\" + nf.format((numBytesUsed+deletesRAMUsed)/1024./1024.));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"334c1175813aea771a71728cd2c4ee4754fd0603","date":1279710173,"type":0,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/DocumentsWriter#balanceRAM().mjava","pathOld":"/dev/null","sourceNew":"  /* We have three pools of RAM: Postings, byte blocks\n   * (holds freq/prox posting data) and per-doc buffers\n   * (stored fields/term vectors).  Different docs require\n   * varying amount of storage from these classes.  For\n   * example, docs with many unique single-occurrence short\n   * terms will use up the Postings RAM and hardly any of\n   * the other two.  Whereas docs with very large terms will\n   * use alot of byte blocks RAM.  This method just frees\n   * allocations from the pools once we are over-budget,\n   * which balances the pools to match the current docs. */\n  void balanceRAM() {\n\n    final boolean doBalance;\n    final long deletesRAMUsed;\n\n    synchronized(this) {\n      if (ramBufferSize == IndexWriterConfig.DISABLE_AUTO_FLUSH || bufferIsFull) {\n        return;\n      }\n    \n      deletesRAMUsed = deletesInRAM.bytesUsed+deletesFlushed.bytesUsed;\n      doBalance = numBytesUsed+deletesRAMUsed >= ramBufferSize;\n    }\n\n    if (doBalance) {\n\n      if (infoStream != null)\n        message(\"  RAM: now balance allocations: usedMB=\" + toMB(numBytesUsed) +\n                \" vs trigger=\" + toMB(ramBufferSize) +\n                \" deletesMB=\" + toMB(deletesRAMUsed) +\n                \" byteBlockFree=\" + toMB(byteBlockAllocator.freeByteBlocks.size()*BYTE_BLOCK_SIZE) +\n                \" perDocFree=\" + toMB(perDocAllocator.freeByteBlocks.size()*PER_DOC_BLOCK_SIZE));\n\n      final long startBytesUsed = numBytesUsed + deletesRAMUsed;\n\n      int iter = 0;\n\n      // We free equally from each pool in 32 KB\n      // chunks until we are below our threshold\n      // (freeLevel)\n\n      boolean any = true;\n\n      while(numBytesUsed+deletesRAMUsed > freeLevel) {\n      \n        synchronized(this) {\n          if (0 == perDocAllocator.freeByteBlocks.size() &&\n              0 == byteBlockAllocator.freeByteBlocks.size() &&\n              0 == freeIntBlocks.size() && !any) {\n            // Nothing else to free -- must flush now.\n            bufferIsFull = numBytesUsed+deletesRAMUsed > ramBufferSize;\n            if (infoStream != null) {\n              if (numBytesUsed+deletesRAMUsed > ramBufferSize)\n                message(\"    nothing to free; now set bufferIsFull\");\n              else\n                message(\"    nothing to free\");\n            }\n            break;\n          }\n\n          if ((0 == iter % 4) && byteBlockAllocator.freeByteBlocks.size() > 0) {\n            byteBlockAllocator.freeByteBlocks.remove(byteBlockAllocator.freeByteBlocks.size()-1);\n            numBytesUsed -= BYTE_BLOCK_SIZE;\n          }\n\n          if ((1 == iter % 4) && freeIntBlocks.size() > 0) {\n            freeIntBlocks.remove(freeIntBlocks.size()-1);\n            numBytesUsed -= INT_BLOCK_SIZE * INT_NUM_BYTE;\n          }\n\n          if ((2 == iter % 4) && perDocAllocator.freeByteBlocks.size() > 0) {\n            // Remove upwards of 32 blocks (each block is 1K)\n            for (int i = 0; i < 32; ++i) {\n              perDocAllocator.freeByteBlocks.remove(perDocAllocator.freeByteBlocks.size() - 1);\n              numBytesUsed -= PER_DOC_BLOCK_SIZE;\n              if (perDocAllocator.freeByteBlocks.size() == 0) {\n                break;\n              }\n            }\n          }\n        }\n\n        if ((3 == iter % 4) && any)\n          // Ask consumer to free any recycled state\n          any = consumer.freeRAM();\n\n        iter++;\n      }\n\n      if (infoStream != null)\n        message(\"    after free: freedMB=\" + nf.format((startBytesUsed-numBytesUsed-deletesRAMUsed)/1024./1024.) + \" usedMB=\" + nf.format((numBytesUsed+deletesRAMUsed)/1024./1024.));\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8fe956d65251358d755c56f14fe8380644790e47","date":1279711318,"type":4,"author":"Michael Busch","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/src/java/org/apache/lucene/index/DocumentsWriter#balanceRAM().mjava","sourceNew":null,"sourceOld":"  /* We have three pools of RAM: Postings, byte blocks\n   * (holds freq/prox posting data) and per-doc buffers\n   * (stored fields/term vectors).  Different docs require\n   * varying amount of storage from these classes.  For\n   * example, docs with many unique single-occurrence short\n   * terms will use up the Postings RAM and hardly any of\n   * the other two.  Whereas docs with very large terms will\n   * use alot of byte blocks RAM.  This method just frees\n   * allocations from the pools once we are over-budget,\n   * which balances the pools to match the current docs. */\n  void balanceRAM() {\n\n    final boolean doBalance;\n    final long deletesRAMUsed;\n\n    synchronized(this) {\n      if (ramBufferSize == IndexWriterConfig.DISABLE_AUTO_FLUSH || bufferIsFull) {\n        return;\n      }\n    \n      deletesRAMUsed = deletesInRAM.bytesUsed+deletesFlushed.bytesUsed;\n      doBalance = numBytesUsed+deletesRAMUsed >= ramBufferSize;\n    }\n\n    if (doBalance) {\n\n      if (infoStream != null)\n        message(\"  RAM: now balance allocations: usedMB=\" + toMB(numBytesUsed) +\n                \" vs trigger=\" + toMB(ramBufferSize) +\n                \" deletesMB=\" + toMB(deletesRAMUsed) +\n                \" byteBlockFree=\" + toMB(byteBlockAllocator.freeByteBlocks.size()*BYTE_BLOCK_SIZE) +\n                \" perDocFree=\" + toMB(perDocAllocator.freeByteBlocks.size()*PER_DOC_BLOCK_SIZE));\n\n      final long startBytesUsed = numBytesUsed + deletesRAMUsed;\n\n      int iter = 0;\n\n      // We free equally from each pool in 32 KB\n      // chunks until we are below our threshold\n      // (freeLevel)\n\n      boolean any = true;\n\n      while(numBytesUsed+deletesRAMUsed > freeLevel) {\n      \n        synchronized(this) {\n          if (0 == perDocAllocator.freeByteBlocks.size() &&\n              0 == byteBlockAllocator.freeByteBlocks.size() &&\n              0 == freeIntBlocks.size() && !any) {\n            // Nothing else to free -- must flush now.\n            bufferIsFull = numBytesUsed+deletesRAMUsed > ramBufferSize;\n            if (infoStream != null) {\n              if (numBytesUsed+deletesRAMUsed > ramBufferSize)\n                message(\"    nothing to free; now set bufferIsFull\");\n              else\n                message(\"    nothing to free\");\n            }\n            break;\n          }\n\n          if ((0 == iter % 4) && byteBlockAllocator.freeByteBlocks.size() > 0) {\n            byteBlockAllocator.freeByteBlocks.remove(byteBlockAllocator.freeByteBlocks.size()-1);\n            numBytesUsed -= BYTE_BLOCK_SIZE;\n          }\n\n          if ((1 == iter % 4) && freeIntBlocks.size() > 0) {\n            freeIntBlocks.remove(freeIntBlocks.size()-1);\n            numBytesUsed -= INT_BLOCK_SIZE * INT_NUM_BYTE;\n          }\n\n          if ((2 == iter % 4) && perDocAllocator.freeByteBlocks.size() > 0) {\n            // Remove upwards of 32 blocks (each block is 1K)\n            for (int i = 0; i < 32; ++i) {\n              perDocAllocator.freeByteBlocks.remove(perDocAllocator.freeByteBlocks.size() - 1);\n              numBytesUsed -= PER_DOC_BLOCK_SIZE;\n              if (perDocAllocator.freeByteBlocks.size() == 0) {\n                break;\n              }\n            }\n          }\n        }\n\n        if ((3 == iter % 4) && any)\n          // Ask consumer to free any recycled state\n          any = consumer.freeRAM();\n\n        iter++;\n      }\n\n      if (infoStream != null)\n        message(\"    after free: freedMB=\" + nf.format((startBytesUsed-numBytesUsed-deletesRAMUsed)/1024./1024.) + \" usedMB=\" + nf.format((numBytesUsed+deletesRAMUsed)/1024./1024.));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5d6c52f55ea3ba9a5b1d5a6dd17f79bc7d308392","date":1286023472,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/DocumentsWriter#balanceRAM().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/DocumentsWriter#balanceRAM().mjava","sourceNew":"  /* We have three pools of RAM: Postings, byte blocks\n   * (holds freq/prox posting data) and per-doc buffers\n   * (stored fields/term vectors).  Different docs require\n   * varying amount of storage from these classes.  For\n   * example, docs with many unique single-occurrence short\n   * terms will use up the Postings RAM and hardly any of\n   * the other two.  Whereas docs with very large terms will\n   * use alot of byte blocks RAM.  This method just frees\n   * allocations from the pools once we are over-budget,\n   * which balances the pools to match the current docs. */\n  void balanceRAM() {\n\n    final boolean doBalance;\n    final long deletesRAMUsed;\n\n    synchronized(this) {\n      if (ramBufferSize == IndexWriterConfig.DISABLE_AUTO_FLUSH || bufferIsFull) {\n        return;\n      }\n    \n      deletesRAMUsed = deletesInRAM.bytesUsed+deletesFlushed.bytesUsed;\n      doBalance = bytesUsed() +deletesRAMUsed >= ramBufferSize;\n    }\n\n    if (doBalance) {\n\n      if (infoStream != null)\n        message(\"  RAM: now balance allocations: usedMB=\" + toMB(bytesUsed()) +\n                \" vs trigger=\" + toMB(ramBufferSize) +\n                \" deletesMB=\" + toMB(deletesRAMUsed) +\n                \" byteBlockFree=\" + toMB(byteBlockAllocator.bytesUsed()) +\n                \" perDocFree=\" + toMB(perDocAllocator.bytesUsed()));\n\n      final long startBytesUsed = bytesUsed() + deletesRAMUsed;\n\n      int iter = 0;\n\n      // We free equally from each pool in 32 KB\n      // chunks until we are below our threshold\n      // (freeLevel)\n\n      boolean any = true;\n\n      while(bytesUsed()+deletesRAMUsed > freeLevel) {\n      \n        synchronized(this) {\n          if (0 == perDocAllocator.numBufferedBlocks() &&\n              0 == byteBlockAllocator.numBufferedBlocks() &&\n              0 == freeIntBlocks.size() && !any) {\n            // Nothing else to free -- must flush now.\n            bufferIsFull = bytesUsed()+deletesRAMUsed > ramBufferSize;\n            if (infoStream != null) {\n              if (bytesUsed()+deletesRAMUsed > ramBufferSize)\n                message(\"    nothing to free; now set bufferIsFull\");\n              else\n                message(\"    nothing to free\");\n            }\n            break;\n          }\n\n          if ((0 == iter % 4) && byteBlockAllocator.numBufferedBlocks() > 0) {\n            byteBlockAllocator.freeBlocks(1);\n          }\n          if ((1 == iter % 4) && freeIntBlocks.size() > 0) {\n            freeIntBlocks.remove(freeIntBlocks.size()-1);\n            bytesUsed.addAndGet(-INT_BLOCK_SIZE * INT_NUM_BYTE);\n          }\n          if ((2 == iter % 4) && perDocAllocator.numBufferedBlocks() > 0) {\n            perDocAllocator.freeBlocks(32); // Remove upwards of 32 blocks (each block is 1K)\n          }\n        }\n\n        if ((3 == iter % 4) && any)\n          // Ask consumer to free any recycled state\n          any = consumer.freeRAM();\n\n        iter++;\n      }\n\n      if (infoStream != null)\n        message(\"    after free: freedMB=\" + nf.format((startBytesUsed-bytesUsed()-deletesRAMUsed)/1024./1024.) + \" usedMB=\" + nf.format((bytesUsed()+deletesRAMUsed)/1024./1024.));\n    }\n  }\n\n","sourceOld":"  /* We have three pools of RAM: Postings, byte blocks\n   * (holds freq/prox posting data) and per-doc buffers\n   * (stored fields/term vectors).  Different docs require\n   * varying amount of storage from these classes.  For\n   * example, docs with many unique single-occurrence short\n   * terms will use up the Postings RAM and hardly any of\n   * the other two.  Whereas docs with very large terms will\n   * use alot of byte blocks RAM.  This method just frees\n   * allocations from the pools once we are over-budget,\n   * which balances the pools to match the current docs. */\n  void balanceRAM() {\n\n    final boolean doBalance;\n    final long deletesRAMUsed;\n\n    synchronized(this) {\n      if (ramBufferSize == IndexWriterConfig.DISABLE_AUTO_FLUSH || bufferIsFull) {\n        return;\n      }\n    \n      deletesRAMUsed = deletesInRAM.bytesUsed+deletesFlushed.bytesUsed;\n      doBalance = numBytesUsed+deletesRAMUsed >= ramBufferSize;\n    }\n\n    if (doBalance) {\n\n      if (infoStream != null)\n        message(\"  RAM: now balance allocations: usedMB=\" + toMB(numBytesUsed) +\n                \" vs trigger=\" + toMB(ramBufferSize) +\n                \" deletesMB=\" + toMB(deletesRAMUsed) +\n                \" byteBlockFree=\" + toMB(byteBlockAllocator.freeByteBlocks.size()*BYTE_BLOCK_SIZE) +\n                \" perDocFree=\" + toMB(perDocAllocator.freeByteBlocks.size()*PER_DOC_BLOCK_SIZE));\n\n      final long startBytesUsed = numBytesUsed + deletesRAMUsed;\n\n      int iter = 0;\n\n      // We free equally from each pool in 32 KB\n      // chunks until we are below our threshold\n      // (freeLevel)\n\n      boolean any = true;\n\n      while(numBytesUsed+deletesRAMUsed > freeLevel) {\n      \n        synchronized(this) {\n          if (0 == perDocAllocator.freeByteBlocks.size() &&\n              0 == byteBlockAllocator.freeByteBlocks.size() &&\n              0 == freeIntBlocks.size() && !any) {\n            // Nothing else to free -- must flush now.\n            bufferIsFull = numBytesUsed+deletesRAMUsed > ramBufferSize;\n            if (infoStream != null) {\n              if (numBytesUsed+deletesRAMUsed > ramBufferSize)\n                message(\"    nothing to free; now set bufferIsFull\");\n              else\n                message(\"    nothing to free\");\n            }\n            break;\n          }\n\n          if ((0 == iter % 4) && byteBlockAllocator.freeByteBlocks.size() > 0) {\n            byteBlockAllocator.freeByteBlocks.remove(byteBlockAllocator.freeByteBlocks.size()-1);\n            numBytesUsed -= BYTE_BLOCK_SIZE;\n          }\n\n          if ((1 == iter % 4) && freeIntBlocks.size() > 0) {\n            freeIntBlocks.remove(freeIntBlocks.size()-1);\n            numBytesUsed -= INT_BLOCK_SIZE * INT_NUM_BYTE;\n          }\n\n          if ((2 == iter % 4) && perDocAllocator.freeByteBlocks.size() > 0) {\n            // Remove upwards of 32 blocks (each block is 1K)\n            for (int i = 0; i < 32; ++i) {\n              perDocAllocator.freeByteBlocks.remove(perDocAllocator.freeByteBlocks.size() - 1);\n              numBytesUsed -= PER_DOC_BLOCK_SIZE;\n              if (perDocAllocator.freeByteBlocks.size() == 0) {\n                break;\n              }\n            }\n          }\n        }\n\n        if ((3 == iter % 4) && any)\n          // Ask consumer to free any recycled state\n          any = consumer.freeRAM();\n\n        iter++;\n      }\n\n      if (infoStream != null)\n        message(\"    after free: freedMB=\" + nf.format((startBytesUsed-numBytesUsed-deletesRAMUsed)/1024./1024.) + \" usedMB=\" + nf.format((numBytesUsed+deletesRAMUsed)/1024./1024.));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"44fcbde6fb2ac44ee3b45e013e54a42911e689ff","date":1292065621,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/DocumentsWriter#balanceRAM().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/DocumentsWriter#balanceRAM().mjava","sourceNew":"  /* We have three pools of RAM: Postings, byte blocks\n   * (holds freq/prox posting data) and per-doc buffers\n   * (stored fields/term vectors).  Different docs require\n   * varying amount of storage from these classes.  For\n   * example, docs with many unique single-occurrence short\n   * terms will use up the Postings RAM and hardly any of\n   * the other two.  Whereas docs with very large terms will\n   * use alot of byte blocks RAM.  This method just frees\n   * allocations from the pools once we are over-budget,\n   * which balances the pools to match the current docs. */\n  void balanceRAM() {\n\n    final boolean doBalance;\n    final long deletesRAMUsed;\n\n    deletesRAMUsed = bufferedDeletes.bytesUsed();\n\n    synchronized(this) {\n      if (ramBufferSize == IndexWriterConfig.DISABLE_AUTO_FLUSH || bufferIsFull) {\n        return;\n      }\n    \n      doBalance = bytesUsed() + deletesRAMUsed >= ramBufferSize;\n    }\n\n    if (doBalance) {\n\n      if (infoStream != null)\n        message(\"  RAM: balance allocations: usedMB=\" + toMB(bytesUsed()) +\n                \" vs trigger=\" + toMB(ramBufferSize) +\n                \" deletesMB=\" + toMB(deletesRAMUsed) +\n                \" byteBlockFree=\" + toMB(byteBlockAllocator.bytesUsed()) +\n                \" perDocFree=\" + toMB(perDocAllocator.bytesUsed()));\n\n      final long startBytesUsed = bytesUsed() + deletesRAMUsed;\n\n      int iter = 0;\n\n      // We free equally from each pool in 32 KB\n      // chunks until we are below our threshold\n      // (freeLevel)\n\n      boolean any = true;\n\n      while(bytesUsed()+deletesRAMUsed > freeLevel) {\n      \n        synchronized(this) {\n          if (0 == perDocAllocator.numBufferedBlocks() &&\n              0 == byteBlockAllocator.numBufferedBlocks() &&\n              0 == freeIntBlocks.size() && !any) {\n            // Nothing else to free -- must flush now.\n            bufferIsFull = bytesUsed()+deletesRAMUsed > ramBufferSize;\n            if (infoStream != null) {\n              if (bytesUsed()+deletesRAMUsed > ramBufferSize)\n                message(\"    nothing to free; set bufferIsFull\");\n              else\n                message(\"    nothing to free\");\n            }\n            break;\n          }\n\n          if ((0 == iter % 4) && byteBlockAllocator.numBufferedBlocks() > 0) {\n            byteBlockAllocator.freeBlocks(1);\n          }\n          if ((1 == iter % 4) && freeIntBlocks.size() > 0) {\n            freeIntBlocks.remove(freeIntBlocks.size()-1);\n            bytesUsed.addAndGet(-INT_BLOCK_SIZE * RamUsageEstimator.NUM_BYTES_INT);\n          }\n          if ((2 == iter % 4) && perDocAllocator.numBufferedBlocks() > 0) {\n            perDocAllocator.freeBlocks(32); // Remove upwards of 32 blocks (each block is 1K)\n          }\n        }\n\n        if ((3 == iter % 4) && any)\n          // Ask consumer to free any recycled state\n          any = consumer.freeRAM();\n\n        iter++;\n      }\n\n      if (infoStream != null)\n        message(\"    after free: freedMB=\" + nf.format((startBytesUsed-bytesUsed()-deletesRAMUsed)/1024./1024.) + \" usedMB=\" + nf.format((bytesUsed()+deletesRAMUsed)/1024./1024.));\n    }\n  }\n\n","sourceOld":"  /* We have three pools of RAM: Postings, byte blocks\n   * (holds freq/prox posting data) and per-doc buffers\n   * (stored fields/term vectors).  Different docs require\n   * varying amount of storage from these classes.  For\n   * example, docs with many unique single-occurrence short\n   * terms will use up the Postings RAM and hardly any of\n   * the other two.  Whereas docs with very large terms will\n   * use alot of byte blocks RAM.  This method just frees\n   * allocations from the pools once we are over-budget,\n   * which balances the pools to match the current docs. */\n  void balanceRAM() {\n\n    final boolean doBalance;\n    final long deletesRAMUsed;\n\n    synchronized(this) {\n      if (ramBufferSize == IndexWriterConfig.DISABLE_AUTO_FLUSH || bufferIsFull) {\n        return;\n      }\n    \n      deletesRAMUsed = deletesInRAM.bytesUsed+deletesFlushed.bytesUsed;\n      doBalance = bytesUsed() +deletesRAMUsed >= ramBufferSize;\n    }\n\n    if (doBalance) {\n\n      if (infoStream != null)\n        message(\"  RAM: now balance allocations: usedMB=\" + toMB(bytesUsed()) +\n                \" vs trigger=\" + toMB(ramBufferSize) +\n                \" deletesMB=\" + toMB(deletesRAMUsed) +\n                \" byteBlockFree=\" + toMB(byteBlockAllocator.bytesUsed()) +\n                \" perDocFree=\" + toMB(perDocAllocator.bytesUsed()));\n\n      final long startBytesUsed = bytesUsed() + deletesRAMUsed;\n\n      int iter = 0;\n\n      // We free equally from each pool in 32 KB\n      // chunks until we are below our threshold\n      // (freeLevel)\n\n      boolean any = true;\n\n      while(bytesUsed()+deletesRAMUsed > freeLevel) {\n      \n        synchronized(this) {\n          if (0 == perDocAllocator.numBufferedBlocks() &&\n              0 == byteBlockAllocator.numBufferedBlocks() &&\n              0 == freeIntBlocks.size() && !any) {\n            // Nothing else to free -- must flush now.\n            bufferIsFull = bytesUsed()+deletesRAMUsed > ramBufferSize;\n            if (infoStream != null) {\n              if (bytesUsed()+deletesRAMUsed > ramBufferSize)\n                message(\"    nothing to free; now set bufferIsFull\");\n              else\n                message(\"    nothing to free\");\n            }\n            break;\n          }\n\n          if ((0 == iter % 4) && byteBlockAllocator.numBufferedBlocks() > 0) {\n            byteBlockAllocator.freeBlocks(1);\n          }\n          if ((1 == iter % 4) && freeIntBlocks.size() > 0) {\n            freeIntBlocks.remove(freeIntBlocks.size()-1);\n            bytesUsed.addAndGet(-INT_BLOCK_SIZE * INT_NUM_BYTE);\n          }\n          if ((2 == iter % 4) && perDocAllocator.numBufferedBlocks() > 0) {\n            perDocAllocator.freeBlocks(32); // Remove upwards of 32 blocks (each block is 1K)\n          }\n        }\n\n        if ((3 == iter % 4) && any)\n          // Ask consumer to free any recycled state\n          any = consumer.freeRAM();\n\n        iter++;\n      }\n\n      if (infoStream != null)\n        message(\"    after free: freedMB=\" + nf.format((startBytesUsed-bytesUsed()-deletesRAMUsed)/1024./1024.) + \" usedMB=\" + nf.format((bytesUsed()+deletesRAMUsed)/1024./1024.));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4948bc5d29211f0c9b5ccc31b2632cdd27066ea5","date":1292695408,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/DocumentsWriter#balanceRAM().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/DocumentsWriter#balanceRAM().mjava","sourceNew":"  /* We have three pools of RAM: Postings, byte blocks\n   * (holds freq/prox posting data) and per-doc buffers\n   * (stored fields/term vectors).  Different docs require\n   * varying amount of storage from these classes.  For\n   * example, docs with many unique single-occurrence short\n   * terms will use up the Postings RAM and hardly any of\n   * the other two.  Whereas docs with very large terms will\n   * use alot of byte blocks RAM.  This method just frees\n   * allocations from the pools once we are over-budget,\n   * which balances the pools to match the current docs. */\n  void balanceRAM() {\n\n    final boolean doBalance;\n    final long deletesRAMUsed;\n\n    deletesRAMUsed = bufferedDeletes.bytesUsed();\n\n    synchronized(this) {\n      if (ramBufferSize == IndexWriterConfig.DISABLE_AUTO_FLUSH || bufferIsFull) {\n        return;\n      }\n    \n      doBalance = bytesUsed() + deletesRAMUsed >= ramBufferSize;\n    }\n\n    if (doBalance) {\n\n      if (infoStream != null) {\n        message(\"  RAM: balance allocations: usedMB=\" + toMB(bytesUsed()) +\n                \" vs trigger=\" + toMB(ramBufferSize) +\n                \" deletesMB=\" + toMB(deletesRAMUsed) +\n                \" byteBlockFree=\" + toMB(byteBlockAllocator.bytesUsed()) +\n                \" perDocFree=\" + toMB(perDocAllocator.bytesUsed()));\n      }\n\n      final long startBytesUsed = bytesUsed() + deletesRAMUsed;\n\n      int iter = 0;\n\n      // We free equally from each pool in 32 KB\n      // chunks until we are below our threshold\n      // (freeLevel)\n\n      boolean any = true;\n\n      while(bytesUsed()+deletesRAMUsed > freeLevel) {\n      \n        synchronized(this) {\n          if (0 == perDocAllocator.numBufferedBlocks() &&\n              0 == byteBlockAllocator.numBufferedBlocks() &&\n              0 == freeIntBlocks.size() && !any) {\n            // Nothing else to free -- must flush now.\n            bufferIsFull = bytesUsed()+deletesRAMUsed > ramBufferSize;\n            if (infoStream != null) {\n              if (bytesUsed()+deletesRAMUsed > ramBufferSize) {\n                message(\"    nothing to free; set bufferIsFull\");\n              } else {\n                message(\"    nothing to free\");\n              }\n            }\n            break;\n          }\n\n          if ((0 == iter % 4) && byteBlockAllocator.numBufferedBlocks() > 0) {\n            byteBlockAllocator.freeBlocks(1);\n          }\n          if ((1 == iter % 4) && freeIntBlocks.size() > 0) {\n            freeIntBlocks.remove(freeIntBlocks.size()-1);\n            bytesUsed.addAndGet(-INT_BLOCK_SIZE * RamUsageEstimator.NUM_BYTES_INT);\n          }\n          if ((2 == iter % 4) && perDocAllocator.numBufferedBlocks() > 0) {\n            perDocAllocator.freeBlocks(32); // Remove upwards of 32 blocks (each block is 1K)\n          }\n        }\n\n        if ((3 == iter % 4) && any) {\n          // Ask consumer to free any recycled state\n          any = consumer.freeRAM();\n        }\n\n        iter++;\n      }\n\n      if (infoStream != null) {\n        message(\"    after free: freedMB=\" + nf.format((startBytesUsed-bytesUsed()-deletesRAMUsed)/1024./1024.) + \" usedMB=\" + nf.format((bytesUsed()+deletesRAMUsed)/1024./1024.));\n      }\n    }\n  }\n\n","sourceOld":"  /* We have three pools of RAM: Postings, byte blocks\n   * (holds freq/prox posting data) and per-doc buffers\n   * (stored fields/term vectors).  Different docs require\n   * varying amount of storage from these classes.  For\n   * example, docs with many unique single-occurrence short\n   * terms will use up the Postings RAM and hardly any of\n   * the other two.  Whereas docs with very large terms will\n   * use alot of byte blocks RAM.  This method just frees\n   * allocations from the pools once we are over-budget,\n   * which balances the pools to match the current docs. */\n  void balanceRAM() {\n\n    final boolean doBalance;\n    final long deletesRAMUsed;\n\n    deletesRAMUsed = bufferedDeletes.bytesUsed();\n\n    synchronized(this) {\n      if (ramBufferSize == IndexWriterConfig.DISABLE_AUTO_FLUSH || bufferIsFull) {\n        return;\n      }\n    \n      doBalance = bytesUsed() + deletesRAMUsed >= ramBufferSize;\n    }\n\n    if (doBalance) {\n\n      if (infoStream != null)\n        message(\"  RAM: balance allocations: usedMB=\" + toMB(bytesUsed()) +\n                \" vs trigger=\" + toMB(ramBufferSize) +\n                \" deletesMB=\" + toMB(deletesRAMUsed) +\n                \" byteBlockFree=\" + toMB(byteBlockAllocator.bytesUsed()) +\n                \" perDocFree=\" + toMB(perDocAllocator.bytesUsed()));\n\n      final long startBytesUsed = bytesUsed() + deletesRAMUsed;\n\n      int iter = 0;\n\n      // We free equally from each pool in 32 KB\n      // chunks until we are below our threshold\n      // (freeLevel)\n\n      boolean any = true;\n\n      while(bytesUsed()+deletesRAMUsed > freeLevel) {\n      \n        synchronized(this) {\n          if (0 == perDocAllocator.numBufferedBlocks() &&\n              0 == byteBlockAllocator.numBufferedBlocks() &&\n              0 == freeIntBlocks.size() && !any) {\n            // Nothing else to free -- must flush now.\n            bufferIsFull = bytesUsed()+deletesRAMUsed > ramBufferSize;\n            if (infoStream != null) {\n              if (bytesUsed()+deletesRAMUsed > ramBufferSize)\n                message(\"    nothing to free; set bufferIsFull\");\n              else\n                message(\"    nothing to free\");\n            }\n            break;\n          }\n\n          if ((0 == iter % 4) && byteBlockAllocator.numBufferedBlocks() > 0) {\n            byteBlockAllocator.freeBlocks(1);\n          }\n          if ((1 == iter % 4) && freeIntBlocks.size() > 0) {\n            freeIntBlocks.remove(freeIntBlocks.size()-1);\n            bytesUsed.addAndGet(-INT_BLOCK_SIZE * RamUsageEstimator.NUM_BYTES_INT);\n          }\n          if ((2 == iter % 4) && perDocAllocator.numBufferedBlocks() > 0) {\n            perDocAllocator.freeBlocks(32); // Remove upwards of 32 blocks (each block is 1K)\n          }\n        }\n\n        if ((3 == iter % 4) && any)\n          // Ask consumer to free any recycled state\n          any = consumer.freeRAM();\n\n        iter++;\n      }\n\n      if (infoStream != null)\n        message(\"    after free: freedMB=\" + nf.format((startBytesUsed-bytesUsed()-deletesRAMUsed)/1024./1024.) + \" usedMB=\" + nf.format((bytesUsed()+deletesRAMUsed)/1024./1024.));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ab5cb6a74aefb78aa0569857970b9151dfe2e787","date":1292842407,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/DocumentsWriter#balanceRAM().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/DocumentsWriter#balanceRAM().mjava","sourceNew":"  /* We have three pools of RAM: Postings, byte blocks\n   * (holds freq/prox posting data) and per-doc buffers\n   * (stored fields/term vectors).  Different docs require\n   * varying amount of storage from these classes.  For\n   * example, docs with many unique single-occurrence short\n   * terms will use up the Postings RAM and hardly any of\n   * the other two.  Whereas docs with very large terms will\n   * use alot of byte blocks RAM.  This method just frees\n   * allocations from the pools once we are over-budget,\n   * which balances the pools to match the current docs. */\n  void balanceRAM() {\n\n    final boolean doBalance;\n    final long deletesRAMUsed;\n\n    deletesRAMUsed = bufferedDeletes.bytesUsed();\n\n    synchronized(this) {\n      if (ramBufferSize == IndexWriterConfig.DISABLE_AUTO_FLUSH || bufferIsFull) {\n        return;\n      }\n    \n      doBalance = bytesUsed() + deletesRAMUsed >= ramBufferSize;\n    }\n\n    if (doBalance) {\n\n      if (infoStream != null) {\n        message(\"  RAM: balance allocations: usedMB=\" + toMB(bytesUsed()) +\n                \" vs trigger=\" + toMB(ramBufferSize) +\n                \" deletesMB=\" + toMB(deletesRAMUsed) +\n                \" byteBlockFree=\" + toMB(byteBlockAllocator.bytesUsed()) +\n                \" perDocFree=\" + toMB(perDocAllocator.bytesUsed()));\n      }\n\n      final long startBytesUsed = bytesUsed() + deletesRAMUsed;\n\n      int iter = 0;\n\n      // We free equally from each pool in 32 KB\n      // chunks until we are below our threshold\n      // (freeLevel)\n\n      boolean any = true;\n\n      while(bytesUsed()+deletesRAMUsed > freeLevel) {\n      \n        synchronized(this) {\n          if (0 == perDocAllocator.numBufferedBlocks() &&\n              0 == byteBlockAllocator.numBufferedBlocks() &&\n              0 == freeIntBlocks.size() && !any) {\n            // Nothing else to free -- must flush now.\n            bufferIsFull = bytesUsed()+deletesRAMUsed > ramBufferSize;\n            if (infoStream != null) {\n              if (bytesUsed()+deletesRAMUsed > ramBufferSize) {\n                message(\"    nothing to free; set bufferIsFull\");\n              } else {\n                message(\"    nothing to free\");\n              }\n            }\n            break;\n          }\n\n          if ((0 == iter % 4) && byteBlockAllocator.numBufferedBlocks() > 0) {\n            byteBlockAllocator.freeBlocks(1);\n          }\n          if ((1 == iter % 4) && freeIntBlocks.size() > 0) {\n            freeIntBlocks.remove(freeIntBlocks.size()-1);\n            bytesUsed.addAndGet(-INT_BLOCK_SIZE * RamUsageEstimator.NUM_BYTES_INT);\n          }\n          if ((2 == iter % 4) && perDocAllocator.numBufferedBlocks() > 0) {\n            perDocAllocator.freeBlocks(32); // Remove upwards of 32 blocks (each block is 1K)\n          }\n        }\n\n        if ((3 == iter % 4) && any) {\n          // Ask consumer to free any recycled state\n          any = consumer.freeRAM();\n        }\n\n        iter++;\n      }\n\n      if (infoStream != null) {\n        message(\"    after free: freedMB=\" + nf.format((startBytesUsed-bytesUsed()-deletesRAMUsed)/1024./1024.) + \" usedMB=\" + nf.format((bytesUsed()+deletesRAMUsed)/1024./1024.));\n      }\n    }\n  }\n\n","sourceOld":"  /* We have three pools of RAM: Postings, byte blocks\n   * (holds freq/prox posting data) and per-doc buffers\n   * (stored fields/term vectors).  Different docs require\n   * varying amount of storage from these classes.  For\n   * example, docs with many unique single-occurrence short\n   * terms will use up the Postings RAM and hardly any of\n   * the other two.  Whereas docs with very large terms will\n   * use alot of byte blocks RAM.  This method just frees\n   * allocations from the pools once we are over-budget,\n   * which balances the pools to match the current docs. */\n  void balanceRAM() {\n\n    final boolean doBalance;\n    final long deletesRAMUsed;\n\n    synchronized(this) {\n      if (ramBufferSize == IndexWriterConfig.DISABLE_AUTO_FLUSH || bufferIsFull) {\n        return;\n      }\n    \n      deletesRAMUsed = deletesInRAM.bytesUsed+deletesFlushed.bytesUsed;\n      doBalance = bytesUsed() +deletesRAMUsed >= ramBufferSize;\n    }\n\n    if (doBalance) {\n\n      if (infoStream != null)\n        message(\"  RAM: now balance allocations: usedMB=\" + toMB(bytesUsed()) +\n                \" vs trigger=\" + toMB(ramBufferSize) +\n                \" deletesMB=\" + toMB(deletesRAMUsed) +\n                \" byteBlockFree=\" + toMB(byteBlockAllocator.bytesUsed()) +\n                \" perDocFree=\" + toMB(perDocAllocator.bytesUsed()));\n\n      final long startBytesUsed = bytesUsed() + deletesRAMUsed;\n\n      int iter = 0;\n\n      // We free equally from each pool in 32 KB\n      // chunks until we are below our threshold\n      // (freeLevel)\n\n      boolean any = true;\n\n      while(bytesUsed()+deletesRAMUsed > freeLevel) {\n      \n        synchronized(this) {\n          if (0 == perDocAllocator.numBufferedBlocks() &&\n              0 == byteBlockAllocator.numBufferedBlocks() &&\n              0 == freeIntBlocks.size() && !any) {\n            // Nothing else to free -- must flush now.\n            bufferIsFull = bytesUsed()+deletesRAMUsed > ramBufferSize;\n            if (infoStream != null) {\n              if (bytesUsed()+deletesRAMUsed > ramBufferSize)\n                message(\"    nothing to free; now set bufferIsFull\");\n              else\n                message(\"    nothing to free\");\n            }\n            break;\n          }\n\n          if ((0 == iter % 4) && byteBlockAllocator.numBufferedBlocks() > 0) {\n            byteBlockAllocator.freeBlocks(1);\n          }\n          if ((1 == iter % 4) && freeIntBlocks.size() > 0) {\n            freeIntBlocks.remove(freeIntBlocks.size()-1);\n            bytesUsed.addAndGet(-INT_BLOCK_SIZE * INT_NUM_BYTE);\n          }\n          if ((2 == iter % 4) && perDocAllocator.numBufferedBlocks() > 0) {\n            perDocAllocator.freeBlocks(32); // Remove upwards of 32 blocks (each block is 1K)\n          }\n        }\n\n        if ((3 == iter % 4) && any)\n          // Ask consumer to free any recycled state\n          any = consumer.freeRAM();\n\n        iter++;\n      }\n\n      if (infoStream != null)\n        message(\"    after free: freedMB=\" + nf.format((startBytesUsed-bytesUsed()-deletesRAMUsed)/1024./1024.) + \" usedMB=\" + nf.format((bytesUsed()+deletesRAMUsed)/1024./1024.));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c19f985e36a65cc969e8e564fe337a0d41512075","date":1296330536,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/DocumentsWriter#balanceRAM().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/DocumentsWriter#balanceRAM().mjava","sourceNew":"  /* We have three pools of RAM: Postings, byte blocks\n   * (holds freq/prox posting data) and per-doc buffers\n   * (stored fields/term vectors).  Different docs require\n   * varying amount of storage from these classes.  For\n   * example, docs with many unique single-occurrence short\n   * terms will use up the Postings RAM and hardly any of\n   * the other two.  Whereas docs with very large terms will\n   * use alot of byte blocks RAM.  This method just frees\n   * allocations from the pools once we are over-budget,\n   * which balances the pools to match the current docs. */\n  void balanceRAM() {\n\n    final boolean doBalance;\n    final long deletesRAMUsed;\n\n    deletesRAMUsed = bufferedDeletesStream.bytesUsed();\n\n    synchronized(this) {\n      if (ramBufferSize == IndexWriterConfig.DISABLE_AUTO_FLUSH || bufferIsFull) {\n        return;\n      }\n    \n      doBalance = bytesUsed() + deletesRAMUsed >= ramBufferSize;\n    }\n\n    if (doBalance) {\n\n      if (infoStream != null) {\n        message(\"  RAM: balance allocations: usedMB=\" + toMB(bytesUsed()) +\n                \" vs trigger=\" + toMB(ramBufferSize) +\n                \" deletesMB=\" + toMB(deletesRAMUsed) +\n                \" byteBlockFree=\" + toMB(byteBlockAllocator.bytesUsed()) +\n                \" perDocFree=\" + toMB(perDocAllocator.bytesUsed()));\n      }\n\n      final long startBytesUsed = bytesUsed() + deletesRAMUsed;\n\n      int iter = 0;\n\n      // We free equally from each pool in 32 KB\n      // chunks until we are below our threshold\n      // (freeLevel)\n\n      boolean any = true;\n\n      while(bytesUsed()+deletesRAMUsed > freeLevel) {\n      \n        synchronized(this) {\n          if (0 == perDocAllocator.numBufferedBlocks() &&\n              0 == byteBlockAllocator.numBufferedBlocks() &&\n              0 == freeIntBlocks.size() && !any) {\n            // Nothing else to free -- must flush now.\n            bufferIsFull = bytesUsed()+deletesRAMUsed > ramBufferSize;\n            if (infoStream != null) {\n              if (bytesUsed()+deletesRAMUsed > ramBufferSize) {\n                message(\"    nothing to free; set bufferIsFull\");\n              } else {\n                message(\"    nothing to free\");\n              }\n            }\n            break;\n          }\n\n          if ((0 == iter % 4) && byteBlockAllocator.numBufferedBlocks() > 0) {\n            byteBlockAllocator.freeBlocks(1);\n          }\n          if ((1 == iter % 4) && freeIntBlocks.size() > 0) {\n            freeIntBlocks.remove(freeIntBlocks.size()-1);\n            bytesUsed.addAndGet(-INT_BLOCK_SIZE * RamUsageEstimator.NUM_BYTES_INT);\n          }\n          if ((2 == iter % 4) && perDocAllocator.numBufferedBlocks() > 0) {\n            perDocAllocator.freeBlocks(32); // Remove upwards of 32 blocks (each block is 1K)\n          }\n        }\n\n        if ((3 == iter % 4) && any) {\n          // Ask consumer to free any recycled state\n          any = consumer.freeRAM();\n        }\n\n        iter++;\n      }\n\n      if (infoStream != null) {\n        message(\"    after free: freedMB=\" + nf.format((startBytesUsed-bytesUsed()-deletesRAMUsed)/1024./1024.) + \" usedMB=\" + nf.format((bytesUsed()+deletesRAMUsed)/1024./1024.));\n      }\n    }\n  }\n\n","sourceOld":"  /* We have three pools of RAM: Postings, byte blocks\n   * (holds freq/prox posting data) and per-doc buffers\n   * (stored fields/term vectors).  Different docs require\n   * varying amount of storage from these classes.  For\n   * example, docs with many unique single-occurrence short\n   * terms will use up the Postings RAM and hardly any of\n   * the other two.  Whereas docs with very large terms will\n   * use alot of byte blocks RAM.  This method just frees\n   * allocations from the pools once we are over-budget,\n   * which balances the pools to match the current docs. */\n  void balanceRAM() {\n\n    final boolean doBalance;\n    final long deletesRAMUsed;\n\n    deletesRAMUsed = bufferedDeletes.bytesUsed();\n\n    synchronized(this) {\n      if (ramBufferSize == IndexWriterConfig.DISABLE_AUTO_FLUSH || bufferIsFull) {\n        return;\n      }\n    \n      doBalance = bytesUsed() + deletesRAMUsed >= ramBufferSize;\n    }\n\n    if (doBalance) {\n\n      if (infoStream != null) {\n        message(\"  RAM: balance allocations: usedMB=\" + toMB(bytesUsed()) +\n                \" vs trigger=\" + toMB(ramBufferSize) +\n                \" deletesMB=\" + toMB(deletesRAMUsed) +\n                \" byteBlockFree=\" + toMB(byteBlockAllocator.bytesUsed()) +\n                \" perDocFree=\" + toMB(perDocAllocator.bytesUsed()));\n      }\n\n      final long startBytesUsed = bytesUsed() + deletesRAMUsed;\n\n      int iter = 0;\n\n      // We free equally from each pool in 32 KB\n      // chunks until we are below our threshold\n      // (freeLevel)\n\n      boolean any = true;\n\n      while(bytesUsed()+deletesRAMUsed > freeLevel) {\n      \n        synchronized(this) {\n          if (0 == perDocAllocator.numBufferedBlocks() &&\n              0 == byteBlockAllocator.numBufferedBlocks() &&\n              0 == freeIntBlocks.size() && !any) {\n            // Nothing else to free -- must flush now.\n            bufferIsFull = bytesUsed()+deletesRAMUsed > ramBufferSize;\n            if (infoStream != null) {\n              if (bytesUsed()+deletesRAMUsed > ramBufferSize) {\n                message(\"    nothing to free; set bufferIsFull\");\n              } else {\n                message(\"    nothing to free\");\n              }\n            }\n            break;\n          }\n\n          if ((0 == iter % 4) && byteBlockAllocator.numBufferedBlocks() > 0) {\n            byteBlockAllocator.freeBlocks(1);\n          }\n          if ((1 == iter % 4) && freeIntBlocks.size() > 0) {\n            freeIntBlocks.remove(freeIntBlocks.size()-1);\n            bytesUsed.addAndGet(-INT_BLOCK_SIZE * RamUsageEstimator.NUM_BYTES_INT);\n          }\n          if ((2 == iter % 4) && perDocAllocator.numBufferedBlocks() > 0) {\n            perDocAllocator.freeBlocks(32); // Remove upwards of 32 blocks (each block is 1K)\n          }\n        }\n\n        if ((3 == iter % 4) && any) {\n          // Ask consumer to free any recycled state\n          any = consumer.freeRAM();\n        }\n\n        iter++;\n      }\n\n      if (infoStream != null) {\n        message(\"    after free: freedMB=\" + nf.format((startBytesUsed-bytesUsed()-deletesRAMUsed)/1024./1024.) + \" usedMB=\" + nf.format((bytesUsed()+deletesRAMUsed)/1024./1024.));\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"29ef99d61cda9641b6250bf9567329a6e65f901d","date":1297244127,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/DocumentsWriter#balanceRAM().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/DocumentsWriter#balanceRAM().mjava","sourceNew":"  /* We have three pools of RAM: Postings, byte blocks\n   * (holds freq/prox posting data) and per-doc buffers\n   * (stored fields/term vectors).  Different docs require\n   * varying amount of storage from these classes.  For\n   * example, docs with many unique single-occurrence short\n   * terms will use up the Postings RAM and hardly any of\n   * the other two.  Whereas docs with very large terms will\n   * use alot of byte blocks RAM.  This method just frees\n   * allocations from the pools once we are over-budget,\n   * which balances the pools to match the current docs. */\n  void balanceRAM() {\n\n    final boolean doBalance;\n    final long deletesRAMUsed;\n\n    deletesRAMUsed = bufferedDeletesStream.bytesUsed();\n\n    synchronized(this) {\n      if (ramBufferSize == IndexWriterConfig.DISABLE_AUTO_FLUSH || bufferIsFull) {\n        return;\n      }\n    \n      doBalance = bytesUsed() + deletesRAMUsed >= ramBufferSize;\n    }\n\n    if (doBalance) {\n\n      if (infoStream != null) {\n        message(\"  RAM: balance allocations: usedMB=\" + toMB(bytesUsed()) +\n                \" vs trigger=\" + toMB(ramBufferSize) +\n                \" deletesMB=\" + toMB(deletesRAMUsed) +\n                \" byteBlockFree=\" + toMB(byteBlockAllocator.bytesUsed()) +\n                \" perDocFree=\" + toMB(perDocAllocator.bytesUsed()));\n      }\n\n      final long startBytesUsed = bytesUsed() + deletesRAMUsed;\n\n      int iter = 0;\n\n      // We free equally from each pool in 32 KB\n      // chunks until we are below our threshold\n      // (freeLevel)\n\n      boolean any = true;\n\n      while(bytesUsed()+deletesRAMUsed > freeLevel) {\n      \n        synchronized(this) {\n          if (0 == perDocAllocator.numBufferedBlocks() &&\n              0 == byteBlockAllocator.numBufferedBlocks() &&\n              0 == freeIntBlocks.size() && !any) {\n            // Nothing else to free -- must flush now.\n            bufferIsFull = bytesUsed()+deletesRAMUsed > ramBufferSize;\n            if (infoStream != null) {\n              if (bytesUsed()+deletesRAMUsed > ramBufferSize) {\n                message(\"    nothing to free; set bufferIsFull\");\n              } else {\n                message(\"    nothing to free\");\n              }\n            }\n            break;\n          }\n\n          if ((0 == iter % 4) && byteBlockAllocator.numBufferedBlocks() > 0) {\n            byteBlockAllocator.freeBlocks(1);\n          }\n          if ((1 == iter % 4) && freeIntBlocks.size() > 0) {\n            freeIntBlocks.remove(freeIntBlocks.size()-1);\n            bytesUsed.addAndGet(-INT_BLOCK_SIZE * RamUsageEstimator.NUM_BYTES_INT);\n          }\n          if ((2 == iter % 4) && perDocAllocator.numBufferedBlocks() > 0) {\n            perDocAllocator.freeBlocks(32); // Remove upwards of 32 blocks (each block is 1K)\n          }\n        }\n\n        if ((3 == iter % 4) && any) {\n          // Ask consumer to free any recycled state\n          any = consumer.freeRAM();\n        }\n\n        iter++;\n      }\n\n      if (infoStream != null) {\n        message(\"    after free: freedMB=\" + nf.format((startBytesUsed-bytesUsed()-deletesRAMUsed)/1024./1024.) + \" usedMB=\" + nf.format((bytesUsed()+deletesRAMUsed)/1024./1024.));\n      }\n    }\n  }\n\n","sourceOld":"  /* We have three pools of RAM: Postings, byte blocks\n   * (holds freq/prox posting data) and per-doc buffers\n   * (stored fields/term vectors).  Different docs require\n   * varying amount of storage from these classes.  For\n   * example, docs with many unique single-occurrence short\n   * terms will use up the Postings RAM and hardly any of\n   * the other two.  Whereas docs with very large terms will\n   * use alot of byte blocks RAM.  This method just frees\n   * allocations from the pools once we are over-budget,\n   * which balances the pools to match the current docs. */\n  void balanceRAM() {\n\n    final boolean doBalance;\n    final long deletesRAMUsed;\n\n    deletesRAMUsed = bufferedDeletes.bytesUsed();\n\n    synchronized(this) {\n      if (ramBufferSize == IndexWriterConfig.DISABLE_AUTO_FLUSH || bufferIsFull) {\n        return;\n      }\n    \n      doBalance = bytesUsed() + deletesRAMUsed >= ramBufferSize;\n    }\n\n    if (doBalance) {\n\n      if (infoStream != null) {\n        message(\"  RAM: balance allocations: usedMB=\" + toMB(bytesUsed()) +\n                \" vs trigger=\" + toMB(ramBufferSize) +\n                \" deletesMB=\" + toMB(deletesRAMUsed) +\n                \" byteBlockFree=\" + toMB(byteBlockAllocator.bytesUsed()) +\n                \" perDocFree=\" + toMB(perDocAllocator.bytesUsed()));\n      }\n\n      final long startBytesUsed = bytesUsed() + deletesRAMUsed;\n\n      int iter = 0;\n\n      // We free equally from each pool in 32 KB\n      // chunks until we are below our threshold\n      // (freeLevel)\n\n      boolean any = true;\n\n      while(bytesUsed()+deletesRAMUsed > freeLevel) {\n      \n        synchronized(this) {\n          if (0 == perDocAllocator.numBufferedBlocks() &&\n              0 == byteBlockAllocator.numBufferedBlocks() &&\n              0 == freeIntBlocks.size() && !any) {\n            // Nothing else to free -- must flush now.\n            bufferIsFull = bytesUsed()+deletesRAMUsed > ramBufferSize;\n            if (infoStream != null) {\n              if (bytesUsed()+deletesRAMUsed > ramBufferSize) {\n                message(\"    nothing to free; set bufferIsFull\");\n              } else {\n                message(\"    nothing to free\");\n              }\n            }\n            break;\n          }\n\n          if ((0 == iter % 4) && byteBlockAllocator.numBufferedBlocks() > 0) {\n            byteBlockAllocator.freeBlocks(1);\n          }\n          if ((1 == iter % 4) && freeIntBlocks.size() > 0) {\n            freeIntBlocks.remove(freeIntBlocks.size()-1);\n            bytesUsed.addAndGet(-INT_BLOCK_SIZE * RamUsageEstimator.NUM_BYTES_INT);\n          }\n          if ((2 == iter % 4) && perDocAllocator.numBufferedBlocks() > 0) {\n            perDocAllocator.freeBlocks(32); // Remove upwards of 32 blocks (each block is 1K)\n          }\n        }\n\n        if ((3 == iter % 4) && any) {\n          // Ask consumer to free any recycled state\n          any = consumer.freeRAM();\n        }\n\n        iter++;\n      }\n\n      if (infoStream != null) {\n        message(\"    after free: freedMB=\" + nf.format((startBytesUsed-bytesUsed()-deletesRAMUsed)/1024./1024.) + \" usedMB=\" + nf.format((bytesUsed()+deletesRAMUsed)/1024./1024.));\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"00b21520fafb9860ce0318d7be5ea84619c185ad","date":1300444600,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/DocumentsWriter#balanceRAM().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/DocumentsWriter#balanceRAM().mjava","sourceNew":"  /* We have three pools of RAM: Postings, byte blocks\n   * (holds freq/prox posting data) and per-doc buffers\n   * (stored fields/term vectors).  Different docs require\n   * varying amount of storage from these classes.  For\n   * example, docs with many unique single-occurrence short\n   * terms will use up the Postings RAM and hardly any of\n   * the other two.  Whereas docs with very large terms will\n   * use alot of byte blocks RAM.  This method just frees\n   * allocations from the pools once we are over-budget,\n   * which balances the pools to match the current docs. */\n  void balanceRAM() {\n\n    final boolean doBalance;\n    final long deletesRAMUsed;\n\n    deletesRAMUsed = bufferedDeletesStream.bytesUsed();\n\n    final long ramBufferSize;\n    final double mb = config.getRAMBufferSizeMB();\n    if (mb == IndexWriterConfig.DISABLE_AUTO_FLUSH) {\n      ramBufferSize = IndexWriterConfig.DISABLE_AUTO_FLUSH;\n    } else {\n      ramBufferSize = (long) (mb*1024*1024);\n    }\n\n    synchronized(this) {\n      if (ramBufferSize == IndexWriterConfig.DISABLE_AUTO_FLUSH || bufferIsFull) {\n        return;\n      }\n    \n      doBalance = bytesUsed() + deletesRAMUsed >= ramBufferSize;\n    }\n\n    if (doBalance) {\n\n      if (infoStream != null) {\n        message(\"  RAM: balance allocations: usedMB=\" + toMB(bytesUsed()) +\n                \" vs trigger=\" + toMB(ramBufferSize) +\n                \" deletesMB=\" + toMB(deletesRAMUsed) +\n                \" byteBlockFree=\" + toMB(byteBlockAllocator.bytesUsed()) +\n                \" perDocFree=\" + toMB(perDocAllocator.bytesUsed()));\n      }\n\n      final long startBytesUsed = bytesUsed() + deletesRAMUsed;\n\n      int iter = 0;\n\n      // We free equally from each pool in 32 KB\n      // chunks until we are below our threshold\n      // (freeLevel)\n\n      boolean any = true;\n\n      final long freeLevel = (long) (0.95 * ramBufferSize);\n\n      while(bytesUsed()+deletesRAMUsed > freeLevel) {\n      \n        synchronized(this) {\n          if (0 == perDocAllocator.numBufferedBlocks() &&\n              0 == byteBlockAllocator.numBufferedBlocks() &&\n              0 == freeIntBlocks.size() && !any) {\n            // Nothing else to free -- must flush now.\n            bufferIsFull = bytesUsed()+deletesRAMUsed > ramBufferSize;\n            if (infoStream != null) {\n              if (bytesUsed()+deletesRAMUsed > ramBufferSize) {\n                message(\"    nothing to free; set bufferIsFull\");\n              } else {\n                message(\"    nothing to free\");\n              }\n            }\n            break;\n          }\n\n          if ((0 == iter % 4) && byteBlockAllocator.numBufferedBlocks() > 0) {\n            byteBlockAllocator.freeBlocks(1);\n          }\n          if ((1 == iter % 4) && freeIntBlocks.size() > 0) {\n            freeIntBlocks.remove(freeIntBlocks.size()-1);\n            bytesUsed.addAndGet(-INT_BLOCK_SIZE * RamUsageEstimator.NUM_BYTES_INT);\n          }\n          if ((2 == iter % 4) && perDocAllocator.numBufferedBlocks() > 0) {\n            perDocAllocator.freeBlocks(32); // Remove upwards of 32 blocks (each block is 1K)\n          }\n        }\n\n        if ((3 == iter % 4) && any) {\n          // Ask consumer to free any recycled state\n          any = consumer.freeRAM();\n        }\n\n        iter++;\n      }\n\n      if (infoStream != null) {\n        message(\"    after free: freedMB=\" + nf.format((startBytesUsed-bytesUsed()-deletesRAMUsed)/1024./1024.) + \" usedMB=\" + nf.format((bytesUsed()+deletesRAMUsed)/1024./1024.));\n      }\n    }\n  }\n\n","sourceOld":"  /* We have three pools of RAM: Postings, byte blocks\n   * (holds freq/prox posting data) and per-doc buffers\n   * (stored fields/term vectors).  Different docs require\n   * varying amount of storage from these classes.  For\n   * example, docs with many unique single-occurrence short\n   * terms will use up the Postings RAM and hardly any of\n   * the other two.  Whereas docs with very large terms will\n   * use alot of byte blocks RAM.  This method just frees\n   * allocations from the pools once we are over-budget,\n   * which balances the pools to match the current docs. */\n  void balanceRAM() {\n\n    final boolean doBalance;\n    final long deletesRAMUsed;\n\n    deletesRAMUsed = bufferedDeletesStream.bytesUsed();\n\n    synchronized(this) {\n      if (ramBufferSize == IndexWriterConfig.DISABLE_AUTO_FLUSH || bufferIsFull) {\n        return;\n      }\n    \n      doBalance = bytesUsed() + deletesRAMUsed >= ramBufferSize;\n    }\n\n    if (doBalance) {\n\n      if (infoStream != null) {\n        message(\"  RAM: balance allocations: usedMB=\" + toMB(bytesUsed()) +\n                \" vs trigger=\" + toMB(ramBufferSize) +\n                \" deletesMB=\" + toMB(deletesRAMUsed) +\n                \" byteBlockFree=\" + toMB(byteBlockAllocator.bytesUsed()) +\n                \" perDocFree=\" + toMB(perDocAllocator.bytesUsed()));\n      }\n\n      final long startBytesUsed = bytesUsed() + deletesRAMUsed;\n\n      int iter = 0;\n\n      // We free equally from each pool in 32 KB\n      // chunks until we are below our threshold\n      // (freeLevel)\n\n      boolean any = true;\n\n      while(bytesUsed()+deletesRAMUsed > freeLevel) {\n      \n        synchronized(this) {\n          if (0 == perDocAllocator.numBufferedBlocks() &&\n              0 == byteBlockAllocator.numBufferedBlocks() &&\n              0 == freeIntBlocks.size() && !any) {\n            // Nothing else to free -- must flush now.\n            bufferIsFull = bytesUsed()+deletesRAMUsed > ramBufferSize;\n            if (infoStream != null) {\n              if (bytesUsed()+deletesRAMUsed > ramBufferSize) {\n                message(\"    nothing to free; set bufferIsFull\");\n              } else {\n                message(\"    nothing to free\");\n              }\n            }\n            break;\n          }\n\n          if ((0 == iter % 4) && byteBlockAllocator.numBufferedBlocks() > 0) {\n            byteBlockAllocator.freeBlocks(1);\n          }\n          if ((1 == iter % 4) && freeIntBlocks.size() > 0) {\n            freeIntBlocks.remove(freeIntBlocks.size()-1);\n            bytesUsed.addAndGet(-INT_BLOCK_SIZE * RamUsageEstimator.NUM_BYTES_INT);\n          }\n          if ((2 == iter % 4) && perDocAllocator.numBufferedBlocks() > 0) {\n            perDocAllocator.freeBlocks(32); // Remove upwards of 32 blocks (each block is 1K)\n          }\n        }\n\n        if ((3 == iter % 4) && any) {\n          // Ask consumer to free any recycled state\n          any = consumer.freeRAM();\n        }\n\n        iter++;\n      }\n\n      if (infoStream != null) {\n        message(\"    after free: freedMB=\" + nf.format((startBytesUsed-bytesUsed()-deletesRAMUsed)/1024./1024.) + \" usedMB=\" + nf.format((bytesUsed()+deletesRAMUsed)/1024./1024.));\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d619839baa8ce5503e496b94a9e42ad6f079293f","date":1301309428,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/DocumentsWriter#balanceRAM().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/DocumentsWriter#balanceRAM().mjava","sourceNew":"  /* We have three pools of RAM: Postings, byte blocks\n   * (holds freq/prox posting data) and per-doc buffers\n   * (stored fields/term vectors).  Different docs require\n   * varying amount of storage from these classes.  For\n   * example, docs with many unique single-occurrence short\n   * terms will use up the Postings RAM and hardly any of\n   * the other two.  Whereas docs with very large terms will\n   * use alot of byte blocks RAM.  This method just frees\n   * allocations from the pools once we are over-budget,\n   * which balances the pools to match the current docs. */\n  void balanceRAM() {\n\n    final boolean doBalance;\n    final long deletesRAMUsed;\n\n    deletesRAMUsed = bufferedDeletesStream.bytesUsed();\n\n    final long ramBufferSize;\n    final double mb = config.getRAMBufferSizeMB();\n    if (mb == IndexWriterConfig.DISABLE_AUTO_FLUSH) {\n      ramBufferSize = IndexWriterConfig.DISABLE_AUTO_FLUSH;\n    } else {\n      ramBufferSize = (long) (mb*1024*1024);\n    }\n\n    synchronized(this) {\n      if (ramBufferSize == IndexWriterConfig.DISABLE_AUTO_FLUSH || bufferIsFull) {\n        return;\n      }\n    \n      doBalance = bytesUsed() + deletesRAMUsed >= ramBufferSize;\n    }\n\n    if (doBalance) {\n\n      if (infoStream != null) {\n        message(\"  RAM: balance allocations: usedMB=\" + toMB(bytesUsed()) +\n                \" vs trigger=\" + toMB(ramBufferSize) +\n                \" deletesMB=\" + toMB(deletesRAMUsed) +\n                \" byteBlockFree=\" + toMB(byteBlockAllocator.bytesUsed()) +\n                \" perDocFree=\" + toMB(perDocAllocator.bytesUsed()));\n      }\n\n      final long startBytesUsed = bytesUsed() + deletesRAMUsed;\n\n      int iter = 0;\n\n      // We free equally from each pool in 32 KB\n      // chunks until we are below our threshold\n      // (freeLevel)\n\n      boolean any = true;\n\n      final long freeLevel = (long) (0.95 * ramBufferSize);\n\n      while(bytesUsed()+deletesRAMUsed > freeLevel) {\n      \n        synchronized(this) {\n          if (0 == perDocAllocator.numBufferedBlocks() &&\n              0 == byteBlockAllocator.numBufferedBlocks() &&\n              0 == freeIntBlocks.size() && !any) {\n            // Nothing else to free -- must flush now.\n            bufferIsFull = bytesUsed()+deletesRAMUsed > ramBufferSize;\n            if (infoStream != null) {\n              if (bytesUsed()+deletesRAMUsed > ramBufferSize) {\n                message(\"    nothing to free; set bufferIsFull\");\n              } else {\n                message(\"    nothing to free\");\n              }\n            }\n            break;\n          }\n\n          if ((0 == iter % 4) && byteBlockAllocator.numBufferedBlocks() > 0) {\n            byteBlockAllocator.freeBlocks(1);\n          }\n          if ((1 == iter % 4) && freeIntBlocks.size() > 0) {\n            freeIntBlocks.remove(freeIntBlocks.size()-1);\n            bytesUsed.addAndGet(-INT_BLOCK_SIZE * RamUsageEstimator.NUM_BYTES_INT);\n          }\n          if ((2 == iter % 4) && perDocAllocator.numBufferedBlocks() > 0) {\n            perDocAllocator.freeBlocks(32); // Remove upwards of 32 blocks (each block is 1K)\n          }\n        }\n\n        if ((3 == iter % 4) && any) {\n          // Ask consumer to free any recycled state\n          any = consumer.freeRAM();\n        }\n\n        iter++;\n      }\n\n      if (infoStream != null) {\n        message(\"    after free: freedMB=\" + nf.format((startBytesUsed-bytesUsed()-deletesRAMUsed)/1024./1024.) + \" usedMB=\" + nf.format((bytesUsed()+deletesRAMUsed)/1024./1024.));\n      }\n    }\n  }\n\n","sourceOld":"  /* We have three pools of RAM: Postings, byte blocks\n   * (holds freq/prox posting data) and per-doc buffers\n   * (stored fields/term vectors).  Different docs require\n   * varying amount of storage from these classes.  For\n   * example, docs with many unique single-occurrence short\n   * terms will use up the Postings RAM and hardly any of\n   * the other two.  Whereas docs with very large terms will\n   * use alot of byte blocks RAM.  This method just frees\n   * allocations from the pools once we are over-budget,\n   * which balances the pools to match the current docs. */\n  void balanceRAM() {\n\n    final boolean doBalance;\n    final long deletesRAMUsed;\n\n    deletesRAMUsed = bufferedDeletesStream.bytesUsed();\n\n    synchronized(this) {\n      if (ramBufferSize == IndexWriterConfig.DISABLE_AUTO_FLUSH || bufferIsFull) {\n        return;\n      }\n    \n      doBalance = bytesUsed() + deletesRAMUsed >= ramBufferSize;\n    }\n\n    if (doBalance) {\n\n      if (infoStream != null) {\n        message(\"  RAM: balance allocations: usedMB=\" + toMB(bytesUsed()) +\n                \" vs trigger=\" + toMB(ramBufferSize) +\n                \" deletesMB=\" + toMB(deletesRAMUsed) +\n                \" byteBlockFree=\" + toMB(byteBlockAllocator.bytesUsed()) +\n                \" perDocFree=\" + toMB(perDocAllocator.bytesUsed()));\n      }\n\n      final long startBytesUsed = bytesUsed() + deletesRAMUsed;\n\n      int iter = 0;\n\n      // We free equally from each pool in 32 KB\n      // chunks until we are below our threshold\n      // (freeLevel)\n\n      boolean any = true;\n\n      while(bytesUsed()+deletesRAMUsed > freeLevel) {\n      \n        synchronized(this) {\n          if (0 == perDocAllocator.numBufferedBlocks() &&\n              0 == byteBlockAllocator.numBufferedBlocks() &&\n              0 == freeIntBlocks.size() && !any) {\n            // Nothing else to free -- must flush now.\n            bufferIsFull = bytesUsed()+deletesRAMUsed > ramBufferSize;\n            if (infoStream != null) {\n              if (bytesUsed()+deletesRAMUsed > ramBufferSize) {\n                message(\"    nothing to free; set bufferIsFull\");\n              } else {\n                message(\"    nothing to free\");\n              }\n            }\n            break;\n          }\n\n          if ((0 == iter % 4) && byteBlockAllocator.numBufferedBlocks() > 0) {\n            byteBlockAllocator.freeBlocks(1);\n          }\n          if ((1 == iter % 4) && freeIntBlocks.size() > 0) {\n            freeIntBlocks.remove(freeIntBlocks.size()-1);\n            bytesUsed.addAndGet(-INT_BLOCK_SIZE * RamUsageEstimator.NUM_BYTES_INT);\n          }\n          if ((2 == iter % 4) && perDocAllocator.numBufferedBlocks() > 0) {\n            perDocAllocator.freeBlocks(32); // Remove upwards of 32 blocks (each block is 1K)\n          }\n        }\n\n        if ((3 == iter % 4) && any) {\n          // Ask consumer to free any recycled state\n          any = consumer.freeRAM();\n        }\n\n        iter++;\n      }\n\n      if (infoStream != null) {\n        message(\"    after free: freedMB=\" + nf.format((startBytesUsed-bytesUsed()-deletesRAMUsed)/1024./1024.) + \" usedMB=\" + nf.format((bytesUsed()+deletesRAMUsed)/1024./1024.));\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b3e06be49006ecac364d39d12b9c9f74882f9b9f","date":1304289513,"type":4,"author":"Uwe Schindler","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/src/java/org/apache/lucene/index/DocumentsWriter#balanceRAM().mjava","sourceNew":null,"sourceOld":"  /* We have three pools of RAM: Postings, byte blocks\n   * (holds freq/prox posting data) and per-doc buffers\n   * (stored fields/term vectors).  Different docs require\n   * varying amount of storage from these classes.  For\n   * example, docs with many unique single-occurrence short\n   * terms will use up the Postings RAM and hardly any of\n   * the other two.  Whereas docs with very large terms will\n   * use alot of byte blocks RAM.  This method just frees\n   * allocations from the pools once we are over-budget,\n   * which balances the pools to match the current docs. */\n  void balanceRAM() {\n\n    final boolean doBalance;\n    final long deletesRAMUsed;\n\n    deletesRAMUsed = bufferedDeletesStream.bytesUsed();\n\n    final long ramBufferSize;\n    final double mb = config.getRAMBufferSizeMB();\n    if (mb == IndexWriterConfig.DISABLE_AUTO_FLUSH) {\n      ramBufferSize = IndexWriterConfig.DISABLE_AUTO_FLUSH;\n    } else {\n      ramBufferSize = (long) (mb*1024*1024);\n    }\n\n    synchronized(this) {\n      if (ramBufferSize == IndexWriterConfig.DISABLE_AUTO_FLUSH || bufferIsFull) {\n        return;\n      }\n    \n      doBalance = bytesUsed() + deletesRAMUsed >= ramBufferSize;\n    }\n\n    if (doBalance) {\n\n      if (infoStream != null) {\n        message(\"  RAM: balance allocations: usedMB=\" + toMB(bytesUsed()) +\n                \" vs trigger=\" + toMB(ramBufferSize) +\n                \" deletesMB=\" + toMB(deletesRAMUsed) +\n                \" byteBlockFree=\" + toMB(byteBlockAllocator.bytesUsed()) +\n                \" perDocFree=\" + toMB(perDocAllocator.bytesUsed()));\n      }\n\n      final long startBytesUsed = bytesUsed() + deletesRAMUsed;\n\n      int iter = 0;\n\n      // We free equally from each pool in 32 KB\n      // chunks until we are below our threshold\n      // (freeLevel)\n\n      boolean any = true;\n\n      final long freeLevel = (long) (0.95 * ramBufferSize);\n\n      while(bytesUsed()+deletesRAMUsed > freeLevel) {\n      \n        synchronized(this) {\n          if (0 == perDocAllocator.numBufferedBlocks() &&\n              0 == byteBlockAllocator.numBufferedBlocks() &&\n              0 == freeIntBlocks.size() && !any) {\n            // Nothing else to free -- must flush now.\n            bufferIsFull = bytesUsed()+deletesRAMUsed > ramBufferSize;\n            if (infoStream != null) {\n              if (bytesUsed()+deletesRAMUsed > ramBufferSize) {\n                message(\"    nothing to free; set bufferIsFull\");\n              } else {\n                message(\"    nothing to free\");\n              }\n            }\n            break;\n          }\n\n          if ((0 == iter % 4) && byteBlockAllocator.numBufferedBlocks() > 0) {\n            byteBlockAllocator.freeBlocks(1);\n          }\n          if ((1 == iter % 4) && freeIntBlocks.size() > 0) {\n            freeIntBlocks.remove(freeIntBlocks.size()-1);\n            bytesUsed.addAndGet(-INT_BLOCK_SIZE * RamUsageEstimator.NUM_BYTES_INT);\n          }\n          if ((2 == iter % 4) && perDocAllocator.numBufferedBlocks() > 0) {\n            perDocAllocator.freeBlocks(32); // Remove upwards of 32 blocks (each block is 1K)\n          }\n        }\n\n        if ((3 == iter % 4) && any) {\n          // Ask consumer to free any recycled state\n          any = consumer.freeRAM();\n        }\n\n        iter++;\n      }\n\n      if (infoStream != null) {\n        message(\"    after free: freedMB=\" + nf.format((startBytesUsed-bytesUsed()-deletesRAMUsed)/1024./1024.) + \" usedMB=\" + nf.format((bytesUsed()+deletesRAMUsed)/1024./1024.));\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"135621f3a0670a9394eb563224a3b76cc4dddc0f","date":1304344257,"type":4,"author":"Simon Willnauer","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/src/java/org/apache/lucene/index/DocumentsWriter#balanceRAM().mjava","sourceNew":null,"sourceOld":"  /* We have three pools of RAM: Postings, byte blocks\n   * (holds freq/prox posting data) and per-doc buffers\n   * (stored fields/term vectors).  Different docs require\n   * varying amount of storage from these classes.  For\n   * example, docs with many unique single-occurrence short\n   * terms will use up the Postings RAM and hardly any of\n   * the other two.  Whereas docs with very large terms will\n   * use alot of byte blocks RAM.  This method just frees\n   * allocations from the pools once we are over-budget,\n   * which balances the pools to match the current docs. */\n  void balanceRAM() {\n\n    final boolean doBalance;\n    final long deletesRAMUsed;\n\n    deletesRAMUsed = bufferedDeletesStream.bytesUsed();\n\n    final long ramBufferSize;\n    final double mb = config.getRAMBufferSizeMB();\n    if (mb == IndexWriterConfig.DISABLE_AUTO_FLUSH) {\n      ramBufferSize = IndexWriterConfig.DISABLE_AUTO_FLUSH;\n    } else {\n      ramBufferSize = (long) (mb*1024*1024);\n    }\n\n    synchronized(this) {\n      if (ramBufferSize == IndexWriterConfig.DISABLE_AUTO_FLUSH || bufferIsFull) {\n        return;\n      }\n    \n      doBalance = bytesUsed() + deletesRAMUsed >= ramBufferSize;\n    }\n\n    if (doBalance) {\n\n      if (infoStream != null) {\n        message(\"  RAM: balance allocations: usedMB=\" + toMB(bytesUsed()) +\n                \" vs trigger=\" + toMB(ramBufferSize) +\n                \" deletesMB=\" + toMB(deletesRAMUsed) +\n                \" byteBlockFree=\" + toMB(byteBlockAllocator.bytesUsed()) +\n                \" perDocFree=\" + toMB(perDocAllocator.bytesUsed()));\n      }\n\n      final long startBytesUsed = bytesUsed() + deletesRAMUsed;\n\n      int iter = 0;\n\n      // We free equally from each pool in 32 KB\n      // chunks until we are below our threshold\n      // (freeLevel)\n\n      boolean any = true;\n\n      final long freeLevel = (long) (0.95 * ramBufferSize);\n\n      while(bytesUsed()+deletesRAMUsed > freeLevel) {\n      \n        synchronized(this) {\n          if (0 == perDocAllocator.numBufferedBlocks() &&\n              0 == byteBlockAllocator.numBufferedBlocks() &&\n              0 == freeIntBlocks.size() && !any) {\n            // Nothing else to free -- must flush now.\n            bufferIsFull = bytesUsed()+deletesRAMUsed > ramBufferSize;\n            if (infoStream != null) {\n              if (bytesUsed()+deletesRAMUsed > ramBufferSize) {\n                message(\"    nothing to free; set bufferIsFull\");\n              } else {\n                message(\"    nothing to free\");\n              }\n            }\n            break;\n          }\n\n          if ((0 == iter % 4) && byteBlockAllocator.numBufferedBlocks() > 0) {\n            byteBlockAllocator.freeBlocks(1);\n          }\n          if ((1 == iter % 4) && freeIntBlocks.size() > 0) {\n            freeIntBlocks.remove(freeIntBlocks.size()-1);\n            bytesUsed.addAndGet(-INT_BLOCK_SIZE * RamUsageEstimator.NUM_BYTES_INT);\n          }\n          if ((2 == iter % 4) && perDocAllocator.numBufferedBlocks() > 0) {\n            perDocAllocator.freeBlocks(32); // Remove upwards of 32 blocks (each block is 1K)\n          }\n        }\n\n        if ((3 == iter % 4) && any) {\n          // Ask consumer to free any recycled state\n          any = consumer.freeRAM();\n        }\n\n        iter++;\n      }\n\n      if (infoStream != null) {\n        message(\"    after free: freedMB=\" + nf.format((startBytesUsed-bytesUsed()-deletesRAMUsed)/1024./1024.) + \" usedMB=\" + nf.format((bytesUsed()+deletesRAMUsed)/1024./1024.));\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":4,"author":"Steven Rowe","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/src/java/org/apache/lucene/index/DocumentsWriter#balanceRAM().mjava","sourceNew":null,"sourceOld":"  /* We have three pools of RAM: Postings, byte blocks\n   * (holds freq/prox posting data) and per-doc buffers\n   * (stored fields/term vectors).  Different docs require\n   * varying amount of storage from these classes.  For\n   * example, docs with many unique single-occurrence short\n   * terms will use up the Postings RAM and hardly any of\n   * the other two.  Whereas docs with very large terms will\n   * use alot of byte blocks RAM.  This method just frees\n   * allocations from the pools once we are over-budget,\n   * which balances the pools to match the current docs. */\n  void balanceRAM() {\n\n    final boolean doBalance;\n    final long deletesRAMUsed;\n\n    deletesRAMUsed = bufferedDeletesStream.bytesUsed();\n\n    final long ramBufferSize;\n    final double mb = config.getRAMBufferSizeMB();\n    if (mb == IndexWriterConfig.DISABLE_AUTO_FLUSH) {\n      ramBufferSize = IndexWriterConfig.DISABLE_AUTO_FLUSH;\n    } else {\n      ramBufferSize = (long) (mb*1024*1024);\n    }\n\n    synchronized(this) {\n      if (ramBufferSize == IndexWriterConfig.DISABLE_AUTO_FLUSH || bufferIsFull) {\n        return;\n      }\n    \n      doBalance = bytesUsed() + deletesRAMUsed >= ramBufferSize;\n    }\n\n    if (doBalance) {\n\n      if (infoStream != null) {\n        message(\"  RAM: balance allocations: usedMB=\" + toMB(bytesUsed()) +\n                \" vs trigger=\" + toMB(ramBufferSize) +\n                \" deletesMB=\" + toMB(deletesRAMUsed) +\n                \" byteBlockFree=\" + toMB(byteBlockAllocator.bytesUsed()) +\n                \" perDocFree=\" + toMB(perDocAllocator.bytesUsed()));\n      }\n\n      final long startBytesUsed = bytesUsed() + deletesRAMUsed;\n\n      int iter = 0;\n\n      // We free equally from each pool in 32 KB\n      // chunks until we are below our threshold\n      // (freeLevel)\n\n      boolean any = true;\n\n      final long freeLevel = (long) (0.95 * ramBufferSize);\n\n      while(bytesUsed()+deletesRAMUsed > freeLevel) {\n      \n        synchronized(this) {\n          if (0 == perDocAllocator.numBufferedBlocks() &&\n              0 == byteBlockAllocator.numBufferedBlocks() &&\n              0 == freeIntBlocks.size() && !any) {\n            // Nothing else to free -- must flush now.\n            bufferIsFull = bytesUsed()+deletesRAMUsed > ramBufferSize;\n            if (infoStream != null) {\n              if (bytesUsed()+deletesRAMUsed > ramBufferSize) {\n                message(\"    nothing to free; set bufferIsFull\");\n              } else {\n                message(\"    nothing to free\");\n              }\n            }\n            break;\n          }\n\n          if ((0 == iter % 4) && byteBlockAllocator.numBufferedBlocks() > 0) {\n            byteBlockAllocator.freeBlocks(1);\n          }\n          if ((1 == iter % 4) && freeIntBlocks.size() > 0) {\n            freeIntBlocks.remove(freeIntBlocks.size()-1);\n            bytesUsed.addAndGet(-INT_BLOCK_SIZE * RamUsageEstimator.NUM_BYTES_INT);\n          }\n          if ((2 == iter % 4) && perDocAllocator.numBufferedBlocks() > 0) {\n            perDocAllocator.freeBlocks(32); // Remove upwards of 32 blocks (each block is 1K)\n          }\n        }\n\n        if ((3 == iter % 4) && any) {\n          // Ask consumer to free any recycled state\n          any = consumer.freeRAM();\n        }\n\n        iter++;\n      }\n\n      if (infoStream != null) {\n        message(\"    after free: freedMB=\" + nf.format((startBytesUsed-bytesUsed()-deletesRAMUsed)/1024./1024.) + \" usedMB=\" + nf.format((bytesUsed()+deletesRAMUsed)/1024./1024.));\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"44fcbde6fb2ac44ee3b45e013e54a42911e689ff":["5d6c52f55ea3ba9a5b1d5a6dd17f79bc7d308392"],"5d6c52f55ea3ba9a5b1d5a6dd17f79bc7d308392":["334c1175813aea771a71728cd2c4ee4754fd0603"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["d619839baa8ce5503e496b94a9e42ad6f079293f","b3e06be49006ecac364d39d12b9c9f74882f9b9f"],"955c32f886db6f6356c9fcdea6b1f1cb4effda24":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"b3e06be49006ecac364d39d12b9c9f74882f9b9f":["00b21520fafb9860ce0318d7be5ea84619c185ad","8fe956d65251358d755c56f14fe8380644790e47"],"ab5cb6a74aefb78aa0569857970b9151dfe2e787":["5d6c52f55ea3ba9a5b1d5a6dd17f79bc7d308392","4948bc5d29211f0c9b5ccc31b2632cdd27066ea5"],"334c1175813aea771a71728cd2c4ee4754fd0603":["9b832cbed6eb3d54a8bb9339296bdda8eeb53014"],"00b21520fafb9860ce0318d7be5ea84619c185ad":["c19f985e36a65cc969e8e564fe337a0d41512075"],"9b832cbed6eb3d54a8bb9339296bdda8eeb53014":["f58dd714e47e4b20e7ddf69802a24d8278a50d3d"],"c19f985e36a65cc969e8e564fe337a0d41512075":["4948bc5d29211f0c9b5ccc31b2632cdd27066ea5"],"f58dd714e47e4b20e7ddf69802a24d8278a50d3d":["955c32f886db6f6356c9fcdea6b1f1cb4effda24"],"d619839baa8ce5503e496b94a9e42ad6f079293f":["29ef99d61cda9641b6250bf9567329a6e65f901d","00b21520fafb9860ce0318d7be5ea84619c185ad"],"a3776dccca01c11e7046323cfad46a3b4a471233":["00b21520fafb9860ce0318d7be5ea84619c185ad","b3e06be49006ecac364d39d12b9c9f74882f9b9f"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["ab5cb6a74aefb78aa0569857970b9151dfe2e787","c19f985e36a65cc969e8e564fe337a0d41512075"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"8fe956d65251358d755c56f14fe8380644790e47":["f58dd714e47e4b20e7ddf69802a24d8278a50d3d"],"4948bc5d29211f0c9b5ccc31b2632cdd27066ea5":["44fcbde6fb2ac44ee3b45e013e54a42911e689ff"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b3e06be49006ecac364d39d12b9c9f74882f9b9f"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"44fcbde6fb2ac44ee3b45e013e54a42911e689ff":["4948bc5d29211f0c9b5ccc31b2632cdd27066ea5"],"5d6c52f55ea3ba9a5b1d5a6dd17f79bc7d308392":["44fcbde6fb2ac44ee3b45e013e54a42911e689ff","ab5cb6a74aefb78aa0569857970b9151dfe2e787"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":[],"b3e06be49006ecac364d39d12b9c9f74882f9b9f":["135621f3a0670a9394eb563224a3b76cc4dddc0f","a3776dccca01c11e7046323cfad46a3b4a471233","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"955c32f886db6f6356c9fcdea6b1f1cb4effda24":["f58dd714e47e4b20e7ddf69802a24d8278a50d3d"],"ab5cb6a74aefb78aa0569857970b9151dfe2e787":["29ef99d61cda9641b6250bf9567329a6e65f901d"],"334c1175813aea771a71728cd2c4ee4754fd0603":["5d6c52f55ea3ba9a5b1d5a6dd17f79bc7d308392"],"00b21520fafb9860ce0318d7be5ea84619c185ad":["b3e06be49006ecac364d39d12b9c9f74882f9b9f","d619839baa8ce5503e496b94a9e42ad6f079293f","a3776dccca01c11e7046323cfad46a3b4a471233"],"9b832cbed6eb3d54a8bb9339296bdda8eeb53014":["334c1175813aea771a71728cd2c4ee4754fd0603"],"c19f985e36a65cc969e8e564fe337a0d41512075":["00b21520fafb9860ce0318d7be5ea84619c185ad","29ef99d61cda9641b6250bf9567329a6e65f901d"],"f58dd714e47e4b20e7ddf69802a24d8278a50d3d":["9b832cbed6eb3d54a8bb9339296bdda8eeb53014","8fe956d65251358d755c56f14fe8380644790e47"],"d619839baa8ce5503e496b94a9e42ad6f079293f":["135621f3a0670a9394eb563224a3b76cc4dddc0f"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["d619839baa8ce5503e496b94a9e42ad6f079293f"],"a3776dccca01c11e7046323cfad46a3b4a471233":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"8fe956d65251358d755c56f14fe8380644790e47":["b3e06be49006ecac364d39d12b9c9f74882f9b9f"],"4948bc5d29211f0c9b5ccc31b2632cdd27066ea5":["ab5cb6a74aefb78aa0569857970b9151dfe2e787","c19f985e36a65cc969e8e564fe337a0d41512075"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["955c32f886db6f6356c9fcdea6b1f1cb4effda24"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["135621f3a0670a9394eb563224a3b76cc4dddc0f","a3776dccca01c11e7046323cfad46a3b4a471233","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}