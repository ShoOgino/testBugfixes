{"path":"lucene/src/java/org/apache/lucene/index/CheckIndex#testTermVectors(SegmentInfo,SegmentReader,NumberFormat).mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/CheckIndex#testTermVectors(SegmentInfo,SegmentReader,NumberFormat).mjava","pathOld":"src/java/org/apache/lucene/index/CheckIndex#testTermVectors(SegmentInfo,SegmentReader,NumberFormat).mjava","sourceNew":"  /**\n   * Test term vectors for a segment.\n   */\n  private Status.TermVectorStatus testTermVectors(SegmentInfo info, SegmentReader reader, NumberFormat format) {\n    final Status.TermVectorStatus status = new Status.TermVectorStatus();\n    \n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: term vectors........\");\n      }\n\n      for (int j = 0; j < info.docCount; ++j) {\n        if (!reader.isDeleted(j)) {\n          status.docCount++;\n          TermFreqVector[] tfv = reader.getTermFreqVectors(j);\n          if (tfv != null) {\n            status.totVectors += tfv.length;\n          }\n        }\n      }\n      \n      msg(\"OK [\" + status.totVectors + \" total vector count; avg \" + \n          format.format((((float) status.totVectors) / status.docCount)) + \" term/freq vector fields per doc]\");\n    } catch (Throwable e) {\n      msg(\"ERROR [\" + String.valueOf(e.getMessage()) + \"]\");\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * Test term vectors for a segment.\n   */\n  private Status.TermVectorStatus testTermVectors(SegmentInfo info, SegmentReader reader, NumberFormat format) {\n    final Status.TermVectorStatus status = new Status.TermVectorStatus();\n    \n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: term vectors........\");\n      }\n\n      for (int j = 0; j < info.docCount; ++j) {\n        if (!reader.isDeleted(j)) {\n          status.docCount++;\n          TermFreqVector[] tfv = reader.getTermFreqVectors(j);\n          if (tfv != null) {\n            status.totVectors += tfv.length;\n          }\n        }\n      }\n      \n      msg(\"OK [\" + status.totVectors + \" total vector count; avg \" + \n          format.format((((float) status.totVectors) / status.docCount)) + \" term/freq vector fields per doc]\");\n    } catch (Throwable e) {\n      msg(\"ERROR [\" + String.valueOf(e.getMessage()) + \"]\");\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"406e7055a3e99d3fa6ce49a555a51dd18b321806","date":1282520243,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/CheckIndex#testTermVectors(SegmentInfo,SegmentReader,NumberFormat).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/CheckIndex#testTermVectors(SegmentInfo,SegmentReader,NumberFormat).mjava","sourceNew":"  /**\n   * Test term vectors for a segment.\n   */\n  private Status.TermVectorStatus testTermVectors(SegmentInfo info, SegmentReader reader, NumberFormat format) {\n    final Status.TermVectorStatus status = new Status.TermVectorStatus();\n    \n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: term vectors........\");\n      }\n\n      final Bits delDocs = reader.getDeletedDocs();\n      for (int j = 0; j < info.docCount; ++j) {\n        if (delDocs == null || !delDocs.get(j)) {\n          status.docCount++;\n          TermFreqVector[] tfv = reader.getTermFreqVectors(j);\n          if (tfv != null) {\n            status.totVectors += tfv.length;\n          }\n        }\n      }\n      \n      msg(\"OK [\" + status.totVectors + \" total vector count; avg \" + \n          format.format((((float) status.totVectors) / status.docCount)) + \" term/freq vector fields per doc]\");\n    } catch (Throwable e) {\n      msg(\"ERROR [\" + String.valueOf(e.getMessage()) + \"]\");\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * Test term vectors for a segment.\n   */\n  private Status.TermVectorStatus testTermVectors(SegmentInfo info, SegmentReader reader, NumberFormat format) {\n    final Status.TermVectorStatus status = new Status.TermVectorStatus();\n    \n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: term vectors........\");\n      }\n\n      for (int j = 0; j < info.docCount; ++j) {\n        if (!reader.isDeleted(j)) {\n          status.docCount++;\n          TermFreqVector[] tfv = reader.getTermFreqVectors(j);\n          if (tfv != null) {\n            status.totVectors += tfv.length;\n          }\n        }\n      }\n      \n      msg(\"OK [\" + status.totVectors + \" total vector count; avg \" + \n          format.format((((float) status.totVectors) / status.docCount)) + \" term/freq vector fields per doc]\");\n    } catch (Throwable e) {\n      msg(\"ERROR [\" + String.valueOf(e.getMessage()) + \"]\");\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":["433ef5e0ff3fa18d549774f572b36aae2ae64232"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/CheckIndex#testTermVectors(SegmentInfo,SegmentReader,NumberFormat).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/CheckIndex#testTermVectors(SegmentInfo,SegmentReader,NumberFormat).mjava","sourceNew":"  /**\n   * Test term vectors for a segment.\n   */\n  private Status.TermVectorStatus testTermVectors(SegmentInfo info, SegmentReader reader, NumberFormat format) {\n    final Status.TermVectorStatus status = new Status.TermVectorStatus();\n    \n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: term vectors........\");\n      }\n\n      final Bits delDocs = reader.getDeletedDocs();\n      for (int j = 0; j < info.docCount; ++j) {\n        if (delDocs == null || !delDocs.get(j)) {\n          status.docCount++;\n          TermFreqVector[] tfv = reader.getTermFreqVectors(j);\n          if (tfv != null) {\n            status.totVectors += tfv.length;\n          }\n        }\n      }\n      \n      msg(\"OK [\" + status.totVectors + \" total vector count; avg \" + \n          format.format((((float) status.totVectors) / status.docCount)) + \" term/freq vector fields per doc]\");\n    } catch (Throwable e) {\n      msg(\"ERROR [\" + String.valueOf(e.getMessage()) + \"]\");\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * Test term vectors for a segment.\n   */\n  private Status.TermVectorStatus testTermVectors(SegmentInfo info, SegmentReader reader, NumberFormat format) {\n    final Status.TermVectorStatus status = new Status.TermVectorStatus();\n    \n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: term vectors........\");\n      }\n\n      for (int j = 0; j < info.docCount; ++j) {\n        if (!reader.isDeleted(j)) {\n          status.docCount++;\n          TermFreqVector[] tfv = reader.getTermFreqVectors(j);\n          if (tfv != null) {\n            status.totVectors += tfv.length;\n          }\n        }\n      }\n      \n      msg(\"OK [\" + status.totVectors + \" total vector count; avg \" + \n          format.format((((float) status.totVectors) / status.docCount)) + \" term/freq vector fields per doc]\");\n    } catch (Throwable e) {\n      msg(\"ERROR [\" + String.valueOf(e.getMessage()) + \"]\");\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e7bd246bb7bc35ac22edfee9157e034dfc4e65eb","date":1309960478,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/CheckIndex#testTermVectors(SegmentInfo,SegmentReader,NumberFormat).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/CheckIndex#testTermVectors(SegmentInfo,SegmentReader,NumberFormat).mjava","sourceNew":"  /**\n   * Test term vectors for a segment.\n   */\n  private Status.TermVectorStatus testTermVectors(SegmentInfo info, SegmentReader reader, NumberFormat format) {\n    final Status.TermVectorStatus status = new Status.TermVectorStatus();\n    \n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: term vectors........\");\n      }\n\n      final Bits liveDocs = reader.getLiveDocs();\n      for (int j = 0; j < info.docCount; ++j) {\n        if (liveDocs == null || liveDocs.get(j)) {\n          status.docCount++;\n          TermFreqVector[] tfv = reader.getTermFreqVectors(j);\n          if (tfv != null) {\n            status.totVectors += tfv.length;\n          }\n        }\n      }\n      \n      msg(\"OK [\" + status.totVectors + \" total vector count; avg \" + \n          format.format((((float) status.totVectors) / status.docCount)) + \" term/freq vector fields per doc]\");\n    } catch (Throwable e) {\n      msg(\"ERROR [\" + String.valueOf(e.getMessage()) + \"]\");\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * Test term vectors for a segment.\n   */\n  private Status.TermVectorStatus testTermVectors(SegmentInfo info, SegmentReader reader, NumberFormat format) {\n    final Status.TermVectorStatus status = new Status.TermVectorStatus();\n    \n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: term vectors........\");\n      }\n\n      final Bits delDocs = reader.getDeletedDocs();\n      for (int j = 0; j < info.docCount; ++j) {\n        if (delDocs == null || !delDocs.get(j)) {\n          status.docCount++;\n          TermFreqVector[] tfv = reader.getTermFreqVectors(j);\n          if (tfv != null) {\n            status.totVectors += tfv.length;\n          }\n        }\n      }\n      \n      msg(\"OK [\" + status.totVectors + \" total vector count; avg \" + \n          format.format((((float) status.totVectors) / status.docCount)) + \" term/freq vector fields per doc]\");\n    } catch (Throwable e) {\n      msg(\"ERROR [\" + String.valueOf(e.getMessage()) + \"]\");\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"817d8435e9135b756f08ce6710ab0baac51bdf88","date":1309986993,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/CheckIndex#testTermVectors(SegmentInfo,SegmentReader,NumberFormat).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/CheckIndex#testTermVectors(SegmentInfo,SegmentReader,NumberFormat).mjava","sourceNew":"  /**\n   * Test term vectors for a segment.\n   */\n  private Status.TermVectorStatus testTermVectors(SegmentInfo info, SegmentReader reader, NumberFormat format) {\n    final Status.TermVectorStatus status = new Status.TermVectorStatus();\n    \n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: term vectors........\");\n      }\n\n      final Bits liveDocs = reader.getLiveDocs();\n      for (int j = 0; j < info.docCount; ++j) {\n        if (liveDocs == null || liveDocs.get(j)) {\n          status.docCount++;\n          TermFreqVector[] tfv = reader.getTermFreqVectors(j);\n          if (tfv != null) {\n            status.totVectors += tfv.length;\n          }\n        }\n      }\n      \n      msg(\"OK [\" + status.totVectors + \" total vector count; avg \" + \n          format.format((((float) status.totVectors) / status.docCount)) + \" term/freq vector fields per doc]\");\n    } catch (Throwable e) {\n      msg(\"ERROR [\" + String.valueOf(e.getMessage()) + \"]\");\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * Test term vectors for a segment.\n   */\n  private Status.TermVectorStatus testTermVectors(SegmentInfo info, SegmentReader reader, NumberFormat format) {\n    final Status.TermVectorStatus status = new Status.TermVectorStatus();\n    \n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: term vectors........\");\n      }\n\n      final Bits delDocs = reader.getDeletedDocs();\n      for (int j = 0; j < info.docCount; ++j) {\n        if (delDocs == null || !delDocs.get(j)) {\n          status.docCount++;\n          TermFreqVector[] tfv = reader.getTermFreqVectors(j);\n          if (tfv != null) {\n            status.totVectors += tfv.length;\n          }\n        }\n      }\n      \n      msg(\"OK [\" + status.totVectors + \" total vector count; avg \" + \n          format.format((((float) status.totVectors) / status.docCount)) + \" term/freq vector fields per doc]\");\n    } catch (Throwable e) {\n      msg(\"ERROR [\" + String.valueOf(e.getMessage()) + \"]\");\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d083e83f225b11e5fdd900e83d26ddb385b6955c","date":1310029438,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/CheckIndex#testTermVectors(SegmentInfo,SegmentReader,NumberFormat).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/CheckIndex#testTermVectors(SegmentInfo,SegmentReader,NumberFormat).mjava","sourceNew":"  /**\n   * Test term vectors for a segment.\n   */\n  private Status.TermVectorStatus testTermVectors(SegmentInfo info, SegmentReader reader, NumberFormat format) {\n    final Status.TermVectorStatus status = new Status.TermVectorStatus();\n    \n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: term vectors........\");\n      }\n\n      final Bits liveDocs = reader.getLiveDocs();\n      for (int j = 0; j < info.docCount; ++j) {\n        if (liveDocs == null || liveDocs.get(j)) {\n          status.docCount++;\n          TermFreqVector[] tfv = reader.getTermFreqVectors(j);\n          if (tfv != null) {\n            status.totVectors += tfv.length;\n          }\n        }\n      }\n      \n      msg(\"OK [\" + status.totVectors + \" total vector count; avg \" + \n          format.format((((float) status.totVectors) / status.docCount)) + \" term/freq vector fields per doc]\");\n    } catch (Throwable e) {\n      msg(\"ERROR [\" + String.valueOf(e.getMessage()) + \"]\");\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * Test term vectors for a segment.\n   */\n  private Status.TermVectorStatus testTermVectors(SegmentInfo info, SegmentReader reader, NumberFormat format) {\n    final Status.TermVectorStatus status = new Status.TermVectorStatus();\n    \n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: term vectors........\");\n      }\n\n      final Bits delDocs = reader.getDeletedDocs();\n      for (int j = 0; j < info.docCount; ++j) {\n        if (delDocs == null || !delDocs.get(j)) {\n          status.docCount++;\n          TermFreqVector[] tfv = reader.getTermFreqVectors(j);\n          if (tfv != null) {\n            status.totVectors += tfv.length;\n          }\n        }\n      }\n      \n      msg(\"OK [\" + status.totVectors + \" total vector count; avg \" + \n          format.format((((float) status.totVectors) / status.docCount)) + \" term/freq vector fields per doc]\");\n    } catch (Throwable e) {\n      msg(\"ERROR [\" + String.valueOf(e.getMessage()) + \"]\");\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3cc749c053615f5871f3b95715fe292f34e70a53","date":1321470575,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/CheckIndex#testTermVectors(SegmentInfo,SegmentReader,NumberFormat).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/CheckIndex#testTermVectors(SegmentInfo,SegmentReader,NumberFormat).mjava","sourceNew":"  /**\n   * Test term vectors for a segment.\n   */\n  private Status.TermVectorStatus testTermVectors(SegmentInfo info, SegmentReader reader, NumberFormat format) {\n    final Status.TermVectorStatus status = new Status.TermVectorStatus();\n    \n    TermsEnum termsEnum = null;\n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: term vectors........\");\n      }\n\n      // TODO: maybe we can factor out testTermIndex and reuse here?\n      DocsEnum docs = null;\n      DocsAndPositionsEnum postings = null;\n      final Bits liveDocs = reader.getLiveDocs();\n      for (int j = 0; j < info.docCount; ++j) {\n        if (liveDocs == null || liveDocs.get(j)) {\n          status.docCount++;\n          Fields tfv = reader.getTermVectors(j);\n          if (tfv != null) {\n            int tfvComputedFieldCount = 0;\n            long tfvComputedTermCount = 0;\n\n            FieldsEnum fieldsEnum = tfv.iterator();\n            String field = null;\n            String lastField = null;\n            while((field = fieldsEnum.next()) != null) {\n              status.totVectors++;\n              tfvComputedFieldCount++;\n\n              if (lastField == null) {\n                lastField = field;\n              } else if (lastField.compareTo(field) > 0) {\n                throw new RuntimeException(\"vector fields are out of order: lastField=\" + lastField + \" field=\" + field + \" doc=\" + j);\n              }\n              \n              Terms terms = tfv.terms(field);\n              termsEnum = terms.iterator(termsEnum);\n              \n              long tfvComputedTermCountForField = 0;\n              long tfvComputedSumTotalTermFreq = 0;\n              \n              BytesRef term = null;\n              while ((term = termsEnum.next()) != null) {\n                tfvComputedTermCountForField++;\n                \n                if (termsEnum.docFreq() != 1) {\n                  throw new RuntimeException(\"vector docFreq for doc \" + j + \", field \" + field + \", term\" + term + \" != 1\");\n                }\n                \n                long totalTermFreq = termsEnum.totalTermFreq();\n                \n                if (totalTermFreq != -1 && totalTermFreq <= 0) {\n                  throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq + \" is out of bounds\");\n                }\n                \n                DocsEnum docsEnum;\n                DocsAndPositionsEnum dp = termsEnum.docsAndPositions(null, postings);\n                if (dp == null) {\n                  DocsEnum d = termsEnum.docs(null, docs);\n                  docsEnum = docs = d;\n                } else {\n                  docsEnum = postings = dp;\n                }\n                  \n                final int doc = docsEnum.nextDoc();\n                  \n                if (doc != 0) {\n                  throw new RuntimeException(\"vector for doc \" + j + \" didn't return docID=0: got docID=\" + doc);\n                }\n                  \n                final int tf = docsEnum.freq();\n                tfvComputedSumTotalTermFreq += tf;\n                \n                if (tf <= 0) {\n                  throw new RuntimeException(\"vector freq \" + tf + \" is out of bounds\");\n                }\n                \n                if (totalTermFreq != -1 && totalTermFreq != tf) {\n                  throw new RuntimeException(\"vector totalTermFreq \" + totalTermFreq + \" != tf \" + tf);\n                }\n                \n                if (dp != null) {\n                  int lastPosition = -1;\n                  for (int i = 0; i < tf; i++) {\n                    int pos = dp.nextPosition();\n                    if (pos != -1 && pos < 0) {\n                      throw new RuntimeException(\"vector position \" + pos + \" is out of bounds\");\n                    }\n                    \n                    if (pos < lastPosition) {\n                      throw new RuntimeException(\"vector position \" + pos + \" < lastPos \" + lastPosition);\n                    }\n                    \n                    lastPosition = pos;\n                  }\n                }\n                  \n                if (docsEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                  throw new RuntimeException(\"vector for doc \" + j + \" references multiple documents!\");\n                }\n              }\n              \n              long uniqueTermCount = terms.getUniqueTermCount();\n              if (uniqueTermCount != -1 && uniqueTermCount != tfvComputedTermCountForField) {\n                throw new RuntimeException(\"vector term count for doc \" + j + \", field \" + field + \" = \" + uniqueTermCount + \" != recomputed term count=\" + tfvComputedTermCountForField);\n              }\n              \n              int docCount = terms.getDocCount();\n              if (docCount != -1 && docCount != 1) {\n                throw new RuntimeException(\"vector doc count for doc \" + j + \", field \" + field + \" = \" + docCount + \" != 1\");\n              }\n              \n              long sumDocFreq = terms.getSumDocFreq();\n              if (sumDocFreq != -1 && sumDocFreq != tfvComputedTermCountForField) {\n                throw new RuntimeException(\"vector postings count for doc \" + j + \", field \" + field + \" = \" + sumDocFreq + \" != recomputed postings count=\" + tfvComputedTermCountForField);\n              }\n              \n              long sumTotalTermFreq = terms.getSumTotalTermFreq();\n              if (sumTotalTermFreq != -1 && sumTotalTermFreq != tfvComputedSumTotalTermFreq) {\n                throw new RuntimeException(\"vector sumTotalTermFreq for doc \" + j + \", field \" + field + \" = \" + sumTotalTermFreq + \" != recomputed sumTotalTermFreq=\" + tfvComputedSumTotalTermFreq);\n              }\n              \n              tfvComputedTermCount += tfvComputedTermCountForField;\n            }\n            \n            int tfvUniqueFieldCount = tfv.getUniqueFieldCount();\n            if (tfvUniqueFieldCount != -1 && tfvUniqueFieldCount != tfvComputedFieldCount) {\n              throw new RuntimeException(\"vector field count for doc \" + j + \"=\" + tfvUniqueFieldCount + \" != recomputed uniqueFieldCount=\" + tfvComputedFieldCount);\n            }\n            \n            long tfvUniqueTermCount = tfv.getUniqueTermCount();\n            if (tfvUniqueTermCount != -1 && tfvUniqueTermCount != tfvComputedTermCount) {\n              throw new RuntimeException(\"vector term count for doc \" + j + \"=\" + tfvUniqueTermCount + \" != recomputed uniqueTermCount=\" + tfvComputedTermCount);\n            }\n          }\n        }\n      }\n      \n      msg(\"OK [\" + status.totVectors + \" total vector count; avg \" + \n          format.format((((float) status.totVectors) / status.docCount)) + \" term/freq vector fields per doc]\");\n    } catch (Throwable e) {\n      msg(\"ERROR [\" + String.valueOf(e.getMessage()) + \"]\");\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * Test term vectors for a segment.\n   */\n  private Status.TermVectorStatus testTermVectors(SegmentInfo info, SegmentReader reader, NumberFormat format) {\n    final Status.TermVectorStatus status = new Status.TermVectorStatus();\n    \n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: term vectors........\");\n      }\n\n      final Bits liveDocs = reader.getLiveDocs();\n      for (int j = 0; j < info.docCount; ++j) {\n        if (liveDocs == null || liveDocs.get(j)) {\n          status.docCount++;\n          TermFreqVector[] tfv = reader.getTermFreqVectors(j);\n          if (tfv != null) {\n            status.totVectors += tfv.length;\n          }\n        }\n      }\n      \n      msg(\"OK [\" + status.totVectors + \" total vector count; avg \" + \n          format.format((((float) status.totVectors) / status.docCount)) + \" term/freq vector fields per doc]\");\n    } catch (Throwable e) {\n      msg(\"ERROR [\" + String.valueOf(e.getMessage()) + \"]\");\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"872cff1d3a554e0cd64014cd97f88d3002b0f491","date":1323024658,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/CheckIndex#testTermVectors(SegmentInfo,SegmentReader,NumberFormat).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/CheckIndex#testTermVectors(SegmentInfo,SegmentReader,NumberFormat).mjava","sourceNew":"  /**\n   * Test term vectors for a segment.\n   */\n  private Status.TermVectorStatus testTermVectors(SegmentInfo info, SegmentReader reader, NumberFormat format) {\n    final Status.TermVectorStatus status = new Status.TermVectorStatus();\n    \n    TermsEnum termsEnum = null;\n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: term vectors........\");\n      }\n\n      // TODO: maybe we can factor out testTermIndex and reuse here?\n      DocsEnum docs = null;\n      DocsEnum docsAndFreqs = null;\n      DocsAndPositionsEnum postings = null;\n      final Bits liveDocs = reader.getLiveDocs();\n      for (int j = 0; j < info.docCount; ++j) {\n        if (liveDocs == null || liveDocs.get(j)) {\n          status.docCount++;\n          Fields tfv = reader.getTermVectors(j);\n          if (tfv != null) {\n            int tfvComputedFieldCount = 0;\n            long tfvComputedTermCount = 0;\n\n            FieldsEnum fieldsEnum = tfv.iterator();\n            String field = null;\n            String lastField = null;\n            while((field = fieldsEnum.next()) != null) {\n              status.totVectors++;\n              tfvComputedFieldCount++;\n\n              if (lastField == null) {\n                lastField = field;\n              } else if (lastField.compareTo(field) > 0) {\n                throw new RuntimeException(\"vector fields are out of order: lastField=\" + lastField + \" field=\" + field + \" doc=\" + j);\n              }\n              \n              Terms terms = tfv.terms(field);\n              termsEnum = terms.iterator(termsEnum);\n              \n              long tfvComputedTermCountForField = 0;\n              long tfvComputedSumTotalTermFreq = 0;\n              \n              BytesRef term = null;\n              while ((term = termsEnum.next()) != null) {\n                tfvComputedTermCountForField++;\n                \n                if (termsEnum.docFreq() != 1) {\n                  throw new RuntimeException(\"vector docFreq for doc \" + j + \", field \" + field + \", term\" + term + \" != 1\");\n                }\n                \n                long totalTermFreq = termsEnum.totalTermFreq();\n                \n                if (totalTermFreq != -1 && totalTermFreq <= 0) {\n                  throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq + \" is out of bounds\");\n                }\n\n                postings = termsEnum.docsAndPositions(null, postings);\n                if (postings == null) {\n                  docsAndFreqs = termsEnum.docs(null, docsAndFreqs, true);\n                  if (docsAndFreqs == null) {\n                    docs = termsEnum.docs(null, docs, false);\n                  } else {\n                    docs = docsAndFreqs;\n                  }\n                } else {\n                  docs = docsAndFreqs = postings;\n                }\n\n                final int doc = docs.nextDoc();\n                  \n                if (doc != 0) {\n                  throw new RuntimeException(\"vector for doc \" + j + \" didn't return docID=0: got docID=\" + doc);\n                }\n\n                if (docsAndFreqs != null) {\n                  final int tf = docsAndFreqs.freq();\n                  if (tf <= 0) {\n                    throw new RuntimeException(\"vector freq \" + tf + \" is out of bounds\");\n                  }\n                  if (totalTermFreq != -1 && totalTermFreq != tf) {\n                    throw new RuntimeException(\"vector totalTermFreq \" + totalTermFreq + \" != tf \" + tf);\n                  }\n                  tfvComputedSumTotalTermFreq += tf;\n                \n                  if (postings != null) {\n                    int lastPosition = -1;\n                    for (int i = 0; i < tf; i++) {\n                      int pos = postings.nextPosition();\n                      if (pos != -1 && pos < 0) {\n                        throw new RuntimeException(\"vector position \" + pos + \" is out of bounds\");\n                      }\n                    \n                      if (pos < lastPosition) {\n                        throw new RuntimeException(\"vector position \" + pos + \" < lastPos \" + lastPosition);\n                      }\n                    \n                      lastPosition = pos;\n                    }\n                  }\n                }\n                  \n                if (docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                  throw new RuntimeException(\"vector for doc \" + j + \" references multiple documents!\");\n                }\n              }\n              \n              long uniqueTermCount = terms.getUniqueTermCount();\n              if (uniqueTermCount != -1 && uniqueTermCount != tfvComputedTermCountForField) {\n                throw new RuntimeException(\"vector term count for doc \" + j + \", field \" + field + \" = \" + uniqueTermCount + \" != recomputed term count=\" + tfvComputedTermCountForField);\n              }\n              \n              int docCount = terms.getDocCount();\n              if (docCount != -1 && docCount != 1) {\n                throw new RuntimeException(\"vector doc count for doc \" + j + \", field \" + field + \" = \" + docCount + \" != 1\");\n              }\n              \n              long sumDocFreq = terms.getSumDocFreq();\n              if (sumDocFreq != -1 && sumDocFreq != tfvComputedTermCountForField) {\n                throw new RuntimeException(\"vector postings count for doc \" + j + \", field \" + field + \" = \" + sumDocFreq + \" != recomputed postings count=\" + tfvComputedTermCountForField);\n              }\n              \n              long sumTotalTermFreq = terms.getSumTotalTermFreq();\n              if (sumTotalTermFreq != -1 && sumTotalTermFreq != tfvComputedSumTotalTermFreq) {\n                throw new RuntimeException(\"vector sumTotalTermFreq for doc \" + j + \", field \" + field + \" = \" + sumTotalTermFreq + \" != recomputed sumTotalTermFreq=\" + tfvComputedSumTotalTermFreq);\n              }\n              \n              tfvComputedTermCount += tfvComputedTermCountForField;\n            }\n            \n            int tfvUniqueFieldCount = tfv.getUniqueFieldCount();\n            if (tfvUniqueFieldCount != -1 && tfvUniqueFieldCount != tfvComputedFieldCount) {\n              throw new RuntimeException(\"vector field count for doc \" + j + \"=\" + tfvUniqueFieldCount + \" != recomputed uniqueFieldCount=\" + tfvComputedFieldCount);\n            }\n            \n            long tfvUniqueTermCount = tfv.getUniqueTermCount();\n            if (tfvUniqueTermCount != -1 && tfvUniqueTermCount != tfvComputedTermCount) {\n              throw new RuntimeException(\"vector term count for doc \" + j + \"=\" + tfvUniqueTermCount + \" != recomputed uniqueTermCount=\" + tfvComputedTermCount);\n            }\n          }\n        }\n      }\n      \n      msg(\"OK [\" + status.totVectors + \" total vector count; avg \" + \n          format.format((((float) status.totVectors) / status.docCount)) + \" term/freq vector fields per doc]\");\n    } catch (Throwable e) {\n      msg(\"ERROR [\" + String.valueOf(e.getMessage()) + \"]\");\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * Test term vectors for a segment.\n   */\n  private Status.TermVectorStatus testTermVectors(SegmentInfo info, SegmentReader reader, NumberFormat format) {\n    final Status.TermVectorStatus status = new Status.TermVectorStatus();\n    \n    TermsEnum termsEnum = null;\n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: term vectors........\");\n      }\n\n      // TODO: maybe we can factor out testTermIndex and reuse here?\n      DocsEnum docs = null;\n      DocsAndPositionsEnum postings = null;\n      final Bits liveDocs = reader.getLiveDocs();\n      for (int j = 0; j < info.docCount; ++j) {\n        if (liveDocs == null || liveDocs.get(j)) {\n          status.docCount++;\n          Fields tfv = reader.getTermVectors(j);\n          if (tfv != null) {\n            int tfvComputedFieldCount = 0;\n            long tfvComputedTermCount = 0;\n\n            FieldsEnum fieldsEnum = tfv.iterator();\n            String field = null;\n            String lastField = null;\n            while((field = fieldsEnum.next()) != null) {\n              status.totVectors++;\n              tfvComputedFieldCount++;\n\n              if (lastField == null) {\n                lastField = field;\n              } else if (lastField.compareTo(field) > 0) {\n                throw new RuntimeException(\"vector fields are out of order: lastField=\" + lastField + \" field=\" + field + \" doc=\" + j);\n              }\n              \n              Terms terms = tfv.terms(field);\n              termsEnum = terms.iterator(termsEnum);\n              \n              long tfvComputedTermCountForField = 0;\n              long tfvComputedSumTotalTermFreq = 0;\n              \n              BytesRef term = null;\n              while ((term = termsEnum.next()) != null) {\n                tfvComputedTermCountForField++;\n                \n                if (termsEnum.docFreq() != 1) {\n                  throw new RuntimeException(\"vector docFreq for doc \" + j + \", field \" + field + \", term\" + term + \" != 1\");\n                }\n                \n                long totalTermFreq = termsEnum.totalTermFreq();\n                \n                if (totalTermFreq != -1 && totalTermFreq <= 0) {\n                  throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq + \" is out of bounds\");\n                }\n                \n                DocsEnum docsEnum;\n                DocsAndPositionsEnum dp = termsEnum.docsAndPositions(null, postings);\n                if (dp == null) {\n                  DocsEnum d = termsEnum.docs(null, docs);\n                  docsEnum = docs = d;\n                } else {\n                  docsEnum = postings = dp;\n                }\n                  \n                final int doc = docsEnum.nextDoc();\n                  \n                if (doc != 0) {\n                  throw new RuntimeException(\"vector for doc \" + j + \" didn't return docID=0: got docID=\" + doc);\n                }\n                  \n                final int tf = docsEnum.freq();\n                tfvComputedSumTotalTermFreq += tf;\n                \n                if (tf <= 0) {\n                  throw new RuntimeException(\"vector freq \" + tf + \" is out of bounds\");\n                }\n                \n                if (totalTermFreq != -1 && totalTermFreq != tf) {\n                  throw new RuntimeException(\"vector totalTermFreq \" + totalTermFreq + \" != tf \" + tf);\n                }\n                \n                if (dp != null) {\n                  int lastPosition = -1;\n                  for (int i = 0; i < tf; i++) {\n                    int pos = dp.nextPosition();\n                    if (pos != -1 && pos < 0) {\n                      throw new RuntimeException(\"vector position \" + pos + \" is out of bounds\");\n                    }\n                    \n                    if (pos < lastPosition) {\n                      throw new RuntimeException(\"vector position \" + pos + \" < lastPos \" + lastPosition);\n                    }\n                    \n                    lastPosition = pos;\n                  }\n                }\n                  \n                if (docsEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                  throw new RuntimeException(\"vector for doc \" + j + \" references multiple documents!\");\n                }\n              }\n              \n              long uniqueTermCount = terms.getUniqueTermCount();\n              if (uniqueTermCount != -1 && uniqueTermCount != tfvComputedTermCountForField) {\n                throw new RuntimeException(\"vector term count for doc \" + j + \", field \" + field + \" = \" + uniqueTermCount + \" != recomputed term count=\" + tfvComputedTermCountForField);\n              }\n              \n              int docCount = terms.getDocCount();\n              if (docCount != -1 && docCount != 1) {\n                throw new RuntimeException(\"vector doc count for doc \" + j + \", field \" + field + \" = \" + docCount + \" != 1\");\n              }\n              \n              long sumDocFreq = terms.getSumDocFreq();\n              if (sumDocFreq != -1 && sumDocFreq != tfvComputedTermCountForField) {\n                throw new RuntimeException(\"vector postings count for doc \" + j + \", field \" + field + \" = \" + sumDocFreq + \" != recomputed postings count=\" + tfvComputedTermCountForField);\n              }\n              \n              long sumTotalTermFreq = terms.getSumTotalTermFreq();\n              if (sumTotalTermFreq != -1 && sumTotalTermFreq != tfvComputedSumTotalTermFreq) {\n                throw new RuntimeException(\"vector sumTotalTermFreq for doc \" + j + \", field \" + field + \" = \" + sumTotalTermFreq + \" != recomputed sumTotalTermFreq=\" + tfvComputedSumTotalTermFreq);\n              }\n              \n              tfvComputedTermCount += tfvComputedTermCountForField;\n            }\n            \n            int tfvUniqueFieldCount = tfv.getUniqueFieldCount();\n            if (tfvUniqueFieldCount != -1 && tfvUniqueFieldCount != tfvComputedFieldCount) {\n              throw new RuntimeException(\"vector field count for doc \" + j + \"=\" + tfvUniqueFieldCount + \" != recomputed uniqueFieldCount=\" + tfvComputedFieldCount);\n            }\n            \n            long tfvUniqueTermCount = tfv.getUniqueTermCount();\n            if (tfvUniqueTermCount != -1 && tfvUniqueTermCount != tfvComputedTermCount) {\n              throw new RuntimeException(\"vector term count for doc \" + j + \"=\" + tfvUniqueTermCount + \" != recomputed uniqueTermCount=\" + tfvComputedTermCount);\n            }\n          }\n        }\n      }\n      \n      msg(\"OK [\" + status.totVectors + \" total vector count; avg \" + \n          format.format((((float) status.totVectors) / status.docCount)) + \" term/freq vector fields per doc]\");\n    } catch (Throwable e) {\n      msg(\"ERROR [\" + String.valueOf(e.getMessage()) + \"]\");\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b65b350ca9588f9fc76ce7d6804160d06c45ff42","date":1323026297,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/CheckIndex#testTermVectors(SegmentInfo,SegmentReader,NumberFormat).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/CheckIndex#testTermVectors(SegmentInfo,SegmentReader,NumberFormat).mjava","sourceNew":"  /**\n   * Test term vectors for a segment.\n   */\n  private Status.TermVectorStatus testTermVectors(SegmentInfo info, SegmentReader reader, NumberFormat format) {\n    final Status.TermVectorStatus status = new Status.TermVectorStatus();\n    \n    TermsEnum termsEnum = null;\n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: term vectors........\");\n      }\n\n      // TODO: maybe we can factor out testTermIndex and reuse here?\n      DocsEnum docs = null;\n      DocsEnum docsAndFreqs = null;\n      DocsAndPositionsEnum postings = null;\n      final Bits liveDocs = reader.getLiveDocs();\n      for (int j = 0; j < info.docCount; ++j) {\n        if (liveDocs == null || liveDocs.get(j)) {\n          status.docCount++;\n          Fields tfv = reader.getTermVectors(j);\n          if (tfv != null) {\n            int tfvComputedFieldCount = 0;\n            long tfvComputedTermCount = 0;\n\n            FieldsEnum fieldsEnum = tfv.iterator();\n            String field = null;\n            String lastField = null;\n            while((field = fieldsEnum.next()) != null) {\n              status.totVectors++;\n              tfvComputedFieldCount++;\n\n              if (lastField == null) {\n                lastField = field;\n              } else if (lastField.compareTo(field) > 0) {\n                throw new RuntimeException(\"vector fields are out of order: lastField=\" + lastField + \" field=\" + field + \" doc=\" + j);\n              }\n              \n              Terms terms = tfv.terms(field);\n              termsEnum = terms.iterator(termsEnum);\n              \n              long tfvComputedTermCountForField = 0;\n              long tfvComputedSumTotalTermFreq = 0;\n              \n              BytesRef term = null;\n              while ((term = termsEnum.next()) != null) {\n                tfvComputedTermCountForField++;\n                \n                if (termsEnum.docFreq() != 1) {\n                  throw new RuntimeException(\"vector docFreq for doc \" + j + \", field \" + field + \", term\" + term + \" != 1\");\n                }\n                \n                long totalTermFreq = termsEnum.totalTermFreq();\n                \n                if (totalTermFreq != -1 && totalTermFreq <= 0) {\n                  throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq + \" is out of bounds\");\n                }\n\n                postings = termsEnum.docsAndPositions(null, postings);\n                if (postings == null) {\n                  docsAndFreqs = termsEnum.docs(null, docsAndFreqs, true);\n                  if (docsAndFreqs == null) {\n                    docs = termsEnum.docs(null, docs, false);\n                  } else {\n                    docs = docsAndFreqs;\n                  }\n                } else {\n                  docs = docsAndFreqs = postings;\n                }\n\n                final int doc = docs.nextDoc();\n                  \n                if (doc != 0) {\n                  throw new RuntimeException(\"vector for doc \" + j + \" didn't return docID=0: got docID=\" + doc);\n                }\n\n                if (docsAndFreqs != null) {\n                  final int tf = docsAndFreqs.freq();\n                  if (tf <= 0) {\n                    throw new RuntimeException(\"vector freq \" + tf + \" is out of bounds\");\n                  }\n                  if (totalTermFreq != -1 && totalTermFreq != tf) {\n                    throw new RuntimeException(\"vector totalTermFreq \" + totalTermFreq + \" != tf \" + tf);\n                  }\n                  tfvComputedSumTotalTermFreq += tf;\n                \n                  if (postings != null) {\n                    int lastPosition = -1;\n                    for (int i = 0; i < tf; i++) {\n                      int pos = postings.nextPosition();\n                      if (pos != -1 && pos < 0) {\n                        throw new RuntimeException(\"vector position \" + pos + \" is out of bounds\");\n                      }\n                    \n                      if (pos < lastPosition) {\n                        throw new RuntimeException(\"vector position \" + pos + \" < lastPos \" + lastPosition);\n                      }\n                    \n                      lastPosition = pos;\n                    }\n                  }\n                }\n                  \n                if (docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                  throw new RuntimeException(\"vector for doc \" + j + \" references multiple documents!\");\n                }\n              }\n              \n              long uniqueTermCount = terms.getUniqueTermCount();\n              if (uniqueTermCount != -1 && uniqueTermCount != tfvComputedTermCountForField) {\n                throw new RuntimeException(\"vector term count for doc \" + j + \", field \" + field + \" = \" + uniqueTermCount + \" != recomputed term count=\" + tfvComputedTermCountForField);\n              }\n              \n              int docCount = terms.getDocCount();\n              if (docCount != -1 && docCount != 1) {\n                throw new RuntimeException(\"vector doc count for doc \" + j + \", field \" + field + \" = \" + docCount + \" != 1\");\n              }\n              \n              long sumDocFreq = terms.getSumDocFreq();\n              if (sumDocFreq != -1 && sumDocFreq != tfvComputedTermCountForField) {\n                throw new RuntimeException(\"vector postings count for doc \" + j + \", field \" + field + \" = \" + sumDocFreq + \" != recomputed postings count=\" + tfvComputedTermCountForField);\n              }\n              \n              long sumTotalTermFreq = terms.getSumTotalTermFreq();\n              if (sumTotalTermFreq != -1 && sumTotalTermFreq != tfvComputedSumTotalTermFreq) {\n                throw new RuntimeException(\"vector sumTotalTermFreq for doc \" + j + \", field \" + field + \" = \" + sumTotalTermFreq + \" != recomputed sumTotalTermFreq=\" + tfvComputedSumTotalTermFreq);\n              }\n              \n              tfvComputedTermCount += tfvComputedTermCountForField;\n            }\n            \n            int tfvUniqueFieldCount = tfv.getUniqueFieldCount();\n            if (tfvUniqueFieldCount != -1 && tfvUniqueFieldCount != tfvComputedFieldCount) {\n              throw new RuntimeException(\"vector field count for doc \" + j + \"=\" + tfvUniqueFieldCount + \" != recomputed uniqueFieldCount=\" + tfvComputedFieldCount);\n            }\n            \n            long tfvUniqueTermCount = tfv.getUniqueTermCount();\n            if (tfvUniqueTermCount != -1 && tfvUniqueTermCount != tfvComputedTermCount) {\n              throw new RuntimeException(\"vector term count for doc \" + j + \"=\" + tfvUniqueTermCount + \" != recomputed uniqueTermCount=\" + tfvComputedTermCount);\n            }\n          }\n        }\n      }\n      \n      msg(\"OK [\" + status.totVectors + \" total vector count; avg \" + \n          format.format((((float) status.totVectors) / status.docCount)) + \" term/freq vector fields per doc]\");\n    } catch (Throwable e) {\n      msg(\"ERROR [\" + String.valueOf(e.getMessage()) + \"]\");\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * Test term vectors for a segment.\n   */\n  private Status.TermVectorStatus testTermVectors(SegmentInfo info, SegmentReader reader, NumberFormat format) {\n    final Status.TermVectorStatus status = new Status.TermVectorStatus();\n    \n    TermsEnum termsEnum = null;\n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: term vectors........\");\n      }\n\n      // TODO: maybe we can factor out testTermIndex and reuse here?\n      DocsEnum docs = null;\n      DocsAndPositionsEnum postings = null;\n      final Bits liveDocs = reader.getLiveDocs();\n      for (int j = 0; j < info.docCount; ++j) {\n        if (liveDocs == null || liveDocs.get(j)) {\n          status.docCount++;\n          Fields tfv = reader.getTermVectors(j);\n          if (tfv != null) {\n            int tfvComputedFieldCount = 0;\n            long tfvComputedTermCount = 0;\n\n            FieldsEnum fieldsEnum = tfv.iterator();\n            String field = null;\n            String lastField = null;\n            while((field = fieldsEnum.next()) != null) {\n              status.totVectors++;\n              tfvComputedFieldCount++;\n\n              if (lastField == null) {\n                lastField = field;\n              } else if (lastField.compareTo(field) > 0) {\n                throw new RuntimeException(\"vector fields are out of order: lastField=\" + lastField + \" field=\" + field + \" doc=\" + j);\n              }\n              \n              Terms terms = tfv.terms(field);\n              termsEnum = terms.iterator(termsEnum);\n              \n              long tfvComputedTermCountForField = 0;\n              long tfvComputedSumTotalTermFreq = 0;\n              \n              BytesRef term = null;\n              while ((term = termsEnum.next()) != null) {\n                tfvComputedTermCountForField++;\n                \n                if (termsEnum.docFreq() != 1) {\n                  throw new RuntimeException(\"vector docFreq for doc \" + j + \", field \" + field + \", term\" + term + \" != 1\");\n                }\n                \n                long totalTermFreq = termsEnum.totalTermFreq();\n                \n                if (totalTermFreq != -1 && totalTermFreq <= 0) {\n                  throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq + \" is out of bounds\");\n                }\n                \n                DocsEnum docsEnum;\n                DocsAndPositionsEnum dp = termsEnum.docsAndPositions(null, postings);\n                if (dp == null) {\n                  DocsEnum d = termsEnum.docs(null, docs);\n                  docsEnum = docs = d;\n                } else {\n                  docsEnum = postings = dp;\n                }\n                  \n                final int doc = docsEnum.nextDoc();\n                  \n                if (doc != 0) {\n                  throw new RuntimeException(\"vector for doc \" + j + \" didn't return docID=0: got docID=\" + doc);\n                }\n                  \n                final int tf = docsEnum.freq();\n                tfvComputedSumTotalTermFreq += tf;\n                \n                if (tf <= 0) {\n                  throw new RuntimeException(\"vector freq \" + tf + \" is out of bounds\");\n                }\n                \n                if (totalTermFreq != -1 && totalTermFreq != tf) {\n                  throw new RuntimeException(\"vector totalTermFreq \" + totalTermFreq + \" != tf \" + tf);\n                }\n                \n                if (dp != null) {\n                  int lastPosition = -1;\n                  for (int i = 0; i < tf; i++) {\n                    int pos = dp.nextPosition();\n                    if (pos != -1 && pos < 0) {\n                      throw new RuntimeException(\"vector position \" + pos + \" is out of bounds\");\n                    }\n                    \n                    if (pos < lastPosition) {\n                      throw new RuntimeException(\"vector position \" + pos + \" < lastPos \" + lastPosition);\n                    }\n                    \n                    lastPosition = pos;\n                  }\n                }\n                  \n                if (docsEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                  throw new RuntimeException(\"vector for doc \" + j + \" references multiple documents!\");\n                }\n              }\n              \n              long uniqueTermCount = terms.getUniqueTermCount();\n              if (uniqueTermCount != -1 && uniqueTermCount != tfvComputedTermCountForField) {\n                throw new RuntimeException(\"vector term count for doc \" + j + \", field \" + field + \" = \" + uniqueTermCount + \" != recomputed term count=\" + tfvComputedTermCountForField);\n              }\n              \n              int docCount = terms.getDocCount();\n              if (docCount != -1 && docCount != 1) {\n                throw new RuntimeException(\"vector doc count for doc \" + j + \", field \" + field + \" = \" + docCount + \" != 1\");\n              }\n              \n              long sumDocFreq = terms.getSumDocFreq();\n              if (sumDocFreq != -1 && sumDocFreq != tfvComputedTermCountForField) {\n                throw new RuntimeException(\"vector postings count for doc \" + j + \", field \" + field + \" = \" + sumDocFreq + \" != recomputed postings count=\" + tfvComputedTermCountForField);\n              }\n              \n              long sumTotalTermFreq = terms.getSumTotalTermFreq();\n              if (sumTotalTermFreq != -1 && sumTotalTermFreq != tfvComputedSumTotalTermFreq) {\n                throw new RuntimeException(\"vector sumTotalTermFreq for doc \" + j + \", field \" + field + \" = \" + sumTotalTermFreq + \" != recomputed sumTotalTermFreq=\" + tfvComputedSumTotalTermFreq);\n              }\n              \n              tfvComputedTermCount += tfvComputedTermCountForField;\n            }\n            \n            int tfvUniqueFieldCount = tfv.getUniqueFieldCount();\n            if (tfvUniqueFieldCount != -1 && tfvUniqueFieldCount != tfvComputedFieldCount) {\n              throw new RuntimeException(\"vector field count for doc \" + j + \"=\" + tfvUniqueFieldCount + \" != recomputed uniqueFieldCount=\" + tfvComputedFieldCount);\n            }\n            \n            long tfvUniqueTermCount = tfv.getUniqueTermCount();\n            if (tfvUniqueTermCount != -1 && tfvUniqueTermCount != tfvComputedTermCount) {\n              throw new RuntimeException(\"vector term count for doc \" + j + \"=\" + tfvUniqueTermCount + \" != recomputed uniqueTermCount=\" + tfvComputedTermCount);\n            }\n          }\n        }\n      }\n      \n      msg(\"OK [\" + status.totVectors + \" total vector count; avg \" + \n          format.format((((float) status.totVectors) / status.docCount)) + \" term/freq vector fields per doc]\");\n    } catch (Throwable e) {\n      msg(\"ERROR [\" + String.valueOf(e.getMessage()) + \"]\");\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"31f025ae60076ae95274433f3fe8e6ace2857a87","date":1326669465,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/CheckIndex#testTermVectors(SegmentInfo,SegmentReader,NumberFormat).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/CheckIndex#testTermVectors(SegmentInfo,SegmentReader,NumberFormat).mjava","sourceNew":"  /**\n   * Test term vectors for a segment.\n   */\n  private Status.TermVectorStatus testTermVectors(SegmentInfo info, SegmentReader reader, NumberFormat format) {\n    final Status.TermVectorStatus status = new Status.TermVectorStatus();\n    \n    // TODO: in theory we could test that term vectors have\n    // same terms/pos/offsets as the postings, but it'd be\n    // very slow...\n\n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: term vectors........\");\n      }\n\n      // TODO: maybe we can factor out testTermIndex and reuse here?\n      DocsEnum docs = null;\n      DocsAndPositionsEnum postings = null;\n\n      // Only used if crossCheckTermVectors is true:\n      DocsEnum postingsDocs = null;\n      DocsAndPositionsEnum postingsPostings = null;\n\n      final Bits liveDocs = reader.getLiveDocs();\n\n      final Fields postingsFields;\n      // TODO: testTermsIndex\n      if (crossCheckTermVectors) {\n        postingsFields = reader.fields();\n      } else {\n        postingsFields = null;\n      }\n\n      TermsEnum termsEnum = null;\n      TermsEnum postingsTermsEnum = null;\n\n      for (int j = 0; j < info.docCount; ++j) {\n        if (liveDocs == null || liveDocs.get(j)) {\n          status.docCount++;\n          Fields tfv = reader.getTermVectors(j);\n          if (tfv != null) {\n            int tfvComputedFieldCount = 0;\n            long tfvComputedTermCount = 0;\n\n            FieldsEnum fieldsEnum = tfv.iterator();\n            String field = null;\n            String lastField = null;\n            while((field = fieldsEnum.next()) != null) {\n              status.totVectors++;\n              tfvComputedFieldCount++;\n\n              if (lastField == null) {\n                lastField = field;\n              } else if (lastField.compareTo(field) > 0) {\n                throw new RuntimeException(\"vector fields are out of order: lastField=\" + lastField + \" field=\" + field + \" doc=\" + j);\n              }\n              \n              Terms terms = tfv.terms(field);\n              termsEnum = terms.iterator(termsEnum);\n\n              if (crossCheckTermVectors) {\n                Terms postingsTerms = postingsFields.terms(field);\n                if (postingsTerms == null) {\n                  throw new RuntimeException(\"vector field=\" + field + \" does not exist in postings; doc=\" + j);\n                }\n                postingsTermsEnum = postingsTerms.iterator(postingsTermsEnum);\n              } else {\n                postingsTermsEnum = null;\n              }\n              \n              long tfvComputedTermCountForField = 0;\n              long tfvComputedSumTotalTermFreq = 0;\n              \n              BytesRef term = null;\n              while ((term = termsEnum.next()) != null) {\n                tfvComputedTermCountForField++;\n                \n                if (termsEnum.docFreq() != 1) {\n                  throw new RuntimeException(\"vector docFreq for doc \" + j + \", field \" + field + \", term\" + term + \" != 1\");\n                }\n                \n                long totalTermFreq = termsEnum.totalTermFreq();\n                \n                if (totalTermFreq != -1 && totalTermFreq <= 0) {\n                  throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq + \" is out of bounds\");\n                }\n\n                final boolean hasPositions;\n                final boolean hasOffsets;\n                final boolean hasFreqs;\n\n                // TODO: really we need a reflection/query\n                // API so we can just ask what was indexed\n                // instead of \"probing\"...\n\n                // Try offsets:\n                postings = termsEnum.docsAndPositions(null, postings, true);\n                if (postings == null) {\n                  hasOffsets = false;\n                  // Try only positions:\n                  postings = termsEnum.docsAndPositions(null, postings, false);\n                  if (postings == null) {\n                    hasPositions = false;\n                    // Try docIDs & freqs:\n                    docs = termsEnum.docs(null, docs, true);\n                    if (docs == null) {\n                      // OK, only docIDs:\n                      hasFreqs = false;\n                      docs = termsEnum.docs(null, docs, false);\n                    } else {\n                      hasFreqs = true;\n                    }\n                  } else {\n                    hasPositions = true;\n                    hasFreqs = true;\n                  }\n                } else {\n                  hasOffsets = true;\n                  // NOTE: may be a lie... but we accept -1 below\n                  hasPositions = true;\n                  hasFreqs = true;\n                }\n\n                final DocsEnum docs2;\n                if (hasPositions || hasOffsets) {\n                  assert postings != null;\n                  docs2 = postings;\n                } else {\n                  assert docs != null;\n                  docs2 = docs;\n                }\n\n                final DocsEnum postingsDocs2;\n                final boolean postingsHasFreq;\n                if (crossCheckTermVectors) {\n                  if (!postingsTermsEnum.seekExact(term, true)) {\n                    throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" does not exist in postings; doc=\" + j);\n                  }\n                  postingsPostings = postingsTermsEnum.docsAndPositions(null, postingsPostings, true);\n                  if (postingsPostings == null) {\n                    // Term vectors were indexed w/ offsets but postings were not\n                    postingsPostings = postingsTermsEnum.docsAndPositions(null, postingsPostings, false);\n                    if (postingsPostings == null) {\n                      postingsDocs = postingsTermsEnum.docs(null, postingsDocs, true);\n                      if (postingsDocs == null) {\n                        postingsHasFreq = false;\n                        postingsDocs = postingsTermsEnum.docs(null, postingsDocs, false);\n                        if (postingsDocs == null) {\n                          throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" does not exist in postings; doc=\" + j);\n                        }\n                      } else {\n                        postingsHasFreq = true;\n                      }\n                    } else {\n                      postingsHasFreq = true;\n                    }\n                  } else {\n                    postingsHasFreq = true;\n                  }\n\n                  if (postingsPostings != null) {\n                    postingsDocs2 = postingsPostings;\n                  } else {\n                    postingsDocs2 = postingsDocs;\n                  }\n                  \n                  final int advanceDoc = postingsDocs2.advance(j);\n                  if (advanceDoc != j) {\n                    throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \": doc=\" + j + \" was not found in postings (got: \" + advanceDoc + \")\");\n                  }\n                } else {\n                  postingsDocs2 = null;\n                  postingsHasFreq = false;\n                }\n\n                final int doc = docs2.nextDoc();\n                  \n                if (doc != 0) {\n                  throw new RuntimeException(\"vector for doc \" + j + \" didn't return docID=0: got docID=\" + doc);\n                }\n\n                if (hasFreqs) {\n                  final int tf = docs2.freq();\n                  if (tf <= 0) {\n                    throw new RuntimeException(\"vector freq \" + tf + \" is out of bounds\");\n                  }\n                  if (totalTermFreq != -1 && totalTermFreq != tf) {\n                    throw new RuntimeException(\"vector totalTermFreq \" + totalTermFreq + \" != tf \" + tf);\n                  }\n                  if (crossCheckTermVectors && postingsHasFreq) {\n                    if (postingsDocs2.freq() != tf) {\n                      throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": freq=\" + tf + \" differs from postings freq=\" + postingsDocs2.freq());\n                    }\n                  }\n                  tfvComputedSumTotalTermFreq += tf;\n                \n                  if (hasPositions || hasOffsets) {\n                    int lastPosition = -1;\n                    //int lastStartOffset = -1;\n                    for (int i = 0; i < tf; i++) {\n                      int pos = postings.nextPosition();\n                      if (hasPositions) {\n                        if (pos != -1 && pos < 0) {\n                          throw new RuntimeException(\"vector position \" + pos + \" is out of bounds\");\n                        }\n                        if (pos < lastPosition) {\n                          throw new RuntimeException(\"vector position \" + pos + \" < lastPos \" + lastPosition);\n                        }\n                    \n                        lastPosition = pos;\n                      }\n\n                      if (crossCheckTermVectors && postingsPostings != null) {\n                        int postingsPos = postingsPostings.nextPosition();\n                        if (pos != -1 && postingsPos != -1 && pos != postingsPos) {\n                          throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": pos=\" + pos + \" differs from postings pos=\" + postingsPos);\n                        }\n                      }\n\n                      if (hasOffsets) {\n                        // Call the methods to at least make\n                        // sure they don't throw exc:\n                        final int startOffset = postings.startOffset();\n                        final int endOffset = postings.endOffset();\n                        // TODO: these are too anal...?\n                        /*\n                        if (endOffset < startOffset) {\n                          throw new RuntimeException(\"vector startOffset=\" + startOffset + \" is > endOffset=\" + endOffset);\n                        }\n                        if (startOffset < lastStartOffset) {\n                          throw new RuntimeException(\"vector startOffset=\" + startOffset + \" is < prior startOffset=\" + lastStartOffset);\n                        }\n                        lastStartOffset = startOffset;\n                        */\n\n                        if (crossCheckTermVectors && postingsPostings != null) {\n                          final int postingsStartOffset = postingsPostings.startOffset();\n\n                          final int postingsEndOffset = postingsPostings.endOffset();\n                          if (startOffset != -1 && postingsStartOffset != -1 && startOffset != postingsStartOffset) {\n                            throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": startOffset=\" + startOffset + \" differs from postings startOffset=\" + postingsStartOffset);\n                          }\n                          if (endOffset != -1 && postingsEndOffset != -1 && endOffset != postingsEndOffset) {\n                            throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": endOffset=\" + endOffset + \" differs from postings endOffset=\" + postingsEndOffset);\n                          }\n                        }\n                      }\n                    }\n                  }\n                }\n                  \n                if (docs2.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                  throw new RuntimeException(\"vector for doc \" + j + \" references multiple documents!\");\n                }\n              }\n              \n              long uniqueTermCount = terms.getUniqueTermCount();\n              if (uniqueTermCount != -1 && uniqueTermCount != tfvComputedTermCountForField) {\n                throw new RuntimeException(\"vector term count for doc \" + j + \", field \" + field + \" = \" + uniqueTermCount + \" != recomputed term count=\" + tfvComputedTermCountForField);\n              }\n              \n              int docCount = terms.getDocCount();\n              if (docCount != -1 && docCount != 1) {\n                throw new RuntimeException(\"vector doc count for doc \" + j + \", field \" + field + \" = \" + docCount + \" != 1\");\n              }\n              \n              long sumDocFreq = terms.getSumDocFreq();\n              if (sumDocFreq != -1 && sumDocFreq != tfvComputedTermCountForField) {\n                throw new RuntimeException(\"vector postings count for doc \" + j + \", field \" + field + \" = \" + sumDocFreq + \" != recomputed postings count=\" + tfvComputedTermCountForField);\n              }\n              \n              long sumTotalTermFreq = terms.getSumTotalTermFreq();\n              if (sumTotalTermFreq != -1 && sumTotalTermFreq != tfvComputedSumTotalTermFreq) {\n                throw new RuntimeException(\"vector sumTotalTermFreq for doc \" + j + \", field \" + field + \" = \" + sumTotalTermFreq + \" != recomputed sumTotalTermFreq=\" + tfvComputedSumTotalTermFreq);\n              }\n              \n              tfvComputedTermCount += tfvComputedTermCountForField;\n            }\n            \n            int tfvUniqueFieldCount = tfv.getUniqueFieldCount();\n            if (tfvUniqueFieldCount != -1 && tfvUniqueFieldCount != tfvComputedFieldCount) {\n              throw new RuntimeException(\"vector field count for doc \" + j + \"=\" + tfvUniqueFieldCount + \" != recomputed uniqueFieldCount=\" + tfvComputedFieldCount);\n            }\n            \n            long tfvUniqueTermCount = tfv.getUniqueTermCount();\n            if (tfvUniqueTermCount != -1 && tfvUniqueTermCount != tfvComputedTermCount) {\n              throw new RuntimeException(\"vector term count for doc \" + j + \"=\" + tfvUniqueTermCount + \" != recomputed uniqueTermCount=\" + tfvComputedTermCount);\n            }\n          }\n        }\n      }\n      \n      msg(\"OK [\" + status.totVectors + \" total vector count; avg \" + \n          format.format((((float) status.totVectors) / status.docCount)) + \" term/freq vector fields per doc]\");\n    } catch (Throwable e) {\n      msg(\"ERROR [\" + String.valueOf(e.getMessage()) + \"]\");\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * Test term vectors for a segment.\n   */\n  private Status.TermVectorStatus testTermVectors(SegmentInfo info, SegmentReader reader, NumberFormat format) {\n    final Status.TermVectorStatus status = new Status.TermVectorStatus();\n    \n    TermsEnum termsEnum = null;\n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: term vectors........\");\n      }\n\n      // TODO: maybe we can factor out testTermIndex and reuse here?\n      DocsEnum docs = null;\n      DocsEnum docsAndFreqs = null;\n      DocsAndPositionsEnum postings = null;\n      final Bits liveDocs = reader.getLiveDocs();\n      for (int j = 0; j < info.docCount; ++j) {\n        if (liveDocs == null || liveDocs.get(j)) {\n          status.docCount++;\n          Fields tfv = reader.getTermVectors(j);\n          if (tfv != null) {\n            int tfvComputedFieldCount = 0;\n            long tfvComputedTermCount = 0;\n\n            FieldsEnum fieldsEnum = tfv.iterator();\n            String field = null;\n            String lastField = null;\n            while((field = fieldsEnum.next()) != null) {\n              status.totVectors++;\n              tfvComputedFieldCount++;\n\n              if (lastField == null) {\n                lastField = field;\n              } else if (lastField.compareTo(field) > 0) {\n                throw new RuntimeException(\"vector fields are out of order: lastField=\" + lastField + \" field=\" + field + \" doc=\" + j);\n              }\n              \n              Terms terms = tfv.terms(field);\n              termsEnum = terms.iterator(termsEnum);\n              \n              long tfvComputedTermCountForField = 0;\n              long tfvComputedSumTotalTermFreq = 0;\n              \n              BytesRef term = null;\n              while ((term = termsEnum.next()) != null) {\n                tfvComputedTermCountForField++;\n                \n                if (termsEnum.docFreq() != 1) {\n                  throw new RuntimeException(\"vector docFreq for doc \" + j + \", field \" + field + \", term\" + term + \" != 1\");\n                }\n                \n                long totalTermFreq = termsEnum.totalTermFreq();\n                \n                if (totalTermFreq != -1 && totalTermFreq <= 0) {\n                  throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq + \" is out of bounds\");\n                }\n\n                postings = termsEnum.docsAndPositions(null, postings);\n                if (postings == null) {\n                  docsAndFreqs = termsEnum.docs(null, docsAndFreqs, true);\n                  if (docsAndFreqs == null) {\n                    docs = termsEnum.docs(null, docs, false);\n                  } else {\n                    docs = docsAndFreqs;\n                  }\n                } else {\n                  docs = docsAndFreqs = postings;\n                }\n\n                final int doc = docs.nextDoc();\n                  \n                if (doc != 0) {\n                  throw new RuntimeException(\"vector for doc \" + j + \" didn't return docID=0: got docID=\" + doc);\n                }\n\n                if (docsAndFreqs != null) {\n                  final int tf = docsAndFreqs.freq();\n                  if (tf <= 0) {\n                    throw new RuntimeException(\"vector freq \" + tf + \" is out of bounds\");\n                  }\n                  if (totalTermFreq != -1 && totalTermFreq != tf) {\n                    throw new RuntimeException(\"vector totalTermFreq \" + totalTermFreq + \" != tf \" + tf);\n                  }\n                  tfvComputedSumTotalTermFreq += tf;\n                \n                  if (postings != null) {\n                    int lastPosition = -1;\n                    for (int i = 0; i < tf; i++) {\n                      int pos = postings.nextPosition();\n                      if (pos != -1 && pos < 0) {\n                        throw new RuntimeException(\"vector position \" + pos + \" is out of bounds\");\n                      }\n                    \n                      if (pos < lastPosition) {\n                        throw new RuntimeException(\"vector position \" + pos + \" < lastPos \" + lastPosition);\n                      }\n                    \n                      lastPosition = pos;\n                    }\n                  }\n                }\n                  \n                if (docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                  throw new RuntimeException(\"vector for doc \" + j + \" references multiple documents!\");\n                }\n              }\n              \n              long uniqueTermCount = terms.getUniqueTermCount();\n              if (uniqueTermCount != -1 && uniqueTermCount != tfvComputedTermCountForField) {\n                throw new RuntimeException(\"vector term count for doc \" + j + \", field \" + field + \" = \" + uniqueTermCount + \" != recomputed term count=\" + tfvComputedTermCountForField);\n              }\n              \n              int docCount = terms.getDocCount();\n              if (docCount != -1 && docCount != 1) {\n                throw new RuntimeException(\"vector doc count for doc \" + j + \", field \" + field + \" = \" + docCount + \" != 1\");\n              }\n              \n              long sumDocFreq = terms.getSumDocFreq();\n              if (sumDocFreq != -1 && sumDocFreq != tfvComputedTermCountForField) {\n                throw new RuntimeException(\"vector postings count for doc \" + j + \", field \" + field + \" = \" + sumDocFreq + \" != recomputed postings count=\" + tfvComputedTermCountForField);\n              }\n              \n              long sumTotalTermFreq = terms.getSumTotalTermFreq();\n              if (sumTotalTermFreq != -1 && sumTotalTermFreq != tfvComputedSumTotalTermFreq) {\n                throw new RuntimeException(\"vector sumTotalTermFreq for doc \" + j + \", field \" + field + \" = \" + sumTotalTermFreq + \" != recomputed sumTotalTermFreq=\" + tfvComputedSumTotalTermFreq);\n              }\n              \n              tfvComputedTermCount += tfvComputedTermCountForField;\n            }\n            \n            int tfvUniqueFieldCount = tfv.getUniqueFieldCount();\n            if (tfvUniqueFieldCount != -1 && tfvUniqueFieldCount != tfvComputedFieldCount) {\n              throw new RuntimeException(\"vector field count for doc \" + j + \"=\" + tfvUniqueFieldCount + \" != recomputed uniqueFieldCount=\" + tfvComputedFieldCount);\n            }\n            \n            long tfvUniqueTermCount = tfv.getUniqueTermCount();\n            if (tfvUniqueTermCount != -1 && tfvUniqueTermCount != tfvComputedTermCount) {\n              throw new RuntimeException(\"vector term count for doc \" + j + \"=\" + tfvUniqueTermCount + \" != recomputed uniqueTermCount=\" + tfvComputedTermCount);\n            }\n          }\n        }\n      }\n      \n      msg(\"OK [\" + status.totVectors + \" total vector count; avg \" + \n          format.format((((float) status.totVectors) / status.docCount)) + \" term/freq vector fields per doc]\");\n    } catch (Throwable e) {\n      msg(\"ERROR [\" + String.valueOf(e.getMessage()) + \"]\");\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d3eed68223cb841b4f909e2ef7dba9c54f3263f7","date":1326844908,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/CheckIndex#testTermVectors(SegmentInfo,SegmentReader,NumberFormat).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/CheckIndex#testTermVectors(SegmentInfo,SegmentReader,NumberFormat).mjava","sourceNew":"  /**\n   * Test term vectors for a segment.\n   */\n  private Status.TermVectorStatus testTermVectors(SegmentInfo info, SegmentReader reader, NumberFormat format) {\n    final Status.TermVectorStatus status = new Status.TermVectorStatus();\n    \n    // TODO: in theory we could test that term vectors have\n    // same terms/pos/offsets as the postings, but it'd be\n    // very slow...\n\n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: term vectors........\");\n      }\n\n      // TODO: maybe we can factor out testTermIndex and reuse here?\n      DocsEnum docs = null;\n      DocsAndPositionsEnum postings = null;\n\n      // Only used if crossCheckTermVectors is true:\n      DocsEnum postingsDocs = null;\n      DocsAndPositionsEnum postingsPostings = null;\n\n      final Bits liveDocs = reader.getLiveDocs();\n\n      final Fields postingsFields;\n      // TODO: testTermsIndex\n      if (crossCheckTermVectors) {\n        postingsFields = reader.fields();\n      } else {\n        postingsFields = null;\n      }\n\n      TermsEnum termsEnum = null;\n      TermsEnum postingsTermsEnum = null;\n\n      for (int j = 0; j < info.docCount; ++j) {\n        if (liveDocs == null || liveDocs.get(j)) {\n          status.docCount++;\n          Fields tfv = reader.getTermVectors(j);\n          if (tfv != null) {\n            int tfvComputedFieldCount = 0;\n            long tfvComputedTermCount = 0;\n\n            FieldsEnum fieldsEnum = tfv.iterator();\n            String field = null;\n            String lastField = null;\n            while((field = fieldsEnum.next()) != null) {\n              status.totVectors++;\n              tfvComputedFieldCount++;\n\n              if (lastField == null) {\n                lastField = field;\n              } else if (lastField.compareTo(field) > 0) {\n                throw new RuntimeException(\"vector fields are out of order: lastField=\" + lastField + \" field=\" + field + \" doc=\" + j);\n              }\n              \n              Terms terms = tfv.terms(field);\n              termsEnum = terms.iterator(termsEnum);\n\n              if (crossCheckTermVectors) {\n                Terms postingsTerms = postingsFields.terms(field);\n                if (postingsTerms == null) {\n                  throw new RuntimeException(\"vector field=\" + field + \" does not exist in postings; doc=\" + j);\n                }\n                postingsTermsEnum = postingsTerms.iterator(postingsTermsEnum);\n              } else {\n                postingsTermsEnum = null;\n              }\n              \n              long tfvComputedTermCountForField = 0;\n              long tfvComputedSumTotalTermFreq = 0;\n              \n              BytesRef lastTerm = null;\n              Comparator<BytesRef> termComp = terms.getComparator();\n              BytesRef term = null;\n              while ((term = termsEnum.next()) != null) {\n                tfvComputedTermCountForField++;\n                \n                // make sure terms arrive in order according to\n                // the comp\n                if (lastTerm == null) {\n                  lastTerm = BytesRef.deepCopyOf(term);\n                } else {\n                  if (termComp.compare(lastTerm, term) >= 0) {\n                    throw new RuntimeException(\"vector terms out of order for doc \" + j + \": lastTerm=\" + lastTerm + \" term=\" + term);\n                  }\n                  lastTerm.copyBytes(term);\n                }\n                \n                if (termsEnum.docFreq() != 1) {\n                  throw new RuntimeException(\"vector docFreq for doc \" + j + \", field \" + field + \", term\" + term + \" != 1\");\n                }\n                \n                long totalTermFreq = termsEnum.totalTermFreq();\n                \n                if (totalTermFreq != -1 && totalTermFreq <= 0) {\n                  throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq + \" is out of bounds\");\n                }\n\n                final boolean hasPositions;\n                final boolean hasOffsets;\n                final boolean hasFreqs;\n\n                // TODO: really we need a reflection/query\n                // API so we can just ask what was indexed\n                // instead of \"probing\"...\n\n                // Try offsets:\n                postings = termsEnum.docsAndPositions(null, postings, true);\n                if (postings == null) {\n                  hasOffsets = false;\n                  // Try only positions:\n                  postings = termsEnum.docsAndPositions(null, postings, false);\n                  if (postings == null) {\n                    hasPositions = false;\n                    // Try docIDs & freqs:\n                    docs = termsEnum.docs(null, docs, true);\n                    if (docs == null) {\n                      // OK, only docIDs:\n                      hasFreqs = false;\n                      docs = termsEnum.docs(null, docs, false);\n                    } else {\n                      hasFreqs = true;\n                    }\n                  } else {\n                    hasPositions = true;\n                    hasFreqs = true;\n                  }\n                } else {\n                  hasOffsets = true;\n                  // NOTE: may be a lie... but we accept -1 below\n                  hasPositions = true;\n                  hasFreqs = true;\n                }\n\n                final DocsEnum docs2;\n                if (hasPositions || hasOffsets) {\n                  assert postings != null;\n                  docs2 = postings;\n                } else {\n                  assert docs != null;\n                  docs2 = docs;\n                }\n\n                final DocsEnum postingsDocs2;\n                final boolean postingsHasFreq;\n                if (crossCheckTermVectors) {\n                  if (!postingsTermsEnum.seekExact(term, true)) {\n                    throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" does not exist in postings; doc=\" + j);\n                  }\n                  postingsPostings = postingsTermsEnum.docsAndPositions(null, postingsPostings, true);\n                  if (postingsPostings == null) {\n                    // Term vectors were indexed w/ offsets but postings were not\n                    postingsPostings = postingsTermsEnum.docsAndPositions(null, postingsPostings, false);\n                    if (postingsPostings == null) {\n                      postingsDocs = postingsTermsEnum.docs(null, postingsDocs, true);\n                      if (postingsDocs == null) {\n                        postingsHasFreq = false;\n                        postingsDocs = postingsTermsEnum.docs(null, postingsDocs, false);\n                        if (postingsDocs == null) {\n                          throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" does not exist in postings; doc=\" + j);\n                        }\n                      } else {\n                        postingsHasFreq = true;\n                      }\n                    } else {\n                      postingsHasFreq = true;\n                    }\n                  } else {\n                    postingsHasFreq = true;\n                  }\n\n                  if (postingsPostings != null) {\n                    postingsDocs2 = postingsPostings;\n                  } else {\n                    postingsDocs2 = postingsDocs;\n                  }\n                  \n                  final int advanceDoc = postingsDocs2.advance(j);\n                  if (advanceDoc != j) {\n                    throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \": doc=\" + j + \" was not found in postings (got: \" + advanceDoc + \")\");\n                  }\n                } else {\n                  postingsDocs2 = null;\n                  postingsHasFreq = false;\n                }\n\n                final int doc = docs2.nextDoc();\n                  \n                if (doc != 0) {\n                  throw new RuntimeException(\"vector for doc \" + j + \" didn't return docID=0: got docID=\" + doc);\n                }\n\n                if (hasFreqs) {\n                  final int tf = docs2.freq();\n                  if (tf <= 0) {\n                    throw new RuntimeException(\"vector freq \" + tf + \" is out of bounds\");\n                  }\n                  if (totalTermFreq != -1 && totalTermFreq != tf) {\n                    throw new RuntimeException(\"vector totalTermFreq \" + totalTermFreq + \" != tf \" + tf);\n                  }\n                  if (crossCheckTermVectors && postingsHasFreq) {\n                    if (postingsDocs2.freq() != tf) {\n                      throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": freq=\" + tf + \" differs from postings freq=\" + postingsDocs2.freq());\n                    }\n                  }\n                  tfvComputedSumTotalTermFreq += tf;\n                \n                  if (hasPositions || hasOffsets) {\n                    int lastPosition = -1;\n                    //int lastStartOffset = -1;\n                    for (int i = 0; i < tf; i++) {\n                      int pos = postings.nextPosition();\n                      if (hasPositions) {\n                        if (pos != -1 && pos < 0) {\n                          throw new RuntimeException(\"vector position \" + pos + \" is out of bounds\");\n                        }\n                        if (pos < lastPosition) {\n                          throw new RuntimeException(\"vector position \" + pos + \" < lastPos \" + lastPosition);\n                        }\n                    \n                        lastPosition = pos;\n                      }\n\n                      if (crossCheckTermVectors && postingsPostings != null) {\n                        int postingsPos = postingsPostings.nextPosition();\n                        if (pos != -1 && postingsPos != -1 && pos != postingsPos) {\n                          throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": pos=\" + pos + \" differs from postings pos=\" + postingsPos);\n                        }\n                      }\n\n                      if (hasOffsets) {\n                        // Call the methods to at least make\n                        // sure they don't throw exc:\n                        final int startOffset = postings.startOffset();\n                        final int endOffset = postings.endOffset();\n                        // TODO: these are too anal...?\n                        /*\n                        if (endOffset < startOffset) {\n                          throw new RuntimeException(\"vector startOffset=\" + startOffset + \" is > endOffset=\" + endOffset);\n                        }\n                        if (startOffset < lastStartOffset) {\n                          throw new RuntimeException(\"vector startOffset=\" + startOffset + \" is < prior startOffset=\" + lastStartOffset);\n                        }\n                        lastStartOffset = startOffset;\n                        */\n\n                        if (crossCheckTermVectors && postingsPostings != null) {\n                          final int postingsStartOffset = postingsPostings.startOffset();\n\n                          final int postingsEndOffset = postingsPostings.endOffset();\n                          if (startOffset != -1 && postingsStartOffset != -1 && startOffset != postingsStartOffset) {\n                            throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": startOffset=\" + startOffset + \" differs from postings startOffset=\" + postingsStartOffset);\n                          }\n                          if (endOffset != -1 && postingsEndOffset != -1 && endOffset != postingsEndOffset) {\n                            throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": endOffset=\" + endOffset + \" differs from postings endOffset=\" + postingsEndOffset);\n                          }\n                        }\n                      }\n                    }\n                  }\n                }\n                  \n                if (docs2.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                  throw new RuntimeException(\"vector for doc \" + j + \" references multiple documents!\");\n                }\n              }\n              \n              long uniqueTermCount = terms.getUniqueTermCount();\n              if (uniqueTermCount != -1 && uniqueTermCount != tfvComputedTermCountForField) {\n                throw new RuntimeException(\"vector term count for doc \" + j + \", field \" + field + \" = \" + uniqueTermCount + \" != recomputed term count=\" + tfvComputedTermCountForField);\n              }\n              \n              int docCount = terms.getDocCount();\n              if (docCount != -1 && docCount != 1) {\n                throw new RuntimeException(\"vector doc count for doc \" + j + \", field \" + field + \" = \" + docCount + \" != 1\");\n              }\n              \n              long sumDocFreq = terms.getSumDocFreq();\n              if (sumDocFreq != -1 && sumDocFreq != tfvComputedTermCountForField) {\n                throw new RuntimeException(\"vector postings count for doc \" + j + \", field \" + field + \" = \" + sumDocFreq + \" != recomputed postings count=\" + tfvComputedTermCountForField);\n              }\n              \n              long sumTotalTermFreq = terms.getSumTotalTermFreq();\n              if (sumTotalTermFreq != -1 && sumTotalTermFreq != tfvComputedSumTotalTermFreq) {\n                throw new RuntimeException(\"vector sumTotalTermFreq for doc \" + j + \", field \" + field + \" = \" + sumTotalTermFreq + \" != recomputed sumTotalTermFreq=\" + tfvComputedSumTotalTermFreq);\n              }\n              \n              tfvComputedTermCount += tfvComputedTermCountForField;\n            }\n            \n            int tfvUniqueFieldCount = tfv.getUniqueFieldCount();\n            if (tfvUniqueFieldCount != -1 && tfvUniqueFieldCount != tfvComputedFieldCount) {\n              throw new RuntimeException(\"vector field count for doc \" + j + \"=\" + tfvUniqueFieldCount + \" != recomputed uniqueFieldCount=\" + tfvComputedFieldCount);\n            }\n            \n            long tfvUniqueTermCount = tfv.getUniqueTermCount();\n            if (tfvUniqueTermCount != -1 && tfvUniqueTermCount != tfvComputedTermCount) {\n              throw new RuntimeException(\"vector term count for doc \" + j + \"=\" + tfvUniqueTermCount + \" != recomputed uniqueTermCount=\" + tfvComputedTermCount);\n            }\n          }\n        }\n      }\n      \n      msg(\"OK [\" + status.totVectors + \" total vector count; avg \" + \n          format.format((((float) status.totVectors) / status.docCount)) + \" term/freq vector fields per doc]\");\n    } catch (Throwable e) {\n      msg(\"ERROR [\" + String.valueOf(e.getMessage()) + \"]\");\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * Test term vectors for a segment.\n   */\n  private Status.TermVectorStatus testTermVectors(SegmentInfo info, SegmentReader reader, NumberFormat format) {\n    final Status.TermVectorStatus status = new Status.TermVectorStatus();\n    \n    // TODO: in theory we could test that term vectors have\n    // same terms/pos/offsets as the postings, but it'd be\n    // very slow...\n\n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: term vectors........\");\n      }\n\n      // TODO: maybe we can factor out testTermIndex and reuse here?\n      DocsEnum docs = null;\n      DocsAndPositionsEnum postings = null;\n\n      // Only used if crossCheckTermVectors is true:\n      DocsEnum postingsDocs = null;\n      DocsAndPositionsEnum postingsPostings = null;\n\n      final Bits liveDocs = reader.getLiveDocs();\n\n      final Fields postingsFields;\n      // TODO: testTermsIndex\n      if (crossCheckTermVectors) {\n        postingsFields = reader.fields();\n      } else {\n        postingsFields = null;\n      }\n\n      TermsEnum termsEnum = null;\n      TermsEnum postingsTermsEnum = null;\n\n      for (int j = 0; j < info.docCount; ++j) {\n        if (liveDocs == null || liveDocs.get(j)) {\n          status.docCount++;\n          Fields tfv = reader.getTermVectors(j);\n          if (tfv != null) {\n            int tfvComputedFieldCount = 0;\n            long tfvComputedTermCount = 0;\n\n            FieldsEnum fieldsEnum = tfv.iterator();\n            String field = null;\n            String lastField = null;\n            while((field = fieldsEnum.next()) != null) {\n              status.totVectors++;\n              tfvComputedFieldCount++;\n\n              if (lastField == null) {\n                lastField = field;\n              } else if (lastField.compareTo(field) > 0) {\n                throw new RuntimeException(\"vector fields are out of order: lastField=\" + lastField + \" field=\" + field + \" doc=\" + j);\n              }\n              \n              Terms terms = tfv.terms(field);\n              termsEnum = terms.iterator(termsEnum);\n\n              if (crossCheckTermVectors) {\n                Terms postingsTerms = postingsFields.terms(field);\n                if (postingsTerms == null) {\n                  throw new RuntimeException(\"vector field=\" + field + \" does not exist in postings; doc=\" + j);\n                }\n                postingsTermsEnum = postingsTerms.iterator(postingsTermsEnum);\n              } else {\n                postingsTermsEnum = null;\n              }\n              \n              long tfvComputedTermCountForField = 0;\n              long tfvComputedSumTotalTermFreq = 0;\n              \n              BytesRef term = null;\n              while ((term = termsEnum.next()) != null) {\n                tfvComputedTermCountForField++;\n                \n                if (termsEnum.docFreq() != 1) {\n                  throw new RuntimeException(\"vector docFreq for doc \" + j + \", field \" + field + \", term\" + term + \" != 1\");\n                }\n                \n                long totalTermFreq = termsEnum.totalTermFreq();\n                \n                if (totalTermFreq != -1 && totalTermFreq <= 0) {\n                  throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq + \" is out of bounds\");\n                }\n\n                final boolean hasPositions;\n                final boolean hasOffsets;\n                final boolean hasFreqs;\n\n                // TODO: really we need a reflection/query\n                // API so we can just ask what was indexed\n                // instead of \"probing\"...\n\n                // Try offsets:\n                postings = termsEnum.docsAndPositions(null, postings, true);\n                if (postings == null) {\n                  hasOffsets = false;\n                  // Try only positions:\n                  postings = termsEnum.docsAndPositions(null, postings, false);\n                  if (postings == null) {\n                    hasPositions = false;\n                    // Try docIDs & freqs:\n                    docs = termsEnum.docs(null, docs, true);\n                    if (docs == null) {\n                      // OK, only docIDs:\n                      hasFreqs = false;\n                      docs = termsEnum.docs(null, docs, false);\n                    } else {\n                      hasFreqs = true;\n                    }\n                  } else {\n                    hasPositions = true;\n                    hasFreqs = true;\n                  }\n                } else {\n                  hasOffsets = true;\n                  // NOTE: may be a lie... but we accept -1 below\n                  hasPositions = true;\n                  hasFreqs = true;\n                }\n\n                final DocsEnum docs2;\n                if (hasPositions || hasOffsets) {\n                  assert postings != null;\n                  docs2 = postings;\n                } else {\n                  assert docs != null;\n                  docs2 = docs;\n                }\n\n                final DocsEnum postingsDocs2;\n                final boolean postingsHasFreq;\n                if (crossCheckTermVectors) {\n                  if (!postingsTermsEnum.seekExact(term, true)) {\n                    throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" does not exist in postings; doc=\" + j);\n                  }\n                  postingsPostings = postingsTermsEnum.docsAndPositions(null, postingsPostings, true);\n                  if (postingsPostings == null) {\n                    // Term vectors were indexed w/ offsets but postings were not\n                    postingsPostings = postingsTermsEnum.docsAndPositions(null, postingsPostings, false);\n                    if (postingsPostings == null) {\n                      postingsDocs = postingsTermsEnum.docs(null, postingsDocs, true);\n                      if (postingsDocs == null) {\n                        postingsHasFreq = false;\n                        postingsDocs = postingsTermsEnum.docs(null, postingsDocs, false);\n                        if (postingsDocs == null) {\n                          throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" does not exist in postings; doc=\" + j);\n                        }\n                      } else {\n                        postingsHasFreq = true;\n                      }\n                    } else {\n                      postingsHasFreq = true;\n                    }\n                  } else {\n                    postingsHasFreq = true;\n                  }\n\n                  if (postingsPostings != null) {\n                    postingsDocs2 = postingsPostings;\n                  } else {\n                    postingsDocs2 = postingsDocs;\n                  }\n                  \n                  final int advanceDoc = postingsDocs2.advance(j);\n                  if (advanceDoc != j) {\n                    throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \": doc=\" + j + \" was not found in postings (got: \" + advanceDoc + \")\");\n                  }\n                } else {\n                  postingsDocs2 = null;\n                  postingsHasFreq = false;\n                }\n\n                final int doc = docs2.nextDoc();\n                  \n                if (doc != 0) {\n                  throw new RuntimeException(\"vector for doc \" + j + \" didn't return docID=0: got docID=\" + doc);\n                }\n\n                if (hasFreqs) {\n                  final int tf = docs2.freq();\n                  if (tf <= 0) {\n                    throw new RuntimeException(\"vector freq \" + tf + \" is out of bounds\");\n                  }\n                  if (totalTermFreq != -1 && totalTermFreq != tf) {\n                    throw new RuntimeException(\"vector totalTermFreq \" + totalTermFreq + \" != tf \" + tf);\n                  }\n                  if (crossCheckTermVectors && postingsHasFreq) {\n                    if (postingsDocs2.freq() != tf) {\n                      throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": freq=\" + tf + \" differs from postings freq=\" + postingsDocs2.freq());\n                    }\n                  }\n                  tfvComputedSumTotalTermFreq += tf;\n                \n                  if (hasPositions || hasOffsets) {\n                    int lastPosition = -1;\n                    //int lastStartOffset = -1;\n                    for (int i = 0; i < tf; i++) {\n                      int pos = postings.nextPosition();\n                      if (hasPositions) {\n                        if (pos != -1 && pos < 0) {\n                          throw new RuntimeException(\"vector position \" + pos + \" is out of bounds\");\n                        }\n                        if (pos < lastPosition) {\n                          throw new RuntimeException(\"vector position \" + pos + \" < lastPos \" + lastPosition);\n                        }\n                    \n                        lastPosition = pos;\n                      }\n\n                      if (crossCheckTermVectors && postingsPostings != null) {\n                        int postingsPos = postingsPostings.nextPosition();\n                        if (pos != -1 && postingsPos != -1 && pos != postingsPos) {\n                          throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": pos=\" + pos + \" differs from postings pos=\" + postingsPos);\n                        }\n                      }\n\n                      if (hasOffsets) {\n                        // Call the methods to at least make\n                        // sure they don't throw exc:\n                        final int startOffset = postings.startOffset();\n                        final int endOffset = postings.endOffset();\n                        // TODO: these are too anal...?\n                        /*\n                        if (endOffset < startOffset) {\n                          throw new RuntimeException(\"vector startOffset=\" + startOffset + \" is > endOffset=\" + endOffset);\n                        }\n                        if (startOffset < lastStartOffset) {\n                          throw new RuntimeException(\"vector startOffset=\" + startOffset + \" is < prior startOffset=\" + lastStartOffset);\n                        }\n                        lastStartOffset = startOffset;\n                        */\n\n                        if (crossCheckTermVectors && postingsPostings != null) {\n                          final int postingsStartOffset = postingsPostings.startOffset();\n\n                          final int postingsEndOffset = postingsPostings.endOffset();\n                          if (startOffset != -1 && postingsStartOffset != -1 && startOffset != postingsStartOffset) {\n                            throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": startOffset=\" + startOffset + \" differs from postings startOffset=\" + postingsStartOffset);\n                          }\n                          if (endOffset != -1 && postingsEndOffset != -1 && endOffset != postingsEndOffset) {\n                            throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": endOffset=\" + endOffset + \" differs from postings endOffset=\" + postingsEndOffset);\n                          }\n                        }\n                      }\n                    }\n                  }\n                }\n                  \n                if (docs2.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                  throw new RuntimeException(\"vector for doc \" + j + \" references multiple documents!\");\n                }\n              }\n              \n              long uniqueTermCount = terms.getUniqueTermCount();\n              if (uniqueTermCount != -1 && uniqueTermCount != tfvComputedTermCountForField) {\n                throw new RuntimeException(\"vector term count for doc \" + j + \", field \" + field + \" = \" + uniqueTermCount + \" != recomputed term count=\" + tfvComputedTermCountForField);\n              }\n              \n              int docCount = terms.getDocCount();\n              if (docCount != -1 && docCount != 1) {\n                throw new RuntimeException(\"vector doc count for doc \" + j + \", field \" + field + \" = \" + docCount + \" != 1\");\n              }\n              \n              long sumDocFreq = terms.getSumDocFreq();\n              if (sumDocFreq != -1 && sumDocFreq != tfvComputedTermCountForField) {\n                throw new RuntimeException(\"vector postings count for doc \" + j + \", field \" + field + \" = \" + sumDocFreq + \" != recomputed postings count=\" + tfvComputedTermCountForField);\n              }\n              \n              long sumTotalTermFreq = terms.getSumTotalTermFreq();\n              if (sumTotalTermFreq != -1 && sumTotalTermFreq != tfvComputedSumTotalTermFreq) {\n                throw new RuntimeException(\"vector sumTotalTermFreq for doc \" + j + \", field \" + field + \" = \" + sumTotalTermFreq + \" != recomputed sumTotalTermFreq=\" + tfvComputedSumTotalTermFreq);\n              }\n              \n              tfvComputedTermCount += tfvComputedTermCountForField;\n            }\n            \n            int tfvUniqueFieldCount = tfv.getUniqueFieldCount();\n            if (tfvUniqueFieldCount != -1 && tfvUniqueFieldCount != tfvComputedFieldCount) {\n              throw new RuntimeException(\"vector field count for doc \" + j + \"=\" + tfvUniqueFieldCount + \" != recomputed uniqueFieldCount=\" + tfvComputedFieldCount);\n            }\n            \n            long tfvUniqueTermCount = tfv.getUniqueTermCount();\n            if (tfvUniqueTermCount != -1 && tfvUniqueTermCount != tfvComputedTermCount) {\n              throw new RuntimeException(\"vector term count for doc \" + j + \"=\" + tfvUniqueTermCount + \" != recomputed uniqueTermCount=\" + tfvComputedTermCount);\n            }\n          }\n        }\n      }\n      \n      msg(\"OK [\" + status.totVectors + \" total vector count; avg \" + \n          format.format((((float) status.totVectors) / status.docCount)) + \" term/freq vector fields per doc]\");\n    } catch (Throwable e) {\n      msg(\"ERROR [\" + String.valueOf(e.getMessage()) + \"]\");\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#testTermVectors(SegmentInfo,SegmentReader,NumberFormat).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/CheckIndex#testTermVectors(SegmentInfo,SegmentReader,NumberFormat).mjava","sourceNew":"  /**\n   * Test term vectors for a segment.\n   */\n  private Status.TermVectorStatus testTermVectors(SegmentInfo info, SegmentReader reader, NumberFormat format) {\n    final Status.TermVectorStatus status = new Status.TermVectorStatus();\n    \n    // TODO: in theory we could test that term vectors have\n    // same terms/pos/offsets as the postings, but it'd be\n    // very slow...\n\n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: term vectors........\");\n      }\n\n      // TODO: maybe we can factor out testTermIndex and reuse here?\n      DocsEnum docs = null;\n      DocsAndPositionsEnum postings = null;\n\n      // Only used if crossCheckTermVectors is true:\n      DocsEnum postingsDocs = null;\n      DocsAndPositionsEnum postingsPostings = null;\n\n      final Bits liveDocs = reader.getLiveDocs();\n\n      final Fields postingsFields;\n      // TODO: testTermsIndex\n      if (crossCheckTermVectors) {\n        postingsFields = reader.fields();\n      } else {\n        postingsFields = null;\n      }\n\n      TermsEnum termsEnum = null;\n      TermsEnum postingsTermsEnum = null;\n\n      for (int j = 0; j < info.docCount; ++j) {\n        if (liveDocs == null || liveDocs.get(j)) {\n          status.docCount++;\n          Fields tfv = reader.getTermVectors(j);\n          if (tfv != null) {\n            int tfvComputedFieldCount = 0;\n            long tfvComputedTermCount = 0;\n\n            FieldsEnum fieldsEnum = tfv.iterator();\n            String field = null;\n            String lastField = null;\n            while((field = fieldsEnum.next()) != null) {\n              status.totVectors++;\n              tfvComputedFieldCount++;\n\n              if (lastField == null) {\n                lastField = field;\n              } else if (lastField.compareTo(field) > 0) {\n                throw new RuntimeException(\"vector fields are out of order: lastField=\" + lastField + \" field=\" + field + \" doc=\" + j);\n              }\n              \n              Terms terms = tfv.terms(field);\n              termsEnum = terms.iterator(termsEnum);\n\n              if (crossCheckTermVectors) {\n                Terms postingsTerms = postingsFields.terms(field);\n                if (postingsTerms == null) {\n                  throw new RuntimeException(\"vector field=\" + field + \" does not exist in postings; doc=\" + j);\n                }\n                postingsTermsEnum = postingsTerms.iterator(postingsTermsEnum);\n              } else {\n                postingsTermsEnum = null;\n              }\n              \n              long tfvComputedTermCountForField = 0;\n              long tfvComputedSumTotalTermFreq = 0;\n              \n              BytesRef lastTerm = null;\n              Comparator<BytesRef> termComp = terms.getComparator();\n              BytesRef term = null;\n              while ((term = termsEnum.next()) != null) {\n                tfvComputedTermCountForField++;\n                \n                // make sure terms arrive in order according to\n                // the comp\n                if (lastTerm == null) {\n                  lastTerm = BytesRef.deepCopyOf(term);\n                } else {\n                  if (termComp.compare(lastTerm, term) >= 0) {\n                    throw new RuntimeException(\"vector terms out of order for doc \" + j + \": lastTerm=\" + lastTerm + \" term=\" + term);\n                  }\n                  lastTerm.copyBytes(term);\n                }\n                \n                if (termsEnum.docFreq() != 1) {\n                  throw new RuntimeException(\"vector docFreq for doc \" + j + \", field \" + field + \", term\" + term + \" != 1\");\n                }\n                \n                long totalTermFreq = termsEnum.totalTermFreq();\n                \n                if (totalTermFreq != -1 && totalTermFreq <= 0) {\n                  throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq + \" is out of bounds\");\n                }\n\n                final boolean hasPositions;\n                final boolean hasOffsets;\n                final boolean hasFreqs;\n\n                // TODO: really we need a reflection/query\n                // API so we can just ask what was indexed\n                // instead of \"probing\"...\n\n                // Try offsets:\n                postings = termsEnum.docsAndPositions(null, postings, true);\n                if (postings == null) {\n                  hasOffsets = false;\n                  // Try only positions:\n                  postings = termsEnum.docsAndPositions(null, postings, false);\n                  if (postings == null) {\n                    hasPositions = false;\n                    // Try docIDs & freqs:\n                    docs = termsEnum.docs(null, docs, true);\n                    if (docs == null) {\n                      // OK, only docIDs:\n                      hasFreqs = false;\n                      docs = termsEnum.docs(null, docs, false);\n                    } else {\n                      hasFreqs = true;\n                    }\n                  } else {\n                    hasPositions = true;\n                    hasFreqs = true;\n                  }\n                } else {\n                  hasOffsets = true;\n                  // NOTE: may be a lie... but we accept -1 below\n                  hasPositions = true;\n                  hasFreqs = true;\n                }\n\n                final DocsEnum docs2;\n                if (hasPositions || hasOffsets) {\n                  assert postings != null;\n                  docs2 = postings;\n                } else {\n                  assert docs != null;\n                  docs2 = docs;\n                }\n\n                final DocsEnum postingsDocs2;\n                final boolean postingsHasFreq;\n                if (crossCheckTermVectors) {\n                  if (!postingsTermsEnum.seekExact(term, true)) {\n                    throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" does not exist in postings; doc=\" + j);\n                  }\n                  postingsPostings = postingsTermsEnum.docsAndPositions(null, postingsPostings, true);\n                  if (postingsPostings == null) {\n                    // Term vectors were indexed w/ offsets but postings were not\n                    postingsPostings = postingsTermsEnum.docsAndPositions(null, postingsPostings, false);\n                    if (postingsPostings == null) {\n                      postingsDocs = postingsTermsEnum.docs(null, postingsDocs, true);\n                      if (postingsDocs == null) {\n                        postingsHasFreq = false;\n                        postingsDocs = postingsTermsEnum.docs(null, postingsDocs, false);\n                        if (postingsDocs == null) {\n                          throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" does not exist in postings; doc=\" + j);\n                        }\n                      } else {\n                        postingsHasFreq = true;\n                      }\n                    } else {\n                      postingsHasFreq = true;\n                    }\n                  } else {\n                    postingsHasFreq = true;\n                  }\n\n                  if (postingsPostings != null) {\n                    postingsDocs2 = postingsPostings;\n                  } else {\n                    postingsDocs2 = postingsDocs;\n                  }\n                  \n                  final int advanceDoc = postingsDocs2.advance(j);\n                  if (advanceDoc != j) {\n                    throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \": doc=\" + j + \" was not found in postings (got: \" + advanceDoc + \")\");\n                  }\n                } else {\n                  postingsDocs2 = null;\n                  postingsHasFreq = false;\n                }\n\n                final int doc = docs2.nextDoc();\n                  \n                if (doc != 0) {\n                  throw new RuntimeException(\"vector for doc \" + j + \" didn't return docID=0: got docID=\" + doc);\n                }\n\n                if (hasFreqs) {\n                  final int tf = docs2.freq();\n                  if (tf <= 0) {\n                    throw new RuntimeException(\"vector freq \" + tf + \" is out of bounds\");\n                  }\n                  if (totalTermFreq != -1 && totalTermFreq != tf) {\n                    throw new RuntimeException(\"vector totalTermFreq \" + totalTermFreq + \" != tf \" + tf);\n                  }\n                  if (crossCheckTermVectors && postingsHasFreq) {\n                    if (postingsDocs2.freq() != tf) {\n                      throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": freq=\" + tf + \" differs from postings freq=\" + postingsDocs2.freq());\n                    }\n                  }\n                  tfvComputedSumTotalTermFreq += tf;\n                \n                  if (hasPositions || hasOffsets) {\n                    int lastPosition = -1;\n                    //int lastStartOffset = -1;\n                    for (int i = 0; i < tf; i++) {\n                      int pos = postings.nextPosition();\n                      if (hasPositions) {\n                        if (pos != -1 && pos < 0) {\n                          throw new RuntimeException(\"vector position \" + pos + \" is out of bounds\");\n                        }\n                        if (pos < lastPosition) {\n                          throw new RuntimeException(\"vector position \" + pos + \" < lastPos \" + lastPosition);\n                        }\n                    \n                        lastPosition = pos;\n                      }\n\n                      if (crossCheckTermVectors && postingsPostings != null) {\n                        int postingsPos = postingsPostings.nextPosition();\n                        if (pos != -1 && postingsPos != -1 && pos != postingsPos) {\n                          throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": pos=\" + pos + \" differs from postings pos=\" + postingsPos);\n                        }\n                      }\n\n                      if (hasOffsets) {\n                        // Call the methods to at least make\n                        // sure they don't throw exc:\n                        final int startOffset = postings.startOffset();\n                        final int endOffset = postings.endOffset();\n                        // TODO: these are too anal...?\n                        /*\n                        if (endOffset < startOffset) {\n                          throw new RuntimeException(\"vector startOffset=\" + startOffset + \" is > endOffset=\" + endOffset);\n                        }\n                        if (startOffset < lastStartOffset) {\n                          throw new RuntimeException(\"vector startOffset=\" + startOffset + \" is < prior startOffset=\" + lastStartOffset);\n                        }\n                        lastStartOffset = startOffset;\n                        */\n\n                        if (crossCheckTermVectors && postingsPostings != null) {\n                          final int postingsStartOffset = postingsPostings.startOffset();\n\n                          final int postingsEndOffset = postingsPostings.endOffset();\n                          if (startOffset != -1 && postingsStartOffset != -1 && startOffset != postingsStartOffset) {\n                            throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": startOffset=\" + startOffset + \" differs from postings startOffset=\" + postingsStartOffset);\n                          }\n                          if (endOffset != -1 && postingsEndOffset != -1 && endOffset != postingsEndOffset) {\n                            throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": endOffset=\" + endOffset + \" differs from postings endOffset=\" + postingsEndOffset);\n                          }\n                        }\n                      }\n                    }\n                  }\n                }\n                  \n                if (docs2.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                  throw new RuntimeException(\"vector for doc \" + j + \" references multiple documents!\");\n                }\n              }\n              \n              long uniqueTermCount = terms.getUniqueTermCount();\n              if (uniqueTermCount != -1 && uniqueTermCount != tfvComputedTermCountForField) {\n                throw new RuntimeException(\"vector term count for doc \" + j + \", field \" + field + \" = \" + uniqueTermCount + \" != recomputed term count=\" + tfvComputedTermCountForField);\n              }\n              \n              int docCount = terms.getDocCount();\n              if (docCount != -1 && docCount != 1) {\n                throw new RuntimeException(\"vector doc count for doc \" + j + \", field \" + field + \" = \" + docCount + \" != 1\");\n              }\n              \n              long sumDocFreq = terms.getSumDocFreq();\n              if (sumDocFreq != -1 && sumDocFreq != tfvComputedTermCountForField) {\n                throw new RuntimeException(\"vector postings count for doc \" + j + \", field \" + field + \" = \" + sumDocFreq + \" != recomputed postings count=\" + tfvComputedTermCountForField);\n              }\n              \n              long sumTotalTermFreq = terms.getSumTotalTermFreq();\n              if (sumTotalTermFreq != -1 && sumTotalTermFreq != tfvComputedSumTotalTermFreq) {\n                throw new RuntimeException(\"vector sumTotalTermFreq for doc \" + j + \", field \" + field + \" = \" + sumTotalTermFreq + \" != recomputed sumTotalTermFreq=\" + tfvComputedSumTotalTermFreq);\n              }\n              \n              tfvComputedTermCount += tfvComputedTermCountForField;\n            }\n            \n            int tfvUniqueFieldCount = tfv.getUniqueFieldCount();\n            if (tfvUniqueFieldCount != -1 && tfvUniqueFieldCount != tfvComputedFieldCount) {\n              throw new RuntimeException(\"vector field count for doc \" + j + \"=\" + tfvUniqueFieldCount + \" != recomputed uniqueFieldCount=\" + tfvComputedFieldCount);\n            }\n            \n            long tfvUniqueTermCount = tfv.getUniqueTermCount();\n            if (tfvUniqueTermCount != -1 && tfvUniqueTermCount != tfvComputedTermCount) {\n              throw new RuntimeException(\"vector term count for doc \" + j + \"=\" + tfvUniqueTermCount + \" != recomputed uniqueTermCount=\" + tfvComputedTermCount);\n            }\n          }\n        }\n      }\n      \n      msg(\"OK [\" + status.totVectors + \" total vector count; avg \" + \n          format.format((((float) status.totVectors) / status.docCount)) + \" term/freq vector fields per doc]\");\n    } catch (Throwable e) {\n      msg(\"ERROR [\" + String.valueOf(e.getMessage()) + \"]\");\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * Test term vectors for a segment.\n   */\n  private Status.TermVectorStatus testTermVectors(SegmentInfo info, SegmentReader reader, NumberFormat format) {\n    final Status.TermVectorStatus status = new Status.TermVectorStatus();\n    \n    // TODO: in theory we could test that term vectors have\n    // same terms/pos/offsets as the postings, but it'd be\n    // very slow...\n\n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: term vectors........\");\n      }\n\n      // TODO: maybe we can factor out testTermIndex and reuse here?\n      DocsEnum docs = null;\n      DocsAndPositionsEnum postings = null;\n\n      // Only used if crossCheckTermVectors is true:\n      DocsEnum postingsDocs = null;\n      DocsAndPositionsEnum postingsPostings = null;\n\n      final Bits liveDocs = reader.getLiveDocs();\n\n      final Fields postingsFields;\n      // TODO: testTermsIndex\n      if (crossCheckTermVectors) {\n        postingsFields = reader.fields();\n      } else {\n        postingsFields = null;\n      }\n\n      TermsEnum termsEnum = null;\n      TermsEnum postingsTermsEnum = null;\n\n      for (int j = 0; j < info.docCount; ++j) {\n        if (liveDocs == null || liveDocs.get(j)) {\n          status.docCount++;\n          Fields tfv = reader.getTermVectors(j);\n          if (tfv != null) {\n            int tfvComputedFieldCount = 0;\n            long tfvComputedTermCount = 0;\n\n            FieldsEnum fieldsEnum = tfv.iterator();\n            String field = null;\n            String lastField = null;\n            while((field = fieldsEnum.next()) != null) {\n              status.totVectors++;\n              tfvComputedFieldCount++;\n\n              if (lastField == null) {\n                lastField = field;\n              } else if (lastField.compareTo(field) > 0) {\n                throw new RuntimeException(\"vector fields are out of order: lastField=\" + lastField + \" field=\" + field + \" doc=\" + j);\n              }\n              \n              Terms terms = tfv.terms(field);\n              termsEnum = terms.iterator(termsEnum);\n\n              if (crossCheckTermVectors) {\n                Terms postingsTerms = postingsFields.terms(field);\n                if (postingsTerms == null) {\n                  throw new RuntimeException(\"vector field=\" + field + \" does not exist in postings; doc=\" + j);\n                }\n                postingsTermsEnum = postingsTerms.iterator(postingsTermsEnum);\n              } else {\n                postingsTermsEnum = null;\n              }\n              \n              long tfvComputedTermCountForField = 0;\n              long tfvComputedSumTotalTermFreq = 0;\n              \n              BytesRef lastTerm = null;\n              Comparator<BytesRef> termComp = terms.getComparator();\n              BytesRef term = null;\n              while ((term = termsEnum.next()) != null) {\n                tfvComputedTermCountForField++;\n                \n                // make sure terms arrive in order according to\n                // the comp\n                if (lastTerm == null) {\n                  lastTerm = BytesRef.deepCopyOf(term);\n                } else {\n                  if (termComp.compare(lastTerm, term) >= 0) {\n                    throw new RuntimeException(\"vector terms out of order for doc \" + j + \": lastTerm=\" + lastTerm + \" term=\" + term);\n                  }\n                  lastTerm.copyBytes(term);\n                }\n                \n                if (termsEnum.docFreq() != 1) {\n                  throw new RuntimeException(\"vector docFreq for doc \" + j + \", field \" + field + \", term\" + term + \" != 1\");\n                }\n                \n                long totalTermFreq = termsEnum.totalTermFreq();\n                \n                if (totalTermFreq != -1 && totalTermFreq <= 0) {\n                  throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq + \" is out of bounds\");\n                }\n\n                final boolean hasPositions;\n                final boolean hasOffsets;\n                final boolean hasFreqs;\n\n                // TODO: really we need a reflection/query\n                // API so we can just ask what was indexed\n                // instead of \"probing\"...\n\n                // Try offsets:\n                postings = termsEnum.docsAndPositions(null, postings, true);\n                if (postings == null) {\n                  hasOffsets = false;\n                  // Try only positions:\n                  postings = termsEnum.docsAndPositions(null, postings, false);\n                  if (postings == null) {\n                    hasPositions = false;\n                    // Try docIDs & freqs:\n                    docs = termsEnum.docs(null, docs, true);\n                    if (docs == null) {\n                      // OK, only docIDs:\n                      hasFreqs = false;\n                      docs = termsEnum.docs(null, docs, false);\n                    } else {\n                      hasFreqs = true;\n                    }\n                  } else {\n                    hasPositions = true;\n                    hasFreqs = true;\n                  }\n                } else {\n                  hasOffsets = true;\n                  // NOTE: may be a lie... but we accept -1 below\n                  hasPositions = true;\n                  hasFreqs = true;\n                }\n\n                final DocsEnum docs2;\n                if (hasPositions || hasOffsets) {\n                  assert postings != null;\n                  docs2 = postings;\n                } else {\n                  assert docs != null;\n                  docs2 = docs;\n                }\n\n                final DocsEnum postingsDocs2;\n                final boolean postingsHasFreq;\n                if (crossCheckTermVectors) {\n                  if (!postingsTermsEnum.seekExact(term, true)) {\n                    throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" does not exist in postings; doc=\" + j);\n                  }\n                  postingsPostings = postingsTermsEnum.docsAndPositions(null, postingsPostings, true);\n                  if (postingsPostings == null) {\n                    // Term vectors were indexed w/ offsets but postings were not\n                    postingsPostings = postingsTermsEnum.docsAndPositions(null, postingsPostings, false);\n                    if (postingsPostings == null) {\n                      postingsDocs = postingsTermsEnum.docs(null, postingsDocs, true);\n                      if (postingsDocs == null) {\n                        postingsHasFreq = false;\n                        postingsDocs = postingsTermsEnum.docs(null, postingsDocs, false);\n                        if (postingsDocs == null) {\n                          throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" does not exist in postings; doc=\" + j);\n                        }\n                      } else {\n                        postingsHasFreq = true;\n                      }\n                    } else {\n                      postingsHasFreq = true;\n                    }\n                  } else {\n                    postingsHasFreq = true;\n                  }\n\n                  if (postingsPostings != null) {\n                    postingsDocs2 = postingsPostings;\n                  } else {\n                    postingsDocs2 = postingsDocs;\n                  }\n                  \n                  final int advanceDoc = postingsDocs2.advance(j);\n                  if (advanceDoc != j) {\n                    throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \": doc=\" + j + \" was not found in postings (got: \" + advanceDoc + \")\");\n                  }\n                } else {\n                  postingsDocs2 = null;\n                  postingsHasFreq = false;\n                }\n\n                final int doc = docs2.nextDoc();\n                  \n                if (doc != 0) {\n                  throw new RuntimeException(\"vector for doc \" + j + \" didn't return docID=0: got docID=\" + doc);\n                }\n\n                if (hasFreqs) {\n                  final int tf = docs2.freq();\n                  if (tf <= 0) {\n                    throw new RuntimeException(\"vector freq \" + tf + \" is out of bounds\");\n                  }\n                  if (totalTermFreq != -1 && totalTermFreq != tf) {\n                    throw new RuntimeException(\"vector totalTermFreq \" + totalTermFreq + \" != tf \" + tf);\n                  }\n                  if (crossCheckTermVectors && postingsHasFreq) {\n                    if (postingsDocs2.freq() != tf) {\n                      throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": freq=\" + tf + \" differs from postings freq=\" + postingsDocs2.freq());\n                    }\n                  }\n                  tfvComputedSumTotalTermFreq += tf;\n                \n                  if (hasPositions || hasOffsets) {\n                    int lastPosition = -1;\n                    //int lastStartOffset = -1;\n                    for (int i = 0; i < tf; i++) {\n                      int pos = postings.nextPosition();\n                      if (hasPositions) {\n                        if (pos != -1 && pos < 0) {\n                          throw new RuntimeException(\"vector position \" + pos + \" is out of bounds\");\n                        }\n                        if (pos < lastPosition) {\n                          throw new RuntimeException(\"vector position \" + pos + \" < lastPos \" + lastPosition);\n                        }\n                    \n                        lastPosition = pos;\n                      }\n\n                      if (crossCheckTermVectors && postingsPostings != null) {\n                        int postingsPos = postingsPostings.nextPosition();\n                        if (pos != -1 && postingsPos != -1 && pos != postingsPos) {\n                          throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": pos=\" + pos + \" differs from postings pos=\" + postingsPos);\n                        }\n                      }\n\n                      if (hasOffsets) {\n                        // Call the methods to at least make\n                        // sure they don't throw exc:\n                        final int startOffset = postings.startOffset();\n                        final int endOffset = postings.endOffset();\n                        // TODO: these are too anal...?\n                        /*\n                        if (endOffset < startOffset) {\n                          throw new RuntimeException(\"vector startOffset=\" + startOffset + \" is > endOffset=\" + endOffset);\n                        }\n                        if (startOffset < lastStartOffset) {\n                          throw new RuntimeException(\"vector startOffset=\" + startOffset + \" is < prior startOffset=\" + lastStartOffset);\n                        }\n                        lastStartOffset = startOffset;\n                        */\n\n                        if (crossCheckTermVectors && postingsPostings != null) {\n                          final int postingsStartOffset = postingsPostings.startOffset();\n\n                          final int postingsEndOffset = postingsPostings.endOffset();\n                          if (startOffset != -1 && postingsStartOffset != -1 && startOffset != postingsStartOffset) {\n                            throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": startOffset=\" + startOffset + \" differs from postings startOffset=\" + postingsStartOffset);\n                          }\n                          if (endOffset != -1 && postingsEndOffset != -1 && endOffset != postingsEndOffset) {\n                            throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": endOffset=\" + endOffset + \" differs from postings endOffset=\" + postingsEndOffset);\n                          }\n                        }\n                      }\n                    }\n                  }\n                }\n                  \n                if (docs2.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                  throw new RuntimeException(\"vector for doc \" + j + \" references multiple documents!\");\n                }\n              }\n              \n              long uniqueTermCount = terms.getUniqueTermCount();\n              if (uniqueTermCount != -1 && uniqueTermCount != tfvComputedTermCountForField) {\n                throw new RuntimeException(\"vector term count for doc \" + j + \", field \" + field + \" = \" + uniqueTermCount + \" != recomputed term count=\" + tfvComputedTermCountForField);\n              }\n              \n              int docCount = terms.getDocCount();\n              if (docCount != -1 && docCount != 1) {\n                throw new RuntimeException(\"vector doc count for doc \" + j + \", field \" + field + \" = \" + docCount + \" != 1\");\n              }\n              \n              long sumDocFreq = terms.getSumDocFreq();\n              if (sumDocFreq != -1 && sumDocFreq != tfvComputedTermCountForField) {\n                throw new RuntimeException(\"vector postings count for doc \" + j + \", field \" + field + \" = \" + sumDocFreq + \" != recomputed postings count=\" + tfvComputedTermCountForField);\n              }\n              \n              long sumTotalTermFreq = terms.getSumTotalTermFreq();\n              if (sumTotalTermFreq != -1 && sumTotalTermFreq != tfvComputedSumTotalTermFreq) {\n                throw new RuntimeException(\"vector sumTotalTermFreq for doc \" + j + \", field \" + field + \" = \" + sumTotalTermFreq + \" != recomputed sumTotalTermFreq=\" + tfvComputedSumTotalTermFreq);\n              }\n              \n              tfvComputedTermCount += tfvComputedTermCountForField;\n            }\n            \n            int tfvUniqueFieldCount = tfv.getUniqueFieldCount();\n            if (tfvUniqueFieldCount != -1 && tfvUniqueFieldCount != tfvComputedFieldCount) {\n              throw new RuntimeException(\"vector field count for doc \" + j + \"=\" + tfvUniqueFieldCount + \" != recomputed uniqueFieldCount=\" + tfvComputedFieldCount);\n            }\n            \n            long tfvUniqueTermCount = tfv.getUniqueTermCount();\n            if (tfvUniqueTermCount != -1 && tfvUniqueTermCount != tfvComputedTermCount) {\n              throw new RuntimeException(\"vector term count for doc \" + j + \"=\" + tfvUniqueTermCount + \" != recomputed uniqueTermCount=\" + tfvComputedTermCount);\n            }\n          }\n        }\n      }\n      \n      msg(\"OK [\" + status.totVectors + \" total vector count; avg \" + \n          format.format((((float) status.totVectors) / status.docCount)) + \" term/freq vector fields per doc]\");\n    } catch (Throwable e) {\n      msg(\"ERROR [\" + String.valueOf(e.getMessage()) + \"]\");\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["d3eed68223cb841b4f909e2ef7dba9c54f3263f7"],"e7bd246bb7bc35ac22edfee9157e034dfc4e65eb":["406e7055a3e99d3fa6ce49a555a51dd18b321806"],"3cc749c053615f5871f3b95715fe292f34e70a53":["e7bd246bb7bc35ac22edfee9157e034dfc4e65eb"],"d3eed68223cb841b4f909e2ef7dba9c54f3263f7":["31f025ae60076ae95274433f3fe8e6ace2857a87"],"872cff1d3a554e0cd64014cd97f88d3002b0f491":["3cc749c053615f5871f3b95715fe292f34e70a53"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["9454a6510e2db155fb01faa5c049b06ece95fab9","406e7055a3e99d3fa6ce49a555a51dd18b321806"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":["406e7055a3e99d3fa6ce49a555a51dd18b321806","e7bd246bb7bc35ac22edfee9157e034dfc4e65eb"],"817d8435e9135b756f08ce6710ab0baac51bdf88":["406e7055a3e99d3fa6ce49a555a51dd18b321806","e7bd246bb7bc35ac22edfee9157e034dfc4e65eb"],"b65b350ca9588f9fc76ce7d6804160d06c45ff42":["3cc749c053615f5871f3b95715fe292f34e70a53","872cff1d3a554e0cd64014cd97f88d3002b0f491"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"406e7055a3e99d3fa6ce49a555a51dd18b321806":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"31f025ae60076ae95274433f3fe8e6ace2857a87":["872cff1d3a554e0cd64014cd97f88d3002b0f491"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"e7bd246bb7bc35ac22edfee9157e034dfc4e65eb":["3cc749c053615f5871f3b95715fe292f34e70a53","d083e83f225b11e5fdd900e83d26ddb385b6955c","817d8435e9135b756f08ce6710ab0baac51bdf88"],"3cc749c053615f5871f3b95715fe292f34e70a53":["872cff1d3a554e0cd64014cd97f88d3002b0f491","b65b350ca9588f9fc76ce7d6804160d06c45ff42"],"d3eed68223cb841b4f909e2ef7dba9c54f3263f7":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"872cff1d3a554e0cd64014cd97f88d3002b0f491":["b65b350ca9588f9fc76ce7d6804160d06c45ff42","31f025ae60076ae95274433f3fe8e6ace2857a87"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":[],"d083e83f225b11e5fdd900e83d26ddb385b6955c":[],"817d8435e9135b756f08ce6710ab0baac51bdf88":[],"b65b350ca9588f9fc76ce7d6804160d06c45ff42":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"406e7055a3e99d3fa6ce49a555a51dd18b321806":["e7bd246bb7bc35ac22edfee9157e034dfc4e65eb","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","d083e83f225b11e5fdd900e83d26ddb385b6955c","817d8435e9135b756f08ce6710ab0baac51bdf88"],"31f025ae60076ae95274433f3fe8e6ace2857a87":["d3eed68223cb841b4f909e2ef7dba9c54f3263f7"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","406e7055a3e99d3fa6ce49a555a51dd18b321806"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","d083e83f225b11e5fdd900e83d26ddb385b6955c","817d8435e9135b756f08ce6710ab0baac51bdf88","b65b350ca9588f9fc76ce7d6804160d06c45ff42","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}