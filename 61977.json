{"path":"lucene/codecs/src/java/org/apache/lucene/codecs/temp/TempFSTTermsReader#TempFSTTermsReader(SegmentReadState,PostingsReaderBase).mjava","commits":[{"id":"e6904bcc97d8afa27bd72ee29ac01e525e327ad4","date":1377958787,"type":0,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/temp/TempFSTTermsReader#TempFSTTermsReader(SegmentReadState,PostingsReaderBase).mjava","pathOld":"/dev/null","sourceNew":"  public TempFSTTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, TempFSTTermsWriter.TERMS_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    this.in = state.directory.openInput(termsFileName, state.context);\n\n    boolean success = false;\n    try {\n      readHeader(in);\n      this.postingsReader.init(in);\n      seekDir(in);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = in.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        int fieldNumber = in.readVInt();\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(fieldNumber);\n        long numTerms = in.readVLong();\n        long sumTotalTermFreq = fieldInfo.getIndexOptions() == IndexOptions.DOCS_ONLY ? -1 : in.readVLong();\n        long sumDocFreq = in.readVLong();\n        int docCount = in.readVInt();\n        int longsSize = in.readVInt();\n        TermsReader current = new TermsReader(fieldInfo, numTerms, sumTotalTermFreq, sumDocFreq, docCount, longsSize);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, current, previous);\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(in);\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"56df73d43b6fc340f5332322862382c7e30f4368","date":1378304988,"type":5,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTTermsReader#FSTTermsReader(SegmentReadState,PostingsReaderBase).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/temp/TempFSTTermsReader#TempFSTTermsReader(SegmentReadState,PostingsReaderBase).mjava","sourceNew":"  public FSTTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTTermsWriter.TERMS_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    this.in = state.directory.openInput(termsFileName, state.context);\n\n    boolean success = false;\n    try {\n      readHeader(in);\n      this.postingsReader.init(in);\n      seekDir(in);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = in.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        int fieldNumber = in.readVInt();\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(fieldNumber);\n        long numTerms = in.readVLong();\n        long sumTotalTermFreq = fieldInfo.getIndexOptions() == IndexOptions.DOCS_ONLY ? -1 : in.readVLong();\n        long sumDocFreq = in.readVLong();\n        int docCount = in.readVInt();\n        int longsSize = in.readVInt();\n        TermsReader current = new TermsReader(fieldInfo, numTerms, sumTotalTermFreq, sumDocFreq, docCount, longsSize);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, current, previous);\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(in);\n      }\n    }\n  }\n\n","sourceOld":"  public TempFSTTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, TempFSTTermsWriter.TERMS_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    this.in = state.directory.openInput(termsFileName, state.context);\n\n    boolean success = false;\n    try {\n      readHeader(in);\n      this.postingsReader.init(in);\n      seekDir(in);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = in.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        int fieldNumber = in.readVInt();\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(fieldNumber);\n        long numTerms = in.readVLong();\n        long sumTotalTermFreq = fieldInfo.getIndexOptions() == IndexOptions.DOCS_ONLY ? -1 : in.readVLong();\n        long sumDocFreq = in.readVLong();\n        int docCount = in.readVInt();\n        int longsSize = in.readVInt();\n        TermsReader current = new TermsReader(fieldInfo, numTerms, sumTotalTermFreq, sumDocFreq, docCount, longsSize);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, current, previous);\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(in);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"56df73d43b6fc340f5332322862382c7e30f4368":["e6904bcc97d8afa27bd72ee29ac01e525e327ad4"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"e6904bcc97d8afa27bd72ee29ac01e525e327ad4":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"56df73d43b6fc340f5332322862382c7e30f4368":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["e6904bcc97d8afa27bd72ee29ac01e525e327ad4","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"e6904bcc97d8afa27bd72ee29ac01e525e327ad4":["56df73d43b6fc340f5332322862382c7e30f4368"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["56df73d43b6fc340f5332322862382c7e30f4368","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}