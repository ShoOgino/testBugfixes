{"path":"solr/src/test/org/apache/solr/analysis/TestTrimFilter#testTrim().mjava","commits":[{"id":"893269407f5c988a4b2ee13c7ffc01ec43136c1d","date":1268598046,"type":0,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/src/test/org/apache/solr/analysis/TestTrimFilter#testTrim().mjava","pathOld":"/dev/null","sourceNew":"  public void testTrim() throws Exception {\n    char[] a = \" a \".toCharArray();\n    char[] b = \"b   \".toCharArray();\n    char[] ccc = \"cCc\".toCharArray();\n    char[] whitespace = \"   \".toCharArray();\n    char[] empty = \"\".toCharArray();\n    TrimFilterFactory factory = new TrimFilterFactory();\n    Map<String,String> args = new HashMap<String,String>();\n    args.put(\"updateOffsets\", \"false\");\n    factory.init(args);\n    TokenStream ts = factory.create(new IterTokenStream(new Token(a, 0, a.length, 1, 5),\n                    new Token(b, 0, b.length, 6, 10),\n                    new Token(ccc, 0, ccc.length, 11, 15),\n                    new Token(whitespace, 0, whitespace.length, 16, 20),\n                    new Token(empty, 0, empty.length, 21, 21)));\n\n    assertTokenStreamContents(ts, new String[] { \"a\", \"b\", \"cCc\", \"\", \"\"});\n\n    a = \" a\".toCharArray();\n    b = \"b \".toCharArray();\n    ccc = \" c \".toCharArray();\n    whitespace = \"   \".toCharArray();\n    factory = new TrimFilterFactory();\n    args = new HashMap<String,String>();\n    args.put(\"updateOffsets\", \"true\");\n    factory.init(args);\n    ts = factory.create(new IterTokenStream(\n            new Token(a, 0, a.length, 0, 2),\n            new Token(b, 0, b.length, 0, 2),\n            new Token(ccc, 0, ccc.length, 0, 3),\n            new Token(whitespace, 0, whitespace.length, 0, 3)));\n    \n    assertTokenStreamContents(ts, \n        new String[] { \"a\", \"b\", \"c\", \"\" },\n        new int[] { 1, 0, 1, 3 },\n        new int[] { 2, 1, 2, 3 },\n        new int[] { 1, 1, 1, 1 });\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8","date":1268599006,"type":4,"author":"Mark Robert Miller","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/src/test/org/apache/solr/analysis/TestTrimFilter#testTrim().mjava","sourceNew":null,"sourceOld":"  public void testTrim() throws Exception {\n    char[] a = \" a \".toCharArray();\n    char[] b = \"b   \".toCharArray();\n    char[] ccc = \"cCc\".toCharArray();\n    char[] whitespace = \"   \".toCharArray();\n    char[] empty = \"\".toCharArray();\n    TrimFilterFactory factory = new TrimFilterFactory();\n    Map<String,String> args = new HashMap<String,String>();\n    args.put(\"updateOffsets\", \"false\");\n    factory.init(args);\n    TokenStream ts = factory.create(new IterTokenStream(new Token(a, 0, a.length, 1, 5),\n                    new Token(b, 0, b.length, 6, 10),\n                    new Token(ccc, 0, ccc.length, 11, 15),\n                    new Token(whitespace, 0, whitespace.length, 16, 20),\n                    new Token(empty, 0, empty.length, 21, 21)));\n\n    assertTokenStreamContents(ts, new String[] { \"a\", \"b\", \"cCc\", \"\", \"\"});\n\n    a = \" a\".toCharArray();\n    b = \"b \".toCharArray();\n    ccc = \" c \".toCharArray();\n    whitespace = \"   \".toCharArray();\n    factory = new TrimFilterFactory();\n    args = new HashMap<String,String>();\n    args.put(\"updateOffsets\", \"true\");\n    factory.init(args);\n    ts = factory.create(new IterTokenStream(\n            new Token(a, 0, a.length, 0, 2),\n            new Token(b, 0, b.length, 0, 2),\n            new Token(ccc, 0, ccc.length, 0, 3),\n            new Token(whitespace, 0, whitespace.length, 0, 3)));\n    \n    assertTokenStreamContents(ts, \n        new String[] { \"a\", \"b\", \"c\", \"\" },\n        new int[] { 1, 0, 1, 3 },\n        new int[] { 2, 1, 2, 3 },\n        new int[] { 1, 1, 1, 1 });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ad94625fb8d088209f46650c8097196fec67f00c","date":1453508319,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/src/test/org/apache/solr/analysis/TestTrimFilter#testTrim().mjava","pathOld":"src/test/org/apache/solr/analysis/TestTrimFilter#testTrim().mjava","sourceNew":"  public void testTrim() throws Exception {\n    char[] a = \" a \".toCharArray();\n    char[] b = \"b   \".toCharArray();\n    char[] ccc = \"cCc\".toCharArray();\n    char[] whitespace = \"   \".toCharArray();\n    char[] empty = \"\".toCharArray();\n    TrimFilterFactory factory = new TrimFilterFactory();\n    Map<String,String> args = new HashMap<String,String>();\n    args.put(\"updateOffsets\", \"false\");\n    factory.init(args);\n    TokenStream ts = factory.create(new IterTokenStream(new Token(a, 0, a.length, 1, 5),\n                    new Token(b, 0, b.length, 6, 10),\n                    new Token(ccc, 0, ccc.length, 11, 15),\n                    new Token(whitespace, 0, whitespace.length, 16, 20),\n                    new Token(empty, 0, empty.length, 21, 21)));\n\n    assertTokenStreamContents(ts, new String[] { \"a\", \"b\", \"cCc\", \"\", \"\"});\n\n    a = \" a\".toCharArray();\n    b = \"b \".toCharArray();\n    ccc = \" c \".toCharArray();\n    whitespace = \"   \".toCharArray();\n    factory = new TrimFilterFactory();\n    args = new HashMap<String,String>();\n    args.put(\"updateOffsets\", \"true\");\n    factory.init(args);\n    ts = factory.create(new IterTokenStream(\n            new Token(a, 0, a.length, 0, 2),\n            new Token(b, 0, b.length, 0, 2),\n            new Token(ccc, 0, ccc.length, 0, 3),\n            new Token(whitespace, 0, whitespace.length, 0, 3)));\n    \n    assertTokenStreamContents(ts, \n        new String[] { \"a\", \"b\", \"c\", \"\" },\n        new int[] { 1, 0, 1, 3 },\n        new int[] { 2, 1, 2, 3 },\n        new int[] { 1, 1, 1, 1 });\n  }\n\n","sourceOld":"  public void testTrim() throws Exception {\n    char[] a = \" a \".toCharArray();\n    char[] b = \"b   \".toCharArray();\n    char[] ccc = \"cCc\".toCharArray();\n    char[] whitespace = \"   \".toCharArray();\n    char[] empty = \"\".toCharArray();\n    TrimFilterFactory factory = new TrimFilterFactory();\n    Map<String,String> args = new HashMap<String,String>();\n    args.put(\"updateOffsets\", \"false\");\n    factory.init(args);\n    TokenStream ts = factory.create(new IterTokenStream(new Token(a, 0, a.length, 1, 5),\n                    new Token(b, 0, b.length, 6, 10),\n                    new Token(ccc, 0, ccc.length, 11, 15),\n                    new Token(whitespace, 0, whitespace.length, 16, 20),\n                    new Token(empty, 0, empty.length, 21, 21)));\n\n    assertTokenStreamContents(ts, new String[] { \"a\", \"b\", \"cCc\", \"\", \"\"});\n\n    a = \" a\".toCharArray();\n    b = \"b \".toCharArray();\n    ccc = \" c \".toCharArray();\n    whitespace = \"   \".toCharArray();\n    factory = new TrimFilterFactory();\n    args = new HashMap<String,String>();\n    args.put(\"updateOffsets\", \"true\");\n    factory.init(args);\n    ts = factory.create(new IterTokenStream(\n            new Token(a, 0, a.length, 0, 2),\n            new Token(b, 0, b.length, 0, 2),\n            new Token(ccc, 0, ccc.length, 0, 3),\n            new Token(whitespace, 0, whitespace.length, 0, 3)));\n    \n    assertTokenStreamContents(ts, \n        new String[] { \"a\", \"b\", \"c\", \"\" },\n        new int[] { 1, 0, 1, 3 },\n        new int[] { 2, 1, 2, 3 },\n        new int[] { 1, 1, 1, 1 });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1da8d55113b689b06716246649de6f62430f15c0","date":1453508340,"type":0,"author":"Dawid Weiss","isMerge":true,"pathNew":"solr/src/test/org/apache/solr/analysis/TestTrimFilter#testTrim().mjava","pathOld":"/dev/null","sourceNew":"  public void testTrim() throws Exception {\n    char[] a = \" a \".toCharArray();\n    char[] b = \"b   \".toCharArray();\n    char[] ccc = \"cCc\".toCharArray();\n    char[] whitespace = \"   \".toCharArray();\n    char[] empty = \"\".toCharArray();\n    TrimFilterFactory factory = new TrimFilterFactory();\n    Map<String,String> args = new HashMap<String,String>();\n    args.put(\"updateOffsets\", \"false\");\n    factory.init(args);\n    TokenStream ts = factory.create(new IterTokenStream(new Token(a, 0, a.length, 1, 5),\n                    new Token(b, 0, b.length, 6, 10),\n                    new Token(ccc, 0, ccc.length, 11, 15),\n                    new Token(whitespace, 0, whitespace.length, 16, 20),\n                    new Token(empty, 0, empty.length, 21, 21)));\n\n    assertTokenStreamContents(ts, new String[] { \"a\", \"b\", \"cCc\", \"\", \"\"});\n\n    a = \" a\".toCharArray();\n    b = \"b \".toCharArray();\n    ccc = \" c \".toCharArray();\n    whitespace = \"   \".toCharArray();\n    factory = new TrimFilterFactory();\n    args = new HashMap<String,String>();\n    args.put(\"updateOffsets\", \"true\");\n    factory.init(args);\n    ts = factory.create(new IterTokenStream(\n            new Token(a, 0, a.length, 0, 2),\n            new Token(b, 0, b.length, 0, 2),\n            new Token(ccc, 0, ccc.length, 0, 3),\n            new Token(whitespace, 0, whitespace.length, 0, 3)));\n    \n    assertTokenStreamContents(ts, \n        new String[] { \"a\", \"b\", \"c\", \"\" },\n        new int[] { 1, 0, 1, 3 },\n        new int[] { 2, 1, 2, 3 },\n        new int[] { 1, 1, 1, 1 });\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"384e84fe86b09273dea9bb358ff47fc7781f3f17","date":1272992848,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/miscellaneous/TestTrimFilter#testTrim().mjava","pathOld":"solr/src/test/org/apache/solr/analysis/TestTrimFilter#testTrim().mjava","sourceNew":"  public void testTrim() throws Exception {\n    char[] a = \" a \".toCharArray();\n    char[] b = \"b   \".toCharArray();\n    char[] ccc = \"cCc\".toCharArray();\n    char[] whitespace = \"   \".toCharArray();\n    char[] empty = \"\".toCharArray();\n\n    TokenStream ts = new IterTokenStream(new Token(a, 0, a.length, 1, 5),\n                    new Token(b, 0, b.length, 6, 10),\n                    new Token(ccc, 0, ccc.length, 11, 15),\n                    new Token(whitespace, 0, whitespace.length, 16, 20),\n                    new Token(empty, 0, empty.length, 21, 21));\n    ts = new TrimFilter(ts, false);\n\n    assertTokenStreamContents(ts, new String[] { \"a\", \"b\", \"cCc\", \"\", \"\"});\n\n    a = \" a\".toCharArray();\n    b = \"b \".toCharArray();\n    ccc = \" c \".toCharArray();\n    whitespace = \"   \".toCharArray();\n    ts = new IterTokenStream(\n            new Token(a, 0, a.length, 0, 2),\n            new Token(b, 0, b.length, 0, 2),\n            new Token(ccc, 0, ccc.length, 0, 3),\n            new Token(whitespace, 0, whitespace.length, 0, 3));\n    ts = new TrimFilter(ts, true);\n    \n    assertTokenStreamContents(ts, \n        new String[] { \"a\", \"b\", \"c\", \"\" },\n        new int[] { 1, 0, 1, 3 },\n        new int[] { 2, 1, 2, 3 },\n        new int[] { 1, 1, 1, 1 });\n  }\n\n","sourceOld":"  public void testTrim() throws Exception {\n    char[] a = \" a \".toCharArray();\n    char[] b = \"b   \".toCharArray();\n    char[] ccc = \"cCc\".toCharArray();\n    char[] whitespace = \"   \".toCharArray();\n    char[] empty = \"\".toCharArray();\n    TrimFilterFactory factory = new TrimFilterFactory();\n    Map<String,String> args = new HashMap<String,String>();\n    args.put(\"updateOffsets\", \"false\");\n    factory.init(args);\n    TokenStream ts = factory.create(new IterTokenStream(new Token(a, 0, a.length, 1, 5),\n                    new Token(b, 0, b.length, 6, 10),\n                    new Token(ccc, 0, ccc.length, 11, 15),\n                    new Token(whitespace, 0, whitespace.length, 16, 20),\n                    new Token(empty, 0, empty.length, 21, 21)));\n\n    assertTokenStreamContents(ts, new String[] { \"a\", \"b\", \"cCc\", \"\", \"\"});\n\n    a = \" a\".toCharArray();\n    b = \"b \".toCharArray();\n    ccc = \" c \".toCharArray();\n    whitespace = \"   \".toCharArray();\n    factory = new TrimFilterFactory();\n    args = new HashMap<String,String>();\n    args.put(\"updateOffsets\", \"true\");\n    factory.init(args);\n    ts = factory.create(new IterTokenStream(\n            new Token(a, 0, a.length, 0, 2),\n            new Token(b, 0, b.length, 0, 2),\n            new Token(ccc, 0, ccc.length, 0, 3),\n            new Token(whitespace, 0, whitespace.length, 0, 3)));\n    \n    assertTokenStreamContents(ts, \n        new String[] { \"a\", \"b\", \"c\", \"\" },\n        new int[] { 1, 0, 1, 3 },\n        new int[] { 2, 1, 2, 3 },\n        new int[] { 1, 1, 1, 1 });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"1da8d55113b689b06716246649de6f62430f15c0":["a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8","ad94625fb8d088209f46650c8097196fec67f00c"],"893269407f5c988a4b2ee13c7ffc01ec43136c1d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"384e84fe86b09273dea9bb358ff47fc7781f3f17":["1da8d55113b689b06716246649de6f62430f15c0"],"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8":["893269407f5c988a4b2ee13c7ffc01ec43136c1d"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":[],"ad94625fb8d088209f46650c8097196fec67f00c":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["384e84fe86b09273dea9bb358ff47fc7781f3f17"]},"commit2Childs":{"1da8d55113b689b06716246649de6f62430f15c0":["384e84fe86b09273dea9bb358ff47fc7781f3f17"],"893269407f5c988a4b2ee13c7ffc01ec43136c1d":["a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8"],"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8":["1da8d55113b689b06716246649de6f62430f15c0"],"384e84fe86b09273dea9bb358ff47fc7781f3f17":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["893269407f5c988a4b2ee13c7ffc01ec43136c1d"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":["ad94625fb8d088209f46650c8097196fec67f00c"],"ad94625fb8d088209f46650c8097196fec67f00c":["1da8d55113b689b06716246649de6f62430f15c0"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"pathCommit":null}