{"path":"contrib/extraction/src/main/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","commits":[{"id":"46dfcd540005e76a7db876d494ac74e82c476523","date":1229095104,"type":1,"author":"Grant Ingersoll","isMerge":false,"pathNew":"contrib/extraction/src/main/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","pathOld":"contrib/extraction/src/main/java/org/apache/solr/handler/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","sourceNew":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      parser = config.getParser(streamType.trim().toLowerCase());\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n      metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n      metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n      metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n      metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n\n      SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        XMLSerializer serializer = null;\n        if (extractOnly == true) {\n          writer = new StringWriter();\n          serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n        parser.parse(inputStream, parsingHandler, metadata);\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n\n        }\n      } catch (Exception e) {\n        //TODO: handle here with an option to not fail and just log the exception\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","sourceOld":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      parser = config.getParser(streamType.trim().toLowerCase());\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n      metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n      metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n      metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n      metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n\n      SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        XMLSerializer serializer = null;\n        if (extractOnly == true) {\n          writer = new StringWriter();\n          serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n        parser.parse(inputStream, parsingHandler, metadata);\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n\n        }\n      } catch (Exception e) {\n        //TODO: handle here with an option to not fail and just log the exception\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"327ca1ed45a74ae6b4a4c009f83ea0a25a6b76d2","date":1240576942,"type":3,"author":"Grant Ingersoll","isMerge":false,"pathNew":"contrib/extraction/src/main/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","pathOld":"contrib/extraction/src/main/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","sourceNew":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      parser = config.getParser(streamType.trim().toLowerCase());\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n      metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n      metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n      metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n      metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n\n      SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        XMLSerializer serializer = null;\n        if (extractOnly == true) {\n          writer = new StringWriter();\n          serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n        parser.parse(inputStream, parsingHandler, metadata);\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (Exception e) {\n        //TODO: handle here with an option to not fail and just log the exception\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","sourceOld":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      parser = config.getParser(streamType.trim().toLowerCase());\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n      metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n      metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n      metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n      metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n\n      SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        XMLSerializer serializer = null;\n        if (extractOnly == true) {\n          writer = new StringWriter();\n          serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n        parser.parse(inputStream, parsingHandler, metadata);\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n\n        }\n      } catch (Exception e) {\n        //TODO: handle here with an option to not fail and just log the exception\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"eecdad1988b0b00f74f945528b689ef1eebf763d","date":1247586785,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"contrib/extraction/src/main/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","pathOld":"contrib/extraction/src/main/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","sourceNew":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      parser = config.getParser(streamType.trim().toLowerCase());\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n      metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n      metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n      metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n      metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n\n      SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        XMLSerializer serializer = null;\n        if (extractOnly == true) {\n          writer = new StringWriter();\n          serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n        parser.parse(inputStream, parsingHandler, metadata);\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (TikaException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","sourceOld":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      parser = config.getParser(streamType.trim().toLowerCase());\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n      metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n      metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n      metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n      metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n\n      SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        XMLSerializer serializer = null;\n        if (extractOnly == true) {\n          writer = new StringWriter();\n          serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n        parser.parse(inputStream, parsingHandler, metadata);\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (Exception e) {\n        //TODO: handle here with an option to not fail and just log the exception\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"afb50671502fba492d01bf5bb44caf67c5b7576e","date":1249695556,"type":3,"author":"Grant Ingersoll","isMerge":false,"pathNew":"contrib/extraction/src/main/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","pathOld":"contrib/extraction/src/main/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","sourceNew":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      parser = config.getParser(streamType.trim().toLowerCase());\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n      metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n      metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n      metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n      metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n\n      SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n        parser.parse(inputStream, parsingHandler, metadata);\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (TikaException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","sourceOld":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      parser = config.getParser(streamType.trim().toLowerCase());\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n      metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n      metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n      metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n      metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n\n      SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        XMLSerializer serializer = null;\n        if (extractOnly == true) {\n          writer = new StringWriter();\n          serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n        parser.parse(inputStream, parsingHandler, metadata);\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (TikaException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ad94625fb8d088209f46650c8097196fec67f00c","date":1453508319,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/contrib/extraction/src/main/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","pathOld":"contrib/extraction/src/main/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","sourceNew":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      parser = config.getParser(streamType.trim().toLowerCase());\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n      metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n      metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n      metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n      metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n\n      SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n        parser.parse(inputStream, parsingHandler, metadata);\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (TikaException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","sourceOld":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      parser = config.getParser(streamType.trim().toLowerCase());\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n      metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n      metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n      metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n      metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n\n      SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n        parser.parse(inputStream, parsingHandler, metadata);\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (TikaException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"eecdad1988b0b00f74f945528b689ef1eebf763d":["327ca1ed45a74ae6b4a4c009f83ea0a25a6b76d2"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":[],"327ca1ed45a74ae6b4a4c009f83ea0a25a6b76d2":["46dfcd540005e76a7db876d494ac74e82c476523"],"ad94625fb8d088209f46650c8097196fec67f00c":["afb50671502fba492d01bf5bb44caf67c5b7576e"],"afb50671502fba492d01bf5bb44caf67c5b7576e":["eecdad1988b0b00f74f945528b689ef1eebf763d"],"46dfcd540005e76a7db876d494ac74e82c476523":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"eecdad1988b0b00f74f945528b689ef1eebf763d":["afb50671502fba492d01bf5bb44caf67c5b7576e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":["46dfcd540005e76a7db876d494ac74e82c476523"],"327ca1ed45a74ae6b4a4c009f83ea0a25a6b76d2":["eecdad1988b0b00f74f945528b689ef1eebf763d"],"ad94625fb8d088209f46650c8097196fec67f00c":[],"afb50671502fba492d01bf5bb44caf67c5b7576e":["ad94625fb8d088209f46650c8097196fec67f00c"],"46dfcd540005e76a7db876d494ac74e82c476523":["327ca1ed45a74ae6b4a4c009f83ea0a25a6b76d2"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["ad94625fb8d088209f46650c8097196fec67f00c","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"pathCommit":null}