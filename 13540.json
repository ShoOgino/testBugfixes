{"path":"lucene/core/src/java/org/apache/lucene/codecs/bloom/BloomFilteringPostingsFormat.BloomFilteredFieldsConsumer#close().mjava","commits":[{"id":"0274c27988a26cb0cda3a0d15b282221b1b453f0","date":1343923460,"type":0,"author":"Mark Harwood","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/bloom/BloomFilteringPostingsFormat.BloomFilteredFieldsConsumer#close().mjava","pathOld":"/dev/null","sourceNew":"    @Override\r\n    public void close() throws IOException {\r\n      delegateFieldsConsumer.close();\r\n      // Now we are done accumulating values for these fields\r\n      List<Entry<FieldInfo,FuzzySet>> nonSaturatedBlooms = new ArrayList<Map.Entry<FieldInfo,FuzzySet>>();\r\n      \r\n      for (Entry<FieldInfo,FuzzySet> entry : bloomFilters.entrySet()) {\r\n        FuzzySet bloomFilter = entry.getValue();\r\n        if(!bloomFilterFactory.isSaturated(bloomFilter,entry.getKey())){          \r\n          nonSaturatedBlooms.add(entry);\r\n        }\r\n      }\r\n      String bloomFileName = IndexFileNames.segmentFileName(\r\n          state.segmentInfo.name, state.segmentSuffix, BLOOM_EXTENSION);\r\n      IndexOutput bloomOutput = null;\r\n      try {\r\n        bloomOutput = state.directory\r\n            .createOutput(bloomFileName, state.context);\r\n        CodecUtil.writeHeader(bloomOutput, BLOOM_CODEC_NAME,\r\n            BLOOM_CODEC_VERSION);\r\n        // remember the name of the postings format we will delegate to\r\n        bloomOutput.writeString(delegatePostingsFormat.getName());\r\n        \r\n        // First field in the output file is the number of fields+blooms saved\r\n        bloomOutput.writeInt(nonSaturatedBlooms.size());\r\n        for (Entry<FieldInfo,FuzzySet> entry : nonSaturatedBlooms) {\r\n          FieldInfo fieldInfo = entry.getKey();\r\n          FuzzySet bloomFilter = entry.getValue();\r\n          bloomOutput.writeInt(fieldInfo.number);\r\n          saveAppropriatelySizedBloomFilter(bloomOutput, bloomFilter, fieldInfo);\r\n        }\r\n      } finally {\r\n        IOUtils.close(bloomOutput);\r\n      }\r\n      //We are done with large bitsets so no need to keep them hanging around\r\n      bloomFilters.clear(); \r\n    }\r\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8fd5be977c105554c6a7b68afcdbc511439723ab","date":1344115570,"type":0,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/bloom/BloomFilteringPostingsFormat.BloomFilteredFieldsConsumer#close().mjava","pathOld":"/dev/null","sourceNew":"    @Override\r\n    public void close() throws IOException {\r\n      delegateFieldsConsumer.close();\r\n      // Now we are done accumulating values for these fields\r\n      List<Entry<FieldInfo,FuzzySet>> nonSaturatedBlooms = new ArrayList<Map.Entry<FieldInfo,FuzzySet>>();\r\n      \r\n      for (Entry<FieldInfo,FuzzySet> entry : bloomFilters.entrySet()) {\r\n        FuzzySet bloomFilter = entry.getValue();\r\n        if(!bloomFilterFactory.isSaturated(bloomFilter,entry.getKey())){          \r\n          nonSaturatedBlooms.add(entry);\r\n        }\r\n      }\r\n      String bloomFileName = IndexFileNames.segmentFileName(\r\n          state.segmentInfo.name, state.segmentSuffix, BLOOM_EXTENSION);\r\n      IndexOutput bloomOutput = null;\r\n      try {\r\n        bloomOutput = state.directory\r\n            .createOutput(bloomFileName, state.context);\r\n        CodecUtil.writeHeader(bloomOutput, BLOOM_CODEC_NAME,\r\n            BLOOM_CODEC_VERSION);\r\n        // remember the name of the postings format we will delegate to\r\n        bloomOutput.writeString(delegatePostingsFormat.getName());\r\n        \r\n        // First field in the output file is the number of fields+blooms saved\r\n        bloomOutput.writeInt(nonSaturatedBlooms.size());\r\n        for (Entry<FieldInfo,FuzzySet> entry : nonSaturatedBlooms) {\r\n          FieldInfo fieldInfo = entry.getKey();\r\n          FuzzySet bloomFilter = entry.getValue();\r\n          bloomOutput.writeInt(fieldInfo.number);\r\n          saveAppropriatelySizedBloomFilter(bloomOutput, bloomFilter, fieldInfo);\r\n        }\r\n      } finally {\r\n        IOUtils.close(bloomOutput);\r\n      }\r\n      //We are done with large bitsets so no need to keep them hanging around\r\n      bloomFilters.clear(); \r\n    }\r\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d6f074e73200c07d54f242d3880a8da5a35ff97b","date":1344507653,"type":0,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/bloom/BloomFilteringPostingsFormat.BloomFilteredFieldsConsumer#close().mjava","pathOld":"/dev/null","sourceNew":"    @Override\r\n    public void close() throws IOException {\r\n      delegateFieldsConsumer.close();\r\n      // Now we are done accumulating values for these fields\r\n      List<Entry<FieldInfo,FuzzySet>> nonSaturatedBlooms = new ArrayList<Map.Entry<FieldInfo,FuzzySet>>();\r\n      \r\n      for (Entry<FieldInfo,FuzzySet> entry : bloomFilters.entrySet()) {\r\n        FuzzySet bloomFilter = entry.getValue();\r\n        if(!bloomFilterFactory.isSaturated(bloomFilter,entry.getKey())){          \r\n          nonSaturatedBlooms.add(entry);\r\n        }\r\n      }\r\n      String bloomFileName = IndexFileNames.segmentFileName(\r\n          state.segmentInfo.name, state.segmentSuffix, BLOOM_EXTENSION);\r\n      IndexOutput bloomOutput = null;\r\n      try {\r\n        bloomOutput = state.directory\r\n            .createOutput(bloomFileName, state.context);\r\n        CodecUtil.writeHeader(bloomOutput, BLOOM_CODEC_NAME,\r\n            BLOOM_CODEC_VERSION);\r\n        // remember the name of the postings format we will delegate to\r\n        bloomOutput.writeString(delegatePostingsFormat.getName());\r\n        \r\n        // First field in the output file is the number of fields+blooms saved\r\n        bloomOutput.writeInt(nonSaturatedBlooms.size());\r\n        for (Entry<FieldInfo,FuzzySet> entry : nonSaturatedBlooms) {\r\n          FieldInfo fieldInfo = entry.getKey();\r\n          FuzzySet bloomFilter = entry.getValue();\r\n          bloomOutput.writeInt(fieldInfo.number);\r\n          saveAppropriatelySizedBloomFilter(bloomOutput, bloomFilter, fieldInfo);\r\n        }\r\n      } finally {\r\n        IOUtils.close(bloomOutput);\r\n      }\r\n      //We are done with large bitsets so no need to keep them hanging around\r\n      bloomFilters.clear(); \r\n    }\r\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d681ca1a1c487b2501ef9bde8602a65c4c717a46","date":1346078839,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/bloom/BloomFilteringPostingsFormat.BloomFilteredFieldsConsumer#close().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/bloom/BloomFilteringPostingsFormat.BloomFilteredFieldsConsumer#close().mjava","sourceNew":"    @Override\n    public void close() throws IOException {\n      delegateFieldsConsumer.close();\n      // Now we are done accumulating values for these fields\n      List<Entry<FieldInfo,FuzzySet>> nonSaturatedBlooms = new ArrayList<Map.Entry<FieldInfo,FuzzySet>>();\n      \n      for (Entry<FieldInfo,FuzzySet> entry : bloomFilters.entrySet()) {\n        FuzzySet bloomFilter = entry.getValue();\n        if(!bloomFilterFactory.isSaturated(bloomFilter,entry.getKey())){          \n          nonSaturatedBlooms.add(entry);\n        }\n      }\n      String bloomFileName = IndexFileNames.segmentFileName(\n          state.segmentInfo.name, state.segmentSuffix, BLOOM_EXTENSION);\n      IndexOutput bloomOutput = null;\n      try {\n        bloomOutput = state.directory\n            .createOutput(bloomFileName, state.context);\n        CodecUtil.writeHeader(bloomOutput, BLOOM_CODEC_NAME,\n            BLOOM_CODEC_VERSION);\n        // remember the name of the postings format we will delegate to\n        bloomOutput.writeString(delegatePostingsFormat.getName());\n        \n        // First field in the output file is the number of fields+blooms saved\n        bloomOutput.writeInt(nonSaturatedBlooms.size());\n        for (Entry<FieldInfo,FuzzySet> entry : nonSaturatedBlooms) {\n          FieldInfo fieldInfo = entry.getKey();\n          FuzzySet bloomFilter = entry.getValue();\n          bloomOutput.writeInt(fieldInfo.number);\n          saveAppropriatelySizedBloomFilter(bloomOutput, bloomFilter, fieldInfo);\n        }\n      } finally {\n        IOUtils.close(bloomOutput);\n      }\n      //We are done with large bitsets so no need to keep them hanging around\n      bloomFilters.clear(); \n    }\n\n","sourceOld":"    @Override\r\n    public void close() throws IOException {\r\n      delegateFieldsConsumer.close();\r\n      // Now we are done accumulating values for these fields\r\n      List<Entry<FieldInfo,FuzzySet>> nonSaturatedBlooms = new ArrayList<Map.Entry<FieldInfo,FuzzySet>>();\r\n      \r\n      for (Entry<FieldInfo,FuzzySet> entry : bloomFilters.entrySet()) {\r\n        FuzzySet bloomFilter = entry.getValue();\r\n        if(!bloomFilterFactory.isSaturated(bloomFilter,entry.getKey())){          \r\n          nonSaturatedBlooms.add(entry);\r\n        }\r\n      }\r\n      String bloomFileName = IndexFileNames.segmentFileName(\r\n          state.segmentInfo.name, state.segmentSuffix, BLOOM_EXTENSION);\r\n      IndexOutput bloomOutput = null;\r\n      try {\r\n        bloomOutput = state.directory\r\n            .createOutput(bloomFileName, state.context);\r\n        CodecUtil.writeHeader(bloomOutput, BLOOM_CODEC_NAME,\r\n            BLOOM_CODEC_VERSION);\r\n        // remember the name of the postings format we will delegate to\r\n        bloomOutput.writeString(delegatePostingsFormat.getName());\r\n        \r\n        // First field in the output file is the number of fields+blooms saved\r\n        bloomOutput.writeInt(nonSaturatedBlooms.size());\r\n        for (Entry<FieldInfo,FuzzySet> entry : nonSaturatedBlooms) {\r\n          FieldInfo fieldInfo = entry.getKey();\r\n          FuzzySet bloomFilter = entry.getValue();\r\n          bloomOutput.writeInt(fieldInfo.number);\r\n          saveAppropriatelySizedBloomFilter(bloomOutput, bloomFilter, fieldInfo);\r\n        }\r\n      } finally {\r\n        IOUtils.close(bloomOutput);\r\n      }\r\n      //We are done with large bitsets so no need to keep them hanging around\r\n      bloomFilters.clear(); \r\n    }\r\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"05a14b2611ead08655a2b2bdc61632eb31316e57","date":1346366621,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/bloom/BloomFilteringPostingsFormat.BloomFilteredFieldsConsumer#close().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/bloom/BloomFilteringPostingsFormat.BloomFilteredFieldsConsumer#close().mjava","sourceNew":"    @Override\n    public void close() throws IOException {\n      delegateFieldsConsumer.close();\n      // Now we are done accumulating values for these fields\n      List<Entry<FieldInfo,FuzzySet>> nonSaturatedBlooms = new ArrayList<Map.Entry<FieldInfo,FuzzySet>>();\n      \n      for (Entry<FieldInfo,FuzzySet> entry : bloomFilters.entrySet()) {\n        FuzzySet bloomFilter = entry.getValue();\n        if(!bloomFilterFactory.isSaturated(bloomFilter,entry.getKey())){          \n          nonSaturatedBlooms.add(entry);\n        }\n      }\n      String bloomFileName = IndexFileNames.segmentFileName(\n          state.segmentInfo.name, state.segmentSuffix, BLOOM_EXTENSION);\n      IndexOutput bloomOutput = null;\n      try {\n        bloomOutput = state.directory\n            .createOutput(bloomFileName, state.context);\n        CodecUtil.writeHeader(bloomOutput, BLOOM_CODEC_NAME,\n            BLOOM_CODEC_VERSION);\n        // remember the name of the postings format we will delegate to\n        bloomOutput.writeString(delegatePostingsFormat.getName());\n        \n        // First field in the output file is the number of fields+blooms saved\n        bloomOutput.writeInt(nonSaturatedBlooms.size());\n        for (Entry<FieldInfo,FuzzySet> entry : nonSaturatedBlooms) {\n          FieldInfo fieldInfo = entry.getKey();\n          FuzzySet bloomFilter = entry.getValue();\n          bloomOutput.writeInt(fieldInfo.number);\n          saveAppropriatelySizedBloomFilter(bloomOutput, bloomFilter, fieldInfo);\n        }\n      } finally {\n        IOUtils.close(bloomOutput);\n      }\n      //We are done with large bitsets so no need to keep them hanging around\n      bloomFilters.clear(); \n    }\n\n","sourceOld":"    @Override\r\n    public void close() throws IOException {\r\n      delegateFieldsConsumer.close();\r\n      // Now we are done accumulating values for these fields\r\n      List<Entry<FieldInfo,FuzzySet>> nonSaturatedBlooms = new ArrayList<Map.Entry<FieldInfo,FuzzySet>>();\r\n      \r\n      for (Entry<FieldInfo,FuzzySet> entry : bloomFilters.entrySet()) {\r\n        FuzzySet bloomFilter = entry.getValue();\r\n        if(!bloomFilterFactory.isSaturated(bloomFilter,entry.getKey())){          \r\n          nonSaturatedBlooms.add(entry);\r\n        }\r\n      }\r\n      String bloomFileName = IndexFileNames.segmentFileName(\r\n          state.segmentInfo.name, state.segmentSuffix, BLOOM_EXTENSION);\r\n      IndexOutput bloomOutput = null;\r\n      try {\r\n        bloomOutput = state.directory\r\n            .createOutput(bloomFileName, state.context);\r\n        CodecUtil.writeHeader(bloomOutput, BLOOM_CODEC_NAME,\r\n            BLOOM_CODEC_VERSION);\r\n        // remember the name of the postings format we will delegate to\r\n        bloomOutput.writeString(delegatePostingsFormat.getName());\r\n        \r\n        // First field in the output file is the number of fields+blooms saved\r\n        bloomOutput.writeInt(nonSaturatedBlooms.size());\r\n        for (Entry<FieldInfo,FuzzySet> entry : nonSaturatedBlooms) {\r\n          FieldInfo fieldInfo = entry.getKey();\r\n          FuzzySet bloomFilter = entry.getValue();\r\n          bloomOutput.writeInt(fieldInfo.number);\r\n          saveAppropriatelySizedBloomFilter(bloomOutput, bloomFilter, fieldInfo);\r\n        }\r\n      } finally {\r\n        IOUtils.close(bloomOutput);\r\n      }\r\n      //We are done with large bitsets so no need to keep them hanging around\r\n      bloomFilters.clear(); \r\n    }\r\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3e45d45bc3730ddd1341f4eb6025f33b8482e6e2","date":1346834651,"type":5,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/bloom/BloomFilteringPostingsFormat.BloomFilteredFieldsConsumer#close().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/bloom/BloomFilteringPostingsFormat.BloomFilteredFieldsConsumer#close().mjava","sourceNew":"    @Override\n    public void close() throws IOException {\n      delegateFieldsConsumer.close();\n      // Now we are done accumulating values for these fields\n      List<Entry<FieldInfo,FuzzySet>> nonSaturatedBlooms = new ArrayList<Map.Entry<FieldInfo,FuzzySet>>();\n      \n      for (Entry<FieldInfo,FuzzySet> entry : bloomFilters.entrySet()) {\n        FuzzySet bloomFilter = entry.getValue();\n        if(!bloomFilterFactory.isSaturated(bloomFilter,entry.getKey())){          \n          nonSaturatedBlooms.add(entry);\n        }\n      }\n      String bloomFileName = IndexFileNames.segmentFileName(\n          state.segmentInfo.name, state.segmentSuffix, BLOOM_EXTENSION);\n      IndexOutput bloomOutput = null;\n      try {\n        bloomOutput = state.directory\n            .createOutput(bloomFileName, state.context);\n        CodecUtil.writeHeader(bloomOutput, BLOOM_CODEC_NAME,\n            BLOOM_CODEC_VERSION);\n        // remember the name of the postings format we will delegate to\n        bloomOutput.writeString(delegatePostingsFormat.getName());\n        \n        // First field in the output file is the number of fields+blooms saved\n        bloomOutput.writeInt(nonSaturatedBlooms.size());\n        for (Entry<FieldInfo,FuzzySet> entry : nonSaturatedBlooms) {\n          FieldInfo fieldInfo = entry.getKey();\n          FuzzySet bloomFilter = entry.getValue();\n          bloomOutput.writeInt(fieldInfo.number);\n          saveAppropriatelySizedBloomFilter(bloomOutput, bloomFilter, fieldInfo);\n        }\n      } finally {\n        IOUtils.close(bloomOutput);\n      }\n      //We are done with large bitsets so no need to keep them hanging around\n      bloomFilters.clear(); \n    }\n\n","sourceOld":"    @Override\n    public void close() throws IOException {\n      delegateFieldsConsumer.close();\n      // Now we are done accumulating values for these fields\n      List<Entry<FieldInfo,FuzzySet>> nonSaturatedBlooms = new ArrayList<Map.Entry<FieldInfo,FuzzySet>>();\n      \n      for (Entry<FieldInfo,FuzzySet> entry : bloomFilters.entrySet()) {\n        FuzzySet bloomFilter = entry.getValue();\n        if(!bloomFilterFactory.isSaturated(bloomFilter,entry.getKey())){          \n          nonSaturatedBlooms.add(entry);\n        }\n      }\n      String bloomFileName = IndexFileNames.segmentFileName(\n          state.segmentInfo.name, state.segmentSuffix, BLOOM_EXTENSION);\n      IndexOutput bloomOutput = null;\n      try {\n        bloomOutput = state.directory\n            .createOutput(bloomFileName, state.context);\n        CodecUtil.writeHeader(bloomOutput, BLOOM_CODEC_NAME,\n            BLOOM_CODEC_VERSION);\n        // remember the name of the postings format we will delegate to\n        bloomOutput.writeString(delegatePostingsFormat.getName());\n        \n        // First field in the output file is the number of fields+blooms saved\n        bloomOutput.writeInt(nonSaturatedBlooms.size());\n        for (Entry<FieldInfo,FuzzySet> entry : nonSaturatedBlooms) {\n          FieldInfo fieldInfo = entry.getKey();\n          FuzzySet bloomFilter = entry.getValue();\n          bloomOutput.writeInt(fieldInfo.number);\n          saveAppropriatelySizedBloomFilter(bloomOutput, bloomFilter, fieldInfo);\n        }\n      } finally {\n        IOUtils.close(bloomOutput);\n      }\n      //We are done with large bitsets so no need to keep them hanging around\n      bloomFilters.clear(); \n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"d681ca1a1c487b2501ef9bde8602a65c4c717a46":["0274c27988a26cb0cda3a0d15b282221b1b453f0"],"3e45d45bc3730ddd1341f4eb6025f33b8482e6e2":["d681ca1a1c487b2501ef9bde8602a65c4c717a46"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"0274c27988a26cb0cda3a0d15b282221b1b453f0":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","0274c27988a26cb0cda3a0d15b282221b1b453f0"],"8fd5be977c105554c6a7b68afcdbc511439723ab":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","0274c27988a26cb0cda3a0d15b282221b1b453f0"],"05a14b2611ead08655a2b2bdc61632eb31316e57":["d6f074e73200c07d54f242d3880a8da5a35ff97b","d681ca1a1c487b2501ef9bde8602a65c4c717a46"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3e45d45bc3730ddd1341f4eb6025f33b8482e6e2"]},"commit2Childs":{"d681ca1a1c487b2501ef9bde8602a65c4c717a46":["3e45d45bc3730ddd1341f4eb6025f33b8482e6e2","05a14b2611ead08655a2b2bdc61632eb31316e57"],"3e45d45bc3730ddd1341f4eb6025f33b8482e6e2":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["0274c27988a26cb0cda3a0d15b282221b1b453f0","d6f074e73200c07d54f242d3880a8da5a35ff97b","8fd5be977c105554c6a7b68afcdbc511439723ab"],"0274c27988a26cb0cda3a0d15b282221b1b453f0":["d681ca1a1c487b2501ef9bde8602a65c4c717a46","d6f074e73200c07d54f242d3880a8da5a35ff97b","8fd5be977c105554c6a7b68afcdbc511439723ab"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":["05a14b2611ead08655a2b2bdc61632eb31316e57"],"8fd5be977c105554c6a7b68afcdbc511439723ab":[],"05a14b2611ead08655a2b2bdc61632eb31316e57":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["8fd5be977c105554c6a7b68afcdbc511439723ab","05a14b2611ead08655a2b2bdc61632eb31316e57","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}