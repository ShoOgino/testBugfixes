{"path":"solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler#prepDistributed(ResponseBuilder).mjava","commits":[{"id":"5676bf22fd531b9a2a3053047d0e0f922c1c53ff","date":1435097302,"type":0,"author":"Ramkumar Aiyengar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler#prepDistributed(ResponseBuilder).mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public void prepDistributed(ResponseBuilder rb) {\n    final SolrQueryRequest req = rb.req;\n    final SolrParams params = req.getParams();\n    final String shards = params.get(ShardParams.SHARDS);\n\n    // since the cost of grabbing cloud state is still up in the air, we grab it only\n    // if we need it.\n    ClusterState clusterState = null;\n    Map<String,Slice> slices = null;\n    CoreDescriptor coreDescriptor = req.getCore().getCoreDescriptor();\n    CloudDescriptor cloudDescriptor = coreDescriptor.getCloudDescriptor();\n    ZkController zkController = coreDescriptor.getCoreContainer().getZkController();\n\n\n    if (shards != null) {\n      List<String> lst = StrUtils.splitSmart(shards, \",\", true);\n      rb.shards = lst.toArray(new String[lst.size()]);\n      rb.slices = new String[rb.shards.length];\n\n      if (zkController != null) {\n        // figure out which shards are slices\n        for (int i=0; i<rb.shards.length; i++) {\n          if (rb.shards[i].indexOf('/') < 0) {\n            // this is a logical shard\n            rb.slices[i] = rb.shards[i];\n            rb.shards[i] = null;\n          }\n        }\n      }\n    } else if (zkController != null) {\n      // we weren't provided with an explicit list of slices to query via \"shards\", so use the cluster state\n\n      clusterState =  zkController.getClusterState();\n      String shardKeys =  params.get(ShardParams._ROUTE_);\n\n      // This will be the complete list of slices we need to query for this request.\n      slices = new HashMap<>();\n\n      // we need to find out what collections this request is for.\n\n      // A comma-separated list of specified collections.\n      // Eg: \"collection1,collection2,collection3\"\n      String collections = params.get(\"collection\");\n      if (collections != null) {\n        // If there were one or more collections specified in the query, split\n        // each parameter and store as a separate member of a List.\n        List<String> collectionList = StrUtils.splitSmart(collections, \",\",\n            true);\n        // In turn, retrieve the slices that cover each collection from the\n        // cloud state and add them to the Map 'slices'.\n        for (String collectionName : collectionList) {\n          // The original code produced <collection-name>_<shard-name> when the collections\n          // parameter was specified (see ClientUtils.appendMap)\n          // Is this necessary if ony one collection is specified?\n          // i.e. should we change multiCollection to collectionList.size() > 1?\n          addSlices(slices, clusterState, params, collectionName,  shardKeys, true);\n        }\n      } else {\n        // just this collection\n        String collectionName = cloudDescriptor.getCollectionName();\n        addSlices(slices, clusterState, params, collectionName,  shardKeys, false);\n      }\n\n\n      // Store the logical slices in the ResponseBuilder and create a new\n      // String array to hold the physical shards (which will be mapped\n      // later).\n      rb.slices = slices.keySet().toArray(new String[slices.size()]);\n      rb.shards = new String[rb.slices.length];\n    }\n\n    //\n    // Map slices to shards\n    //\n    if (zkController != null) {\n\n      // Are we hosting the shard that this request is for, and are we active? If so, then handle it ourselves\n      // and make it a non-distributed request.\n      String ourSlice = cloudDescriptor.getShardId();\n      String ourCollection = cloudDescriptor.getCollectionName();\n      if (rb.slices.length == 1 && rb.slices[0] != null\n          && ( rb.slices[0].equals(ourSlice) || rb.slices[0].equals(ourCollection + \"_\" + ourSlice) )  // handle the <collection>_<slice> format\n          && cloudDescriptor.getLastPublished() == Replica.State.ACTIVE) {\n        boolean shortCircuit = params.getBool(\"shortCircuit\", true);       // currently just a debugging parameter to check distrib search on a single node\n\n        String targetHandler = params.get(ShardParams.SHARDS_QT);\n        shortCircuit = shortCircuit && targetHandler == null;             // if a different handler is specified, don't short-circuit\n\n        if (shortCircuit) {\n          rb.isDistrib = false;\n          rb.shortCircuitedURL = ZkCoreNodeProps.getCoreUrl(zkController.getBaseUrl(), coreDescriptor.getName());\n          return;\n        }\n        // We shouldn't need to do anything to handle \"shard.rows\" since it was previously meant to be an optimization?\n      }\n\n\n      for (int i=0; i<rb.shards.length; i++) {\n        if (rb.shards[i] == null) {\n          if (clusterState == null) {\n            clusterState =  zkController.getClusterState();\n            slices = clusterState.getSlicesMap(cloudDescriptor.getCollectionName());\n          }\n          String sliceName = rb.slices[i];\n\n          Slice slice = slices.get(sliceName);\n\n          if (slice==null) {\n            // Treat this the same as \"all servers down\" for a slice, and let things continue\n            // if partial results are acceptable\n            rb.shards[i] = \"\";\n            continue;\n            // throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"no such shard: \" + sliceName);\n          }\n\n          Map<String, Replica> sliceShards = slice.getReplicasMap();\n\n          // For now, recreate the | delimited list of equivalent servers\n          StringBuilder sliceShardsStr = new StringBuilder();\n          boolean first = true;\n          for (Replica replica : sliceShards.values()) {\n            if (!clusterState.liveNodesContain(replica.getNodeName())\n                || replica.getState() != Replica.State.ACTIVE) {\n              continue;\n            }\n            if (first) {\n              first = false;\n            } else {\n              sliceShardsStr.append('|');\n            }\n            String url = ZkCoreNodeProps.getCoreUrl(replica);\n            sliceShardsStr.append(url);\n          }\n\n          if (sliceShardsStr.length() == 0) {\n            boolean tolerant = rb.req.getParams().getBool(ShardParams.SHARDS_TOLERANT, false);\n            if (!tolerant) {\n              // stop the check when there are no replicas available for a shard\n              throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n                  \"no servers hosting shard: \" + rb.slices[i]);\n            }\n          }\n\n          rb.shards[i] = sliceShardsStr.toString();\n        }\n      }\n    }\n    String shards_rows = params.get(ShardParams.SHARDS_ROWS);\n    if(shards_rows != null) {\n      rb.shards_rows = Integer.parseInt(shards_rows);\n    }\n    String shards_start = params.get(ShardParams.SHARDS_START);\n    if(shards_start != null) {\n      rb.shards_start = Integer.parseInt(shards_start);\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["344b0840364d990b29b97467bfcc766ff8325d11"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"23e55c29de60130e8a1226800b66c5f6d7e16e8a","date":1447950053,"type":3,"author":"Christine Poerschke","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler#prepDistributed(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler#prepDistributed(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void prepDistributed(ResponseBuilder rb) {\n    final SolrQueryRequest req = rb.req;\n    final SolrParams params = req.getParams();\n    final String shards = params.get(ShardParams.SHARDS);\n\n    // since the cost of grabbing cloud state is still up in the air, we grab it only\n    // if we need it.\n    ClusterState clusterState = null;\n    Map<String,Slice> slices = null;\n    CoreDescriptor coreDescriptor = req.getCore().getCoreDescriptor();\n    CloudDescriptor cloudDescriptor = coreDescriptor.getCloudDescriptor();\n    ZkController zkController = coreDescriptor.getCoreContainer().getZkController();\n\n    if (params.getBool(CommonParams.PREFER_LOCAL_SHARDS, false)) {\n      rb.preferredHostAddress = (zkController != null) ? zkController.getBaseUrl() : null;\n      if (rb.preferredHostAddress == null) {\n        log.warn(\"Couldn't determine current host address to prefer local shards\");\n      }\n    }\n\n    if (shards != null) {\n      List<String> lst = StrUtils.splitSmart(shards, \",\", true);\n      rb.shards = lst.toArray(new String[lst.size()]);\n      rb.slices = new String[rb.shards.length];\n\n      if (zkController != null) {\n        // figure out which shards are slices\n        for (int i=0; i<rb.shards.length; i++) {\n          if (rb.shards[i].indexOf('/') < 0) {\n            // this is a logical shard\n            rb.slices[i] = rb.shards[i];\n            rb.shards[i] = null;\n          }\n        }\n      }\n    } else if (zkController != null) {\n      // we weren't provided with an explicit list of slices to query via \"shards\", so use the cluster state\n\n      clusterState =  zkController.getClusterState();\n      String shardKeys =  params.get(ShardParams._ROUTE_);\n\n      // This will be the complete list of slices we need to query for this request.\n      slices = new HashMap<>();\n\n      // we need to find out what collections this request is for.\n\n      // A comma-separated list of specified collections.\n      // Eg: \"collection1,collection2,collection3\"\n      String collections = params.get(\"collection\");\n      if (collections != null) {\n        // If there were one or more collections specified in the query, split\n        // each parameter and store as a separate member of a List.\n        List<String> collectionList = StrUtils.splitSmart(collections, \",\",\n            true);\n        // In turn, retrieve the slices that cover each collection from the\n        // cloud state and add them to the Map 'slices'.\n        for (String collectionName : collectionList) {\n          // The original code produced <collection-name>_<shard-name> when the collections\n          // parameter was specified (see ClientUtils.appendMap)\n          // Is this necessary if ony one collection is specified?\n          // i.e. should we change multiCollection to collectionList.size() > 1?\n          addSlices(slices, clusterState, params, collectionName,  shardKeys, true);\n        }\n      } else {\n        // just this collection\n        String collectionName = cloudDescriptor.getCollectionName();\n        addSlices(slices, clusterState, params, collectionName,  shardKeys, false);\n      }\n\n\n      // Store the logical slices in the ResponseBuilder and create a new\n      // String array to hold the physical shards (which will be mapped\n      // later).\n      rb.slices = slices.keySet().toArray(new String[slices.size()]);\n      rb.shards = new String[rb.slices.length];\n    }\n\n    //\n    // Map slices to shards\n    //\n    if (zkController != null) {\n\n      // Are we hosting the shard that this request is for, and are we active? If so, then handle it ourselves\n      // and make it a non-distributed request.\n      String ourSlice = cloudDescriptor.getShardId();\n      String ourCollection = cloudDescriptor.getCollectionName();\n      if (rb.slices.length == 1 && rb.slices[0] != null\n          && ( rb.slices[0].equals(ourSlice) || rb.slices[0].equals(ourCollection + \"_\" + ourSlice) )  // handle the <collection>_<slice> format\n          && cloudDescriptor.getLastPublished() == Replica.State.ACTIVE) {\n        boolean shortCircuit = params.getBool(\"shortCircuit\", true);       // currently just a debugging parameter to check distrib search on a single node\n\n        String targetHandler = params.get(ShardParams.SHARDS_QT);\n        shortCircuit = shortCircuit && targetHandler == null;             // if a different handler is specified, don't short-circuit\n\n        if (shortCircuit) {\n          rb.isDistrib = false;\n          rb.shortCircuitedURL = ZkCoreNodeProps.getCoreUrl(zkController.getBaseUrl(), coreDescriptor.getName());\n          return;\n        }\n        // We shouldn't need to do anything to handle \"shard.rows\" since it was previously meant to be an optimization?\n      }\n\n\n      for (int i=0; i<rb.shards.length; i++) {\n        if (rb.shards[i] == null) {\n          if (clusterState == null) {\n            clusterState =  zkController.getClusterState();\n            slices = clusterState.getSlicesMap(cloudDescriptor.getCollectionName());\n          }\n          String sliceName = rb.slices[i];\n\n          Slice slice = slices.get(sliceName);\n\n          if (slice==null) {\n            // Treat this the same as \"all servers down\" for a slice, and let things continue\n            // if partial results are acceptable\n            rb.shards[i] = \"\";\n            continue;\n            // throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"no such shard: \" + sliceName);\n          }\n\n          Map<String, Replica> sliceShards = slice.getReplicasMap();\n\n          // For now, recreate the | delimited list of equivalent servers\n          StringBuilder sliceShardsStr = new StringBuilder();\n          boolean first = true;\n          for (Replica replica : sliceShards.values()) {\n            if (!clusterState.liveNodesContain(replica.getNodeName())\n                || replica.getState() != Replica.State.ACTIVE) {\n              continue;\n            }\n            if (first) {\n              first = false;\n            } else {\n              sliceShardsStr.append('|');\n            }\n            String url = ZkCoreNodeProps.getCoreUrl(replica);\n            sliceShardsStr.append(url);\n          }\n\n          if (sliceShardsStr.length() == 0) {\n            boolean tolerant = rb.req.getParams().getBool(ShardParams.SHARDS_TOLERANT, false);\n            if (!tolerant) {\n              // stop the check when there are no replicas available for a shard\n              throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n                  \"no servers hosting shard: \" + rb.slices[i]);\n            }\n          }\n\n          rb.shards[i] = sliceShardsStr.toString();\n        }\n      }\n    }\n    String shards_rows = params.get(ShardParams.SHARDS_ROWS);\n    if(shards_rows != null) {\n      rb.shards_rows = Integer.parseInt(shards_rows);\n    }\n    String shards_start = params.get(ShardParams.SHARDS_START);\n    if(shards_start != null) {\n      rb.shards_start = Integer.parseInt(shards_start);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void prepDistributed(ResponseBuilder rb) {\n    final SolrQueryRequest req = rb.req;\n    final SolrParams params = req.getParams();\n    final String shards = params.get(ShardParams.SHARDS);\n\n    // since the cost of grabbing cloud state is still up in the air, we grab it only\n    // if we need it.\n    ClusterState clusterState = null;\n    Map<String,Slice> slices = null;\n    CoreDescriptor coreDescriptor = req.getCore().getCoreDescriptor();\n    CloudDescriptor cloudDescriptor = coreDescriptor.getCloudDescriptor();\n    ZkController zkController = coreDescriptor.getCoreContainer().getZkController();\n\n\n    if (shards != null) {\n      List<String> lst = StrUtils.splitSmart(shards, \",\", true);\n      rb.shards = lst.toArray(new String[lst.size()]);\n      rb.slices = new String[rb.shards.length];\n\n      if (zkController != null) {\n        // figure out which shards are slices\n        for (int i=0; i<rb.shards.length; i++) {\n          if (rb.shards[i].indexOf('/') < 0) {\n            // this is a logical shard\n            rb.slices[i] = rb.shards[i];\n            rb.shards[i] = null;\n          }\n        }\n      }\n    } else if (zkController != null) {\n      // we weren't provided with an explicit list of slices to query via \"shards\", so use the cluster state\n\n      clusterState =  zkController.getClusterState();\n      String shardKeys =  params.get(ShardParams._ROUTE_);\n\n      // This will be the complete list of slices we need to query for this request.\n      slices = new HashMap<>();\n\n      // we need to find out what collections this request is for.\n\n      // A comma-separated list of specified collections.\n      // Eg: \"collection1,collection2,collection3\"\n      String collections = params.get(\"collection\");\n      if (collections != null) {\n        // If there were one or more collections specified in the query, split\n        // each parameter and store as a separate member of a List.\n        List<String> collectionList = StrUtils.splitSmart(collections, \",\",\n            true);\n        // In turn, retrieve the slices that cover each collection from the\n        // cloud state and add them to the Map 'slices'.\n        for (String collectionName : collectionList) {\n          // The original code produced <collection-name>_<shard-name> when the collections\n          // parameter was specified (see ClientUtils.appendMap)\n          // Is this necessary if ony one collection is specified?\n          // i.e. should we change multiCollection to collectionList.size() > 1?\n          addSlices(slices, clusterState, params, collectionName,  shardKeys, true);\n        }\n      } else {\n        // just this collection\n        String collectionName = cloudDescriptor.getCollectionName();\n        addSlices(slices, clusterState, params, collectionName,  shardKeys, false);\n      }\n\n\n      // Store the logical slices in the ResponseBuilder and create a new\n      // String array to hold the physical shards (which will be mapped\n      // later).\n      rb.slices = slices.keySet().toArray(new String[slices.size()]);\n      rb.shards = new String[rb.slices.length];\n    }\n\n    //\n    // Map slices to shards\n    //\n    if (zkController != null) {\n\n      // Are we hosting the shard that this request is for, and are we active? If so, then handle it ourselves\n      // and make it a non-distributed request.\n      String ourSlice = cloudDescriptor.getShardId();\n      String ourCollection = cloudDescriptor.getCollectionName();\n      if (rb.slices.length == 1 && rb.slices[0] != null\n          && ( rb.slices[0].equals(ourSlice) || rb.slices[0].equals(ourCollection + \"_\" + ourSlice) )  // handle the <collection>_<slice> format\n          && cloudDescriptor.getLastPublished() == Replica.State.ACTIVE) {\n        boolean shortCircuit = params.getBool(\"shortCircuit\", true);       // currently just a debugging parameter to check distrib search on a single node\n\n        String targetHandler = params.get(ShardParams.SHARDS_QT);\n        shortCircuit = shortCircuit && targetHandler == null;             // if a different handler is specified, don't short-circuit\n\n        if (shortCircuit) {\n          rb.isDistrib = false;\n          rb.shortCircuitedURL = ZkCoreNodeProps.getCoreUrl(zkController.getBaseUrl(), coreDescriptor.getName());\n          return;\n        }\n        // We shouldn't need to do anything to handle \"shard.rows\" since it was previously meant to be an optimization?\n      }\n\n\n      for (int i=0; i<rb.shards.length; i++) {\n        if (rb.shards[i] == null) {\n          if (clusterState == null) {\n            clusterState =  zkController.getClusterState();\n            slices = clusterState.getSlicesMap(cloudDescriptor.getCollectionName());\n          }\n          String sliceName = rb.slices[i];\n\n          Slice slice = slices.get(sliceName);\n\n          if (slice==null) {\n            // Treat this the same as \"all servers down\" for a slice, and let things continue\n            // if partial results are acceptable\n            rb.shards[i] = \"\";\n            continue;\n            // throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"no such shard: \" + sliceName);\n          }\n\n          Map<String, Replica> sliceShards = slice.getReplicasMap();\n\n          // For now, recreate the | delimited list of equivalent servers\n          StringBuilder sliceShardsStr = new StringBuilder();\n          boolean first = true;\n          for (Replica replica : sliceShards.values()) {\n            if (!clusterState.liveNodesContain(replica.getNodeName())\n                || replica.getState() != Replica.State.ACTIVE) {\n              continue;\n            }\n            if (first) {\n              first = false;\n            } else {\n              sliceShardsStr.append('|');\n            }\n            String url = ZkCoreNodeProps.getCoreUrl(replica);\n            sliceShardsStr.append(url);\n          }\n\n          if (sliceShardsStr.length() == 0) {\n            boolean tolerant = rb.req.getParams().getBool(ShardParams.SHARDS_TOLERANT, false);\n            if (!tolerant) {\n              // stop the check when there are no replicas available for a shard\n              throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n                  \"no servers hosting shard: \" + rb.slices[i]);\n            }\n          }\n\n          rb.shards[i] = sliceShardsStr.toString();\n        }\n      }\n    }\n    String shards_rows = params.get(ShardParams.SHARDS_ROWS);\n    if(shards_rows != null) {\n      rb.shards_rows = Integer.parseInt(shards_rows);\n    }\n    String shards_start = params.get(ShardParams.SHARDS_START);\n    if(shards_start != null) {\n      rb.shards_start = Integer.parseInt(shards_start);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f82cd77bc27bbdd30a6dd22e5adb2cf8def2c34a","date":1478684774,"type":3,"author":"Christine Poerschke","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler#prepDistributed(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler#prepDistributed(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void prepDistributed(ResponseBuilder rb) {\n    final SolrQueryRequest req = rb.req;\n    final SolrParams params = req.getParams();\n    final String shards = params.get(ShardParams.SHARDS);\n\n    // since the cost of grabbing cloud state is still up in the air, we grab it only\n    // if we need it.\n    ClusterState clusterState = null;\n    Map<String,Slice> slices = null;\n    CoreDescriptor coreDescriptor = req.getCore().getCoreDescriptor();\n    CloudDescriptor cloudDescriptor = coreDescriptor.getCloudDescriptor();\n    ZkController zkController = coreDescriptor.getCoreContainer().getZkController();\n\n    if (params.getBool(CommonParams.PREFER_LOCAL_SHARDS, false)) {\n      rb.preferredHostAddress = (zkController != null) ? zkController.getBaseUrl() : null;\n      if (rb.preferredHostAddress == null) {\n        log.warn(\"Couldn't determine current host address to prefer local shards\");\n      }\n    }\n\n    final ReplicaListTransformer replicaListTransformer = httpShardHandlerFactory.getReplicaListTransformer(req);\n\n    if (shards != null) {\n      List<String> lst = StrUtils.splitSmart(shards, \",\", true);\n      rb.shards = lst.toArray(new String[lst.size()]);\n      rb.slices = new String[rb.shards.length];\n\n      if (zkController != null) {\n        // figure out which shards are slices\n        for (int i=0; i<rb.shards.length; i++) {\n          if (rb.shards[i].indexOf('/') < 0) {\n            // this is a logical shard\n            rb.slices[i] = rb.shards[i];\n            rb.shards[i] = null;\n          }\n        }\n      }\n    } else if (zkController != null) {\n      // we weren't provided with an explicit list of slices to query via \"shards\", so use the cluster state\n\n      clusterState =  zkController.getClusterState();\n      String shardKeys =  params.get(ShardParams._ROUTE_);\n\n      // This will be the complete list of slices we need to query for this request.\n      slices = new HashMap<>();\n\n      // we need to find out what collections this request is for.\n\n      // A comma-separated list of specified collections.\n      // Eg: \"collection1,collection2,collection3\"\n      String collections = params.get(\"collection\");\n      if (collections != null) {\n        // If there were one or more collections specified in the query, split\n        // each parameter and store as a separate member of a List.\n        List<String> collectionList = StrUtils.splitSmart(collections, \",\",\n            true);\n        // In turn, retrieve the slices that cover each collection from the\n        // cloud state and add them to the Map 'slices'.\n        for (String collectionName : collectionList) {\n          // The original code produced <collection-name>_<shard-name> when the collections\n          // parameter was specified (see ClientUtils.appendMap)\n          // Is this necessary if ony one collection is specified?\n          // i.e. should we change multiCollection to collectionList.size() > 1?\n          addSlices(slices, clusterState, params, collectionName,  shardKeys, true);\n        }\n      } else {\n        // just this collection\n        String collectionName = cloudDescriptor.getCollectionName();\n        addSlices(slices, clusterState, params, collectionName,  shardKeys, false);\n      }\n\n\n      // Store the logical slices in the ResponseBuilder and create a new\n      // String array to hold the physical shards (which will be mapped\n      // later).\n      rb.slices = slices.keySet().toArray(new String[slices.size()]);\n      rb.shards = new String[rb.slices.length];\n    }\n\n    //\n    // Map slices to shards\n    //\n    if (zkController != null) {\n\n      // Are we hosting the shard that this request is for, and are we active? If so, then handle it ourselves\n      // and make it a non-distributed request.\n      String ourSlice = cloudDescriptor.getShardId();\n      String ourCollection = cloudDescriptor.getCollectionName();\n      if (rb.slices.length == 1 && rb.slices[0] != null\n          && ( rb.slices[0].equals(ourSlice) || rb.slices[0].equals(ourCollection + \"_\" + ourSlice) )  // handle the <collection>_<slice> format\n          && cloudDescriptor.getLastPublished() == Replica.State.ACTIVE) {\n        boolean shortCircuit = params.getBool(\"shortCircuit\", true);       // currently just a debugging parameter to check distrib search on a single node\n\n        String targetHandler = params.get(ShardParams.SHARDS_QT);\n        shortCircuit = shortCircuit && targetHandler == null;             // if a different handler is specified, don't short-circuit\n\n        if (shortCircuit) {\n          rb.isDistrib = false;\n          rb.shortCircuitedURL = ZkCoreNodeProps.getCoreUrl(zkController.getBaseUrl(), coreDescriptor.getName());\n          return;\n        }\n        // We shouldn't need to do anything to handle \"shard.rows\" since it was previously meant to be an optimization?\n      }\n\n\n      for (int i=0; i<rb.shards.length; i++) {\n        final List<String> shardUrls;\n        if (rb.shards[i] != null) {\n          shardUrls = StrUtils.splitSmart(rb.shards[i], \"|\", true);\n          replicaListTransformer.transform(shardUrls);\n        } else {\n          if (clusterState == null) {\n            clusterState =  zkController.getClusterState();\n            slices = clusterState.getSlicesMap(cloudDescriptor.getCollectionName());\n          }\n          String sliceName = rb.slices[i];\n\n          Slice slice = slices.get(sliceName);\n\n          if (slice==null) {\n            // Treat this the same as \"all servers down\" for a slice, and let things continue\n            // if partial results are acceptable\n            rb.shards[i] = \"\";\n            continue;\n            // throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"no such shard: \" + sliceName);\n          }\n\n          final Collection<Replica> allSliceReplicas = slice.getReplicasMap().values();\n          final List<Replica> eligibleSliceReplicas = new ArrayList<>(allSliceReplicas.size());\n          for (Replica replica : allSliceReplicas) {\n            if (!clusterState.liveNodesContain(replica.getNodeName())\n                || replica.getState() != Replica.State.ACTIVE) {\n              continue;\n            }\n            eligibleSliceReplicas.add(replica);\n          }\n\n          replicaListTransformer.transform(eligibleSliceReplicas);\n\n          shardUrls = new ArrayList<>(eligibleSliceReplicas.size());\n          for (Replica replica : eligibleSliceReplicas) {\n            String url = ZkCoreNodeProps.getCoreUrl(replica);\n            shardUrls.add(url);\n          }\n\n          if (shardUrls.isEmpty()) {\n            boolean tolerant = rb.req.getParams().getBool(ShardParams.SHARDS_TOLERANT, false);\n            if (!tolerant) {\n              // stop the check when there are no replicas available for a shard\n              throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n                  \"no servers hosting shard: \" + rb.slices[i]);\n            }\n          }\n        }\n        // And now recreate the | delimited list of equivalent servers\n        final StringBuilder sliceShardsStr = new StringBuilder();\n        boolean first = true;\n        for (String shardUrl : shardUrls) {\n          if (first) {\n            first = false;\n          } else {\n            sliceShardsStr.append('|');\n          }\n          sliceShardsStr.append(shardUrl);\n        }\n        rb.shards[i] = sliceShardsStr.toString();\n      }\n    }\n    String shards_rows = params.get(ShardParams.SHARDS_ROWS);\n    if(shards_rows != null) {\n      rb.shards_rows = Integer.parseInt(shards_rows);\n    }\n    String shards_start = params.get(ShardParams.SHARDS_START);\n    if(shards_start != null) {\n      rb.shards_start = Integer.parseInt(shards_start);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void prepDistributed(ResponseBuilder rb) {\n    final SolrQueryRequest req = rb.req;\n    final SolrParams params = req.getParams();\n    final String shards = params.get(ShardParams.SHARDS);\n\n    // since the cost of grabbing cloud state is still up in the air, we grab it only\n    // if we need it.\n    ClusterState clusterState = null;\n    Map<String,Slice> slices = null;\n    CoreDescriptor coreDescriptor = req.getCore().getCoreDescriptor();\n    CloudDescriptor cloudDescriptor = coreDescriptor.getCloudDescriptor();\n    ZkController zkController = coreDescriptor.getCoreContainer().getZkController();\n\n    if (params.getBool(CommonParams.PREFER_LOCAL_SHARDS, false)) {\n      rb.preferredHostAddress = (zkController != null) ? zkController.getBaseUrl() : null;\n      if (rb.preferredHostAddress == null) {\n        log.warn(\"Couldn't determine current host address to prefer local shards\");\n      }\n    }\n\n    if (shards != null) {\n      List<String> lst = StrUtils.splitSmart(shards, \",\", true);\n      rb.shards = lst.toArray(new String[lst.size()]);\n      rb.slices = new String[rb.shards.length];\n\n      if (zkController != null) {\n        // figure out which shards are slices\n        for (int i=0; i<rb.shards.length; i++) {\n          if (rb.shards[i].indexOf('/') < 0) {\n            // this is a logical shard\n            rb.slices[i] = rb.shards[i];\n            rb.shards[i] = null;\n          }\n        }\n      }\n    } else if (zkController != null) {\n      // we weren't provided with an explicit list of slices to query via \"shards\", so use the cluster state\n\n      clusterState =  zkController.getClusterState();\n      String shardKeys =  params.get(ShardParams._ROUTE_);\n\n      // This will be the complete list of slices we need to query for this request.\n      slices = new HashMap<>();\n\n      // we need to find out what collections this request is for.\n\n      // A comma-separated list of specified collections.\n      // Eg: \"collection1,collection2,collection3\"\n      String collections = params.get(\"collection\");\n      if (collections != null) {\n        // If there were one or more collections specified in the query, split\n        // each parameter and store as a separate member of a List.\n        List<String> collectionList = StrUtils.splitSmart(collections, \",\",\n            true);\n        // In turn, retrieve the slices that cover each collection from the\n        // cloud state and add them to the Map 'slices'.\n        for (String collectionName : collectionList) {\n          // The original code produced <collection-name>_<shard-name> when the collections\n          // parameter was specified (see ClientUtils.appendMap)\n          // Is this necessary if ony one collection is specified?\n          // i.e. should we change multiCollection to collectionList.size() > 1?\n          addSlices(slices, clusterState, params, collectionName,  shardKeys, true);\n        }\n      } else {\n        // just this collection\n        String collectionName = cloudDescriptor.getCollectionName();\n        addSlices(slices, clusterState, params, collectionName,  shardKeys, false);\n      }\n\n\n      // Store the logical slices in the ResponseBuilder and create a new\n      // String array to hold the physical shards (which will be mapped\n      // later).\n      rb.slices = slices.keySet().toArray(new String[slices.size()]);\n      rb.shards = new String[rb.slices.length];\n    }\n\n    //\n    // Map slices to shards\n    //\n    if (zkController != null) {\n\n      // Are we hosting the shard that this request is for, and are we active? If so, then handle it ourselves\n      // and make it a non-distributed request.\n      String ourSlice = cloudDescriptor.getShardId();\n      String ourCollection = cloudDescriptor.getCollectionName();\n      if (rb.slices.length == 1 && rb.slices[0] != null\n          && ( rb.slices[0].equals(ourSlice) || rb.slices[0].equals(ourCollection + \"_\" + ourSlice) )  // handle the <collection>_<slice> format\n          && cloudDescriptor.getLastPublished() == Replica.State.ACTIVE) {\n        boolean shortCircuit = params.getBool(\"shortCircuit\", true);       // currently just a debugging parameter to check distrib search on a single node\n\n        String targetHandler = params.get(ShardParams.SHARDS_QT);\n        shortCircuit = shortCircuit && targetHandler == null;             // if a different handler is specified, don't short-circuit\n\n        if (shortCircuit) {\n          rb.isDistrib = false;\n          rb.shortCircuitedURL = ZkCoreNodeProps.getCoreUrl(zkController.getBaseUrl(), coreDescriptor.getName());\n          return;\n        }\n        // We shouldn't need to do anything to handle \"shard.rows\" since it was previously meant to be an optimization?\n      }\n\n\n      for (int i=0; i<rb.shards.length; i++) {\n        if (rb.shards[i] == null) {\n          if (clusterState == null) {\n            clusterState =  zkController.getClusterState();\n            slices = clusterState.getSlicesMap(cloudDescriptor.getCollectionName());\n          }\n          String sliceName = rb.slices[i];\n\n          Slice slice = slices.get(sliceName);\n\n          if (slice==null) {\n            // Treat this the same as \"all servers down\" for a slice, and let things continue\n            // if partial results are acceptable\n            rb.shards[i] = \"\";\n            continue;\n            // throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"no such shard: \" + sliceName);\n          }\n\n          Map<String, Replica> sliceShards = slice.getReplicasMap();\n\n          // For now, recreate the | delimited list of equivalent servers\n          StringBuilder sliceShardsStr = new StringBuilder();\n          boolean first = true;\n          for (Replica replica : sliceShards.values()) {\n            if (!clusterState.liveNodesContain(replica.getNodeName())\n                || replica.getState() != Replica.State.ACTIVE) {\n              continue;\n            }\n            if (first) {\n              first = false;\n            } else {\n              sliceShardsStr.append('|');\n            }\n            String url = ZkCoreNodeProps.getCoreUrl(replica);\n            sliceShardsStr.append(url);\n          }\n\n          if (sliceShardsStr.length() == 0) {\n            boolean tolerant = rb.req.getParams().getBool(ShardParams.SHARDS_TOLERANT, false);\n            if (!tolerant) {\n              // stop the check when there are no replicas available for a shard\n              throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n                  \"no servers hosting shard: \" + rb.slices[i]);\n            }\n          }\n\n          rb.shards[i] = sliceShardsStr.toString();\n        }\n      }\n    }\n    String shards_rows = params.get(ShardParams.SHARDS_ROWS);\n    if(shards_rows != null) {\n      rb.shards_rows = Integer.parseInt(shards_rows);\n    }\n    String shards_start = params.get(ShardParams.SHARDS_START);\n    if(shards_start != null) {\n      rb.shards_start = Integer.parseInt(shards_start);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"199dfa410f1fdbfd3294106b04096cce5ed34b21","date":1478812506,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler#prepDistributed(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler#prepDistributed(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void prepDistributed(ResponseBuilder rb) {\n    final SolrQueryRequest req = rb.req;\n    final SolrParams params = req.getParams();\n    final String shards = params.get(ShardParams.SHARDS);\n\n    // since the cost of grabbing cloud state is still up in the air, we grab it only\n    // if we need it.\n    ClusterState clusterState = null;\n    Map<String,Slice> slices = null;\n    CoreDescriptor coreDescriptor = req.getCore().getCoreDescriptor();\n    CloudDescriptor cloudDescriptor = coreDescriptor.getCloudDescriptor();\n    ZkController zkController = coreDescriptor.getCoreContainer().getZkController();\n\n    if (params.getBool(CommonParams.PREFER_LOCAL_SHARDS, false)) {\n      rb.preferredHostAddress = (zkController != null) ? zkController.getBaseUrl() : null;\n      if (rb.preferredHostAddress == null) {\n        log.warn(\"Couldn't determine current host address to prefer local shards\");\n      }\n    }\n\n    final ReplicaListTransformer replicaListTransformer = httpShardHandlerFactory.getReplicaListTransformer(req);\n\n    if (shards != null) {\n      List<String> lst = StrUtils.splitSmart(shards, \",\", true);\n      rb.shards = lst.toArray(new String[lst.size()]);\n      rb.slices = new String[rb.shards.length];\n\n      if (zkController != null) {\n        // figure out which shards are slices\n        for (int i=0; i<rb.shards.length; i++) {\n          if (rb.shards[i].indexOf('/') < 0) {\n            // this is a logical shard\n            rb.slices[i] = rb.shards[i];\n            rb.shards[i] = null;\n          }\n        }\n      }\n    } else if (zkController != null) {\n      // we weren't provided with an explicit list of slices to query via \"shards\", so use the cluster state\n\n      clusterState =  zkController.getClusterState();\n      String shardKeys =  params.get(ShardParams._ROUTE_);\n\n      // This will be the complete list of slices we need to query for this request.\n      slices = new HashMap<>();\n\n      // we need to find out what collections this request is for.\n\n      // A comma-separated list of specified collections.\n      // Eg: \"collection1,collection2,collection3\"\n      String collections = params.get(\"collection\");\n      if (collections != null) {\n        // If there were one or more collections specified in the query, split\n        // each parameter and store as a separate member of a List.\n        List<String> collectionList = StrUtils.splitSmart(collections, \",\",\n            true);\n        // In turn, retrieve the slices that cover each collection from the\n        // cloud state and add them to the Map 'slices'.\n        for (String collectionName : collectionList) {\n          // The original code produced <collection-name>_<shard-name> when the collections\n          // parameter was specified (see ClientUtils.appendMap)\n          // Is this necessary if ony one collection is specified?\n          // i.e. should we change multiCollection to collectionList.size() > 1?\n          addSlices(slices, clusterState, params, collectionName,  shardKeys, true);\n        }\n      } else {\n        // just this collection\n        String collectionName = cloudDescriptor.getCollectionName();\n        addSlices(slices, clusterState, params, collectionName,  shardKeys, false);\n      }\n\n\n      // Store the logical slices in the ResponseBuilder and create a new\n      // String array to hold the physical shards (which will be mapped\n      // later).\n      rb.slices = slices.keySet().toArray(new String[slices.size()]);\n      rb.shards = new String[rb.slices.length];\n    }\n\n    //\n    // Map slices to shards\n    //\n    if (zkController != null) {\n\n      // Are we hosting the shard that this request is for, and are we active? If so, then handle it ourselves\n      // and make it a non-distributed request.\n      String ourSlice = cloudDescriptor.getShardId();\n      String ourCollection = cloudDescriptor.getCollectionName();\n      if (rb.slices.length == 1 && rb.slices[0] != null\n          && ( rb.slices[0].equals(ourSlice) || rb.slices[0].equals(ourCollection + \"_\" + ourSlice) )  // handle the <collection>_<slice> format\n          && cloudDescriptor.getLastPublished() == Replica.State.ACTIVE) {\n        boolean shortCircuit = params.getBool(\"shortCircuit\", true);       // currently just a debugging parameter to check distrib search on a single node\n\n        String targetHandler = params.get(ShardParams.SHARDS_QT);\n        shortCircuit = shortCircuit && targetHandler == null;             // if a different handler is specified, don't short-circuit\n\n        if (shortCircuit) {\n          rb.isDistrib = false;\n          rb.shortCircuitedURL = ZkCoreNodeProps.getCoreUrl(zkController.getBaseUrl(), coreDescriptor.getName());\n          return;\n        }\n        // We shouldn't need to do anything to handle \"shard.rows\" since it was previously meant to be an optimization?\n      }\n\n\n      for (int i=0; i<rb.shards.length; i++) {\n        final List<String> shardUrls;\n        if (rb.shards[i] != null) {\n          shardUrls = StrUtils.splitSmart(rb.shards[i], \"|\", true);\n          replicaListTransformer.transform(shardUrls);\n        } else {\n          if (clusterState == null) {\n            clusterState =  zkController.getClusterState();\n            slices = clusterState.getSlicesMap(cloudDescriptor.getCollectionName());\n          }\n          String sliceName = rb.slices[i];\n\n          Slice slice = slices.get(sliceName);\n\n          if (slice==null) {\n            // Treat this the same as \"all servers down\" for a slice, and let things continue\n            // if partial results are acceptable\n            rb.shards[i] = \"\";\n            continue;\n            // throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"no such shard: \" + sliceName);\n          }\n\n          final Collection<Replica> allSliceReplicas = slice.getReplicasMap().values();\n          final List<Replica> eligibleSliceReplicas = new ArrayList<>(allSliceReplicas.size());\n          for (Replica replica : allSliceReplicas) {\n            if (!clusterState.liveNodesContain(replica.getNodeName())\n                || replica.getState() != Replica.State.ACTIVE) {\n              continue;\n            }\n            eligibleSliceReplicas.add(replica);\n          }\n\n          replicaListTransformer.transform(eligibleSliceReplicas);\n\n          shardUrls = new ArrayList<>(eligibleSliceReplicas.size());\n          for (Replica replica : eligibleSliceReplicas) {\n            String url = ZkCoreNodeProps.getCoreUrl(replica);\n            shardUrls.add(url);\n          }\n\n          if (shardUrls.isEmpty()) {\n            boolean tolerant = rb.req.getParams().getBool(ShardParams.SHARDS_TOLERANT, false);\n            if (!tolerant) {\n              // stop the check when there are no replicas available for a shard\n              throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n                  \"no servers hosting shard: \" + rb.slices[i]);\n            }\n          }\n        }\n        // And now recreate the | delimited list of equivalent servers\n        final StringBuilder sliceShardsStr = new StringBuilder();\n        boolean first = true;\n        for (String shardUrl : shardUrls) {\n          if (first) {\n            first = false;\n          } else {\n            sliceShardsStr.append('|');\n          }\n          sliceShardsStr.append(shardUrl);\n        }\n        rb.shards[i] = sliceShardsStr.toString();\n      }\n    }\n    String shards_rows = params.get(ShardParams.SHARDS_ROWS);\n    if(shards_rows != null) {\n      rb.shards_rows = Integer.parseInt(shards_rows);\n    }\n    String shards_start = params.get(ShardParams.SHARDS_START);\n    if(shards_start != null) {\n      rb.shards_start = Integer.parseInt(shards_start);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void prepDistributed(ResponseBuilder rb) {\n    final SolrQueryRequest req = rb.req;\n    final SolrParams params = req.getParams();\n    final String shards = params.get(ShardParams.SHARDS);\n\n    // since the cost of grabbing cloud state is still up in the air, we grab it only\n    // if we need it.\n    ClusterState clusterState = null;\n    Map<String,Slice> slices = null;\n    CoreDescriptor coreDescriptor = req.getCore().getCoreDescriptor();\n    CloudDescriptor cloudDescriptor = coreDescriptor.getCloudDescriptor();\n    ZkController zkController = coreDescriptor.getCoreContainer().getZkController();\n\n    if (params.getBool(CommonParams.PREFER_LOCAL_SHARDS, false)) {\n      rb.preferredHostAddress = (zkController != null) ? zkController.getBaseUrl() : null;\n      if (rb.preferredHostAddress == null) {\n        log.warn(\"Couldn't determine current host address to prefer local shards\");\n      }\n    }\n\n    if (shards != null) {\n      List<String> lst = StrUtils.splitSmart(shards, \",\", true);\n      rb.shards = lst.toArray(new String[lst.size()]);\n      rb.slices = new String[rb.shards.length];\n\n      if (zkController != null) {\n        // figure out which shards are slices\n        for (int i=0; i<rb.shards.length; i++) {\n          if (rb.shards[i].indexOf('/') < 0) {\n            // this is a logical shard\n            rb.slices[i] = rb.shards[i];\n            rb.shards[i] = null;\n          }\n        }\n      }\n    } else if (zkController != null) {\n      // we weren't provided with an explicit list of slices to query via \"shards\", so use the cluster state\n\n      clusterState =  zkController.getClusterState();\n      String shardKeys =  params.get(ShardParams._ROUTE_);\n\n      // This will be the complete list of slices we need to query for this request.\n      slices = new HashMap<>();\n\n      // we need to find out what collections this request is for.\n\n      // A comma-separated list of specified collections.\n      // Eg: \"collection1,collection2,collection3\"\n      String collections = params.get(\"collection\");\n      if (collections != null) {\n        // If there were one or more collections specified in the query, split\n        // each parameter and store as a separate member of a List.\n        List<String> collectionList = StrUtils.splitSmart(collections, \",\",\n            true);\n        // In turn, retrieve the slices that cover each collection from the\n        // cloud state and add them to the Map 'slices'.\n        for (String collectionName : collectionList) {\n          // The original code produced <collection-name>_<shard-name> when the collections\n          // parameter was specified (see ClientUtils.appendMap)\n          // Is this necessary if ony one collection is specified?\n          // i.e. should we change multiCollection to collectionList.size() > 1?\n          addSlices(slices, clusterState, params, collectionName,  shardKeys, true);\n        }\n      } else {\n        // just this collection\n        String collectionName = cloudDescriptor.getCollectionName();\n        addSlices(slices, clusterState, params, collectionName,  shardKeys, false);\n      }\n\n\n      // Store the logical slices in the ResponseBuilder and create a new\n      // String array to hold the physical shards (which will be mapped\n      // later).\n      rb.slices = slices.keySet().toArray(new String[slices.size()]);\n      rb.shards = new String[rb.slices.length];\n    }\n\n    //\n    // Map slices to shards\n    //\n    if (zkController != null) {\n\n      // Are we hosting the shard that this request is for, and are we active? If so, then handle it ourselves\n      // and make it a non-distributed request.\n      String ourSlice = cloudDescriptor.getShardId();\n      String ourCollection = cloudDescriptor.getCollectionName();\n      if (rb.slices.length == 1 && rb.slices[0] != null\n          && ( rb.slices[0].equals(ourSlice) || rb.slices[0].equals(ourCollection + \"_\" + ourSlice) )  // handle the <collection>_<slice> format\n          && cloudDescriptor.getLastPublished() == Replica.State.ACTIVE) {\n        boolean shortCircuit = params.getBool(\"shortCircuit\", true);       // currently just a debugging parameter to check distrib search on a single node\n\n        String targetHandler = params.get(ShardParams.SHARDS_QT);\n        shortCircuit = shortCircuit && targetHandler == null;             // if a different handler is specified, don't short-circuit\n\n        if (shortCircuit) {\n          rb.isDistrib = false;\n          rb.shortCircuitedURL = ZkCoreNodeProps.getCoreUrl(zkController.getBaseUrl(), coreDescriptor.getName());\n          return;\n        }\n        // We shouldn't need to do anything to handle \"shard.rows\" since it was previously meant to be an optimization?\n      }\n\n\n      for (int i=0; i<rb.shards.length; i++) {\n        if (rb.shards[i] == null) {\n          if (clusterState == null) {\n            clusterState =  zkController.getClusterState();\n            slices = clusterState.getSlicesMap(cloudDescriptor.getCollectionName());\n          }\n          String sliceName = rb.slices[i];\n\n          Slice slice = slices.get(sliceName);\n\n          if (slice==null) {\n            // Treat this the same as \"all servers down\" for a slice, and let things continue\n            // if partial results are acceptable\n            rb.shards[i] = \"\";\n            continue;\n            // throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"no such shard: \" + sliceName);\n          }\n\n          Map<String, Replica> sliceShards = slice.getReplicasMap();\n\n          // For now, recreate the | delimited list of equivalent servers\n          StringBuilder sliceShardsStr = new StringBuilder();\n          boolean first = true;\n          for (Replica replica : sliceShards.values()) {\n            if (!clusterState.liveNodesContain(replica.getNodeName())\n                || replica.getState() != Replica.State.ACTIVE) {\n              continue;\n            }\n            if (first) {\n              first = false;\n            } else {\n              sliceShardsStr.append('|');\n            }\n            String url = ZkCoreNodeProps.getCoreUrl(replica);\n            sliceShardsStr.append(url);\n          }\n\n          if (sliceShardsStr.length() == 0) {\n            boolean tolerant = rb.req.getParams().getBool(ShardParams.SHARDS_TOLERANT, false);\n            if (!tolerant) {\n              // stop the check when there are no replicas available for a shard\n              throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n                  \"no servers hosting shard: \" + rb.slices[i]);\n            }\n          }\n\n          rb.shards[i] = sliceShardsStr.toString();\n        }\n      }\n    }\n    String shards_rows = params.get(ShardParams.SHARDS_ROWS);\n    if(shards_rows != null) {\n      rb.shards_rows = Integer.parseInt(shards_rows);\n    }\n    String shards_start = params.get(ShardParams.SHARDS_START);\n    if(shards_start != null) {\n      rb.shards_start = Integer.parseInt(shards_start);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"304ef848381e39ff6cf3e7af6127733a6f4db389","date":1482353305,"type":3,"author":"Christine Poerschke","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler#prepDistributed(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler#prepDistributed(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void prepDistributed(ResponseBuilder rb) {\n    final SolrQueryRequest req = rb.req;\n    final SolrParams params = req.getParams();\n    final String shards = params.get(ShardParams.SHARDS);\n\n    // since the cost of grabbing cloud state is still up in the air, we grab it only\n    // if we need it.\n    ClusterState clusterState = null;\n    Map<String,Slice> slices = null;\n    CoreDescriptor coreDescriptor = req.getCore().getCoreDescriptor();\n    CloudDescriptor cloudDescriptor = coreDescriptor.getCloudDescriptor();\n    ZkController zkController = coreDescriptor.getCoreContainer().getZkController();\n\n    final ReplicaListTransformer replicaListTransformer = httpShardHandlerFactory.getReplicaListTransformer(req);\n\n    if (shards != null) {\n      List<String> lst = StrUtils.splitSmart(shards, \",\", true);\n      rb.shards = lst.toArray(new String[lst.size()]);\n      rb.slices = new String[rb.shards.length];\n\n      if (zkController != null) {\n        // figure out which shards are slices\n        for (int i=0; i<rb.shards.length; i++) {\n          if (rb.shards[i].indexOf('/') < 0) {\n            // this is a logical shard\n            rb.slices[i] = rb.shards[i];\n            rb.shards[i] = null;\n          }\n        }\n      }\n    } else if (zkController != null) {\n      // we weren't provided with an explicit list of slices to query via \"shards\", so use the cluster state\n\n      clusterState =  zkController.getClusterState();\n      String shardKeys =  params.get(ShardParams._ROUTE_);\n\n      // This will be the complete list of slices we need to query for this request.\n      slices = new HashMap<>();\n\n      // we need to find out what collections this request is for.\n\n      // A comma-separated list of specified collections.\n      // Eg: \"collection1,collection2,collection3\"\n      String collections = params.get(\"collection\");\n      if (collections != null) {\n        // If there were one or more collections specified in the query, split\n        // each parameter and store as a separate member of a List.\n        List<String> collectionList = StrUtils.splitSmart(collections, \",\",\n            true);\n        // In turn, retrieve the slices that cover each collection from the\n        // cloud state and add them to the Map 'slices'.\n        for (String collectionName : collectionList) {\n          // The original code produced <collection-name>_<shard-name> when the collections\n          // parameter was specified (see ClientUtils.appendMap)\n          // Is this necessary if ony one collection is specified?\n          // i.e. should we change multiCollection to collectionList.size() > 1?\n          addSlices(slices, clusterState, params, collectionName,  shardKeys, true);\n        }\n      } else {\n        // just this collection\n        String collectionName = cloudDescriptor.getCollectionName();\n        addSlices(slices, clusterState, params, collectionName,  shardKeys, false);\n      }\n\n\n      // Store the logical slices in the ResponseBuilder and create a new\n      // String array to hold the physical shards (which will be mapped\n      // later).\n      rb.slices = slices.keySet().toArray(new String[slices.size()]);\n      rb.shards = new String[rb.slices.length];\n    }\n\n    //\n    // Map slices to shards\n    //\n    if (zkController != null) {\n\n      // Are we hosting the shard that this request is for, and are we active? If so, then handle it ourselves\n      // and make it a non-distributed request.\n      String ourSlice = cloudDescriptor.getShardId();\n      String ourCollection = cloudDescriptor.getCollectionName();\n      if (rb.slices.length == 1 && rb.slices[0] != null\n          && ( rb.slices[0].equals(ourSlice) || rb.slices[0].equals(ourCollection + \"_\" + ourSlice) )  // handle the <collection>_<slice> format\n          && cloudDescriptor.getLastPublished() == Replica.State.ACTIVE) {\n        boolean shortCircuit = params.getBool(\"shortCircuit\", true);       // currently just a debugging parameter to check distrib search on a single node\n\n        String targetHandler = params.get(ShardParams.SHARDS_QT);\n        shortCircuit = shortCircuit && targetHandler == null;             // if a different handler is specified, don't short-circuit\n\n        if (shortCircuit) {\n          rb.isDistrib = false;\n          rb.shortCircuitedURL = ZkCoreNodeProps.getCoreUrl(zkController.getBaseUrl(), coreDescriptor.getName());\n          return;\n        }\n        // We shouldn't need to do anything to handle \"shard.rows\" since it was previously meant to be an optimization?\n      }\n\n\n      for (int i=0; i<rb.shards.length; i++) {\n        final List<String> shardUrls;\n        if (rb.shards[i] != null) {\n          shardUrls = StrUtils.splitSmart(rb.shards[i], \"|\", true);\n          replicaListTransformer.transform(shardUrls);\n        } else {\n          if (clusterState == null) {\n            clusterState =  zkController.getClusterState();\n            slices = clusterState.getSlicesMap(cloudDescriptor.getCollectionName());\n          }\n          String sliceName = rb.slices[i];\n\n          Slice slice = slices.get(sliceName);\n\n          if (slice==null) {\n            // Treat this the same as \"all servers down\" for a slice, and let things continue\n            // if partial results are acceptable\n            rb.shards[i] = \"\";\n            continue;\n            // throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"no such shard: \" + sliceName);\n          }\n\n          final Collection<Replica> allSliceReplicas = slice.getReplicasMap().values();\n          final List<Replica> eligibleSliceReplicas = new ArrayList<>(allSliceReplicas.size());\n          for (Replica replica : allSliceReplicas) {\n            if (!clusterState.liveNodesContain(replica.getNodeName())\n                || replica.getState() != Replica.State.ACTIVE) {\n              continue;\n            }\n            eligibleSliceReplicas.add(replica);\n          }\n\n          replicaListTransformer.transform(eligibleSliceReplicas);\n\n          shardUrls = new ArrayList<>(eligibleSliceReplicas.size());\n          for (Replica replica : eligibleSliceReplicas) {\n            String url = ZkCoreNodeProps.getCoreUrl(replica);\n            shardUrls.add(url);\n          }\n\n          if (shardUrls.isEmpty()) {\n            boolean tolerant = rb.req.getParams().getBool(ShardParams.SHARDS_TOLERANT, false);\n            if (!tolerant) {\n              // stop the check when there are no replicas available for a shard\n              throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n                  \"no servers hosting shard: \" + rb.slices[i]);\n            }\n          }\n        }\n        // And now recreate the | delimited list of equivalent servers\n        final StringBuilder sliceShardsStr = new StringBuilder();\n        boolean first = true;\n        for (String shardUrl : shardUrls) {\n          if (first) {\n            first = false;\n          } else {\n            sliceShardsStr.append('|');\n          }\n          sliceShardsStr.append(shardUrl);\n        }\n        rb.shards[i] = sliceShardsStr.toString();\n      }\n    }\n    String shards_rows = params.get(ShardParams.SHARDS_ROWS);\n    if(shards_rows != null) {\n      rb.shards_rows = Integer.parseInt(shards_rows);\n    }\n    String shards_start = params.get(ShardParams.SHARDS_START);\n    if(shards_start != null) {\n      rb.shards_start = Integer.parseInt(shards_start);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void prepDistributed(ResponseBuilder rb) {\n    final SolrQueryRequest req = rb.req;\n    final SolrParams params = req.getParams();\n    final String shards = params.get(ShardParams.SHARDS);\n\n    // since the cost of grabbing cloud state is still up in the air, we grab it only\n    // if we need it.\n    ClusterState clusterState = null;\n    Map<String,Slice> slices = null;\n    CoreDescriptor coreDescriptor = req.getCore().getCoreDescriptor();\n    CloudDescriptor cloudDescriptor = coreDescriptor.getCloudDescriptor();\n    ZkController zkController = coreDescriptor.getCoreContainer().getZkController();\n\n    if (params.getBool(CommonParams.PREFER_LOCAL_SHARDS, false)) {\n      rb.preferredHostAddress = (zkController != null) ? zkController.getBaseUrl() : null;\n      if (rb.preferredHostAddress == null) {\n        log.warn(\"Couldn't determine current host address to prefer local shards\");\n      }\n    }\n\n    final ReplicaListTransformer replicaListTransformer = httpShardHandlerFactory.getReplicaListTransformer(req);\n\n    if (shards != null) {\n      List<String> lst = StrUtils.splitSmart(shards, \",\", true);\n      rb.shards = lst.toArray(new String[lst.size()]);\n      rb.slices = new String[rb.shards.length];\n\n      if (zkController != null) {\n        // figure out which shards are slices\n        for (int i=0; i<rb.shards.length; i++) {\n          if (rb.shards[i].indexOf('/') < 0) {\n            // this is a logical shard\n            rb.slices[i] = rb.shards[i];\n            rb.shards[i] = null;\n          }\n        }\n      }\n    } else if (zkController != null) {\n      // we weren't provided with an explicit list of slices to query via \"shards\", so use the cluster state\n\n      clusterState =  zkController.getClusterState();\n      String shardKeys =  params.get(ShardParams._ROUTE_);\n\n      // This will be the complete list of slices we need to query for this request.\n      slices = new HashMap<>();\n\n      // we need to find out what collections this request is for.\n\n      // A comma-separated list of specified collections.\n      // Eg: \"collection1,collection2,collection3\"\n      String collections = params.get(\"collection\");\n      if (collections != null) {\n        // If there were one or more collections specified in the query, split\n        // each parameter and store as a separate member of a List.\n        List<String> collectionList = StrUtils.splitSmart(collections, \",\",\n            true);\n        // In turn, retrieve the slices that cover each collection from the\n        // cloud state and add them to the Map 'slices'.\n        for (String collectionName : collectionList) {\n          // The original code produced <collection-name>_<shard-name> when the collections\n          // parameter was specified (see ClientUtils.appendMap)\n          // Is this necessary if ony one collection is specified?\n          // i.e. should we change multiCollection to collectionList.size() > 1?\n          addSlices(slices, clusterState, params, collectionName,  shardKeys, true);\n        }\n      } else {\n        // just this collection\n        String collectionName = cloudDescriptor.getCollectionName();\n        addSlices(slices, clusterState, params, collectionName,  shardKeys, false);\n      }\n\n\n      // Store the logical slices in the ResponseBuilder and create a new\n      // String array to hold the physical shards (which will be mapped\n      // later).\n      rb.slices = slices.keySet().toArray(new String[slices.size()]);\n      rb.shards = new String[rb.slices.length];\n    }\n\n    //\n    // Map slices to shards\n    //\n    if (zkController != null) {\n\n      // Are we hosting the shard that this request is for, and are we active? If so, then handle it ourselves\n      // and make it a non-distributed request.\n      String ourSlice = cloudDescriptor.getShardId();\n      String ourCollection = cloudDescriptor.getCollectionName();\n      if (rb.slices.length == 1 && rb.slices[0] != null\n          && ( rb.slices[0].equals(ourSlice) || rb.slices[0].equals(ourCollection + \"_\" + ourSlice) )  // handle the <collection>_<slice> format\n          && cloudDescriptor.getLastPublished() == Replica.State.ACTIVE) {\n        boolean shortCircuit = params.getBool(\"shortCircuit\", true);       // currently just a debugging parameter to check distrib search on a single node\n\n        String targetHandler = params.get(ShardParams.SHARDS_QT);\n        shortCircuit = shortCircuit && targetHandler == null;             // if a different handler is specified, don't short-circuit\n\n        if (shortCircuit) {\n          rb.isDistrib = false;\n          rb.shortCircuitedURL = ZkCoreNodeProps.getCoreUrl(zkController.getBaseUrl(), coreDescriptor.getName());\n          return;\n        }\n        // We shouldn't need to do anything to handle \"shard.rows\" since it was previously meant to be an optimization?\n      }\n\n\n      for (int i=0; i<rb.shards.length; i++) {\n        final List<String> shardUrls;\n        if (rb.shards[i] != null) {\n          shardUrls = StrUtils.splitSmart(rb.shards[i], \"|\", true);\n          replicaListTransformer.transform(shardUrls);\n        } else {\n          if (clusterState == null) {\n            clusterState =  zkController.getClusterState();\n            slices = clusterState.getSlicesMap(cloudDescriptor.getCollectionName());\n          }\n          String sliceName = rb.slices[i];\n\n          Slice slice = slices.get(sliceName);\n\n          if (slice==null) {\n            // Treat this the same as \"all servers down\" for a slice, and let things continue\n            // if partial results are acceptable\n            rb.shards[i] = \"\";\n            continue;\n            // throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"no such shard: \" + sliceName);\n          }\n\n          final Collection<Replica> allSliceReplicas = slice.getReplicasMap().values();\n          final List<Replica> eligibleSliceReplicas = new ArrayList<>(allSliceReplicas.size());\n          for (Replica replica : allSliceReplicas) {\n            if (!clusterState.liveNodesContain(replica.getNodeName())\n                || replica.getState() != Replica.State.ACTIVE) {\n              continue;\n            }\n            eligibleSliceReplicas.add(replica);\n          }\n\n          replicaListTransformer.transform(eligibleSliceReplicas);\n\n          shardUrls = new ArrayList<>(eligibleSliceReplicas.size());\n          for (Replica replica : eligibleSliceReplicas) {\n            String url = ZkCoreNodeProps.getCoreUrl(replica);\n            shardUrls.add(url);\n          }\n\n          if (shardUrls.isEmpty()) {\n            boolean tolerant = rb.req.getParams().getBool(ShardParams.SHARDS_TOLERANT, false);\n            if (!tolerant) {\n              // stop the check when there are no replicas available for a shard\n              throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n                  \"no servers hosting shard: \" + rb.slices[i]);\n            }\n          }\n        }\n        // And now recreate the | delimited list of equivalent servers\n        final StringBuilder sliceShardsStr = new StringBuilder();\n        boolean first = true;\n        for (String shardUrl : shardUrls) {\n          if (first) {\n            first = false;\n          } else {\n            sliceShardsStr.append('|');\n          }\n          sliceShardsStr.append(shardUrl);\n        }\n        rb.shards[i] = sliceShardsStr.toString();\n      }\n    }\n    String shards_rows = params.get(ShardParams.SHARDS_ROWS);\n    if(shards_rows != null) {\n      rb.shards_rows = Integer.parseInt(shards_rows);\n    }\n    String shards_start = params.get(ShardParams.SHARDS_START);\n    if(shards_start != null) {\n      rb.shards_start = Integer.parseInt(shards_start);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f03e4bed5023ec3ef93a771b8888cae991cf448d","date":1483469262,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler#prepDistributed(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler#prepDistributed(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void prepDistributed(ResponseBuilder rb) {\n    final SolrQueryRequest req = rb.req;\n    final SolrParams params = req.getParams();\n    final String shards = params.get(ShardParams.SHARDS);\n\n    // since the cost of grabbing cloud state is still up in the air, we grab it only\n    // if we need it.\n    ClusterState clusterState = null;\n    Map<String,Slice> slices = null;\n    CoreDescriptor coreDescriptor = req.getCore().getCoreDescriptor();\n    CloudDescriptor cloudDescriptor = coreDescriptor.getCloudDescriptor();\n    ZkController zkController = coreDescriptor.getCoreContainer().getZkController();\n\n    final ReplicaListTransformer replicaListTransformer = httpShardHandlerFactory.getReplicaListTransformer(req);\n\n    if (shards != null) {\n      List<String> lst = StrUtils.splitSmart(shards, \",\", true);\n      rb.shards = lst.toArray(new String[lst.size()]);\n      rb.slices = new String[rb.shards.length];\n\n      if (zkController != null) {\n        // figure out which shards are slices\n        for (int i=0; i<rb.shards.length; i++) {\n          if (rb.shards[i].indexOf('/') < 0) {\n            // this is a logical shard\n            rb.slices[i] = rb.shards[i];\n            rb.shards[i] = null;\n          }\n        }\n      }\n    } else if (zkController != null) {\n      // we weren't provided with an explicit list of slices to query via \"shards\", so use the cluster state\n\n      clusterState =  zkController.getClusterState();\n      String shardKeys =  params.get(ShardParams._ROUTE_);\n\n      // This will be the complete list of slices we need to query for this request.\n      slices = new HashMap<>();\n\n      // we need to find out what collections this request is for.\n\n      // A comma-separated list of specified collections.\n      // Eg: \"collection1,collection2,collection3\"\n      String collections = params.get(\"collection\");\n      if (collections != null) {\n        // If there were one or more collections specified in the query, split\n        // each parameter and store as a separate member of a List.\n        List<String> collectionList = StrUtils.splitSmart(collections, \",\",\n            true);\n        // In turn, retrieve the slices that cover each collection from the\n        // cloud state and add them to the Map 'slices'.\n        for (String collectionName : collectionList) {\n          // The original code produced <collection-name>_<shard-name> when the collections\n          // parameter was specified (see ClientUtils.appendMap)\n          // Is this necessary if ony one collection is specified?\n          // i.e. should we change multiCollection to collectionList.size() > 1?\n          addSlices(slices, clusterState, params, collectionName,  shardKeys, true);\n        }\n      } else {\n        // just this collection\n        String collectionName = cloudDescriptor.getCollectionName();\n        addSlices(slices, clusterState, params, collectionName,  shardKeys, false);\n      }\n\n\n      // Store the logical slices in the ResponseBuilder and create a new\n      // String array to hold the physical shards (which will be mapped\n      // later).\n      rb.slices = slices.keySet().toArray(new String[slices.size()]);\n      rb.shards = new String[rb.slices.length];\n    }\n\n    //\n    // Map slices to shards\n    //\n    if (zkController != null) {\n\n      // Are we hosting the shard that this request is for, and are we active? If so, then handle it ourselves\n      // and make it a non-distributed request.\n      String ourSlice = cloudDescriptor.getShardId();\n      String ourCollection = cloudDescriptor.getCollectionName();\n      if (rb.slices.length == 1 && rb.slices[0] != null\n          && ( rb.slices[0].equals(ourSlice) || rb.slices[0].equals(ourCollection + \"_\" + ourSlice) )  // handle the <collection>_<slice> format\n          && cloudDescriptor.getLastPublished() == Replica.State.ACTIVE) {\n        boolean shortCircuit = params.getBool(\"shortCircuit\", true);       // currently just a debugging parameter to check distrib search on a single node\n\n        String targetHandler = params.get(ShardParams.SHARDS_QT);\n        shortCircuit = shortCircuit && targetHandler == null;             // if a different handler is specified, don't short-circuit\n\n        if (shortCircuit) {\n          rb.isDistrib = false;\n          rb.shortCircuitedURL = ZkCoreNodeProps.getCoreUrl(zkController.getBaseUrl(), coreDescriptor.getName());\n          return;\n        }\n        // We shouldn't need to do anything to handle \"shard.rows\" since it was previously meant to be an optimization?\n      }\n\n\n      for (int i=0; i<rb.shards.length; i++) {\n        final List<String> shardUrls;\n        if (rb.shards[i] != null) {\n          shardUrls = StrUtils.splitSmart(rb.shards[i], \"|\", true);\n          replicaListTransformer.transform(shardUrls);\n        } else {\n          if (clusterState == null) {\n            clusterState =  zkController.getClusterState();\n            slices = clusterState.getSlicesMap(cloudDescriptor.getCollectionName());\n          }\n          String sliceName = rb.slices[i];\n\n          Slice slice = slices.get(sliceName);\n\n          if (slice==null) {\n            // Treat this the same as \"all servers down\" for a slice, and let things continue\n            // if partial results are acceptable\n            rb.shards[i] = \"\";\n            continue;\n            // throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"no such shard: \" + sliceName);\n          }\n\n          final Collection<Replica> allSliceReplicas = slice.getReplicasMap().values();\n          final List<Replica> eligibleSliceReplicas = new ArrayList<>(allSliceReplicas.size());\n          for (Replica replica : allSliceReplicas) {\n            if (!clusterState.liveNodesContain(replica.getNodeName())\n                || replica.getState() != Replica.State.ACTIVE) {\n              continue;\n            }\n            eligibleSliceReplicas.add(replica);\n          }\n\n          replicaListTransformer.transform(eligibleSliceReplicas);\n\n          shardUrls = new ArrayList<>(eligibleSliceReplicas.size());\n          for (Replica replica : eligibleSliceReplicas) {\n            String url = ZkCoreNodeProps.getCoreUrl(replica);\n            shardUrls.add(url);\n          }\n\n          if (shardUrls.isEmpty()) {\n            boolean tolerant = rb.req.getParams().getBool(ShardParams.SHARDS_TOLERANT, false);\n            if (!tolerant) {\n              // stop the check when there are no replicas available for a shard\n              throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n                  \"no servers hosting shard: \" + rb.slices[i]);\n            }\n          }\n        }\n        // And now recreate the | delimited list of equivalent servers\n        final StringBuilder sliceShardsStr = new StringBuilder();\n        boolean first = true;\n        for (String shardUrl : shardUrls) {\n          if (first) {\n            first = false;\n          } else {\n            sliceShardsStr.append('|');\n          }\n          sliceShardsStr.append(shardUrl);\n        }\n        rb.shards[i] = sliceShardsStr.toString();\n      }\n    }\n    String shards_rows = params.get(ShardParams.SHARDS_ROWS);\n    if(shards_rows != null) {\n      rb.shards_rows = Integer.parseInt(shards_rows);\n    }\n    String shards_start = params.get(ShardParams.SHARDS_START);\n    if(shards_start != null) {\n      rb.shards_start = Integer.parseInt(shards_start);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void prepDistributed(ResponseBuilder rb) {\n    final SolrQueryRequest req = rb.req;\n    final SolrParams params = req.getParams();\n    final String shards = params.get(ShardParams.SHARDS);\n\n    // since the cost of grabbing cloud state is still up in the air, we grab it only\n    // if we need it.\n    ClusterState clusterState = null;\n    Map<String,Slice> slices = null;\n    CoreDescriptor coreDescriptor = req.getCore().getCoreDescriptor();\n    CloudDescriptor cloudDescriptor = coreDescriptor.getCloudDescriptor();\n    ZkController zkController = coreDescriptor.getCoreContainer().getZkController();\n\n    if (params.getBool(CommonParams.PREFER_LOCAL_SHARDS, false)) {\n      rb.preferredHostAddress = (zkController != null) ? zkController.getBaseUrl() : null;\n      if (rb.preferredHostAddress == null) {\n        log.warn(\"Couldn't determine current host address to prefer local shards\");\n      }\n    }\n\n    final ReplicaListTransformer replicaListTransformer = httpShardHandlerFactory.getReplicaListTransformer(req);\n\n    if (shards != null) {\n      List<String> lst = StrUtils.splitSmart(shards, \",\", true);\n      rb.shards = lst.toArray(new String[lst.size()]);\n      rb.slices = new String[rb.shards.length];\n\n      if (zkController != null) {\n        // figure out which shards are slices\n        for (int i=0; i<rb.shards.length; i++) {\n          if (rb.shards[i].indexOf('/') < 0) {\n            // this is a logical shard\n            rb.slices[i] = rb.shards[i];\n            rb.shards[i] = null;\n          }\n        }\n      }\n    } else if (zkController != null) {\n      // we weren't provided with an explicit list of slices to query via \"shards\", so use the cluster state\n\n      clusterState =  zkController.getClusterState();\n      String shardKeys =  params.get(ShardParams._ROUTE_);\n\n      // This will be the complete list of slices we need to query for this request.\n      slices = new HashMap<>();\n\n      // we need to find out what collections this request is for.\n\n      // A comma-separated list of specified collections.\n      // Eg: \"collection1,collection2,collection3\"\n      String collections = params.get(\"collection\");\n      if (collections != null) {\n        // If there were one or more collections specified in the query, split\n        // each parameter and store as a separate member of a List.\n        List<String> collectionList = StrUtils.splitSmart(collections, \",\",\n            true);\n        // In turn, retrieve the slices that cover each collection from the\n        // cloud state and add them to the Map 'slices'.\n        for (String collectionName : collectionList) {\n          // The original code produced <collection-name>_<shard-name> when the collections\n          // parameter was specified (see ClientUtils.appendMap)\n          // Is this necessary if ony one collection is specified?\n          // i.e. should we change multiCollection to collectionList.size() > 1?\n          addSlices(slices, clusterState, params, collectionName,  shardKeys, true);\n        }\n      } else {\n        // just this collection\n        String collectionName = cloudDescriptor.getCollectionName();\n        addSlices(slices, clusterState, params, collectionName,  shardKeys, false);\n      }\n\n\n      // Store the logical slices in the ResponseBuilder and create a new\n      // String array to hold the physical shards (which will be mapped\n      // later).\n      rb.slices = slices.keySet().toArray(new String[slices.size()]);\n      rb.shards = new String[rb.slices.length];\n    }\n\n    //\n    // Map slices to shards\n    //\n    if (zkController != null) {\n\n      // Are we hosting the shard that this request is for, and are we active? If so, then handle it ourselves\n      // and make it a non-distributed request.\n      String ourSlice = cloudDescriptor.getShardId();\n      String ourCollection = cloudDescriptor.getCollectionName();\n      if (rb.slices.length == 1 && rb.slices[0] != null\n          && ( rb.slices[0].equals(ourSlice) || rb.slices[0].equals(ourCollection + \"_\" + ourSlice) )  // handle the <collection>_<slice> format\n          && cloudDescriptor.getLastPublished() == Replica.State.ACTIVE) {\n        boolean shortCircuit = params.getBool(\"shortCircuit\", true);       // currently just a debugging parameter to check distrib search on a single node\n\n        String targetHandler = params.get(ShardParams.SHARDS_QT);\n        shortCircuit = shortCircuit && targetHandler == null;             // if a different handler is specified, don't short-circuit\n\n        if (shortCircuit) {\n          rb.isDistrib = false;\n          rb.shortCircuitedURL = ZkCoreNodeProps.getCoreUrl(zkController.getBaseUrl(), coreDescriptor.getName());\n          return;\n        }\n        // We shouldn't need to do anything to handle \"shard.rows\" since it was previously meant to be an optimization?\n      }\n\n\n      for (int i=0; i<rb.shards.length; i++) {\n        final List<String> shardUrls;\n        if (rb.shards[i] != null) {\n          shardUrls = StrUtils.splitSmart(rb.shards[i], \"|\", true);\n          replicaListTransformer.transform(shardUrls);\n        } else {\n          if (clusterState == null) {\n            clusterState =  zkController.getClusterState();\n            slices = clusterState.getSlicesMap(cloudDescriptor.getCollectionName());\n          }\n          String sliceName = rb.slices[i];\n\n          Slice slice = slices.get(sliceName);\n\n          if (slice==null) {\n            // Treat this the same as \"all servers down\" for a slice, and let things continue\n            // if partial results are acceptable\n            rb.shards[i] = \"\";\n            continue;\n            // throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"no such shard: \" + sliceName);\n          }\n\n          final Collection<Replica> allSliceReplicas = slice.getReplicasMap().values();\n          final List<Replica> eligibleSliceReplicas = new ArrayList<>(allSliceReplicas.size());\n          for (Replica replica : allSliceReplicas) {\n            if (!clusterState.liveNodesContain(replica.getNodeName())\n                || replica.getState() != Replica.State.ACTIVE) {\n              continue;\n            }\n            eligibleSliceReplicas.add(replica);\n          }\n\n          replicaListTransformer.transform(eligibleSliceReplicas);\n\n          shardUrls = new ArrayList<>(eligibleSliceReplicas.size());\n          for (Replica replica : eligibleSliceReplicas) {\n            String url = ZkCoreNodeProps.getCoreUrl(replica);\n            shardUrls.add(url);\n          }\n\n          if (shardUrls.isEmpty()) {\n            boolean tolerant = rb.req.getParams().getBool(ShardParams.SHARDS_TOLERANT, false);\n            if (!tolerant) {\n              // stop the check when there are no replicas available for a shard\n              throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n                  \"no servers hosting shard: \" + rb.slices[i]);\n            }\n          }\n        }\n        // And now recreate the | delimited list of equivalent servers\n        final StringBuilder sliceShardsStr = new StringBuilder();\n        boolean first = true;\n        for (String shardUrl : shardUrls) {\n          if (first) {\n            first = false;\n          } else {\n            sliceShardsStr.append('|');\n          }\n          sliceShardsStr.append(shardUrl);\n        }\n        rb.shards[i] = sliceShardsStr.toString();\n      }\n    }\n    String shards_rows = params.get(ShardParams.SHARDS_ROWS);\n    if(shards_rows != null) {\n      rb.shards_rows = Integer.parseInt(shards_rows);\n    }\n    String shards_start = params.get(ShardParams.SHARDS_START);\n    if(shards_start != null) {\n      rb.shards_start = Integer.parseInt(shards_start);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"729cb470f975115d4c60517b2cb7c42e37a7a2e1","date":1492041760,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler#prepDistributed(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler#prepDistributed(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void prepDistributed(ResponseBuilder rb) {\n    final SolrQueryRequest req = rb.req;\n    final SolrParams params = req.getParams();\n    final String shards = params.get(ShardParams.SHARDS);\n\n    // since the cost of grabbing cloud state is still up in the air, we grab it only\n    // if we need it.\n    ClusterState clusterState = null;\n    Map<String,Slice> slices = null;\n    CoreDescriptor coreDescriptor = req.getCore().getCoreDescriptor();\n    CloudDescriptor cloudDescriptor = coreDescriptor.getCloudDescriptor();\n    ZkController zkController = req.getCore().getCoreContainer().getZkController();\n\n    final ReplicaListTransformer replicaListTransformer = httpShardHandlerFactory.getReplicaListTransformer(req);\n\n    if (shards != null) {\n      List<String> lst = StrUtils.splitSmart(shards, \",\", true);\n      rb.shards = lst.toArray(new String[lst.size()]);\n      rb.slices = new String[rb.shards.length];\n\n      if (zkController != null) {\n        // figure out which shards are slices\n        for (int i=0; i<rb.shards.length; i++) {\n          if (rb.shards[i].indexOf('/') < 0) {\n            // this is a logical shard\n            rb.slices[i] = rb.shards[i];\n            rb.shards[i] = null;\n          }\n        }\n      }\n    } else if (zkController != null) {\n      // we weren't provided with an explicit list of slices to query via \"shards\", so use the cluster state\n\n      clusterState =  zkController.getClusterState();\n      String shardKeys =  params.get(ShardParams._ROUTE_);\n\n      // This will be the complete list of slices we need to query for this request.\n      slices = new HashMap<>();\n\n      // we need to find out what collections this request is for.\n\n      // A comma-separated list of specified collections.\n      // Eg: \"collection1,collection2,collection3\"\n      String collections = params.get(\"collection\");\n      if (collections != null) {\n        // If there were one or more collections specified in the query, split\n        // each parameter and store as a separate member of a List.\n        List<String> collectionList = StrUtils.splitSmart(collections, \",\",\n            true);\n        // In turn, retrieve the slices that cover each collection from the\n        // cloud state and add them to the Map 'slices'.\n        for (String collectionName : collectionList) {\n          // The original code produced <collection-name>_<shard-name> when the collections\n          // parameter was specified (see ClientUtils.appendMap)\n          // Is this necessary if ony one collection is specified?\n          // i.e. should we change multiCollection to collectionList.size() > 1?\n          addSlices(slices, clusterState, params, collectionName,  shardKeys, true);\n        }\n      } else {\n        // just this collection\n        String collectionName = cloudDescriptor.getCollectionName();\n        addSlices(slices, clusterState, params, collectionName,  shardKeys, false);\n      }\n\n\n      // Store the logical slices in the ResponseBuilder and create a new\n      // String array to hold the physical shards (which will be mapped\n      // later).\n      rb.slices = slices.keySet().toArray(new String[slices.size()]);\n      rb.shards = new String[rb.slices.length];\n    }\n\n    //\n    // Map slices to shards\n    //\n    if (zkController != null) {\n\n      // Are we hosting the shard that this request is for, and are we active? If so, then handle it ourselves\n      // and make it a non-distributed request.\n      String ourSlice = cloudDescriptor.getShardId();\n      String ourCollection = cloudDescriptor.getCollectionName();\n      if (rb.slices.length == 1 && rb.slices[0] != null\n          && ( rb.slices[0].equals(ourSlice) || rb.slices[0].equals(ourCollection + \"_\" + ourSlice) )  // handle the <collection>_<slice> format\n          && cloudDescriptor.getLastPublished() == Replica.State.ACTIVE) {\n        boolean shortCircuit = params.getBool(\"shortCircuit\", true);       // currently just a debugging parameter to check distrib search on a single node\n\n        String targetHandler = params.get(ShardParams.SHARDS_QT);\n        shortCircuit = shortCircuit && targetHandler == null;             // if a different handler is specified, don't short-circuit\n\n        if (shortCircuit) {\n          rb.isDistrib = false;\n          rb.shortCircuitedURL = ZkCoreNodeProps.getCoreUrl(zkController.getBaseUrl(), coreDescriptor.getName());\n          return;\n        }\n        // We shouldn't need to do anything to handle \"shard.rows\" since it was previously meant to be an optimization?\n      }\n\n\n      for (int i=0; i<rb.shards.length; i++) {\n        final List<String> shardUrls;\n        if (rb.shards[i] != null) {\n          shardUrls = StrUtils.splitSmart(rb.shards[i], \"|\", true);\n          replicaListTransformer.transform(shardUrls);\n        } else {\n          if (clusterState == null) {\n            clusterState =  zkController.getClusterState();\n            slices = clusterState.getSlicesMap(cloudDescriptor.getCollectionName());\n          }\n          String sliceName = rb.slices[i];\n\n          Slice slice = slices.get(sliceName);\n\n          if (slice==null) {\n            // Treat this the same as \"all servers down\" for a slice, and let things continue\n            // if partial results are acceptable\n            rb.shards[i] = \"\";\n            continue;\n            // throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"no such shard: \" + sliceName);\n          }\n\n          final Collection<Replica> allSliceReplicas = slice.getReplicasMap().values();\n          final List<Replica> eligibleSliceReplicas = new ArrayList<>(allSliceReplicas.size());\n          for (Replica replica : allSliceReplicas) {\n            if (!clusterState.liveNodesContain(replica.getNodeName())\n                || replica.getState() != Replica.State.ACTIVE) {\n              continue;\n            }\n            eligibleSliceReplicas.add(replica);\n          }\n\n          replicaListTransformer.transform(eligibleSliceReplicas);\n\n          shardUrls = new ArrayList<>(eligibleSliceReplicas.size());\n          for (Replica replica : eligibleSliceReplicas) {\n            String url = ZkCoreNodeProps.getCoreUrl(replica);\n            shardUrls.add(url);\n          }\n\n          if (shardUrls.isEmpty()) {\n            boolean tolerant = rb.req.getParams().getBool(ShardParams.SHARDS_TOLERANT, false);\n            if (!tolerant) {\n              // stop the check when there are no replicas available for a shard\n              throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n                  \"no servers hosting shard: \" + rb.slices[i]);\n            }\n          }\n        }\n        // And now recreate the | delimited list of equivalent servers\n        final StringBuilder sliceShardsStr = new StringBuilder();\n        boolean first = true;\n        for (String shardUrl : shardUrls) {\n          if (first) {\n            first = false;\n          } else {\n            sliceShardsStr.append('|');\n          }\n          sliceShardsStr.append(shardUrl);\n        }\n        rb.shards[i] = sliceShardsStr.toString();\n      }\n    }\n    String shards_rows = params.get(ShardParams.SHARDS_ROWS);\n    if(shards_rows != null) {\n      rb.shards_rows = Integer.parseInt(shards_rows);\n    }\n    String shards_start = params.get(ShardParams.SHARDS_START);\n    if(shards_start != null) {\n      rb.shards_start = Integer.parseInt(shards_start);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void prepDistributed(ResponseBuilder rb) {\n    final SolrQueryRequest req = rb.req;\n    final SolrParams params = req.getParams();\n    final String shards = params.get(ShardParams.SHARDS);\n\n    // since the cost of grabbing cloud state is still up in the air, we grab it only\n    // if we need it.\n    ClusterState clusterState = null;\n    Map<String,Slice> slices = null;\n    CoreDescriptor coreDescriptor = req.getCore().getCoreDescriptor();\n    CloudDescriptor cloudDescriptor = coreDescriptor.getCloudDescriptor();\n    ZkController zkController = coreDescriptor.getCoreContainer().getZkController();\n\n    final ReplicaListTransformer replicaListTransformer = httpShardHandlerFactory.getReplicaListTransformer(req);\n\n    if (shards != null) {\n      List<String> lst = StrUtils.splitSmart(shards, \",\", true);\n      rb.shards = lst.toArray(new String[lst.size()]);\n      rb.slices = new String[rb.shards.length];\n\n      if (zkController != null) {\n        // figure out which shards are slices\n        for (int i=0; i<rb.shards.length; i++) {\n          if (rb.shards[i].indexOf('/') < 0) {\n            // this is a logical shard\n            rb.slices[i] = rb.shards[i];\n            rb.shards[i] = null;\n          }\n        }\n      }\n    } else if (zkController != null) {\n      // we weren't provided with an explicit list of slices to query via \"shards\", so use the cluster state\n\n      clusterState =  zkController.getClusterState();\n      String shardKeys =  params.get(ShardParams._ROUTE_);\n\n      // This will be the complete list of slices we need to query for this request.\n      slices = new HashMap<>();\n\n      // we need to find out what collections this request is for.\n\n      // A comma-separated list of specified collections.\n      // Eg: \"collection1,collection2,collection3\"\n      String collections = params.get(\"collection\");\n      if (collections != null) {\n        // If there were one or more collections specified in the query, split\n        // each parameter and store as a separate member of a List.\n        List<String> collectionList = StrUtils.splitSmart(collections, \",\",\n            true);\n        // In turn, retrieve the slices that cover each collection from the\n        // cloud state and add them to the Map 'slices'.\n        for (String collectionName : collectionList) {\n          // The original code produced <collection-name>_<shard-name> when the collections\n          // parameter was specified (see ClientUtils.appendMap)\n          // Is this necessary if ony one collection is specified?\n          // i.e. should we change multiCollection to collectionList.size() > 1?\n          addSlices(slices, clusterState, params, collectionName,  shardKeys, true);\n        }\n      } else {\n        // just this collection\n        String collectionName = cloudDescriptor.getCollectionName();\n        addSlices(slices, clusterState, params, collectionName,  shardKeys, false);\n      }\n\n\n      // Store the logical slices in the ResponseBuilder and create a new\n      // String array to hold the physical shards (which will be mapped\n      // later).\n      rb.slices = slices.keySet().toArray(new String[slices.size()]);\n      rb.shards = new String[rb.slices.length];\n    }\n\n    //\n    // Map slices to shards\n    //\n    if (zkController != null) {\n\n      // Are we hosting the shard that this request is for, and are we active? If so, then handle it ourselves\n      // and make it a non-distributed request.\n      String ourSlice = cloudDescriptor.getShardId();\n      String ourCollection = cloudDescriptor.getCollectionName();\n      if (rb.slices.length == 1 && rb.slices[0] != null\n          && ( rb.slices[0].equals(ourSlice) || rb.slices[0].equals(ourCollection + \"_\" + ourSlice) )  // handle the <collection>_<slice> format\n          && cloudDescriptor.getLastPublished() == Replica.State.ACTIVE) {\n        boolean shortCircuit = params.getBool(\"shortCircuit\", true);       // currently just a debugging parameter to check distrib search on a single node\n\n        String targetHandler = params.get(ShardParams.SHARDS_QT);\n        shortCircuit = shortCircuit && targetHandler == null;             // if a different handler is specified, don't short-circuit\n\n        if (shortCircuit) {\n          rb.isDistrib = false;\n          rb.shortCircuitedURL = ZkCoreNodeProps.getCoreUrl(zkController.getBaseUrl(), coreDescriptor.getName());\n          return;\n        }\n        // We shouldn't need to do anything to handle \"shard.rows\" since it was previously meant to be an optimization?\n      }\n\n\n      for (int i=0; i<rb.shards.length; i++) {\n        final List<String> shardUrls;\n        if (rb.shards[i] != null) {\n          shardUrls = StrUtils.splitSmart(rb.shards[i], \"|\", true);\n          replicaListTransformer.transform(shardUrls);\n        } else {\n          if (clusterState == null) {\n            clusterState =  zkController.getClusterState();\n            slices = clusterState.getSlicesMap(cloudDescriptor.getCollectionName());\n          }\n          String sliceName = rb.slices[i];\n\n          Slice slice = slices.get(sliceName);\n\n          if (slice==null) {\n            // Treat this the same as \"all servers down\" for a slice, and let things continue\n            // if partial results are acceptable\n            rb.shards[i] = \"\";\n            continue;\n            // throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"no such shard: \" + sliceName);\n          }\n\n          final Collection<Replica> allSliceReplicas = slice.getReplicasMap().values();\n          final List<Replica> eligibleSliceReplicas = new ArrayList<>(allSliceReplicas.size());\n          for (Replica replica : allSliceReplicas) {\n            if (!clusterState.liveNodesContain(replica.getNodeName())\n                || replica.getState() != Replica.State.ACTIVE) {\n              continue;\n            }\n            eligibleSliceReplicas.add(replica);\n          }\n\n          replicaListTransformer.transform(eligibleSliceReplicas);\n\n          shardUrls = new ArrayList<>(eligibleSliceReplicas.size());\n          for (Replica replica : eligibleSliceReplicas) {\n            String url = ZkCoreNodeProps.getCoreUrl(replica);\n            shardUrls.add(url);\n          }\n\n          if (shardUrls.isEmpty()) {\n            boolean tolerant = rb.req.getParams().getBool(ShardParams.SHARDS_TOLERANT, false);\n            if (!tolerant) {\n              // stop the check when there are no replicas available for a shard\n              throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n                  \"no servers hosting shard: \" + rb.slices[i]);\n            }\n          }\n        }\n        // And now recreate the | delimited list of equivalent servers\n        final StringBuilder sliceShardsStr = new StringBuilder();\n        boolean first = true;\n        for (String shardUrl : shardUrls) {\n          if (first) {\n            first = false;\n          } else {\n            sliceShardsStr.append('|');\n          }\n          sliceShardsStr.append(shardUrl);\n        }\n        rb.shards[i] = sliceShardsStr.toString();\n      }\n    }\n    String shards_rows = params.get(ShardParams.SHARDS_ROWS);\n    if(shards_rows != null) {\n      rb.shards_rows = Integer.parseInt(shards_rows);\n    }\n    String shards_start = params.get(ShardParams.SHARDS_START);\n    if(shards_start != null) {\n      rb.shards_start = Integer.parseInt(shards_start);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"54ca69905c5d9d1529286f06ab1d12c68f6c13cb","date":1492683554,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler#prepDistributed(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler#prepDistributed(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void prepDistributed(ResponseBuilder rb) {\n    final SolrQueryRequest req = rb.req;\n    final SolrParams params = req.getParams();\n    final String shards = params.get(ShardParams.SHARDS);\n\n    // since the cost of grabbing cloud state is still up in the air, we grab it only\n    // if we need it.\n    ClusterState clusterState = null;\n    Map<String,Slice> slices = null;\n    CoreDescriptor coreDescriptor = req.getCore().getCoreDescriptor();\n    CloudDescriptor cloudDescriptor = coreDescriptor.getCloudDescriptor();\n    ZkController zkController = req.getCore().getCoreContainer().getZkController();\n\n    final ReplicaListTransformer replicaListTransformer = httpShardHandlerFactory.getReplicaListTransformer(req);\n\n    if (shards != null) {\n      List<String> lst = StrUtils.splitSmart(shards, \",\", true);\n      rb.shards = lst.toArray(new String[lst.size()]);\n      rb.slices = new String[rb.shards.length];\n\n      if (zkController != null) {\n        // figure out which shards are slices\n        for (int i=0; i<rb.shards.length; i++) {\n          if (rb.shards[i].indexOf('/') < 0) {\n            // this is a logical shard\n            rb.slices[i] = rb.shards[i];\n            rb.shards[i] = null;\n          }\n        }\n      }\n    } else if (zkController != null) {\n      // we weren't provided with an explicit list of slices to query via \"shards\", so use the cluster state\n\n      clusterState =  zkController.getClusterState();\n      String shardKeys =  params.get(ShardParams._ROUTE_);\n\n      // This will be the complete list of slices we need to query for this request.\n      slices = new HashMap<>();\n\n      // we need to find out what collections this request is for.\n\n      // A comma-separated list of specified collections.\n      // Eg: \"collection1,collection2,collection3\"\n      String collections = params.get(\"collection\");\n      if (collections != null) {\n        // If there were one or more collections specified in the query, split\n        // each parameter and store as a separate member of a List.\n        List<String> collectionList = StrUtils.splitSmart(collections, \",\",\n            true);\n        // In turn, retrieve the slices that cover each collection from the\n        // cloud state and add them to the Map 'slices'.\n        for (String collectionName : collectionList) {\n          // The original code produced <collection-name>_<shard-name> when the collections\n          // parameter was specified (see ClientUtils.appendMap)\n          // Is this necessary if ony one collection is specified?\n          // i.e. should we change multiCollection to collectionList.size() > 1?\n          addSlices(slices, clusterState, params, collectionName,  shardKeys, true);\n        }\n      } else {\n        // just this collection\n        String collectionName = cloudDescriptor.getCollectionName();\n        addSlices(slices, clusterState, params, collectionName,  shardKeys, false);\n      }\n\n\n      // Store the logical slices in the ResponseBuilder and create a new\n      // String array to hold the physical shards (which will be mapped\n      // later).\n      rb.slices = slices.keySet().toArray(new String[slices.size()]);\n      rb.shards = new String[rb.slices.length];\n    }\n\n    //\n    // Map slices to shards\n    //\n    if (zkController != null) {\n\n      // Are we hosting the shard that this request is for, and are we active? If so, then handle it ourselves\n      // and make it a non-distributed request.\n      String ourSlice = cloudDescriptor.getShardId();\n      String ourCollection = cloudDescriptor.getCollectionName();\n      if (rb.slices.length == 1 && rb.slices[0] != null\n          && ( rb.slices[0].equals(ourSlice) || rb.slices[0].equals(ourCollection + \"_\" + ourSlice) )  // handle the <collection>_<slice> format\n          && cloudDescriptor.getLastPublished() == Replica.State.ACTIVE) {\n        boolean shortCircuit = params.getBool(\"shortCircuit\", true);       // currently just a debugging parameter to check distrib search on a single node\n\n        String targetHandler = params.get(ShardParams.SHARDS_QT);\n        shortCircuit = shortCircuit && targetHandler == null;             // if a different handler is specified, don't short-circuit\n\n        if (shortCircuit) {\n          rb.isDistrib = false;\n          rb.shortCircuitedURL = ZkCoreNodeProps.getCoreUrl(zkController.getBaseUrl(), coreDescriptor.getName());\n          return;\n        }\n        // We shouldn't need to do anything to handle \"shard.rows\" since it was previously meant to be an optimization?\n      }\n\n\n      for (int i=0; i<rb.shards.length; i++) {\n        final List<String> shardUrls;\n        if (rb.shards[i] != null) {\n          shardUrls = StrUtils.splitSmart(rb.shards[i], \"|\", true);\n          replicaListTransformer.transform(shardUrls);\n        } else {\n          if (clusterState == null) {\n            clusterState =  zkController.getClusterState();\n            slices = clusterState.getSlicesMap(cloudDescriptor.getCollectionName());\n          }\n          String sliceName = rb.slices[i];\n\n          Slice slice = slices.get(sliceName);\n\n          if (slice==null) {\n            // Treat this the same as \"all servers down\" for a slice, and let things continue\n            // if partial results are acceptable\n            rb.shards[i] = \"\";\n            continue;\n            // throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"no such shard: \" + sliceName);\n          }\n\n          final Collection<Replica> allSliceReplicas = slice.getReplicasMap().values();\n          final List<Replica> eligibleSliceReplicas = new ArrayList<>(allSliceReplicas.size());\n          for (Replica replica : allSliceReplicas) {\n            if (!clusterState.liveNodesContain(replica.getNodeName())\n                || replica.getState() != Replica.State.ACTIVE) {\n              continue;\n            }\n            eligibleSliceReplicas.add(replica);\n          }\n\n          replicaListTransformer.transform(eligibleSliceReplicas);\n\n          shardUrls = new ArrayList<>(eligibleSliceReplicas.size());\n          for (Replica replica : eligibleSliceReplicas) {\n            String url = ZkCoreNodeProps.getCoreUrl(replica);\n            shardUrls.add(url);\n          }\n\n          if (shardUrls.isEmpty()) {\n            boolean tolerant = rb.req.getParams().getBool(ShardParams.SHARDS_TOLERANT, false);\n            if (!tolerant) {\n              // stop the check when there are no replicas available for a shard\n              throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n                  \"no servers hosting shard: \" + rb.slices[i]);\n            }\n          }\n        }\n        // And now recreate the | delimited list of equivalent servers\n        final StringBuilder sliceShardsStr = new StringBuilder();\n        boolean first = true;\n        for (String shardUrl : shardUrls) {\n          if (first) {\n            first = false;\n          } else {\n            sliceShardsStr.append('|');\n          }\n          sliceShardsStr.append(shardUrl);\n        }\n        rb.shards[i] = sliceShardsStr.toString();\n      }\n    }\n    String shards_rows = params.get(ShardParams.SHARDS_ROWS);\n    if(shards_rows != null) {\n      rb.shards_rows = Integer.parseInt(shards_rows);\n    }\n    String shards_start = params.get(ShardParams.SHARDS_START);\n    if(shards_start != null) {\n      rb.shards_start = Integer.parseInt(shards_start);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void prepDistributed(ResponseBuilder rb) {\n    final SolrQueryRequest req = rb.req;\n    final SolrParams params = req.getParams();\n    final String shards = params.get(ShardParams.SHARDS);\n\n    // since the cost of grabbing cloud state is still up in the air, we grab it only\n    // if we need it.\n    ClusterState clusterState = null;\n    Map<String,Slice> slices = null;\n    CoreDescriptor coreDescriptor = req.getCore().getCoreDescriptor();\n    CloudDescriptor cloudDescriptor = coreDescriptor.getCloudDescriptor();\n    ZkController zkController = coreDescriptor.getCoreContainer().getZkController();\n\n    final ReplicaListTransformer replicaListTransformer = httpShardHandlerFactory.getReplicaListTransformer(req);\n\n    if (shards != null) {\n      List<String> lst = StrUtils.splitSmart(shards, \",\", true);\n      rb.shards = lst.toArray(new String[lst.size()]);\n      rb.slices = new String[rb.shards.length];\n\n      if (zkController != null) {\n        // figure out which shards are slices\n        for (int i=0; i<rb.shards.length; i++) {\n          if (rb.shards[i].indexOf('/') < 0) {\n            // this is a logical shard\n            rb.slices[i] = rb.shards[i];\n            rb.shards[i] = null;\n          }\n        }\n      }\n    } else if (zkController != null) {\n      // we weren't provided with an explicit list of slices to query via \"shards\", so use the cluster state\n\n      clusterState =  zkController.getClusterState();\n      String shardKeys =  params.get(ShardParams._ROUTE_);\n\n      // This will be the complete list of slices we need to query for this request.\n      slices = new HashMap<>();\n\n      // we need to find out what collections this request is for.\n\n      // A comma-separated list of specified collections.\n      // Eg: \"collection1,collection2,collection3\"\n      String collections = params.get(\"collection\");\n      if (collections != null) {\n        // If there were one or more collections specified in the query, split\n        // each parameter and store as a separate member of a List.\n        List<String> collectionList = StrUtils.splitSmart(collections, \",\",\n            true);\n        // In turn, retrieve the slices that cover each collection from the\n        // cloud state and add them to the Map 'slices'.\n        for (String collectionName : collectionList) {\n          // The original code produced <collection-name>_<shard-name> when the collections\n          // parameter was specified (see ClientUtils.appendMap)\n          // Is this necessary if ony one collection is specified?\n          // i.e. should we change multiCollection to collectionList.size() > 1?\n          addSlices(slices, clusterState, params, collectionName,  shardKeys, true);\n        }\n      } else {\n        // just this collection\n        String collectionName = cloudDescriptor.getCollectionName();\n        addSlices(slices, clusterState, params, collectionName,  shardKeys, false);\n      }\n\n\n      // Store the logical slices in the ResponseBuilder and create a new\n      // String array to hold the physical shards (which will be mapped\n      // later).\n      rb.slices = slices.keySet().toArray(new String[slices.size()]);\n      rb.shards = new String[rb.slices.length];\n    }\n\n    //\n    // Map slices to shards\n    //\n    if (zkController != null) {\n\n      // Are we hosting the shard that this request is for, and are we active? If so, then handle it ourselves\n      // and make it a non-distributed request.\n      String ourSlice = cloudDescriptor.getShardId();\n      String ourCollection = cloudDescriptor.getCollectionName();\n      if (rb.slices.length == 1 && rb.slices[0] != null\n          && ( rb.slices[0].equals(ourSlice) || rb.slices[0].equals(ourCollection + \"_\" + ourSlice) )  // handle the <collection>_<slice> format\n          && cloudDescriptor.getLastPublished() == Replica.State.ACTIVE) {\n        boolean shortCircuit = params.getBool(\"shortCircuit\", true);       // currently just a debugging parameter to check distrib search on a single node\n\n        String targetHandler = params.get(ShardParams.SHARDS_QT);\n        shortCircuit = shortCircuit && targetHandler == null;             // if a different handler is specified, don't short-circuit\n\n        if (shortCircuit) {\n          rb.isDistrib = false;\n          rb.shortCircuitedURL = ZkCoreNodeProps.getCoreUrl(zkController.getBaseUrl(), coreDescriptor.getName());\n          return;\n        }\n        // We shouldn't need to do anything to handle \"shard.rows\" since it was previously meant to be an optimization?\n      }\n\n\n      for (int i=0; i<rb.shards.length; i++) {\n        final List<String> shardUrls;\n        if (rb.shards[i] != null) {\n          shardUrls = StrUtils.splitSmart(rb.shards[i], \"|\", true);\n          replicaListTransformer.transform(shardUrls);\n        } else {\n          if (clusterState == null) {\n            clusterState =  zkController.getClusterState();\n            slices = clusterState.getSlicesMap(cloudDescriptor.getCollectionName());\n          }\n          String sliceName = rb.slices[i];\n\n          Slice slice = slices.get(sliceName);\n\n          if (slice==null) {\n            // Treat this the same as \"all servers down\" for a slice, and let things continue\n            // if partial results are acceptable\n            rb.shards[i] = \"\";\n            continue;\n            // throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"no such shard: \" + sliceName);\n          }\n\n          final Collection<Replica> allSliceReplicas = slice.getReplicasMap().values();\n          final List<Replica> eligibleSliceReplicas = new ArrayList<>(allSliceReplicas.size());\n          for (Replica replica : allSliceReplicas) {\n            if (!clusterState.liveNodesContain(replica.getNodeName())\n                || replica.getState() != Replica.State.ACTIVE) {\n              continue;\n            }\n            eligibleSliceReplicas.add(replica);\n          }\n\n          replicaListTransformer.transform(eligibleSliceReplicas);\n\n          shardUrls = new ArrayList<>(eligibleSliceReplicas.size());\n          for (Replica replica : eligibleSliceReplicas) {\n            String url = ZkCoreNodeProps.getCoreUrl(replica);\n            shardUrls.add(url);\n          }\n\n          if (shardUrls.isEmpty()) {\n            boolean tolerant = rb.req.getParams().getBool(ShardParams.SHARDS_TOLERANT, false);\n            if (!tolerant) {\n              // stop the check when there are no replicas available for a shard\n              throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n                  \"no servers hosting shard: \" + rb.slices[i]);\n            }\n          }\n        }\n        // And now recreate the | delimited list of equivalent servers\n        final StringBuilder sliceShardsStr = new StringBuilder();\n        boolean first = true;\n        for (String shardUrl : shardUrls) {\n          if (first) {\n            first = false;\n          } else {\n            sliceShardsStr.append('|');\n          }\n          sliceShardsStr.append(shardUrl);\n        }\n        rb.shards[i] = sliceShardsStr.toString();\n      }\n    }\n    String shards_rows = params.get(ShardParams.SHARDS_ROWS);\n    if(shards_rows != null) {\n      rb.shards_rows = Integer.parseInt(shards_rows);\n    }\n    String shards_start = params.get(ShardParams.SHARDS_START);\n    if(shards_start != null) {\n      rb.shards_start = Integer.parseInt(shards_start);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"61c45e99cf6676da48f19d7511c73712ad39402b","date":1495508331,"type":3,"author":"Tomas Fernandez Lobbe","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler#prepDistributed(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler#prepDistributed(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void prepDistributed(ResponseBuilder rb) {\n    final SolrQueryRequest req = rb.req;\n    final SolrParams params = req.getParams();\n    final String shards = params.get(ShardParams.SHARDS);\n\n    // since the cost of grabbing cloud state is still up in the air, we grab it only\n    // if we need it.\n    ClusterState clusterState = null;\n    Map<String,Slice> slices = null;\n    CoreDescriptor coreDescriptor = req.getCore().getCoreDescriptor();\n    CloudDescriptor cloudDescriptor = coreDescriptor.getCloudDescriptor();\n    ZkController zkController = req.getCore().getCoreContainer().getZkController();\n\n    final ReplicaListTransformer replicaListTransformer = httpShardHandlerFactory.getReplicaListTransformer(req);\n\n    if (shards != null) {\n      List<String> lst = StrUtils.splitSmart(shards, \",\", true);\n      rb.shards = lst.toArray(new String[lst.size()]);\n      rb.slices = new String[rb.shards.length];\n\n      if (zkController != null) {\n        // figure out which shards are slices\n        for (int i=0; i<rb.shards.length; i++) {\n          if (rb.shards[i].indexOf('/') < 0) {\n            // this is a logical shard\n            rb.slices[i] = rb.shards[i];\n            rb.shards[i] = null;\n          }\n        }\n      }\n    } else if (zkController != null) {\n      // we weren't provided with an explicit list of slices to query via \"shards\", so use the cluster state\n\n      clusterState =  zkController.getClusterState();\n      String shardKeys =  params.get(ShardParams._ROUTE_);\n\n      // This will be the complete list of slices we need to query for this request.\n      slices = new HashMap<>();\n\n      // we need to find out what collections this request is for.\n\n      // A comma-separated list of specified collections.\n      // Eg: \"collection1,collection2,collection3\"\n      String collections = params.get(\"collection\");\n      if (collections != null) {\n        // If there were one or more collections specified in the query, split\n        // each parameter and store as a separate member of a List.\n        List<String> collectionList = StrUtils.splitSmart(collections, \",\",\n            true);\n        // In turn, retrieve the slices that cover each collection from the\n        // cloud state and add them to the Map 'slices'.\n        for (String collectionName : collectionList) {\n          // The original code produced <collection-name>_<shard-name> when the collections\n          // parameter was specified (see ClientUtils.appendMap)\n          // Is this necessary if ony one collection is specified?\n          // i.e. should we change multiCollection to collectionList.size() > 1?\n          addSlices(slices, clusterState, params, collectionName,  shardKeys, true);\n        }\n      } else {\n        // just this collection\n        String collectionName = cloudDescriptor.getCollectionName();\n        addSlices(slices, clusterState, params, collectionName,  shardKeys, false);\n      }\n\n\n      // Store the logical slices in the ResponseBuilder and create a new\n      // String array to hold the physical shards (which will be mapped\n      // later).\n      rb.slices = slices.keySet().toArray(new String[slices.size()]);\n      rb.shards = new String[rb.slices.length];\n    }\n\n    //\n    // Map slices to shards\n    //\n    if (zkController != null) {\n\n      // Are we hosting the shard that this request is for, and are we active? If so, then handle it ourselves\n      // and make it a non-distributed request.\n      String ourSlice = cloudDescriptor.getShardId();\n      String ourCollection = cloudDescriptor.getCollectionName();\n      // Some requests may only be fulfilled by replicas of type Replica.Type.NRT\n      boolean onlyNrtReplicas = Boolean.TRUE == req.getContext().get(ONLY_NRT_REPLICAS);\n      if (rb.slices.length == 1 && rb.slices[0] != null\n          && ( rb.slices[0].equals(ourSlice) || rb.slices[0].equals(ourCollection + \"_\" + ourSlice) )  // handle the <collection>_<slice> format\n          && cloudDescriptor.getLastPublished() == Replica.State.ACTIVE\n          && (!onlyNrtReplicas || cloudDescriptor.getReplicaType() == Replica.Type.NRT)) {\n        boolean shortCircuit = params.getBool(\"shortCircuit\", true);       // currently just a debugging parameter to check distrib search on a single node\n\n        String targetHandler = params.get(ShardParams.SHARDS_QT);\n        shortCircuit = shortCircuit && targetHandler == null;             // if a different handler is specified, don't short-circuit\n\n        if (shortCircuit) {\n          rb.isDistrib = false;\n          rb.shortCircuitedURL = ZkCoreNodeProps.getCoreUrl(zkController.getBaseUrl(), coreDescriptor.getName());\n          return;\n        }\n        // We shouldn't need to do anything to handle \"shard.rows\" since it was previously meant to be an optimization?\n      }\n\n\n      for (int i=0; i<rb.shards.length; i++) {\n        final List<String> shardUrls;\n        if (rb.shards[i] != null) {\n          shardUrls = StrUtils.splitSmart(rb.shards[i], \"|\", true);\n          replicaListTransformer.transform(shardUrls);\n        } else {\n          if (clusterState == null) {\n            clusterState =  zkController.getClusterState();\n            slices = clusterState.getSlicesMap(cloudDescriptor.getCollectionName());\n          }\n          String sliceName = rb.slices[i];\n\n          Slice slice = slices.get(sliceName);\n\n          if (slice==null) {\n            // Treat this the same as \"all servers down\" for a slice, and let things continue\n            // if partial results are acceptable\n            rb.shards[i] = \"\";\n            continue;\n            // throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"no such shard: \" + sliceName);\n          }\n          Replica shardLeader = null;\n\n          final Collection<Replica> allSliceReplicas = slice.getReplicasMap().values();\n          final List<Replica> eligibleSliceReplicas = new ArrayList<>(allSliceReplicas.size());\n          for (Replica replica : allSliceReplicas) {\n            if (!clusterState.liveNodesContain(replica.getNodeName())\n                || replica.getState() != Replica.State.ACTIVE\n                || (onlyNrtReplicas && replica.getType() == Replica.Type.PULL)) {\n              continue;\n            }\n            \n            if (onlyNrtReplicas && replica.getType() == Replica.Type.TLOG) {\n              if (shardLeader == null) {\n                try {\n                  shardLeader = zkController.getZkStateReader().getLeaderRetry(cloudDescriptor.getCollectionName(), slice.getName());\n                } catch (InterruptedException e) {\n                  throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + slice.getName() + \" in collection \" \n                      + cloudDescriptor.getCollectionName(), e);\n                } catch (SolrException e) {\n                  if (log.isDebugEnabled()) {\n                    log.debug(\"Exception finding leader for shard {} in collection {}. Collection State: {}\", \n                        slice.getName(), cloudDescriptor.getCollectionName(), zkController.getZkStateReader().getClusterState().getCollectionOrNull(cloudDescriptor.getCollectionName()));\n                  }\n                  throw e;\n                }\n              }\n              if (!replica.getName().equals(shardLeader.getName())) {\n                continue;\n              }\n            }\n            eligibleSliceReplicas.add(replica);\n          }\n\n          replicaListTransformer.transform(eligibleSliceReplicas);\n\n          shardUrls = new ArrayList<>(eligibleSliceReplicas.size());\n          for (Replica replica : eligibleSliceReplicas) {\n            String url = ZkCoreNodeProps.getCoreUrl(replica);\n            shardUrls.add(url);\n          }\n\n          if (shardUrls.isEmpty()) {\n            boolean tolerant = rb.req.getParams().getBool(ShardParams.SHARDS_TOLERANT, false);\n            if (!tolerant) {\n              // stop the check when there are no replicas available for a shard\n              throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n                  \"no servers hosting shard: \" + rb.slices[i]);\n            }\n          }\n        }\n        // And now recreate the | delimited list of equivalent servers\n        final StringBuilder sliceShardsStr = new StringBuilder();\n        boolean first = true;\n        for (String shardUrl : shardUrls) {\n          if (first) {\n            first = false;\n          } else {\n            sliceShardsStr.append('|');\n          }\n          sliceShardsStr.append(shardUrl);\n        }\n        rb.shards[i] = sliceShardsStr.toString();\n      }\n    }\n    String shards_rows = params.get(ShardParams.SHARDS_ROWS);\n    if(shards_rows != null) {\n      rb.shards_rows = Integer.parseInt(shards_rows);\n    }\n    String shards_start = params.get(ShardParams.SHARDS_START);\n    if(shards_start != null) {\n      rb.shards_start = Integer.parseInt(shards_start);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void prepDistributed(ResponseBuilder rb) {\n    final SolrQueryRequest req = rb.req;\n    final SolrParams params = req.getParams();\n    final String shards = params.get(ShardParams.SHARDS);\n\n    // since the cost of grabbing cloud state is still up in the air, we grab it only\n    // if we need it.\n    ClusterState clusterState = null;\n    Map<String,Slice> slices = null;\n    CoreDescriptor coreDescriptor = req.getCore().getCoreDescriptor();\n    CloudDescriptor cloudDescriptor = coreDescriptor.getCloudDescriptor();\n    ZkController zkController = req.getCore().getCoreContainer().getZkController();\n\n    final ReplicaListTransformer replicaListTransformer = httpShardHandlerFactory.getReplicaListTransformer(req);\n\n    if (shards != null) {\n      List<String> lst = StrUtils.splitSmart(shards, \",\", true);\n      rb.shards = lst.toArray(new String[lst.size()]);\n      rb.slices = new String[rb.shards.length];\n\n      if (zkController != null) {\n        // figure out which shards are slices\n        for (int i=0; i<rb.shards.length; i++) {\n          if (rb.shards[i].indexOf('/') < 0) {\n            // this is a logical shard\n            rb.slices[i] = rb.shards[i];\n            rb.shards[i] = null;\n          }\n        }\n      }\n    } else if (zkController != null) {\n      // we weren't provided with an explicit list of slices to query via \"shards\", so use the cluster state\n\n      clusterState =  zkController.getClusterState();\n      String shardKeys =  params.get(ShardParams._ROUTE_);\n\n      // This will be the complete list of slices we need to query for this request.\n      slices = new HashMap<>();\n\n      // we need to find out what collections this request is for.\n\n      // A comma-separated list of specified collections.\n      // Eg: \"collection1,collection2,collection3\"\n      String collections = params.get(\"collection\");\n      if (collections != null) {\n        // If there were one or more collections specified in the query, split\n        // each parameter and store as a separate member of a List.\n        List<String> collectionList = StrUtils.splitSmart(collections, \",\",\n            true);\n        // In turn, retrieve the slices that cover each collection from the\n        // cloud state and add them to the Map 'slices'.\n        for (String collectionName : collectionList) {\n          // The original code produced <collection-name>_<shard-name> when the collections\n          // parameter was specified (see ClientUtils.appendMap)\n          // Is this necessary if ony one collection is specified?\n          // i.e. should we change multiCollection to collectionList.size() > 1?\n          addSlices(slices, clusterState, params, collectionName,  shardKeys, true);\n        }\n      } else {\n        // just this collection\n        String collectionName = cloudDescriptor.getCollectionName();\n        addSlices(slices, clusterState, params, collectionName,  shardKeys, false);\n      }\n\n\n      // Store the logical slices in the ResponseBuilder and create a new\n      // String array to hold the physical shards (which will be mapped\n      // later).\n      rb.slices = slices.keySet().toArray(new String[slices.size()]);\n      rb.shards = new String[rb.slices.length];\n    }\n\n    //\n    // Map slices to shards\n    //\n    if (zkController != null) {\n\n      // Are we hosting the shard that this request is for, and are we active? If so, then handle it ourselves\n      // and make it a non-distributed request.\n      String ourSlice = cloudDescriptor.getShardId();\n      String ourCollection = cloudDescriptor.getCollectionName();\n      if (rb.slices.length == 1 && rb.slices[0] != null\n          && ( rb.slices[0].equals(ourSlice) || rb.slices[0].equals(ourCollection + \"_\" + ourSlice) )  // handle the <collection>_<slice> format\n          && cloudDescriptor.getLastPublished() == Replica.State.ACTIVE) {\n        boolean shortCircuit = params.getBool(\"shortCircuit\", true);       // currently just a debugging parameter to check distrib search on a single node\n\n        String targetHandler = params.get(ShardParams.SHARDS_QT);\n        shortCircuit = shortCircuit && targetHandler == null;             // if a different handler is specified, don't short-circuit\n\n        if (shortCircuit) {\n          rb.isDistrib = false;\n          rb.shortCircuitedURL = ZkCoreNodeProps.getCoreUrl(zkController.getBaseUrl(), coreDescriptor.getName());\n          return;\n        }\n        // We shouldn't need to do anything to handle \"shard.rows\" since it was previously meant to be an optimization?\n      }\n\n\n      for (int i=0; i<rb.shards.length; i++) {\n        final List<String> shardUrls;\n        if (rb.shards[i] != null) {\n          shardUrls = StrUtils.splitSmart(rb.shards[i], \"|\", true);\n          replicaListTransformer.transform(shardUrls);\n        } else {\n          if (clusterState == null) {\n            clusterState =  zkController.getClusterState();\n            slices = clusterState.getSlicesMap(cloudDescriptor.getCollectionName());\n          }\n          String sliceName = rb.slices[i];\n\n          Slice slice = slices.get(sliceName);\n\n          if (slice==null) {\n            // Treat this the same as \"all servers down\" for a slice, and let things continue\n            // if partial results are acceptable\n            rb.shards[i] = \"\";\n            continue;\n            // throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"no such shard: \" + sliceName);\n          }\n\n          final Collection<Replica> allSliceReplicas = slice.getReplicasMap().values();\n          final List<Replica> eligibleSliceReplicas = new ArrayList<>(allSliceReplicas.size());\n          for (Replica replica : allSliceReplicas) {\n            if (!clusterState.liveNodesContain(replica.getNodeName())\n                || replica.getState() != Replica.State.ACTIVE) {\n              continue;\n            }\n            eligibleSliceReplicas.add(replica);\n          }\n\n          replicaListTransformer.transform(eligibleSliceReplicas);\n\n          shardUrls = new ArrayList<>(eligibleSliceReplicas.size());\n          for (Replica replica : eligibleSliceReplicas) {\n            String url = ZkCoreNodeProps.getCoreUrl(replica);\n            shardUrls.add(url);\n          }\n\n          if (shardUrls.isEmpty()) {\n            boolean tolerant = rb.req.getParams().getBool(ShardParams.SHARDS_TOLERANT, false);\n            if (!tolerant) {\n              // stop the check when there are no replicas available for a shard\n              throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n                  \"no servers hosting shard: \" + rb.slices[i]);\n            }\n          }\n        }\n        // And now recreate the | delimited list of equivalent servers\n        final StringBuilder sliceShardsStr = new StringBuilder();\n        boolean first = true;\n        for (String shardUrl : shardUrls) {\n          if (first) {\n            first = false;\n          } else {\n            sliceShardsStr.append('|');\n          }\n          sliceShardsStr.append(shardUrl);\n        }\n        rb.shards[i] = sliceShardsStr.toString();\n      }\n    }\n    String shards_rows = params.get(ShardParams.SHARDS_ROWS);\n    if(shards_rows != null) {\n      rb.shards_rows = Integer.parseInt(shards_rows);\n    }\n    String shards_start = params.get(ShardParams.SHARDS_START);\n    if(shards_start != null) {\n      rb.shards_start = Integer.parseInt(shards_start);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d19b466e346f2319504d6a159d78f56e1b70b6fa","date":1495792377,"type":3,"author":"Christine Poerschke","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler#prepDistributed(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler#prepDistributed(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void prepDistributed(ResponseBuilder rb) {\n    final SolrQueryRequest req = rb.req;\n    final SolrParams params = req.getParams();\n    final String shards = params.get(ShardParams.SHARDS);\n\n    // since the cost of grabbing cloud state is still up in the air, we grab it only\n    // if we need it.\n    ClusterState clusterState = null;\n    Map<String,Slice> slices = null;\n    CoreDescriptor coreDescriptor = req.getCore().getCoreDescriptor();\n    CloudDescriptor cloudDescriptor = coreDescriptor.getCloudDescriptor();\n    ZkController zkController = req.getCore().getCoreContainer().getZkController();\n\n    final ReplicaListTransformer replicaListTransformer = httpShardHandlerFactory.getReplicaListTransformer(req);\n\n    if (shards != null) {\n      List<String> lst = StrUtils.splitSmart(shards, \",\", true);\n      rb.shards = lst.toArray(new String[lst.size()]);\n      rb.slices = new String[rb.shards.length];\n\n      if (zkController != null) {\n        // figure out which shards are slices\n        for (int i=0; i<rb.shards.length; i++) {\n          if (rb.shards[i].indexOf('/') < 0) {\n            // this is a logical shard\n            rb.slices[i] = rb.shards[i];\n            rb.shards[i] = null;\n          }\n        }\n      }\n    } else if (zkController != null) {\n      // we weren't provided with an explicit list of slices to query via \"shards\", so use the cluster state\n\n      clusterState =  zkController.getClusterState();\n      String shardKeys =  params.get(ShardParams._ROUTE_);\n\n      // This will be the complete list of slices we need to query for this request.\n      slices = new HashMap<>();\n\n      // we need to find out what collections this request is for.\n\n      // A comma-separated list of specified collections.\n      // Eg: \"collection1,collection2,collection3\"\n      String collections = params.get(\"collection\");\n      if (collections != null) {\n        // If there were one or more collections specified in the query, split\n        // each parameter and store as a separate member of a List.\n        List<String> collectionList = StrUtils.splitSmart(collections, \",\",\n            true);\n        // In turn, retrieve the slices that cover each collection from the\n        // cloud state and add them to the Map 'slices'.\n        for (String collectionName : collectionList) {\n          // The original code produced <collection-name>_<shard-name> when the collections\n          // parameter was specified (see ClientUtils.appendMap)\n          // Is this necessary if ony one collection is specified?\n          // i.e. should we change multiCollection to collectionList.size() > 1?\n          addSlices(slices, clusterState, params, collectionName,  shardKeys, true);\n        }\n      } else {\n        // just this collection\n        String collectionName = cloudDescriptor.getCollectionName();\n        addSlices(slices, clusterState, params, collectionName,  shardKeys, false);\n      }\n\n\n      // Store the logical slices in the ResponseBuilder and create a new\n      // String array to hold the physical shards (which will be mapped\n      // later).\n      rb.slices = slices.keySet().toArray(new String[slices.size()]);\n      rb.shards = new String[rb.slices.length];\n    }\n\n    //\n    // Map slices to shards\n    //\n    if (zkController != null) {\n\n      // Are we hosting the shard that this request is for, and are we active? If so, then handle it ourselves\n      // and make it a non-distributed request.\n      String ourSlice = cloudDescriptor.getShardId();\n      String ourCollection = cloudDescriptor.getCollectionName();\n      // Some requests may only be fulfilled by replicas of type Replica.Type.NRT\n      boolean onlyNrtReplicas = Boolean.TRUE == req.getContext().get(ONLY_NRT_REPLICAS);\n      if (rb.slices.length == 1 && rb.slices[0] != null\n          && ( rb.slices[0].equals(ourSlice) || rb.slices[0].equals(ourCollection + \"_\" + ourSlice) )  // handle the <collection>_<slice> format\n          && cloudDescriptor.getLastPublished() == Replica.State.ACTIVE\n          && (!onlyNrtReplicas || cloudDescriptor.getReplicaType() == Replica.Type.NRT)) {\n        boolean shortCircuit = params.getBool(\"shortCircuit\", true);       // currently just a debugging parameter to check distrib search on a single node\n\n        String targetHandler = params.get(ShardParams.SHARDS_QT);\n        shortCircuit = shortCircuit && targetHandler == null;             // if a different handler is specified, don't short-circuit\n\n        if (shortCircuit) {\n          rb.isDistrib = false;\n          rb.shortCircuitedURL = ZkCoreNodeProps.getCoreUrl(zkController.getBaseUrl(), coreDescriptor.getName());\n          return;\n        }\n        // We shouldn't need to do anything to handle \"shard.rows\" since it was previously meant to be an optimization?\n      }\n\n\n      for (int i=0; i<rb.shards.length; i++) {\n        final List<String> shardUrls;\n        if (rb.shards[i] != null) {\n          shardUrls = StrUtils.splitSmart(rb.shards[i], \"|\", true);\n          replicaListTransformer.transform(shardUrls);\n        } else {\n          if (clusterState == null) {\n            clusterState =  zkController.getClusterState();\n            slices = clusterState.getSlicesMap(cloudDescriptor.getCollectionName());\n          }\n          String sliceName = rb.slices[i];\n\n          Slice slice = slices.get(sliceName);\n\n          if (slice==null) {\n            // Treat this the same as \"all servers down\" for a slice, and let things continue\n            // if partial results are acceptable\n            rb.shards[i] = \"\";\n            continue;\n            // throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"no such shard: \" + sliceName);\n          }\n          Replica shardLeader = null;\n\n          final Collection<Replica> allSliceReplicas = slice.getReplicasMap().values();\n          final List<Replica> eligibleSliceReplicas = new ArrayList<>(allSliceReplicas.size());\n          for (Replica replica : allSliceReplicas) {\n            if (!clusterState.liveNodesContain(replica.getNodeName())\n                || replica.getState() != Replica.State.ACTIVE\n                || (onlyNrtReplicas && replica.getType() == Replica.Type.PULL)) {\n              continue;\n            }\n            \n            if (onlyNrtReplicas && replica.getType() == Replica.Type.TLOG) {\n              if (shardLeader == null) {\n                try {\n                  shardLeader = zkController.getZkStateReader().getLeaderRetry(cloudDescriptor.getCollectionName(), slice.getName());\n                } catch (InterruptedException e) {\n                  throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + slice.getName() + \" in collection \" \n                      + cloudDescriptor.getCollectionName(), e);\n                } catch (SolrException e) {\n                  if (log.isDebugEnabled()) {\n                    log.debug(\"Exception finding leader for shard {} in collection {}. Collection State: {}\", \n                        slice.getName(), cloudDescriptor.getCollectionName(), zkController.getZkStateReader().getClusterState().getCollectionOrNull(cloudDescriptor.getCollectionName()));\n                  }\n                  throw e;\n                }\n              }\n              if (!replica.getName().equals(shardLeader.getName())) {\n                continue;\n              }\n            }\n            eligibleSliceReplicas.add(replica);\n          }\n\n          replicaListTransformer.transform(eligibleSliceReplicas);\n\n          shardUrls = new ArrayList<>(eligibleSliceReplicas.size());\n          for (Replica replica : eligibleSliceReplicas) {\n            String url = ZkCoreNodeProps.getCoreUrl(replica);\n            shardUrls.add(url);\n          }\n\n          if (shardUrls.isEmpty()) {\n            boolean tolerant = rb.req.getParams().getBool(ShardParams.SHARDS_TOLERANT, false);\n            if (!tolerant) {\n              // stop the check when there are no replicas available for a shard\n              throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n                  \"no servers hosting shard: \" + rb.slices[i]);\n            }\n          }\n        }\n        // And now recreate the | delimited list of equivalent servers\n        rb.shards[i] = createSliceShardsStr(shardUrls);\n      }\n    }\n    String shards_rows = params.get(ShardParams.SHARDS_ROWS);\n    if(shards_rows != null) {\n      rb.shards_rows = Integer.parseInt(shards_rows);\n    }\n    String shards_start = params.get(ShardParams.SHARDS_START);\n    if(shards_start != null) {\n      rb.shards_start = Integer.parseInt(shards_start);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void prepDistributed(ResponseBuilder rb) {\n    final SolrQueryRequest req = rb.req;\n    final SolrParams params = req.getParams();\n    final String shards = params.get(ShardParams.SHARDS);\n\n    // since the cost of grabbing cloud state is still up in the air, we grab it only\n    // if we need it.\n    ClusterState clusterState = null;\n    Map<String,Slice> slices = null;\n    CoreDescriptor coreDescriptor = req.getCore().getCoreDescriptor();\n    CloudDescriptor cloudDescriptor = coreDescriptor.getCloudDescriptor();\n    ZkController zkController = req.getCore().getCoreContainer().getZkController();\n\n    final ReplicaListTransformer replicaListTransformer = httpShardHandlerFactory.getReplicaListTransformer(req);\n\n    if (shards != null) {\n      List<String> lst = StrUtils.splitSmart(shards, \",\", true);\n      rb.shards = lst.toArray(new String[lst.size()]);\n      rb.slices = new String[rb.shards.length];\n\n      if (zkController != null) {\n        // figure out which shards are slices\n        for (int i=0; i<rb.shards.length; i++) {\n          if (rb.shards[i].indexOf('/') < 0) {\n            // this is a logical shard\n            rb.slices[i] = rb.shards[i];\n            rb.shards[i] = null;\n          }\n        }\n      }\n    } else if (zkController != null) {\n      // we weren't provided with an explicit list of slices to query via \"shards\", so use the cluster state\n\n      clusterState =  zkController.getClusterState();\n      String shardKeys =  params.get(ShardParams._ROUTE_);\n\n      // This will be the complete list of slices we need to query for this request.\n      slices = new HashMap<>();\n\n      // we need to find out what collections this request is for.\n\n      // A comma-separated list of specified collections.\n      // Eg: \"collection1,collection2,collection3\"\n      String collections = params.get(\"collection\");\n      if (collections != null) {\n        // If there were one or more collections specified in the query, split\n        // each parameter and store as a separate member of a List.\n        List<String> collectionList = StrUtils.splitSmart(collections, \",\",\n            true);\n        // In turn, retrieve the slices that cover each collection from the\n        // cloud state and add them to the Map 'slices'.\n        for (String collectionName : collectionList) {\n          // The original code produced <collection-name>_<shard-name> when the collections\n          // parameter was specified (see ClientUtils.appendMap)\n          // Is this necessary if ony one collection is specified?\n          // i.e. should we change multiCollection to collectionList.size() > 1?\n          addSlices(slices, clusterState, params, collectionName,  shardKeys, true);\n        }\n      } else {\n        // just this collection\n        String collectionName = cloudDescriptor.getCollectionName();\n        addSlices(slices, clusterState, params, collectionName,  shardKeys, false);\n      }\n\n\n      // Store the logical slices in the ResponseBuilder and create a new\n      // String array to hold the physical shards (which will be mapped\n      // later).\n      rb.slices = slices.keySet().toArray(new String[slices.size()]);\n      rb.shards = new String[rb.slices.length];\n    }\n\n    //\n    // Map slices to shards\n    //\n    if (zkController != null) {\n\n      // Are we hosting the shard that this request is for, and are we active? If so, then handle it ourselves\n      // and make it a non-distributed request.\n      String ourSlice = cloudDescriptor.getShardId();\n      String ourCollection = cloudDescriptor.getCollectionName();\n      // Some requests may only be fulfilled by replicas of type Replica.Type.NRT\n      boolean onlyNrtReplicas = Boolean.TRUE == req.getContext().get(ONLY_NRT_REPLICAS);\n      if (rb.slices.length == 1 && rb.slices[0] != null\n          && ( rb.slices[0].equals(ourSlice) || rb.slices[0].equals(ourCollection + \"_\" + ourSlice) )  // handle the <collection>_<slice> format\n          && cloudDescriptor.getLastPublished() == Replica.State.ACTIVE\n          && (!onlyNrtReplicas || cloudDescriptor.getReplicaType() == Replica.Type.NRT)) {\n        boolean shortCircuit = params.getBool(\"shortCircuit\", true);       // currently just a debugging parameter to check distrib search on a single node\n\n        String targetHandler = params.get(ShardParams.SHARDS_QT);\n        shortCircuit = shortCircuit && targetHandler == null;             // if a different handler is specified, don't short-circuit\n\n        if (shortCircuit) {\n          rb.isDistrib = false;\n          rb.shortCircuitedURL = ZkCoreNodeProps.getCoreUrl(zkController.getBaseUrl(), coreDescriptor.getName());\n          return;\n        }\n        // We shouldn't need to do anything to handle \"shard.rows\" since it was previously meant to be an optimization?\n      }\n\n\n      for (int i=0; i<rb.shards.length; i++) {\n        final List<String> shardUrls;\n        if (rb.shards[i] != null) {\n          shardUrls = StrUtils.splitSmart(rb.shards[i], \"|\", true);\n          replicaListTransformer.transform(shardUrls);\n        } else {\n          if (clusterState == null) {\n            clusterState =  zkController.getClusterState();\n            slices = clusterState.getSlicesMap(cloudDescriptor.getCollectionName());\n          }\n          String sliceName = rb.slices[i];\n\n          Slice slice = slices.get(sliceName);\n\n          if (slice==null) {\n            // Treat this the same as \"all servers down\" for a slice, and let things continue\n            // if partial results are acceptable\n            rb.shards[i] = \"\";\n            continue;\n            // throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"no such shard: \" + sliceName);\n          }\n          Replica shardLeader = null;\n\n          final Collection<Replica> allSliceReplicas = slice.getReplicasMap().values();\n          final List<Replica> eligibleSliceReplicas = new ArrayList<>(allSliceReplicas.size());\n          for (Replica replica : allSliceReplicas) {\n            if (!clusterState.liveNodesContain(replica.getNodeName())\n                || replica.getState() != Replica.State.ACTIVE\n                || (onlyNrtReplicas && replica.getType() == Replica.Type.PULL)) {\n              continue;\n            }\n            \n            if (onlyNrtReplicas && replica.getType() == Replica.Type.TLOG) {\n              if (shardLeader == null) {\n                try {\n                  shardLeader = zkController.getZkStateReader().getLeaderRetry(cloudDescriptor.getCollectionName(), slice.getName());\n                } catch (InterruptedException e) {\n                  throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + slice.getName() + \" in collection \" \n                      + cloudDescriptor.getCollectionName(), e);\n                } catch (SolrException e) {\n                  if (log.isDebugEnabled()) {\n                    log.debug(\"Exception finding leader for shard {} in collection {}. Collection State: {}\", \n                        slice.getName(), cloudDescriptor.getCollectionName(), zkController.getZkStateReader().getClusterState().getCollectionOrNull(cloudDescriptor.getCollectionName()));\n                  }\n                  throw e;\n                }\n              }\n              if (!replica.getName().equals(shardLeader.getName())) {\n                continue;\n              }\n            }\n            eligibleSliceReplicas.add(replica);\n          }\n\n          replicaListTransformer.transform(eligibleSliceReplicas);\n\n          shardUrls = new ArrayList<>(eligibleSliceReplicas.size());\n          for (Replica replica : eligibleSliceReplicas) {\n            String url = ZkCoreNodeProps.getCoreUrl(replica);\n            shardUrls.add(url);\n          }\n\n          if (shardUrls.isEmpty()) {\n            boolean tolerant = rb.req.getParams().getBool(ShardParams.SHARDS_TOLERANT, false);\n            if (!tolerant) {\n              // stop the check when there are no replicas available for a shard\n              throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n                  \"no servers hosting shard: \" + rb.slices[i]);\n            }\n          }\n        }\n        // And now recreate the | delimited list of equivalent servers\n        final StringBuilder sliceShardsStr = new StringBuilder();\n        boolean first = true;\n        for (String shardUrl : shardUrls) {\n          if (first) {\n            first = false;\n          } else {\n            sliceShardsStr.append('|');\n          }\n          sliceShardsStr.append(shardUrl);\n        }\n        rb.shards[i] = sliceShardsStr.toString();\n      }\n    }\n    String shards_rows = params.get(ShardParams.SHARDS_ROWS);\n    if(shards_rows != null) {\n      rb.shards_rows = Integer.parseInt(shards_rows);\n    }\n    String shards_start = params.get(ShardParams.SHARDS_START);\n    if(shards_start != null) {\n      rb.shards_start = Integer.parseInt(shards_start);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d1f5728f32a4a256b36cfabd7a2636452f599bb9","date":1496231774,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler#prepDistributed(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler#prepDistributed(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void prepDistributed(ResponseBuilder rb) {\n    final SolrQueryRequest req = rb.req;\n    final SolrParams params = req.getParams();\n    final String shards = params.get(ShardParams.SHARDS);\n\n    // since the cost of grabbing cloud state is still up in the air, we grab it only\n    // if we need it.\n    ClusterState clusterState = null;\n    Map<String,Slice> slices = null;\n    CoreDescriptor coreDescriptor = req.getCore().getCoreDescriptor();\n    CloudDescriptor cloudDescriptor = coreDescriptor.getCloudDescriptor();\n    ZkController zkController = req.getCore().getCoreContainer().getZkController();\n\n    final ReplicaListTransformer replicaListTransformer = httpShardHandlerFactory.getReplicaListTransformer(req);\n\n    if (shards != null) {\n      List<String> lst = StrUtils.splitSmart(shards, \",\", true);\n      rb.shards = lst.toArray(new String[lst.size()]);\n      rb.slices = new String[rb.shards.length];\n\n      if (zkController != null) {\n        // figure out which shards are slices\n        for (int i=0; i<rb.shards.length; i++) {\n          if (rb.shards[i].indexOf('/') < 0) {\n            // this is a logical shard\n            rb.slices[i] = rb.shards[i];\n            rb.shards[i] = null;\n          }\n        }\n      }\n    } else if (zkController != null) {\n      // we weren't provided with an explicit list of slices to query via \"shards\", so use the cluster state\n\n      clusterState =  zkController.getClusterState();\n      String shardKeys =  params.get(ShardParams._ROUTE_);\n\n      // This will be the complete list of slices we need to query for this request.\n      slices = new HashMap<>();\n\n      // we need to find out what collections this request is for.\n\n      // A comma-separated list of specified collections.\n      // Eg: \"collection1,collection2,collection3\"\n      String collections = params.get(\"collection\");\n      if (collections != null) {\n        // If there were one or more collections specified in the query, split\n        // each parameter and store as a separate member of a List.\n        List<String> collectionList = StrUtils.splitSmart(collections, \",\",\n            true);\n        // In turn, retrieve the slices that cover each collection from the\n        // cloud state and add them to the Map 'slices'.\n        for (String collectionName : collectionList) {\n          // The original code produced <collection-name>_<shard-name> when the collections\n          // parameter was specified (see ClientUtils.appendMap)\n          // Is this necessary if ony one collection is specified?\n          // i.e. should we change multiCollection to collectionList.size() > 1?\n          addSlices(slices, clusterState, params, collectionName,  shardKeys, true);\n        }\n      } else {\n        // just this collection\n        String collectionName = cloudDescriptor.getCollectionName();\n        addSlices(slices, clusterState, params, collectionName,  shardKeys, false);\n      }\n\n\n      // Store the logical slices in the ResponseBuilder and create a new\n      // String array to hold the physical shards (which will be mapped\n      // later).\n      rb.slices = slices.keySet().toArray(new String[slices.size()]);\n      rb.shards = new String[rb.slices.length];\n    }\n\n    //\n    // Map slices to shards\n    //\n    if (zkController != null) {\n\n      // Are we hosting the shard that this request is for, and are we active? If so, then handle it ourselves\n      // and make it a non-distributed request.\n      String ourSlice = cloudDescriptor.getShardId();\n      String ourCollection = cloudDescriptor.getCollectionName();\n      // Some requests may only be fulfilled by replicas of type Replica.Type.NRT\n      boolean onlyNrtReplicas = Boolean.TRUE == req.getContext().get(ONLY_NRT_REPLICAS);\n      if (rb.slices.length == 1 && rb.slices[0] != null\n          && ( rb.slices[0].equals(ourSlice) || rb.slices[0].equals(ourCollection + \"_\" + ourSlice) )  // handle the <collection>_<slice> format\n          && cloudDescriptor.getLastPublished() == Replica.State.ACTIVE\n          && (!onlyNrtReplicas || cloudDescriptor.getReplicaType() == Replica.Type.NRT)) {\n        boolean shortCircuit = params.getBool(\"shortCircuit\", true);       // currently just a debugging parameter to check distrib search on a single node\n\n        String targetHandler = params.get(ShardParams.SHARDS_QT);\n        shortCircuit = shortCircuit && targetHandler == null;             // if a different handler is specified, don't short-circuit\n\n        if (shortCircuit) {\n          rb.isDistrib = false;\n          rb.shortCircuitedURL = ZkCoreNodeProps.getCoreUrl(zkController.getBaseUrl(), coreDescriptor.getName());\n          return;\n        }\n        // We shouldn't need to do anything to handle \"shard.rows\" since it was previously meant to be an optimization?\n      }\n\n\n      for (int i=0; i<rb.shards.length; i++) {\n        final List<String> shardUrls;\n        if (rb.shards[i] != null) {\n          shardUrls = StrUtils.splitSmart(rb.shards[i], \"|\", true);\n          replicaListTransformer.transform(shardUrls);\n        } else {\n          if (clusterState == null) {\n            clusterState =  zkController.getClusterState();\n            slices = clusterState.getSlicesMap(cloudDescriptor.getCollectionName());\n          }\n          String sliceName = rb.slices[i];\n\n          Slice slice = slices.get(sliceName);\n\n          if (slice==null) {\n            // Treat this the same as \"all servers down\" for a slice, and let things continue\n            // if partial results are acceptable\n            rb.shards[i] = \"\";\n            continue;\n            // throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"no such shard: \" + sliceName);\n          }\n          Replica shardLeader = null;\n\n          final Collection<Replica> allSliceReplicas = slice.getReplicasMap().values();\n          final List<Replica> eligibleSliceReplicas = new ArrayList<>(allSliceReplicas.size());\n          for (Replica replica : allSliceReplicas) {\n            if (!clusterState.liveNodesContain(replica.getNodeName())\n                || replica.getState() != Replica.State.ACTIVE\n                || (onlyNrtReplicas && replica.getType() == Replica.Type.PULL)) {\n              continue;\n            }\n            \n            if (onlyNrtReplicas && replica.getType() == Replica.Type.TLOG) {\n              if (shardLeader == null) {\n                try {\n                  shardLeader = zkController.getZkStateReader().getLeaderRetry(cloudDescriptor.getCollectionName(), slice.getName());\n                } catch (InterruptedException e) {\n                  throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + slice.getName() + \" in collection \" \n                      + cloudDescriptor.getCollectionName(), e);\n                } catch (SolrException e) {\n                  if (log.isDebugEnabled()) {\n                    log.debug(\"Exception finding leader for shard {} in collection {}. Collection State: {}\", \n                        slice.getName(), cloudDescriptor.getCollectionName(), zkController.getZkStateReader().getClusterState().getCollectionOrNull(cloudDescriptor.getCollectionName()));\n                  }\n                  throw e;\n                }\n              }\n              if (!replica.getName().equals(shardLeader.getName())) {\n                continue;\n              }\n            }\n            eligibleSliceReplicas.add(replica);\n          }\n\n          replicaListTransformer.transform(eligibleSliceReplicas);\n\n          shardUrls = new ArrayList<>(eligibleSliceReplicas.size());\n          for (Replica replica : eligibleSliceReplicas) {\n            String url = ZkCoreNodeProps.getCoreUrl(replica);\n            shardUrls.add(url);\n          }\n\n          if (shardUrls.isEmpty()) {\n            boolean tolerant = rb.req.getParams().getBool(ShardParams.SHARDS_TOLERANT, false);\n            if (!tolerant) {\n              // stop the check when there are no replicas available for a shard\n              throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n                  \"no servers hosting shard: \" + rb.slices[i]);\n            }\n          }\n        }\n        // And now recreate the | delimited list of equivalent servers\n        rb.shards[i] = createSliceShardsStr(shardUrls);\n      }\n    }\n    String shards_rows = params.get(ShardParams.SHARDS_ROWS);\n    if(shards_rows != null) {\n      rb.shards_rows = Integer.parseInt(shards_rows);\n    }\n    String shards_start = params.get(ShardParams.SHARDS_START);\n    if(shards_start != null) {\n      rb.shards_start = Integer.parseInt(shards_start);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void prepDistributed(ResponseBuilder rb) {\n    final SolrQueryRequest req = rb.req;\n    final SolrParams params = req.getParams();\n    final String shards = params.get(ShardParams.SHARDS);\n\n    // since the cost of grabbing cloud state is still up in the air, we grab it only\n    // if we need it.\n    ClusterState clusterState = null;\n    Map<String,Slice> slices = null;\n    CoreDescriptor coreDescriptor = req.getCore().getCoreDescriptor();\n    CloudDescriptor cloudDescriptor = coreDescriptor.getCloudDescriptor();\n    ZkController zkController = req.getCore().getCoreContainer().getZkController();\n\n    final ReplicaListTransformer replicaListTransformer = httpShardHandlerFactory.getReplicaListTransformer(req);\n\n    if (shards != null) {\n      List<String> lst = StrUtils.splitSmart(shards, \",\", true);\n      rb.shards = lst.toArray(new String[lst.size()]);\n      rb.slices = new String[rb.shards.length];\n\n      if (zkController != null) {\n        // figure out which shards are slices\n        for (int i=0; i<rb.shards.length; i++) {\n          if (rb.shards[i].indexOf('/') < 0) {\n            // this is a logical shard\n            rb.slices[i] = rb.shards[i];\n            rb.shards[i] = null;\n          }\n        }\n      }\n    } else if (zkController != null) {\n      // we weren't provided with an explicit list of slices to query via \"shards\", so use the cluster state\n\n      clusterState =  zkController.getClusterState();\n      String shardKeys =  params.get(ShardParams._ROUTE_);\n\n      // This will be the complete list of slices we need to query for this request.\n      slices = new HashMap<>();\n\n      // we need to find out what collections this request is for.\n\n      // A comma-separated list of specified collections.\n      // Eg: \"collection1,collection2,collection3\"\n      String collections = params.get(\"collection\");\n      if (collections != null) {\n        // If there were one or more collections specified in the query, split\n        // each parameter and store as a separate member of a List.\n        List<String> collectionList = StrUtils.splitSmart(collections, \",\",\n            true);\n        // In turn, retrieve the slices that cover each collection from the\n        // cloud state and add them to the Map 'slices'.\n        for (String collectionName : collectionList) {\n          // The original code produced <collection-name>_<shard-name> when the collections\n          // parameter was specified (see ClientUtils.appendMap)\n          // Is this necessary if ony one collection is specified?\n          // i.e. should we change multiCollection to collectionList.size() > 1?\n          addSlices(slices, clusterState, params, collectionName,  shardKeys, true);\n        }\n      } else {\n        // just this collection\n        String collectionName = cloudDescriptor.getCollectionName();\n        addSlices(slices, clusterState, params, collectionName,  shardKeys, false);\n      }\n\n\n      // Store the logical slices in the ResponseBuilder and create a new\n      // String array to hold the physical shards (which will be mapped\n      // later).\n      rb.slices = slices.keySet().toArray(new String[slices.size()]);\n      rb.shards = new String[rb.slices.length];\n    }\n\n    //\n    // Map slices to shards\n    //\n    if (zkController != null) {\n\n      // Are we hosting the shard that this request is for, and are we active? If so, then handle it ourselves\n      // and make it a non-distributed request.\n      String ourSlice = cloudDescriptor.getShardId();\n      String ourCollection = cloudDescriptor.getCollectionName();\n      // Some requests may only be fulfilled by replicas of type Replica.Type.NRT\n      boolean onlyNrtReplicas = Boolean.TRUE == req.getContext().get(ONLY_NRT_REPLICAS);\n      if (rb.slices.length == 1 && rb.slices[0] != null\n          && ( rb.slices[0].equals(ourSlice) || rb.slices[0].equals(ourCollection + \"_\" + ourSlice) )  // handle the <collection>_<slice> format\n          && cloudDescriptor.getLastPublished() == Replica.State.ACTIVE\n          && (!onlyNrtReplicas || cloudDescriptor.getReplicaType() == Replica.Type.NRT)) {\n        boolean shortCircuit = params.getBool(\"shortCircuit\", true);       // currently just a debugging parameter to check distrib search on a single node\n\n        String targetHandler = params.get(ShardParams.SHARDS_QT);\n        shortCircuit = shortCircuit && targetHandler == null;             // if a different handler is specified, don't short-circuit\n\n        if (shortCircuit) {\n          rb.isDistrib = false;\n          rb.shortCircuitedURL = ZkCoreNodeProps.getCoreUrl(zkController.getBaseUrl(), coreDescriptor.getName());\n          return;\n        }\n        // We shouldn't need to do anything to handle \"shard.rows\" since it was previously meant to be an optimization?\n      }\n\n\n      for (int i=0; i<rb.shards.length; i++) {\n        final List<String> shardUrls;\n        if (rb.shards[i] != null) {\n          shardUrls = StrUtils.splitSmart(rb.shards[i], \"|\", true);\n          replicaListTransformer.transform(shardUrls);\n        } else {\n          if (clusterState == null) {\n            clusterState =  zkController.getClusterState();\n            slices = clusterState.getSlicesMap(cloudDescriptor.getCollectionName());\n          }\n          String sliceName = rb.slices[i];\n\n          Slice slice = slices.get(sliceName);\n\n          if (slice==null) {\n            // Treat this the same as \"all servers down\" for a slice, and let things continue\n            // if partial results are acceptable\n            rb.shards[i] = \"\";\n            continue;\n            // throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"no such shard: \" + sliceName);\n          }\n          Replica shardLeader = null;\n\n          final Collection<Replica> allSliceReplicas = slice.getReplicasMap().values();\n          final List<Replica> eligibleSliceReplicas = new ArrayList<>(allSliceReplicas.size());\n          for (Replica replica : allSliceReplicas) {\n            if (!clusterState.liveNodesContain(replica.getNodeName())\n                || replica.getState() != Replica.State.ACTIVE\n                || (onlyNrtReplicas && replica.getType() == Replica.Type.PULL)) {\n              continue;\n            }\n            \n            if (onlyNrtReplicas && replica.getType() == Replica.Type.TLOG) {\n              if (shardLeader == null) {\n                try {\n                  shardLeader = zkController.getZkStateReader().getLeaderRetry(cloudDescriptor.getCollectionName(), slice.getName());\n                } catch (InterruptedException e) {\n                  throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + slice.getName() + \" in collection \" \n                      + cloudDescriptor.getCollectionName(), e);\n                } catch (SolrException e) {\n                  if (log.isDebugEnabled()) {\n                    log.debug(\"Exception finding leader for shard {} in collection {}. Collection State: {}\", \n                        slice.getName(), cloudDescriptor.getCollectionName(), zkController.getZkStateReader().getClusterState().getCollectionOrNull(cloudDescriptor.getCollectionName()));\n                  }\n                  throw e;\n                }\n              }\n              if (!replica.getName().equals(shardLeader.getName())) {\n                continue;\n              }\n            }\n            eligibleSliceReplicas.add(replica);\n          }\n\n          replicaListTransformer.transform(eligibleSliceReplicas);\n\n          shardUrls = new ArrayList<>(eligibleSliceReplicas.size());\n          for (Replica replica : eligibleSliceReplicas) {\n            String url = ZkCoreNodeProps.getCoreUrl(replica);\n            shardUrls.add(url);\n          }\n\n          if (shardUrls.isEmpty()) {\n            boolean tolerant = rb.req.getParams().getBool(ShardParams.SHARDS_TOLERANT, false);\n            if (!tolerant) {\n              // stop the check when there are no replicas available for a shard\n              throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n                  \"no servers hosting shard: \" + rb.slices[i]);\n            }\n          }\n        }\n        // And now recreate the | delimited list of equivalent servers\n        final StringBuilder sliceShardsStr = new StringBuilder();\n        boolean first = true;\n        for (String shardUrl : shardUrls) {\n          if (first) {\n            first = false;\n          } else {\n            sliceShardsStr.append('|');\n          }\n          sliceShardsStr.append(shardUrl);\n        }\n        rb.shards[i] = sliceShardsStr.toString();\n      }\n    }\n    String shards_rows = params.get(ShardParams.SHARDS_ROWS);\n    if(shards_rows != null) {\n      rb.shards_rows = Integer.parseInt(shards_rows);\n    }\n    String shards_start = params.get(ShardParams.SHARDS_START);\n    if(shards_start != null) {\n      rb.shards_start = Integer.parseInt(shards_start);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e73ed7d4570aa6de9e2054e7d2c5701733790f81","date":1496424870,"type":3,"author":"Tomas Fernandez Lobbe","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler#prepDistributed(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler#prepDistributed(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void prepDistributed(ResponseBuilder rb) {\n    final SolrQueryRequest req = rb.req;\n    final SolrParams params = req.getParams();\n    final String shards = params.get(ShardParams.SHARDS);\n\n    // since the cost of grabbing cloud state is still up in the air, we grab it only\n    // if we need it.\n    ClusterState clusterState = null;\n    Map<String,Slice> slices = null;\n    CoreDescriptor coreDescriptor = req.getCore().getCoreDescriptor();\n    CloudDescriptor cloudDescriptor = coreDescriptor.getCloudDescriptor();\n    ZkController zkController = req.getCore().getCoreContainer().getZkController();\n\n    final ReplicaListTransformer replicaListTransformer = httpShardHandlerFactory.getReplicaListTransformer(req);\n\n    if (shards != null) {\n      List<String> lst = StrUtils.splitSmart(shards, \",\", true);\n      rb.shards = lst.toArray(new String[lst.size()]);\n      rb.slices = new String[rb.shards.length];\n\n      if (zkController != null) {\n        // figure out which shards are slices\n        for (int i=0; i<rb.shards.length; i++) {\n          if (rb.shards[i].indexOf('/') < 0) {\n            // this is a logical shard\n            rb.slices[i] = rb.shards[i];\n            rb.shards[i] = null;\n          }\n        }\n      }\n    } else if (zkController != null) {\n      // we weren't provided with an explicit list of slices to query via \"shards\", so use the cluster state\n\n      clusterState =  zkController.getClusterState();\n      String shardKeys =  params.get(ShardParams._ROUTE_);\n\n      // This will be the complete list of slices we need to query for this request.\n      slices = new HashMap<>();\n\n      // we need to find out what collections this request is for.\n\n      // A comma-separated list of specified collections.\n      // Eg: \"collection1,collection2,collection3\"\n      String collections = params.get(\"collection\");\n      if (collections != null) {\n        // If there were one or more collections specified in the query, split\n        // each parameter and store as a separate member of a List.\n        List<String> collectionList = StrUtils.splitSmart(collections, \",\",\n            true);\n        // In turn, retrieve the slices that cover each collection from the\n        // cloud state and add them to the Map 'slices'.\n        for (String collectionName : collectionList) {\n          // The original code produced <collection-name>_<shard-name> when the collections\n          // parameter was specified (see ClientUtils.appendMap)\n          // Is this necessary if ony one collection is specified?\n          // i.e. should we change multiCollection to collectionList.size() > 1?\n          addSlices(slices, clusterState, params, collectionName,  shardKeys, true);\n        }\n      } else {\n        // just this collection\n        String collectionName = cloudDescriptor.getCollectionName();\n        addSlices(slices, clusterState, params, collectionName,  shardKeys, false);\n      }\n\n\n      // Store the logical slices in the ResponseBuilder and create a new\n      // String array to hold the physical shards (which will be mapped\n      // later).\n      rb.slices = slices.keySet().toArray(new String[slices.size()]);\n      rb.shards = new String[rb.slices.length];\n    }\n\n    //\n    // Map slices to shards\n    //\n    if (zkController != null) {\n\n      // Are we hosting the shard that this request is for, and are we active? If so, then handle it ourselves\n      // and make it a non-distributed request.\n      String ourSlice = cloudDescriptor.getShardId();\n      String ourCollection = cloudDescriptor.getCollectionName();\n      // Some requests may only be fulfilled by replicas of type Replica.Type.NRT\n      boolean onlyNrtReplicas = Boolean.TRUE == req.getContext().get(ONLY_NRT_REPLICAS);\n      if (rb.slices.length == 1 && rb.slices[0] != null\n          && ( rb.slices[0].equals(ourSlice) || rb.slices[0].equals(ourCollection + \"_\" + ourSlice) )  // handle the <collection>_<slice> format\n          && cloudDescriptor.getLastPublished() == Replica.State.ACTIVE\n          && (!onlyNrtReplicas || cloudDescriptor.getReplicaType() == Replica.Type.NRT)) {\n        boolean shortCircuit = params.getBool(\"shortCircuit\", true);       // currently just a debugging parameter to check distrib search on a single node\n\n        String targetHandler = params.get(ShardParams.SHARDS_QT);\n        shortCircuit = shortCircuit && targetHandler == null;             // if a different handler is specified, don't short-circuit\n\n        if (shortCircuit) {\n          rb.isDistrib = false;\n          rb.shortCircuitedURL = ZkCoreNodeProps.getCoreUrl(zkController.getBaseUrl(), coreDescriptor.getName());\n          return;\n        }\n        // We shouldn't need to do anything to handle \"shard.rows\" since it was previously meant to be an optimization?\n      }\n\n\n      for (int i=0; i<rb.shards.length; i++) {\n        final List<String> shardUrls;\n        if (rb.shards[i] != null) {\n          shardUrls = StrUtils.splitSmart(rb.shards[i], \"|\", true);\n          replicaListTransformer.transform(shardUrls);\n        } else {\n          if (clusterState == null) {\n            clusterState =  zkController.getClusterState();\n            slices = clusterState.getSlicesMap(cloudDescriptor.getCollectionName());\n          }\n          String sliceName = rb.slices[i];\n\n          Slice slice = slices.get(sliceName);\n\n          if (slice==null) {\n            // Treat this the same as \"all servers down\" for a slice, and let things continue\n            // if partial results are acceptable\n            rb.shards[i] = \"\";\n            continue;\n            // throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"no such shard: \" + sliceName);\n          }\n          final Predicate<Replica> isShardLeader = new Predicate<Replica>() {\n            private Replica shardLeader = null;\n\n            @Override\n            public boolean test(Replica replica) {\n              if (shardLeader == null) {\n                try {\n                  shardLeader = zkController.getZkStateReader().getLeaderRetry(cloudDescriptor.getCollectionName(), slice.getName());\n                } catch (InterruptedException e) {\n                  throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + slice.getName() + \" in collection \" \n                      + cloudDescriptor.getCollectionName(), e);\n                } catch (SolrException e) {\n                  if (log.isDebugEnabled()) {\n                    log.debug(\"Exception finding leader for shard {} in collection {}. Collection State: {}\", \n                        slice.getName(), cloudDescriptor.getCollectionName(), zkController.getZkStateReader().getClusterState().getCollectionOrNull(cloudDescriptor.getCollectionName()));\n                  }\n                  throw e;\n                }\n              }\n              return replica.getName().equals(shardLeader.getName());\n            }\n          };\n\n          final List<Replica> eligibleSliceReplicas = collectEligibleReplicas(slice, clusterState, onlyNrtReplicas, isShardLeader);\n\n          replicaListTransformer.transform(eligibleSliceReplicas);\n\n          shardUrls = new ArrayList<>(eligibleSliceReplicas.size());\n          for (Replica replica : eligibleSliceReplicas) {\n            String url = ZkCoreNodeProps.getCoreUrl(replica);\n            shardUrls.add(url);\n          }\n\n          if (shardUrls.isEmpty()) {\n            boolean tolerant = rb.req.getParams().getBool(ShardParams.SHARDS_TOLERANT, false);\n            if (!tolerant) {\n              // stop the check when there are no replicas available for a shard\n              throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n                  \"no servers hosting shard: \" + rb.slices[i]);\n            }\n          }\n        }\n        // And now recreate the | delimited list of equivalent servers\n        rb.shards[i] = createSliceShardsStr(shardUrls);\n      }\n    }\n    String shards_rows = params.get(ShardParams.SHARDS_ROWS);\n    if(shards_rows != null) {\n      rb.shards_rows = Integer.parseInt(shards_rows);\n    }\n    String shards_start = params.get(ShardParams.SHARDS_START);\n    if(shards_start != null) {\n      rb.shards_start = Integer.parseInt(shards_start);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void prepDistributed(ResponseBuilder rb) {\n    final SolrQueryRequest req = rb.req;\n    final SolrParams params = req.getParams();\n    final String shards = params.get(ShardParams.SHARDS);\n\n    // since the cost of grabbing cloud state is still up in the air, we grab it only\n    // if we need it.\n    ClusterState clusterState = null;\n    Map<String,Slice> slices = null;\n    CoreDescriptor coreDescriptor = req.getCore().getCoreDescriptor();\n    CloudDescriptor cloudDescriptor = coreDescriptor.getCloudDescriptor();\n    ZkController zkController = req.getCore().getCoreContainer().getZkController();\n\n    final ReplicaListTransformer replicaListTransformer = httpShardHandlerFactory.getReplicaListTransformer(req);\n\n    if (shards != null) {\n      List<String> lst = StrUtils.splitSmart(shards, \",\", true);\n      rb.shards = lst.toArray(new String[lst.size()]);\n      rb.slices = new String[rb.shards.length];\n\n      if (zkController != null) {\n        // figure out which shards are slices\n        for (int i=0; i<rb.shards.length; i++) {\n          if (rb.shards[i].indexOf('/') < 0) {\n            // this is a logical shard\n            rb.slices[i] = rb.shards[i];\n            rb.shards[i] = null;\n          }\n        }\n      }\n    } else if (zkController != null) {\n      // we weren't provided with an explicit list of slices to query via \"shards\", so use the cluster state\n\n      clusterState =  zkController.getClusterState();\n      String shardKeys =  params.get(ShardParams._ROUTE_);\n\n      // This will be the complete list of slices we need to query for this request.\n      slices = new HashMap<>();\n\n      // we need to find out what collections this request is for.\n\n      // A comma-separated list of specified collections.\n      // Eg: \"collection1,collection2,collection3\"\n      String collections = params.get(\"collection\");\n      if (collections != null) {\n        // If there were one or more collections specified in the query, split\n        // each parameter and store as a separate member of a List.\n        List<String> collectionList = StrUtils.splitSmart(collections, \",\",\n            true);\n        // In turn, retrieve the slices that cover each collection from the\n        // cloud state and add them to the Map 'slices'.\n        for (String collectionName : collectionList) {\n          // The original code produced <collection-name>_<shard-name> when the collections\n          // parameter was specified (see ClientUtils.appendMap)\n          // Is this necessary if ony one collection is specified?\n          // i.e. should we change multiCollection to collectionList.size() > 1?\n          addSlices(slices, clusterState, params, collectionName,  shardKeys, true);\n        }\n      } else {\n        // just this collection\n        String collectionName = cloudDescriptor.getCollectionName();\n        addSlices(slices, clusterState, params, collectionName,  shardKeys, false);\n      }\n\n\n      // Store the logical slices in the ResponseBuilder and create a new\n      // String array to hold the physical shards (which will be mapped\n      // later).\n      rb.slices = slices.keySet().toArray(new String[slices.size()]);\n      rb.shards = new String[rb.slices.length];\n    }\n\n    //\n    // Map slices to shards\n    //\n    if (zkController != null) {\n\n      // Are we hosting the shard that this request is for, and are we active? If so, then handle it ourselves\n      // and make it a non-distributed request.\n      String ourSlice = cloudDescriptor.getShardId();\n      String ourCollection = cloudDescriptor.getCollectionName();\n      // Some requests may only be fulfilled by replicas of type Replica.Type.NRT\n      boolean onlyNrtReplicas = Boolean.TRUE == req.getContext().get(ONLY_NRT_REPLICAS);\n      if (rb.slices.length == 1 && rb.slices[0] != null\n          && ( rb.slices[0].equals(ourSlice) || rb.slices[0].equals(ourCollection + \"_\" + ourSlice) )  // handle the <collection>_<slice> format\n          && cloudDescriptor.getLastPublished() == Replica.State.ACTIVE\n          && (!onlyNrtReplicas || cloudDescriptor.getReplicaType() == Replica.Type.NRT)) {\n        boolean shortCircuit = params.getBool(\"shortCircuit\", true);       // currently just a debugging parameter to check distrib search on a single node\n\n        String targetHandler = params.get(ShardParams.SHARDS_QT);\n        shortCircuit = shortCircuit && targetHandler == null;             // if a different handler is specified, don't short-circuit\n\n        if (shortCircuit) {\n          rb.isDistrib = false;\n          rb.shortCircuitedURL = ZkCoreNodeProps.getCoreUrl(zkController.getBaseUrl(), coreDescriptor.getName());\n          return;\n        }\n        // We shouldn't need to do anything to handle \"shard.rows\" since it was previously meant to be an optimization?\n      }\n\n\n      for (int i=0; i<rb.shards.length; i++) {\n        final List<String> shardUrls;\n        if (rb.shards[i] != null) {\n          shardUrls = StrUtils.splitSmart(rb.shards[i], \"|\", true);\n          replicaListTransformer.transform(shardUrls);\n        } else {\n          if (clusterState == null) {\n            clusterState =  zkController.getClusterState();\n            slices = clusterState.getSlicesMap(cloudDescriptor.getCollectionName());\n          }\n          String sliceName = rb.slices[i];\n\n          Slice slice = slices.get(sliceName);\n\n          if (slice==null) {\n            // Treat this the same as \"all servers down\" for a slice, and let things continue\n            // if partial results are acceptable\n            rb.shards[i] = \"\";\n            continue;\n            // throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"no such shard: \" + sliceName);\n          }\n          Replica shardLeader = null;\n\n          final Collection<Replica> allSliceReplicas = slice.getReplicasMap().values();\n          final List<Replica> eligibleSliceReplicas = new ArrayList<>(allSliceReplicas.size());\n          for (Replica replica : allSliceReplicas) {\n            if (!clusterState.liveNodesContain(replica.getNodeName())\n                || replica.getState() != Replica.State.ACTIVE\n                || (onlyNrtReplicas && replica.getType() == Replica.Type.PULL)) {\n              continue;\n            }\n            \n            if (onlyNrtReplicas && replica.getType() == Replica.Type.TLOG) {\n              if (shardLeader == null) {\n                try {\n                  shardLeader = zkController.getZkStateReader().getLeaderRetry(cloudDescriptor.getCollectionName(), slice.getName());\n                } catch (InterruptedException e) {\n                  throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + slice.getName() + \" in collection \" \n                      + cloudDescriptor.getCollectionName(), e);\n                } catch (SolrException e) {\n                  if (log.isDebugEnabled()) {\n                    log.debug(\"Exception finding leader for shard {} in collection {}. Collection State: {}\", \n                        slice.getName(), cloudDescriptor.getCollectionName(), zkController.getZkStateReader().getClusterState().getCollectionOrNull(cloudDescriptor.getCollectionName()));\n                  }\n                  throw e;\n                }\n              }\n              if (!replica.getName().equals(shardLeader.getName())) {\n                continue;\n              }\n            }\n            eligibleSliceReplicas.add(replica);\n          }\n\n          replicaListTransformer.transform(eligibleSliceReplicas);\n\n          shardUrls = new ArrayList<>(eligibleSliceReplicas.size());\n          for (Replica replica : eligibleSliceReplicas) {\n            String url = ZkCoreNodeProps.getCoreUrl(replica);\n            shardUrls.add(url);\n          }\n\n          if (shardUrls.isEmpty()) {\n            boolean tolerant = rb.req.getParams().getBool(ShardParams.SHARDS_TOLERANT, false);\n            if (!tolerant) {\n              // stop the check when there are no replicas available for a shard\n              throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n                  \"no servers hosting shard: \" + rb.slices[i]);\n            }\n          }\n        }\n        // And now recreate the | delimited list of equivalent servers\n        rb.shards[i] = createSliceShardsStr(shardUrls);\n      }\n    }\n    String shards_rows = params.get(ShardParams.SHARDS_ROWS);\n    if(shards_rows != null) {\n      rb.shards_rows = Integer.parseInt(shards_rows);\n    }\n    String shards_start = params.get(ShardParams.SHARDS_START);\n    if(shards_start != null) {\n      rb.shards_start = Integer.parseInt(shards_start);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e9017cf144952056066919f1ebc7897ff9bd71b1","date":1496757600,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler#prepDistributed(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler#prepDistributed(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void prepDistributed(ResponseBuilder rb) {\n    final SolrQueryRequest req = rb.req;\n    final SolrParams params = req.getParams();\n    final String shards = params.get(ShardParams.SHARDS);\n\n    // since the cost of grabbing cloud state is still up in the air, we grab it only\n    // if we need it.\n    ClusterState clusterState = null;\n    Map<String,Slice> slices = null;\n    CoreDescriptor coreDescriptor = req.getCore().getCoreDescriptor();\n    CloudDescriptor cloudDescriptor = coreDescriptor.getCloudDescriptor();\n    ZkController zkController = req.getCore().getCoreContainer().getZkController();\n\n    final ReplicaListTransformer replicaListTransformer = httpShardHandlerFactory.getReplicaListTransformer(req);\n\n    if (shards != null) {\n      List<String> lst = StrUtils.splitSmart(shards, \",\", true);\n      rb.shards = lst.toArray(new String[lst.size()]);\n      rb.slices = new String[rb.shards.length];\n\n      if (zkController != null) {\n        // figure out which shards are slices\n        for (int i=0; i<rb.shards.length; i++) {\n          if (rb.shards[i].indexOf('/') < 0) {\n            // this is a logical shard\n            rb.slices[i] = rb.shards[i];\n            rb.shards[i] = null;\n          }\n        }\n      }\n    } else if (zkController != null) {\n      // we weren't provided with an explicit list of slices to query via \"shards\", so use the cluster state\n\n      clusterState =  zkController.getClusterState();\n      String shardKeys =  params.get(ShardParams._ROUTE_);\n\n      // This will be the complete list of slices we need to query for this request.\n      slices = new HashMap<>();\n\n      // we need to find out what collections this request is for.\n\n      // A comma-separated list of specified collections.\n      // Eg: \"collection1,collection2,collection3\"\n      String collections = params.get(\"collection\");\n      if (collections != null) {\n        // If there were one or more collections specified in the query, split\n        // each parameter and store as a separate member of a List.\n        List<String> collectionList = StrUtils.splitSmart(collections, \",\",\n            true);\n        // In turn, retrieve the slices that cover each collection from the\n        // cloud state and add them to the Map 'slices'.\n        for (String collectionName : collectionList) {\n          // The original code produced <collection-name>_<shard-name> when the collections\n          // parameter was specified (see ClientUtils.appendMap)\n          // Is this necessary if ony one collection is specified?\n          // i.e. should we change multiCollection to collectionList.size() > 1?\n          addSlices(slices, clusterState, params, collectionName,  shardKeys, true);\n        }\n      } else {\n        // just this collection\n        String collectionName = cloudDescriptor.getCollectionName();\n        addSlices(slices, clusterState, params, collectionName,  shardKeys, false);\n      }\n\n\n      // Store the logical slices in the ResponseBuilder and create a new\n      // String array to hold the physical shards (which will be mapped\n      // later).\n      rb.slices = slices.keySet().toArray(new String[slices.size()]);\n      rb.shards = new String[rb.slices.length];\n    }\n\n    //\n    // Map slices to shards\n    //\n    if (zkController != null) {\n\n      // Are we hosting the shard that this request is for, and are we active? If so, then handle it ourselves\n      // and make it a non-distributed request.\n      String ourSlice = cloudDescriptor.getShardId();\n      String ourCollection = cloudDescriptor.getCollectionName();\n      // Some requests may only be fulfilled by replicas of type Replica.Type.NRT\n      boolean onlyNrtReplicas = Boolean.TRUE == req.getContext().get(ONLY_NRT_REPLICAS);\n      if (rb.slices.length == 1 && rb.slices[0] != null\n          && ( rb.slices[0].equals(ourSlice) || rb.slices[0].equals(ourCollection + \"_\" + ourSlice) )  // handle the <collection>_<slice> format\n          && cloudDescriptor.getLastPublished() == Replica.State.ACTIVE\n          && (!onlyNrtReplicas || cloudDescriptor.getReplicaType() == Replica.Type.NRT)) {\n        boolean shortCircuit = params.getBool(\"shortCircuit\", true);       // currently just a debugging parameter to check distrib search on a single node\n\n        String targetHandler = params.get(ShardParams.SHARDS_QT);\n        shortCircuit = shortCircuit && targetHandler == null;             // if a different handler is specified, don't short-circuit\n\n        if (shortCircuit) {\n          rb.isDistrib = false;\n          rb.shortCircuitedURL = ZkCoreNodeProps.getCoreUrl(zkController.getBaseUrl(), coreDescriptor.getName());\n          return;\n        }\n        // We shouldn't need to do anything to handle \"shard.rows\" since it was previously meant to be an optimization?\n      }\n\n\n      for (int i=0; i<rb.shards.length; i++) {\n        final List<String> shardUrls;\n        if (rb.shards[i] != null) {\n          shardUrls = StrUtils.splitSmart(rb.shards[i], \"|\", true);\n          replicaListTransformer.transform(shardUrls);\n        } else {\n          if (clusterState == null) {\n            clusterState =  zkController.getClusterState();\n            slices = clusterState.getSlicesMap(cloudDescriptor.getCollectionName());\n          }\n          String sliceName = rb.slices[i];\n\n          Slice slice = slices.get(sliceName);\n\n          if (slice==null) {\n            // Treat this the same as \"all servers down\" for a slice, and let things continue\n            // if partial results are acceptable\n            rb.shards[i] = \"\";\n            continue;\n            // throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"no such shard: \" + sliceName);\n          }\n          final Predicate<Replica> isShardLeader = new Predicate<Replica>() {\n            private Replica shardLeader = null;\n\n            @Override\n            public boolean test(Replica replica) {\n              if (shardLeader == null) {\n                try {\n                  shardLeader = zkController.getZkStateReader().getLeaderRetry(cloudDescriptor.getCollectionName(), slice.getName());\n                } catch (InterruptedException e) {\n                  throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + slice.getName() + \" in collection \" \n                      + cloudDescriptor.getCollectionName(), e);\n                } catch (SolrException e) {\n                  if (log.isDebugEnabled()) {\n                    log.debug(\"Exception finding leader for shard {} in collection {}. Collection State: {}\", \n                        slice.getName(), cloudDescriptor.getCollectionName(), zkController.getZkStateReader().getClusterState().getCollectionOrNull(cloudDescriptor.getCollectionName()));\n                  }\n                  throw e;\n                }\n              }\n              return replica.getName().equals(shardLeader.getName());\n            }\n          };\n\n          final List<Replica> eligibleSliceReplicas = collectEligibleReplicas(slice, clusterState, onlyNrtReplicas, isShardLeader);\n\n          replicaListTransformer.transform(eligibleSliceReplicas);\n\n          shardUrls = new ArrayList<>(eligibleSliceReplicas.size());\n          for (Replica replica : eligibleSliceReplicas) {\n            String url = ZkCoreNodeProps.getCoreUrl(replica);\n            shardUrls.add(url);\n          }\n\n          if (shardUrls.isEmpty()) {\n            boolean tolerant = rb.req.getParams().getBool(ShardParams.SHARDS_TOLERANT, false);\n            if (!tolerant) {\n              // stop the check when there are no replicas available for a shard\n              throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n                  \"no servers hosting shard: \" + rb.slices[i]);\n            }\n          }\n        }\n        // And now recreate the | delimited list of equivalent servers\n        rb.shards[i] = createSliceShardsStr(shardUrls);\n      }\n    }\n    String shards_rows = params.get(ShardParams.SHARDS_ROWS);\n    if(shards_rows != null) {\n      rb.shards_rows = Integer.parseInt(shards_rows);\n    }\n    String shards_start = params.get(ShardParams.SHARDS_START);\n    if(shards_start != null) {\n      rb.shards_start = Integer.parseInt(shards_start);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void prepDistributed(ResponseBuilder rb) {\n    final SolrQueryRequest req = rb.req;\n    final SolrParams params = req.getParams();\n    final String shards = params.get(ShardParams.SHARDS);\n\n    // since the cost of grabbing cloud state is still up in the air, we grab it only\n    // if we need it.\n    ClusterState clusterState = null;\n    Map<String,Slice> slices = null;\n    CoreDescriptor coreDescriptor = req.getCore().getCoreDescriptor();\n    CloudDescriptor cloudDescriptor = coreDescriptor.getCloudDescriptor();\n    ZkController zkController = req.getCore().getCoreContainer().getZkController();\n\n    final ReplicaListTransformer replicaListTransformer = httpShardHandlerFactory.getReplicaListTransformer(req);\n\n    if (shards != null) {\n      List<String> lst = StrUtils.splitSmart(shards, \",\", true);\n      rb.shards = lst.toArray(new String[lst.size()]);\n      rb.slices = new String[rb.shards.length];\n\n      if (zkController != null) {\n        // figure out which shards are slices\n        for (int i=0; i<rb.shards.length; i++) {\n          if (rb.shards[i].indexOf('/') < 0) {\n            // this is a logical shard\n            rb.slices[i] = rb.shards[i];\n            rb.shards[i] = null;\n          }\n        }\n      }\n    } else if (zkController != null) {\n      // we weren't provided with an explicit list of slices to query via \"shards\", so use the cluster state\n\n      clusterState =  zkController.getClusterState();\n      String shardKeys =  params.get(ShardParams._ROUTE_);\n\n      // This will be the complete list of slices we need to query for this request.\n      slices = new HashMap<>();\n\n      // we need to find out what collections this request is for.\n\n      // A comma-separated list of specified collections.\n      // Eg: \"collection1,collection2,collection3\"\n      String collections = params.get(\"collection\");\n      if (collections != null) {\n        // If there were one or more collections specified in the query, split\n        // each parameter and store as a separate member of a List.\n        List<String> collectionList = StrUtils.splitSmart(collections, \",\",\n            true);\n        // In turn, retrieve the slices that cover each collection from the\n        // cloud state and add them to the Map 'slices'.\n        for (String collectionName : collectionList) {\n          // The original code produced <collection-name>_<shard-name> when the collections\n          // parameter was specified (see ClientUtils.appendMap)\n          // Is this necessary if ony one collection is specified?\n          // i.e. should we change multiCollection to collectionList.size() > 1?\n          addSlices(slices, clusterState, params, collectionName,  shardKeys, true);\n        }\n      } else {\n        // just this collection\n        String collectionName = cloudDescriptor.getCollectionName();\n        addSlices(slices, clusterState, params, collectionName,  shardKeys, false);\n      }\n\n\n      // Store the logical slices in the ResponseBuilder and create a new\n      // String array to hold the physical shards (which will be mapped\n      // later).\n      rb.slices = slices.keySet().toArray(new String[slices.size()]);\n      rb.shards = new String[rb.slices.length];\n    }\n\n    //\n    // Map slices to shards\n    //\n    if (zkController != null) {\n\n      // Are we hosting the shard that this request is for, and are we active? If so, then handle it ourselves\n      // and make it a non-distributed request.\n      String ourSlice = cloudDescriptor.getShardId();\n      String ourCollection = cloudDescriptor.getCollectionName();\n      if (rb.slices.length == 1 && rb.slices[0] != null\n          && ( rb.slices[0].equals(ourSlice) || rb.slices[0].equals(ourCollection + \"_\" + ourSlice) )  // handle the <collection>_<slice> format\n          && cloudDescriptor.getLastPublished() == Replica.State.ACTIVE) {\n        boolean shortCircuit = params.getBool(\"shortCircuit\", true);       // currently just a debugging parameter to check distrib search on a single node\n\n        String targetHandler = params.get(ShardParams.SHARDS_QT);\n        shortCircuit = shortCircuit && targetHandler == null;             // if a different handler is specified, don't short-circuit\n\n        if (shortCircuit) {\n          rb.isDistrib = false;\n          rb.shortCircuitedURL = ZkCoreNodeProps.getCoreUrl(zkController.getBaseUrl(), coreDescriptor.getName());\n          return;\n        }\n        // We shouldn't need to do anything to handle \"shard.rows\" since it was previously meant to be an optimization?\n      }\n\n\n      for (int i=0; i<rb.shards.length; i++) {\n        final List<String> shardUrls;\n        if (rb.shards[i] != null) {\n          shardUrls = StrUtils.splitSmart(rb.shards[i], \"|\", true);\n          replicaListTransformer.transform(shardUrls);\n        } else {\n          if (clusterState == null) {\n            clusterState =  zkController.getClusterState();\n            slices = clusterState.getSlicesMap(cloudDescriptor.getCollectionName());\n          }\n          String sliceName = rb.slices[i];\n\n          Slice slice = slices.get(sliceName);\n\n          if (slice==null) {\n            // Treat this the same as \"all servers down\" for a slice, and let things continue\n            // if partial results are acceptable\n            rb.shards[i] = \"\";\n            continue;\n            // throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"no such shard: \" + sliceName);\n          }\n\n          final Collection<Replica> allSliceReplicas = slice.getReplicasMap().values();\n          final List<Replica> eligibleSliceReplicas = new ArrayList<>(allSliceReplicas.size());\n          for (Replica replica : allSliceReplicas) {\n            if (!clusterState.liveNodesContain(replica.getNodeName())\n                || replica.getState() != Replica.State.ACTIVE) {\n              continue;\n            }\n            eligibleSliceReplicas.add(replica);\n          }\n\n          replicaListTransformer.transform(eligibleSliceReplicas);\n\n          shardUrls = new ArrayList<>(eligibleSliceReplicas.size());\n          for (Replica replica : eligibleSliceReplicas) {\n            String url = ZkCoreNodeProps.getCoreUrl(replica);\n            shardUrls.add(url);\n          }\n\n          if (shardUrls.isEmpty()) {\n            boolean tolerant = rb.req.getParams().getBool(ShardParams.SHARDS_TOLERANT, false);\n            if (!tolerant) {\n              // stop the check when there are no replicas available for a shard\n              throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n                  \"no servers hosting shard: \" + rb.slices[i]);\n            }\n          }\n        }\n        // And now recreate the | delimited list of equivalent servers\n        final StringBuilder sliceShardsStr = new StringBuilder();\n        boolean first = true;\n        for (String shardUrl : shardUrls) {\n          if (first) {\n            first = false;\n          } else {\n            sliceShardsStr.append('|');\n          }\n          sliceShardsStr.append(shardUrl);\n        }\n        rb.shards[i] = sliceShardsStr.toString();\n      }\n    }\n    String shards_rows = params.get(ShardParams.SHARDS_ROWS);\n    if(shards_rows != null) {\n      rb.shards_rows = Integer.parseInt(shards_rows);\n    }\n    String shards_start = params.get(ShardParams.SHARDS_START);\n    if(shards_start != null) {\n      rb.shards_start = Integer.parseInt(shards_start);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ba8018c05af07413630c7437681d62d5f001a9db","date":1496838473,"type":3,"author":"Christine Poerschke","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler#prepDistributed(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler#prepDistributed(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void prepDistributed(ResponseBuilder rb) {\n    final SolrQueryRequest req = rb.req;\n    final SolrParams params = req.getParams();\n    final String shards = params.get(ShardParams.SHARDS);\n\n    // since the cost of grabbing cloud state is still up in the air, we grab it only\n    // if we need it.\n    ClusterState clusterState = null;\n    Map<String,Slice> slices = null;\n    CoreDescriptor coreDescriptor = req.getCore().getCoreDescriptor();\n    CloudDescriptor cloudDescriptor = coreDescriptor.getCloudDescriptor();\n    ZkController zkController = req.getCore().getCoreContainer().getZkController();\n\n    final ReplicaListTransformer replicaListTransformer = httpShardHandlerFactory.getReplicaListTransformer(req);\n\n    if (shards != null) {\n      List<String> lst = StrUtils.splitSmart(shards, \",\", true);\n      rb.shards = lst.toArray(new String[lst.size()]);\n      rb.slices = new String[rb.shards.length];\n\n      if (zkController != null) {\n        // figure out which shards are slices\n        for (int i=0; i<rb.shards.length; i++) {\n          if (rb.shards[i].indexOf('/') < 0) {\n            // this is a logical shard\n            rb.slices[i] = rb.shards[i];\n            rb.shards[i] = null;\n          }\n        }\n      }\n    } else if (zkController != null) {\n      // we weren't provided with an explicit list of slices to query via \"shards\", so use the cluster state\n\n      clusterState =  zkController.getClusterState();\n      String shardKeys =  params.get(ShardParams._ROUTE_);\n\n      // This will be the complete list of slices we need to query for this request.\n      slices = new HashMap<>();\n\n      // we need to find out what collections this request is for.\n\n      // A comma-separated list of specified collections.\n      // Eg: \"collection1,collection2,collection3\"\n      String collections = params.get(\"collection\");\n      if (collections != null) {\n        // If there were one or more collections specified in the query, split\n        // each parameter and store as a separate member of a List.\n        List<String> collectionList = StrUtils.splitSmart(collections, \",\",\n            true);\n        // In turn, retrieve the slices that cover each collection from the\n        // cloud state and add them to the Map 'slices'.\n        for (String collectionName : collectionList) {\n          // The original code produced <collection-name>_<shard-name> when the collections\n          // parameter was specified (see ClientUtils.appendMap)\n          // Is this necessary if ony one collection is specified?\n          // i.e. should we change multiCollection to collectionList.size() > 1?\n          addSlices(slices, clusterState, params, collectionName,  shardKeys, true);\n        }\n      } else {\n        // just this collection\n        String collectionName = cloudDescriptor.getCollectionName();\n        addSlices(slices, clusterState, params, collectionName,  shardKeys, false);\n      }\n\n\n      // Store the logical slices in the ResponseBuilder and create a new\n      // String array to hold the physical shards (which will be mapped\n      // later).\n      rb.slices = slices.keySet().toArray(new String[slices.size()]);\n      rb.shards = new String[rb.slices.length];\n    }\n\n    //\n    // Map slices to shards\n    //\n    if (zkController != null) {\n\n      // Are we hosting the shard that this request is for, and are we active? If so, then handle it ourselves\n      // and make it a non-distributed request.\n      String ourSlice = cloudDescriptor.getShardId();\n      String ourCollection = cloudDescriptor.getCollectionName();\n      // Some requests may only be fulfilled by replicas of type Replica.Type.NRT\n      boolean onlyNrtReplicas = Boolean.TRUE == req.getContext().get(ONLY_NRT_REPLICAS);\n      if (rb.slices.length == 1 && rb.slices[0] != null\n          && ( rb.slices[0].equals(ourSlice) || rb.slices[0].equals(ourCollection + \"_\" + ourSlice) )  // handle the <collection>_<slice> format\n          && cloudDescriptor.getLastPublished() == Replica.State.ACTIVE\n          && (!onlyNrtReplicas || cloudDescriptor.getReplicaType() == Replica.Type.NRT)) {\n        boolean shortCircuit = params.getBool(\"shortCircuit\", true);       // currently just a debugging parameter to check distrib search on a single node\n\n        String targetHandler = params.get(ShardParams.SHARDS_QT);\n        shortCircuit = shortCircuit && targetHandler == null;             // if a different handler is specified, don't short-circuit\n\n        if (shortCircuit) {\n          rb.isDistrib = false;\n          rb.shortCircuitedURL = ZkCoreNodeProps.getCoreUrl(zkController.getBaseUrl(), coreDescriptor.getName());\n          return;\n        }\n        // We shouldn't need to do anything to handle \"shard.rows\" since it was previously meant to be an optimization?\n      }\n\n\n      for (int i=0; i<rb.shards.length; i++) {\n        if (rb.shards[i] != null) {\n          final List<String> shardUrls = StrUtils.splitSmart(rb.shards[i], \"|\", true);\n          replicaListTransformer.transform(shardUrls);\n          // And now recreate the | delimited list of equivalent servers\n          rb.shards[i] = createSliceShardsStr(shardUrls);\n        } else {\n          if (clusterState == null) {\n            clusterState =  zkController.getClusterState();\n            slices = clusterState.getSlicesMap(cloudDescriptor.getCollectionName());\n          }\n          String sliceName = rb.slices[i];\n\n          Slice slice = slices.get(sliceName);\n\n          if (slice==null) {\n            // Treat this the same as \"all servers down\" for a slice, and let things continue\n            // if partial results are acceptable\n            rb.shards[i] = \"\";\n            continue;\n            // throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"no such shard: \" + sliceName);\n          }\n          final Predicate<Replica> isShardLeader = new Predicate<Replica>() {\n            private Replica shardLeader = null;\n\n            @Override\n            public boolean test(Replica replica) {\n              if (shardLeader == null) {\n                try {\n                  shardLeader = zkController.getZkStateReader().getLeaderRetry(cloudDescriptor.getCollectionName(), slice.getName());\n                } catch (InterruptedException e) {\n                  throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + slice.getName() + \" in collection \" \n                      + cloudDescriptor.getCollectionName(), e);\n                } catch (SolrException e) {\n                  if (log.isDebugEnabled()) {\n                    log.debug(\"Exception finding leader for shard {} in collection {}. Collection State: {}\", \n                        slice.getName(), cloudDescriptor.getCollectionName(), zkController.getZkStateReader().getClusterState().getCollectionOrNull(cloudDescriptor.getCollectionName()));\n                  }\n                  throw e;\n                }\n              }\n              return replica.getName().equals(shardLeader.getName());\n            }\n          };\n\n          final List<Replica> eligibleSliceReplicas = collectEligibleReplicas(slice, clusterState, onlyNrtReplicas, isShardLeader);\n\n          final List<String> shardUrls = transformReplicasToShardUrls(replicaListTransformer, eligibleSliceReplicas);\n\n          // And now recreate the | delimited list of equivalent servers\n          final String sliceShardsStr = createSliceShardsStr(shardUrls);\n          if (sliceShardsStr.isEmpty()) {\n            boolean tolerant = rb.req.getParams().getBool(ShardParams.SHARDS_TOLERANT, false);\n            if (!tolerant) {\n              // stop the check when there are no replicas available for a shard\n              throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n                  \"no servers hosting shard: \" + rb.slices[i]);\n            }\n          }\n          rb.shards[i] = sliceShardsStr;\n        }\n      }\n    }\n    String shards_rows = params.get(ShardParams.SHARDS_ROWS);\n    if(shards_rows != null) {\n      rb.shards_rows = Integer.parseInt(shards_rows);\n    }\n    String shards_start = params.get(ShardParams.SHARDS_START);\n    if(shards_start != null) {\n      rb.shards_start = Integer.parseInt(shards_start);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void prepDistributed(ResponseBuilder rb) {\n    final SolrQueryRequest req = rb.req;\n    final SolrParams params = req.getParams();\n    final String shards = params.get(ShardParams.SHARDS);\n\n    // since the cost of grabbing cloud state is still up in the air, we grab it only\n    // if we need it.\n    ClusterState clusterState = null;\n    Map<String,Slice> slices = null;\n    CoreDescriptor coreDescriptor = req.getCore().getCoreDescriptor();\n    CloudDescriptor cloudDescriptor = coreDescriptor.getCloudDescriptor();\n    ZkController zkController = req.getCore().getCoreContainer().getZkController();\n\n    final ReplicaListTransformer replicaListTransformer = httpShardHandlerFactory.getReplicaListTransformer(req);\n\n    if (shards != null) {\n      List<String> lst = StrUtils.splitSmart(shards, \",\", true);\n      rb.shards = lst.toArray(new String[lst.size()]);\n      rb.slices = new String[rb.shards.length];\n\n      if (zkController != null) {\n        // figure out which shards are slices\n        for (int i=0; i<rb.shards.length; i++) {\n          if (rb.shards[i].indexOf('/') < 0) {\n            // this is a logical shard\n            rb.slices[i] = rb.shards[i];\n            rb.shards[i] = null;\n          }\n        }\n      }\n    } else if (zkController != null) {\n      // we weren't provided with an explicit list of slices to query via \"shards\", so use the cluster state\n\n      clusterState =  zkController.getClusterState();\n      String shardKeys =  params.get(ShardParams._ROUTE_);\n\n      // This will be the complete list of slices we need to query for this request.\n      slices = new HashMap<>();\n\n      // we need to find out what collections this request is for.\n\n      // A comma-separated list of specified collections.\n      // Eg: \"collection1,collection2,collection3\"\n      String collections = params.get(\"collection\");\n      if (collections != null) {\n        // If there were one or more collections specified in the query, split\n        // each parameter and store as a separate member of a List.\n        List<String> collectionList = StrUtils.splitSmart(collections, \",\",\n            true);\n        // In turn, retrieve the slices that cover each collection from the\n        // cloud state and add them to the Map 'slices'.\n        for (String collectionName : collectionList) {\n          // The original code produced <collection-name>_<shard-name> when the collections\n          // parameter was specified (see ClientUtils.appendMap)\n          // Is this necessary if ony one collection is specified?\n          // i.e. should we change multiCollection to collectionList.size() > 1?\n          addSlices(slices, clusterState, params, collectionName,  shardKeys, true);\n        }\n      } else {\n        // just this collection\n        String collectionName = cloudDescriptor.getCollectionName();\n        addSlices(slices, clusterState, params, collectionName,  shardKeys, false);\n      }\n\n\n      // Store the logical slices in the ResponseBuilder and create a new\n      // String array to hold the physical shards (which will be mapped\n      // later).\n      rb.slices = slices.keySet().toArray(new String[slices.size()]);\n      rb.shards = new String[rb.slices.length];\n    }\n\n    //\n    // Map slices to shards\n    //\n    if (zkController != null) {\n\n      // Are we hosting the shard that this request is for, and are we active? If so, then handle it ourselves\n      // and make it a non-distributed request.\n      String ourSlice = cloudDescriptor.getShardId();\n      String ourCollection = cloudDescriptor.getCollectionName();\n      // Some requests may only be fulfilled by replicas of type Replica.Type.NRT\n      boolean onlyNrtReplicas = Boolean.TRUE == req.getContext().get(ONLY_NRT_REPLICAS);\n      if (rb.slices.length == 1 && rb.slices[0] != null\n          && ( rb.slices[0].equals(ourSlice) || rb.slices[0].equals(ourCollection + \"_\" + ourSlice) )  // handle the <collection>_<slice> format\n          && cloudDescriptor.getLastPublished() == Replica.State.ACTIVE\n          && (!onlyNrtReplicas || cloudDescriptor.getReplicaType() == Replica.Type.NRT)) {\n        boolean shortCircuit = params.getBool(\"shortCircuit\", true);       // currently just a debugging parameter to check distrib search on a single node\n\n        String targetHandler = params.get(ShardParams.SHARDS_QT);\n        shortCircuit = shortCircuit && targetHandler == null;             // if a different handler is specified, don't short-circuit\n\n        if (shortCircuit) {\n          rb.isDistrib = false;\n          rb.shortCircuitedURL = ZkCoreNodeProps.getCoreUrl(zkController.getBaseUrl(), coreDescriptor.getName());\n          return;\n        }\n        // We shouldn't need to do anything to handle \"shard.rows\" since it was previously meant to be an optimization?\n      }\n\n\n      for (int i=0; i<rb.shards.length; i++) {\n        final List<String> shardUrls;\n        if (rb.shards[i] != null) {\n          shardUrls = StrUtils.splitSmart(rb.shards[i], \"|\", true);\n          replicaListTransformer.transform(shardUrls);\n        } else {\n          if (clusterState == null) {\n            clusterState =  zkController.getClusterState();\n            slices = clusterState.getSlicesMap(cloudDescriptor.getCollectionName());\n          }\n          String sliceName = rb.slices[i];\n\n          Slice slice = slices.get(sliceName);\n\n          if (slice==null) {\n            // Treat this the same as \"all servers down\" for a slice, and let things continue\n            // if partial results are acceptable\n            rb.shards[i] = \"\";\n            continue;\n            // throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"no such shard: \" + sliceName);\n          }\n          final Predicate<Replica> isShardLeader = new Predicate<Replica>() {\n            private Replica shardLeader = null;\n\n            @Override\n            public boolean test(Replica replica) {\n              if (shardLeader == null) {\n                try {\n                  shardLeader = zkController.getZkStateReader().getLeaderRetry(cloudDescriptor.getCollectionName(), slice.getName());\n                } catch (InterruptedException e) {\n                  throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + slice.getName() + \" in collection \" \n                      + cloudDescriptor.getCollectionName(), e);\n                } catch (SolrException e) {\n                  if (log.isDebugEnabled()) {\n                    log.debug(\"Exception finding leader for shard {} in collection {}. Collection State: {}\", \n                        slice.getName(), cloudDescriptor.getCollectionName(), zkController.getZkStateReader().getClusterState().getCollectionOrNull(cloudDescriptor.getCollectionName()));\n                  }\n                  throw e;\n                }\n              }\n              return replica.getName().equals(shardLeader.getName());\n            }\n          };\n\n          final List<Replica> eligibleSliceReplicas = collectEligibleReplicas(slice, clusterState, onlyNrtReplicas, isShardLeader);\n\n          replicaListTransformer.transform(eligibleSliceReplicas);\n\n          shardUrls = new ArrayList<>(eligibleSliceReplicas.size());\n          for (Replica replica : eligibleSliceReplicas) {\n            String url = ZkCoreNodeProps.getCoreUrl(replica);\n            shardUrls.add(url);\n          }\n\n          if (shardUrls.isEmpty()) {\n            boolean tolerant = rb.req.getParams().getBool(ShardParams.SHARDS_TOLERANT, false);\n            if (!tolerant) {\n              // stop the check when there are no replicas available for a shard\n              throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n                  \"no servers hosting shard: \" + rb.slices[i]);\n            }\n          }\n        }\n        // And now recreate the | delimited list of equivalent servers\n        rb.shards[i] = createSliceShardsStr(shardUrls);\n      }\n    }\n    String shards_rows = params.get(ShardParams.SHARDS_ROWS);\n    if(shards_rows != null) {\n      rb.shards_rows = Integer.parseInt(shards_rows);\n    }\n    String shards_start = params.get(ShardParams.SHARDS_START);\n    if(shards_start != null) {\n      rb.shards_start = Integer.parseInt(shards_start);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f344bb33ca91f48e99c061980115b46fa84fc8f5","date":1496903283,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler#prepDistributed(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler#prepDistributed(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void prepDistributed(ResponseBuilder rb) {\n    final SolrQueryRequest req = rb.req;\n    final SolrParams params = req.getParams();\n    final String shards = params.get(ShardParams.SHARDS);\n\n    // since the cost of grabbing cloud state is still up in the air, we grab it only\n    // if we need it.\n    ClusterState clusterState = null;\n    Map<String,Slice> slices = null;\n    CoreDescriptor coreDescriptor = req.getCore().getCoreDescriptor();\n    CloudDescriptor cloudDescriptor = coreDescriptor.getCloudDescriptor();\n    ZkController zkController = req.getCore().getCoreContainer().getZkController();\n\n    final ReplicaListTransformer replicaListTransformer = httpShardHandlerFactory.getReplicaListTransformer(req);\n\n    if (shards != null) {\n      List<String> lst = StrUtils.splitSmart(shards, \",\", true);\n      rb.shards = lst.toArray(new String[lst.size()]);\n      rb.slices = new String[rb.shards.length];\n\n      if (zkController != null) {\n        // figure out which shards are slices\n        for (int i=0; i<rb.shards.length; i++) {\n          if (rb.shards[i].indexOf('/') < 0) {\n            // this is a logical shard\n            rb.slices[i] = rb.shards[i];\n            rb.shards[i] = null;\n          }\n        }\n      }\n    } else if (zkController != null) {\n      // we weren't provided with an explicit list of slices to query via \"shards\", so use the cluster state\n\n      clusterState =  zkController.getClusterState();\n      String shardKeys =  params.get(ShardParams._ROUTE_);\n\n      // This will be the complete list of slices we need to query for this request.\n      slices = new HashMap<>();\n\n      // we need to find out what collections this request is for.\n\n      // A comma-separated list of specified collections.\n      // Eg: \"collection1,collection2,collection3\"\n      String collections = params.get(\"collection\");\n      if (collections != null) {\n        // If there were one or more collections specified in the query, split\n        // each parameter and store as a separate member of a List.\n        List<String> collectionList = StrUtils.splitSmart(collections, \",\",\n            true);\n        // In turn, retrieve the slices that cover each collection from the\n        // cloud state and add them to the Map 'slices'.\n        for (String collectionName : collectionList) {\n          // The original code produced <collection-name>_<shard-name> when the collections\n          // parameter was specified (see ClientUtils.appendMap)\n          // Is this necessary if ony one collection is specified?\n          // i.e. should we change multiCollection to collectionList.size() > 1?\n          addSlices(slices, clusterState, params, collectionName,  shardKeys, true);\n        }\n      } else {\n        // just this collection\n        String collectionName = cloudDescriptor.getCollectionName();\n        addSlices(slices, clusterState, params, collectionName,  shardKeys, false);\n      }\n\n\n      // Store the logical slices in the ResponseBuilder and create a new\n      // String array to hold the physical shards (which will be mapped\n      // later).\n      rb.slices = slices.keySet().toArray(new String[slices.size()]);\n      rb.shards = new String[rb.slices.length];\n    }\n\n    //\n    // Map slices to shards\n    //\n    if (zkController != null) {\n\n      // Are we hosting the shard that this request is for, and are we active? If so, then handle it ourselves\n      // and make it a non-distributed request.\n      String ourSlice = cloudDescriptor.getShardId();\n      String ourCollection = cloudDescriptor.getCollectionName();\n      // Some requests may only be fulfilled by replicas of type Replica.Type.NRT\n      boolean onlyNrtReplicas = Boolean.TRUE == req.getContext().get(ONLY_NRT_REPLICAS);\n      if (rb.slices.length == 1 && rb.slices[0] != null\n          && ( rb.slices[0].equals(ourSlice) || rb.slices[0].equals(ourCollection + \"_\" + ourSlice) )  // handle the <collection>_<slice> format\n          && cloudDescriptor.getLastPublished() == Replica.State.ACTIVE\n          && (!onlyNrtReplicas || cloudDescriptor.getReplicaType() == Replica.Type.NRT)) {\n        boolean shortCircuit = params.getBool(\"shortCircuit\", true);       // currently just a debugging parameter to check distrib search on a single node\n\n        String targetHandler = params.get(ShardParams.SHARDS_QT);\n        shortCircuit = shortCircuit && targetHandler == null;             // if a different handler is specified, don't short-circuit\n\n        if (shortCircuit) {\n          rb.isDistrib = false;\n          rb.shortCircuitedURL = ZkCoreNodeProps.getCoreUrl(zkController.getBaseUrl(), coreDescriptor.getName());\n          return;\n        }\n        // We shouldn't need to do anything to handle \"shard.rows\" since it was previously meant to be an optimization?\n      }\n\n\n      for (int i=0; i<rb.shards.length; i++) {\n        if (rb.shards[i] != null) {\n          final List<String> shardUrls = StrUtils.splitSmart(rb.shards[i], \"|\", true);\n          replicaListTransformer.transform(shardUrls);\n          // And now recreate the | delimited list of equivalent servers\n          rb.shards[i] = createSliceShardsStr(shardUrls);\n        } else {\n          if (clusterState == null) {\n            clusterState =  zkController.getClusterState();\n            slices = clusterState.getSlicesMap(cloudDescriptor.getCollectionName());\n          }\n          String sliceName = rb.slices[i];\n\n          Slice slice = slices.get(sliceName);\n\n          if (slice==null) {\n            // Treat this the same as \"all servers down\" for a slice, and let things continue\n            // if partial results are acceptable\n            rb.shards[i] = \"\";\n            continue;\n            // throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"no such shard: \" + sliceName);\n          }\n          final Predicate<Replica> isShardLeader = new Predicate<Replica>() {\n            private Replica shardLeader = null;\n\n            @Override\n            public boolean test(Replica replica) {\n              if (shardLeader == null) {\n                try {\n                  shardLeader = zkController.getZkStateReader().getLeaderRetry(cloudDescriptor.getCollectionName(), slice.getName());\n                } catch (InterruptedException e) {\n                  throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + slice.getName() + \" in collection \" \n                      + cloudDescriptor.getCollectionName(), e);\n                } catch (SolrException e) {\n                  if (log.isDebugEnabled()) {\n                    log.debug(\"Exception finding leader for shard {} in collection {}. Collection State: {}\", \n                        slice.getName(), cloudDescriptor.getCollectionName(), zkController.getZkStateReader().getClusterState().getCollectionOrNull(cloudDescriptor.getCollectionName()));\n                  }\n                  throw e;\n                }\n              }\n              return replica.getName().equals(shardLeader.getName());\n            }\n          };\n\n          final List<Replica> eligibleSliceReplicas = collectEligibleReplicas(slice, clusterState, onlyNrtReplicas, isShardLeader);\n\n          final List<String> shardUrls = transformReplicasToShardUrls(replicaListTransformer, eligibleSliceReplicas);\n\n          // And now recreate the | delimited list of equivalent servers\n          final String sliceShardsStr = createSliceShardsStr(shardUrls);\n          if (sliceShardsStr.isEmpty()) {\n            boolean tolerant = rb.req.getParams().getBool(ShardParams.SHARDS_TOLERANT, false);\n            if (!tolerant) {\n              // stop the check when there are no replicas available for a shard\n              throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n                  \"no servers hosting shard: \" + rb.slices[i]);\n            }\n          }\n          rb.shards[i] = sliceShardsStr;\n        }\n      }\n    }\n    String shards_rows = params.get(ShardParams.SHARDS_ROWS);\n    if(shards_rows != null) {\n      rb.shards_rows = Integer.parseInt(shards_rows);\n    }\n    String shards_start = params.get(ShardParams.SHARDS_START);\n    if(shards_start != null) {\n      rb.shards_start = Integer.parseInt(shards_start);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void prepDistributed(ResponseBuilder rb) {\n    final SolrQueryRequest req = rb.req;\n    final SolrParams params = req.getParams();\n    final String shards = params.get(ShardParams.SHARDS);\n\n    // since the cost of grabbing cloud state is still up in the air, we grab it only\n    // if we need it.\n    ClusterState clusterState = null;\n    Map<String,Slice> slices = null;\n    CoreDescriptor coreDescriptor = req.getCore().getCoreDescriptor();\n    CloudDescriptor cloudDescriptor = coreDescriptor.getCloudDescriptor();\n    ZkController zkController = req.getCore().getCoreContainer().getZkController();\n\n    final ReplicaListTransformer replicaListTransformer = httpShardHandlerFactory.getReplicaListTransformer(req);\n\n    if (shards != null) {\n      List<String> lst = StrUtils.splitSmart(shards, \",\", true);\n      rb.shards = lst.toArray(new String[lst.size()]);\n      rb.slices = new String[rb.shards.length];\n\n      if (zkController != null) {\n        // figure out which shards are slices\n        for (int i=0; i<rb.shards.length; i++) {\n          if (rb.shards[i].indexOf('/') < 0) {\n            // this is a logical shard\n            rb.slices[i] = rb.shards[i];\n            rb.shards[i] = null;\n          }\n        }\n      }\n    } else if (zkController != null) {\n      // we weren't provided with an explicit list of slices to query via \"shards\", so use the cluster state\n\n      clusterState =  zkController.getClusterState();\n      String shardKeys =  params.get(ShardParams._ROUTE_);\n\n      // This will be the complete list of slices we need to query for this request.\n      slices = new HashMap<>();\n\n      // we need to find out what collections this request is for.\n\n      // A comma-separated list of specified collections.\n      // Eg: \"collection1,collection2,collection3\"\n      String collections = params.get(\"collection\");\n      if (collections != null) {\n        // If there were one or more collections specified in the query, split\n        // each parameter and store as a separate member of a List.\n        List<String> collectionList = StrUtils.splitSmart(collections, \",\",\n            true);\n        // In turn, retrieve the slices that cover each collection from the\n        // cloud state and add them to the Map 'slices'.\n        for (String collectionName : collectionList) {\n          // The original code produced <collection-name>_<shard-name> when the collections\n          // parameter was specified (see ClientUtils.appendMap)\n          // Is this necessary if ony one collection is specified?\n          // i.e. should we change multiCollection to collectionList.size() > 1?\n          addSlices(slices, clusterState, params, collectionName,  shardKeys, true);\n        }\n      } else {\n        // just this collection\n        String collectionName = cloudDescriptor.getCollectionName();\n        addSlices(slices, clusterState, params, collectionName,  shardKeys, false);\n      }\n\n\n      // Store the logical slices in the ResponseBuilder and create a new\n      // String array to hold the physical shards (which will be mapped\n      // later).\n      rb.slices = slices.keySet().toArray(new String[slices.size()]);\n      rb.shards = new String[rb.slices.length];\n    }\n\n    //\n    // Map slices to shards\n    //\n    if (zkController != null) {\n\n      // Are we hosting the shard that this request is for, and are we active? If so, then handle it ourselves\n      // and make it a non-distributed request.\n      String ourSlice = cloudDescriptor.getShardId();\n      String ourCollection = cloudDescriptor.getCollectionName();\n      // Some requests may only be fulfilled by replicas of type Replica.Type.NRT\n      boolean onlyNrtReplicas = Boolean.TRUE == req.getContext().get(ONLY_NRT_REPLICAS);\n      if (rb.slices.length == 1 && rb.slices[0] != null\n          && ( rb.slices[0].equals(ourSlice) || rb.slices[0].equals(ourCollection + \"_\" + ourSlice) )  // handle the <collection>_<slice> format\n          && cloudDescriptor.getLastPublished() == Replica.State.ACTIVE\n          && (!onlyNrtReplicas || cloudDescriptor.getReplicaType() == Replica.Type.NRT)) {\n        boolean shortCircuit = params.getBool(\"shortCircuit\", true);       // currently just a debugging parameter to check distrib search on a single node\n\n        String targetHandler = params.get(ShardParams.SHARDS_QT);\n        shortCircuit = shortCircuit && targetHandler == null;             // if a different handler is specified, don't short-circuit\n\n        if (shortCircuit) {\n          rb.isDistrib = false;\n          rb.shortCircuitedURL = ZkCoreNodeProps.getCoreUrl(zkController.getBaseUrl(), coreDescriptor.getName());\n          return;\n        }\n        // We shouldn't need to do anything to handle \"shard.rows\" since it was previously meant to be an optimization?\n      }\n\n\n      for (int i=0; i<rb.shards.length; i++) {\n        final List<String> shardUrls;\n        if (rb.shards[i] != null) {\n          shardUrls = StrUtils.splitSmart(rb.shards[i], \"|\", true);\n          replicaListTransformer.transform(shardUrls);\n        } else {\n          if (clusterState == null) {\n            clusterState =  zkController.getClusterState();\n            slices = clusterState.getSlicesMap(cloudDescriptor.getCollectionName());\n          }\n          String sliceName = rb.slices[i];\n\n          Slice slice = slices.get(sliceName);\n\n          if (slice==null) {\n            // Treat this the same as \"all servers down\" for a slice, and let things continue\n            // if partial results are acceptable\n            rb.shards[i] = \"\";\n            continue;\n            // throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"no such shard: \" + sliceName);\n          }\n          final Predicate<Replica> isShardLeader = new Predicate<Replica>() {\n            private Replica shardLeader = null;\n\n            @Override\n            public boolean test(Replica replica) {\n              if (shardLeader == null) {\n                try {\n                  shardLeader = zkController.getZkStateReader().getLeaderRetry(cloudDescriptor.getCollectionName(), slice.getName());\n                } catch (InterruptedException e) {\n                  throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + slice.getName() + \" in collection \" \n                      + cloudDescriptor.getCollectionName(), e);\n                } catch (SolrException e) {\n                  if (log.isDebugEnabled()) {\n                    log.debug(\"Exception finding leader for shard {} in collection {}. Collection State: {}\", \n                        slice.getName(), cloudDescriptor.getCollectionName(), zkController.getZkStateReader().getClusterState().getCollectionOrNull(cloudDescriptor.getCollectionName()));\n                  }\n                  throw e;\n                }\n              }\n              return replica.getName().equals(shardLeader.getName());\n            }\n          };\n\n          final List<Replica> eligibleSliceReplicas = collectEligibleReplicas(slice, clusterState, onlyNrtReplicas, isShardLeader);\n\n          replicaListTransformer.transform(eligibleSliceReplicas);\n\n          shardUrls = new ArrayList<>(eligibleSliceReplicas.size());\n          for (Replica replica : eligibleSliceReplicas) {\n            String url = ZkCoreNodeProps.getCoreUrl(replica);\n            shardUrls.add(url);\n          }\n\n          if (shardUrls.isEmpty()) {\n            boolean tolerant = rb.req.getParams().getBool(ShardParams.SHARDS_TOLERANT, false);\n            if (!tolerant) {\n              // stop the check when there are no replicas available for a shard\n              throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n                  \"no servers hosting shard: \" + rb.slices[i]);\n            }\n          }\n        }\n        // And now recreate the | delimited list of equivalent servers\n        rb.shards[i] = createSliceShardsStr(shardUrls);\n      }\n    }\n    String shards_rows = params.get(ShardParams.SHARDS_ROWS);\n    if(shards_rows != null) {\n      rb.shards_rows = Integer.parseInt(shards_rows);\n    }\n    String shards_start = params.get(ShardParams.SHARDS_START);\n    if(shards_start != null) {\n      rb.shards_start = Integer.parseInt(shards_start);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9","date":1498028748,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler#prepDistributed(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler#prepDistributed(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void prepDistributed(ResponseBuilder rb) {\n    final SolrQueryRequest req = rb.req;\n    final SolrParams params = req.getParams();\n    final String shards = params.get(ShardParams.SHARDS);\n\n    // since the cost of grabbing cloud state is still up in the air, we grab it only\n    // if we need it.\n    ClusterState clusterState = null;\n    Map<String,Slice> slices = null;\n    CoreDescriptor coreDescriptor = req.getCore().getCoreDescriptor();\n    CloudDescriptor cloudDescriptor = coreDescriptor.getCloudDescriptor();\n    ZkController zkController = req.getCore().getCoreContainer().getZkController();\n\n    final ReplicaListTransformer replicaListTransformer = httpShardHandlerFactory.getReplicaListTransformer(req);\n\n    if (shards != null) {\n      List<String> lst = StrUtils.splitSmart(shards, \",\", true);\n      rb.shards = lst.toArray(new String[lst.size()]);\n      rb.slices = new String[rb.shards.length];\n\n      if (zkController != null) {\n        // figure out which shards are slices\n        for (int i=0; i<rb.shards.length; i++) {\n          if (rb.shards[i].indexOf('/') < 0) {\n            // this is a logical shard\n            rb.slices[i] = rb.shards[i];\n            rb.shards[i] = null;\n          }\n        }\n      }\n    } else if (zkController != null) {\n      // we weren't provided with an explicit list of slices to query via \"shards\", so use the cluster state\n\n      clusterState =  zkController.getClusterState();\n      String shardKeys =  params.get(ShardParams._ROUTE_);\n\n      // This will be the complete list of slices we need to query for this request.\n      slices = new HashMap<>();\n\n      // we need to find out what collections this request is for.\n\n      // A comma-separated list of specified collections.\n      // Eg: \"collection1,collection2,collection3\"\n      String collections = params.get(\"collection\");\n      if (collections != null) {\n        // If there were one or more collections specified in the query, split\n        // each parameter and store as a separate member of a List.\n        List<String> collectionList = StrUtils.splitSmart(collections, \",\",\n            true);\n        // In turn, retrieve the slices that cover each collection from the\n        // cloud state and add them to the Map 'slices'.\n        for (String collectionName : collectionList) {\n          // The original code produced <collection-name>_<shard-name> when the collections\n          // parameter was specified (see ClientUtils.appendMap)\n          // Is this necessary if ony one collection is specified?\n          // i.e. should we change multiCollection to collectionList.size() > 1?\n          addSlices(slices, clusterState, params, collectionName,  shardKeys, true);\n        }\n      } else {\n        // just this collection\n        String collectionName = cloudDescriptor.getCollectionName();\n        addSlices(slices, clusterState, params, collectionName,  shardKeys, false);\n      }\n\n\n      // Store the logical slices in the ResponseBuilder and create a new\n      // String array to hold the physical shards (which will be mapped\n      // later).\n      rb.slices = slices.keySet().toArray(new String[slices.size()]);\n      rb.shards = new String[rb.slices.length];\n    }\n\n    //\n    // Map slices to shards\n    //\n    if (zkController != null) {\n\n      // Are we hosting the shard that this request is for, and are we active? If so, then handle it ourselves\n      // and make it a non-distributed request.\n      String ourSlice = cloudDescriptor.getShardId();\n      String ourCollection = cloudDescriptor.getCollectionName();\n      // Some requests may only be fulfilled by replicas of type Replica.Type.NRT\n      boolean onlyNrtReplicas = Boolean.TRUE == req.getContext().get(ONLY_NRT_REPLICAS);\n      if (rb.slices.length == 1 && rb.slices[0] != null\n          && ( rb.slices[0].equals(ourSlice) || rb.slices[0].equals(ourCollection + \"_\" + ourSlice) )  // handle the <collection>_<slice> format\n          && cloudDescriptor.getLastPublished() == Replica.State.ACTIVE\n          && (!onlyNrtReplicas || cloudDescriptor.getReplicaType() == Replica.Type.NRT)) {\n        boolean shortCircuit = params.getBool(\"shortCircuit\", true);       // currently just a debugging parameter to check distrib search on a single node\n\n        String targetHandler = params.get(ShardParams.SHARDS_QT);\n        shortCircuit = shortCircuit && targetHandler == null;             // if a different handler is specified, don't short-circuit\n\n        if (shortCircuit) {\n          rb.isDistrib = false;\n          rb.shortCircuitedURL = ZkCoreNodeProps.getCoreUrl(zkController.getBaseUrl(), coreDescriptor.getName());\n          return;\n        }\n        // We shouldn't need to do anything to handle \"shard.rows\" since it was previously meant to be an optimization?\n      }\n\n\n      for (int i=0; i<rb.shards.length; i++) {\n        if (rb.shards[i] != null) {\n          final List<String> shardUrls = StrUtils.splitSmart(rb.shards[i], \"|\", true);\n          replicaListTransformer.transform(shardUrls);\n          // And now recreate the | delimited list of equivalent servers\n          rb.shards[i] = createSliceShardsStr(shardUrls);\n        } else {\n          if (clusterState == null) {\n            clusterState =  zkController.getClusterState();\n            slices = clusterState.getSlicesMap(cloudDescriptor.getCollectionName());\n          }\n          String sliceName = rb.slices[i];\n\n          Slice slice = slices.get(sliceName);\n\n          if (slice==null) {\n            // Treat this the same as \"all servers down\" for a slice, and let things continue\n            // if partial results are acceptable\n            rb.shards[i] = \"\";\n            continue;\n            // throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"no such shard: \" + sliceName);\n          }\n          final Predicate<Replica> isShardLeader = new Predicate<Replica>() {\n            private Replica shardLeader = null;\n\n            @Override\n            public boolean test(Replica replica) {\n              if (shardLeader == null) {\n                try {\n                  shardLeader = zkController.getZkStateReader().getLeaderRetry(cloudDescriptor.getCollectionName(), slice.getName());\n                } catch (InterruptedException e) {\n                  throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + slice.getName() + \" in collection \" \n                      + cloudDescriptor.getCollectionName(), e);\n                } catch (SolrException e) {\n                  if (log.isDebugEnabled()) {\n                    log.debug(\"Exception finding leader for shard {} in collection {}. Collection State: {}\", \n                        slice.getName(), cloudDescriptor.getCollectionName(), zkController.getZkStateReader().getClusterState().getCollectionOrNull(cloudDescriptor.getCollectionName()));\n                  }\n                  throw e;\n                }\n              }\n              return replica.getName().equals(shardLeader.getName());\n            }\n          };\n\n          final List<Replica> eligibleSliceReplicas = collectEligibleReplicas(slice, clusterState, onlyNrtReplicas, isShardLeader);\n\n          final List<String> shardUrls = transformReplicasToShardUrls(replicaListTransformer, eligibleSliceReplicas);\n\n          // And now recreate the | delimited list of equivalent servers\n          final String sliceShardsStr = createSliceShardsStr(shardUrls);\n          if (sliceShardsStr.isEmpty()) {\n            boolean tolerant = rb.req.getParams().getBool(ShardParams.SHARDS_TOLERANT, false);\n            if (!tolerant) {\n              // stop the check when there are no replicas available for a shard\n              throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n                  \"no servers hosting shard: \" + rb.slices[i]);\n            }\n          }\n          rb.shards[i] = sliceShardsStr;\n        }\n      }\n    }\n    String shards_rows = params.get(ShardParams.SHARDS_ROWS);\n    if(shards_rows != null) {\n      rb.shards_rows = Integer.parseInt(shards_rows);\n    }\n    String shards_start = params.get(ShardParams.SHARDS_START);\n    if(shards_start != null) {\n      rb.shards_start = Integer.parseInt(shards_start);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void prepDistributed(ResponseBuilder rb) {\n    final SolrQueryRequest req = rb.req;\n    final SolrParams params = req.getParams();\n    final String shards = params.get(ShardParams.SHARDS);\n\n    // since the cost of grabbing cloud state is still up in the air, we grab it only\n    // if we need it.\n    ClusterState clusterState = null;\n    Map<String,Slice> slices = null;\n    CoreDescriptor coreDescriptor = req.getCore().getCoreDescriptor();\n    CloudDescriptor cloudDescriptor = coreDescriptor.getCloudDescriptor();\n    ZkController zkController = req.getCore().getCoreContainer().getZkController();\n\n    final ReplicaListTransformer replicaListTransformer = httpShardHandlerFactory.getReplicaListTransformer(req);\n\n    if (shards != null) {\n      List<String> lst = StrUtils.splitSmart(shards, \",\", true);\n      rb.shards = lst.toArray(new String[lst.size()]);\n      rb.slices = new String[rb.shards.length];\n\n      if (zkController != null) {\n        // figure out which shards are slices\n        for (int i=0; i<rb.shards.length; i++) {\n          if (rb.shards[i].indexOf('/') < 0) {\n            // this is a logical shard\n            rb.slices[i] = rb.shards[i];\n            rb.shards[i] = null;\n          }\n        }\n      }\n    } else if (zkController != null) {\n      // we weren't provided with an explicit list of slices to query via \"shards\", so use the cluster state\n\n      clusterState =  zkController.getClusterState();\n      String shardKeys =  params.get(ShardParams._ROUTE_);\n\n      // This will be the complete list of slices we need to query for this request.\n      slices = new HashMap<>();\n\n      // we need to find out what collections this request is for.\n\n      // A comma-separated list of specified collections.\n      // Eg: \"collection1,collection2,collection3\"\n      String collections = params.get(\"collection\");\n      if (collections != null) {\n        // If there were one or more collections specified in the query, split\n        // each parameter and store as a separate member of a List.\n        List<String> collectionList = StrUtils.splitSmart(collections, \",\",\n            true);\n        // In turn, retrieve the slices that cover each collection from the\n        // cloud state and add them to the Map 'slices'.\n        for (String collectionName : collectionList) {\n          // The original code produced <collection-name>_<shard-name> when the collections\n          // parameter was specified (see ClientUtils.appendMap)\n          // Is this necessary if ony one collection is specified?\n          // i.e. should we change multiCollection to collectionList.size() > 1?\n          addSlices(slices, clusterState, params, collectionName,  shardKeys, true);\n        }\n      } else {\n        // just this collection\n        String collectionName = cloudDescriptor.getCollectionName();\n        addSlices(slices, clusterState, params, collectionName,  shardKeys, false);\n      }\n\n\n      // Store the logical slices in the ResponseBuilder and create a new\n      // String array to hold the physical shards (which will be mapped\n      // later).\n      rb.slices = slices.keySet().toArray(new String[slices.size()]);\n      rb.shards = new String[rb.slices.length];\n    }\n\n    //\n    // Map slices to shards\n    //\n    if (zkController != null) {\n\n      // Are we hosting the shard that this request is for, and are we active? If so, then handle it ourselves\n      // and make it a non-distributed request.\n      String ourSlice = cloudDescriptor.getShardId();\n      String ourCollection = cloudDescriptor.getCollectionName();\n      // Some requests may only be fulfilled by replicas of type Replica.Type.NRT\n      boolean onlyNrtReplicas = Boolean.TRUE == req.getContext().get(ONLY_NRT_REPLICAS);\n      if (rb.slices.length == 1 && rb.slices[0] != null\n          && ( rb.slices[0].equals(ourSlice) || rb.slices[0].equals(ourCollection + \"_\" + ourSlice) )  // handle the <collection>_<slice> format\n          && cloudDescriptor.getLastPublished() == Replica.State.ACTIVE\n          && (!onlyNrtReplicas || cloudDescriptor.getReplicaType() == Replica.Type.NRT)) {\n        boolean shortCircuit = params.getBool(\"shortCircuit\", true);       // currently just a debugging parameter to check distrib search on a single node\n\n        String targetHandler = params.get(ShardParams.SHARDS_QT);\n        shortCircuit = shortCircuit && targetHandler == null;             // if a different handler is specified, don't short-circuit\n\n        if (shortCircuit) {\n          rb.isDistrib = false;\n          rb.shortCircuitedURL = ZkCoreNodeProps.getCoreUrl(zkController.getBaseUrl(), coreDescriptor.getName());\n          return;\n        }\n        // We shouldn't need to do anything to handle \"shard.rows\" since it was previously meant to be an optimization?\n      }\n\n\n      for (int i=0; i<rb.shards.length; i++) {\n        final List<String> shardUrls;\n        if (rb.shards[i] != null) {\n          shardUrls = StrUtils.splitSmart(rb.shards[i], \"|\", true);\n          replicaListTransformer.transform(shardUrls);\n        } else {\n          if (clusterState == null) {\n            clusterState =  zkController.getClusterState();\n            slices = clusterState.getSlicesMap(cloudDescriptor.getCollectionName());\n          }\n          String sliceName = rb.slices[i];\n\n          Slice slice = slices.get(sliceName);\n\n          if (slice==null) {\n            // Treat this the same as \"all servers down\" for a slice, and let things continue\n            // if partial results are acceptable\n            rb.shards[i] = \"\";\n            continue;\n            // throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"no such shard: \" + sliceName);\n          }\n          final Predicate<Replica> isShardLeader = new Predicate<Replica>() {\n            private Replica shardLeader = null;\n\n            @Override\n            public boolean test(Replica replica) {\n              if (shardLeader == null) {\n                try {\n                  shardLeader = zkController.getZkStateReader().getLeaderRetry(cloudDescriptor.getCollectionName(), slice.getName());\n                } catch (InterruptedException e) {\n                  throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + slice.getName() + \" in collection \" \n                      + cloudDescriptor.getCollectionName(), e);\n                } catch (SolrException e) {\n                  if (log.isDebugEnabled()) {\n                    log.debug(\"Exception finding leader for shard {} in collection {}. Collection State: {}\", \n                        slice.getName(), cloudDescriptor.getCollectionName(), zkController.getZkStateReader().getClusterState().getCollectionOrNull(cloudDescriptor.getCollectionName()));\n                  }\n                  throw e;\n                }\n              }\n              return replica.getName().equals(shardLeader.getName());\n            }\n          };\n\n          final List<Replica> eligibleSliceReplicas = collectEligibleReplicas(slice, clusterState, onlyNrtReplicas, isShardLeader);\n\n          replicaListTransformer.transform(eligibleSliceReplicas);\n\n          shardUrls = new ArrayList<>(eligibleSliceReplicas.size());\n          for (Replica replica : eligibleSliceReplicas) {\n            String url = ZkCoreNodeProps.getCoreUrl(replica);\n            shardUrls.add(url);\n          }\n\n          if (shardUrls.isEmpty()) {\n            boolean tolerant = rb.req.getParams().getBool(ShardParams.SHARDS_TOLERANT, false);\n            if (!tolerant) {\n              // stop the check when there are no replicas available for a shard\n              throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n                  \"no servers hosting shard: \" + rb.slices[i]);\n            }\n          }\n        }\n        // And now recreate the | delimited list of equivalent servers\n        rb.shards[i] = createSliceShardsStr(shardUrls);\n      }\n    }\n    String shards_rows = params.get(ShardParams.SHARDS_ROWS);\n    if(shards_rows != null) {\n      rb.shards_rows = Integer.parseInt(shards_rows);\n    }\n    String shards_start = params.get(ShardParams.SHARDS_START);\n    if(shards_start != null) {\n      rb.shards_start = Integer.parseInt(shards_start);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"28288370235ed02234a64753cdbf0c6ec096304a","date":1498726817,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler#prepDistributed(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler#prepDistributed(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void prepDistributed(ResponseBuilder rb) {\n    final SolrQueryRequest req = rb.req;\n    final SolrParams params = req.getParams();\n    final String shards = params.get(ShardParams.SHARDS);\n\n    // since the cost of grabbing cloud state is still up in the air, we grab it only\n    // if we need it.\n    ClusterState clusterState = null;\n    Map<String,Slice> slices = null;\n    CoreDescriptor coreDescriptor = req.getCore().getCoreDescriptor();\n    CloudDescriptor cloudDescriptor = coreDescriptor.getCloudDescriptor();\n    ZkController zkController = req.getCore().getCoreContainer().getZkController();\n\n    final ReplicaListTransformer replicaListTransformer = httpShardHandlerFactory.getReplicaListTransformer(req);\n\n    if (shards != null) {\n      List<String> lst = StrUtils.splitSmart(shards, \",\", true);\n      rb.shards = lst.toArray(new String[lst.size()]);\n      rb.slices = new String[rb.shards.length];\n\n      if (zkController != null) {\n        // figure out which shards are slices\n        for (int i=0; i<rb.shards.length; i++) {\n          if (rb.shards[i].indexOf('/') < 0) {\n            // this is a logical shard\n            rb.slices[i] = rb.shards[i];\n            rb.shards[i] = null;\n          }\n        }\n      }\n    } else if (zkController != null) {\n      // we weren't provided with an explicit list of slices to query via \"shards\", so use the cluster state\n\n      clusterState =  zkController.getClusterState();\n      String shardKeys =  params.get(ShardParams._ROUTE_);\n\n      // This will be the complete list of slices we need to query for this request.\n      slices = new HashMap<>();\n\n      // we need to find out what collections this request is for.\n\n      // A comma-separated list of specified collections.\n      // Eg: \"collection1,collection2,collection3\"\n      String collections = params.get(\"collection\");\n      if (collections != null) {\n        // If there were one or more collections specified in the query, split\n        // each parameter and store as a separate member of a List.\n        List<String> collectionList = StrUtils.splitSmart(collections, \",\",\n            true);\n        // In turn, retrieve the slices that cover each collection from the\n        // cloud state and add them to the Map 'slices'.\n        for (String collectionName : collectionList) {\n          // The original code produced <collection-name>_<shard-name> when the collections\n          // parameter was specified (see ClientUtils.appendMap)\n          // Is this necessary if ony one collection is specified?\n          // i.e. should we change multiCollection to collectionList.size() > 1?\n          addSlices(slices, clusterState, params, collectionName,  shardKeys, true);\n        }\n      } else {\n        // just this collection\n        String collectionName = cloudDescriptor.getCollectionName();\n        addSlices(slices, clusterState, params, collectionName,  shardKeys, false);\n      }\n\n\n      // Store the logical slices in the ResponseBuilder and create a new\n      // String array to hold the physical shards (which will be mapped\n      // later).\n      rb.slices = slices.keySet().toArray(new String[slices.size()]);\n      rb.shards = new String[rb.slices.length];\n    }\n\n    //\n    // Map slices to shards\n    //\n    if (zkController != null) {\n\n      // Are we hosting the shard that this request is for, and are we active? If so, then handle it ourselves\n      // and make it a non-distributed request.\n      String ourSlice = cloudDescriptor.getShardId();\n      String ourCollection = cloudDescriptor.getCollectionName();\n      // Some requests may only be fulfilled by replicas of type Replica.Type.NRT\n      boolean onlyNrtReplicas = Boolean.TRUE == req.getContext().get(ONLY_NRT_REPLICAS);\n      if (rb.slices.length == 1 && rb.slices[0] != null\n          && ( rb.slices[0].equals(ourSlice) || rb.slices[0].equals(ourCollection + \"_\" + ourSlice) )  // handle the <collection>_<slice> format\n          && cloudDescriptor.getLastPublished() == Replica.State.ACTIVE\n          && (!onlyNrtReplicas || cloudDescriptor.getReplicaType() == Replica.Type.NRT)) {\n        boolean shortCircuit = params.getBool(\"shortCircuit\", true);       // currently just a debugging parameter to check distrib search on a single node\n\n        String targetHandler = params.get(ShardParams.SHARDS_QT);\n        shortCircuit = shortCircuit && targetHandler == null;             // if a different handler is specified, don't short-circuit\n\n        if (shortCircuit) {\n          rb.isDistrib = false;\n          rb.shortCircuitedURL = ZkCoreNodeProps.getCoreUrl(zkController.getBaseUrl(), coreDescriptor.getName());\n          return;\n        }\n        // We shouldn't need to do anything to handle \"shard.rows\" since it was previously meant to be an optimization?\n      }\n\n\n      for (int i=0; i<rb.shards.length; i++) {\n        if (rb.shards[i] != null) {\n          final List<String> shardUrls = StrUtils.splitSmart(rb.shards[i], \"|\", true);\n          replicaListTransformer.transform(shardUrls);\n          // And now recreate the | delimited list of equivalent servers\n          rb.shards[i] = createSliceShardsStr(shardUrls);\n        } else {\n          if (clusterState == null) {\n            clusterState =  zkController.getClusterState();\n            slices = clusterState.getSlicesMap(cloudDescriptor.getCollectionName());\n          }\n          String sliceName = rb.slices[i];\n\n          Slice slice = slices.get(sliceName);\n\n          if (slice==null) {\n            // Treat this the same as \"all servers down\" for a slice, and let things continue\n            // if partial results are acceptable\n            rb.shards[i] = \"\";\n            continue;\n            // throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"no such shard: \" + sliceName);\n          }\n          final Predicate<Replica> isShardLeader = new Predicate<Replica>() {\n            private Replica shardLeader = null;\n\n            @Override\n            public boolean test(Replica replica) {\n              if (shardLeader == null) {\n                try {\n                  shardLeader = zkController.getZkStateReader().getLeaderRetry(cloudDescriptor.getCollectionName(), slice.getName());\n                } catch (InterruptedException e) {\n                  throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + slice.getName() + \" in collection \" \n                      + cloudDescriptor.getCollectionName(), e);\n                } catch (SolrException e) {\n                  if (log.isDebugEnabled()) {\n                    log.debug(\"Exception finding leader for shard {} in collection {}. Collection State: {}\", \n                        slice.getName(), cloudDescriptor.getCollectionName(), zkController.getZkStateReader().getClusterState().getCollectionOrNull(cloudDescriptor.getCollectionName()));\n                  }\n                  throw e;\n                }\n              }\n              return replica.getName().equals(shardLeader.getName());\n            }\n          };\n\n          final List<Replica> eligibleSliceReplicas = collectEligibleReplicas(slice, clusterState, onlyNrtReplicas, isShardLeader);\n\n          final List<String> shardUrls = transformReplicasToShardUrls(replicaListTransformer, eligibleSliceReplicas);\n\n          // And now recreate the | delimited list of equivalent servers\n          final String sliceShardsStr = createSliceShardsStr(shardUrls);\n          if (sliceShardsStr.isEmpty()) {\n            boolean tolerant = rb.req.getParams().getBool(ShardParams.SHARDS_TOLERANT, false);\n            if (!tolerant) {\n              // stop the check when there are no replicas available for a shard\n              throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n                  \"no servers hosting shard: \" + rb.slices[i]);\n            }\n          }\n          rb.shards[i] = sliceShardsStr;\n        }\n      }\n    }\n    String shards_rows = params.get(ShardParams.SHARDS_ROWS);\n    if(shards_rows != null) {\n      rb.shards_rows = Integer.parseInt(shards_rows);\n    }\n    String shards_start = params.get(ShardParams.SHARDS_START);\n    if(shards_start != null) {\n      rb.shards_start = Integer.parseInt(shards_start);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void prepDistributed(ResponseBuilder rb) {\n    final SolrQueryRequest req = rb.req;\n    final SolrParams params = req.getParams();\n    final String shards = params.get(ShardParams.SHARDS);\n\n    // since the cost of grabbing cloud state is still up in the air, we grab it only\n    // if we need it.\n    ClusterState clusterState = null;\n    Map<String,Slice> slices = null;\n    CoreDescriptor coreDescriptor = req.getCore().getCoreDescriptor();\n    CloudDescriptor cloudDescriptor = coreDescriptor.getCloudDescriptor();\n    ZkController zkController = req.getCore().getCoreContainer().getZkController();\n\n    final ReplicaListTransformer replicaListTransformer = httpShardHandlerFactory.getReplicaListTransformer(req);\n\n    if (shards != null) {\n      List<String> lst = StrUtils.splitSmart(shards, \",\", true);\n      rb.shards = lst.toArray(new String[lst.size()]);\n      rb.slices = new String[rb.shards.length];\n\n      if (zkController != null) {\n        // figure out which shards are slices\n        for (int i=0; i<rb.shards.length; i++) {\n          if (rb.shards[i].indexOf('/') < 0) {\n            // this is a logical shard\n            rb.slices[i] = rb.shards[i];\n            rb.shards[i] = null;\n          }\n        }\n      }\n    } else if (zkController != null) {\n      // we weren't provided with an explicit list of slices to query via \"shards\", so use the cluster state\n\n      clusterState =  zkController.getClusterState();\n      String shardKeys =  params.get(ShardParams._ROUTE_);\n\n      // This will be the complete list of slices we need to query for this request.\n      slices = new HashMap<>();\n\n      // we need to find out what collections this request is for.\n\n      // A comma-separated list of specified collections.\n      // Eg: \"collection1,collection2,collection3\"\n      String collections = params.get(\"collection\");\n      if (collections != null) {\n        // If there were one or more collections specified in the query, split\n        // each parameter and store as a separate member of a List.\n        List<String> collectionList = StrUtils.splitSmart(collections, \",\",\n            true);\n        // In turn, retrieve the slices that cover each collection from the\n        // cloud state and add them to the Map 'slices'.\n        for (String collectionName : collectionList) {\n          // The original code produced <collection-name>_<shard-name> when the collections\n          // parameter was specified (see ClientUtils.appendMap)\n          // Is this necessary if ony one collection is specified?\n          // i.e. should we change multiCollection to collectionList.size() > 1?\n          addSlices(slices, clusterState, params, collectionName,  shardKeys, true);\n        }\n      } else {\n        // just this collection\n        String collectionName = cloudDescriptor.getCollectionName();\n        addSlices(slices, clusterState, params, collectionName,  shardKeys, false);\n      }\n\n\n      // Store the logical slices in the ResponseBuilder and create a new\n      // String array to hold the physical shards (which will be mapped\n      // later).\n      rb.slices = slices.keySet().toArray(new String[slices.size()]);\n      rb.shards = new String[rb.slices.length];\n    }\n\n    //\n    // Map slices to shards\n    //\n    if (zkController != null) {\n\n      // Are we hosting the shard that this request is for, and are we active? If so, then handle it ourselves\n      // and make it a non-distributed request.\n      String ourSlice = cloudDescriptor.getShardId();\n      String ourCollection = cloudDescriptor.getCollectionName();\n      // Some requests may only be fulfilled by replicas of type Replica.Type.NRT\n      boolean onlyNrtReplicas = Boolean.TRUE == req.getContext().get(ONLY_NRT_REPLICAS);\n      if (rb.slices.length == 1 && rb.slices[0] != null\n          && ( rb.slices[0].equals(ourSlice) || rb.slices[0].equals(ourCollection + \"_\" + ourSlice) )  // handle the <collection>_<slice> format\n          && cloudDescriptor.getLastPublished() == Replica.State.ACTIVE\n          && (!onlyNrtReplicas || cloudDescriptor.getReplicaType() == Replica.Type.NRT)) {\n        boolean shortCircuit = params.getBool(\"shortCircuit\", true);       // currently just a debugging parameter to check distrib search on a single node\n\n        String targetHandler = params.get(ShardParams.SHARDS_QT);\n        shortCircuit = shortCircuit && targetHandler == null;             // if a different handler is specified, don't short-circuit\n\n        if (shortCircuit) {\n          rb.isDistrib = false;\n          rb.shortCircuitedURL = ZkCoreNodeProps.getCoreUrl(zkController.getBaseUrl(), coreDescriptor.getName());\n          return;\n        }\n        // We shouldn't need to do anything to handle \"shard.rows\" since it was previously meant to be an optimization?\n      }\n\n\n      for (int i=0; i<rb.shards.length; i++) {\n        final List<String> shardUrls;\n        if (rb.shards[i] != null) {\n          shardUrls = StrUtils.splitSmart(rb.shards[i], \"|\", true);\n          replicaListTransformer.transform(shardUrls);\n        } else {\n          if (clusterState == null) {\n            clusterState =  zkController.getClusterState();\n            slices = clusterState.getSlicesMap(cloudDescriptor.getCollectionName());\n          }\n          String sliceName = rb.slices[i];\n\n          Slice slice = slices.get(sliceName);\n\n          if (slice==null) {\n            // Treat this the same as \"all servers down\" for a slice, and let things continue\n            // if partial results are acceptable\n            rb.shards[i] = \"\";\n            continue;\n            // throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"no such shard: \" + sliceName);\n          }\n          Replica shardLeader = null;\n\n          final Collection<Replica> allSliceReplicas = slice.getReplicasMap().values();\n          final List<Replica> eligibleSliceReplicas = new ArrayList<>(allSliceReplicas.size());\n          for (Replica replica : allSliceReplicas) {\n            if (!clusterState.liveNodesContain(replica.getNodeName())\n                || replica.getState() != Replica.State.ACTIVE\n                || (onlyNrtReplicas && replica.getType() == Replica.Type.PULL)) {\n              continue;\n            }\n            \n            if (onlyNrtReplicas && replica.getType() == Replica.Type.TLOG) {\n              if (shardLeader == null) {\n                try {\n                  shardLeader = zkController.getZkStateReader().getLeaderRetry(cloudDescriptor.getCollectionName(), slice.getName());\n                } catch (InterruptedException e) {\n                  throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + slice.getName() + \" in collection \" \n                      + cloudDescriptor.getCollectionName(), e);\n                } catch (SolrException e) {\n                  if (log.isDebugEnabled()) {\n                    log.debug(\"Exception finding leader for shard {} in collection {}. Collection State: {}\", \n                        slice.getName(), cloudDescriptor.getCollectionName(), zkController.getZkStateReader().getClusterState().getCollectionOrNull(cloudDescriptor.getCollectionName()));\n                  }\n                  throw e;\n                }\n              }\n              if (!replica.getName().equals(shardLeader.getName())) {\n                continue;\n              }\n            }\n            eligibleSliceReplicas.add(replica);\n          }\n\n          replicaListTransformer.transform(eligibleSliceReplicas);\n\n          shardUrls = new ArrayList<>(eligibleSliceReplicas.size());\n          for (Replica replica : eligibleSliceReplicas) {\n            String url = ZkCoreNodeProps.getCoreUrl(replica);\n            shardUrls.add(url);\n          }\n\n          if (shardUrls.isEmpty()) {\n            boolean tolerant = rb.req.getParams().getBool(ShardParams.SHARDS_TOLERANT, false);\n            if (!tolerant) {\n              // stop the check when there are no replicas available for a shard\n              throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n                  \"no servers hosting shard: \" + rb.slices[i]);\n            }\n          }\n        }\n        // And now recreate the | delimited list of equivalent servers\n        rb.shards[i] = createSliceShardsStr(shardUrls);\n      }\n    }\n    String shards_rows = params.get(ShardParams.SHARDS_ROWS);\n    if(shards_rows != null) {\n      rb.shards_rows = Integer.parseInt(shards_rows);\n    }\n    String shards_start = params.get(ShardParams.SHARDS_START);\n    if(shards_start != null) {\n      rb.shards_start = Integer.parseInt(shards_start);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"344b0840364d990b29b97467bfcc766ff8325d11","date":1501574100,"type":3,"author":"Cao Manh Dat","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler#prepDistributed(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler#prepDistributed(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void prepDistributed(ResponseBuilder rb) {\n    final SolrQueryRequest req = rb.req;\n    final SolrParams params = req.getParams();\n    final String shards = params.get(ShardParams.SHARDS);\n\n    // since the cost of grabbing cloud state is still up in the air, we grab it only\n    // if we need it.\n    ClusterState clusterState = null;\n    Map<String,Slice> slices = null;\n    CoreDescriptor coreDescriptor = req.getCore().getCoreDescriptor();\n    CloudDescriptor cloudDescriptor = coreDescriptor.getCloudDescriptor();\n    ZkController zkController = req.getCore().getCoreContainer().getZkController();\n\n    final ReplicaListTransformer replicaListTransformer = httpShardHandlerFactory.getReplicaListTransformer(req);\n\n    if (shards != null) {\n      List<String> lst = StrUtils.splitSmart(shards, \",\", true);\n      rb.shards = lst.toArray(new String[lst.size()]);\n      rb.slices = new String[rb.shards.length];\n\n      if (zkController != null) {\n        // figure out which shards are slices\n        for (int i=0; i<rb.shards.length; i++) {\n          if (rb.shards[i].indexOf('/') < 0) {\n            // this is a logical shard\n            rb.slices[i] = rb.shards[i];\n            rb.shards[i] = null;\n          }\n        }\n      }\n    } else if (zkController != null) {\n      // we weren't provided with an explicit list of slices to query via \"shards\", so use the cluster state\n\n      clusterState =  zkController.getClusterState();\n      String shardKeys =  params.get(ShardParams._ROUTE_);\n\n      // This will be the complete list of slices we need to query for this request.\n      slices = new HashMap<>();\n\n      // we need to find out what collections this request is for.\n\n      // A comma-separated list of specified collections.\n      // Eg: \"collection1,collection2,collection3\"\n      String collections = params.get(\"collection\");\n      if (collections != null) {\n        // If there were one or more collections specified in the query, split\n        // each parameter and store as a separate member of a List.\n        List<String> collectionList = StrUtils.splitSmart(collections, \",\",\n            true);\n        // In turn, retrieve the slices that cover each collection from the\n        // cloud state and add them to the Map 'slices'.\n        for (String collectionName : collectionList) {\n          // The original code produced <collection-name>_<shard-name> when the collections\n          // parameter was specified (see ClientUtils.appendMap)\n          // Is this necessary if ony one collection is specified?\n          // i.e. should we change multiCollection to collectionList.size() > 1?\n          addSlices(slices, clusterState, params, collectionName,  shardKeys, true);\n        }\n      } else {\n        // just this collection\n        String collectionName = cloudDescriptor.getCollectionName();\n        addSlices(slices, clusterState, params, collectionName,  shardKeys, false);\n      }\n\n\n      // Store the logical slices in the ResponseBuilder and create a new\n      // String array to hold the physical shards (which will be mapped\n      // later).\n      rb.slices = slices.keySet().toArray(new String[slices.size()]);\n      rb.shards = new String[rb.slices.length];\n    }\n\n    //\n    // Map slices to shards\n    //\n    if (zkController != null) {\n\n      // Are we hosting the shard that this request is for, and are we active? If so, then handle it ourselves\n      // and make it a non-distributed request.\n      String ourSlice = cloudDescriptor.getShardId();\n      String ourCollection = cloudDescriptor.getCollectionName();\n      // Some requests may only be fulfilled by replicas of type Replica.Type.NRT\n      boolean onlyNrtReplicas = Boolean.TRUE == req.getContext().get(ONLY_NRT_REPLICAS);\n      if (rb.slices.length == 1 && rb.slices[0] != null\n          && ( rb.slices[0].equals(ourSlice) || rb.slices[0].equals(ourCollection + \"_\" + ourSlice) )  // handle the <collection>_<slice> format\n          && cloudDescriptor.getLastPublished() == Replica.State.ACTIVE\n          && (!onlyNrtReplicas || cloudDescriptor.getReplicaType() == Replica.Type.NRT)) {\n        boolean shortCircuit = params.getBool(\"shortCircuit\", true);       // currently just a debugging parameter to check distrib search on a single node\n\n        String targetHandler = params.get(ShardParams.SHARDS_QT);\n        shortCircuit = shortCircuit && targetHandler == null;             // if a different handler is specified, don't short-circuit\n\n        if (shortCircuit) {\n          rb.isDistrib = false;\n          rb.shortCircuitedURL = ZkCoreNodeProps.getCoreUrl(zkController.getBaseUrl(), coreDescriptor.getName());\n          return;\n        }\n        // We shouldn't need to do anything to handle \"shard.rows\" since it was previously meant to be an optimization?\n      }\n\n\n      for (int i=0; i<rb.shards.length; i++) {\n        if (rb.shards[i] != null) {\n          final List<String> shardUrls = StrUtils.splitSmart(rb.shards[i], \"|\", true);\n          replicaListTransformer.transform(shardUrls);\n          // And now recreate the | delimited list of equivalent servers\n          rb.shards[i] = createSliceShardsStr(shardUrls);\n        } else {\n          if (clusterState == null) {\n            clusterState =  zkController.getClusterState();\n            slices = clusterState.getCollection(cloudDescriptor.getCollectionName()).getSlicesMap();\n          }\n          String sliceName = rb.slices[i];\n\n          Slice slice = slices.get(sliceName);\n\n          if (slice==null) {\n            // Treat this the same as \"all servers down\" for a slice, and let things continue\n            // if partial results are acceptable\n            rb.shards[i] = \"\";\n            continue;\n            // throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"no such shard: \" + sliceName);\n          }\n          final Predicate<Replica> isShardLeader = new Predicate<Replica>() {\n            private Replica shardLeader = null;\n\n            @Override\n            public boolean test(Replica replica) {\n              if (shardLeader == null) {\n                try {\n                  shardLeader = zkController.getZkStateReader().getLeaderRetry(cloudDescriptor.getCollectionName(), slice.getName());\n                } catch (InterruptedException e) {\n                  throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + slice.getName() + \" in collection \" \n                      + cloudDescriptor.getCollectionName(), e);\n                } catch (SolrException e) {\n                  if (log.isDebugEnabled()) {\n                    log.debug(\"Exception finding leader for shard {} in collection {}. Collection State: {}\", \n                        slice.getName(), cloudDescriptor.getCollectionName(), zkController.getZkStateReader().getClusterState().getCollectionOrNull(cloudDescriptor.getCollectionName()));\n                  }\n                  throw e;\n                }\n              }\n              return replica.getName().equals(shardLeader.getName());\n            }\n          };\n\n          final List<Replica> eligibleSliceReplicas = collectEligibleReplicas(slice, clusterState, onlyNrtReplicas, isShardLeader);\n\n          final List<String> shardUrls = transformReplicasToShardUrls(replicaListTransformer, eligibleSliceReplicas);\n\n          // And now recreate the | delimited list of equivalent servers\n          final String sliceShardsStr = createSliceShardsStr(shardUrls);\n          if (sliceShardsStr.isEmpty()) {\n            boolean tolerant = rb.req.getParams().getBool(ShardParams.SHARDS_TOLERANT, false);\n            if (!tolerant) {\n              // stop the check when there are no replicas available for a shard\n              throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n                  \"no servers hosting shard: \" + rb.slices[i]);\n            }\n          }\n          rb.shards[i] = sliceShardsStr;\n        }\n      }\n    }\n    String shards_rows = params.get(ShardParams.SHARDS_ROWS);\n    if(shards_rows != null) {\n      rb.shards_rows = Integer.parseInt(shards_rows);\n    }\n    String shards_start = params.get(ShardParams.SHARDS_START);\n    if(shards_start != null) {\n      rb.shards_start = Integer.parseInt(shards_start);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void prepDistributed(ResponseBuilder rb) {\n    final SolrQueryRequest req = rb.req;\n    final SolrParams params = req.getParams();\n    final String shards = params.get(ShardParams.SHARDS);\n\n    // since the cost of grabbing cloud state is still up in the air, we grab it only\n    // if we need it.\n    ClusterState clusterState = null;\n    Map<String,Slice> slices = null;\n    CoreDescriptor coreDescriptor = req.getCore().getCoreDescriptor();\n    CloudDescriptor cloudDescriptor = coreDescriptor.getCloudDescriptor();\n    ZkController zkController = req.getCore().getCoreContainer().getZkController();\n\n    final ReplicaListTransformer replicaListTransformer = httpShardHandlerFactory.getReplicaListTransformer(req);\n\n    if (shards != null) {\n      List<String> lst = StrUtils.splitSmart(shards, \",\", true);\n      rb.shards = lst.toArray(new String[lst.size()]);\n      rb.slices = new String[rb.shards.length];\n\n      if (zkController != null) {\n        // figure out which shards are slices\n        for (int i=0; i<rb.shards.length; i++) {\n          if (rb.shards[i].indexOf('/') < 0) {\n            // this is a logical shard\n            rb.slices[i] = rb.shards[i];\n            rb.shards[i] = null;\n          }\n        }\n      }\n    } else if (zkController != null) {\n      // we weren't provided with an explicit list of slices to query via \"shards\", so use the cluster state\n\n      clusterState =  zkController.getClusterState();\n      String shardKeys =  params.get(ShardParams._ROUTE_);\n\n      // This will be the complete list of slices we need to query for this request.\n      slices = new HashMap<>();\n\n      // we need to find out what collections this request is for.\n\n      // A comma-separated list of specified collections.\n      // Eg: \"collection1,collection2,collection3\"\n      String collections = params.get(\"collection\");\n      if (collections != null) {\n        // If there were one or more collections specified in the query, split\n        // each parameter and store as a separate member of a List.\n        List<String> collectionList = StrUtils.splitSmart(collections, \",\",\n            true);\n        // In turn, retrieve the slices that cover each collection from the\n        // cloud state and add them to the Map 'slices'.\n        for (String collectionName : collectionList) {\n          // The original code produced <collection-name>_<shard-name> when the collections\n          // parameter was specified (see ClientUtils.appendMap)\n          // Is this necessary if ony one collection is specified?\n          // i.e. should we change multiCollection to collectionList.size() > 1?\n          addSlices(slices, clusterState, params, collectionName,  shardKeys, true);\n        }\n      } else {\n        // just this collection\n        String collectionName = cloudDescriptor.getCollectionName();\n        addSlices(slices, clusterState, params, collectionName,  shardKeys, false);\n      }\n\n\n      // Store the logical slices in the ResponseBuilder and create a new\n      // String array to hold the physical shards (which will be mapped\n      // later).\n      rb.slices = slices.keySet().toArray(new String[slices.size()]);\n      rb.shards = new String[rb.slices.length];\n    }\n\n    //\n    // Map slices to shards\n    //\n    if (zkController != null) {\n\n      // Are we hosting the shard that this request is for, and are we active? If so, then handle it ourselves\n      // and make it a non-distributed request.\n      String ourSlice = cloudDescriptor.getShardId();\n      String ourCollection = cloudDescriptor.getCollectionName();\n      // Some requests may only be fulfilled by replicas of type Replica.Type.NRT\n      boolean onlyNrtReplicas = Boolean.TRUE == req.getContext().get(ONLY_NRT_REPLICAS);\n      if (rb.slices.length == 1 && rb.slices[0] != null\n          && ( rb.slices[0].equals(ourSlice) || rb.slices[0].equals(ourCollection + \"_\" + ourSlice) )  // handle the <collection>_<slice> format\n          && cloudDescriptor.getLastPublished() == Replica.State.ACTIVE\n          && (!onlyNrtReplicas || cloudDescriptor.getReplicaType() == Replica.Type.NRT)) {\n        boolean shortCircuit = params.getBool(\"shortCircuit\", true);       // currently just a debugging parameter to check distrib search on a single node\n\n        String targetHandler = params.get(ShardParams.SHARDS_QT);\n        shortCircuit = shortCircuit && targetHandler == null;             // if a different handler is specified, don't short-circuit\n\n        if (shortCircuit) {\n          rb.isDistrib = false;\n          rb.shortCircuitedURL = ZkCoreNodeProps.getCoreUrl(zkController.getBaseUrl(), coreDescriptor.getName());\n          return;\n        }\n        // We shouldn't need to do anything to handle \"shard.rows\" since it was previously meant to be an optimization?\n      }\n\n\n      for (int i=0; i<rb.shards.length; i++) {\n        if (rb.shards[i] != null) {\n          final List<String> shardUrls = StrUtils.splitSmart(rb.shards[i], \"|\", true);\n          replicaListTransformer.transform(shardUrls);\n          // And now recreate the | delimited list of equivalent servers\n          rb.shards[i] = createSliceShardsStr(shardUrls);\n        } else {\n          if (clusterState == null) {\n            clusterState =  zkController.getClusterState();\n            slices = clusterState.getSlicesMap(cloudDescriptor.getCollectionName());\n          }\n          String sliceName = rb.slices[i];\n\n          Slice slice = slices.get(sliceName);\n\n          if (slice==null) {\n            // Treat this the same as \"all servers down\" for a slice, and let things continue\n            // if partial results are acceptable\n            rb.shards[i] = \"\";\n            continue;\n            // throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"no such shard: \" + sliceName);\n          }\n          final Predicate<Replica> isShardLeader = new Predicate<Replica>() {\n            private Replica shardLeader = null;\n\n            @Override\n            public boolean test(Replica replica) {\n              if (shardLeader == null) {\n                try {\n                  shardLeader = zkController.getZkStateReader().getLeaderRetry(cloudDescriptor.getCollectionName(), slice.getName());\n                } catch (InterruptedException e) {\n                  throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + slice.getName() + \" in collection \" \n                      + cloudDescriptor.getCollectionName(), e);\n                } catch (SolrException e) {\n                  if (log.isDebugEnabled()) {\n                    log.debug(\"Exception finding leader for shard {} in collection {}. Collection State: {}\", \n                        slice.getName(), cloudDescriptor.getCollectionName(), zkController.getZkStateReader().getClusterState().getCollectionOrNull(cloudDescriptor.getCollectionName()));\n                  }\n                  throw e;\n                }\n              }\n              return replica.getName().equals(shardLeader.getName());\n            }\n          };\n\n          final List<Replica> eligibleSliceReplicas = collectEligibleReplicas(slice, clusterState, onlyNrtReplicas, isShardLeader);\n\n          final List<String> shardUrls = transformReplicasToShardUrls(replicaListTransformer, eligibleSliceReplicas);\n\n          // And now recreate the | delimited list of equivalent servers\n          final String sliceShardsStr = createSliceShardsStr(shardUrls);\n          if (sliceShardsStr.isEmpty()) {\n            boolean tolerant = rb.req.getParams().getBool(ShardParams.SHARDS_TOLERANT, false);\n            if (!tolerant) {\n              // stop the check when there are no replicas available for a shard\n              throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n                  \"no servers hosting shard: \" + rb.slices[i]);\n            }\n          }\n          rb.shards[i] = sliceShardsStr;\n        }\n      }\n    }\n    String shards_rows = params.get(ShardParams.SHARDS_ROWS);\n    if(shards_rows != null) {\n      rb.shards_rows = Integer.parseInt(shards_rows);\n    }\n    String shards_start = params.get(ShardParams.SHARDS_START);\n    if(shards_start != null) {\n      rb.shards_start = Integer.parseInt(shards_start);\n    }\n  }\n\n","bugFix":["5676bf22fd531b9a2a3053047d0e0f922c1c53ff"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7a23cf16c8fa265dc0a564adcabb55e3f054e0ac","date":1502192746,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler#prepDistributed(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler#prepDistributed(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void prepDistributed(ResponseBuilder rb) {\n    final SolrQueryRequest req = rb.req;\n    final SolrParams params = req.getParams();\n    final String shards = params.get(ShardParams.SHARDS);\n\n    // since the cost of grabbing cloud state is still up in the air, we grab it only\n    // if we need it.\n    ClusterState clusterState = null;\n    Map<String,Slice> slices = null;\n    CoreDescriptor coreDescriptor = req.getCore().getCoreDescriptor();\n    CloudDescriptor cloudDescriptor = coreDescriptor.getCloudDescriptor();\n    ZkController zkController = req.getCore().getCoreContainer().getZkController();\n\n    final ReplicaListTransformer replicaListTransformer = httpShardHandlerFactory.getReplicaListTransformer(req);\n\n    if (shards != null) {\n      List<String> lst = StrUtils.splitSmart(shards, \",\", true);\n      rb.shards = lst.toArray(new String[lst.size()]);\n      rb.slices = new String[rb.shards.length];\n\n      if (zkController != null) {\n        // figure out which shards are slices\n        for (int i=0; i<rb.shards.length; i++) {\n          if (rb.shards[i].indexOf('/') < 0) {\n            // this is a logical shard\n            rb.slices[i] = rb.shards[i];\n            rb.shards[i] = null;\n          }\n        }\n      }\n    } else if (zkController != null) {\n      // we weren't provided with an explicit list of slices to query via \"shards\", so use the cluster state\n\n      clusterState =  zkController.getClusterState();\n      String shardKeys =  params.get(ShardParams._ROUTE_);\n\n      // This will be the complete list of slices we need to query for this request.\n      slices = new HashMap<>();\n\n      // we need to find out what collections this request is for.\n\n      // A comma-separated list of specified collections.\n      // Eg: \"collection1,collection2,collection3\"\n      String collections = params.get(\"collection\");\n      if (collections != null) {\n        // If there were one or more collections specified in the query, split\n        // each parameter and store as a separate member of a List.\n        List<String> collectionList = StrUtils.splitSmart(collections, \",\",\n            true);\n        // In turn, retrieve the slices that cover each collection from the\n        // cloud state and add them to the Map 'slices'.\n        for (String collectionName : collectionList) {\n          // The original code produced <collection-name>_<shard-name> when the collections\n          // parameter was specified (see ClientUtils.appendMap)\n          // Is this necessary if ony one collection is specified?\n          // i.e. should we change multiCollection to collectionList.size() > 1?\n          addSlices(slices, clusterState, params, collectionName,  shardKeys, true);\n        }\n      } else {\n        // just this collection\n        String collectionName = cloudDescriptor.getCollectionName();\n        addSlices(slices, clusterState, params, collectionName,  shardKeys, false);\n      }\n\n\n      // Store the logical slices in the ResponseBuilder and create a new\n      // String array to hold the physical shards (which will be mapped\n      // later).\n      rb.slices = slices.keySet().toArray(new String[slices.size()]);\n      rb.shards = new String[rb.slices.length];\n    }\n\n    //\n    // Map slices to shards\n    //\n    if (zkController != null) {\n\n      // Are we hosting the shard that this request is for, and are we active? If so, then handle it ourselves\n      // and make it a non-distributed request.\n      String ourSlice = cloudDescriptor.getShardId();\n      String ourCollection = cloudDescriptor.getCollectionName();\n      // Some requests may only be fulfilled by replicas of type Replica.Type.NRT\n      boolean onlyNrtReplicas = Boolean.TRUE == req.getContext().get(ONLY_NRT_REPLICAS);\n      if (rb.slices.length == 1 && rb.slices[0] != null\n          && ( rb.slices[0].equals(ourSlice) || rb.slices[0].equals(ourCollection + \"_\" + ourSlice) )  // handle the <collection>_<slice> format\n          && cloudDescriptor.getLastPublished() == Replica.State.ACTIVE\n          && (!onlyNrtReplicas || cloudDescriptor.getReplicaType() == Replica.Type.NRT)) {\n        boolean shortCircuit = params.getBool(\"shortCircuit\", true);       // currently just a debugging parameter to check distrib search on a single node\n\n        String targetHandler = params.get(ShardParams.SHARDS_QT);\n        shortCircuit = shortCircuit && targetHandler == null;             // if a different handler is specified, don't short-circuit\n\n        if (shortCircuit) {\n          rb.isDistrib = false;\n          rb.shortCircuitedURL = ZkCoreNodeProps.getCoreUrl(zkController.getBaseUrl(), coreDescriptor.getName());\n          return;\n        }\n        // We shouldn't need to do anything to handle \"shard.rows\" since it was previously meant to be an optimization?\n      }\n\n\n      for (int i=0; i<rb.shards.length; i++) {\n        if (rb.shards[i] != null) {\n          final List<String> shardUrls = StrUtils.splitSmart(rb.shards[i], \"|\", true);\n          replicaListTransformer.transform(shardUrls);\n          // And now recreate the | delimited list of equivalent servers\n          rb.shards[i] = createSliceShardsStr(shardUrls);\n        } else {\n          if (clusterState == null) {\n            clusterState =  zkController.getClusterState();\n            slices = clusterState.getCollection(cloudDescriptor.getCollectionName()).getSlicesMap();\n          }\n          String sliceName = rb.slices[i];\n\n          Slice slice = slices.get(sliceName);\n\n          if (slice==null) {\n            // Treat this the same as \"all servers down\" for a slice, and let things continue\n            // if partial results are acceptable\n            rb.shards[i] = \"\";\n            continue;\n            // throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"no such shard: \" + sliceName);\n          }\n          final Predicate<Replica> isShardLeader = new Predicate<Replica>() {\n            private Replica shardLeader = null;\n\n            @Override\n            public boolean test(Replica replica) {\n              if (shardLeader == null) {\n                try {\n                  shardLeader = zkController.getZkStateReader().getLeaderRetry(cloudDescriptor.getCollectionName(), slice.getName());\n                } catch (InterruptedException e) {\n                  throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + slice.getName() + \" in collection \" \n                      + cloudDescriptor.getCollectionName(), e);\n                } catch (SolrException e) {\n                  if (log.isDebugEnabled()) {\n                    log.debug(\"Exception finding leader for shard {} in collection {}. Collection State: {}\", \n                        slice.getName(), cloudDescriptor.getCollectionName(), zkController.getZkStateReader().getClusterState().getCollectionOrNull(cloudDescriptor.getCollectionName()));\n                  }\n                  throw e;\n                }\n              }\n              return replica.getName().equals(shardLeader.getName());\n            }\n          };\n\n          final List<Replica> eligibleSliceReplicas = collectEligibleReplicas(slice, clusterState, onlyNrtReplicas, isShardLeader);\n\n          final List<String> shardUrls = transformReplicasToShardUrls(replicaListTransformer, eligibleSliceReplicas);\n\n          // And now recreate the | delimited list of equivalent servers\n          final String sliceShardsStr = createSliceShardsStr(shardUrls);\n          if (sliceShardsStr.isEmpty()) {\n            boolean tolerant = rb.req.getParams().getBool(ShardParams.SHARDS_TOLERANT, false);\n            if (!tolerant) {\n              // stop the check when there are no replicas available for a shard\n              throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n                  \"no servers hosting shard: \" + rb.slices[i]);\n            }\n          }\n          rb.shards[i] = sliceShardsStr;\n        }\n      }\n    }\n    String shards_rows = params.get(ShardParams.SHARDS_ROWS);\n    if(shards_rows != null) {\n      rb.shards_rows = Integer.parseInt(shards_rows);\n    }\n    String shards_start = params.get(ShardParams.SHARDS_START);\n    if(shards_start != null) {\n      rb.shards_start = Integer.parseInt(shards_start);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void prepDistributed(ResponseBuilder rb) {\n    final SolrQueryRequest req = rb.req;\n    final SolrParams params = req.getParams();\n    final String shards = params.get(ShardParams.SHARDS);\n\n    // since the cost of grabbing cloud state is still up in the air, we grab it only\n    // if we need it.\n    ClusterState clusterState = null;\n    Map<String,Slice> slices = null;\n    CoreDescriptor coreDescriptor = req.getCore().getCoreDescriptor();\n    CloudDescriptor cloudDescriptor = coreDescriptor.getCloudDescriptor();\n    ZkController zkController = req.getCore().getCoreContainer().getZkController();\n\n    final ReplicaListTransformer replicaListTransformer = httpShardHandlerFactory.getReplicaListTransformer(req);\n\n    if (shards != null) {\n      List<String> lst = StrUtils.splitSmart(shards, \",\", true);\n      rb.shards = lst.toArray(new String[lst.size()]);\n      rb.slices = new String[rb.shards.length];\n\n      if (zkController != null) {\n        // figure out which shards are slices\n        for (int i=0; i<rb.shards.length; i++) {\n          if (rb.shards[i].indexOf('/') < 0) {\n            // this is a logical shard\n            rb.slices[i] = rb.shards[i];\n            rb.shards[i] = null;\n          }\n        }\n      }\n    } else if (zkController != null) {\n      // we weren't provided with an explicit list of slices to query via \"shards\", so use the cluster state\n\n      clusterState =  zkController.getClusterState();\n      String shardKeys =  params.get(ShardParams._ROUTE_);\n\n      // This will be the complete list of slices we need to query for this request.\n      slices = new HashMap<>();\n\n      // we need to find out what collections this request is for.\n\n      // A comma-separated list of specified collections.\n      // Eg: \"collection1,collection2,collection3\"\n      String collections = params.get(\"collection\");\n      if (collections != null) {\n        // If there were one or more collections specified in the query, split\n        // each parameter and store as a separate member of a List.\n        List<String> collectionList = StrUtils.splitSmart(collections, \",\",\n            true);\n        // In turn, retrieve the slices that cover each collection from the\n        // cloud state and add them to the Map 'slices'.\n        for (String collectionName : collectionList) {\n          // The original code produced <collection-name>_<shard-name> when the collections\n          // parameter was specified (see ClientUtils.appendMap)\n          // Is this necessary if ony one collection is specified?\n          // i.e. should we change multiCollection to collectionList.size() > 1?\n          addSlices(slices, clusterState, params, collectionName,  shardKeys, true);\n        }\n      } else {\n        // just this collection\n        String collectionName = cloudDescriptor.getCollectionName();\n        addSlices(slices, clusterState, params, collectionName,  shardKeys, false);\n      }\n\n\n      // Store the logical slices in the ResponseBuilder and create a new\n      // String array to hold the physical shards (which will be mapped\n      // later).\n      rb.slices = slices.keySet().toArray(new String[slices.size()]);\n      rb.shards = new String[rb.slices.length];\n    }\n\n    //\n    // Map slices to shards\n    //\n    if (zkController != null) {\n\n      // Are we hosting the shard that this request is for, and are we active? If so, then handle it ourselves\n      // and make it a non-distributed request.\n      String ourSlice = cloudDescriptor.getShardId();\n      String ourCollection = cloudDescriptor.getCollectionName();\n      // Some requests may only be fulfilled by replicas of type Replica.Type.NRT\n      boolean onlyNrtReplicas = Boolean.TRUE == req.getContext().get(ONLY_NRT_REPLICAS);\n      if (rb.slices.length == 1 && rb.slices[0] != null\n          && ( rb.slices[0].equals(ourSlice) || rb.slices[0].equals(ourCollection + \"_\" + ourSlice) )  // handle the <collection>_<slice> format\n          && cloudDescriptor.getLastPublished() == Replica.State.ACTIVE\n          && (!onlyNrtReplicas || cloudDescriptor.getReplicaType() == Replica.Type.NRT)) {\n        boolean shortCircuit = params.getBool(\"shortCircuit\", true);       // currently just a debugging parameter to check distrib search on a single node\n\n        String targetHandler = params.get(ShardParams.SHARDS_QT);\n        shortCircuit = shortCircuit && targetHandler == null;             // if a different handler is specified, don't short-circuit\n\n        if (shortCircuit) {\n          rb.isDistrib = false;\n          rb.shortCircuitedURL = ZkCoreNodeProps.getCoreUrl(zkController.getBaseUrl(), coreDescriptor.getName());\n          return;\n        }\n        // We shouldn't need to do anything to handle \"shard.rows\" since it was previously meant to be an optimization?\n      }\n\n\n      for (int i=0; i<rb.shards.length; i++) {\n        if (rb.shards[i] != null) {\n          final List<String> shardUrls = StrUtils.splitSmart(rb.shards[i], \"|\", true);\n          replicaListTransformer.transform(shardUrls);\n          // And now recreate the | delimited list of equivalent servers\n          rb.shards[i] = createSliceShardsStr(shardUrls);\n        } else {\n          if (clusterState == null) {\n            clusterState =  zkController.getClusterState();\n            slices = clusterState.getSlicesMap(cloudDescriptor.getCollectionName());\n          }\n          String sliceName = rb.slices[i];\n\n          Slice slice = slices.get(sliceName);\n\n          if (slice==null) {\n            // Treat this the same as \"all servers down\" for a slice, and let things continue\n            // if partial results are acceptable\n            rb.shards[i] = \"\";\n            continue;\n            // throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"no such shard: \" + sliceName);\n          }\n          final Predicate<Replica> isShardLeader = new Predicate<Replica>() {\n            private Replica shardLeader = null;\n\n            @Override\n            public boolean test(Replica replica) {\n              if (shardLeader == null) {\n                try {\n                  shardLeader = zkController.getZkStateReader().getLeaderRetry(cloudDescriptor.getCollectionName(), slice.getName());\n                } catch (InterruptedException e) {\n                  throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + slice.getName() + \" in collection \" \n                      + cloudDescriptor.getCollectionName(), e);\n                } catch (SolrException e) {\n                  if (log.isDebugEnabled()) {\n                    log.debug(\"Exception finding leader for shard {} in collection {}. Collection State: {}\", \n                        slice.getName(), cloudDescriptor.getCollectionName(), zkController.getZkStateReader().getClusterState().getCollectionOrNull(cloudDescriptor.getCollectionName()));\n                  }\n                  throw e;\n                }\n              }\n              return replica.getName().equals(shardLeader.getName());\n            }\n          };\n\n          final List<Replica> eligibleSliceReplicas = collectEligibleReplicas(slice, clusterState, onlyNrtReplicas, isShardLeader);\n\n          final List<String> shardUrls = transformReplicasToShardUrls(replicaListTransformer, eligibleSliceReplicas);\n\n          // And now recreate the | delimited list of equivalent servers\n          final String sliceShardsStr = createSliceShardsStr(shardUrls);\n          if (sliceShardsStr.isEmpty()) {\n            boolean tolerant = rb.req.getParams().getBool(ShardParams.SHARDS_TOLERANT, false);\n            if (!tolerant) {\n              // stop the check when there are no replicas available for a shard\n              throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n                  \"no servers hosting shard: \" + rb.slices[i]);\n            }\n          }\n          rb.shards[i] = sliceShardsStr;\n        }\n      }\n    }\n    String shards_rows = params.get(ShardParams.SHARDS_ROWS);\n    if(shards_rows != null) {\n      rb.shards_rows = Integer.parseInt(shards_rows);\n    }\n    String shards_start = params.get(ShardParams.SHARDS_START);\n    if(shards_start != null) {\n      rb.shards_start = Integer.parseInt(shards_start);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bd22dcd3ba035a1626face7319c94be45ae07172","date":1527224634,"type":3,"author":"Steve Rowe","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler#prepDistributed(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler#prepDistributed(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void prepDistributed(ResponseBuilder rb) {\n    final SolrQueryRequest req = rb.req;\n    final SolrParams params = req.getParams();\n    final String shards = params.get(ShardParams.SHARDS);\n\n    // since the cost of grabbing cloud state is still up in the air, we grab it only\n    // if we need it.\n    ClusterState clusterState = null;\n    Map<String,Slice> slices = null;\n    CoreDescriptor coreDescriptor = req.getCore().getCoreDescriptor();\n    CloudDescriptor cloudDescriptor = coreDescriptor.getCloudDescriptor();\n    ZkController zkController = req.getCore().getCoreContainer().getZkController();\n\n    final ReplicaListTransformer replicaListTransformer = httpShardHandlerFactory.getReplicaListTransformer(req);\n\n    if (shards != null) {\n      List<String> lst = StrUtils.splitSmart(shards, \",\", true);\n      rb.shards = lst.toArray(new String[lst.size()]);\n      rb.slices = new String[rb.shards.length];\n\n      if (zkController != null) {\n        // figure out which shards are slices\n        for (int i=0; i<rb.shards.length; i++) {\n          if (rb.shards[i].indexOf('/') < 0) {\n            // this is a logical shard\n            rb.slices[i] = rb.shards[i];\n            rb.shards[i] = null;\n          }\n        }\n      }\n    } else if (zkController != null) {\n      // we weren't provided with an explicit list of slices to query via \"shards\", so use the cluster state\n\n      clusterState =  zkController.getClusterState();\n      String shardKeys =  params.get(ShardParams._ROUTE_);\n\n      // This will be the complete list of slices we need to query for this request.\n      slices = new HashMap<>();\n\n      // we need to find out what collections this request is for.\n\n      // A comma-separated list of specified collections.\n      // Eg: \"collection1,collection2,collection3\"\n      String collections = params.get(\"collection\");\n      if (collections != null) {\n        // If there were one or more collections specified in the query, split\n        // each parameter and store as a separate member of a List.\n        List<String> collectionList = StrUtils.splitSmart(collections, \",\",\n            true);\n        // In turn, retrieve the slices that cover each collection from the\n        // cloud state and add them to the Map 'slices'.\n        for (String collectionName : collectionList) {\n          // The original code produced <collection-name>_<shard-name> when the collections\n          // parameter was specified (see ClientUtils.appendMap)\n          // Is this necessary if ony one collection is specified?\n          // i.e. should we change multiCollection to collectionList.size() > 1?\n          addSlices(slices, clusterState, params, collectionName,  shardKeys, true);\n        }\n      } else {\n        // just this collection\n        String collectionName = cloudDescriptor.getCollectionName();\n        addSlices(slices, clusterState, params, collectionName,  shardKeys, false);\n      }\n\n\n      // Store the logical slices in the ResponseBuilder and create a new\n      // String array to hold the physical shards (which will be mapped\n      // later).\n      rb.slices = slices.keySet().toArray(new String[slices.size()]);\n      rb.shards = new String[rb.slices.length];\n    }\n\n    //\n    // Map slices to shards\n    //\n    if (zkController != null) {\n\n      // Are we hosting the shard that this request is for, and are we active? If so, then handle it ourselves\n      // and make it a non-distributed request.\n      String ourSlice = cloudDescriptor.getShardId();\n      String ourCollection = cloudDescriptor.getCollectionName();\n      // Some requests may only be fulfilled by replicas of type Replica.Type.NRT\n      boolean onlyNrtReplicas = Boolean.TRUE == req.getContext().get(ONLY_NRT_REPLICAS);\n      if (rb.slices.length == 1 && rb.slices[0] != null\n          && ( rb.slices[0].equals(ourSlice) || rb.slices[0].equals(ourCollection + \"_\" + ourSlice) )  // handle the <collection>_<slice> format\n          && cloudDescriptor.getLastPublished() == Replica.State.ACTIVE\n          && (!onlyNrtReplicas || cloudDescriptor.getReplicaType() == Replica.Type.NRT)) {\n        boolean shortCircuit = params.getBool(\"shortCircuit\", true);       // currently just a debugging parameter to check distrib search on a single node\n\n        String targetHandler = params.get(ShardParams.SHARDS_QT);\n        shortCircuit = shortCircuit && targetHandler == null;             // if a different handler is specified, don't short-circuit\n\n        if (shortCircuit) {\n          rb.isDistrib = false;\n          rb.shortCircuitedURL = ZkCoreNodeProps.getCoreUrl(zkController.getBaseUrl(), coreDescriptor.getName());\n          return;\n        }\n        // We shouldn't need to do anything to handle \"shard.rows\" since it was previously meant to be an optimization?\n      }\n\n\n      for (int i=0; i<rb.shards.length; i++) {\n        if (rb.shards[i] != null) {\n          final List<String> shardUrls = StrUtils.splitSmart(rb.shards[i], \"|\", true);\n          replicaListTransformer.transform(shardUrls);\n          // And now recreate the | delimited list of equivalent servers\n          rb.shards[i] = createSliceShardsStr(shardUrls);\n        } else {\n          if (clusterState == null) {\n            clusterState =  zkController.getClusterState();\n            slices = clusterState.getCollection(cloudDescriptor.getCollectionName()).getSlicesMap();\n          }\n          String sliceName = rb.slices[i];\n\n          Slice slice = slices.get(sliceName);\n\n          if (slice==null) {\n            // Treat this the same as \"all servers down\" for a slice, and let things continue\n            // if partial results are acceptable\n            rb.shards[i] = \"\";\n            continue;\n            // throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"no such shard: \" + sliceName);\n          }\n          final Predicate<Replica> isShardLeader = new Predicate<Replica>() {\n            private Replica shardLeader = null;\n\n            @Override\n            public boolean test(Replica replica) {\n              if (shardLeader == null) {\n                try {\n                  shardLeader = zkController.getZkStateReader().getLeaderRetry(cloudDescriptor.getCollectionName(), slice.getName());\n                } catch (InterruptedException e) {\n                  throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + slice.getName() + \" in collection \" \n                      + cloudDescriptor.getCollectionName(), e);\n                } catch (SolrException e) {\n                  if (log.isDebugEnabled()) {\n                    log.debug(\"Exception finding leader for shard {} in collection {}. Collection State: {}\", \n                        slice.getName(), cloudDescriptor.getCollectionName(), zkController.getZkStateReader().getClusterState().getCollectionOrNull(cloudDescriptor.getCollectionName()));\n                  }\n                  throw e;\n                }\n              }\n              return replica.getName().equals(shardLeader.getName());\n            }\n          };\n\n          final List<Replica> eligibleSliceReplicas = collectEligibleReplicas(slice, clusterState, onlyNrtReplicas, isShardLeader);\n\n          final List<String> shardUrls = transformReplicasToShardUrls(replicaListTransformer, eligibleSliceReplicas);\n\n          // And now recreate the | delimited list of equivalent servers\n          final String sliceShardsStr = createSliceShardsStr(shardUrls);\n          if (sliceShardsStr.isEmpty()) {\n            boolean tolerant = ShardParams.getShardsTolerantAsBool(rb.req.getParams());\n            if (!tolerant) {\n              // stop the check when there are no replicas available for a shard\n              throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n                  \"no servers hosting shard: \" + rb.slices[i]);\n            }\n          }\n          rb.shards[i] = sliceShardsStr;\n        }\n      }\n    }\n    String shards_rows = params.get(ShardParams.SHARDS_ROWS);\n    if(shards_rows != null) {\n      rb.shards_rows = Integer.parseInt(shards_rows);\n    }\n    String shards_start = params.get(ShardParams.SHARDS_START);\n    if(shards_start != null) {\n      rb.shards_start = Integer.parseInt(shards_start);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void prepDistributed(ResponseBuilder rb) {\n    final SolrQueryRequest req = rb.req;\n    final SolrParams params = req.getParams();\n    final String shards = params.get(ShardParams.SHARDS);\n\n    // since the cost of grabbing cloud state is still up in the air, we grab it only\n    // if we need it.\n    ClusterState clusterState = null;\n    Map<String,Slice> slices = null;\n    CoreDescriptor coreDescriptor = req.getCore().getCoreDescriptor();\n    CloudDescriptor cloudDescriptor = coreDescriptor.getCloudDescriptor();\n    ZkController zkController = req.getCore().getCoreContainer().getZkController();\n\n    final ReplicaListTransformer replicaListTransformer = httpShardHandlerFactory.getReplicaListTransformer(req);\n\n    if (shards != null) {\n      List<String> lst = StrUtils.splitSmart(shards, \",\", true);\n      rb.shards = lst.toArray(new String[lst.size()]);\n      rb.slices = new String[rb.shards.length];\n\n      if (zkController != null) {\n        // figure out which shards are slices\n        for (int i=0; i<rb.shards.length; i++) {\n          if (rb.shards[i].indexOf('/') < 0) {\n            // this is a logical shard\n            rb.slices[i] = rb.shards[i];\n            rb.shards[i] = null;\n          }\n        }\n      }\n    } else if (zkController != null) {\n      // we weren't provided with an explicit list of slices to query via \"shards\", so use the cluster state\n\n      clusterState =  zkController.getClusterState();\n      String shardKeys =  params.get(ShardParams._ROUTE_);\n\n      // This will be the complete list of slices we need to query for this request.\n      slices = new HashMap<>();\n\n      // we need to find out what collections this request is for.\n\n      // A comma-separated list of specified collections.\n      // Eg: \"collection1,collection2,collection3\"\n      String collections = params.get(\"collection\");\n      if (collections != null) {\n        // If there were one or more collections specified in the query, split\n        // each parameter and store as a separate member of a List.\n        List<String> collectionList = StrUtils.splitSmart(collections, \",\",\n            true);\n        // In turn, retrieve the slices that cover each collection from the\n        // cloud state and add them to the Map 'slices'.\n        for (String collectionName : collectionList) {\n          // The original code produced <collection-name>_<shard-name> when the collections\n          // parameter was specified (see ClientUtils.appendMap)\n          // Is this necessary if ony one collection is specified?\n          // i.e. should we change multiCollection to collectionList.size() > 1?\n          addSlices(slices, clusterState, params, collectionName,  shardKeys, true);\n        }\n      } else {\n        // just this collection\n        String collectionName = cloudDescriptor.getCollectionName();\n        addSlices(slices, clusterState, params, collectionName,  shardKeys, false);\n      }\n\n\n      // Store the logical slices in the ResponseBuilder and create a new\n      // String array to hold the physical shards (which will be mapped\n      // later).\n      rb.slices = slices.keySet().toArray(new String[slices.size()]);\n      rb.shards = new String[rb.slices.length];\n    }\n\n    //\n    // Map slices to shards\n    //\n    if (zkController != null) {\n\n      // Are we hosting the shard that this request is for, and are we active? If so, then handle it ourselves\n      // and make it a non-distributed request.\n      String ourSlice = cloudDescriptor.getShardId();\n      String ourCollection = cloudDescriptor.getCollectionName();\n      // Some requests may only be fulfilled by replicas of type Replica.Type.NRT\n      boolean onlyNrtReplicas = Boolean.TRUE == req.getContext().get(ONLY_NRT_REPLICAS);\n      if (rb.slices.length == 1 && rb.slices[0] != null\n          && ( rb.slices[0].equals(ourSlice) || rb.slices[0].equals(ourCollection + \"_\" + ourSlice) )  // handle the <collection>_<slice> format\n          && cloudDescriptor.getLastPublished() == Replica.State.ACTIVE\n          && (!onlyNrtReplicas || cloudDescriptor.getReplicaType() == Replica.Type.NRT)) {\n        boolean shortCircuit = params.getBool(\"shortCircuit\", true);       // currently just a debugging parameter to check distrib search on a single node\n\n        String targetHandler = params.get(ShardParams.SHARDS_QT);\n        shortCircuit = shortCircuit && targetHandler == null;             // if a different handler is specified, don't short-circuit\n\n        if (shortCircuit) {\n          rb.isDistrib = false;\n          rb.shortCircuitedURL = ZkCoreNodeProps.getCoreUrl(zkController.getBaseUrl(), coreDescriptor.getName());\n          return;\n        }\n        // We shouldn't need to do anything to handle \"shard.rows\" since it was previously meant to be an optimization?\n      }\n\n\n      for (int i=0; i<rb.shards.length; i++) {\n        if (rb.shards[i] != null) {\n          final List<String> shardUrls = StrUtils.splitSmart(rb.shards[i], \"|\", true);\n          replicaListTransformer.transform(shardUrls);\n          // And now recreate the | delimited list of equivalent servers\n          rb.shards[i] = createSliceShardsStr(shardUrls);\n        } else {\n          if (clusterState == null) {\n            clusterState =  zkController.getClusterState();\n            slices = clusterState.getCollection(cloudDescriptor.getCollectionName()).getSlicesMap();\n          }\n          String sliceName = rb.slices[i];\n\n          Slice slice = slices.get(sliceName);\n\n          if (slice==null) {\n            // Treat this the same as \"all servers down\" for a slice, and let things continue\n            // if partial results are acceptable\n            rb.shards[i] = \"\";\n            continue;\n            // throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"no such shard: \" + sliceName);\n          }\n          final Predicate<Replica> isShardLeader = new Predicate<Replica>() {\n            private Replica shardLeader = null;\n\n            @Override\n            public boolean test(Replica replica) {\n              if (shardLeader == null) {\n                try {\n                  shardLeader = zkController.getZkStateReader().getLeaderRetry(cloudDescriptor.getCollectionName(), slice.getName());\n                } catch (InterruptedException e) {\n                  throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + slice.getName() + \" in collection \" \n                      + cloudDescriptor.getCollectionName(), e);\n                } catch (SolrException e) {\n                  if (log.isDebugEnabled()) {\n                    log.debug(\"Exception finding leader for shard {} in collection {}. Collection State: {}\", \n                        slice.getName(), cloudDescriptor.getCollectionName(), zkController.getZkStateReader().getClusterState().getCollectionOrNull(cloudDescriptor.getCollectionName()));\n                  }\n                  throw e;\n                }\n              }\n              return replica.getName().equals(shardLeader.getName());\n            }\n          };\n\n          final List<Replica> eligibleSliceReplicas = collectEligibleReplicas(slice, clusterState, onlyNrtReplicas, isShardLeader);\n\n          final List<String> shardUrls = transformReplicasToShardUrls(replicaListTransformer, eligibleSliceReplicas);\n\n          // And now recreate the | delimited list of equivalent servers\n          final String sliceShardsStr = createSliceShardsStr(shardUrls);\n          if (sliceShardsStr.isEmpty()) {\n            boolean tolerant = rb.req.getParams().getBool(ShardParams.SHARDS_TOLERANT, false);\n            if (!tolerant) {\n              // stop the check when there are no replicas available for a shard\n              throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n                  \"no servers hosting shard: \" + rb.slices[i]);\n            }\n          }\n          rb.shards[i] = sliceShardsStr;\n        }\n      }\n    }\n    String shards_rows = params.get(ShardParams.SHARDS_ROWS);\n    if(shards_rows != null) {\n      rb.shards_rows = Integer.parseInt(shards_rows);\n    }\n    String shards_start = params.get(ShardParams.SHARDS_START);\n    if(shards_start != null) {\n      rb.shards_start = Integer.parseInt(shards_start);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4d51e7db479b42602c7e23ba871b177387268179","date":1547581497,"type":3,"author":"Tomas Fernandez Lobbe","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler#prepDistributed(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler#prepDistributed(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void prepDistributed(ResponseBuilder rb) {\n    final SolrQueryRequest req = rb.req;\n    final SolrParams params = req.getParams();\n    final String shards = params.get(ShardParams.SHARDS);\n\n    // since the cost of grabbing cloud state is still up in the air, we grab it only\n    // if we need it.\n    ClusterState clusterState = null;\n    Map<String,Slice> slices = null;\n    CoreDescriptor coreDescriptor = req.getCore().getCoreDescriptor();\n    CloudDescriptor cloudDescriptor = coreDescriptor.getCloudDescriptor();\n    ZkController zkController = req.getCore().getCoreContainer().getZkController();\n\n    final ReplicaListTransformer replicaListTransformer = httpShardHandlerFactory.getReplicaListTransformer(req);\n\n    if (shards != null) {\n      List<String> lst = StrUtils.splitSmart(shards, \",\", true);\n      rb.shards = lst.toArray(new String[lst.size()]);\n      rb.slices = new String[rb.shards.length];\n\n      if (zkController != null) {\n        // figure out which shards are slices\n        for (int i=0; i<rb.shards.length; i++) {\n          if (rb.shards[i].indexOf('/') < 0) {\n            // this is a logical shard\n            rb.slices[i] = rb.shards[i];\n            rb.shards[i] = null;\n          }\n        }\n      }\n    } else if (zkController != null) {\n      // we weren't provided with an explicit list of slices to query via \"shards\", so use the cluster state\n\n      clusterState =  zkController.getClusterState();\n      String shardKeys =  params.get(ShardParams._ROUTE_);\n\n      // This will be the complete list of slices we need to query for this request.\n      slices = new HashMap<>();\n\n      // we need to find out what collections this request is for.\n\n      // A comma-separated list of specified collections.\n      // Eg: \"collection1,collection2,collection3\"\n      String collections = params.get(\"collection\");\n      if (collections != null) {\n        // If there were one or more collections specified in the query, split\n        // each parameter and store as a separate member of a List.\n        List<String> collectionList = StrUtils.splitSmart(collections, \",\",\n            true);\n        // In turn, retrieve the slices that cover each collection from the\n        // cloud state and add them to the Map 'slices'.\n        for (String collectionName : collectionList) {\n          // The original code produced <collection-name>_<shard-name> when the collections\n          // parameter was specified (see ClientUtils.appendMap)\n          // Is this necessary if ony one collection is specified?\n          // i.e. should we change multiCollection to collectionList.size() > 1?\n          addSlices(slices, clusterState, params, collectionName,  shardKeys, true);\n        }\n      } else {\n        // just this collection\n        String collectionName = cloudDescriptor.getCollectionName();\n        addSlices(slices, clusterState, params, collectionName,  shardKeys, false);\n      }\n\n\n      // Store the logical slices in the ResponseBuilder and create a new\n      // String array to hold the physical shards (which will be mapped\n      // later).\n      rb.slices = slices.keySet().toArray(new String[slices.size()]);\n      rb.shards = new String[rb.slices.length];\n    }\n\n    HttpShardHandlerFactory.WhitelistHostChecker hostChecker = httpShardHandlerFactory.getWhitelistHostChecker();\n    if (shards != null && zkController == null && hostChecker.isWhitelistHostCheckingEnabled() && !hostChecker.hasExplicitWhitelist()) {\n      throw new SolrException(ErrorCode.FORBIDDEN, \"HttpShardHandlerFactory \"+HttpShardHandlerFactory.INIT_SHARDS_WHITELIST\n          +\" not configured but required (in lieu of ZkController and ClusterState) when using the '\"+ShardParams.SHARDS+\"' parameter.\"\n          +HttpShardHandlerFactory.SET_SOLR_DISABLE_SHARDS_WHITELIST_CLUE);\n    }\n\n    //\n    // Map slices to shards\n    //\n    if (zkController != null) {\n\n      // Are we hosting the shard that this request is for, and are we active? If so, then handle it ourselves\n      // and make it a non-distributed request.\n      String ourSlice = cloudDescriptor.getShardId();\n      String ourCollection = cloudDescriptor.getCollectionName();\n      // Some requests may only be fulfilled by replicas of type Replica.Type.NRT\n      boolean onlyNrtReplicas = Boolean.TRUE == req.getContext().get(ONLY_NRT_REPLICAS);\n      if (rb.slices.length == 1 && rb.slices[0] != null\n          && ( rb.slices[0].equals(ourSlice) || rb.slices[0].equals(ourCollection + \"_\" + ourSlice) )  // handle the <collection>_<slice> format\n          && cloudDescriptor.getLastPublished() == Replica.State.ACTIVE\n          && (!onlyNrtReplicas || cloudDescriptor.getReplicaType() == Replica.Type.NRT)) {\n        boolean shortCircuit = params.getBool(\"shortCircuit\", true);       // currently just a debugging parameter to check distrib search on a single node\n\n        String targetHandler = params.get(ShardParams.SHARDS_QT);\n        shortCircuit = shortCircuit && targetHandler == null;             // if a different handler is specified, don't short-circuit\n\n        if (shortCircuit) {\n          rb.isDistrib = false;\n          rb.shortCircuitedURL = ZkCoreNodeProps.getCoreUrl(zkController.getBaseUrl(), coreDescriptor.getName());\n          if (hostChecker.isWhitelistHostCheckingEnabled() && hostChecker.hasExplicitWhitelist()) {\n            /*\n             * We only need to check the host whitelist if there is an explicit whitelist (other than all the live nodes)\n             * when the \"shards\" indicate cluster state elements only\n             */\n            hostChecker.checkWhitelist(clusterState, shards, Arrays.asList(rb.shortCircuitedURL));\n          }\n          return;\n        }\n        // We shouldn't need to do anything to handle \"shard.rows\" since it was previously meant to be an optimization?\n      }\n      \n      if (clusterState == null && zkController != null) {\n        clusterState =  zkController.getClusterState();\n      }\n\n\n      for (int i=0; i<rb.shards.length; i++) {\n        if (rb.shards[i] != null) {\n          final List<String> shardUrls = StrUtils.splitSmart(rb.shards[i], \"|\", true);\n          replicaListTransformer.transform(shardUrls);\n          hostChecker.checkWhitelist(clusterState, shards, shardUrls);\n          // And now recreate the | delimited list of equivalent servers\n          rb.shards[i] = createSliceShardsStr(shardUrls);\n        } else {\n          if (slices == null) {\n            slices = clusterState.getCollection(cloudDescriptor.getCollectionName()).getSlicesMap();\n          }\n          String sliceName = rb.slices[i];\n\n          Slice slice = slices.get(sliceName);\n\n          if (slice==null) {\n            // Treat this the same as \"all servers down\" for a slice, and let things continue\n            // if partial results are acceptable\n            rb.shards[i] = \"\";\n            continue;\n            // throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"no such shard: \" + sliceName);\n          }\n          final Predicate<Replica> isShardLeader = new Predicate<Replica>() {\n            private Replica shardLeader = null;\n\n            @Override\n            public boolean test(Replica replica) {\n              if (shardLeader == null) {\n                try {\n                  shardLeader = zkController.getZkStateReader().getLeaderRetry(cloudDescriptor.getCollectionName(), slice.getName());\n                } catch (InterruptedException e) {\n                  throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + slice.getName() + \" in collection \" \n                      + cloudDescriptor.getCollectionName(), e);\n                } catch (SolrException e) {\n                  if (log.isDebugEnabled()) {\n                    log.debug(\"Exception finding leader for shard {} in collection {}. Collection State: {}\", \n                        slice.getName(), cloudDescriptor.getCollectionName(), zkController.getZkStateReader().getClusterState().getCollectionOrNull(cloudDescriptor.getCollectionName()));\n                  }\n                  throw e;\n                }\n              }\n              return replica.getName().equals(shardLeader.getName());\n            }\n          };\n\n          final List<Replica> eligibleSliceReplicas = collectEligibleReplicas(slice, clusterState, onlyNrtReplicas, isShardLeader);\n\n          final List<String> shardUrls = transformReplicasToShardUrls(replicaListTransformer, eligibleSliceReplicas);\n\n          if (hostChecker.isWhitelistHostCheckingEnabled() && hostChecker.hasExplicitWhitelist()) {\n            /*\n             * We only need to check the host whitelist if there is an explicit whitelist (other than all the live nodes)\n             * when the \"shards\" indicate cluster state elements only\n             */\n            hostChecker.checkWhitelist(clusterState, shards, shardUrls);\n          }\n\n          // And now recreate the | delimited list of equivalent servers\n          final String sliceShardsStr = createSliceShardsStr(shardUrls);\n          if (sliceShardsStr.isEmpty()) {\n            boolean tolerant = ShardParams.getShardsTolerantAsBool(rb.req.getParams());\n            if (!tolerant) {\n              // stop the check when there are no replicas available for a shard\n              throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n                  \"no servers hosting shard: \" + rb.slices[i]);\n            }\n          }\n          rb.shards[i] = sliceShardsStr;\n        }\n      }\n    } else {\n      if (shards != null) {\n        // No cloud, verbatim check of shards\n        hostChecker.checkWhitelist(shards, new ArrayList<>(Arrays.asList(shards.split(\"[,|]\"))));\n      }\n    }\n    String shards_rows = params.get(ShardParams.SHARDS_ROWS);\n    if(shards_rows != null) {\n      rb.shards_rows = Integer.parseInt(shards_rows);\n    }\n    String shards_start = params.get(ShardParams.SHARDS_START);\n    if(shards_start != null) {\n      rb.shards_start = Integer.parseInt(shards_start);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void prepDistributed(ResponseBuilder rb) {\n    final SolrQueryRequest req = rb.req;\n    final SolrParams params = req.getParams();\n    final String shards = params.get(ShardParams.SHARDS);\n\n    // since the cost of grabbing cloud state is still up in the air, we grab it only\n    // if we need it.\n    ClusterState clusterState = null;\n    Map<String,Slice> slices = null;\n    CoreDescriptor coreDescriptor = req.getCore().getCoreDescriptor();\n    CloudDescriptor cloudDescriptor = coreDescriptor.getCloudDescriptor();\n    ZkController zkController = req.getCore().getCoreContainer().getZkController();\n\n    final ReplicaListTransformer replicaListTransformer = httpShardHandlerFactory.getReplicaListTransformer(req);\n\n    if (shards != null) {\n      List<String> lst = StrUtils.splitSmart(shards, \",\", true);\n      rb.shards = lst.toArray(new String[lst.size()]);\n      rb.slices = new String[rb.shards.length];\n\n      if (zkController != null) {\n        // figure out which shards are slices\n        for (int i=0; i<rb.shards.length; i++) {\n          if (rb.shards[i].indexOf('/') < 0) {\n            // this is a logical shard\n            rb.slices[i] = rb.shards[i];\n            rb.shards[i] = null;\n          }\n        }\n      }\n    } else if (zkController != null) {\n      // we weren't provided with an explicit list of slices to query via \"shards\", so use the cluster state\n\n      clusterState =  zkController.getClusterState();\n      String shardKeys =  params.get(ShardParams._ROUTE_);\n\n      // This will be the complete list of slices we need to query for this request.\n      slices = new HashMap<>();\n\n      // we need to find out what collections this request is for.\n\n      // A comma-separated list of specified collections.\n      // Eg: \"collection1,collection2,collection3\"\n      String collections = params.get(\"collection\");\n      if (collections != null) {\n        // If there were one or more collections specified in the query, split\n        // each parameter and store as a separate member of a List.\n        List<String> collectionList = StrUtils.splitSmart(collections, \",\",\n            true);\n        // In turn, retrieve the slices that cover each collection from the\n        // cloud state and add them to the Map 'slices'.\n        for (String collectionName : collectionList) {\n          // The original code produced <collection-name>_<shard-name> when the collections\n          // parameter was specified (see ClientUtils.appendMap)\n          // Is this necessary if ony one collection is specified?\n          // i.e. should we change multiCollection to collectionList.size() > 1?\n          addSlices(slices, clusterState, params, collectionName,  shardKeys, true);\n        }\n      } else {\n        // just this collection\n        String collectionName = cloudDescriptor.getCollectionName();\n        addSlices(slices, clusterState, params, collectionName,  shardKeys, false);\n      }\n\n\n      // Store the logical slices in the ResponseBuilder and create a new\n      // String array to hold the physical shards (which will be mapped\n      // later).\n      rb.slices = slices.keySet().toArray(new String[slices.size()]);\n      rb.shards = new String[rb.slices.length];\n    }\n\n    //\n    // Map slices to shards\n    //\n    if (zkController != null) {\n\n      // Are we hosting the shard that this request is for, and are we active? If so, then handle it ourselves\n      // and make it a non-distributed request.\n      String ourSlice = cloudDescriptor.getShardId();\n      String ourCollection = cloudDescriptor.getCollectionName();\n      // Some requests may only be fulfilled by replicas of type Replica.Type.NRT\n      boolean onlyNrtReplicas = Boolean.TRUE == req.getContext().get(ONLY_NRT_REPLICAS);\n      if (rb.slices.length == 1 && rb.slices[0] != null\n          && ( rb.slices[0].equals(ourSlice) || rb.slices[0].equals(ourCollection + \"_\" + ourSlice) )  // handle the <collection>_<slice> format\n          && cloudDescriptor.getLastPublished() == Replica.State.ACTIVE\n          && (!onlyNrtReplicas || cloudDescriptor.getReplicaType() == Replica.Type.NRT)) {\n        boolean shortCircuit = params.getBool(\"shortCircuit\", true);       // currently just a debugging parameter to check distrib search on a single node\n\n        String targetHandler = params.get(ShardParams.SHARDS_QT);\n        shortCircuit = shortCircuit && targetHandler == null;             // if a different handler is specified, don't short-circuit\n\n        if (shortCircuit) {\n          rb.isDistrib = false;\n          rb.shortCircuitedURL = ZkCoreNodeProps.getCoreUrl(zkController.getBaseUrl(), coreDescriptor.getName());\n          return;\n        }\n        // We shouldn't need to do anything to handle \"shard.rows\" since it was previously meant to be an optimization?\n      }\n\n\n      for (int i=0; i<rb.shards.length; i++) {\n        if (rb.shards[i] != null) {\n          final List<String> shardUrls = StrUtils.splitSmart(rb.shards[i], \"|\", true);\n          replicaListTransformer.transform(shardUrls);\n          // And now recreate the | delimited list of equivalent servers\n          rb.shards[i] = createSliceShardsStr(shardUrls);\n        } else {\n          if (clusterState == null) {\n            clusterState =  zkController.getClusterState();\n            slices = clusterState.getCollection(cloudDescriptor.getCollectionName()).getSlicesMap();\n          }\n          String sliceName = rb.slices[i];\n\n          Slice slice = slices.get(sliceName);\n\n          if (slice==null) {\n            // Treat this the same as \"all servers down\" for a slice, and let things continue\n            // if partial results are acceptable\n            rb.shards[i] = \"\";\n            continue;\n            // throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"no such shard: \" + sliceName);\n          }\n          final Predicate<Replica> isShardLeader = new Predicate<Replica>() {\n            private Replica shardLeader = null;\n\n            @Override\n            public boolean test(Replica replica) {\n              if (shardLeader == null) {\n                try {\n                  shardLeader = zkController.getZkStateReader().getLeaderRetry(cloudDescriptor.getCollectionName(), slice.getName());\n                } catch (InterruptedException e) {\n                  throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + slice.getName() + \" in collection \" \n                      + cloudDescriptor.getCollectionName(), e);\n                } catch (SolrException e) {\n                  if (log.isDebugEnabled()) {\n                    log.debug(\"Exception finding leader for shard {} in collection {}. Collection State: {}\", \n                        slice.getName(), cloudDescriptor.getCollectionName(), zkController.getZkStateReader().getClusterState().getCollectionOrNull(cloudDescriptor.getCollectionName()));\n                  }\n                  throw e;\n                }\n              }\n              return replica.getName().equals(shardLeader.getName());\n            }\n          };\n\n          final List<Replica> eligibleSliceReplicas = collectEligibleReplicas(slice, clusterState, onlyNrtReplicas, isShardLeader);\n\n          final List<String> shardUrls = transformReplicasToShardUrls(replicaListTransformer, eligibleSliceReplicas);\n\n          // And now recreate the | delimited list of equivalent servers\n          final String sliceShardsStr = createSliceShardsStr(shardUrls);\n          if (sliceShardsStr.isEmpty()) {\n            boolean tolerant = ShardParams.getShardsTolerantAsBool(rb.req.getParams());\n            if (!tolerant) {\n              // stop the check when there are no replicas available for a shard\n              throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n                  \"no servers hosting shard: \" + rb.slices[i]);\n            }\n          }\n          rb.shards[i] = sliceShardsStr;\n        }\n      }\n    }\n    String shards_rows = params.get(ShardParams.SHARDS_ROWS);\n    if(shards_rows != null) {\n      rb.shards_rows = Integer.parseInt(shards_rows);\n    }\n    String shards_start = params.get(ShardParams.SHARDS_START);\n    if(shards_start != null) {\n      rb.shards_start = Integer.parseInt(shards_start);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cc28b46d62a8b91c8e90f9345612c4050eab98d4","date":1581344825,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler#prepDistributed(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler#prepDistributed(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void prepDistributed(ResponseBuilder rb) {\n    final SolrQueryRequest req = rb.req;\n    final SolrParams params = req.getParams();\n    final String shards = params.get(ShardParams.SHARDS);\n\n    CoreDescriptor coreDescriptor = req.getCore().getCoreDescriptor();\n    CloudDescriptor cloudDescriptor = coreDescriptor.getCloudDescriptor();\n    ZkController zkController = req.getCore().getCoreContainer().getZkController();\n\n    final ReplicaListTransformer replicaListTransformer = httpShardHandlerFactory.getReplicaListTransformer(req);\n\n    HttpShardHandlerFactory.WhitelistHostChecker hostChecker = httpShardHandlerFactory.getWhitelistHostChecker();\n    if (shards != null && zkController == null && hostChecker.isWhitelistHostCheckingEnabled() && !hostChecker.hasExplicitWhitelist()) {\n      throw new SolrException(SolrException.ErrorCode.FORBIDDEN, \"HttpShardHandlerFactory \" + HttpShardHandlerFactory.INIT_SHARDS_WHITELIST\n          + \" not configured but required (in lieu of ZkController and ClusterState) when using the '\" + ShardParams.SHARDS + \"' parameter.\"\n          + HttpShardHandlerFactory.SET_SOLR_DISABLE_SHARDS_WHITELIST_CLUE);\n    }\n\n    ReplicaSource replicaSource;\n    if (zkController != null) {\n      boolean onlyNrt = Boolean.TRUE == req.getContext().get(ONLY_NRT_REPLICAS);\n\n      replicaSource = new CloudReplicaSource.Builder()\n          .params(params)\n          .zkStateReader(zkController.getZkStateReader())\n          .whitelistHostChecker(hostChecker)\n          .replicaListTransformer(replicaListTransformer)\n          .collection(cloudDescriptor.getCollectionName())\n          .onlyNrt(onlyNrt)\n          .build();\n      rb.slices = replicaSource.getSliceNames().toArray(new String[replicaSource.getSliceCount()]);\n\n      if (canShortCircuit(rb.slices, onlyNrt, params, cloudDescriptor)) {\n        rb.isDistrib = false;\n        rb.shortCircuitedURL = ZkCoreNodeProps.getCoreUrl(zkController.getBaseUrl(), coreDescriptor.getName());\n        return;\n        // We shouldn't need to do anything to handle \"shard.rows\" since it was previously meant to be an optimization?\n      }\n\n      for (int i = 0; i < rb.slices.length; i++) {\n        if (!ShardParams.getShardsTolerantAsBool(params) && replicaSource.getReplicasBySlice(i).isEmpty()) {\n          // stop the check when there are no replicas available for a shard\n          // todo fix use of slices[i] which can be null if user specified urls in shards param\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"no servers hosting shard: \" + rb.slices[i]);\n        }\n      }\n    } else {\n      replicaSource = new LegacyReplicaSource.Builder()\n          .whitelistHostChecker(hostChecker)\n          .shards(shards)\n          .build();\n      rb.slices = new String[replicaSource.getSliceCount()];\n    }\n\n    rb.shards = new String[rb.slices.length];\n    for (int i = 0; i < rb.slices.length; i++) {\n      rb.shards[i] = createSliceShardsStr(replicaSource.getReplicasBySlice(i));\n    }\n\n    String shards_rows = params.get(ShardParams.SHARDS_ROWS);\n    if (shards_rows != null) {\n      rb.shards_rows = Integer.parseInt(shards_rows);\n    }\n    String shards_start = params.get(ShardParams.SHARDS_START);\n    if (shards_start != null) {\n      rb.shards_start = Integer.parseInt(shards_start);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void prepDistributed(ResponseBuilder rb) {\n    final SolrQueryRequest req = rb.req;\n    final SolrParams params = req.getParams();\n    final String shards = params.get(ShardParams.SHARDS);\n\n    // since the cost of grabbing cloud state is still up in the air, we grab it only\n    // if we need it.\n    ClusterState clusterState = null;\n    Map<String,Slice> slices = null;\n    CoreDescriptor coreDescriptor = req.getCore().getCoreDescriptor();\n    CloudDescriptor cloudDescriptor = coreDescriptor.getCloudDescriptor();\n    ZkController zkController = req.getCore().getCoreContainer().getZkController();\n\n    final ReplicaListTransformer replicaListTransformer = httpShardHandlerFactory.getReplicaListTransformer(req);\n\n    if (shards != null) {\n      List<String> lst = StrUtils.splitSmart(shards, \",\", true);\n      rb.shards = lst.toArray(new String[lst.size()]);\n      rb.slices = new String[rb.shards.length];\n\n      if (zkController != null) {\n        // figure out which shards are slices\n        for (int i=0; i<rb.shards.length; i++) {\n          if (rb.shards[i].indexOf('/') < 0) {\n            // this is a logical shard\n            rb.slices[i] = rb.shards[i];\n            rb.shards[i] = null;\n          }\n        }\n      }\n    } else if (zkController != null) {\n      // we weren't provided with an explicit list of slices to query via \"shards\", so use the cluster state\n\n      clusterState =  zkController.getClusterState();\n      String shardKeys =  params.get(ShardParams._ROUTE_);\n\n      // This will be the complete list of slices we need to query for this request.\n      slices = new HashMap<>();\n\n      // we need to find out what collections this request is for.\n\n      // A comma-separated list of specified collections.\n      // Eg: \"collection1,collection2,collection3\"\n      String collections = params.get(\"collection\");\n      if (collections != null) {\n        // If there were one or more collections specified in the query, split\n        // each parameter and store as a separate member of a List.\n        List<String> collectionList = StrUtils.splitSmart(collections, \",\",\n            true);\n        // In turn, retrieve the slices that cover each collection from the\n        // cloud state and add them to the Map 'slices'.\n        for (String collectionName : collectionList) {\n          // The original code produced <collection-name>_<shard-name> when the collections\n          // parameter was specified (see ClientUtils.appendMap)\n          // Is this necessary if ony one collection is specified?\n          // i.e. should we change multiCollection to collectionList.size() > 1?\n          addSlices(slices, clusterState, params, collectionName,  shardKeys, true);\n        }\n      } else {\n        // just this collection\n        String collectionName = cloudDescriptor.getCollectionName();\n        addSlices(slices, clusterState, params, collectionName,  shardKeys, false);\n      }\n\n\n      // Store the logical slices in the ResponseBuilder and create a new\n      // String array to hold the physical shards (which will be mapped\n      // later).\n      rb.slices = slices.keySet().toArray(new String[slices.size()]);\n      rb.shards = new String[rb.slices.length];\n    }\n\n    HttpShardHandlerFactory.WhitelistHostChecker hostChecker = httpShardHandlerFactory.getWhitelistHostChecker();\n    if (shards != null && zkController == null && hostChecker.isWhitelistHostCheckingEnabled() && !hostChecker.hasExplicitWhitelist()) {\n      throw new SolrException(ErrorCode.FORBIDDEN, \"HttpShardHandlerFactory \"+HttpShardHandlerFactory.INIT_SHARDS_WHITELIST\n          +\" not configured but required (in lieu of ZkController and ClusterState) when using the '\"+ShardParams.SHARDS+\"' parameter.\"\n          +HttpShardHandlerFactory.SET_SOLR_DISABLE_SHARDS_WHITELIST_CLUE);\n    }\n\n    //\n    // Map slices to shards\n    //\n    if (zkController != null) {\n\n      // Are we hosting the shard that this request is for, and are we active? If so, then handle it ourselves\n      // and make it a non-distributed request.\n      String ourSlice = cloudDescriptor.getShardId();\n      String ourCollection = cloudDescriptor.getCollectionName();\n      // Some requests may only be fulfilled by replicas of type Replica.Type.NRT\n      boolean onlyNrtReplicas = Boolean.TRUE == req.getContext().get(ONLY_NRT_REPLICAS);\n      if (rb.slices.length == 1 && rb.slices[0] != null\n          && ( rb.slices[0].equals(ourSlice) || rb.slices[0].equals(ourCollection + \"_\" + ourSlice) )  // handle the <collection>_<slice> format\n          && cloudDescriptor.getLastPublished() == Replica.State.ACTIVE\n          && (!onlyNrtReplicas || cloudDescriptor.getReplicaType() == Replica.Type.NRT)) {\n        boolean shortCircuit = params.getBool(\"shortCircuit\", true);       // currently just a debugging parameter to check distrib search on a single node\n\n        String targetHandler = params.get(ShardParams.SHARDS_QT);\n        shortCircuit = shortCircuit && targetHandler == null;             // if a different handler is specified, don't short-circuit\n\n        if (shortCircuit) {\n          rb.isDistrib = false;\n          rb.shortCircuitedURL = ZkCoreNodeProps.getCoreUrl(zkController.getBaseUrl(), coreDescriptor.getName());\n          if (hostChecker.isWhitelistHostCheckingEnabled() && hostChecker.hasExplicitWhitelist()) {\n            /*\n             * We only need to check the host whitelist if there is an explicit whitelist (other than all the live nodes)\n             * when the \"shards\" indicate cluster state elements only\n             */\n            hostChecker.checkWhitelist(clusterState, shards, Arrays.asList(rb.shortCircuitedURL));\n          }\n          return;\n        }\n        // We shouldn't need to do anything to handle \"shard.rows\" since it was previously meant to be an optimization?\n      }\n      \n      if (clusterState == null && zkController != null) {\n        clusterState =  zkController.getClusterState();\n      }\n\n\n      for (int i=0; i<rb.shards.length; i++) {\n        if (rb.shards[i] != null) {\n          final List<String> shardUrls = StrUtils.splitSmart(rb.shards[i], \"|\", true);\n          replicaListTransformer.transform(shardUrls);\n          hostChecker.checkWhitelist(clusterState, shards, shardUrls);\n          // And now recreate the | delimited list of equivalent servers\n          rb.shards[i] = createSliceShardsStr(shardUrls);\n        } else {\n          if (slices == null) {\n            slices = clusterState.getCollection(cloudDescriptor.getCollectionName()).getSlicesMap();\n          }\n          String sliceName = rb.slices[i];\n\n          Slice slice = slices.get(sliceName);\n\n          if (slice==null) {\n            // Treat this the same as \"all servers down\" for a slice, and let things continue\n            // if partial results are acceptable\n            rb.shards[i] = \"\";\n            continue;\n            // throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"no such shard: \" + sliceName);\n          }\n          final Predicate<Replica> isShardLeader = new Predicate<Replica>() {\n            private Replica shardLeader = null;\n\n            @Override\n            public boolean test(Replica replica) {\n              if (shardLeader == null) {\n                try {\n                  shardLeader = zkController.getZkStateReader().getLeaderRetry(cloudDescriptor.getCollectionName(), slice.getName());\n                } catch (InterruptedException e) {\n                  throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + slice.getName() + \" in collection \" \n                      + cloudDescriptor.getCollectionName(), e);\n                } catch (SolrException e) {\n                  if (log.isDebugEnabled()) {\n                    log.debug(\"Exception finding leader for shard {} in collection {}. Collection State: {}\", \n                        slice.getName(), cloudDescriptor.getCollectionName(), zkController.getZkStateReader().getClusterState().getCollectionOrNull(cloudDescriptor.getCollectionName()));\n                  }\n                  throw e;\n                }\n              }\n              return replica.getName().equals(shardLeader.getName());\n            }\n          };\n\n          final List<Replica> eligibleSliceReplicas = collectEligibleReplicas(slice, clusterState, onlyNrtReplicas, isShardLeader);\n\n          final List<String> shardUrls = transformReplicasToShardUrls(replicaListTransformer, eligibleSliceReplicas);\n\n          if (hostChecker.isWhitelistHostCheckingEnabled() && hostChecker.hasExplicitWhitelist()) {\n            /*\n             * We only need to check the host whitelist if there is an explicit whitelist (other than all the live nodes)\n             * when the \"shards\" indicate cluster state elements only\n             */\n            hostChecker.checkWhitelist(clusterState, shards, shardUrls);\n          }\n\n          // And now recreate the | delimited list of equivalent servers\n          final String sliceShardsStr = createSliceShardsStr(shardUrls);\n          if (sliceShardsStr.isEmpty()) {\n            boolean tolerant = ShardParams.getShardsTolerantAsBool(rb.req.getParams());\n            if (!tolerant) {\n              // stop the check when there are no replicas available for a shard\n              throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n                  \"no servers hosting shard: \" + rb.slices[i]);\n            }\n          }\n          rb.shards[i] = sliceShardsStr;\n        }\n      }\n    } else {\n      if (shards != null) {\n        // No cloud, verbatim check of shards\n        hostChecker.checkWhitelist(shards, new ArrayList<>(Arrays.asList(shards.split(\"[,|]\"))));\n      }\n    }\n    String shards_rows = params.get(ShardParams.SHARDS_ROWS);\n    if(shards_rows != null) {\n      rb.shards_rows = Integer.parseInt(shards_rows);\n    }\n    String shards_start = params.get(ShardParams.SHARDS_START);\n    if(shards_start != null) {\n      rb.shards_start = Integer.parseInt(shards_start);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"59781d3bed3e710d1eb267b259b850c1f5043a8e","date":1583026251,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler#prepDistributed(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler#prepDistributed(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void prepDistributed(ResponseBuilder rb) {\n    final SolrQueryRequest req = rb.req;\n    final SolrParams params = req.getParams();\n    final String shards = params.get(ShardParams.SHARDS);\n\n    CoreDescriptor coreDescriptor = req.getCore().getCoreDescriptor();\n    CloudDescriptor cloudDescriptor = coreDescriptor.getCloudDescriptor();\n    ZkController zkController = req.getCore().getCoreContainer().getZkController();\n\n    final ReplicaListTransformer replicaListTransformer = httpShardHandlerFactory.getReplicaListTransformer(req);\n\n    HttpShardHandlerFactory.WhitelistHostChecker hostChecker = httpShardHandlerFactory.getWhitelistHostChecker();\n    if (shards != null && zkController == null && hostChecker.isWhitelistHostCheckingEnabled() && !hostChecker.hasExplicitWhitelist()) {\n      throw new SolrException(SolrException.ErrorCode.FORBIDDEN, \"HttpShardHandlerFactory \" + HttpShardHandlerFactory.INIT_SHARDS_WHITELIST\n          + \" not configured but required (in lieu of ZkController and ClusterState) when using the '\" + ShardParams.SHARDS + \"' parameter.\"\n          + HttpShardHandlerFactory.SET_SOLR_DISABLE_SHARDS_WHITELIST_CLUE);\n    }\n\n    ReplicaSource replicaSource;\n    if (zkController != null) {\n      boolean onlyNrt = Boolean.TRUE == req.getContext().get(ONLY_NRT_REPLICAS);\n\n      replicaSource = new CloudReplicaSource.Builder()\n          .params(params)\n          .zkStateReader(zkController.getZkStateReader())\n          .whitelistHostChecker(hostChecker)\n          .replicaListTransformer(replicaListTransformer)\n          .collection(cloudDescriptor.getCollectionName())\n          .onlyNrt(onlyNrt)\n          .build();\n      rb.slices = replicaSource.getSliceNames().toArray(new String[replicaSource.getSliceCount()]);\n\n      if (canShortCircuit(rb.slices, onlyNrt, params, cloudDescriptor)) {\n        rb.isDistrib = false;\n        rb.shortCircuitedURL = ZkCoreNodeProps.getCoreUrl(zkController.getBaseUrl(), coreDescriptor.getName());\n        return;\n        // We shouldn't need to do anything to handle \"shard.rows\" since it was previously meant to be an optimization?\n      }\n\n      for (int i = 0; i < rb.slices.length; i++) {\n        if (!ShardParams.getShardsTolerantAsBool(params) && replicaSource.getReplicasBySlice(i).isEmpty()) {\n          // stop the check when there are no replicas available for a shard\n          // todo fix use of slices[i] which can be null if user specified urls in shards param\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"no servers hosting shard: \" + rb.slices[i]);\n        }\n      }\n    } else {\n      replicaSource = new StandaloneReplicaSource.Builder()\n          .whitelistHostChecker(hostChecker)\n          .shards(shards)\n          .build();\n      rb.slices = new String[replicaSource.getSliceCount()];\n    }\n\n    rb.shards = new String[rb.slices.length];\n    for (int i = 0; i < rb.slices.length; i++) {\n      rb.shards[i] = createSliceShardsStr(replicaSource.getReplicasBySlice(i));\n    }\n\n    String shards_rows = params.get(ShardParams.SHARDS_ROWS);\n    if (shards_rows != null) {\n      rb.shards_rows = Integer.parseInt(shards_rows);\n    }\n    String shards_start = params.get(ShardParams.SHARDS_START);\n    if (shards_start != null) {\n      rb.shards_start = Integer.parseInt(shards_start);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void prepDistributed(ResponseBuilder rb) {\n    final SolrQueryRequest req = rb.req;\n    final SolrParams params = req.getParams();\n    final String shards = params.get(ShardParams.SHARDS);\n\n    CoreDescriptor coreDescriptor = req.getCore().getCoreDescriptor();\n    CloudDescriptor cloudDescriptor = coreDescriptor.getCloudDescriptor();\n    ZkController zkController = req.getCore().getCoreContainer().getZkController();\n\n    final ReplicaListTransformer replicaListTransformer = httpShardHandlerFactory.getReplicaListTransformer(req);\n\n    HttpShardHandlerFactory.WhitelistHostChecker hostChecker = httpShardHandlerFactory.getWhitelistHostChecker();\n    if (shards != null && zkController == null && hostChecker.isWhitelistHostCheckingEnabled() && !hostChecker.hasExplicitWhitelist()) {\n      throw new SolrException(SolrException.ErrorCode.FORBIDDEN, \"HttpShardHandlerFactory \" + HttpShardHandlerFactory.INIT_SHARDS_WHITELIST\n          + \" not configured but required (in lieu of ZkController and ClusterState) when using the '\" + ShardParams.SHARDS + \"' parameter.\"\n          + HttpShardHandlerFactory.SET_SOLR_DISABLE_SHARDS_WHITELIST_CLUE);\n    }\n\n    ReplicaSource replicaSource;\n    if (zkController != null) {\n      boolean onlyNrt = Boolean.TRUE == req.getContext().get(ONLY_NRT_REPLICAS);\n\n      replicaSource = new CloudReplicaSource.Builder()\n          .params(params)\n          .zkStateReader(zkController.getZkStateReader())\n          .whitelistHostChecker(hostChecker)\n          .replicaListTransformer(replicaListTransformer)\n          .collection(cloudDescriptor.getCollectionName())\n          .onlyNrt(onlyNrt)\n          .build();\n      rb.slices = replicaSource.getSliceNames().toArray(new String[replicaSource.getSliceCount()]);\n\n      if (canShortCircuit(rb.slices, onlyNrt, params, cloudDescriptor)) {\n        rb.isDistrib = false;\n        rb.shortCircuitedURL = ZkCoreNodeProps.getCoreUrl(zkController.getBaseUrl(), coreDescriptor.getName());\n        return;\n        // We shouldn't need to do anything to handle \"shard.rows\" since it was previously meant to be an optimization?\n      }\n\n      for (int i = 0; i < rb.slices.length; i++) {\n        if (!ShardParams.getShardsTolerantAsBool(params) && replicaSource.getReplicasBySlice(i).isEmpty()) {\n          // stop the check when there are no replicas available for a shard\n          // todo fix use of slices[i] which can be null if user specified urls in shards param\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"no servers hosting shard: \" + rb.slices[i]);\n        }\n      }\n    } else {\n      replicaSource = new LegacyReplicaSource.Builder()\n          .whitelistHostChecker(hostChecker)\n          .shards(shards)\n          .build();\n      rb.slices = new String[replicaSource.getSliceCount()];\n    }\n\n    rb.shards = new String[rb.slices.length];\n    for (int i = 0; i < rb.slices.length; i++) {\n      rb.shards[i] = createSliceShardsStr(replicaSource.getReplicasBySlice(i));\n    }\n\n    String shards_rows = params.get(ShardParams.SHARDS_ROWS);\n    if (shards_rows != null) {\n      rb.shards_rows = Integer.parseInt(shards_rows);\n    }\n    String shards_start = params.get(ShardParams.SHARDS_START);\n    if (shards_start != null) {\n      rb.shards_start = Integer.parseInt(shards_start);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"54ca69905c5d9d1529286f06ab1d12c68f6c13cb":["304ef848381e39ff6cf3e7af6127733a6f4db389"],"344b0840364d990b29b97467bfcc766ff8325d11":["28288370235ed02234a64753cdbf0c6ec096304a"],"d19b466e346f2319504d6a159d78f56e1b70b6fa":["61c45e99cf6676da48f19d7511c73712ad39402b"],"199dfa410f1fdbfd3294106b04096cce5ed34b21":["23e55c29de60130e8a1226800b66c5f6d7e16e8a","f82cd77bc27bbdd30a6dd22e5adb2cf8def2c34a"],"e9017cf144952056066919f1ebc7897ff9bd71b1":["54ca69905c5d9d1529286f06ab1d12c68f6c13cb","e73ed7d4570aa6de9e2054e7d2c5701733790f81"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cc28b46d62a8b91c8e90f9345612c4050eab98d4":["4d51e7db479b42602c7e23ba871b177387268179"],"59781d3bed3e710d1eb267b259b850c1f5043a8e":["cc28b46d62a8b91c8e90f9345612c4050eab98d4"],"d1f5728f32a4a256b36cfabd7a2636452f599bb9":["61c45e99cf6676da48f19d7511c73712ad39402b","d19b466e346f2319504d6a159d78f56e1b70b6fa"],"61c45e99cf6676da48f19d7511c73712ad39402b":["729cb470f975115d4c60517b2cb7c42e37a7a2e1"],"ba8018c05af07413630c7437681d62d5f001a9db":["e73ed7d4570aa6de9e2054e7d2c5701733790f81"],"f344bb33ca91f48e99c061980115b46fa84fc8f5":["e73ed7d4570aa6de9e2054e7d2c5701733790f81","ba8018c05af07413630c7437681d62d5f001a9db"],"f82cd77bc27bbdd30a6dd22e5adb2cf8def2c34a":["23e55c29de60130e8a1226800b66c5f6d7e16e8a"],"304ef848381e39ff6cf3e7af6127733a6f4db389":["f82cd77bc27bbdd30a6dd22e5adb2cf8def2c34a"],"729cb470f975115d4c60517b2cb7c42e37a7a2e1":["304ef848381e39ff6cf3e7af6127733a6f4db389"],"28288370235ed02234a64753cdbf0c6ec096304a":["d1f5728f32a4a256b36cfabd7a2636452f599bb9","f344bb33ca91f48e99c061980115b46fa84fc8f5"],"f03e4bed5023ec3ef93a771b8888cae991cf448d":["199dfa410f1fdbfd3294106b04096cce5ed34b21","304ef848381e39ff6cf3e7af6127733a6f4db389"],"4d51e7db479b42602c7e23ba871b177387268179":["bd22dcd3ba035a1626face7319c94be45ae07172"],"7a23cf16c8fa265dc0a564adcabb55e3f054e0ac":["2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9","344b0840364d990b29b97467bfcc766ff8325d11"],"e73ed7d4570aa6de9e2054e7d2c5701733790f81":["d19b466e346f2319504d6a159d78f56e1b70b6fa"],"bd22dcd3ba035a1626face7319c94be45ae07172":["344b0840364d990b29b97467bfcc766ff8325d11"],"5676bf22fd531b9a2a3053047d0e0f922c1c53ff":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"23e55c29de60130e8a1226800b66c5f6d7e16e8a":["5676bf22fd531b9a2a3053047d0e0f922c1c53ff"],"2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9":["e9017cf144952056066919f1ebc7897ff9bd71b1","f344bb33ca91f48e99c061980115b46fa84fc8f5"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["59781d3bed3e710d1eb267b259b850c1f5043a8e"]},"commit2Childs":{"54ca69905c5d9d1529286f06ab1d12c68f6c13cb":["e9017cf144952056066919f1ebc7897ff9bd71b1"],"344b0840364d990b29b97467bfcc766ff8325d11":["7a23cf16c8fa265dc0a564adcabb55e3f054e0ac","bd22dcd3ba035a1626face7319c94be45ae07172"],"d19b466e346f2319504d6a159d78f56e1b70b6fa":["d1f5728f32a4a256b36cfabd7a2636452f599bb9","e73ed7d4570aa6de9e2054e7d2c5701733790f81"],"199dfa410f1fdbfd3294106b04096cce5ed34b21":["f03e4bed5023ec3ef93a771b8888cae991cf448d"],"e9017cf144952056066919f1ebc7897ff9bd71b1":["2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["5676bf22fd531b9a2a3053047d0e0f922c1c53ff"],"cc28b46d62a8b91c8e90f9345612c4050eab98d4":["59781d3bed3e710d1eb267b259b850c1f5043a8e"],"59781d3bed3e710d1eb267b259b850c1f5043a8e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"d1f5728f32a4a256b36cfabd7a2636452f599bb9":["28288370235ed02234a64753cdbf0c6ec096304a"],"61c45e99cf6676da48f19d7511c73712ad39402b":["d19b466e346f2319504d6a159d78f56e1b70b6fa","d1f5728f32a4a256b36cfabd7a2636452f599bb9"],"ba8018c05af07413630c7437681d62d5f001a9db":["f344bb33ca91f48e99c061980115b46fa84fc8f5"],"f344bb33ca91f48e99c061980115b46fa84fc8f5":["28288370235ed02234a64753cdbf0c6ec096304a","2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9"],"f82cd77bc27bbdd30a6dd22e5adb2cf8def2c34a":["199dfa410f1fdbfd3294106b04096cce5ed34b21","304ef848381e39ff6cf3e7af6127733a6f4db389"],"304ef848381e39ff6cf3e7af6127733a6f4db389":["54ca69905c5d9d1529286f06ab1d12c68f6c13cb","729cb470f975115d4c60517b2cb7c42e37a7a2e1","f03e4bed5023ec3ef93a771b8888cae991cf448d"],"28288370235ed02234a64753cdbf0c6ec096304a":["344b0840364d990b29b97467bfcc766ff8325d11"],"729cb470f975115d4c60517b2cb7c42e37a7a2e1":["61c45e99cf6676da48f19d7511c73712ad39402b"],"f03e4bed5023ec3ef93a771b8888cae991cf448d":[],"4d51e7db479b42602c7e23ba871b177387268179":["cc28b46d62a8b91c8e90f9345612c4050eab98d4"],"7a23cf16c8fa265dc0a564adcabb55e3f054e0ac":[],"e73ed7d4570aa6de9e2054e7d2c5701733790f81":["e9017cf144952056066919f1ebc7897ff9bd71b1","ba8018c05af07413630c7437681d62d5f001a9db","f344bb33ca91f48e99c061980115b46fa84fc8f5"],"bd22dcd3ba035a1626face7319c94be45ae07172":["4d51e7db479b42602c7e23ba871b177387268179"],"5676bf22fd531b9a2a3053047d0e0f922c1c53ff":["23e55c29de60130e8a1226800b66c5f6d7e16e8a"],"23e55c29de60130e8a1226800b66c5f6d7e16e8a":["199dfa410f1fdbfd3294106b04096cce5ed34b21","f82cd77bc27bbdd30a6dd22e5adb2cf8def2c34a"],"2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9":["7a23cf16c8fa265dc0a564adcabb55e3f054e0ac"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["f03e4bed5023ec3ef93a771b8888cae991cf448d","7a23cf16c8fa265dc0a564adcabb55e3f054e0ac","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}