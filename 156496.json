{"path":"lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader#testRandomMultipleSchemaGensSameField().mjava","commits":[{"id":"4d9aa91d3fdd25528bac3b2e6115d54fc2f28753","date":1416999434,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader#testRandomMultipleSchemaGensSameField().mjava","pathOld":"/dev/null","sourceNew":"  /** First schema change creates a new \"number\" DV field off the stored field; subsequent changes just change the value of that number\n   *  field for all docs. */\n  public void testRandomMultipleSchemaGensSameField() throws Exception {\n\n    AtomicLong currentSchemaGen = new AtomicLong();\n    AtomicLong mergingSchemaGen = new AtomicLong();\n\n    ReindexingReader reindexer = null;\n\n    // TODO: separate refresh thread, search threads, indexing threads\n    int numDocs = atLeast(TEST_NIGHTLY ? 20000 : 2000);\n    int maxID = 0;\n    Path root = createTempDir();\n    int refreshEveryNumDocs = 100;\n    int commitCloseNumDocs = 1000;\n\n    for(int i=0;i<numDocs;i++) {\n      if (reindexer == null) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: open new reader/writer\");\n        reindexer = getReindexerSameDVField(root, currentSchemaGen, mergingSchemaGen);\n      }\n\n      Document doc = new Document();\n      String id;\n      String updateID;\n      if (maxID > 0 && random().nextInt(10) == 7) {\n        // Replace a doc\n        id = \"\" + random().nextInt(maxID);\n        updateID = id;\n      } else {\n        id = \"\" + (maxID++);\n        updateID = null;\n      }\n        \n      doc.add(newStringField(\"id\", id, Field.Store.NO));\n      doc.add(newTextField(\"text\", \"number \" + TestUtil.nextInt(random(), -10000, 10000), Field.Store.YES));\n      if (updateID == null) {\n        reindexer.w.addDocument(doc);\n      } else {\n        reindexer.w.updateDocument(new Term(\"id\", updateID), doc);\n      }\n      if (random().nextInt(refreshEveryNumDocs) == 17) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: refresh @ \" + (i+1) + \" docs\");\n        reindexer.mgr.maybeRefresh();\n        DirectoryReader r = reindexer.mgr.acquire();\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: got reader=\" + r);\n        try {\n          checkAllNumberDVs(r, \"number\", true, (int) currentSchemaGen.get());\n        } finally {\n          reindexer.mgr.release(r);\n        }\n        if (DEBUG) reindexer.printRefCounts();\n        refreshEveryNumDocs = (int) (1.25 * refreshEveryNumDocs);\n      }\n\n      if (random().nextInt(500) == 17) {\n        currentSchemaGen.incrementAndGet();\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: advance schemaGen to \" + currentSchemaGen);\n        if (random().nextBoolean()) {\n          mergingSchemaGen.incrementAndGet();\n          if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: advance mergingSchemaGen to \" + mergingSchemaGen);\n        }\n      }\n\n      if (i > 0 && random().nextInt(10) == 7) {\n        // Random delete:\n        reindexer.w.deleteDocuments(new Term(\"id\", \"\"+random().nextInt(i)));\n      }\n\n      if (random().nextInt(commitCloseNumDocs) == 17) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: commit @ \" + (i+1) + \" docs\");\n        reindexer.commit();\n        //reindexer.printRefCounts();\n        commitCloseNumDocs = (int) (1.25 * commitCloseNumDocs);\n      }\n\n      // Sometimes close & reopen writer/manager, to confirm the parallel segments persist:\n      if (random().nextInt(commitCloseNumDocs) == 17) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: close writer @ \" + (i+1) + \" docs\");\n        reindexer.close();\n        reindexer = null;\n        commitCloseNumDocs = (int) (1.25 * commitCloseNumDocs);\n      }\n    }\n\n    if (reindexer != null) {\n      reindexer.close();\n    }\n\n    // Verify main index never reflects schema changes beyond mergingSchemaGen:\n    try (Directory dir = newFSDirectory(root.resolve(\"index\"));\n         IndexReader r = DirectoryReader.open(dir)) {\n        for (LeafReaderContext ctx : r.leaves()) {\n          LeafReader leaf = ctx.reader();\n          NumericDocValues numbers = leaf.getNumericDocValues(\"number\");\n          if (numbers != null) {\n            int maxDoc = leaf.maxDoc();\n            for(int i=0;i<maxDoc;i++) {\n              StoredDocument doc = leaf.document(i);\n              long value = Long.parseLong(doc.get(\"text\").split(\" \")[1]);\n              long dvValue = numbers.get(i);\n              if (value == 0) {\n                assertEquals(0, dvValue);\n              } else {\n                assertTrue(dvValue % value == 0);\n                assertTrue(dvValue / value <= mergingSchemaGen.get());\n              }\n            }\n          }\n        }\n      }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"91efc148b027dbb57e9dbdf18b654785c1d716f2","date":1417123160,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader#testRandomMultipleSchemaGensSameField().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader#testRandomMultipleSchemaGensSameField().mjava","sourceNew":"  /** First schema change creates a new \"number\" DV field off the stored field; subsequent changes just change the value of that number\n   *  field for all docs. */\n  public void testRandomMultipleSchemaGensSameField() throws Exception {\n\n    AtomicLong currentSchemaGen = new AtomicLong();\n    AtomicLong mergingSchemaGen = new AtomicLong();\n\n    ReindexingReader reindexer = null;\n\n    // TODO: separate refresh thread, search threads, indexing threads\n    int numDocs = atLeast(TEST_NIGHTLY ? 20000 : 1000);\n    int maxID = 0;\n    Path root = createTempDir();\n    int refreshEveryNumDocs = 100;\n    int commitCloseNumDocs = 1000;\n\n    for(int i=0;i<numDocs;i++) {\n      if (reindexer == null) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: open new reader/writer\");\n        reindexer = getReindexerSameDVField(root, currentSchemaGen, mergingSchemaGen);\n      }\n\n      Document doc = new Document();\n      String id;\n      String updateID;\n      if (maxID > 0 && random().nextInt(10) == 7) {\n        // Replace a doc\n        id = \"\" + random().nextInt(maxID);\n        updateID = id;\n      } else {\n        id = \"\" + (maxID++);\n        updateID = null;\n      }\n        \n      doc.add(newStringField(\"id\", id, Field.Store.NO));\n      doc.add(newTextField(\"text\", \"number \" + TestUtil.nextInt(random(), -10000, 10000), Field.Store.YES));\n      if (updateID == null) {\n        reindexer.w.addDocument(doc);\n      } else {\n        reindexer.w.updateDocument(new Term(\"id\", updateID), doc);\n      }\n      if (random().nextInt(refreshEveryNumDocs) == 17) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: refresh @ \" + (i+1) + \" docs\");\n        reindexer.mgr.maybeRefresh();\n        DirectoryReader r = reindexer.mgr.acquire();\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: got reader=\" + r);\n        try {\n          checkAllNumberDVs(r, \"number\", true, (int) currentSchemaGen.get());\n        } finally {\n          reindexer.mgr.release(r);\n        }\n        if (DEBUG) reindexer.printRefCounts();\n        refreshEveryNumDocs = (int) (1.25 * refreshEveryNumDocs);\n      }\n\n      if (random().nextInt(500) == 17) {\n        currentSchemaGen.incrementAndGet();\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: advance schemaGen to \" + currentSchemaGen);\n        if (random().nextBoolean()) {\n          mergingSchemaGen.incrementAndGet();\n          if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: advance mergingSchemaGen to \" + mergingSchemaGen);\n        }\n      }\n\n      if (i > 0 && random().nextInt(10) == 7) {\n        // Random delete:\n        reindexer.w.deleteDocuments(new Term(\"id\", \"\"+random().nextInt(i)));\n      }\n\n      if (random().nextInt(commitCloseNumDocs) == 17) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: commit @ \" + (i+1) + \" docs\");\n        reindexer.commit();\n        //reindexer.printRefCounts();\n        commitCloseNumDocs = (int) (1.25 * commitCloseNumDocs);\n      }\n\n      // Sometimes close & reopen writer/manager, to confirm the parallel segments persist:\n      if (random().nextInt(commitCloseNumDocs) == 17) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: close writer @ \" + (i+1) + \" docs\");\n        reindexer.close();\n        reindexer = null;\n        commitCloseNumDocs = (int) (1.25 * commitCloseNumDocs);\n      }\n    }\n\n    if (reindexer != null) {\n      reindexer.close();\n    }\n\n    // Verify main index never reflects schema changes beyond mergingSchemaGen:\n    try (Directory dir = newFSDirectory(root.resolve(\"index\"));\n         IndexReader r = DirectoryReader.open(dir)) {\n        for (LeafReaderContext ctx : r.leaves()) {\n          LeafReader leaf = ctx.reader();\n          NumericDocValues numbers = leaf.getNumericDocValues(\"number\");\n          if (numbers != null) {\n            int maxDoc = leaf.maxDoc();\n            for(int i=0;i<maxDoc;i++) {\n              StoredDocument doc = leaf.document(i);\n              long value = Long.parseLong(doc.get(\"text\").split(\" \")[1]);\n              long dvValue = numbers.get(i);\n              if (value == 0) {\n                assertEquals(0, dvValue);\n              } else {\n                assertTrue(dvValue % value == 0);\n                assertTrue(dvValue / value <= mergingSchemaGen.get());\n              }\n            }\n          }\n        }\n      }\n  }\n\n","sourceOld":"  /** First schema change creates a new \"number\" DV field off the stored field; subsequent changes just change the value of that number\n   *  field for all docs. */\n  public void testRandomMultipleSchemaGensSameField() throws Exception {\n\n    AtomicLong currentSchemaGen = new AtomicLong();\n    AtomicLong mergingSchemaGen = new AtomicLong();\n\n    ReindexingReader reindexer = null;\n\n    // TODO: separate refresh thread, search threads, indexing threads\n    int numDocs = atLeast(TEST_NIGHTLY ? 20000 : 2000);\n    int maxID = 0;\n    Path root = createTempDir();\n    int refreshEveryNumDocs = 100;\n    int commitCloseNumDocs = 1000;\n\n    for(int i=0;i<numDocs;i++) {\n      if (reindexer == null) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: open new reader/writer\");\n        reindexer = getReindexerSameDVField(root, currentSchemaGen, mergingSchemaGen);\n      }\n\n      Document doc = new Document();\n      String id;\n      String updateID;\n      if (maxID > 0 && random().nextInt(10) == 7) {\n        // Replace a doc\n        id = \"\" + random().nextInt(maxID);\n        updateID = id;\n      } else {\n        id = \"\" + (maxID++);\n        updateID = null;\n      }\n        \n      doc.add(newStringField(\"id\", id, Field.Store.NO));\n      doc.add(newTextField(\"text\", \"number \" + TestUtil.nextInt(random(), -10000, 10000), Field.Store.YES));\n      if (updateID == null) {\n        reindexer.w.addDocument(doc);\n      } else {\n        reindexer.w.updateDocument(new Term(\"id\", updateID), doc);\n      }\n      if (random().nextInt(refreshEveryNumDocs) == 17) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: refresh @ \" + (i+1) + \" docs\");\n        reindexer.mgr.maybeRefresh();\n        DirectoryReader r = reindexer.mgr.acquire();\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: got reader=\" + r);\n        try {\n          checkAllNumberDVs(r, \"number\", true, (int) currentSchemaGen.get());\n        } finally {\n          reindexer.mgr.release(r);\n        }\n        if (DEBUG) reindexer.printRefCounts();\n        refreshEveryNumDocs = (int) (1.25 * refreshEveryNumDocs);\n      }\n\n      if (random().nextInt(500) == 17) {\n        currentSchemaGen.incrementAndGet();\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: advance schemaGen to \" + currentSchemaGen);\n        if (random().nextBoolean()) {\n          mergingSchemaGen.incrementAndGet();\n          if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: advance mergingSchemaGen to \" + mergingSchemaGen);\n        }\n      }\n\n      if (i > 0 && random().nextInt(10) == 7) {\n        // Random delete:\n        reindexer.w.deleteDocuments(new Term(\"id\", \"\"+random().nextInt(i)));\n      }\n\n      if (random().nextInt(commitCloseNumDocs) == 17) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: commit @ \" + (i+1) + \" docs\");\n        reindexer.commit();\n        //reindexer.printRefCounts();\n        commitCloseNumDocs = (int) (1.25 * commitCloseNumDocs);\n      }\n\n      // Sometimes close & reopen writer/manager, to confirm the parallel segments persist:\n      if (random().nextInt(commitCloseNumDocs) == 17) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: close writer @ \" + (i+1) + \" docs\");\n        reindexer.close();\n        reindexer = null;\n        commitCloseNumDocs = (int) (1.25 * commitCloseNumDocs);\n      }\n    }\n\n    if (reindexer != null) {\n      reindexer.close();\n    }\n\n    // Verify main index never reflects schema changes beyond mergingSchemaGen:\n    try (Directory dir = newFSDirectory(root.resolve(\"index\"));\n         IndexReader r = DirectoryReader.open(dir)) {\n        for (LeafReaderContext ctx : r.leaves()) {\n          LeafReader leaf = ctx.reader();\n          NumericDocValues numbers = leaf.getNumericDocValues(\"number\");\n          if (numbers != null) {\n            int maxDoc = leaf.maxDoc();\n            for(int i=0;i<maxDoc;i++) {\n              StoredDocument doc = leaf.document(i);\n              long value = Long.parseLong(doc.get(\"text\").split(\" \")[1]);\n              long dvValue = numbers.get(i);\n              if (value == 0) {\n                assertEquals(0, dvValue);\n              } else {\n                assertTrue(dvValue % value == 0);\n                assertTrue(dvValue / value <= mergingSchemaGen.get());\n              }\n            }\n          }\n        }\n      }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c","date":1453060490,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader#testRandomMultipleSchemaGensSameField().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader#testRandomMultipleSchemaGensSameField().mjava","sourceNew":"  /** First schema change creates a new \"number\" DV field off the stored field; subsequent changes just change the value of that number\n   *  field for all docs. */\n  public void testRandomMultipleSchemaGensSameField() throws Exception {\n\n    AtomicLong currentSchemaGen = new AtomicLong();\n    AtomicLong mergingSchemaGen = new AtomicLong();\n\n    ReindexingReader reindexer = null;\n\n    // TODO: separate refresh thread, search threads, indexing threads\n    int numDocs = atLeast(TEST_NIGHTLY ? 20000 : 1000);\n    int maxID = 0;\n    Path root = createTempDir();\n    int refreshEveryNumDocs = 100;\n    int commitCloseNumDocs = 1000;\n\n    for(int i=0;i<numDocs;i++) {\n      if (reindexer == null) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: open new reader/writer\");\n        reindexer = getReindexerSameDVField(root, currentSchemaGen, mergingSchemaGen);\n      }\n\n      Document doc = new Document();\n      String id;\n      String updateID;\n      if (maxID > 0 && random().nextInt(10) == 7) {\n        // Replace a doc\n        id = \"\" + random().nextInt(maxID);\n        updateID = id;\n      } else {\n        id = \"\" + (maxID++);\n        updateID = null;\n      }\n        \n      doc.add(newStringField(\"id\", id, Field.Store.NO));\n      doc.add(newTextField(\"text\", \"number \" + TestUtil.nextInt(random(), -10000, 10000), Field.Store.YES));\n      if (updateID == null) {\n        reindexer.w.addDocument(doc);\n      } else {\n        reindexer.w.updateDocument(new Term(\"id\", updateID), doc);\n      }\n      if (random().nextInt(refreshEveryNumDocs) == 17) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: refresh @ \" + (i+1) + \" docs\");\n        reindexer.mgr.maybeRefresh();\n        DirectoryReader r = reindexer.mgr.acquire();\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: got reader=\" + r);\n        try {\n          checkAllNumberDVs(r, \"number\", true, (int) currentSchemaGen.get());\n        } finally {\n          reindexer.mgr.release(r);\n        }\n        if (DEBUG) reindexer.printRefCounts();\n        refreshEveryNumDocs = (int) (1.25 * refreshEveryNumDocs);\n      }\n\n      if (random().nextInt(500) == 17) {\n        currentSchemaGen.incrementAndGet();\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: advance schemaGen to \" + currentSchemaGen);\n        if (random().nextBoolean()) {\n          mergingSchemaGen.incrementAndGet();\n          if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: advance mergingSchemaGen to \" + mergingSchemaGen);\n        }\n      }\n\n      if (i > 0 && random().nextInt(10) == 7) {\n        // Random delete:\n        reindexer.w.deleteDocuments(new Term(\"id\", \"\"+random().nextInt(i)));\n      }\n\n      if (random().nextInt(commitCloseNumDocs) == 17) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: commit @ \" + (i+1) + \" docs\");\n        reindexer.commit();\n        //reindexer.printRefCounts();\n        commitCloseNumDocs = (int) (1.25 * commitCloseNumDocs);\n      }\n\n      // Sometimes close & reopen writer/manager, to confirm the parallel segments persist:\n      if (random().nextInt(commitCloseNumDocs) == 17) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: close writer @ \" + (i+1) + \" docs\");\n        reindexer.close();\n        reindexer = null;\n        commitCloseNumDocs = (int) (1.25 * commitCloseNumDocs);\n      }\n    }\n\n    if (reindexer != null) {\n      reindexer.close();\n    }\n\n    // Verify main index never reflects schema changes beyond mergingSchemaGen:\n    try (Directory dir = newFSDirectory(root.resolve(\"index\"));\n         IndexReader r = DirectoryReader.open(dir)) {\n        for (LeafReaderContext ctx : r.leaves()) {\n          LeafReader leaf = ctx.reader();\n          NumericDocValues numbers = leaf.getNumericDocValues(\"number\");\n          if (numbers != null) {\n            int maxDoc = leaf.maxDoc();\n            for(int i=0;i<maxDoc;i++) {\n              Document doc = leaf.document(i);\n              long value = Long.parseLong(doc.get(\"text\").split(\" \")[1]);\n              long dvValue = numbers.get(i);\n              if (value == 0) {\n                assertEquals(0, dvValue);\n              } else {\n                assertTrue(dvValue % value == 0);\n                assertTrue(dvValue / value <= mergingSchemaGen.get());\n              }\n            }\n          }\n        }\n      }\n  }\n\n","sourceOld":"  /** First schema change creates a new \"number\" DV field off the stored field; subsequent changes just change the value of that number\n   *  field for all docs. */\n  public void testRandomMultipleSchemaGensSameField() throws Exception {\n\n    AtomicLong currentSchemaGen = new AtomicLong();\n    AtomicLong mergingSchemaGen = new AtomicLong();\n\n    ReindexingReader reindexer = null;\n\n    // TODO: separate refresh thread, search threads, indexing threads\n    int numDocs = atLeast(TEST_NIGHTLY ? 20000 : 1000);\n    int maxID = 0;\n    Path root = createTempDir();\n    int refreshEveryNumDocs = 100;\n    int commitCloseNumDocs = 1000;\n\n    for(int i=0;i<numDocs;i++) {\n      if (reindexer == null) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: open new reader/writer\");\n        reindexer = getReindexerSameDVField(root, currentSchemaGen, mergingSchemaGen);\n      }\n\n      Document doc = new Document();\n      String id;\n      String updateID;\n      if (maxID > 0 && random().nextInt(10) == 7) {\n        // Replace a doc\n        id = \"\" + random().nextInt(maxID);\n        updateID = id;\n      } else {\n        id = \"\" + (maxID++);\n        updateID = null;\n      }\n        \n      doc.add(newStringField(\"id\", id, Field.Store.NO));\n      doc.add(newTextField(\"text\", \"number \" + TestUtil.nextInt(random(), -10000, 10000), Field.Store.YES));\n      if (updateID == null) {\n        reindexer.w.addDocument(doc);\n      } else {\n        reindexer.w.updateDocument(new Term(\"id\", updateID), doc);\n      }\n      if (random().nextInt(refreshEveryNumDocs) == 17) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: refresh @ \" + (i+1) + \" docs\");\n        reindexer.mgr.maybeRefresh();\n        DirectoryReader r = reindexer.mgr.acquire();\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: got reader=\" + r);\n        try {\n          checkAllNumberDVs(r, \"number\", true, (int) currentSchemaGen.get());\n        } finally {\n          reindexer.mgr.release(r);\n        }\n        if (DEBUG) reindexer.printRefCounts();\n        refreshEveryNumDocs = (int) (1.25 * refreshEveryNumDocs);\n      }\n\n      if (random().nextInt(500) == 17) {\n        currentSchemaGen.incrementAndGet();\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: advance schemaGen to \" + currentSchemaGen);\n        if (random().nextBoolean()) {\n          mergingSchemaGen.incrementAndGet();\n          if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: advance mergingSchemaGen to \" + mergingSchemaGen);\n        }\n      }\n\n      if (i > 0 && random().nextInt(10) == 7) {\n        // Random delete:\n        reindexer.w.deleteDocuments(new Term(\"id\", \"\"+random().nextInt(i)));\n      }\n\n      if (random().nextInt(commitCloseNumDocs) == 17) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: commit @ \" + (i+1) + \" docs\");\n        reindexer.commit();\n        //reindexer.printRefCounts();\n        commitCloseNumDocs = (int) (1.25 * commitCloseNumDocs);\n      }\n\n      // Sometimes close & reopen writer/manager, to confirm the parallel segments persist:\n      if (random().nextInt(commitCloseNumDocs) == 17) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: close writer @ \" + (i+1) + \" docs\");\n        reindexer.close();\n        reindexer = null;\n        commitCloseNumDocs = (int) (1.25 * commitCloseNumDocs);\n      }\n    }\n\n    if (reindexer != null) {\n      reindexer.close();\n    }\n\n    // Verify main index never reflects schema changes beyond mergingSchemaGen:\n    try (Directory dir = newFSDirectory(root.resolve(\"index\"));\n         IndexReader r = DirectoryReader.open(dir)) {\n        for (LeafReaderContext ctx : r.leaves()) {\n          LeafReader leaf = ctx.reader();\n          NumericDocValues numbers = leaf.getNumericDocValues(\"number\");\n          if (numbers != null) {\n            int maxDoc = leaf.maxDoc();\n            for(int i=0;i<maxDoc;i++) {\n              StoredDocument doc = leaf.document(i);\n              long value = Long.parseLong(doc.get(\"text\").split(\" \")[1]);\n              long dvValue = numbers.get(i);\n              if (value == 0) {\n                assertEquals(0, dvValue);\n              } else {\n                assertTrue(dvValue % value == 0);\n                assertTrue(dvValue / value <= mergingSchemaGen.get());\n              }\n            }\n          }\n        }\n      }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6bfe104fc023fadc9e709f8d17403d2cc61133fe","date":1454446396,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader#testRandomMultipleSchemaGensSameField().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader#testRandomMultipleSchemaGensSameField().mjava","sourceNew":"  /** First schema change creates a new \"number\" DV field off the stored field; subsequent changes just change the value of that number\n   *  field for all docs. */\n  public void testRandomMultipleSchemaGensSameField() throws Exception {\n\n    AtomicLong currentSchemaGen = new AtomicLong();\n    AtomicLong mergingSchemaGen = new AtomicLong();\n\n    ReindexingReader reindexer = null;\n\n    // TODO: separate refresh thread, search threads, indexing threads\n    int numDocs = atLeast(TEST_NIGHTLY ? 20000 : 1000);\n    int maxID = 0;\n    Path root = createTempDir();\n    assumeFalse(\"we directly delete files\", TestUtil.hasVirusChecker(root));\n    int refreshEveryNumDocs = 100;\n    int commitCloseNumDocs = 1000;\n\n    for(int i=0;i<numDocs;i++) {\n      if (reindexer == null) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: open new reader/writer\");\n        reindexer = getReindexerSameDVField(root, currentSchemaGen, mergingSchemaGen);\n      }\n\n      Document doc = new Document();\n      String id;\n      String updateID;\n      if (maxID > 0 && random().nextInt(10) == 7) {\n        // Replace a doc\n        id = \"\" + random().nextInt(maxID);\n        updateID = id;\n      } else {\n        id = \"\" + (maxID++);\n        updateID = null;\n      }\n        \n      doc.add(newStringField(\"id\", id, Field.Store.NO));\n      doc.add(newTextField(\"text\", \"number \" + TestUtil.nextInt(random(), -10000, 10000), Field.Store.YES));\n      if (updateID == null) {\n        reindexer.w.addDocument(doc);\n      } else {\n        reindexer.w.updateDocument(new Term(\"id\", updateID), doc);\n      }\n      if (random().nextInt(refreshEveryNumDocs) == 17) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: refresh @ \" + (i+1) + \" docs\");\n        reindexer.mgr.maybeRefresh();\n        DirectoryReader r = reindexer.mgr.acquire();\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: got reader=\" + r);\n        try {\n          checkAllNumberDVs(r, \"number\", true, (int) currentSchemaGen.get());\n        } finally {\n          reindexer.mgr.release(r);\n        }\n        if (DEBUG) reindexer.printRefCounts();\n        refreshEveryNumDocs = (int) (1.25 * refreshEveryNumDocs);\n      }\n\n      if (random().nextInt(500) == 17) {\n        currentSchemaGen.incrementAndGet();\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: advance schemaGen to \" + currentSchemaGen);\n        if (random().nextBoolean()) {\n          mergingSchemaGen.incrementAndGet();\n          if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: advance mergingSchemaGen to \" + mergingSchemaGen);\n        }\n      }\n\n      if (i > 0 && random().nextInt(10) == 7) {\n        // Random delete:\n        reindexer.w.deleteDocuments(new Term(\"id\", \"\"+random().nextInt(i)));\n      }\n\n      if (random().nextInt(commitCloseNumDocs) == 17) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: commit @ \" + (i+1) + \" docs\");\n        reindexer.commit();\n        //reindexer.printRefCounts();\n        commitCloseNumDocs = (int) (1.25 * commitCloseNumDocs);\n      }\n\n      // Sometimes close & reopen writer/manager, to confirm the parallel segments persist:\n      if (random().nextInt(commitCloseNumDocs) == 17) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: close writer @ \" + (i+1) + \" docs\");\n        reindexer.close();\n        reindexer = null;\n        commitCloseNumDocs = (int) (1.25 * commitCloseNumDocs);\n      }\n    }\n\n    if (reindexer != null) {\n      reindexer.close();\n    }\n\n    // Verify main index never reflects schema changes beyond mergingSchemaGen:\n    try (Directory dir = newFSDirectory(root.resolve(\"index\"));\n         IndexReader r = DirectoryReader.open(dir)) {\n        for (LeafReaderContext ctx : r.leaves()) {\n          LeafReader leaf = ctx.reader();\n          NumericDocValues numbers = leaf.getNumericDocValues(\"number\");\n          if (numbers != null) {\n            int maxDoc = leaf.maxDoc();\n            for(int i=0;i<maxDoc;i++) {\n              Document doc = leaf.document(i);\n              long value = Long.parseLong(doc.get(\"text\").split(\" \")[1]);\n              long dvValue = numbers.get(i);\n              if (value == 0) {\n                assertEquals(0, dvValue);\n              } else {\n                assertTrue(dvValue % value == 0);\n                assertTrue(dvValue / value <= mergingSchemaGen.get());\n              }\n            }\n          }\n        }\n      }\n  }\n\n","sourceOld":"  /** First schema change creates a new \"number\" DV field off the stored field; subsequent changes just change the value of that number\n   *  field for all docs. */\n  public void testRandomMultipleSchemaGensSameField() throws Exception {\n\n    AtomicLong currentSchemaGen = new AtomicLong();\n    AtomicLong mergingSchemaGen = new AtomicLong();\n\n    ReindexingReader reindexer = null;\n\n    // TODO: separate refresh thread, search threads, indexing threads\n    int numDocs = atLeast(TEST_NIGHTLY ? 20000 : 1000);\n    int maxID = 0;\n    Path root = createTempDir();\n    int refreshEveryNumDocs = 100;\n    int commitCloseNumDocs = 1000;\n\n    for(int i=0;i<numDocs;i++) {\n      if (reindexer == null) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: open new reader/writer\");\n        reindexer = getReindexerSameDVField(root, currentSchemaGen, mergingSchemaGen);\n      }\n\n      Document doc = new Document();\n      String id;\n      String updateID;\n      if (maxID > 0 && random().nextInt(10) == 7) {\n        // Replace a doc\n        id = \"\" + random().nextInt(maxID);\n        updateID = id;\n      } else {\n        id = \"\" + (maxID++);\n        updateID = null;\n      }\n        \n      doc.add(newStringField(\"id\", id, Field.Store.NO));\n      doc.add(newTextField(\"text\", \"number \" + TestUtil.nextInt(random(), -10000, 10000), Field.Store.YES));\n      if (updateID == null) {\n        reindexer.w.addDocument(doc);\n      } else {\n        reindexer.w.updateDocument(new Term(\"id\", updateID), doc);\n      }\n      if (random().nextInt(refreshEveryNumDocs) == 17) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: refresh @ \" + (i+1) + \" docs\");\n        reindexer.mgr.maybeRefresh();\n        DirectoryReader r = reindexer.mgr.acquire();\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: got reader=\" + r);\n        try {\n          checkAllNumberDVs(r, \"number\", true, (int) currentSchemaGen.get());\n        } finally {\n          reindexer.mgr.release(r);\n        }\n        if (DEBUG) reindexer.printRefCounts();\n        refreshEveryNumDocs = (int) (1.25 * refreshEveryNumDocs);\n      }\n\n      if (random().nextInt(500) == 17) {\n        currentSchemaGen.incrementAndGet();\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: advance schemaGen to \" + currentSchemaGen);\n        if (random().nextBoolean()) {\n          mergingSchemaGen.incrementAndGet();\n          if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: advance mergingSchemaGen to \" + mergingSchemaGen);\n        }\n      }\n\n      if (i > 0 && random().nextInt(10) == 7) {\n        // Random delete:\n        reindexer.w.deleteDocuments(new Term(\"id\", \"\"+random().nextInt(i)));\n      }\n\n      if (random().nextInt(commitCloseNumDocs) == 17) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: commit @ \" + (i+1) + \" docs\");\n        reindexer.commit();\n        //reindexer.printRefCounts();\n        commitCloseNumDocs = (int) (1.25 * commitCloseNumDocs);\n      }\n\n      // Sometimes close & reopen writer/manager, to confirm the parallel segments persist:\n      if (random().nextInt(commitCloseNumDocs) == 17) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: close writer @ \" + (i+1) + \" docs\");\n        reindexer.close();\n        reindexer = null;\n        commitCloseNumDocs = (int) (1.25 * commitCloseNumDocs);\n      }\n    }\n\n    if (reindexer != null) {\n      reindexer.close();\n    }\n\n    // Verify main index never reflects schema changes beyond mergingSchemaGen:\n    try (Directory dir = newFSDirectory(root.resolve(\"index\"));\n         IndexReader r = DirectoryReader.open(dir)) {\n        for (LeafReaderContext ctx : r.leaves()) {\n          LeafReader leaf = ctx.reader();\n          NumericDocValues numbers = leaf.getNumericDocValues(\"number\");\n          if (numbers != null) {\n            int maxDoc = leaf.maxDoc();\n            for(int i=0;i<maxDoc;i++) {\n              Document doc = leaf.document(i);\n              long value = Long.parseLong(doc.get(\"text\").split(\" \")[1]);\n              long dvValue = numbers.get(i);\n              if (value == 0) {\n                assertEquals(0, dvValue);\n              } else {\n                assertTrue(dvValue % value == 0);\n                assertTrue(dvValue / value <= mergingSchemaGen.get());\n              }\n            }\n          }\n        }\n      }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"34d6426cef006e0c3625cabe7a7ec1c2b08bc501","date":1454683374,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader#testRandomMultipleSchemaGensSameField().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader#testRandomMultipleSchemaGensSameField().mjava","sourceNew":"  /** First schema change creates a new \"number\" DV field off the stored field; subsequent changes just change the value of that number\n   *  field for all docs. */\n  public void testRandomMultipleSchemaGensSameField() throws Exception {\n\n    AtomicLong currentSchemaGen = new AtomicLong();\n    AtomicLong mergingSchemaGen = new AtomicLong();\n\n    ReindexingReader reindexer = null;\n\n    // TODO: separate refresh thread, search threads, indexing threads\n    int numDocs = atLeast(TEST_NIGHTLY ? 20000 : 1000);\n    int maxID = 0;\n    Path root = createTempDir();\n    int refreshEveryNumDocs = 100;\n    int commitCloseNumDocs = 1000;\n\n    for(int i=0;i<numDocs;i++) {\n      if (reindexer == null) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: open new reader/writer\");\n        reindexer = getReindexerSameDVField(root, currentSchemaGen, mergingSchemaGen);\n      }\n\n      Document doc = new Document();\n      String id;\n      String updateID;\n      if (maxID > 0 && random().nextInt(10) == 7) {\n        // Replace a doc\n        id = \"\" + random().nextInt(maxID);\n        updateID = id;\n      } else {\n        id = \"\" + (maxID++);\n        updateID = null;\n      }\n        \n      doc.add(newStringField(\"id\", id, Field.Store.NO));\n      doc.add(newTextField(\"text\", \"number \" + TestUtil.nextInt(random(), -10000, 10000), Field.Store.YES));\n      if (updateID == null) {\n        reindexer.w.addDocument(doc);\n      } else {\n        reindexer.w.updateDocument(new Term(\"id\", updateID), doc);\n      }\n      if (random().nextInt(refreshEveryNumDocs) == 17) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: refresh @ \" + (i+1) + \" docs\");\n        reindexer.mgr.maybeRefresh();\n        DirectoryReader r = reindexer.mgr.acquire();\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: got reader=\" + r);\n        try {\n          checkAllNumberDVs(r, \"number\", true, (int) currentSchemaGen.get());\n        } finally {\n          reindexer.mgr.release(r);\n        }\n        if (DEBUG) reindexer.printRefCounts();\n        refreshEveryNumDocs = (int) (1.25 * refreshEveryNumDocs);\n      }\n\n      if (random().nextInt(500) == 17) {\n        currentSchemaGen.incrementAndGet();\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: advance schemaGen to \" + currentSchemaGen);\n        if (random().nextBoolean()) {\n          mergingSchemaGen.incrementAndGet();\n          if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: advance mergingSchemaGen to \" + mergingSchemaGen);\n        }\n      }\n\n      if (i > 0 && random().nextInt(10) == 7) {\n        // Random delete:\n        reindexer.w.deleteDocuments(new Term(\"id\", \"\"+random().nextInt(i)));\n      }\n\n      if (random().nextInt(commitCloseNumDocs) == 17) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: commit @ \" + (i+1) + \" docs\");\n        reindexer.commit();\n        //reindexer.printRefCounts();\n        commitCloseNumDocs = (int) (1.25 * commitCloseNumDocs);\n      }\n\n      // Sometimes close & reopen writer/manager, to confirm the parallel segments persist:\n      if (random().nextInt(commitCloseNumDocs) == 17) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: close writer @ \" + (i+1) + \" docs\");\n        reindexer.close();\n        reindexer = null;\n        commitCloseNumDocs = (int) (1.25 * commitCloseNumDocs);\n      }\n    }\n\n    if (reindexer != null) {\n      reindexer.close();\n    }\n\n    // Verify main index never reflects schema changes beyond mergingSchemaGen:\n    try (Directory dir = newFSDirectory(root.resolve(\"index\"));\n         IndexReader r = DirectoryReader.open(dir)) {\n        for (LeafReaderContext ctx : r.leaves()) {\n          LeafReader leaf = ctx.reader();\n          NumericDocValues numbers = leaf.getNumericDocValues(\"number\");\n          if (numbers != null) {\n            int maxDoc = leaf.maxDoc();\n            for(int i=0;i<maxDoc;i++) {\n              Document doc = leaf.document(i);\n              long value = Long.parseLong(doc.get(\"text\").split(\" \")[1]);\n              long dvValue = numbers.get(i);\n              if (value == 0) {\n                assertEquals(0, dvValue);\n              } else {\n                assertTrue(dvValue % value == 0);\n                assertTrue(dvValue / value <= mergingSchemaGen.get());\n              }\n            }\n          }\n        }\n      }\n  }\n\n","sourceOld":"  /** First schema change creates a new \"number\" DV field off the stored field; subsequent changes just change the value of that number\n   *  field for all docs. */\n  public void testRandomMultipleSchemaGensSameField() throws Exception {\n\n    AtomicLong currentSchemaGen = new AtomicLong();\n    AtomicLong mergingSchemaGen = new AtomicLong();\n\n    ReindexingReader reindexer = null;\n\n    // TODO: separate refresh thread, search threads, indexing threads\n    int numDocs = atLeast(TEST_NIGHTLY ? 20000 : 1000);\n    int maxID = 0;\n    Path root = createTempDir();\n    assumeFalse(\"we directly delete files\", TestUtil.hasVirusChecker(root));\n    int refreshEveryNumDocs = 100;\n    int commitCloseNumDocs = 1000;\n\n    for(int i=0;i<numDocs;i++) {\n      if (reindexer == null) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: open new reader/writer\");\n        reindexer = getReindexerSameDVField(root, currentSchemaGen, mergingSchemaGen);\n      }\n\n      Document doc = new Document();\n      String id;\n      String updateID;\n      if (maxID > 0 && random().nextInt(10) == 7) {\n        // Replace a doc\n        id = \"\" + random().nextInt(maxID);\n        updateID = id;\n      } else {\n        id = \"\" + (maxID++);\n        updateID = null;\n      }\n        \n      doc.add(newStringField(\"id\", id, Field.Store.NO));\n      doc.add(newTextField(\"text\", \"number \" + TestUtil.nextInt(random(), -10000, 10000), Field.Store.YES));\n      if (updateID == null) {\n        reindexer.w.addDocument(doc);\n      } else {\n        reindexer.w.updateDocument(new Term(\"id\", updateID), doc);\n      }\n      if (random().nextInt(refreshEveryNumDocs) == 17) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: refresh @ \" + (i+1) + \" docs\");\n        reindexer.mgr.maybeRefresh();\n        DirectoryReader r = reindexer.mgr.acquire();\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: got reader=\" + r);\n        try {\n          checkAllNumberDVs(r, \"number\", true, (int) currentSchemaGen.get());\n        } finally {\n          reindexer.mgr.release(r);\n        }\n        if (DEBUG) reindexer.printRefCounts();\n        refreshEveryNumDocs = (int) (1.25 * refreshEveryNumDocs);\n      }\n\n      if (random().nextInt(500) == 17) {\n        currentSchemaGen.incrementAndGet();\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: advance schemaGen to \" + currentSchemaGen);\n        if (random().nextBoolean()) {\n          mergingSchemaGen.incrementAndGet();\n          if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: advance mergingSchemaGen to \" + mergingSchemaGen);\n        }\n      }\n\n      if (i > 0 && random().nextInt(10) == 7) {\n        // Random delete:\n        reindexer.w.deleteDocuments(new Term(\"id\", \"\"+random().nextInt(i)));\n      }\n\n      if (random().nextInt(commitCloseNumDocs) == 17) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: commit @ \" + (i+1) + \" docs\");\n        reindexer.commit();\n        //reindexer.printRefCounts();\n        commitCloseNumDocs = (int) (1.25 * commitCloseNumDocs);\n      }\n\n      // Sometimes close & reopen writer/manager, to confirm the parallel segments persist:\n      if (random().nextInt(commitCloseNumDocs) == 17) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: close writer @ \" + (i+1) + \" docs\");\n        reindexer.close();\n        reindexer = null;\n        commitCloseNumDocs = (int) (1.25 * commitCloseNumDocs);\n      }\n    }\n\n    if (reindexer != null) {\n      reindexer.close();\n    }\n\n    // Verify main index never reflects schema changes beyond mergingSchemaGen:\n    try (Directory dir = newFSDirectory(root.resolve(\"index\"));\n         IndexReader r = DirectoryReader.open(dir)) {\n        for (LeafReaderContext ctx : r.leaves()) {\n          LeafReader leaf = ctx.reader();\n          NumericDocValues numbers = leaf.getNumericDocValues(\"number\");\n          if (numbers != null) {\n            int maxDoc = leaf.maxDoc();\n            for(int i=0;i<maxDoc;i++) {\n              Document doc = leaf.document(i);\n              long value = Long.parseLong(doc.get(\"text\").split(\" \")[1]);\n              long dvValue = numbers.get(i);\n              if (value == 0) {\n                assertEquals(0, dvValue);\n              } else {\n                assertTrue(dvValue % value == 0);\n                assertTrue(dvValue / value <= mergingSchemaGen.get());\n              }\n            }\n          }\n        }\n      }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6652c74b2358a0b13223817a6a793bf1c9d0749d","date":1474465301,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader#testRandomMultipleSchemaGensSameField().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader#testRandomMultipleSchemaGensSameField().mjava","sourceNew":"  /** First schema change creates a new \"number\" DV field off the stored field; subsequent changes just change the value of that number\n   *  field for all docs. */\n  public void testRandomMultipleSchemaGensSameField() throws Exception {\n\n    AtomicLong currentSchemaGen = new AtomicLong();\n    AtomicLong mergingSchemaGen = new AtomicLong();\n\n    ReindexingReader reindexer = null;\n\n    // TODO: separate refresh thread, search threads, indexing threads\n    int numDocs = atLeast(TEST_NIGHTLY ? 20000 : 1000);\n    int maxID = 0;\n    Path root = createTempDir();\n    int refreshEveryNumDocs = 100;\n    int commitCloseNumDocs = 1000;\n\n    for(int i=0;i<numDocs;i++) {\n      if (reindexer == null) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: open new reader/writer\");\n        reindexer = getReindexerSameDVField(root, currentSchemaGen, mergingSchemaGen);\n      }\n\n      Document doc = new Document();\n      String id;\n      String updateID;\n      if (maxID > 0 && random().nextInt(10) == 7) {\n        // Replace a doc\n        id = \"\" + random().nextInt(maxID);\n        updateID = id;\n      } else {\n        id = \"\" + (maxID++);\n        updateID = null;\n      }\n        \n      doc.add(newStringField(\"id\", id, Field.Store.NO));\n      doc.add(newTextField(\"text\", \"number \" + TestUtil.nextInt(random(), -10000, 10000), Field.Store.YES));\n      if (updateID == null) {\n        reindexer.w.addDocument(doc);\n      } else {\n        reindexer.w.updateDocument(new Term(\"id\", updateID), doc);\n      }\n      if (random().nextInt(refreshEveryNumDocs) == 17) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: refresh @ \" + (i+1) + \" docs\");\n        reindexer.mgr.maybeRefresh();\n        DirectoryReader r = reindexer.mgr.acquire();\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: got reader=\" + r);\n        try {\n          checkAllNumberDVs(r, \"number\", true, (int) currentSchemaGen.get());\n        } finally {\n          reindexer.mgr.release(r);\n        }\n        if (DEBUG) reindexer.printRefCounts();\n        refreshEveryNumDocs = (int) (1.25 * refreshEveryNumDocs);\n      }\n\n      if (random().nextInt(500) == 17) {\n        currentSchemaGen.incrementAndGet();\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: advance schemaGen to \" + currentSchemaGen);\n        if (random().nextBoolean()) {\n          mergingSchemaGen.incrementAndGet();\n          if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: advance mergingSchemaGen to \" + mergingSchemaGen);\n        }\n      }\n\n      if (i > 0 && random().nextInt(10) == 7) {\n        // Random delete:\n        reindexer.w.deleteDocuments(new Term(\"id\", \"\"+random().nextInt(i)));\n      }\n\n      if (random().nextInt(commitCloseNumDocs) == 17) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: commit @ \" + (i+1) + \" docs\");\n        reindexer.commit();\n        //reindexer.printRefCounts();\n        commitCloseNumDocs = (int) (1.25 * commitCloseNumDocs);\n      }\n\n      // Sometimes close & reopen writer/manager, to confirm the parallel segments persist:\n      if (random().nextInt(commitCloseNumDocs) == 17) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: close writer @ \" + (i+1) + \" docs\");\n        reindexer.close();\n        reindexer = null;\n        commitCloseNumDocs = (int) (1.25 * commitCloseNumDocs);\n      }\n    }\n\n    if (reindexer != null) {\n      reindexer.close();\n    }\n\n    // Verify main index never reflects schema changes beyond mergingSchemaGen:\n    try (Directory dir = newFSDirectory(root.resolve(\"index\"));\n         IndexReader r = DirectoryReader.open(dir)) {\n        for (LeafReaderContext ctx : r.leaves()) {\n          LeafReader leaf = ctx.reader();\n          NumericDocValues numbers = leaf.getNumericDocValues(\"number\");\n          if (numbers != null) {\n            int maxDoc = leaf.maxDoc();\n            for(int i=0;i<maxDoc;i++) {\n              Document doc = leaf.document(i);\n              long value = Long.parseLong(doc.get(\"text\").split(\" \")[1]);\n              assertEquals(i, numbers.nextDoc());\n              long dvValue = numbers.longValue();\n              if (value == 0) {\n                assertEquals(0, dvValue);\n              } else {\n                assertTrue(dvValue % value == 0);\n                assertTrue(dvValue / value <= mergingSchemaGen.get());\n              }\n            }\n          }\n        }\n      }\n  }\n\n","sourceOld":"  /** First schema change creates a new \"number\" DV field off the stored field; subsequent changes just change the value of that number\n   *  field for all docs. */\n  public void testRandomMultipleSchemaGensSameField() throws Exception {\n\n    AtomicLong currentSchemaGen = new AtomicLong();\n    AtomicLong mergingSchemaGen = new AtomicLong();\n\n    ReindexingReader reindexer = null;\n\n    // TODO: separate refresh thread, search threads, indexing threads\n    int numDocs = atLeast(TEST_NIGHTLY ? 20000 : 1000);\n    int maxID = 0;\n    Path root = createTempDir();\n    int refreshEveryNumDocs = 100;\n    int commitCloseNumDocs = 1000;\n\n    for(int i=0;i<numDocs;i++) {\n      if (reindexer == null) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: open new reader/writer\");\n        reindexer = getReindexerSameDVField(root, currentSchemaGen, mergingSchemaGen);\n      }\n\n      Document doc = new Document();\n      String id;\n      String updateID;\n      if (maxID > 0 && random().nextInt(10) == 7) {\n        // Replace a doc\n        id = \"\" + random().nextInt(maxID);\n        updateID = id;\n      } else {\n        id = \"\" + (maxID++);\n        updateID = null;\n      }\n        \n      doc.add(newStringField(\"id\", id, Field.Store.NO));\n      doc.add(newTextField(\"text\", \"number \" + TestUtil.nextInt(random(), -10000, 10000), Field.Store.YES));\n      if (updateID == null) {\n        reindexer.w.addDocument(doc);\n      } else {\n        reindexer.w.updateDocument(new Term(\"id\", updateID), doc);\n      }\n      if (random().nextInt(refreshEveryNumDocs) == 17) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: refresh @ \" + (i+1) + \" docs\");\n        reindexer.mgr.maybeRefresh();\n        DirectoryReader r = reindexer.mgr.acquire();\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: got reader=\" + r);\n        try {\n          checkAllNumberDVs(r, \"number\", true, (int) currentSchemaGen.get());\n        } finally {\n          reindexer.mgr.release(r);\n        }\n        if (DEBUG) reindexer.printRefCounts();\n        refreshEveryNumDocs = (int) (1.25 * refreshEveryNumDocs);\n      }\n\n      if (random().nextInt(500) == 17) {\n        currentSchemaGen.incrementAndGet();\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: advance schemaGen to \" + currentSchemaGen);\n        if (random().nextBoolean()) {\n          mergingSchemaGen.incrementAndGet();\n          if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: advance mergingSchemaGen to \" + mergingSchemaGen);\n        }\n      }\n\n      if (i > 0 && random().nextInt(10) == 7) {\n        // Random delete:\n        reindexer.w.deleteDocuments(new Term(\"id\", \"\"+random().nextInt(i)));\n      }\n\n      if (random().nextInt(commitCloseNumDocs) == 17) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: commit @ \" + (i+1) + \" docs\");\n        reindexer.commit();\n        //reindexer.printRefCounts();\n        commitCloseNumDocs = (int) (1.25 * commitCloseNumDocs);\n      }\n\n      // Sometimes close & reopen writer/manager, to confirm the parallel segments persist:\n      if (random().nextInt(commitCloseNumDocs) == 17) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: close writer @ \" + (i+1) + \" docs\");\n        reindexer.close();\n        reindexer = null;\n        commitCloseNumDocs = (int) (1.25 * commitCloseNumDocs);\n      }\n    }\n\n    if (reindexer != null) {\n      reindexer.close();\n    }\n\n    // Verify main index never reflects schema changes beyond mergingSchemaGen:\n    try (Directory dir = newFSDirectory(root.resolve(\"index\"));\n         IndexReader r = DirectoryReader.open(dir)) {\n        for (LeafReaderContext ctx : r.leaves()) {\n          LeafReader leaf = ctx.reader();\n          NumericDocValues numbers = leaf.getNumericDocValues(\"number\");\n          if (numbers != null) {\n            int maxDoc = leaf.maxDoc();\n            for(int i=0;i<maxDoc;i++) {\n              Document doc = leaf.document(i);\n              long value = Long.parseLong(doc.get(\"text\").split(\" \")[1]);\n              long dvValue = numbers.get(i);\n              if (value == 0) {\n                assertEquals(0, dvValue);\n              } else {\n                assertTrue(dvValue % value == 0);\n                assertTrue(dvValue / value <= mergingSchemaGen.get());\n              }\n            }\n          }\n        }\n      }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"17e5da53e4e5bd659e22add9bba1cfa222e7e30d","date":1475435902,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader#testRandomMultipleSchemaGensSameField().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader#testRandomMultipleSchemaGensSameField().mjava","sourceNew":"  /** First schema change creates a new \"number\" DV field off the stored field; subsequent changes just change the value of that number\n   *  field for all docs. */\n  public void testRandomMultipleSchemaGensSameField() throws Exception {\n\n    AtomicLong currentSchemaGen = new AtomicLong();\n    AtomicLong mergingSchemaGen = new AtomicLong();\n\n    ReindexingReader reindexer = null;\n\n    // TODO: separate refresh thread, search threads, indexing threads\n    int numDocs = atLeast(TEST_NIGHTLY ? 20000 : 1000);\n    int maxID = 0;\n    Path root = createTempDir();\n    int refreshEveryNumDocs = 100;\n    int commitCloseNumDocs = 1000;\n\n    for(int i=0;i<numDocs;i++) {\n      if (reindexer == null) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: open new reader/writer\");\n        reindexer = getReindexerSameDVField(root, currentSchemaGen, mergingSchemaGen);\n      }\n\n      Document doc = new Document();\n      String id;\n      String updateID;\n      if (maxID > 0 && random().nextInt(10) == 7) {\n        // Replace a doc\n        id = \"\" + random().nextInt(maxID);\n        updateID = id;\n      } else {\n        id = \"\" + (maxID++);\n        updateID = null;\n      }\n        \n      doc.add(newStringField(\"id\", id, Field.Store.NO));\n      doc.add(newTextField(\"text\", \"number \" + TestUtil.nextInt(random(), -10000, 10000), Field.Store.YES));\n      if (updateID == null) {\n        reindexer.w.addDocument(doc);\n      } else {\n        reindexer.w.updateDocument(new Term(\"id\", updateID), doc);\n      }\n      if (random().nextInt(refreshEveryNumDocs) == 17) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: refresh @ \" + (i+1) + \" docs\");\n        reindexer.mgr.maybeRefresh();\n        DirectoryReader r = reindexer.mgr.acquire();\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: got reader=\" + r);\n        try {\n          checkAllNumberDVs(r, \"number\", true, (int) currentSchemaGen.get());\n        } finally {\n          reindexer.mgr.release(r);\n        }\n        if (DEBUG) reindexer.printRefCounts();\n        refreshEveryNumDocs = (int) (1.25 * refreshEveryNumDocs);\n      }\n\n      if (random().nextInt(500) == 17) {\n        currentSchemaGen.incrementAndGet();\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: advance schemaGen to \" + currentSchemaGen);\n        if (random().nextBoolean()) {\n          mergingSchemaGen.incrementAndGet();\n          if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: advance mergingSchemaGen to \" + mergingSchemaGen);\n        }\n      }\n\n      if (i > 0 && random().nextInt(10) == 7) {\n        // Random delete:\n        reindexer.w.deleteDocuments(new Term(\"id\", \"\"+random().nextInt(i)));\n      }\n\n      if (random().nextInt(commitCloseNumDocs) == 17) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: commit @ \" + (i+1) + \" docs\");\n        reindexer.commit();\n        //reindexer.printRefCounts();\n        commitCloseNumDocs = (int) (1.25 * commitCloseNumDocs);\n      }\n\n      // Sometimes close & reopen writer/manager, to confirm the parallel segments persist:\n      if (random().nextInt(commitCloseNumDocs) == 17) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: close writer @ \" + (i+1) + \" docs\");\n        reindexer.close();\n        reindexer = null;\n        commitCloseNumDocs = (int) (1.25 * commitCloseNumDocs);\n      }\n    }\n\n    if (reindexer != null) {\n      reindexer.close();\n    }\n\n    // Verify main index never reflects schema changes beyond mergingSchemaGen:\n    try (Directory dir = newFSDirectory(root.resolve(\"index\"));\n         IndexReader r = DirectoryReader.open(dir)) {\n        for (LeafReaderContext ctx : r.leaves()) {\n          LeafReader leaf = ctx.reader();\n          NumericDocValues numbers = leaf.getNumericDocValues(\"number\");\n          if (numbers != null) {\n            int maxDoc = leaf.maxDoc();\n            for(int i=0;i<maxDoc;i++) {\n              Document doc = leaf.document(i);\n              long value = Long.parseLong(doc.get(\"text\").split(\" \")[1]);\n              assertEquals(i, numbers.nextDoc());\n              long dvValue = numbers.longValue();\n              if (value == 0) {\n                assertEquals(0, dvValue);\n              } else {\n                assertTrue(dvValue % value == 0);\n                assertTrue(dvValue / value <= mergingSchemaGen.get());\n              }\n            }\n          }\n        }\n      }\n  }\n\n","sourceOld":"  /** First schema change creates a new \"number\" DV field off the stored field; subsequent changes just change the value of that number\n   *  field for all docs. */\n  public void testRandomMultipleSchemaGensSameField() throws Exception {\n\n    AtomicLong currentSchemaGen = new AtomicLong();\n    AtomicLong mergingSchemaGen = new AtomicLong();\n\n    ReindexingReader reindexer = null;\n\n    // TODO: separate refresh thread, search threads, indexing threads\n    int numDocs = atLeast(TEST_NIGHTLY ? 20000 : 1000);\n    int maxID = 0;\n    Path root = createTempDir();\n    int refreshEveryNumDocs = 100;\n    int commitCloseNumDocs = 1000;\n\n    for(int i=0;i<numDocs;i++) {\n      if (reindexer == null) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: open new reader/writer\");\n        reindexer = getReindexerSameDVField(root, currentSchemaGen, mergingSchemaGen);\n      }\n\n      Document doc = new Document();\n      String id;\n      String updateID;\n      if (maxID > 0 && random().nextInt(10) == 7) {\n        // Replace a doc\n        id = \"\" + random().nextInt(maxID);\n        updateID = id;\n      } else {\n        id = \"\" + (maxID++);\n        updateID = null;\n      }\n        \n      doc.add(newStringField(\"id\", id, Field.Store.NO));\n      doc.add(newTextField(\"text\", \"number \" + TestUtil.nextInt(random(), -10000, 10000), Field.Store.YES));\n      if (updateID == null) {\n        reindexer.w.addDocument(doc);\n      } else {\n        reindexer.w.updateDocument(new Term(\"id\", updateID), doc);\n      }\n      if (random().nextInt(refreshEveryNumDocs) == 17) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: refresh @ \" + (i+1) + \" docs\");\n        reindexer.mgr.maybeRefresh();\n        DirectoryReader r = reindexer.mgr.acquire();\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: got reader=\" + r);\n        try {\n          checkAllNumberDVs(r, \"number\", true, (int) currentSchemaGen.get());\n        } finally {\n          reindexer.mgr.release(r);\n        }\n        if (DEBUG) reindexer.printRefCounts();\n        refreshEveryNumDocs = (int) (1.25 * refreshEveryNumDocs);\n      }\n\n      if (random().nextInt(500) == 17) {\n        currentSchemaGen.incrementAndGet();\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: advance schemaGen to \" + currentSchemaGen);\n        if (random().nextBoolean()) {\n          mergingSchemaGen.incrementAndGet();\n          if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: advance mergingSchemaGen to \" + mergingSchemaGen);\n        }\n      }\n\n      if (i > 0 && random().nextInt(10) == 7) {\n        // Random delete:\n        reindexer.w.deleteDocuments(new Term(\"id\", \"\"+random().nextInt(i)));\n      }\n\n      if (random().nextInt(commitCloseNumDocs) == 17) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: commit @ \" + (i+1) + \" docs\");\n        reindexer.commit();\n        //reindexer.printRefCounts();\n        commitCloseNumDocs = (int) (1.25 * commitCloseNumDocs);\n      }\n\n      // Sometimes close & reopen writer/manager, to confirm the parallel segments persist:\n      if (random().nextInt(commitCloseNumDocs) == 17) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: close writer @ \" + (i+1) + \" docs\");\n        reindexer.close();\n        reindexer = null;\n        commitCloseNumDocs = (int) (1.25 * commitCloseNumDocs);\n      }\n    }\n\n    if (reindexer != null) {\n      reindexer.close();\n    }\n\n    // Verify main index never reflects schema changes beyond mergingSchemaGen:\n    try (Directory dir = newFSDirectory(root.resolve(\"index\"));\n         IndexReader r = DirectoryReader.open(dir)) {\n        for (LeafReaderContext ctx : r.leaves()) {\n          LeafReader leaf = ctx.reader();\n          NumericDocValues numbers = leaf.getNumericDocValues(\"number\");\n          if (numbers != null) {\n            int maxDoc = leaf.maxDoc();\n            for(int i=0;i<maxDoc;i++) {\n              Document doc = leaf.document(i);\n              long value = Long.parseLong(doc.get(\"text\").split(\" \")[1]);\n              long dvValue = numbers.get(i);\n              if (value == 0) {\n                assertEquals(0, dvValue);\n              } else {\n                assertTrue(dvValue % value == 0);\n                assertTrue(dvValue / value <= mergingSchemaGen.get());\n              }\n            }\n          }\n        }\n      }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader#testRandomMultipleSchemaGensSameField().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader#testRandomMultipleSchemaGensSameField().mjava","sourceNew":"  /** First schema change creates a new \"number\" DV field off the stored field; subsequent changes just change the value of that number\n   *  field for all docs. */\n  public void testRandomMultipleSchemaGensSameField() throws Exception {\n\n    AtomicLong currentSchemaGen = new AtomicLong();\n    AtomicLong mergingSchemaGen = new AtomicLong();\n\n    ReindexingReader reindexer = null;\n\n    // TODO: separate refresh thread, search threads, indexing threads\n    int numDocs = atLeast(TEST_NIGHTLY ? 20000 : 1000);\n    int maxID = 0;\n    Path root = createTempDir();\n    int refreshEveryNumDocs = 100;\n    int commitCloseNumDocs = 1000;\n\n    for(int i=0;i<numDocs;i++) {\n      if (reindexer == null) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: open new reader/writer\");\n        reindexer = getReindexerSameDVField(root, currentSchemaGen, mergingSchemaGen);\n      }\n\n      Document doc = new Document();\n      String id;\n      String updateID;\n      if (maxID > 0 && random().nextInt(10) == 7) {\n        // Replace a doc\n        id = \"\" + random().nextInt(maxID);\n        updateID = id;\n      } else {\n        id = \"\" + (maxID++);\n        updateID = null;\n      }\n        \n      doc.add(newStringField(\"id\", id, Field.Store.NO));\n      doc.add(newTextField(\"text\", \"number \" + TestUtil.nextInt(random(), -10000, 10000), Field.Store.YES));\n      if (updateID == null) {\n        reindexer.w.addDocument(doc);\n      } else {\n        reindexer.w.updateDocument(new Term(\"id\", updateID), doc);\n      }\n      if (random().nextInt(refreshEveryNumDocs) == 17) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: refresh @ \" + (i+1) + \" docs\");\n        reindexer.mgr.maybeRefresh();\n        DirectoryReader r = reindexer.mgr.acquire();\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: got reader=\" + r);\n        try {\n          checkAllNumberDVs(r, \"number\", true, (int) currentSchemaGen.get());\n        } finally {\n          reindexer.mgr.release(r);\n        }\n        if (DEBUG) reindexer.printRefCounts();\n        refreshEveryNumDocs = (int) (1.25 * refreshEveryNumDocs);\n      }\n\n      if (random().nextInt(500) == 17) {\n        currentSchemaGen.incrementAndGet();\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: advance schemaGen to \" + currentSchemaGen);\n        if (random().nextBoolean()) {\n          mergingSchemaGen.incrementAndGet();\n          if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: advance mergingSchemaGen to \" + mergingSchemaGen);\n        }\n      }\n\n      if (i > 0 && random().nextInt(10) == 7) {\n        // Random delete:\n        reindexer.w.deleteDocuments(new Term(\"id\", \"\"+random().nextInt(i)));\n      }\n\n      if (random().nextInt(commitCloseNumDocs) == 17) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: commit @ \" + (i+1) + \" docs\");\n        reindexer.commit();\n        //reindexer.printRefCounts();\n        commitCloseNumDocs = (int) (1.25 * commitCloseNumDocs);\n      }\n\n      // Sometimes close & reopen writer/manager, to confirm the parallel segments persist:\n      if (random().nextInt(commitCloseNumDocs) == 17) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: close writer @ \" + (i+1) + \" docs\");\n        reindexer.close();\n        reindexer = null;\n        commitCloseNumDocs = (int) (1.25 * commitCloseNumDocs);\n      }\n    }\n\n    if (reindexer != null) {\n      reindexer.close();\n    }\n\n    // Verify main index never reflects schema changes beyond mergingSchemaGen:\n    try (Directory dir = newFSDirectory(root.resolve(\"index\"));\n         IndexReader r = DirectoryReader.open(dir)) {\n        for (LeafReaderContext ctx : r.leaves()) {\n          LeafReader leaf = ctx.reader();\n          NumericDocValues numbers = leaf.getNumericDocValues(\"number\");\n          if (numbers != null) {\n            int maxDoc = leaf.maxDoc();\n            for(int i=0;i<maxDoc;i++) {\n              Document doc = leaf.document(i);\n              long value = Long.parseLong(doc.get(\"text\").split(\" \")[1]);\n              assertEquals(i, numbers.nextDoc());\n              long dvValue = numbers.longValue();\n              if (value == 0) {\n                assertEquals(0, dvValue);\n              } else {\n                assertTrue(dvValue % value == 0);\n                assertTrue(dvValue / value <= mergingSchemaGen.get());\n              }\n            }\n          }\n        }\n      }\n  }\n\n","sourceOld":"  /** First schema change creates a new \"number\" DV field off the stored field; subsequent changes just change the value of that number\n   *  field for all docs. */\n  public void testRandomMultipleSchemaGensSameField() throws Exception {\n\n    AtomicLong currentSchemaGen = new AtomicLong();\n    AtomicLong mergingSchemaGen = new AtomicLong();\n\n    ReindexingReader reindexer = null;\n\n    // TODO: separate refresh thread, search threads, indexing threads\n    int numDocs = atLeast(TEST_NIGHTLY ? 20000 : 1000);\n    int maxID = 0;\n    Path root = createTempDir();\n    int refreshEveryNumDocs = 100;\n    int commitCloseNumDocs = 1000;\n\n    for(int i=0;i<numDocs;i++) {\n      if (reindexer == null) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: open new reader/writer\");\n        reindexer = getReindexerSameDVField(root, currentSchemaGen, mergingSchemaGen);\n      }\n\n      Document doc = new Document();\n      String id;\n      String updateID;\n      if (maxID > 0 && random().nextInt(10) == 7) {\n        // Replace a doc\n        id = \"\" + random().nextInt(maxID);\n        updateID = id;\n      } else {\n        id = \"\" + (maxID++);\n        updateID = null;\n      }\n        \n      doc.add(newStringField(\"id\", id, Field.Store.NO));\n      doc.add(newTextField(\"text\", \"number \" + TestUtil.nextInt(random(), -10000, 10000), Field.Store.YES));\n      if (updateID == null) {\n        reindexer.w.addDocument(doc);\n      } else {\n        reindexer.w.updateDocument(new Term(\"id\", updateID), doc);\n      }\n      if (random().nextInt(refreshEveryNumDocs) == 17) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: refresh @ \" + (i+1) + \" docs\");\n        reindexer.mgr.maybeRefresh();\n        DirectoryReader r = reindexer.mgr.acquire();\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: got reader=\" + r);\n        try {\n          checkAllNumberDVs(r, \"number\", true, (int) currentSchemaGen.get());\n        } finally {\n          reindexer.mgr.release(r);\n        }\n        if (DEBUG) reindexer.printRefCounts();\n        refreshEveryNumDocs = (int) (1.25 * refreshEveryNumDocs);\n      }\n\n      if (random().nextInt(500) == 17) {\n        currentSchemaGen.incrementAndGet();\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: advance schemaGen to \" + currentSchemaGen);\n        if (random().nextBoolean()) {\n          mergingSchemaGen.incrementAndGet();\n          if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: advance mergingSchemaGen to \" + mergingSchemaGen);\n        }\n      }\n\n      if (i > 0 && random().nextInt(10) == 7) {\n        // Random delete:\n        reindexer.w.deleteDocuments(new Term(\"id\", \"\"+random().nextInt(i)));\n      }\n\n      if (random().nextInt(commitCloseNumDocs) == 17) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: commit @ \" + (i+1) + \" docs\");\n        reindexer.commit();\n        //reindexer.printRefCounts();\n        commitCloseNumDocs = (int) (1.25 * commitCloseNumDocs);\n      }\n\n      // Sometimes close & reopen writer/manager, to confirm the parallel segments persist:\n      if (random().nextInt(commitCloseNumDocs) == 17) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: close writer @ \" + (i+1) + \" docs\");\n        reindexer.close();\n        reindexer = null;\n        commitCloseNumDocs = (int) (1.25 * commitCloseNumDocs);\n      }\n    }\n\n    if (reindexer != null) {\n      reindexer.close();\n    }\n\n    // Verify main index never reflects schema changes beyond mergingSchemaGen:\n    try (Directory dir = newFSDirectory(root.resolve(\"index\"));\n         IndexReader r = DirectoryReader.open(dir)) {\n        for (LeafReaderContext ctx : r.leaves()) {\n          LeafReader leaf = ctx.reader();\n          NumericDocValues numbers = leaf.getNumericDocValues(\"number\");\n          if (numbers != null) {\n            int maxDoc = leaf.maxDoc();\n            for(int i=0;i<maxDoc;i++) {\n              Document doc = leaf.document(i);\n              long value = Long.parseLong(doc.get(\"text\").split(\" \")[1]);\n              long dvValue = numbers.get(i);\n              if (value == 0) {\n                assertEquals(0, dvValue);\n              } else {\n                assertTrue(dvValue % value == 0);\n                assertTrue(dvValue / value <= mergingSchemaGen.get());\n              }\n            }\n          }\n        }\n      }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fc1e9ddca40a3ddf8b097f2cf1fe2547fe8e384f","date":1579652839,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader#testRandomMultipleSchemaGensSameField().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader#testRandomMultipleSchemaGensSameField().mjava","sourceNew":"  /** First schema change creates a new \"number\" DV field off the stored field; subsequent changes just change the value of that number\n   *  field for all docs. */\n  public void testRandomMultipleSchemaGensSameField() throws Exception {\n\n    AtomicLong currentSchemaGen = new AtomicLong();\n    AtomicLong mergingSchemaGen = new AtomicLong();\n\n    ReindexingReader reindexer = null;\n\n    // TODO: separate refresh thread, search threads, indexing threads\n    int numDocs = atLeast(TEST_NIGHTLY ? 20000 : 200);\n    int maxID = 0;\n    Path root = createTempDir();\n    int refreshEveryNumDocs = 100;\n    int commitCloseNumDocs = 1000;\n\n    for(int i=0;i<numDocs;i++) {\n      if (reindexer == null) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: open new reader/writer\");\n        reindexer = getReindexerSameDVField(root, currentSchemaGen, mergingSchemaGen);\n      }\n\n      Document doc = new Document();\n      String id;\n      String updateID;\n      if (maxID > 0 && random().nextInt(10) == 7) {\n        // Replace a doc\n        id = \"\" + random().nextInt(maxID);\n        updateID = id;\n      } else {\n        id = \"\" + (maxID++);\n        updateID = null;\n      }\n        \n      doc.add(newStringField(\"id\", id, Field.Store.NO));\n      doc.add(newTextField(\"text\", \"number \" + TestUtil.nextInt(random(), -10000, 10000), Field.Store.YES));\n      if (updateID == null) {\n        reindexer.w.addDocument(doc);\n      } else {\n        reindexer.w.updateDocument(new Term(\"id\", updateID), doc);\n      }\n      if (random().nextInt(refreshEveryNumDocs) == 17) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: refresh @ \" + (i+1) + \" docs\");\n        reindexer.mgr.maybeRefresh();\n        DirectoryReader r = reindexer.mgr.acquire();\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: got reader=\" + r);\n        try {\n          checkAllNumberDVs(r, \"number\", true, (int) currentSchemaGen.get());\n        } finally {\n          reindexer.mgr.release(r);\n        }\n        if (DEBUG) reindexer.printRefCounts();\n        refreshEveryNumDocs = (int) (1.25 * refreshEveryNumDocs);\n      }\n\n      if (random().nextInt(500) == 17) {\n        currentSchemaGen.incrementAndGet();\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: advance schemaGen to \" + currentSchemaGen);\n        if (random().nextBoolean()) {\n          mergingSchemaGen.incrementAndGet();\n          if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: advance mergingSchemaGen to \" + mergingSchemaGen);\n        }\n      }\n\n      if (i > 0 && random().nextInt(10) == 7) {\n        // Random delete:\n        reindexer.w.deleteDocuments(new Term(\"id\", \"\"+random().nextInt(i)));\n      }\n\n      if (random().nextInt(commitCloseNumDocs) == 17) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: commit @ \" + (i+1) + \" docs\");\n        reindexer.commit();\n        //reindexer.printRefCounts();\n        commitCloseNumDocs = (int) (1.25 * commitCloseNumDocs);\n      }\n\n      // Sometimes close & reopen writer/manager, to confirm the parallel segments persist:\n      if (random().nextInt(commitCloseNumDocs) == 17) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: close writer @ \" + (i+1) + \" docs\");\n        reindexer.close();\n        reindexer = null;\n        commitCloseNumDocs = (int) (1.25 * commitCloseNumDocs);\n      }\n    }\n\n    if (reindexer != null) {\n      reindexer.close();\n    }\n\n    // Verify main index never reflects schema changes beyond mergingSchemaGen:\n    try (Directory dir = newFSDirectory(root.resolve(\"index\"));\n         IndexReader r = DirectoryReader.open(dir)) {\n        for (LeafReaderContext ctx : r.leaves()) {\n          LeafReader leaf = ctx.reader();\n          NumericDocValues numbers = leaf.getNumericDocValues(\"number\");\n          if (numbers != null) {\n            int maxDoc = leaf.maxDoc();\n            for(int i=0;i<maxDoc;i++) {\n              Document doc = leaf.document(i);\n              long value = Long.parseLong(doc.get(\"text\").split(\" \")[1]);\n              assertEquals(i, numbers.nextDoc());\n              long dvValue = numbers.longValue();\n              if (value == 0) {\n                assertEquals(0, dvValue);\n              } else {\n                assertTrue(dvValue % value == 0);\n                assertTrue(dvValue / value <= mergingSchemaGen.get());\n              }\n            }\n          }\n        }\n      }\n  }\n\n","sourceOld":"  /** First schema change creates a new \"number\" DV field off the stored field; subsequent changes just change the value of that number\n   *  field for all docs. */\n  public void testRandomMultipleSchemaGensSameField() throws Exception {\n\n    AtomicLong currentSchemaGen = new AtomicLong();\n    AtomicLong mergingSchemaGen = new AtomicLong();\n\n    ReindexingReader reindexer = null;\n\n    // TODO: separate refresh thread, search threads, indexing threads\n    int numDocs = atLeast(TEST_NIGHTLY ? 20000 : 1000);\n    int maxID = 0;\n    Path root = createTempDir();\n    int refreshEveryNumDocs = 100;\n    int commitCloseNumDocs = 1000;\n\n    for(int i=0;i<numDocs;i++) {\n      if (reindexer == null) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: open new reader/writer\");\n        reindexer = getReindexerSameDVField(root, currentSchemaGen, mergingSchemaGen);\n      }\n\n      Document doc = new Document();\n      String id;\n      String updateID;\n      if (maxID > 0 && random().nextInt(10) == 7) {\n        // Replace a doc\n        id = \"\" + random().nextInt(maxID);\n        updateID = id;\n      } else {\n        id = \"\" + (maxID++);\n        updateID = null;\n      }\n        \n      doc.add(newStringField(\"id\", id, Field.Store.NO));\n      doc.add(newTextField(\"text\", \"number \" + TestUtil.nextInt(random(), -10000, 10000), Field.Store.YES));\n      if (updateID == null) {\n        reindexer.w.addDocument(doc);\n      } else {\n        reindexer.w.updateDocument(new Term(\"id\", updateID), doc);\n      }\n      if (random().nextInt(refreshEveryNumDocs) == 17) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: refresh @ \" + (i+1) + \" docs\");\n        reindexer.mgr.maybeRefresh();\n        DirectoryReader r = reindexer.mgr.acquire();\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: got reader=\" + r);\n        try {\n          checkAllNumberDVs(r, \"number\", true, (int) currentSchemaGen.get());\n        } finally {\n          reindexer.mgr.release(r);\n        }\n        if (DEBUG) reindexer.printRefCounts();\n        refreshEveryNumDocs = (int) (1.25 * refreshEveryNumDocs);\n      }\n\n      if (random().nextInt(500) == 17) {\n        currentSchemaGen.incrementAndGet();\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: advance schemaGen to \" + currentSchemaGen);\n        if (random().nextBoolean()) {\n          mergingSchemaGen.incrementAndGet();\n          if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: advance mergingSchemaGen to \" + mergingSchemaGen);\n        }\n      }\n\n      if (i > 0 && random().nextInt(10) == 7) {\n        // Random delete:\n        reindexer.w.deleteDocuments(new Term(\"id\", \"\"+random().nextInt(i)));\n      }\n\n      if (random().nextInt(commitCloseNumDocs) == 17) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: commit @ \" + (i+1) + \" docs\");\n        reindexer.commit();\n        //reindexer.printRefCounts();\n        commitCloseNumDocs = (int) (1.25 * commitCloseNumDocs);\n      }\n\n      // Sometimes close & reopen writer/manager, to confirm the parallel segments persist:\n      if (random().nextInt(commitCloseNumDocs) == 17) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST TOP: close writer @ \" + (i+1) + \" docs\");\n        reindexer.close();\n        reindexer = null;\n        commitCloseNumDocs = (int) (1.25 * commitCloseNumDocs);\n      }\n    }\n\n    if (reindexer != null) {\n      reindexer.close();\n    }\n\n    // Verify main index never reflects schema changes beyond mergingSchemaGen:\n    try (Directory dir = newFSDirectory(root.resolve(\"index\"));\n         IndexReader r = DirectoryReader.open(dir)) {\n        for (LeafReaderContext ctx : r.leaves()) {\n          LeafReader leaf = ctx.reader();\n          NumericDocValues numbers = leaf.getNumericDocValues(\"number\");\n          if (numbers != null) {\n            int maxDoc = leaf.maxDoc();\n            for(int i=0;i<maxDoc;i++) {\n              Document doc = leaf.document(i);\n              long value = Long.parseLong(doc.get(\"text\").split(\" \")[1]);\n              assertEquals(i, numbers.nextDoc());\n              long dvValue = numbers.longValue();\n              if (value == 0) {\n                assertEquals(0, dvValue);\n              } else {\n                assertTrue(dvValue % value == 0);\n                assertTrue(dvValue / value <= mergingSchemaGen.get());\n              }\n            }\n          }\n        }\n      }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"34d6426cef006e0c3625cabe7a7ec1c2b08bc501":["6bfe104fc023fadc9e709f8d17403d2cc61133fe"],"fc1e9ddca40a3ddf8b097f2cf1fe2547fe8e384f":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"4d9aa91d3fdd25528bac3b2e6115d54fc2f28753":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"91efc148b027dbb57e9dbdf18b654785c1d716f2":["4d9aa91d3fdd25528bac3b2e6115d54fc2f28753"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"17e5da53e4e5bd659e22add9bba1cfa222e7e30d":["6654c5f3ec2e4a84ef867c82d4eec872c2372c8c","6652c74b2358a0b13223817a6a793bf1c9d0749d"],"6652c74b2358a0b13223817a6a793bf1c9d0749d":["6654c5f3ec2e4a84ef867c82d4eec872c2372c8c"],"6bfe104fc023fadc9e709f8d17403d2cc61133fe":["6654c5f3ec2e4a84ef867c82d4eec872c2372c8c"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["6654c5f3ec2e4a84ef867c82d4eec872c2372c8c","17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["fc1e9ddca40a3ddf8b097f2cf1fe2547fe8e384f"],"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c":["91efc148b027dbb57e9dbdf18b654785c1d716f2"]},"commit2Childs":{"34d6426cef006e0c3625cabe7a7ec1c2b08bc501":[],"fc1e9ddca40a3ddf8b097f2cf1fe2547fe8e384f":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"4d9aa91d3fdd25528bac3b2e6115d54fc2f28753":["91efc148b027dbb57e9dbdf18b654785c1d716f2"],"91efc148b027dbb57e9dbdf18b654785c1d716f2":["6654c5f3ec2e4a84ef867c82d4eec872c2372c8c"],"17e5da53e4e5bd659e22add9bba1cfa222e7e30d":["fc1e9ddca40a3ddf8b097f2cf1fe2547fe8e384f","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["4d9aa91d3fdd25528bac3b2e6115d54fc2f28753"],"6652c74b2358a0b13223817a6a793bf1c9d0749d":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"6bfe104fc023fadc9e709f8d17403d2cc61133fe":["34d6426cef006e0c3625cabe7a7ec1c2b08bc501"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d","6652c74b2358a0b13223817a6a793bf1c9d0749d","6bfe104fc023fadc9e709f8d17403d2cc61133fe","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["34d6426cef006e0c3625cabe7a7ec1c2b08bc501","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}