{"path":"src/java/org/apache/solr/highlight/MultiValueTokenStream[SolrHighlighter]#next().mjava","commits":[{"id":"6a67b839dba6c0047c752067352e6a7847fbe8d3","date":1183443247,"type":0,"author":"Ryan McKinley","isMerge":false,"pathNew":"src/java/org/apache/solr/highlight/MultiValueTokenStream[SolrHighlighter]#next().mjava","pathOld":"/dev/null","sourceNew":"  /** Returns the next token in the stream, or null at EOS. */\n  @Override\n  public Token next() throws IOException {\n    int extra = 0;\n    if(currentStream == null) {\n      curIndex++;        \n      if(curIndex < values.length) {\n        currentStream = analyzer.tokenStream(fieldName, \n                                             new StringReader(values[curIndex]));\n        if (orderTokenOffsets) currentStream = new TokenOrderingFilter(currentStream,10);\n        // add extra space between multiple values\n        if(curIndex > 0) \n          extra = analyzer.getPositionIncrementGap(fieldName);\n      } else {\n        return null;\n      }\n    }\n    Token nextToken = currentStream.next();\n    if(nextToken == null) {\n      curOffset += values[curIndex].length();\n      currentStream = null;\n      return next();\n    }\n    // create an modified token which is the offset into the concatenated\n    // string of all values\n    Token offsetToken = new Token(nextToken.termText(), \n                                  nextToken.startOffset() + curOffset,\n                                  nextToken.endOffset() + curOffset);\n    offsetToken.setPositionIncrement(nextToken.getPositionIncrement() + extra*10);\n    return offsetToken;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"303b28b90016c2de1b5870759794476dbf4fd6ce","date":1206052767,"type":5,"author":"Mike Klaas","isMerge":false,"pathNew":"src/java/org/apache/solr/highlight/MultiValueTokenStream[DefaultSolrHighlighter]#next().mjava","pathOld":"src/java/org/apache/solr/highlight/MultiValueTokenStream[SolrHighlighter]#next().mjava","sourceNew":"  /** Returns the next token in the stream, or null at EOS. */\n  @Override\n  public Token next() throws IOException {\n    int extra = 0;\n    if(currentStream == null) {\n      curIndex++;        \n      if(curIndex < values.length) {\n        currentStream = analyzer.tokenStream(fieldName, \n                                             new StringReader(values[curIndex]));\n        if (orderTokenOffsets) currentStream = new TokenOrderingFilter(currentStream,10);\n        // add extra space between multiple values\n        if(curIndex > 0) \n          extra = analyzer.getPositionIncrementGap(fieldName);\n      } else {\n        return null;\n      }\n    }\n    Token nextToken = currentStream.next();\n    if(nextToken == null) {\n      curOffset += values[curIndex].length();\n      currentStream = null;\n      return next();\n    }\n    // create an modified token which is the offset into the concatenated\n    // string of all values\n    Token offsetToken = new Token(nextToken.termText(), \n                                  nextToken.startOffset() + curOffset,\n                                  nextToken.endOffset() + curOffset);\n    offsetToken.setPositionIncrement(nextToken.getPositionIncrement() + extra*10);\n    return offsetToken;\n  }\n\n","sourceOld":"  /** Returns the next token in the stream, or null at EOS. */\n  @Override\n  public Token next() throws IOException {\n    int extra = 0;\n    if(currentStream == null) {\n      curIndex++;        \n      if(curIndex < values.length) {\n        currentStream = analyzer.tokenStream(fieldName, \n                                             new StringReader(values[curIndex]));\n        if (orderTokenOffsets) currentStream = new TokenOrderingFilter(currentStream,10);\n        // add extra space between multiple values\n        if(curIndex > 0) \n          extra = analyzer.getPositionIncrementGap(fieldName);\n      } else {\n        return null;\n      }\n    }\n    Token nextToken = currentStream.next();\n    if(nextToken == null) {\n      curOffset += values[curIndex].length();\n      currentStream = null;\n      return next();\n    }\n    // create an modified token which is the offset into the concatenated\n    // string of all values\n    Token offsetToken = new Token(nextToken.termText(), \n                                  nextToken.startOffset() + curOffset,\n                                  nextToken.endOffset() + curOffset);\n    offsetToken.setPositionIncrement(nextToken.getPositionIncrement() + extra*10);\n    return offsetToken;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":[],"6a67b839dba6c0047c752067352e6a7847fbe8d3":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"303b28b90016c2de1b5870759794476dbf4fd6ce":["6a67b839dba6c0047c752067352e6a7847fbe8d3"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":["6a67b839dba6c0047c752067352e6a7847fbe8d3"],"6a67b839dba6c0047c752067352e6a7847fbe8d3":["303b28b90016c2de1b5870759794476dbf4fd6ce"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"303b28b90016c2de1b5870759794476dbf4fd6ce":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817","303b28b90016c2de1b5870759794476dbf4fd6ce"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"pathCommit":null}