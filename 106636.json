{"path":"lucene/src/java/org/apache/lucene/analysis/Analyzer#tokenStream(String,Reader).mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":2,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/analysis/Analyzer#tokenStream(String,Reader).mjava","pathOld":"backwards/src/java/org/apache/lucene/analysis/Analyzer#tokenStream(String,Reader).mjava","sourceNew":"  /** Creates a TokenStream which tokenizes all the text in the provided\n   * Reader.  Must be able to handle null field name for\n   * backward compatibility.\n   */\n  public abstract TokenStream tokenStream(String fieldName, Reader reader);\n\n","sourceOld":"  /** Creates a TokenStream which tokenizes all the text in the provided\n   * Reader.  Must be able to handle null field name for\n   * backward compatibility.\n   */\n  public abstract TokenStream tokenStream(String fieldName, Reader reader);\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2f49143da0a5d278a72f741432047fcfa6da996e","date":1316927425,"type":3,"author":"Christopher John Male","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/analysis/Analyzer#tokenStream(String,Reader).mjava","pathOld":"lucene/src/java/org/apache/lucene/analysis/Analyzer#tokenStream(String,Reader).mjava","sourceNew":"  /**\n   * Creates a TokenStream which tokenizes all the text in the provided\n   * Reader.\n   * <p>\n   * This method uses {@link #createComponents(String, Reader)} to obtain an\n   * instance of {@link TokenStreamComponents} and returns the sink of the\n   * components. Each calls to this method will create a new instance of\n   * {@link TokenStreamComponents}. Created {@link TokenStream} instances are \n   * never reused.\n   * </p>\n   * \n   * @param fieldName the name of the field the created TokenStream is used for\n   * @param reader the reader the streams source reads from\n   */\n  public final TokenStream tokenStream(final String fieldName,\n      final Reader reader) {\n    return createComponents(fieldName, initReader(reader)).getTokenStream();\n  }\n\n","sourceOld":"  /** Creates a TokenStream which tokenizes all the text in the provided\n   * Reader.  Must be able to handle null field name for\n   * backward compatibility.\n   */\n  public abstract TokenStream tokenStream(String fieldName, Reader reader);\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"69e043c521d4e8db770cc140c63f5ef51f03426a","date":1317187614,"type":3,"author":"Christopher John Male","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/analysis/Analyzer#tokenStream(String,Reader).mjava","pathOld":"lucene/src/java/org/apache/lucene/analysis/Analyzer#tokenStream(String,Reader).mjava","sourceNew":"  /**\n   * Creates a TokenStream that is allowed to be re-use from the previous time\n   * that the same thread called this method.  Callers that do not need to use\n   * more than one TokenStream at the same time from this analyzer should use\n   * this method for better performance.\n   * <p>\n   * This method uses {@link #createComponents(String, Reader)} to obtain an\n   * instance of {@link TokenStreamComponents}. It returns the sink of the\n   * components and stores the components internally. Subsequent calls to this\n   * method will reuse the previously stored components after resetting them\n   * through {@link TokenStreamComponents#reset(Reader)}.\n   * </p>\n   * \n   * @param fieldName the name of the field the created TokenStream is used for\n   * @param reader the reader the streams source reads from\n   */\n  public final TokenStream tokenStream(final String fieldName,\n                                       final Reader reader) throws IOException {\n    TokenStreamComponents components = reuseStrategy.getReusableComponents(fieldName);\n    final Reader r = initReader(reader);\n    if (components == null) {\n      components = createComponents(fieldName, r);\n      reuseStrategy.setReusableComponents(fieldName, components);\n    } else {\n      components.reset(r);\n    }\n    return components.getTokenStream();\n  }\n\n","sourceOld":"  /**\n   * Creates a TokenStream which tokenizes all the text in the provided\n   * Reader.\n   * <p>\n   * This method uses {@link #createComponents(String, Reader)} to obtain an\n   * instance of {@link TokenStreamComponents} and returns the sink of the\n   * components. Each calls to this method will create a new instance of\n   * {@link TokenStreamComponents}. Created {@link TokenStream} instances are \n   * never reused.\n   * </p>\n   * \n   * @param fieldName the name of the field the created TokenStream is used for\n   * @param reader the reader the streams source reads from\n   */\n  public final TokenStream tokenStream(final String fieldName,\n      final Reader reader) {\n    return createComponents(fieldName, initReader(reader)).getTokenStream();\n  }\n\n","bugFix":null,"bugIntro":["56584ae6fa4912e4dd6e818a7da3799cf807234f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/analysis/Analyzer#tokenStream(String,Reader).mjava","pathOld":"lucene/src/java/org/apache/lucene/analysis/Analyzer#tokenStream(String,Reader).mjava","sourceNew":"  /**\n   * Creates a TokenStream that is allowed to be re-use from the previous time\n   * that the same thread called this method.  Callers that do not need to use\n   * more than one TokenStream at the same time from this analyzer should use\n   * this method for better performance.\n   * <p>\n   * This method uses {@link #createComponents(String, Reader)} to obtain an\n   * instance of {@link TokenStreamComponents}. It returns the sink of the\n   * components and stores the components internally. Subsequent calls to this\n   * method will reuse the previously stored components after resetting them\n   * through {@link TokenStreamComponents#reset(Reader)}.\n   * </p>\n   * \n   * @param fieldName the name of the field the created TokenStream is used for\n   * @param reader the reader the streams source reads from\n   */\n  public final TokenStream tokenStream(final String fieldName,\n                                       final Reader reader) throws IOException {\n    TokenStreamComponents components = reuseStrategy.getReusableComponents(fieldName);\n    final Reader r = initReader(reader);\n    if (components == null) {\n      components = createComponents(fieldName, r);\n      reuseStrategy.setReusableComponents(fieldName, components);\n    } else {\n      components.reset(r);\n    }\n    return components.getTokenStream();\n  }\n\n","sourceOld":"  /**\n   * Creates a TokenStream that is allowed to be re-use from the previous time\n   * that the same thread called this method.  Callers that do not need to use\n   * more than one TokenStream at the same time from this analyzer should use\n   * this method for better performance.\n   * <p>\n   * This method uses {@link #createComponents(String, Reader)} to obtain an\n   * instance of {@link TokenStreamComponents}. It returns the sink of the\n   * components and stores the components internally. Subsequent calls to this\n   * method will reuse the previously stored components after resetting them\n   * through {@link TokenStreamComponents#reset(Reader)}.\n   * </p>\n   * \n   * @param fieldName the name of the field the created TokenStream is used for\n   * @param reader the reader the streams source reads from\n   */\n  public final TokenStream tokenStream(final String fieldName,\n                                       final Reader reader) throws IOException {\n    TokenStreamComponents components = reuseStrategy.getReusableComponents(fieldName);\n    final Reader r = initReader(reader);\n    if (components == null) {\n      components = createComponents(fieldName, r);\n      reuseStrategy.setReusableComponents(fieldName, components);\n    } else {\n      components.reset(r);\n    }\n    return components.getTokenStream();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["69e043c521d4e8db770cc140c63f5ef51f03426a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"2f49143da0a5d278a72f741432047fcfa6da996e":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"69e043c521d4e8db770cc140c63f5ef51f03426a":["2f49143da0a5d278a72f741432047fcfa6da996e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"2f49143da0a5d278a72f741432047fcfa6da996e":["69e043c521d4e8db770cc140c63f5ef51f03426a"],"69e043c521d4e8db770cc140c63f5ef51f03426a":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["2f49143da0a5d278a72f741432047fcfa6da996e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}