{"path":"lucene/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/DocMaker#setConfig(Config).mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/DocMaker#setConfig(Config).mjava","pathOld":"contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/DocMaker#setConfig(Config).mjava","sourceNew":"  /** Set the configuration parameters of this doc maker. */\n  public void setConfig(Config config) {\n    this.config = config;\n    try {\n      String sourceClass = config.get(\"content.source\", \"org.apache.lucene.benchmark.byTask.feeds.SingleDocSource\");\n      source = Class.forName(sourceClass).asSubclass(ContentSource.class).newInstance();\n      source.setConfig(config);\n    } catch (Exception e) {\n      // Should not get here. Throw runtime exception.\n      throw new RuntimeException(e);\n    }\n\n    boolean stored = config.get(\"doc.stored\", false);\n    boolean bodyStored = config.get(\"doc.body.stored\", stored);\n    boolean tokenized = config.get(\"doc.tokenized\", true);\n    boolean bodyTokenized = config.get(\"doc.body.tokenized\", tokenized);\n    boolean norms = config.get(\"doc.tokenized.norms\", false);\n    boolean bodyNorms = config.get(\"doc.body.tokenized.norms\", true);\n    boolean termVec = config.get(\"doc.term.vector\", false);\n    storeVal = (stored ? Field.Store.YES : Field.Store.NO);\n    bodyStoreVal = (bodyStored ? Field.Store.YES : Field.Store.NO);\n    if (tokenized) {\n      indexVal = norms ? Index.ANALYZED : Index.ANALYZED_NO_NORMS;\n    } else {\n      indexVal = norms ? Index.NOT_ANALYZED : Index.NOT_ANALYZED_NO_NORMS;\n    }\n\n    if (bodyTokenized) {\n      bodyIndexVal = bodyNorms ? Index.ANALYZED : Index.ANALYZED_NO_NORMS;\n    } else {\n      bodyIndexVal = bodyNorms ? Index.NOT_ANALYZED : Index.NOT_ANALYZED_NO_NORMS;\n    }\n\n    boolean termVecPositions = config.get(\"doc.term.vector.positions\", false);\n    boolean termVecOffsets = config.get(\"doc.term.vector.offsets\", false);\n    if (termVecPositions && termVecOffsets) {\n      termVecVal = TermVector.WITH_POSITIONS_OFFSETS;\n    } else if (termVecPositions) {\n      termVecVal = TermVector.WITH_POSITIONS;\n    } else if (termVecOffsets) {\n      termVecVal = TermVector.WITH_OFFSETS;\n    } else if (termVec) {\n      termVecVal = TermVector.YES;\n    } else {\n      termVecVal = TermVector.NO;\n    }\n    storeBytes = config.get(\"doc.store.body.bytes\", false);\n    \n    reuseFields = config.get(\"doc.reuse.fields\", true);\n\n    // In a multi-rounds run, it is important to reset DocState since settings\n    // of fields may change between rounds, and this is the only way to reset\n    // the cache of all threads.\n    docState = new ThreadLocal<DocState>();\n    \n    indexProperties = config.get(\"doc.index.props\", false);\n\n    updateDocIDLimit = config.get(\"doc.random.id.limit\", -1);\n    if (updateDocIDLimit != -1) {\n      r = new Random(179);\n    }\n  }\n\n","sourceOld":"  /** Set the configuration parameters of this doc maker. */\n  public void setConfig(Config config) {\n    this.config = config;\n    try {\n      String sourceClass = config.get(\"content.source\", \"org.apache.lucene.benchmark.byTask.feeds.SingleDocSource\");\n      source = Class.forName(sourceClass).asSubclass(ContentSource.class).newInstance();\n      source.setConfig(config);\n    } catch (Exception e) {\n      // Should not get here. Throw runtime exception.\n      throw new RuntimeException(e);\n    }\n\n    boolean stored = config.get(\"doc.stored\", false);\n    boolean bodyStored = config.get(\"doc.body.stored\", stored);\n    boolean tokenized = config.get(\"doc.tokenized\", true);\n    boolean bodyTokenized = config.get(\"doc.body.tokenized\", tokenized);\n    boolean norms = config.get(\"doc.tokenized.norms\", false);\n    boolean bodyNorms = config.get(\"doc.body.tokenized.norms\", true);\n    boolean termVec = config.get(\"doc.term.vector\", false);\n    storeVal = (stored ? Field.Store.YES : Field.Store.NO);\n    bodyStoreVal = (bodyStored ? Field.Store.YES : Field.Store.NO);\n    if (tokenized) {\n      indexVal = norms ? Index.ANALYZED : Index.ANALYZED_NO_NORMS;\n    } else {\n      indexVal = norms ? Index.NOT_ANALYZED : Index.NOT_ANALYZED_NO_NORMS;\n    }\n\n    if (bodyTokenized) {\n      bodyIndexVal = bodyNorms ? Index.ANALYZED : Index.ANALYZED_NO_NORMS;\n    } else {\n      bodyIndexVal = bodyNorms ? Index.NOT_ANALYZED : Index.NOT_ANALYZED_NO_NORMS;\n    }\n\n    boolean termVecPositions = config.get(\"doc.term.vector.positions\", false);\n    boolean termVecOffsets = config.get(\"doc.term.vector.offsets\", false);\n    if (termVecPositions && termVecOffsets) {\n      termVecVal = TermVector.WITH_POSITIONS_OFFSETS;\n    } else if (termVecPositions) {\n      termVecVal = TermVector.WITH_POSITIONS;\n    } else if (termVecOffsets) {\n      termVecVal = TermVector.WITH_OFFSETS;\n    } else if (termVec) {\n      termVecVal = TermVector.YES;\n    } else {\n      termVecVal = TermVector.NO;\n    }\n    storeBytes = config.get(\"doc.store.body.bytes\", false);\n    \n    reuseFields = config.get(\"doc.reuse.fields\", true);\n\n    // In a multi-rounds run, it is important to reset DocState since settings\n    // of fields may change between rounds, and this is the only way to reset\n    // the cache of all threads.\n    docState = new ThreadLocal<DocState>();\n    \n    indexProperties = config.get(\"doc.index.props\", false);\n\n    updateDocIDLimit = config.get(\"doc.random.id.limit\", -1);\n    if (updateDocIDLimit != -1) {\n      r = new Random(179);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"01f60198ece724a6e96cd0b45f289cf42ff83d4f","date":1286864103,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/DocMaker#setConfig(Config).mjava","pathOld":"lucene/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/DocMaker#setConfig(Config).mjava","sourceNew":"  /** Set the configuration parameters of this doc maker. */\n  public void setConfig(Config config) {\n    this.config = config;\n    try {\n      String sourceClass = config.get(\"content.source\", \"org.apache.lucene.benchmark.byTask.feeds.SingleDocSource\");\n      source = Class.forName(sourceClass).asSubclass(ContentSource.class).newInstance();\n      source.setConfig(config);\n    } catch (Exception e) {\n      // Should not get here. Throw runtime exception.\n      throw new RuntimeException(e);\n    }\n\n    boolean stored = config.get(\"doc.stored\", false);\n    boolean bodyStored = config.get(\"doc.body.stored\", stored);\n    boolean tokenized = config.get(\"doc.tokenized\", true);\n    boolean bodyTokenized = config.get(\"doc.body.tokenized\", tokenized);\n    boolean norms = config.get(\"doc.tokenized.norms\", false);\n    boolean bodyNorms = config.get(\"doc.body.tokenized.norms\", true);\n    boolean termVec = config.get(\"doc.term.vector\", false);\n    fieldVauleMap = parseValueFields(config.get(\"doc.stored.values\", null));\n    storeVal = (stored ? Field.Store.YES : Field.Store.NO);\n    bodyStoreVal = (bodyStored ? Field.Store.YES : Field.Store.NO);\n    if (tokenized) {\n      indexVal = norms ? Index.ANALYZED : Index.ANALYZED_NO_NORMS;\n    } else {\n      indexVal = norms ? Index.NOT_ANALYZED : Index.NOT_ANALYZED_NO_NORMS;\n    }\n\n    if (bodyTokenized) {\n      bodyIndexVal = bodyNorms ? Index.ANALYZED : Index.ANALYZED_NO_NORMS;\n    } else {\n      bodyIndexVal = bodyNorms ? Index.NOT_ANALYZED : Index.NOT_ANALYZED_NO_NORMS;\n    }\n\n    boolean termVecPositions = config.get(\"doc.term.vector.positions\", false);\n    boolean termVecOffsets = config.get(\"doc.term.vector.offsets\", false);\n    if (termVecPositions && termVecOffsets) {\n      termVecVal = TermVector.WITH_POSITIONS_OFFSETS;\n    } else if (termVecPositions) {\n      termVecVal = TermVector.WITH_POSITIONS;\n    } else if (termVecOffsets) {\n      termVecVal = TermVector.WITH_OFFSETS;\n    } else if (termVec) {\n      termVecVal = TermVector.YES;\n    } else {\n      termVecVal = TermVector.NO;\n    }\n    storeBytes = config.get(\"doc.store.body.bytes\", false);\n    \n    reuseFields = config.get(\"doc.reuse.fields\", true);\n\n    // In a multi-rounds run, it is important to reset DocState since settings\n    // of fields may change between rounds, and this is the only way to reset\n    // the cache of all threads.\n    docState = new ThreadLocal<DocState>();\n    \n    indexProperties = config.get(\"doc.index.props\", false);\n    updateDocIDLimit = config.get(\"doc.random.id.limit\", -1);\n    if (updateDocIDLimit != -1) {\n      r = new Random(179);\n    }\n  }\n\n","sourceOld":"  /** Set the configuration parameters of this doc maker. */\n  public void setConfig(Config config) {\n    this.config = config;\n    try {\n      String sourceClass = config.get(\"content.source\", \"org.apache.lucene.benchmark.byTask.feeds.SingleDocSource\");\n      source = Class.forName(sourceClass).asSubclass(ContentSource.class).newInstance();\n      source.setConfig(config);\n    } catch (Exception e) {\n      // Should not get here. Throw runtime exception.\n      throw new RuntimeException(e);\n    }\n\n    boolean stored = config.get(\"doc.stored\", false);\n    boolean bodyStored = config.get(\"doc.body.stored\", stored);\n    boolean tokenized = config.get(\"doc.tokenized\", true);\n    boolean bodyTokenized = config.get(\"doc.body.tokenized\", tokenized);\n    boolean norms = config.get(\"doc.tokenized.norms\", false);\n    boolean bodyNorms = config.get(\"doc.body.tokenized.norms\", true);\n    boolean termVec = config.get(\"doc.term.vector\", false);\n    storeVal = (stored ? Field.Store.YES : Field.Store.NO);\n    bodyStoreVal = (bodyStored ? Field.Store.YES : Field.Store.NO);\n    if (tokenized) {\n      indexVal = norms ? Index.ANALYZED : Index.ANALYZED_NO_NORMS;\n    } else {\n      indexVal = norms ? Index.NOT_ANALYZED : Index.NOT_ANALYZED_NO_NORMS;\n    }\n\n    if (bodyTokenized) {\n      bodyIndexVal = bodyNorms ? Index.ANALYZED : Index.ANALYZED_NO_NORMS;\n    } else {\n      bodyIndexVal = bodyNorms ? Index.NOT_ANALYZED : Index.NOT_ANALYZED_NO_NORMS;\n    }\n\n    boolean termVecPositions = config.get(\"doc.term.vector.positions\", false);\n    boolean termVecOffsets = config.get(\"doc.term.vector.offsets\", false);\n    if (termVecPositions && termVecOffsets) {\n      termVecVal = TermVector.WITH_POSITIONS_OFFSETS;\n    } else if (termVecPositions) {\n      termVecVal = TermVector.WITH_POSITIONS;\n    } else if (termVecOffsets) {\n      termVecVal = TermVector.WITH_OFFSETS;\n    } else if (termVec) {\n      termVecVal = TermVector.YES;\n    } else {\n      termVecVal = TermVector.NO;\n    }\n    storeBytes = config.get(\"doc.store.body.bytes\", false);\n    \n    reuseFields = config.get(\"doc.reuse.fields\", true);\n\n    // In a multi-rounds run, it is important to reset DocState since settings\n    // of fields may change between rounds, and this is the only way to reset\n    // the cache of all threads.\n    docState = new ThreadLocal<DocState>();\n    \n    indexProperties = config.get(\"doc.index.props\", false);\n\n    updateDocIDLimit = config.get(\"doc.random.id.limit\", -1);\n    if (updateDocIDLimit != -1) {\n      r = new Random(179);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ecc11368dc265bfdad90214f8bf5da99016ab1e2","date":1294144090,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"modules/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/DocMaker#setConfig(Config).mjava","pathOld":"lucene/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/DocMaker#setConfig(Config).mjava","sourceNew":"  /** Set the configuration parameters of this doc maker. */\n  public void setConfig(Config config) {\n    this.config = config;\n    try {\n      String sourceClass = config.get(\"content.source\", \"org.apache.lucene.benchmark.byTask.feeds.SingleDocSource\");\n      source = Class.forName(sourceClass).asSubclass(ContentSource.class).newInstance();\n      source.setConfig(config);\n    } catch (Exception e) {\n      // Should not get here. Throw runtime exception.\n      throw new RuntimeException(e);\n    }\n\n    boolean stored = config.get(\"doc.stored\", false);\n    boolean bodyStored = config.get(\"doc.body.stored\", stored);\n    boolean tokenized = config.get(\"doc.tokenized\", true);\n    boolean bodyTokenized = config.get(\"doc.body.tokenized\", tokenized);\n    boolean norms = config.get(\"doc.tokenized.norms\", false);\n    boolean bodyNorms = config.get(\"doc.body.tokenized.norms\", true);\n    boolean termVec = config.get(\"doc.term.vector\", false);\n    storeVal = (stored ? Field.Store.YES : Field.Store.NO);\n    bodyStoreVal = (bodyStored ? Field.Store.YES : Field.Store.NO);\n    if (tokenized) {\n      indexVal = norms ? Index.ANALYZED : Index.ANALYZED_NO_NORMS;\n    } else {\n      indexVal = norms ? Index.NOT_ANALYZED : Index.NOT_ANALYZED_NO_NORMS;\n    }\n\n    if (bodyTokenized) {\n      bodyIndexVal = bodyNorms ? Index.ANALYZED : Index.ANALYZED_NO_NORMS;\n    } else {\n      bodyIndexVal = bodyNorms ? Index.NOT_ANALYZED : Index.NOT_ANALYZED_NO_NORMS;\n    }\n\n    boolean termVecPositions = config.get(\"doc.term.vector.positions\", false);\n    boolean termVecOffsets = config.get(\"doc.term.vector.offsets\", false);\n    if (termVecPositions && termVecOffsets) {\n      termVecVal = TermVector.WITH_POSITIONS_OFFSETS;\n    } else if (termVecPositions) {\n      termVecVal = TermVector.WITH_POSITIONS;\n    } else if (termVecOffsets) {\n      termVecVal = TermVector.WITH_OFFSETS;\n    } else if (termVec) {\n      termVecVal = TermVector.YES;\n    } else {\n      termVecVal = TermVector.NO;\n    }\n    storeBytes = config.get(\"doc.store.body.bytes\", false);\n    \n    reuseFields = config.get(\"doc.reuse.fields\", true);\n\n    // In a multi-rounds run, it is important to reset DocState since settings\n    // of fields may change between rounds, and this is the only way to reset\n    // the cache of all threads.\n    docState = new ThreadLocal<DocState>();\n    \n    indexProperties = config.get(\"doc.index.props\", false);\n\n    updateDocIDLimit = config.get(\"doc.random.id.limit\", -1);\n    if (updateDocIDLimit != -1) {\n      r = new Random(179);\n    }\n  }\n\n","sourceOld":"  /** Set the configuration parameters of this doc maker. */\n  public void setConfig(Config config) {\n    this.config = config;\n    try {\n      String sourceClass = config.get(\"content.source\", \"org.apache.lucene.benchmark.byTask.feeds.SingleDocSource\");\n      source = Class.forName(sourceClass).asSubclass(ContentSource.class).newInstance();\n      source.setConfig(config);\n    } catch (Exception e) {\n      // Should not get here. Throw runtime exception.\n      throw new RuntimeException(e);\n    }\n\n    boolean stored = config.get(\"doc.stored\", false);\n    boolean bodyStored = config.get(\"doc.body.stored\", stored);\n    boolean tokenized = config.get(\"doc.tokenized\", true);\n    boolean bodyTokenized = config.get(\"doc.body.tokenized\", tokenized);\n    boolean norms = config.get(\"doc.tokenized.norms\", false);\n    boolean bodyNorms = config.get(\"doc.body.tokenized.norms\", true);\n    boolean termVec = config.get(\"doc.term.vector\", false);\n    storeVal = (stored ? Field.Store.YES : Field.Store.NO);\n    bodyStoreVal = (bodyStored ? Field.Store.YES : Field.Store.NO);\n    if (tokenized) {\n      indexVal = norms ? Index.ANALYZED : Index.ANALYZED_NO_NORMS;\n    } else {\n      indexVal = norms ? Index.NOT_ANALYZED : Index.NOT_ANALYZED_NO_NORMS;\n    }\n\n    if (bodyTokenized) {\n      bodyIndexVal = bodyNorms ? Index.ANALYZED : Index.ANALYZED_NO_NORMS;\n    } else {\n      bodyIndexVal = bodyNorms ? Index.NOT_ANALYZED : Index.NOT_ANALYZED_NO_NORMS;\n    }\n\n    boolean termVecPositions = config.get(\"doc.term.vector.positions\", false);\n    boolean termVecOffsets = config.get(\"doc.term.vector.offsets\", false);\n    if (termVecPositions && termVecOffsets) {\n      termVecVal = TermVector.WITH_POSITIONS_OFFSETS;\n    } else if (termVecPositions) {\n      termVecVal = TermVector.WITH_POSITIONS;\n    } else if (termVecOffsets) {\n      termVecVal = TermVector.WITH_OFFSETS;\n    } else if (termVec) {\n      termVecVal = TermVector.YES;\n    } else {\n      termVecVal = TermVector.NO;\n    }\n    storeBytes = config.get(\"doc.store.body.bytes\", false);\n    \n    reuseFields = config.get(\"doc.reuse.fields\", true);\n\n    // In a multi-rounds run, it is important to reset DocState since settings\n    // of fields may change between rounds, and this is the only way to reset\n    // the cache of all threads.\n    docState = new ThreadLocal<DocState>();\n    \n    indexProperties = config.get(\"doc.index.props\", false);\n\n    updateDocIDLimit = config.get(\"doc.random.id.limit\", -1);\n    if (updateDocIDLimit != -1) {\n      r = new Random(179);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"70ad682703b8585f5d0a637efec044d57ec05efb","date":1294259117,"type":4,"author":"Simon Willnauer","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/DocMaker#setConfig(Config).mjava","sourceNew":null,"sourceOld":"  /** Set the configuration parameters of this doc maker. */\n  public void setConfig(Config config) {\n    this.config = config;\n    try {\n      String sourceClass = config.get(\"content.source\", \"org.apache.lucene.benchmark.byTask.feeds.SingleDocSource\");\n      source = Class.forName(sourceClass).asSubclass(ContentSource.class).newInstance();\n      source.setConfig(config);\n    } catch (Exception e) {\n      // Should not get here. Throw runtime exception.\n      throw new RuntimeException(e);\n    }\n\n    boolean stored = config.get(\"doc.stored\", false);\n    boolean bodyStored = config.get(\"doc.body.stored\", stored);\n    boolean tokenized = config.get(\"doc.tokenized\", true);\n    boolean bodyTokenized = config.get(\"doc.body.tokenized\", tokenized);\n    boolean norms = config.get(\"doc.tokenized.norms\", false);\n    boolean bodyNorms = config.get(\"doc.body.tokenized.norms\", true);\n    boolean termVec = config.get(\"doc.term.vector\", false);\n    fieldVauleMap = parseValueFields(config.get(\"doc.stored.values\", null));\n    storeVal = (stored ? Field.Store.YES : Field.Store.NO);\n    bodyStoreVal = (bodyStored ? Field.Store.YES : Field.Store.NO);\n    if (tokenized) {\n      indexVal = norms ? Index.ANALYZED : Index.ANALYZED_NO_NORMS;\n    } else {\n      indexVal = norms ? Index.NOT_ANALYZED : Index.NOT_ANALYZED_NO_NORMS;\n    }\n\n    if (bodyTokenized) {\n      bodyIndexVal = bodyNorms ? Index.ANALYZED : Index.ANALYZED_NO_NORMS;\n    } else {\n      bodyIndexVal = bodyNorms ? Index.NOT_ANALYZED : Index.NOT_ANALYZED_NO_NORMS;\n    }\n\n    boolean termVecPositions = config.get(\"doc.term.vector.positions\", false);\n    boolean termVecOffsets = config.get(\"doc.term.vector.offsets\", false);\n    if (termVecPositions && termVecOffsets) {\n      termVecVal = TermVector.WITH_POSITIONS_OFFSETS;\n    } else if (termVecPositions) {\n      termVecVal = TermVector.WITH_POSITIONS;\n    } else if (termVecOffsets) {\n      termVecVal = TermVector.WITH_OFFSETS;\n    } else if (termVec) {\n      termVecVal = TermVector.YES;\n    } else {\n      termVecVal = TermVector.NO;\n    }\n    storeBytes = config.get(\"doc.store.body.bytes\", false);\n    \n    reuseFields = config.get(\"doc.reuse.fields\", true);\n\n    // In a multi-rounds run, it is important to reset DocState since settings\n    // of fields may change between rounds, and this is the only way to reset\n    // the cache of all threads.\n    docState = new ThreadLocal<DocState>();\n    \n    indexProperties = config.get(\"doc.index.props\", false);\n    updateDocIDLimit = config.get(\"doc.random.id.limit\", -1);\n    if (updateDocIDLimit != -1) {\n      r = new Random(179);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"868da859b43505d9d2a023bfeae6dd0c795f5295","date":1294948401,"type":5,"author":"Michael Busch","isMerge":true,"pathNew":"modules/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/DocMaker#setConfig(Config).mjava","pathOld":"lucene/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/DocMaker#setConfig(Config).mjava","sourceNew":"  /** Set the configuration parameters of this doc maker. */\n  public void setConfig(Config config) {\n    this.config = config;\n    try {\n      String sourceClass = config.get(\"content.source\", \"org.apache.lucene.benchmark.byTask.feeds.SingleDocSource\");\n      source = Class.forName(sourceClass).asSubclass(ContentSource.class).newInstance();\n      source.setConfig(config);\n    } catch (Exception e) {\n      // Should not get here. Throw runtime exception.\n      throw new RuntimeException(e);\n    }\n\n    boolean stored = config.get(\"doc.stored\", false);\n    boolean bodyStored = config.get(\"doc.body.stored\", stored);\n    boolean tokenized = config.get(\"doc.tokenized\", true);\n    boolean bodyTokenized = config.get(\"doc.body.tokenized\", tokenized);\n    boolean norms = config.get(\"doc.tokenized.norms\", false);\n    boolean bodyNorms = config.get(\"doc.body.tokenized.norms\", true);\n    boolean termVec = config.get(\"doc.term.vector\", false);\n    storeVal = (stored ? Field.Store.YES : Field.Store.NO);\n    bodyStoreVal = (bodyStored ? Field.Store.YES : Field.Store.NO);\n    if (tokenized) {\n      indexVal = norms ? Index.ANALYZED : Index.ANALYZED_NO_NORMS;\n    } else {\n      indexVal = norms ? Index.NOT_ANALYZED : Index.NOT_ANALYZED_NO_NORMS;\n    }\n\n    if (bodyTokenized) {\n      bodyIndexVal = bodyNorms ? Index.ANALYZED : Index.ANALYZED_NO_NORMS;\n    } else {\n      bodyIndexVal = bodyNorms ? Index.NOT_ANALYZED : Index.NOT_ANALYZED_NO_NORMS;\n    }\n\n    boolean termVecPositions = config.get(\"doc.term.vector.positions\", false);\n    boolean termVecOffsets = config.get(\"doc.term.vector.offsets\", false);\n    if (termVecPositions && termVecOffsets) {\n      termVecVal = TermVector.WITH_POSITIONS_OFFSETS;\n    } else if (termVecPositions) {\n      termVecVal = TermVector.WITH_POSITIONS;\n    } else if (termVecOffsets) {\n      termVecVal = TermVector.WITH_OFFSETS;\n    } else if (termVec) {\n      termVecVal = TermVector.YES;\n    } else {\n      termVecVal = TermVector.NO;\n    }\n    storeBytes = config.get(\"doc.store.body.bytes\", false);\n    \n    reuseFields = config.get(\"doc.reuse.fields\", true);\n\n    // In a multi-rounds run, it is important to reset DocState since settings\n    // of fields may change between rounds, and this is the only way to reset\n    // the cache of all threads.\n    docState = new ThreadLocal<DocState>();\n    \n    indexProperties = config.get(\"doc.index.props\", false);\n\n    updateDocIDLimit = config.get(\"doc.random.id.limit\", -1);\n    if (updateDocIDLimit != -1) {\n      r = new Random(179);\n    }\n  }\n\n","sourceOld":"  /** Set the configuration parameters of this doc maker. */\n  public void setConfig(Config config) {\n    this.config = config;\n    try {\n      String sourceClass = config.get(\"content.source\", \"org.apache.lucene.benchmark.byTask.feeds.SingleDocSource\");\n      source = Class.forName(sourceClass).asSubclass(ContentSource.class).newInstance();\n      source.setConfig(config);\n    } catch (Exception e) {\n      // Should not get here. Throw runtime exception.\n      throw new RuntimeException(e);\n    }\n\n    boolean stored = config.get(\"doc.stored\", false);\n    boolean bodyStored = config.get(\"doc.body.stored\", stored);\n    boolean tokenized = config.get(\"doc.tokenized\", true);\n    boolean bodyTokenized = config.get(\"doc.body.tokenized\", tokenized);\n    boolean norms = config.get(\"doc.tokenized.norms\", false);\n    boolean bodyNorms = config.get(\"doc.body.tokenized.norms\", true);\n    boolean termVec = config.get(\"doc.term.vector\", false);\n    storeVal = (stored ? Field.Store.YES : Field.Store.NO);\n    bodyStoreVal = (bodyStored ? Field.Store.YES : Field.Store.NO);\n    if (tokenized) {\n      indexVal = norms ? Index.ANALYZED : Index.ANALYZED_NO_NORMS;\n    } else {\n      indexVal = norms ? Index.NOT_ANALYZED : Index.NOT_ANALYZED_NO_NORMS;\n    }\n\n    if (bodyTokenized) {\n      bodyIndexVal = bodyNorms ? Index.ANALYZED : Index.ANALYZED_NO_NORMS;\n    } else {\n      bodyIndexVal = bodyNorms ? Index.NOT_ANALYZED : Index.NOT_ANALYZED_NO_NORMS;\n    }\n\n    boolean termVecPositions = config.get(\"doc.term.vector.positions\", false);\n    boolean termVecOffsets = config.get(\"doc.term.vector.offsets\", false);\n    if (termVecPositions && termVecOffsets) {\n      termVecVal = TermVector.WITH_POSITIONS_OFFSETS;\n    } else if (termVecPositions) {\n      termVecVal = TermVector.WITH_POSITIONS;\n    } else if (termVecOffsets) {\n      termVecVal = TermVector.WITH_OFFSETS;\n    } else if (termVec) {\n      termVecVal = TermVector.YES;\n    } else {\n      termVecVal = TermVector.NO;\n    }\n    storeBytes = config.get(\"doc.store.body.bytes\", false);\n    \n    reuseFields = config.get(\"doc.reuse.fields\", true);\n\n    // In a multi-rounds run, it is important to reset DocState since settings\n    // of fields may change between rounds, and this is the only way to reset\n    // the cache of all threads.\n    docState = new ThreadLocal<DocState>();\n    \n    indexProperties = config.get(\"doc.index.props\", false);\n\n    updateDocIDLimit = config.get(\"doc.random.id.limit\", -1);\n    if (updateDocIDLimit != -1) {\n      r = new Random(179);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"70ad682703b8585f5d0a637efec044d57ec05efb":["01f60198ece724a6e96cd0b45f289cf42ff83d4f","ecc11368dc265bfdad90214f8bf5da99016ab1e2"],"ecc11368dc265bfdad90214f8bf5da99016ab1e2":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"868da859b43505d9d2a023bfeae6dd0c795f5295":["9454a6510e2db155fb01faa5c049b06ece95fab9","ecc11368dc265bfdad90214f8bf5da99016ab1e2"],"01f60198ece724a6e96cd0b45f289cf42ff83d4f":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["ecc11368dc265bfdad90214f8bf5da99016ab1e2"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"70ad682703b8585f5d0a637efec044d57ec05efb":[],"ecc11368dc265bfdad90214f8bf5da99016ab1e2":["70ad682703b8585f5d0a637efec044d57ec05efb","868da859b43505d9d2a023bfeae6dd0c795f5295","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"01f60198ece724a6e96cd0b45f289cf42ff83d4f":["70ad682703b8585f5d0a637efec044d57ec05efb"],"868da859b43505d9d2a023bfeae6dd0c795f5295":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["ecc11368dc265bfdad90214f8bf5da99016ab1e2","868da859b43505d9d2a023bfeae6dd0c795f5295","01f60198ece724a6e96cd0b45f289cf42ff83d4f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["70ad682703b8585f5d0a637efec044d57ec05efb","868da859b43505d9d2a023bfeae6dd0c795f5295","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}