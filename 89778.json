{"path":"modules/facet/src/java/org/apache/lucene/facet/util/RandomSample#sample2(ScoredDocIDs,int,int[],long[]).mjava","commits":[{"id":"89f15687f60bd49cd3d9de427e85c17fd9397d61","date":1309381327,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"modules/facet/src/java/org/apache/lucene/facet/util/RandomSample#sample2(ScoredDocIDs,int,int[],long[]).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Returns <code>sample</code>.length values chosen from the first <code>collectionSize</code>\n   * locations of <code>collection</code>, using the HASHING algorithm. Performance measurements\n   * are returned in <code>times</code>, which must be an array of at least three longs. The first\n   * will be set when the algorithm starts; the second, when a hash key has been calculated and\n   * inserted into the priority queue for every element in the collection; and the third when the\n   * original elements associated with the keys remaining in the PQ have been stored in the sample\n   * array for return.\n   * <P>\n   * This algorithm slows as the sample size becomes a significant fraction of the collection\n   * size, because the PQ is as large as the sample set, and will not do early rejection of values\n   * below the minimum until it fills up, and a larger PQ contains more small values to be purged,\n   * resulting in less early rejection and more logN insertions.\n   * \n   * @param collection The set to be sampled.\n   * @param collectionSize The number of values to use (starting from first).\n   * @param sample The array in which to return the sample.\n   * @param times The times of three events, for measuring performance.\n   */\n  private static void sample2(ScoredDocIDs collection, int collectionSize, int[] sample, long[] times) \n  throws IOException {\n    if (RandomSample.returnTimings) {\n      times[0] = System.currentTimeMillis();\n    }\n    int sampleSize = sample.length;\n    IntPriorityQueue pq = new IntPriorityQueue(sampleSize);\n    /*\n     * Convert every value in the collection to a hashed \"weight\" value, and insert\n     * into a bounded PQ (retains only sampleSize highest weights).\n     */\n    ScoredDocIDsIterator it = collection.iterator();\n    while (it.next()) {\n      pq.insertWithReuse((int)(it.getDocID() * PHI_32) & 0x7FFFFFFF);\n    }\n    if (RandomSample.returnTimings) {\n      times[1] = System.currentTimeMillis();\n    }\n    /*\n     * Extract heap, convert weights back to original values, and return as integers.\n     */\n    Object[] heap = pq.getHeap();\n    for (int si = 0; si < sampleSize; si++) {\n      sample[si] = (int)(((IntPriorityQueue.MI)(heap[si+1])).value * PHI_32I) & 0x7FFFFFFF;\n    }\n    if (RandomSample.returnTimings) {\n      times[2] = System.currentTimeMillis();\n    }\n  } // end RandomSample.sample2()\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"817d8435e9135b756f08ce6710ab0baac51bdf88","date":1309986993,"type":0,"author":"Steven Rowe","isMerge":true,"pathNew":"modules/facet/src/java/org/apache/lucene/facet/util/RandomSample#sample2(ScoredDocIDs,int,int[],long[]).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Returns <code>sample</code>.length values chosen from the first <code>collectionSize</code>\n   * locations of <code>collection</code>, using the HASHING algorithm. Performance measurements\n   * are returned in <code>times</code>, which must be an array of at least three longs. The first\n   * will be set when the algorithm starts; the second, when a hash key has been calculated and\n   * inserted into the priority queue for every element in the collection; and the third when the\n   * original elements associated with the keys remaining in the PQ have been stored in the sample\n   * array for return.\n   * <P>\n   * This algorithm slows as the sample size becomes a significant fraction of the collection\n   * size, because the PQ is as large as the sample set, and will not do early rejection of values\n   * below the minimum until it fills up, and a larger PQ contains more small values to be purged,\n   * resulting in less early rejection and more logN insertions.\n   * \n   * @param collection The set to be sampled.\n   * @param collectionSize The number of values to use (starting from first).\n   * @param sample The array in which to return the sample.\n   * @param times The times of three events, for measuring performance.\n   */\n  private static void sample2(ScoredDocIDs collection, int collectionSize, int[] sample, long[] times) \n  throws IOException {\n    if (RandomSample.returnTimings) {\n      times[0] = System.currentTimeMillis();\n    }\n    int sampleSize = sample.length;\n    IntPriorityQueue pq = new IntPriorityQueue(sampleSize);\n    /*\n     * Convert every value in the collection to a hashed \"weight\" value, and insert\n     * into a bounded PQ (retains only sampleSize highest weights).\n     */\n    ScoredDocIDsIterator it = collection.iterator();\n    while (it.next()) {\n      pq.insertWithReuse((int)(it.getDocID() * PHI_32) & 0x7FFFFFFF);\n    }\n    if (RandomSample.returnTimings) {\n      times[1] = System.currentTimeMillis();\n    }\n    /*\n     * Extract heap, convert weights back to original values, and return as integers.\n     */\n    Object[] heap = pq.getHeap();\n    for (int si = 0; si < sampleSize; si++) {\n      sample[si] = (int)(((IntPriorityQueue.MI)(heap[si+1])).value * PHI_32I) & 0x7FFFFFFF;\n    }\n    if (RandomSample.returnTimings) {\n      times[2] = System.currentTimeMillis();\n    }\n  } // end RandomSample.sample2()\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d083e83f225b11e5fdd900e83d26ddb385b6955c","date":1310029438,"type":0,"author":"Simon Willnauer","isMerge":true,"pathNew":"modules/facet/src/java/org/apache/lucene/facet/util/RandomSample#sample2(ScoredDocIDs,int,int[],long[]).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Returns <code>sample</code>.length values chosen from the first <code>collectionSize</code>\n   * locations of <code>collection</code>, using the HASHING algorithm. Performance measurements\n   * are returned in <code>times</code>, which must be an array of at least three longs. The first\n   * will be set when the algorithm starts; the second, when a hash key has been calculated and\n   * inserted into the priority queue for every element in the collection; and the third when the\n   * original elements associated with the keys remaining in the PQ have been stored in the sample\n   * array for return.\n   * <P>\n   * This algorithm slows as the sample size becomes a significant fraction of the collection\n   * size, because the PQ is as large as the sample set, and will not do early rejection of values\n   * below the minimum until it fills up, and a larger PQ contains more small values to be purged,\n   * resulting in less early rejection and more logN insertions.\n   * \n   * @param collection The set to be sampled.\n   * @param collectionSize The number of values to use (starting from first).\n   * @param sample The array in which to return the sample.\n   * @param times The times of three events, for measuring performance.\n   */\n  private static void sample2(ScoredDocIDs collection, int collectionSize, int[] sample, long[] times) \n  throws IOException {\n    if (RandomSample.returnTimings) {\n      times[0] = System.currentTimeMillis();\n    }\n    int sampleSize = sample.length;\n    IntPriorityQueue pq = new IntPriorityQueue(sampleSize);\n    /*\n     * Convert every value in the collection to a hashed \"weight\" value, and insert\n     * into a bounded PQ (retains only sampleSize highest weights).\n     */\n    ScoredDocIDsIterator it = collection.iterator();\n    while (it.next()) {\n      pq.insertWithReuse((int)(it.getDocID() * PHI_32) & 0x7FFFFFFF);\n    }\n    if (RandomSample.returnTimings) {\n      times[1] = System.currentTimeMillis();\n    }\n    /*\n     * Extract heap, convert weights back to original values, and return as integers.\n     */\n    Object[] heap = pq.getHeap();\n    for (int si = 0; si < sampleSize; si++) {\n      sample[si] = (int)(((IntPriorityQueue.MI)(heap[si+1])).value * PHI_32I) & 0x7FFFFFFF;\n    }\n    if (RandomSample.returnTimings) {\n      times[2] = System.currentTimeMillis();\n    }\n  } // end RandomSample.sample2()\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"99b17503f4e360f8140fe80a593268486cd718b4","date":1318337685,"type":5,"author":"Doron Cohen","isMerge":false,"pathNew":"modules/facet/src/java/org/apache/lucene/facet/search/sampling/RepeatableSampler#sample2(ScoredDocIDs,int,int[],long[]).mjava","pathOld":"modules/facet/src/java/org/apache/lucene/facet/util/RandomSample#sample2(ScoredDocIDs,int,int[],long[]).mjava","sourceNew":"  /**\n   * Returns <code>sample</code>.length values chosen from the first <code>collectionSize</code>\n   * locations of <code>collection</code>, using the HASHING algorithm. Performance measurements\n   * are returned in <code>times</code>, which must be an array of at least three longs. The first\n   * will be set when the algorithm starts; the second, when a hash key has been calculated and\n   * inserted into the priority queue for every element in the collection; and the third when the\n   * original elements associated with the keys remaining in the PQ have been stored in the sample\n   * array for return.\n   * <P>\n   * This algorithm slows as the sample size becomes a significant fraction of the collection\n   * size, because the PQ is as large as the sample set, and will not do early rejection of values\n   * below the minimum until it fills up, and a larger PQ contains more small values to be purged,\n   * resulting in less early rejection and more logN insertions.\n   * \n   * @param collection The set to be sampled.\n   * @param collectionSize The number of values to use (starting from first).\n   * @param sample The array in which to return the sample.\n   * @param times The times of three events, for measuring performance.\n   */\n  private static void sample2(ScoredDocIDs collection, int collectionSize, int[] sample, long[] times) \n  throws IOException {\n    if (returnTimings) {\n      times[0] = System.currentTimeMillis();\n    }\n    int sampleSize = sample.length;\n    IntPriorityQueue pq = new IntPriorityQueue(sampleSize);\n    /*\n     * Convert every value in the collection to a hashed \"weight\" value, and insert\n     * into a bounded PQ (retains only sampleSize highest weights).\n     */\n    ScoredDocIDsIterator it = collection.iterator();\n    while (it.next()) {\n      pq.insertWithReuse((int)(it.getDocID() * PHI_32) & 0x7FFFFFFF);\n    }\n    if (returnTimings) {\n      times[1] = System.currentTimeMillis();\n    }\n    /*\n     * Extract heap, convert weights back to original values, and return as integers.\n     */\n    Object[] heap = pq.getHeap();\n    for (int si = 0; si < sampleSize; si++) {\n      sample[si] = (int)(((IntPriorityQueue.MI)(heap[si+1])).value * PHI_32I) & 0x7FFFFFFF;\n    }\n    if (returnTimings) {\n      times[2] = System.currentTimeMillis();\n    }\n  }\n\n","sourceOld":"  /**\n   * Returns <code>sample</code>.length values chosen from the first <code>collectionSize</code>\n   * locations of <code>collection</code>, using the HASHING algorithm. Performance measurements\n   * are returned in <code>times</code>, which must be an array of at least three longs. The first\n   * will be set when the algorithm starts; the second, when a hash key has been calculated and\n   * inserted into the priority queue for every element in the collection; and the third when the\n   * original elements associated with the keys remaining in the PQ have been stored in the sample\n   * array for return.\n   * <P>\n   * This algorithm slows as the sample size becomes a significant fraction of the collection\n   * size, because the PQ is as large as the sample set, and will not do early rejection of values\n   * below the minimum until it fills up, and a larger PQ contains more small values to be purged,\n   * resulting in less early rejection and more logN insertions.\n   * \n   * @param collection The set to be sampled.\n   * @param collectionSize The number of values to use (starting from first).\n   * @param sample The array in which to return the sample.\n   * @param times The times of three events, for measuring performance.\n   */\n  private static void sample2(ScoredDocIDs collection, int collectionSize, int[] sample, long[] times) \n  throws IOException {\n    if (RandomSample.returnTimings) {\n      times[0] = System.currentTimeMillis();\n    }\n    int sampleSize = sample.length;\n    IntPriorityQueue pq = new IntPriorityQueue(sampleSize);\n    /*\n     * Convert every value in the collection to a hashed \"weight\" value, and insert\n     * into a bounded PQ (retains only sampleSize highest weights).\n     */\n    ScoredDocIDsIterator it = collection.iterator();\n    while (it.next()) {\n      pq.insertWithReuse((int)(it.getDocID() * PHI_32) & 0x7FFFFFFF);\n    }\n    if (RandomSample.returnTimings) {\n      times[1] = System.currentTimeMillis();\n    }\n    /*\n     * Extract heap, convert weights back to original values, and return as integers.\n     */\n    Object[] heap = pq.getHeap();\n    for (int si = 0; si < sampleSize; si++) {\n      sample[si] = (int)(((IntPriorityQueue.MI)(heap[si+1])).value * PHI_32I) & 0x7FFFFFFF;\n    }\n    if (RandomSample.returnTimings) {\n      times[2] = System.currentTimeMillis();\n    }\n  } // end RandomSample.sample2()\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"99b17503f4e360f8140fe80a593268486cd718b4":["89f15687f60bd49cd3d9de427e85c17fd9397d61"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d083e83f225b11e5fdd900e83d26ddb385b6955c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","89f15687f60bd49cd3d9de427e85c17fd9397d61"],"89f15687f60bd49cd3d9de427e85c17fd9397d61":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"817d8435e9135b756f08ce6710ab0baac51bdf88":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","89f15687f60bd49cd3d9de427e85c17fd9397d61"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["99b17503f4e360f8140fe80a593268486cd718b4"]},"commit2Childs":{"99b17503f4e360f8140fe80a593268486cd718b4":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["d083e83f225b11e5fdd900e83d26ddb385b6955c","89f15687f60bd49cd3d9de427e85c17fd9397d61","817d8435e9135b756f08ce6710ab0baac51bdf88"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":[],"89f15687f60bd49cd3d9de427e85c17fd9397d61":["99b17503f4e360f8140fe80a593268486cd718b4","d083e83f225b11e5fdd900e83d26ddb385b6955c","817d8435e9135b756f08ce6710ab0baac51bdf88"],"817d8435e9135b756f08ce6710ab0baac51bdf88":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["d083e83f225b11e5fdd900e83d26ddb385b6955c","817d8435e9135b756f08ce6710ab0baac51bdf88","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}