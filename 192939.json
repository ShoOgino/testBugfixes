{"path":"lucene/core/src/java/org/apache/lucene/analysis/AbstractAnalysisFactory#getSnowballWordSet(ResourceLoader,String,boolean).mjava","commits":[{"id":"313c36388b6cae6118f75a1860ad0ba0af7e1344","date":1601279368,"type":1,"author":"Tomoko Uchida","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/analysis/AbstractAnalysisFactory#getSnowballWordSet(ResourceLoader,String,boolean).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/util/AbstractAnalysisFactory#getSnowballWordSet(ResourceLoader,String,boolean).mjava","sourceNew":"  /** same as {@link #getWordSet(ResourceLoader, String, boolean)},\n   * except the input is in snowball format. */\n  protected final CharArraySet getSnowballWordSet(ResourceLoader loader,\n      String wordFiles, boolean ignoreCase) throws IOException {\n    List<String> files = splitFileNames(wordFiles);\n    CharArraySet words = null;\n    if (files.size() > 0) {\n      // default stopwords list has 35 or so words, but maybe don't make it that\n      // big to start\n      words = new CharArraySet(files.size() * 10, ignoreCase);\n      for (String file : files) {\n        InputStream stream = null;\n        Reader reader = null;\n        try {\n          stream = loader.openResource(file.trim());\n          CharsetDecoder decoder = StandardCharsets.UTF_8.newDecoder()\n              .onMalformedInput(CodingErrorAction.REPORT)\n              .onUnmappableCharacter(CodingErrorAction.REPORT);\n          reader = new InputStreamReader(stream, decoder);\n          WordlistLoader.getSnowballWordSet(reader, words);\n        } finally {\n          IOUtils.closeWhileHandlingException(reader, stream);\n        }\n      }\n    }\n    return words;\n  }\n\n","sourceOld":"  /** same as {@link #getWordSet(ResourceLoader, String, boolean)},\n   * except the input is in snowball format. */\n  protected final CharArraySet getSnowballWordSet(ResourceLoader loader,\n      String wordFiles, boolean ignoreCase) throws IOException {\n    List<String> files = splitFileNames(wordFiles);\n    CharArraySet words = null;\n    if (files.size() > 0) {\n      // default stopwords list has 35 or so words, but maybe don't make it that\n      // big to start\n      words = new CharArraySet(files.size() * 10, ignoreCase);\n      for (String file : files) {\n        InputStream stream = null;\n        Reader reader = null;\n        try {\n          stream = loader.openResource(file.trim());\n          CharsetDecoder decoder = StandardCharsets.UTF_8.newDecoder()\n              .onMalformedInput(CodingErrorAction.REPORT)\n              .onUnmappableCharacter(CodingErrorAction.REPORT);\n          reader = new InputStreamReader(stream, decoder);\n          WordlistLoader.getSnowballWordSet(reader, words);\n        } finally {\n          IOUtils.closeWhileHandlingException(reader, stream);\n        }\n      }\n    }\n    return words;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"313c36388b6cae6118f75a1860ad0ba0af7e1344":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["313c36388b6cae6118f75a1860ad0ba0af7e1344"]},"commit2Childs":{"313c36388b6cae6118f75a1860ad0ba0af7e1344":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["313c36388b6cae6118f75a1860ad0ba0af7e1344"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}