{"path":"solr/core/src/java/org/apache/solr/search/IGainTermsQParserPlugin.IGainTermsCollector#finish().mjava","commits":[{"id":"f6b1e64caa933f6fb3c0494afd6ca2597f55cc91","date":1470238980,"type":0,"author":"jbernste","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/IGainTermsQParserPlugin.IGainTermsCollector#finish().mjava","pathOld":"/dev/null","sourceNew":"    @Override\n    public void finish() throws IOException {\n      NamedList<Double> analytics = new NamedList<Double>();\n      NamedList<Integer> topFreq = new NamedList();\n\n      NamedList<Integer> allFreq = new NamedList();\n\n      rb.rsp.add(\"featuredTerms\", analytics);\n      rb.rsp.add(\"docFreq\", topFreq);\n      rb.rsp.add(\"numDocs\", count);\n\n      TreeSet<TermWithScore> topTerms = new TreeSet<>();\n\n      double numDocs = count;\n      double pc = numPositiveDocs / numDocs;\n      double entropyC = binaryEntropy(pc);\n\n      Terms terms = MultiFields.getFields(searcher.getIndexReader()).terms(field);\n      TermsEnum termsEnum = terms.iterator();\n      BytesRef term;\n      PostingsEnum postingsEnum = null;\n      while ((term = termsEnum.next()) != null) {\n        postingsEnum = termsEnum.postings(postingsEnum);\n        int xc = 0;\n        int nc = 0;\n        while (postingsEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n          if (positiveSet.get(postingsEnum.docID())) {\n            xc++;\n          } else if (negativeSet.get(postingsEnum.docID())) {\n            nc++;\n          }\n        }\n\n        int docFreq = xc+nc;\n\n        double entropyContainsTerm = binaryEntropy( (double) xc / docFreq );\n        double entropyNotContainsTerm = binaryEntropy( (double) (numPositiveDocs - xc) / (numDocs - docFreq + 1) );\n        double score = entropyC - ( (docFreq / numDocs) * entropyContainsTerm + (1.0 - docFreq / numDocs) * entropyNotContainsTerm);\n\n        topFreq.add(term.utf8ToString(), docFreq);\n        if (topTerms.size() < numTerms) {\n          topTerms.add(new TermWithScore(term.utf8ToString(), score));\n        } else  {\n          if (topTerms.first().score < score) {\n            topTerms.pollFirst();\n            topTerms.add(new TermWithScore(term.utf8ToString(), score));\n          }\n        }\n      }\n\n      for (TermWithScore topTerm : topTerms) {\n        analytics.add(topTerm.term, topTerm.score);\n        topFreq.add(topTerm.term, allFreq.get(topTerm.term));\n      }\n\n      if (this.delegate instanceof DelegatingCollector) {\n        ((DelegatingCollector) this.delegate).finish();\n      }\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["3185d4c8bb14af74e2ef0bde19f22e33b954b568"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3b013574eedcdbac35dc7e35b0ee616ffc38895d","date":1470897818,"type":0,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/IGainTermsQParserPlugin.IGainTermsCollector#finish().mjava","pathOld":"/dev/null","sourceNew":"    @Override\n    public void finish() throws IOException {\n      NamedList<Double> analytics = new NamedList<Double>();\n      NamedList<Integer> topFreq = new NamedList();\n\n      NamedList<Integer> allFreq = new NamedList();\n\n      rb.rsp.add(\"featuredTerms\", analytics);\n      rb.rsp.add(\"docFreq\", topFreq);\n      rb.rsp.add(\"numDocs\", count);\n\n      TreeSet<TermWithScore> topTerms = new TreeSet<>();\n\n      double numDocs = count;\n      double pc = numPositiveDocs / numDocs;\n      double entropyC = binaryEntropy(pc);\n\n      Terms terms = MultiFields.getFields(searcher.getIndexReader()).terms(field);\n      TermsEnum termsEnum = terms.iterator();\n      BytesRef term;\n      PostingsEnum postingsEnum = null;\n      while ((term = termsEnum.next()) != null) {\n        postingsEnum = termsEnum.postings(postingsEnum);\n        int xc = 0;\n        int nc = 0;\n        while (postingsEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n          if (positiveSet.get(postingsEnum.docID())) {\n            xc++;\n          } else if (negativeSet.get(postingsEnum.docID())) {\n            nc++;\n          }\n        }\n\n        int docFreq = xc+nc;\n\n        double entropyContainsTerm = binaryEntropy( (double) xc / docFreq );\n        double entropyNotContainsTerm = binaryEntropy( (double) (numPositiveDocs - xc) / (numDocs - docFreq + 1) );\n        double score = entropyC - ( (docFreq / numDocs) * entropyContainsTerm + (1.0 - docFreq / numDocs) * entropyNotContainsTerm);\n\n        topFreq.add(term.utf8ToString(), docFreq);\n        if (topTerms.size() < numTerms) {\n          topTerms.add(new TermWithScore(term.utf8ToString(), score));\n        } else  {\n          if (topTerms.first().score < score) {\n            topTerms.pollFirst();\n            topTerms.add(new TermWithScore(term.utf8ToString(), score));\n          }\n        }\n      }\n\n      for (TermWithScore topTerm : topTerms) {\n        analytics.add(topTerm.term, topTerm.score);\n        topFreq.add(topTerm.term, allFreq.get(topTerm.term));\n      }\n\n      if (this.delegate instanceof DelegatingCollector) {\n        ((DelegatingCollector) this.delegate).finish();\n      }\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":0,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/IGainTermsQParserPlugin.IGainTermsCollector#finish().mjava","pathOld":"/dev/null","sourceNew":"    @Override\n    public void finish() throws IOException {\n      NamedList<Double> analytics = new NamedList<Double>();\n      NamedList<Integer> topFreq = new NamedList();\n\n      NamedList<Integer> allFreq = new NamedList();\n\n      rb.rsp.add(\"featuredTerms\", analytics);\n      rb.rsp.add(\"docFreq\", topFreq);\n      rb.rsp.add(\"numDocs\", count);\n\n      TreeSet<TermWithScore> topTerms = new TreeSet<>();\n\n      double numDocs = count;\n      double pc = numPositiveDocs / numDocs;\n      double entropyC = binaryEntropy(pc);\n\n      Terms terms = MultiFields.getFields(searcher.getIndexReader()).terms(field);\n      TermsEnum termsEnum = terms.iterator();\n      BytesRef term;\n      PostingsEnum postingsEnum = null;\n      while ((term = termsEnum.next()) != null) {\n        postingsEnum = termsEnum.postings(postingsEnum);\n        int xc = 0;\n        int nc = 0;\n        while (postingsEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n          if (positiveSet.get(postingsEnum.docID())) {\n            xc++;\n          } else if (negativeSet.get(postingsEnum.docID())) {\n            nc++;\n          }\n        }\n\n        int docFreq = xc+nc;\n\n        double entropyContainsTerm = binaryEntropy( (double) xc / docFreq );\n        double entropyNotContainsTerm = binaryEntropy( (double) (numPositiveDocs - xc) / (numDocs - docFreq + 1) );\n        double score = entropyC - ( (docFreq / numDocs) * entropyContainsTerm + (1.0 - docFreq / numDocs) * entropyNotContainsTerm);\n\n        topFreq.add(term.utf8ToString(), docFreq);\n        if (topTerms.size() < numTerms) {\n          topTerms.add(new TermWithScore(term.utf8ToString(), score));\n        } else  {\n          if (topTerms.first().score < score) {\n            topTerms.pollFirst();\n            topTerms.add(new TermWithScore(term.utf8ToString(), score));\n          }\n        }\n      }\n\n      for (TermWithScore topTerm : topTerms) {\n        analytics.add(topTerm.term, topTerm.score);\n        topFreq.add(topTerm.term, allFreq.get(topTerm.term));\n      }\n\n      if (this.delegate instanceof DelegatingCollector) {\n        ((DelegatingCollector) this.delegate).finish();\n      }\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3185d4c8bb14af74e2ef0bde19f22e33b954b568","date":1497065963,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/IGainTermsQParserPlugin.IGainTermsCollector#finish().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/IGainTermsQParserPlugin.IGainTermsCollector#finish().mjava","sourceNew":"    @Override\n    public void finish() throws IOException {\n      NamedList<Double> analytics = new NamedList<Double>();\n      NamedList<Integer> topFreq = new NamedList();\n\n      NamedList<Integer> allFreq = new NamedList();\n\n      rb.rsp.add(\"featuredTerms\", analytics);\n      rb.rsp.add(\"docFreq\", topFreq);\n      rb.rsp.add(\"numDocs\", count);\n\n      TreeSet<TermWithScore> topTerms = new TreeSet<>();\n\n      double numDocs = count;\n      double pc = numPositiveDocs / numDocs;\n      double entropyC = binaryEntropy(pc);\n\n      Terms terms = ((SolrIndexSearcher)searcher).getSlowAtomicReader().terms(field);\n      TermsEnum termsEnum = terms == null ? TermsEnum.EMPTY : terms.iterator();\n      BytesRef term;\n      PostingsEnum postingsEnum = null;\n      while ((term = termsEnum.next()) != null) {\n        postingsEnum = termsEnum.postings(postingsEnum);\n        int xc = 0;\n        int nc = 0;\n        while (postingsEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n          if (positiveSet.get(postingsEnum.docID())) {\n            xc++;\n          } else if (negativeSet.get(postingsEnum.docID())) {\n            nc++;\n          }\n        }\n\n        int docFreq = xc+nc;\n\n        double entropyContainsTerm = binaryEntropy( (double) xc / docFreq );\n        double entropyNotContainsTerm = binaryEntropy( (double) (numPositiveDocs - xc) / (numDocs - docFreq + 1) );\n        double score = entropyC - ( (docFreq / numDocs) * entropyContainsTerm + (1.0 - docFreq / numDocs) * entropyNotContainsTerm);\n\n        topFreq.add(term.utf8ToString(), docFreq);\n        if (topTerms.size() < numTerms) {\n          topTerms.add(new TermWithScore(term.utf8ToString(), score));\n        } else  {\n          if (topTerms.first().score < score) {\n            topTerms.pollFirst();\n            topTerms.add(new TermWithScore(term.utf8ToString(), score));\n          }\n        }\n      }\n\n      for (TermWithScore topTerm : topTerms) {\n        analytics.add(topTerm.term, topTerm.score);\n        topFreq.add(topTerm.term, allFreq.get(topTerm.term));\n      }\n\n      if (this.delegate instanceof DelegatingCollector) {\n        ((DelegatingCollector) this.delegate).finish();\n      }\n    }\n\n","sourceOld":"    @Override\n    public void finish() throws IOException {\n      NamedList<Double> analytics = new NamedList<Double>();\n      NamedList<Integer> topFreq = new NamedList();\n\n      NamedList<Integer> allFreq = new NamedList();\n\n      rb.rsp.add(\"featuredTerms\", analytics);\n      rb.rsp.add(\"docFreq\", topFreq);\n      rb.rsp.add(\"numDocs\", count);\n\n      TreeSet<TermWithScore> topTerms = new TreeSet<>();\n\n      double numDocs = count;\n      double pc = numPositiveDocs / numDocs;\n      double entropyC = binaryEntropy(pc);\n\n      Terms terms = MultiFields.getFields(searcher.getIndexReader()).terms(field);\n      TermsEnum termsEnum = terms.iterator();\n      BytesRef term;\n      PostingsEnum postingsEnum = null;\n      while ((term = termsEnum.next()) != null) {\n        postingsEnum = termsEnum.postings(postingsEnum);\n        int xc = 0;\n        int nc = 0;\n        while (postingsEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n          if (positiveSet.get(postingsEnum.docID())) {\n            xc++;\n          } else if (negativeSet.get(postingsEnum.docID())) {\n            nc++;\n          }\n        }\n\n        int docFreq = xc+nc;\n\n        double entropyContainsTerm = binaryEntropy( (double) xc / docFreq );\n        double entropyNotContainsTerm = binaryEntropy( (double) (numPositiveDocs - xc) / (numDocs - docFreq + 1) );\n        double score = entropyC - ( (docFreq / numDocs) * entropyContainsTerm + (1.0 - docFreq / numDocs) * entropyNotContainsTerm);\n\n        topFreq.add(term.utf8ToString(), docFreq);\n        if (topTerms.size() < numTerms) {\n          topTerms.add(new TermWithScore(term.utf8ToString(), score));\n        } else  {\n          if (topTerms.first().score < score) {\n            topTerms.pollFirst();\n            topTerms.add(new TermWithScore(term.utf8ToString(), score));\n          }\n        }\n      }\n\n      for (TermWithScore topTerm : topTerms) {\n        analytics.add(topTerm.term, topTerm.score);\n        topFreq.add(topTerm.term, allFreq.get(topTerm.term));\n      }\n\n      if (this.delegate instanceof DelegatingCollector) {\n        ((DelegatingCollector) this.delegate).finish();\n      }\n    }\n\n","bugFix":["f6b1e64caa933f6fb3c0494afd6ca2597f55cc91"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9","date":1498028748,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/IGainTermsQParserPlugin.IGainTermsCollector#finish().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/IGainTermsQParserPlugin.IGainTermsCollector#finish().mjava","sourceNew":"    @Override\n    public void finish() throws IOException {\n      NamedList<Double> analytics = new NamedList<Double>();\n      NamedList<Integer> topFreq = new NamedList();\n\n      NamedList<Integer> allFreq = new NamedList();\n\n      rb.rsp.add(\"featuredTerms\", analytics);\n      rb.rsp.add(\"docFreq\", topFreq);\n      rb.rsp.add(\"numDocs\", count);\n\n      TreeSet<TermWithScore> topTerms = new TreeSet<>();\n\n      double numDocs = count;\n      double pc = numPositiveDocs / numDocs;\n      double entropyC = binaryEntropy(pc);\n\n      Terms terms = ((SolrIndexSearcher)searcher).getSlowAtomicReader().terms(field);\n      TermsEnum termsEnum = terms == null ? TermsEnum.EMPTY : terms.iterator();\n      BytesRef term;\n      PostingsEnum postingsEnum = null;\n      while ((term = termsEnum.next()) != null) {\n        postingsEnum = termsEnum.postings(postingsEnum);\n        int xc = 0;\n        int nc = 0;\n        while (postingsEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n          if (positiveSet.get(postingsEnum.docID())) {\n            xc++;\n          } else if (negativeSet.get(postingsEnum.docID())) {\n            nc++;\n          }\n        }\n\n        int docFreq = xc+nc;\n\n        double entropyContainsTerm = binaryEntropy( (double) xc / docFreq );\n        double entropyNotContainsTerm = binaryEntropy( (double) (numPositiveDocs - xc) / (numDocs - docFreq + 1) );\n        double score = entropyC - ( (docFreq / numDocs) * entropyContainsTerm + (1.0 - docFreq / numDocs) * entropyNotContainsTerm);\n\n        topFreq.add(term.utf8ToString(), docFreq);\n        if (topTerms.size() < numTerms) {\n          topTerms.add(new TermWithScore(term.utf8ToString(), score));\n        } else  {\n          if (topTerms.first().score < score) {\n            topTerms.pollFirst();\n            topTerms.add(new TermWithScore(term.utf8ToString(), score));\n          }\n        }\n      }\n\n      for (TermWithScore topTerm : topTerms) {\n        analytics.add(topTerm.term, topTerm.score);\n        topFreq.add(topTerm.term, allFreq.get(topTerm.term));\n      }\n\n      if (this.delegate instanceof DelegatingCollector) {\n        ((DelegatingCollector) this.delegate).finish();\n      }\n    }\n\n","sourceOld":"    @Override\n    public void finish() throws IOException {\n      NamedList<Double> analytics = new NamedList<Double>();\n      NamedList<Integer> topFreq = new NamedList();\n\n      NamedList<Integer> allFreq = new NamedList();\n\n      rb.rsp.add(\"featuredTerms\", analytics);\n      rb.rsp.add(\"docFreq\", topFreq);\n      rb.rsp.add(\"numDocs\", count);\n\n      TreeSet<TermWithScore> topTerms = new TreeSet<>();\n\n      double numDocs = count;\n      double pc = numPositiveDocs / numDocs;\n      double entropyC = binaryEntropy(pc);\n\n      Terms terms = MultiFields.getFields(searcher.getIndexReader()).terms(field);\n      TermsEnum termsEnum = terms.iterator();\n      BytesRef term;\n      PostingsEnum postingsEnum = null;\n      while ((term = termsEnum.next()) != null) {\n        postingsEnum = termsEnum.postings(postingsEnum);\n        int xc = 0;\n        int nc = 0;\n        while (postingsEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n          if (positiveSet.get(postingsEnum.docID())) {\n            xc++;\n          } else if (negativeSet.get(postingsEnum.docID())) {\n            nc++;\n          }\n        }\n\n        int docFreq = xc+nc;\n\n        double entropyContainsTerm = binaryEntropy( (double) xc / docFreq );\n        double entropyNotContainsTerm = binaryEntropy( (double) (numPositiveDocs - xc) / (numDocs - docFreq + 1) );\n        double score = entropyC - ( (docFreq / numDocs) * entropyContainsTerm + (1.0 - docFreq / numDocs) * entropyNotContainsTerm);\n\n        topFreq.add(term.utf8ToString(), docFreq);\n        if (topTerms.size() < numTerms) {\n          topTerms.add(new TermWithScore(term.utf8ToString(), score));\n        } else  {\n          if (topTerms.first().score < score) {\n            topTerms.pollFirst();\n            topTerms.add(new TermWithScore(term.utf8ToString(), score));\n          }\n        }\n      }\n\n      for (TermWithScore topTerm : topTerms) {\n        analytics.add(topTerm.term, topTerm.score);\n        topFreq.add(topTerm.term, allFreq.get(topTerm.term));\n      }\n\n      if (this.delegate instanceof DelegatingCollector) {\n        ((DelegatingCollector) this.delegate).finish();\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"28288370235ed02234a64753cdbf0c6ec096304a","date":1498726817,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/IGainTermsQParserPlugin.IGainTermsCollector#finish().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/IGainTermsQParserPlugin.IGainTermsCollector#finish().mjava","sourceNew":"    @Override\n    public void finish() throws IOException {\n      NamedList<Double> analytics = new NamedList<Double>();\n      NamedList<Integer> topFreq = new NamedList();\n\n      NamedList<Integer> allFreq = new NamedList();\n\n      rb.rsp.add(\"featuredTerms\", analytics);\n      rb.rsp.add(\"docFreq\", topFreq);\n      rb.rsp.add(\"numDocs\", count);\n\n      TreeSet<TermWithScore> topTerms = new TreeSet<>();\n\n      double numDocs = count;\n      double pc = numPositiveDocs / numDocs;\n      double entropyC = binaryEntropy(pc);\n\n      Terms terms = ((SolrIndexSearcher)searcher).getSlowAtomicReader().terms(field);\n      TermsEnum termsEnum = terms == null ? TermsEnum.EMPTY : terms.iterator();\n      BytesRef term;\n      PostingsEnum postingsEnum = null;\n      while ((term = termsEnum.next()) != null) {\n        postingsEnum = termsEnum.postings(postingsEnum);\n        int xc = 0;\n        int nc = 0;\n        while (postingsEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n          if (positiveSet.get(postingsEnum.docID())) {\n            xc++;\n          } else if (negativeSet.get(postingsEnum.docID())) {\n            nc++;\n          }\n        }\n\n        int docFreq = xc+nc;\n\n        double entropyContainsTerm = binaryEntropy( (double) xc / docFreq );\n        double entropyNotContainsTerm = binaryEntropy( (double) (numPositiveDocs - xc) / (numDocs - docFreq + 1) );\n        double score = entropyC - ( (docFreq / numDocs) * entropyContainsTerm + (1.0 - docFreq / numDocs) * entropyNotContainsTerm);\n\n        topFreq.add(term.utf8ToString(), docFreq);\n        if (topTerms.size() < numTerms) {\n          topTerms.add(new TermWithScore(term.utf8ToString(), score));\n        } else  {\n          if (topTerms.first().score < score) {\n            topTerms.pollFirst();\n            topTerms.add(new TermWithScore(term.utf8ToString(), score));\n          }\n        }\n      }\n\n      for (TermWithScore topTerm : topTerms) {\n        analytics.add(topTerm.term, topTerm.score);\n        topFreq.add(topTerm.term, allFreq.get(topTerm.term));\n      }\n\n      if (this.delegate instanceof DelegatingCollector) {\n        ((DelegatingCollector) this.delegate).finish();\n      }\n    }\n\n","sourceOld":"    @Override\n    public void finish() throws IOException {\n      NamedList<Double> analytics = new NamedList<Double>();\n      NamedList<Integer> topFreq = new NamedList();\n\n      NamedList<Integer> allFreq = new NamedList();\n\n      rb.rsp.add(\"featuredTerms\", analytics);\n      rb.rsp.add(\"docFreq\", topFreq);\n      rb.rsp.add(\"numDocs\", count);\n\n      TreeSet<TermWithScore> topTerms = new TreeSet<>();\n\n      double numDocs = count;\n      double pc = numPositiveDocs / numDocs;\n      double entropyC = binaryEntropy(pc);\n\n      Terms terms = MultiFields.getFields(searcher.getIndexReader()).terms(field);\n      TermsEnum termsEnum = terms.iterator();\n      BytesRef term;\n      PostingsEnum postingsEnum = null;\n      while ((term = termsEnum.next()) != null) {\n        postingsEnum = termsEnum.postings(postingsEnum);\n        int xc = 0;\n        int nc = 0;\n        while (postingsEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n          if (positiveSet.get(postingsEnum.docID())) {\n            xc++;\n          } else if (negativeSet.get(postingsEnum.docID())) {\n            nc++;\n          }\n        }\n\n        int docFreq = xc+nc;\n\n        double entropyContainsTerm = binaryEntropy( (double) xc / docFreq );\n        double entropyNotContainsTerm = binaryEntropy( (double) (numPositiveDocs - xc) / (numDocs - docFreq + 1) );\n        double score = entropyC - ( (docFreq / numDocs) * entropyContainsTerm + (1.0 - docFreq / numDocs) * entropyNotContainsTerm);\n\n        topFreq.add(term.utf8ToString(), docFreq);\n        if (topTerms.size() < numTerms) {\n          topTerms.add(new TermWithScore(term.utf8ToString(), score));\n        } else  {\n          if (topTerms.first().score < score) {\n            topTerms.pollFirst();\n            topTerms.add(new TermWithScore(term.utf8ToString(), score));\n          }\n        }\n      }\n\n      for (TermWithScore topTerm : topTerms) {\n        analytics.add(topTerm.term, topTerm.score);\n        topFreq.add(topTerm.term, allFreq.get(topTerm.term));\n      }\n\n      if (this.delegate instanceof DelegatingCollector) {\n        ((DelegatingCollector) this.delegate).finish();\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"50dfd19525c8d73e856dca6edb64b7aea074037f","date":1591579225,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/IGainTermsQParserPlugin.IGainTermsCollector#finish().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/IGainTermsQParserPlugin.IGainTermsCollector#finish().mjava","sourceNew":"    @Override\n    public void finish() throws IOException {\n      NamedList<Double> analytics = new NamedList<Double>();\n      @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n      NamedList<Integer> topFreq = new NamedList();\n\n      @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n      NamedList<Integer> allFreq = new NamedList();\n\n      rb.rsp.add(\"featuredTerms\", analytics);\n      rb.rsp.add(\"docFreq\", topFreq);\n      rb.rsp.add(\"numDocs\", count);\n\n      TreeSet<TermWithScore> topTerms = new TreeSet<>();\n\n      double numDocs = count;\n      double pc = numPositiveDocs / numDocs;\n      double entropyC = binaryEntropy(pc);\n\n      Terms terms = ((SolrIndexSearcher)searcher).getSlowAtomicReader().terms(field);\n      TermsEnum termsEnum = terms == null ? TermsEnum.EMPTY : terms.iterator();\n      BytesRef term;\n      PostingsEnum postingsEnum = null;\n      while ((term = termsEnum.next()) != null) {\n        postingsEnum = termsEnum.postings(postingsEnum);\n        int xc = 0;\n        int nc = 0;\n        while (postingsEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n          if (positiveSet.get(postingsEnum.docID())) {\n            xc++;\n          } else if (negativeSet.get(postingsEnum.docID())) {\n            nc++;\n          }\n        }\n\n        int docFreq = xc+nc;\n\n        double entropyContainsTerm = binaryEntropy( (double) xc / docFreq );\n        double entropyNotContainsTerm = binaryEntropy( (double) (numPositiveDocs - xc) / (numDocs - docFreq + 1) );\n        double score = entropyC - ( (docFreq / numDocs) * entropyContainsTerm + (1.0 - docFreq / numDocs) * entropyNotContainsTerm);\n\n        topFreq.add(term.utf8ToString(), docFreq);\n        if (topTerms.size() < numTerms) {\n          topTerms.add(new TermWithScore(term.utf8ToString(), score));\n        } else  {\n          if (topTerms.first().score < score) {\n            topTerms.pollFirst();\n            topTerms.add(new TermWithScore(term.utf8ToString(), score));\n          }\n        }\n      }\n\n      for (TermWithScore topTerm : topTerms) {\n        analytics.add(topTerm.term, topTerm.score);\n        topFreq.add(topTerm.term, allFreq.get(topTerm.term));\n      }\n\n      if (this.delegate instanceof DelegatingCollector) {\n        ((DelegatingCollector) this.delegate).finish();\n      }\n    }\n\n","sourceOld":"    @Override\n    public void finish() throws IOException {\n      NamedList<Double> analytics = new NamedList<Double>();\n      NamedList<Integer> topFreq = new NamedList();\n\n      NamedList<Integer> allFreq = new NamedList();\n\n      rb.rsp.add(\"featuredTerms\", analytics);\n      rb.rsp.add(\"docFreq\", topFreq);\n      rb.rsp.add(\"numDocs\", count);\n\n      TreeSet<TermWithScore> topTerms = new TreeSet<>();\n\n      double numDocs = count;\n      double pc = numPositiveDocs / numDocs;\n      double entropyC = binaryEntropy(pc);\n\n      Terms terms = ((SolrIndexSearcher)searcher).getSlowAtomicReader().terms(field);\n      TermsEnum termsEnum = terms == null ? TermsEnum.EMPTY : terms.iterator();\n      BytesRef term;\n      PostingsEnum postingsEnum = null;\n      while ((term = termsEnum.next()) != null) {\n        postingsEnum = termsEnum.postings(postingsEnum);\n        int xc = 0;\n        int nc = 0;\n        while (postingsEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n          if (positiveSet.get(postingsEnum.docID())) {\n            xc++;\n          } else if (negativeSet.get(postingsEnum.docID())) {\n            nc++;\n          }\n        }\n\n        int docFreq = xc+nc;\n\n        double entropyContainsTerm = binaryEntropy( (double) xc / docFreq );\n        double entropyNotContainsTerm = binaryEntropy( (double) (numPositiveDocs - xc) / (numDocs - docFreq + 1) );\n        double score = entropyC - ( (docFreq / numDocs) * entropyContainsTerm + (1.0 - docFreq / numDocs) * entropyNotContainsTerm);\n\n        topFreq.add(term.utf8ToString(), docFreq);\n        if (topTerms.size() < numTerms) {\n          topTerms.add(new TermWithScore(term.utf8ToString(), score));\n        } else  {\n          if (topTerms.first().score < score) {\n            topTerms.pollFirst();\n            topTerms.add(new TermWithScore(term.utf8ToString(), score));\n          }\n        }\n      }\n\n      for (TermWithScore topTerm : topTerms) {\n        analytics.add(topTerm.term, topTerm.score);\n        topFreq.add(topTerm.term, allFreq.get(topTerm.term));\n      }\n\n      if (this.delegate instanceof DelegatingCollector) {\n        ((DelegatingCollector) this.delegate).finish();\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"3185d4c8bb14af74e2ef0bde19f22e33b954b568":["f6b1e64caa933f6fb3c0494afd6ca2597f55cc91"],"50dfd19525c8d73e856dca6edb64b7aea074037f":["28288370235ed02234a64753cdbf0c6ec096304a"],"f6b1e64caa933f6fb3c0494afd6ca2597f55cc91":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"28288370235ed02234a64753cdbf0c6ec096304a":["f6b1e64caa933f6fb3c0494afd6ca2597f55cc91","3185d4c8bb14af74e2ef0bde19f22e33b954b568"],"2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9":["f6b1e64caa933f6fb3c0494afd6ca2597f55cc91","3185d4c8bb14af74e2ef0bde19f22e33b954b568"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","f6b1e64caa933f6fb3c0494afd6ca2597f55cc91"],"3b013574eedcdbac35dc7e35b0ee616ffc38895d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","f6b1e64caa933f6fb3c0494afd6ca2597f55cc91"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["50dfd19525c8d73e856dca6edb64b7aea074037f"]},"commit2Childs":{"3185d4c8bb14af74e2ef0bde19f22e33b954b568":["28288370235ed02234a64753cdbf0c6ec096304a","2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9"],"50dfd19525c8d73e856dca6edb64b7aea074037f":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"f6b1e64caa933f6fb3c0494afd6ca2597f55cc91":["3185d4c8bb14af74e2ef0bde19f22e33b954b568","28288370235ed02234a64753cdbf0c6ec096304a","2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","3b013574eedcdbac35dc7e35b0ee616ffc38895d"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["f6b1e64caa933f6fb3c0494afd6ca2597f55cc91","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","3b013574eedcdbac35dc7e35b0ee616ffc38895d"],"28288370235ed02234a64753cdbf0c6ec096304a":["50dfd19525c8d73e856dca6edb64b7aea074037f"],"2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9":[],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"3b013574eedcdbac35dc7e35b0ee616ffc38895d":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","3b013574eedcdbac35dc7e35b0ee616ffc38895d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}